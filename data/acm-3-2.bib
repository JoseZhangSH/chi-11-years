
@inproceedings{andres_introducing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Introducing {Peripheral} {Awareness} as a {Neurological} {State} for {Human}-{Computer} {Integration}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376128},
	doi = {10.1145/3313831.3376128},
	abstract = {In this work we introduce peripheral awareness as a neurological state for real-time human-computer integration, where the human is assisted by a computer to interact with the world. Changes to the field of view in peripheral awareness have been linked with quality of human performance. This instinctive narrowing of vision that occurs as a threat is perceived has implications in activities that benefit from the user having a wide field of view, such as cycling to navigate the environment. We present "Ena", a novel EEG-eBike system that draws from the user's neural activity to determine when the user is in a state of peripheral awareness to regulate engine support. A study with 20 participants revealed various themes and tactics suggesting that peripheral awareness as a neurological state is viable to align human-machine integration with internal bodily processes. Ena suggests that our work facilitates a safe and enjoyable human-computer integration experience.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Andres, Josh and schraefel, m.c. and Semertzidis, Nathan and Dwivedi, Brahmi and Kulwe, Yutika C. and von Kaenel, Juerg and Mueller, Florian Floyd},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {human-computer-integration, human-system partnership, inbodied interaction, peripheral awareness},
	pages = {1--13},
}

@inproceedings{mor_venous_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Venous {Materials}: {Towards} {Interactive} {Fluidic} {Mechanisms}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376129},
	doi = {10.1145/3313831.3376129},
	abstract = {Venous Materials is a novel concept and approach of an interactive material utilizing fluidic channels. We present a design method for fluidic mechanisms that respond to deformation by mechanical inputs from the user, such as pressure and bending. We designed a set of primitive venous structures that act as embedded analog fluidic sensors, displaying flow and color change. In this paper, we consider the fluid as the medium to drive tangible information triggered by deformation, and at the same time, to function as a responsive display of that information. To provide users with a simple way to create and validate designs of fluidic structures, we built a software platform and design tool UI. This design tool allows users to quickly design the geometry, and simulate the flow with intended mechanical force dynamically. We present a range of applications that demonstrate how Venous Materials can be utilized to augment interactivity of everyday physical objects.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mor, Hila and Yu, Tianyu and Nakagaki, Ken and Miller, Benjamin Harvey and Jia, Yichen and Ishii, Hiroshi},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {human material interactions, microfluidics, programmable materials},
	pages = {1--14},
}

@inproceedings{yu_considering_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Considering {Parents} in {Coding} {Kit} {Design}: {Understanding} {Parents}' {Perspectives} and {Roles}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376130},
	doi = {10.1145/3313831.3376130},
	abstract = {As education researchers, policymakers, and industry leaders recognize the importance of computing, many coding kits (toys and apps) have emerged to help young children learn to code at home. However, how parents perceive and support their children's use of the kits at home are less understood. In this study, we performed semi-structured interviews with eighteen parents who obtained coding kits for their young children for home use. The results show parents expected their kids to have fun and meaningful interactions with the kits. In supporting the play, parents took on various roles, mostly acting as spectator, scaffolder, and teacher. While parents perceived benefits of coding kits like a changed perspective on coding, they also reported concerns, such as their limited programming knowledge to provide help. Finally, we reflect on design and research implications to develop coding kits that consider parents' perspectives and important roles in supporting young children's exploration with computational thinking.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yu, Junnan and Bai, Chenke and Roque, Ricarose},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {educational technology, coding toys and kits, informal learning, parent roles, parents' perspectives, young children},
	pages = {1--14},
}

@inproceedings{xiao_if_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {If {I} {Hear} {You} {Correctly}: {Building} and {Evaluating} {Interview} {Chatbots} with {Active} {Listening} {Skills}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376131},
	doi = {10.1145/3313831.3376131},
	abstract = {Interview chatbots engage users in a text-based conversation to draw out their views and opinions. It is, however, challenging to build effective interview chatbots that can handle user free-text responses to open-ended questions and deliver engaging user experience. As the first step, we are investigating the feasibility and effectiveness of using publicly available, practical AI technologies to build effective interview chatbots. To demonstrate feasibility, we built a prototype scoped to enable interview chatbots with a subset of active listening skills-the abilities to comprehend a user's input and respond properly. To evaluate the effectiveness of our prototype, we compared the performance of interview chatbots with or without active listening skills on four common interview topics in a live evaluation with 206 users. Our work presents practical design implications for building effective interview chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview tasks.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Xiao, Ziang and Zhou, Michelle X. and Chen, Wenxi and Yang, Huahai and Chi, Changyan},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {conversational agents, deep learning, active listening, ai chatbot, chatbot platform, interview chatbot},
	pages = {1--14},
}

@inproceedings{wang_blyncsync_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{BlyncSync}: {Enabling} {Multimodal} {Smartwatch} {Gestures} with {Synchronous} {Touch} and {Blink}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376132},
	doi = {10.1145/3313831.3376132},
	abstract = {Input techniques have been drawing abiding attention along with the continual miniaturization of personal computers. In this paper, we present BlyncSync, a novel multi-modal gesture set that leverages the synchronicity of touch and blink events to augment the input vocabulary of smartwatches with a rapid gesture, while at the same time, offers a solution to the false activation problem of blink-based input. BlyncSync contributes the concept of a mutual delimiter, where two modalities are used to jointly delimit the intention of each other's input. A study shows that BlyncSync is 33\% faster than using a baseline input delimiter (physical smartwatch button), with only 150ms in overhead cost compared to traditional touch events. Furthermore, our data indicates that the gesture can be tuned to elicit a true positive rate of 97\% and a false positive rate of 1.68\%.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Bryan and Grossman, Tovi},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {smartwatch, wearables, blyncsync, gaze ui, mobile hci, mutual delimiter},
	pages = {1--14},
}

@inproceedings{dai_making_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Making {Space} for {Social} {Sharing}: {Insights} from a {Community}-{Based} {Social} {Group} for {People} with {Dementia}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376133},
	doi = {10.1145/3313831.3376133},
	abstract = {People with dementia face major challenges in maintaining active social interaction. Designing digital tools for social sharing within families and care facilities has been well explored by HCI research, but comparatively less work has considered community settings. Situated in a community-based program for storytelling and socializing, our field observations and semi-structured interviews with people living with early-middle stage dementia, family caregivers, and program facilitators illustrate both positive and challenging aspects of social activities. We contribute a nuanced understanding of participants' social lives and identify four factors that aid in achieving positive outcomes: effective agencies for social interaction, normalized and friendly environments, collaboration and teamwork, and mediating social cues and communication. Finally, we examine our findings through the lens of past HCI work and offer insights for designing new social technologies to diversify the range of social spaces in community settings, through expanding peer collaboration, leveraging physical and virtual spaces, creating open-ended experiences, and developing flexible platforms.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dai, Jiamin and Moffatt, Karyn},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {dementia, community, social interaction, social sharing},
	pages = {1--13},
}

@inproceedings{kianzad_phasking_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Phasking on {Paper}: {Accessing} a {Continuum} of {PHysically} {Assisted} {SKetchING}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376134},
	doi = {10.1145/3313831.3376134},
	abstract = {When sketching, we must choose between paper (expressive ease, ruler and eraser) and computational assistance (parametric support, a digital record). PHysically Assisted SKetching provides both, with a pen that displays force constraints with which the sketcher interacts as they draw on paper. Phasking provides passive, "bound" constraints (like a ruler); or actively "brings" the sketcher along a commanded path (e.g., a curve), which they can violate for creative variation. The sketcher modulates constraint strength (control sharing) by bearing down on the pen-tip. Phasking requires untethered, graded force-feedback, achieved by modifying a ballpoint drive that generates force through rolling surface contact. To understand phasking's viability, we implemented its interaction concepts, related them to sketching tasks and measured device performance. We assessed the experience of 10 sketchers, who could understand, use and delight in phasking, and who valued its control-sharing and digital twinning for productivity, creative control and learning to draw.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kianzad, Soheil and Huang, Yuxiang and Xiao, Robert and MacLean, Karon E.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {sketching, haptics, computer aided drawing, force-feedback, shared control drawing, stylus interaction},
	pages = {1--12},
}

@inproceedings{wilkins_peer--peer_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Peer-to-{Peer} {Energy} {Markets}: {Understanding} the {Values} of {Collective} and {Community} {Trading}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376135},
	doi = {10.1145/3313831.3376135},
	abstract = {Peer-to-peer energy-trading platforms (P2P) have the potential to transform the current energy system. However, research is presently scarce on how people would like to participate in, and what would they expect to gain from, such platforms. We address this gap by exploring these questions in the context of the UK energy market. Using a qualitative interview study, we examine how 45 people with an interest in renewable energy understand P2P. We find that the prospective users value the collective benefits of P2P, and understand participation as a mechanism to support social, ecological and economic benefits for communities and larger groups. Drawing on the findings from the interview analysis, we explore broad design characteristics that a prospective P2P energy trading platform should provide to meet the expectations and concerns voiced by our study participants.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wilkins, Denise J. and Chitchyan, Ruzanna and Levine, Mark},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {peer to peer energy trading platforms, semi-structured interview, sustainability, thematic analysis},
	pages = {1--14},
}

@inproceedings{tejada_airtouch_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{AirTouch}: {3D}-{Printed} {Touch}-{Sensitive} {Objects} {Using} {Pneumatic} {Sensing}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376136},
	doi = {10.1145/3313831.3376136},
	abstract = {3D printing technology can be used to rapidly prototype the look and feel of 3D objects. However, the objects produced are passive. There has been increasing interest in making these objects interactive, yet they often require assembling components or complex calibration. In this paper, we contribute AirTouch, a technique that enables designers to fabricate touch-sensitive objects with minimal assembly and calibration using pneumatic sensing. AirTouch-enabled objects are 3D printed as a single structure using a consumer-level 3D printer. AirTouch uses pre-trained machine learning models to identify interactions with fabricated objects, meaning that there is no calibration required once the object has completed printing. We evaluate our technique using fabricated objects with various geometries and touch sensitive locations, obtaining accuracies of at least 90\% with 12 interactive locations.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tejada, Carlos E. and Ramakers, Raf and Boring, Sebastian and Ashbrook, Daniel},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {3d printing, pneumatic sensing, touch interactio},
	pages = {1--10},
}

@inproceedings{jensen_digital_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Digital {Liminalities}: {Understanding} {Isolated} {Communities} on the {Edge}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376137},
	doi = {10.1145/3313831.3376137},
	abstract = {This paper brings together three distinct case studies to explore how social isolation and notions of liminality shape ontological security within communities on "the edge" of society. Each case study exemplifies the differing nature of liminality in everyday contexts and the extent to which increased digitalisation perturbs it in multiple ways. Taking an ethnographic approach, the research engaged with seafarers onboard container ships in European waters, communities in Greenland and welfare claimants in the North East of England. It posits that technological innovation must attend to the routinisation of everyday life through which people establish ontological security if such innovation is to be supportive. The paper thus moves beyond existing HCI scholarship by foregrounding the contextual and relational aspects of social isolation rather than the technological. It does so by advocating a ground-up design process that considers ontological security in relation to notions of liminality among communities on the edge.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jensen, Rikke Bjerg and Coles-Kemp, Lizzie and Wendt, Nicola and Lewis, Makayla},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ethnography, communities, design principles, isolation, liminality: ontological security},
	pages = {1--14},
}

@inproceedings{han_mouille_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Mouillé: {Exploring} {Wetness} {Illusion} on {Fingertips} to {Enhance} {Immersive} {Experience} in {VR}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376138},
	doi = {10.1145/3313831.3376138},
	abstract = {Providing users with rich sensations is beneficial to enhance their immersion in Virtual Reality (VR) environments. Wetness is one such imperative sensation that affects users' sense of comfort and helps users adjust grip force when interacting with objects. Researchers have recently begun to explore ways to create wetness illusions, primarily on a user's face or body skin. In this work, we extended this line of research by creating wetness illusion on users' fingertips. We first conducted a user study to understand the effect of thermal and tactile feedback on users' perceived wetness sensation. Informed by the findings, we designed and evaluated a prototype—Mouillé—that provides various levels of wetness illusions on fingertips for both hard and soft items when users squeeze, lift, or scratch it. Study results indicated that users were able to feel wetness with different levels of temperature changes and they were able to distinguish three levels of wetness for simulated VR objects. We further presented applications that simulated an ice cube, an iced cola bottle, and a wet sponge, etc, to demonstrate its use in VR.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Han, Teng and Wang, Sirui and Wang, Sijia and Fan, Xiangmin and Liu, Jie and Tian, Feng and Fan, Mingming},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, user study, prototype, wetness illusion},
	pages = {1--10},
}

@inproceedings{gupta_replicate_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Replicate and {Reuse}: {Tangible} {Interaction} {Design} for {Digitally}-{Augmented} {Physical} {Media} {Objects}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376139},
	doi = {10.1145/3313831.3376139},
	abstract = {Technology has transformed our physical interactions into infinitely more scalable and flexible digital ones. We can peruse an infinite number of photos, news articles, and books. However, these digital experiences lack the physical experience of paging through an album, reading a newspaper, or meandering through a bookshelf. Overlaying physical objects with digital content using augmented reality is a promising avenue towards bridging this gap. In this paper, we investigate the interaction design for such digital-overlaid physical objects and their varying levels of tangibility. We first conduct a user evaluation of a physical photo album that uses tangible interactions to support physical and digital operations. We further prototype multiple objects including bookshelves and newspapers and probe users on their usage, capabilities, and interactions. We then conduct a qualitative investigation of three interaction designs with varying tangibility that use three different input modalities. Finally, we discuss the insights from our investigations and recommend design guidelines.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gupta, Aakar and Lin, Bo Rui and Ji, Siyi and Patel, Arjav and Vogel, Daniel},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {design, augmented reality, tangible interaction, physical objects},
	pages = {1--12},
}

@inproceedings{sun_fdhelper_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{FDHelper}: {Assist} {Unsupervised} {Fraud} {Detection} {Experts} with {Interactive} {Feature} {Selection} and {Evaluation}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376140},
	doi = {10.1145/3313831.3376140},
	abstract = {Online fraud is the well-known dark side of the modern Internet. Unsupervised fraud detection algorithms are widely used to address this problem. However, selecting features, adjusting hyperparameters, evaluating the algorithms, and eliminating false positives all require human expert involvement. In this work, we design and implement an end-to-end interactive visualization system, FDHelper, based on the deep understanding of the mechanism of the black market and fraud detection algorithms. We identify a workflow based on experience from both fraud detection algorithm experts and domain experts. Using a multi-granularity three-layer visualization map embedding an entropy-based distance metric ColDis, analysts can interactively select different feature sets, refine fraud detection algorithms, tune parameters and evaluate the detection result in near real-time. We demonstrate the effectiveness and significance of FDHelper through two case studies with state-of-the-art fraud detection algorithms, interviews with domain experts and algorithm experts, and a user study with eight first-time end users.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Jiao and Li, Yin and Chen, Charley and Lee, Jihae and Liu, Xin and Zhang, Zhongping and Huang, Ling and Shi, Lei and Xu, Wei},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {visualization, fraud detection, human computer interaction},
	pages = {1--12},
}

@inproceedings{damen_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding {Walking} {Meetings}: {Drivers} and {Barriers}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376141},
	doi = {10.1145/3313831.3376141},
	abstract = {There is increased interest in reducing sedentary behavior of office workers to combat the negative health effects of prolonged sitting. Walking meetings offer a promising solution to this problem as they facilitate a physically active way of working. To inform future development of technologies supporting these type of meetings, in-depth qualitative insights into people's experiences of walking meetings are needed. We conducted semi-structured walking interviews (N=16) to identify key drivers and barriers for walking meetings in a living lab setting by using the 'WorkWalk'. The 'WorkWalk' is a 1.8 km walking route indicated by a dotted blue line with outdoor meeting points, integrated into the room booking system. Our findings provide insights into how walking meetings are experienced and affect the set-up and social dynamics of meetings. We offer design recommendations for the development of future technologies and service design elements to support walking meetings and active ways of working.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Damen, Ida and Lallemand, Carine and Brankaert, Rens and Brombacher, Aarnout and van Wesemael, Pieter and Vos, Steven},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {physical activity, design research, field study, office workers, sedentary behavior, walking meetings},
	pages = {1--14},
}

@inproceedings{gorski_listen_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Listen to {Developers}! {A} {Participatory} {Design} {Study} on {Security} {Warnings} for {Cryptographic} {APIs}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376142},
	doi = {10.1145/3313831.3376142},
	abstract = {The positive effect of security information communicated to developers through API warnings has been established. However, current prototypical designs are based on security warnings for end-users. To improve security feedback for developers, we conducted a participatory design study with 25 professional software developers in focus groups. We identify which security information is considered helpful in avoiding insecure cryptographic API use during development. Concerning console messages, participants suggested five core elements, namely message classification, title message, code location, link to detailed external resources, and color. Design guidelines for end-user warnings are only partially suitable in this context. Participants emphasized the importance of tailoring the detail and content of security information to the context. Console warnings call for concise communication; further information needs to be linked externally. Therefore, security feedback should transcend tools and should be adjustable by software developers across development tools, considering the work context and developer needs.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gorski, Peter Leo and Acar, Yasemin and Lo Iacono, Luigi and Fahl, Sascha},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {participatory design, cryptographic apis, developer console, focus groups, security warning design, software development},
	pages = {1--13},
}

@inproceedings{ahmetovic_recog_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{ReCog}: {Supporting} {Blind} {People} in {Recognizing} {Personal} {Objects}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376143},
	doi = {10.1145/3313831.3376143},
	abstract = {We present ReCog, a mobile app that enables blind users to recognize objects by training a deep network with their own photos of such objects. This functionality is useful to differentiate personal objects, which cannot be recognized with pre-trained recognizers and may lack distinguishing tactile features. To ensure that the objects are well-framed in the captured photos, ReCog integrates a camera-aiming guidance that tracks target objects and instructs the user through verbal and sonification feedback to appropriately frame them.We report a two-session study with 10 blind participants using ReCog for object training and recognition, with and without guidance. We show that ReCog enables blind users to train and recognize their personal objects, and that camera-aiming guidance helps novice users to increase their confidence, achieve better accuracy, and learn strategies to capture better photos.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ahmetovic, Dragan and Sato, Daisuke and Oh, Uran and Ishihara, Tatsuya and Kitani, Kris and Asakawa, Chieko},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {visual impairment, object recognition, photography guidance},
	pages = {1--12},
}

@inproceedings{putze_breaking_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Breaking {The} {Experience}: {Effects} of {Questionnaires} in {VR} {User} {Studies}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376144},
	doi = {10.1145/3313831.3376144},
	abstract = {Questionnaires are among the most common research tools in virtual reality (VR) evaluations and user studies. However, transitioning from virtual worlds to the physical world to respond to VR experience questionnaires can potentially lead to systematic biases. Administering questionnaires in VR (inVRQs) is becoming more common in contemporary research. This is based on the intuitive notion that inVRQs may ease participation, reduce the Break in Presence (BIP) and avoid biases. In this paper, we perform a systematic investigation into the effects of interrupting the VR experience through questionnaires using physiological data as a continuous and objective measure of presence. In a user study (n=50), we evaluated question-asking procedures using a VR shooter with two different levels of immersion. The users rated their player experience with a questionnaire either inside or outside of VR. Our results indicate a reduced BIP for the employed inVRQ without affecting the self-reported player experience.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Putze, Susanne and Alexandrovsky, Dmitry and Putze, Felix and Höffner, Sebastian and Smeddinck, Jan David and Malaka, Rainer},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, user studies, research methods, vr, biosignals, break in presence, in-vr questionnaires, invrqs, surveys},
	pages = {1--15},
}

@inproceedings{reinders_hey_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{Hey} {Model}!" – {Natural} {User} {Interactions} and {Agency} in {Accessible} {Interactive} {3D} {Models}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376145},
	doi = {10.1145/3313831.3376145},
	abstract = {While developments in 3D printing have opened up opportunities for improved access to graphical information for people who are blind or have low vision (BLV), they can provide only limited detailed and contextual information. Interactive 3D printed models (I3Ms) that provide audio labels and/or a conversational agent interface potentially overcome this limitation. We conducted a Wizard-of-Oz exploratory study to uncover the multi-modal interaction techniques that BLV people would like to use when exploring I3Ms, and investigated their attitudes towards different levels of model agency. These findings informed the creation of an I3M prototype of the solar system. A second user study with this model revealed a hierarchy of interaction, with BLV users preferring tactile exploration, followed by touch gestures to trigger audio labels, and then natural language to fill in knowledge gaps and confirm understanding.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Reinders, Samuel and Butler, Matthew and Marriott, Kim},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, input techniques, assistive technologies, individuals with disabilities \&amp, touch/haptic/pointing/gesture},
	pages = {1--13},
}

@inproceedings{villanueva_meta-ar-app_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Meta-{AR}-{App}: {An} {Authoring} {Platform} for {Collaborative} {Augmented} {Reality} in {STEM} {Classrooms}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376146},
	doi = {10.1145/3313831.3376146},
	abstract = {Augmented Reality (AR) has become a valuable tool for education and training processes. Meanwhile, cloud-based technologies can foster collaboration and other interaction modalities to enhance learning. We combine the cloud capabilities with AR technologies to present Meta-AR-App, an authoring platform for collaborative AR, which enables authoring between instructors and students. Additionally, we introduce a new application of an established collaboration process, the pull-based development model, to enable sharing and retrieving of AR learning content. We customize this model and create two modalities of interaction for the classroom: local (student to student) and global (instructor to class) pull. Based on observations from our user studies, we organize a four-category classroom model which implements our system: Work, Design, Collaboration, and Technology. Further, our system enables an iterative improvement workflow of the class content and enables synergistic collaboration that empowers students to be active agents in the learning process.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Villanueva, Ana and Zhu, Zhengzhe and Liu, Ziyi and Peppler, Kylie and Redick, Thomas and Ramani, Karthik},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {augmented reality, collaboration, authoring, classroom, electrical circuitry, git, pull-based model, stem, version control},
	pages = {1--14},
}

@inproceedings{matulic_pensight_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{PenSight}: {Enhanced} {Interaction} with a {Pen}-{Top} {Camera}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376147},
	doi = {10.1145/3313831.3376147},
	abstract = {We propose mounting a downward-facing camera above the top end of a digital tablet pen. This creates a unique and practical viewing angle for capturing the pen-holding hand and the immediate surroundings which can include the other hand. The fabrication of a prototype device is described and the enabled interaction design space is explored, including dominant and non-dominant hand pose recognition, tablet grip detection, hand gestures, capturing physical content in the environment, and detecting users and pens. A deep learning computer vision pipeline is developed for classification, regression, and keypoint detection to enable these interactions. Example applications demonstrate usage scenarios and a qualitative user evaluation confirms the potential of the approach.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Matulic, Fabrice and Arakawa, Riku and Vogel, Brian and Vogel, Daniel},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {pen input, hand pose estimation, tablet input},
	pages = {1--14},
}

@inproceedings{martinez-maldonado_data_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {From {Data} to {Insights}: {A} {Layered} {Storytelling} {Approach} for {Multimodal} {Learning} {Analytics}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376148},
	doi = {10.1145/3313831.3376148},
	abstract = {Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is naïve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Martinez-Maldonado, Roberto and Echeverria, Vanessa and Fernandez Nieto, Gloria and Buckingham Shum, Simon},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {visualization, CSCW, data storytelling, teamwork},
	pages = {1--15},
}

@inproceedings{oleson_computing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Computing {Students}' {Learning} {Difficulties} in {HCI} {Education}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376149},
	doi = {10.1145/3313831.3376149},
	abstract = {Software developers often make interface design decisions and work with designers. Therefore, computing students who seek to become developers need some education about interface design. While prior work has studied difficulties that educators face when teaching design to computing students, there is comparatively little work on the difficulties computing students face when learning HCI design skills. To uncover these difficulties, we conducted two qualitative studies consisting of surveys and interviews with (1) computing students and (2) educators who teach interface design to computing students. Qualitative analysis of their responses revealed 18 types of learning difficulties students might experience in HCI design education, including difficulties around the mechanics of design work, project management skills, the wicked nature of design problems, and distorted perspectives on design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Oleson, Alannah and Solomon, Meron and Ko, Amy J.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {hci education, interface design education, learning difficulties, pedagogical content knowledge},
	pages = {1--14},
}

@inproceedings{warner_evaluating_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Evaluating '{Prefer} {Not} to {Say}' {Around} {Sensitive} {Disclosures}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376150},
	doi = {10.1145/3313831.3376150},
	abstract = {As people's offline and online lives become increasingly entwined, the sensitivity of personal information disclosed online is increasing. Disclosures often occur through structured disclosure fields (e.g., drop-down lists). Prior research suggests these fields may limit privacy, with non-disclosing users being presumed to be hiding undesirable information. We investigated this around HIV status disclosure in online dating apps used by men who have sex with men. Our online study asked participants (N=183) to rate profiles where HIV status was either disclosed or undisclosed. We tested three designs for displaying undisclosed fields. Visibility of undisclosed fields had a significant effect on the way profiles were rated, and other profile information (e.g., ethnicity) could affect inferences that develop around undisclosed information. Our research highlights complexities around designing for non-disclosure and questions the voluntary nature of these fields. Further work is outlined to ensure disclosure control is appropriately implemented around online sensitive information disclosures.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Warner, Mark and Kitkowska, Agnieszka and Gibbs, Jo and Maestre, Juan F. and Blandford, Ann},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, disclosure, non-disclosure, online dating, online privacy, prefer not to say, privacy unraveling, structured disclosure fields},
	pages = {1--13},
}

@inproceedings{seering_proximate_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Proximate {Social} {Factors} in {First}-{Time} {Contribution} to {Online} {Communities}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376151},
	doi = {10.1145/3313831.3376151},
	abstract = {In the course of every member's integration into an online community, a decision must be made to participate for the first time. The challenges of effective recruitment, management, and retention of new users have been extensively explored in social computing research. However, little work has looked at in-the-moment factors that lead users to decide to participate instead of "lurk", conditions which can be shaped to draw new users in at crucial moments. In this work we analyze 183 million messages scraped from chatrooms on the livestreaming platform Twitch in order to understand differences between first-time participants' and regulars' behaviors and to identify conditions that encourage first-time participation. We find that presence of diverse types of users increases likelihood of new participation, with effects depending on the size of the community. We also find that information-seeking behaviors in first-time participation are negatively associated with retention in the short and medium term.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Seering, Joseph and Hammer, Jessica and Kaufman, Geoff and Yang, Diyi},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {twitch, participation, newcomers, online communities, retention, social roles},
	pages = {1--14},
}

@inproceedings{liu_data-driven_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Data-{Driven} {Multi}-{Level} {Segmentation} of {Image} {Editing} {Logs}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376152},
	doi = {10.1145/3313831.3376152},
	abstract = {Automatic segmentation of logs for creativity tools such as image editing systems could improve their usability and learnability by supporting such interaction use cases as smart history navigation or recommending alternative design choices. We propose a multi-level segmentation model that works for many image editing tasks including poster creation, portrait retouching, and special effect creation. The lowest-level chunks of logged events are computed using a support vector machine model and higher-level chunks are built on top of these, at a level of granularity that can be customized for specific use cases. Our model takes into account features derived from four event attributes collected in realistically complex Photoshop sessions with expert users: command, timestamp, image content, and artwork layer. We present a detailed analysis of the relevance of each feature and evaluate the model using both quantitative performance metrics and qualitative analysis of sample sessions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liu, Zipeng and Liu, Zhicheng and Munzner, Tamara},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {image editing logs, interaction history, log segmentation, multi-level hierarchy},
	pages = {1--12},
}

@inproceedings{clegg_data_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Data {Everyday}: {Data} {Literacy} {Practices} in a {Division} {I} {College} {Sports} {Context}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376153},
	doi = {10.1145/3313831.3376153},
	abstract = {Data analysis is central to sports training. Today, cutting-edge digital technologies are deployed to measure and improve athletes' performance. But too often researchers focus on the technology collecting performance data at the expense of understanding athletes' experiences with data. This is particularly the case in the understudied context of collegiate athletics, where competition is fierce, tools for data analysis abound, and the institution actively manages athletes' lives. By investigating how student-athletes analyze their performance data and are analyzed in turn, we can better understand the individual and institutional factors that make data literacy practices in athletics meaningful and productive-or not. Our pilot interview study of student-athletes at one Division I university reveals a set of opportunities for student-athletes to engage with and learn from data analytics practices. These opportunities come with a set of contextual tensions that should inform the design of new technologies for collegiate sports settings.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Clegg, Tamara and Greene, Daniel M. and Beard, Nate and Brunson, Jasmine},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {data literacy, hci and sports, personal informatics},
	pages = {1--13},
}

@inproceedings{shin_talkingboogie_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{TalkingBoogie}: {Collaborative} {Mobile} {AAC} {System} for {Non}-{Verbal} {Children} with {Developmental} {Disabilities} and {Their} {Caregivers}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376154},
	doi = {10.1145/3313831.3376154},
	abstract = {Augmentative and alternative communication (AAC) technologies are widely used to help non-verbal children enable communication. For AAC-aided communication to be successful, caregivers should support children with consistent intervention strategies in various settings. As such, caregivers need to continuously observe and discuss children's AAC usage to create a shared understanding of these strategies. However, caregivers often find it challenging to effectively collaborate with one another due to a lack of family involvement and the unstructured process of collaboration. To address these issues, we present TalkingBoogie, which consists of two mobile apps: TalkingBoogie-AAC for caregiver-child communication, and TalkingBoogie-coach supporting caregiver collaboration. Working together, these applications provide contextualized layouts for symbol arrangement, scaffold the process of sharing and discussing observations, and induce caregivers' balanced participation. A two-week deployment study with four groups (N=11) found that TalkingBoogie helped increase mutual understanding of strategies and encourage balanced participation between caregivers with reduced cognitive loads.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Shin, Donghoon and Song, Jaeyoon and Song, Seokwoo and Park, Jisoo and Lee, Joonhwan and Jun, Soojin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, assistive technology, aac, caregiver collaboration, developmental disability},
	pages = {1--13},
}

@inproceedings{subramonyam_texsketch_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{TexSketch}: {Active} {Diagramming} through {Pen}-and-{Ink} {Annotations}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376155},
	doi = {10.1145/3313831.3376155},
	abstract = {Learning from text is a constructive activity in which sentence-level information is combined by the reader to build coherent mental models. With increasingly complex texts, forming a mental model becomes challenging due to a lack of background knowledge, and limits in working memory and attention. To address this, we are taught knowledge externalization strategies such as active reading and diagramming. Unfortunately, paper-and-pencil approaches may not always be appropriate, and software solutions create friction through difficult input modalities, limited workflow support, and barriers between reading and diagramming. For all but the simplest text, building coherent diagrams can be tedious and difficult. We propose Active Diagramming, an approach extending familiar active reading strategies to the task of diagram construction. Our prototype, texSketch, combines pen-and-ink interactions with natural language processing to reduce the cost of producing diagrams while maintaining the cognitive effort necessary for comprehension. Our user study finds that readers can effectively create diagrams without disrupting reading.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Subramonyam, Hariharan and Seifert, Colleen and Shah, Priti and Adar, Eytan},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {active reading, diagramming, pen-and-ink gestures},
	pages = {1--13},
}

@inproceedings{petro_out_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{Out} of {Luck}": {Socio}-{Economic} {Differences} in {Student} {Coping} {Responses} to {Technology} {Problems}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376156},
	doi = {10.1145/3313831.3376156},
	abstract = {Despite high levels of digital technology access among college students, technology disruption remains an issue. This study was conducted to understand how technology disruption might contribute to socio-economic disparities in academic performance. Data were analyzed from a non-representative sample of 748 undergraduate students. We examined socio-economic differences in types of technology problems students experience; the consequences of those problems; and beliefs about how to handle future problems. Socio-economic status was not associated with types of technology problems, but it was associated with greater negative consequences and less-efficacious beliefs about handling future situations. These findings are consistent with sociological work on socio-economic differences in student help-seeking. They also elaborate mechanistic understanding of the technology maintenance construct. Finally, for those interested in designing to reduce socio-economic inequalities, they suggest the need for interfaces that go beyond information accessibility to facilitate student empowerment and student-teacher communication.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Petro, Gwen and Gonzales, Amy and Calarco, Jessica},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, empirical study that tells us about people, education/learning, schools/educational setting},
	pages = {1--10},
}

@inproceedings{komatsu_exploring_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Exploring {Auditory} {Information} to {Change} {Users}' {Perception} of {Time} {Passing} as {Shorter}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376157},
	doi = {10.1145/3313831.3376157},
	abstract = {Although the processing speed of computers has been drastically increasing year by year, users still have to wait for computers to complete tasks or to respond. To cope with this, several studies have proposed presenting certain visual information to users to change their perception of time passing as shorter, e.g., progress bars with animated ribbing or faster/slower virtual clocks. As speech interfaces such as smart speakers are becoming popular, a novel method is required to make users perceive the passing of time as shorter by presenting auditory stimuli. We thus prepared 20 pieces of auditory information as experimental stimuli; that is, 11 auditory stimuli that have the same 10.1-second duration but different numbers of 0.1-second sine-wave sounds and 9 other auditory stimuli that have the same 10.1-second duration and numbers of sounds but different interval patterns between the sounds. We conducted three experiments to figure out which kinds of auditory stimuli can change users' perception of time passing as shorter. We found that a 10.1-second auditory stimulus that has 0.1-second sine-wave sounds appearing 11 times with intervals between the sounds that narrow rapidly in a linear fashion was perceived as shortest at about 9.3 seconds, which was 7.6\% shorter than the actual duration of the stimulus. We also found that different interval patterns of sounds in auditory information significantly affected users' perception of time passing as shorter, while different numbers of sounds did not.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Komatsu, Takanori and Yamada, Seiji},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {auditory information, eyes-free interaction, filled-duration illusion, users' perception of time passing, waiting time},
	pages = {1--12},
}

@inproceedings{manuel_place-based_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Place-{Based} {Policymaking} and {HCI}: {Opportunities} and {Challenges} for {Technology} {Design}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376158},
	doi = {10.1145/3313831.3376158},
	abstract = {There has been a growing interest in HCI in designing and developing technology to support democratic participation, particularly in the domain of urban planning or place-based research. In addition, the HCI field has increasingly considered the intersection of HCI and policymaking to understand how our research can have a broader impact. In this paper, we report on a series of workshops with citizens and city planners to explore place-based policymaking through the case study of neighbourhood planning in the UK. Our analysis highlights the tensions, opportunities and challenges faced by citizens in creating policy. Drawing from our findings, we stress the need for HCI to be actively involved in supporting, innovating and (re)designing civic policymaking processes while emphasising design considerations for the development of technological tools.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Manuel, Jennifer and Crivellaro, Clara},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {digital civics, citizen participation, policymaking},
	pages = {1--16},
}

@inproceedings{gibson_designing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Designing {Clinical} {AAC} {Tablet} {Applications} with {Adults} {Who} {Have} {Mild} {Intellectual} {Disabilities}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376159},
	doi = {10.1145/3313831.3376159},
	abstract = {Patients with mild intellectual disabilities (ID) face significant communication barriers within primary care services. This has a detrimental effect on the quality of treatment being provided, meaning the consultation process could benefit from augmentative and alternative communication (AAC) technologies. However, little research has been conducted in this area beyond that of paper-based aids. We address this by extracting design requirements for a clinical AAC tablet application from n=10 adults with mild ID. Our results show that such technologies can promote communication between general practitioners (GPs) and patients with mild ID by extracting symptoms in advance of the consultation via an accessible questionnaire. These symptoms act as a referent and assist in raising the awareness of conditions commonly overlooked by GPs. Furthermore, the application can support people with ID in identifying and accessing healthcare services. Finally, the participants identified 6 key factors that affect the clarity of medical images.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gibson, Ryan Colin and Dunlop, Mark D. and Bouamrane, Matt-Mouley and Nayar, Revathy},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, augmentative and alternative communication, intellectual disabilities, mobile applications, primary health care},
	pages = {1--13},
}

@inproceedings{leiva_pronto_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Pronto: {Rapid} {Augmented} {Reality} {Video} {Prototyping} {Using} {Sketches} and {Enaction}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376160},
	doi = {10.1145/3313831.3376160},
	abstract = {Designers have limited tools to prototype AR experiences rapidly. Can lightweight, immediate tools let designers prototype dynamic AR interactions while capturing the nuances of a 3D experience? We interviewed three AR experts and identified several recurring issues in AR design: creating and positioning 3D assets, handling the changing user position, and orchestrating multiple animations. We introduce PROJECT PRONTO, a tablet-based video prototyping system that combines 2D video with 3D manipulation. PRONTO supports four intertwined activities: capturing 3D spatial information alongside a video scenario, positioning and sketching 2D drawings in a 3D world, and enacting animations with physical interactions. An observational study with professional designers shows that participants can use PRONTO to prototype diverse AR experiences. All participants performed two tasks: replicating a sample non-trivial AR experience and prototyping their open-ended designs. All participants completed the replication task and found PRONTO easy to use. Most participants found that PRONTO encourages more exploration of designs than their current practices.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Leiva, Germán and Nguyen, Cuong and Kazi, Rubaiat Habib and Asente, Paul},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {sketching, ar, design by enaction, video prototyping},
	pages = {1--13},
}

@inproceedings{foley_student_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Student {Engagement} in {Sensitive} {Design} {Contexts}: {A} {Case} {Study} in {Dementia} {Care}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376161},
	doi = {10.1145/3313831.3376161},
	abstract = {There is a growing body of HCI work that seeks to understand and enhance the lived experience of people with dementia. The majority of this work involves researchers working alongside people with dementia and their carers, focused on the design project outcomes. In order to enrich the social context of this work, we explore broadening participation to include student volunteers. To encourage mutually engaging experiences in this design context, careful consideration of how to support both students and people with dementia is needed. In this paper, we present two case- studies of co-design projects between students and people with dementia. Our findings detail the use of design methods to reconfigure the role of the residents in care contexts and the students learning process. We discuss the project learning outcomes as well as practical and ethical considerations to support the use of design methods to support mutual engagement in sensitive contexts.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Foley, Sarah and Pantidi, Nadia and McCarthy, John},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {dementia, co-design, experience-centered design, inter-generational engagement},
	pages = {1--13},
}

@inproceedings{koelle_social_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Social {Acceptability} in {HCI}: {A} {Survey} of {Methods}, {Measures}, and {Design} {Strategies}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376162},
	doi = {10.1145/3313831.3376162},
	abstract = {With the increasing ubiquity of personal devices, social acceptability of human-machine interactions has gained relevance and growing interest from the HCI community. Yet, there are no best practices or established methods for evaluating social acceptability. Design strategies for increasing social acceptability have been described and employed, but so far not been holistically appraised and evaluated. We offer a systematic literature analysis (N=69) of social acceptability in HCI and contribute a better understanding of current research practices, namely, methods employed, measures and design strategies. Our review identified an unbalanced distribution of study approaches, shortcomings in employed measures, and a lack of interweaving between empirical and artifact-creating approaches. The latter causes a discrepancy between design recommendations based on user research, and design strategies employed in artifact creation. Our survey lays the groundwork for a more nuanced evaluation of social acceptability, the development of best practices, and a future research agenda.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Koelle, Marion and Ananthanarayan, Swamy and Boll, Susanne},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {research methods, literature analysis, social acceptability},
	pages = {1--19},
}

@inproceedings{sarsenbayeva_does_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Does {Smartphone} {Use} {Drive} {Our} {Emotions} or {Vice} {Versa}? {A} {Causal} {Analysis}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376163},
	doi = {10.1145/3313831.3376163},
	abstract = {In this paper, we demonstrate the existence of a bidirectional causal relationship between smartphone application use and user emotions. In a two-week long in-the-wild study with 30 participants we captured 502,851 instances of smartphone application use in tandem with corresponding emotional data from facial expressions. Our analysis shows that while in most cases application use drives user emotions, multiple application categories exist for which the causal effect is in the opposite direction. Our findings shed light on the relationship between smartphone use and emotional states. We furthermore discuss the opportunities for research and practice that arise from our findings and their potential to support emotional well-being.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sarsenbayeva, Zhanna and Marini, Gabriele and van Berkel, Niels and Luo, Chu and Jiang, Weiwei and Yang, Kangning and Wadley, Greg and Dingler, Tilman and Kostakos, Vassilis and Goncalves, Jorge},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {emotion detection, emotional well-being, emotions, mobile application use, mobile interaction, smartphones},
	pages = {1--15},
}

@inproceedings{arshad_east_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{EAST}: {Early} {Autism} {Screening} {Tool} for {Preschoolers}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376164},
	doi = {10.1145/3313831.3376164},
	abstract = {We describe the iterative co-design process and evaluation of an early autism screening tool (EAST). EAST is an intermediary interactive tablet based app that assists in the early-detection of Autism Spectrum Disorder (ASD) by screening preschoolers in Pakistan through play-based activities in a home, school or clinical setting. Medical professionals, parents of autistic children and teachers were surveyed through focus groups to understand the reasons that contribute to the increasing number of missed early detections, and late- or misdiagnoses. We also evaluate the acceptability, usability and validity of our tool. We tested EAST with both typically developed and autistic children on how they relate to people, imitation, motor skills, visual and intellectual response. They were scored via time taken, the number of wrong attempts, or incorrect answers and audiovisual feedback. This paper contributes towards a digital autism screening tool that delivers insights into the child's behaviour and enables collaboration among parents, teachers and medical professionals.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Arshad, Muhammad Bilal and Sarwar, Muhammad Farhan and Zaidi, Meher Fatima and Shahid, Suleman},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {autism screening, digital tool, preschool children},
	pages = {1--14},
}

@inproceedings{dev_why_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Why {Johnny} {Can}'t {Unsubscribe}: {Barriers} to {Stopping} {Unwanted} {Email}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376165},
	doi = {10.1145/3313831.3376165},
	abstract = {A large proportion of email messages in an average Internet user's inbox are unwanted commercial messages from mailing lists, bots, and so on. Although such messages often include instructions to unsubscribe, people still struggle with stopping unwanted email. We investigated the user experience of unsubscribing from unwanted email messages by recruiting 18 individuals for via a lab study followed by semi-structured interviews. Based on unsubscribing practices of the study participants, we synthesized eight common unsubscription mechanisms and identified the corresponding user experience challenges. We further uncovered alternative practices aimed at circumventing the need to unsubscribe. Our findings reveal frustration with the prevailing options for limiting access to the self by managing email boundaries. We apply our insight to offer design suggestions that could help commercial providers improve the user experience of unsubscribing and provide users more control over the email they receive.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dev, Jayati and Rader, Emilee and Patil, Sameer},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, boundary management, mailing lists, marketing email, newsletters, opt-out, unsubscribing, unwanted email},
	pages = {1--12},
}

@inproceedings{karusala_making_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Making {Chat} at {Home} in the {Hospital}: {Exploring} {Chat} {Use} by {Nurses}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376166},
	doi = {10.1145/3313831.3376166},
	abstract = {In this paper, we examine WhatsApp use by nurses in India. Globally, personal chat apps have taken the workplace by storm, and healthcare is no exception. In the hospital setting, this raises questions around how chat apps are integrated into hospital work and the consequences of using such personal tools for work. To address these questions, we conducted an ethnographic study of chat use in nurses' work in a large multi-specialty hospital. By examining how chat is embedded in the hospital, rather than focusing on individual use of personal tools, we throw new light on the adoption of personal tools at work — specifically what happens when such tools are adopted and used as though they were organisational tools. In doing so, we explicate their impact on invisible work [77] and the creep of work into personal time, as well as how hierarchy and power play out in technology use. Thus, we point to the importance of looking beyond individual adoption by knowledge workers when studying the impact of personal tools at work.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Karusala, Naveena and Wang, Ding and O'Neill, Jacki},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ethnography, work-life balance, chat apps, hospital communication, nursing, whatsapp, workplace studies},
	pages = {1--15},
}

@inproceedings{mcdonald_politics_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {Politics} of {Privacy} {Theories}: {Moving} from {Norms} to {Vulnerabilities}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376167},
	doi = {10.1145/3313831.3376167},
	abstract = {Privacy and surveillance are central features of public discourse around use of computing systems. As the systems we design and study are increasingly used and regulated as potential instruments of surveillance, HCI researchers-even those whose focus is not privacy-find themselves needing to understand privacy in their work. Concepts like contextual integrity and boundary regulation have become touchstones for thinking about privacy in HCI. In this paper, we draw on HCI and privacy literature to understand the limitations of commonly used theories and examine their assumptions, politics, strengths, and weaknesses. We use a case study from the HCI literature to illustrate conceptual gaps in existing frameworks where privacy requirements can fall through. Finally, we advocate vulnerability as a core concept for privacy theorizing and examine how feminist, queer-Marxist, and intersectional thinking may augment our existing repertoire of privacy theories to create a more inclusive scholarship and design practice.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {McDonald, Nora and Forte, Andrea},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {feminist intersectional theory, privacy theory, queer theory},
	pages = {1--14},
}

@inproceedings{albakry_what_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {What is {This} {URL}'s {Destination}? {Empirical} {Evaluation} of {Users}' {URL} {Reading}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376168},
	doi = {10.1145/3313831.3376168},
	abstract = {Common anti-phishing advice tells users to mouse over links, look at the URL, and compare to the expected destination, implicitly assuming that they are able to read the URL. To test this assumption, we conducted a survey with 1929 participants recruited from the Amazon Mechanical Turk and Prolific Academic platforms. Participants were shown 23 URLs with various URL structures. For each URL, participants were asked via a multiple choice question where the URL would lead and how safe they feel clicking on it would be. Using latent class analysis, participants were stratified by self-reported technology use. Participants were strongly biased towards answering that the URL would lead to the website of the organization whose name appeared in the URL, regardless of its position in the URL structure. The group with the highest technology use was only minorly better at URL reading.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Albakry, Sara and Vaniea, Kami and Wolters, Maria K.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {link destination, online security, phishing, technology usage, uniform resource locators, url readability, web literacy},
	pages = {1--12},
}

@inproceedings{iivari_arseing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{Arseing} around {Was} {Fun}!" – {Humor} as a {Resource} in {Design} and {Making}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376169},
	doi = {10.1145/3313831.3376169},
	abstract = {Humor is an inevitable part of human life. Most of us are capable of experiencing and appreciating humor. From this perspective, surprisingly little HCI research can be found scrutinizing the existence, role, and potential of humor in our design practice. The gap remains also related to children and teenagers; there is a lack of studies appreciating the emergence and existence of humor in the design process without intentionally evoking it. Thus, this study examines humor as a naturally occurring phenomenon in the design process. The study was conducted in collaboration with a class of teenagers and their teachers. The study identifies various forms and functions of humor in the design process and reveals its situated, emergent nature as a resource in interaction within design. The study proposes a practical tool for designers for anticipating and potentially facilitating the emergence, forms and usages of humor as an interactional resource in design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Iivari, Netta and Kinnula, Marianne and Kuure, Leena and Keisanen, Tiina},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {children, design, interaction, discourse, humor, making in education, nexus analysis, teenager},
	pages = {1--13},
}

@inproceedings{evans_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding the {Care} {Ecologies} of {Veterans} with {PTSD}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376170},
	doi = {10.1145/3313831.3376170},
	abstract = {Post-traumatic stress disorder (PTSD) disproportionately affects United States veterans, yet they may be reluctant to seek or engage in care. We interview 21 participants, including veterans with PTSD, clinicians who treat veterans and friends and family that support veterans through mental health ordeals. We investigate the military identity these veterans share. We explore how this may add to their reluctance in care-seeking behaviors. We also explore the roles of human and non-human intermediaries in ecologies of care and the potential for enhancing patient empowerment in current clinical treatment contexts. We discuss how military culture can be utilized in clinical care, how multiple perspectives can be leveraged to create a more holistic view of the patient, and finally, how veterans can be empowered during treatment. We conclude with recommendations for the design of sociotechnical systems that prioritize the above in support of the mental well-being of veterans with PTSD.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Evans, Hayley and Lakshmi, Udaya and Watson, Hue and Ismail, Azra and Sherrill, Andrew M. and Kumar, Neha and Arriaga, Rosa I.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {mental health, therapy, care ecologies, ptsd, treatment, veteran care},
	pages = {1--15},
}

@inproceedings{wilson_self-expression_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Self-{Expression} by {Design}: {Co}-{Designing} the {ExpressiBall} with {Minimally}-{Verbal} {Children} on the {Autism} {Spectrum}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376171},
	doi = {10.1145/3313831.3376171},
	abstract = {Expressing one's thoughts and feelings is a fundamental human need - the basis for communication and social interaction. We ask, how do minimally-verbal children on the autism spectrum express themselves? How can we better recognise instances of self-expression? And how might technologies support and encourage self-expression? To address these questions, we undertook co-design research at an autism-specific primary school with 20 children over one school year. This paper contributes six Modalities of Self-Expression, through which children self-express and convey their design insights. Each modality of self-expression can occur across two different dimensions (socio-expressive and auto-expressive) and can be of a fundamental or an integrative nature. Further, we contribute the design trajectory of a tangible ball prototype, the ExpressiBall, which - through voice, sounds, lights, and motion sensors - explores how tangible technologies can support this range of expressive modalities. Finally, we discuss the concept of Self-Expression by Design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wilson, Cara and Sitbon, Laurianne and Ploderer, Bernd and Opie, Jeremy and Brereton, Margot},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {children, play, multimodal, autism, minimally-verbal, modalities, non-verbal, self-expression, tangible},
	pages = {1--13},
}

@inproceedings{zhang_dataquilt_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{DataQuilt}: {Extracting} {Visual} {Elements} from {Images} to {Craft} {Pictorial} {Visualizations}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376172},
	doi = {10.1145/3313831.3376172},
	abstract = {Recent years have seen an increasing interest in the authoring and crafting of personal visualizations. Mainstream data analysis and authoring tools lack the flexibility for customization and personalization, whereas tools from the research community either require creativity and drawing skills, or are limited to simple vector graphics. We present DataQuilt, a novel system that enables visualization authors to iteratively design pictorial visualizations as collages. Real images (e.g., paintings, photographs, sketches) act as both inspiration and as a resource of visual elements that can be mapped to data. The creative pipeline involves the semi-guided extraction of relevant elements of an image (arbitrary regions, regular shapes, color palettes, textures) aided by computer vision techniques; the binding of these graphical elements and their features to data in order to create meaningful visualizations; and the iterative refinement of both features and visualizations through direct manipulation. We demonstrate the usability of DataQuilt in a controlled study and its expressiveness through a collection of authored visualizations from a second open-ended study.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Jiayi Eris and Sultanum, Nicole and Bezerianos, Anastasia and Chevalier, Fanny},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {creativity, collage, graphic design, pictorial visualization},
	pages = {1--13},
}

@inproceedings{ghosh_eyeditor_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{EYEditor}: {Towards} {On}-the-{Go} {Heads}-{Up} {Text} {Editing} {Using} {Voice} and {Manual} {Input}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376173},
	doi = {10.1145/3313831.3376173},
	abstract = {On-the-go text-editing is difficult, yet frequently done in everyday lives. Using smartphones for editing text forces users into a heads-down posture which can be undesirable and unsafe. We present EYEditor, a heads-up smartglass-based solution that displays the text on a see-through peripheral display and allows text-editing with voice and manual input. The choices of output modality (visual and/or audio) and content presentation were made after a controlled experiment, which showed that sentence-by-sentence visual-only presentation is best for optimizing users' editing and path-navigation capabilities. A second experiment formally evaluated EYEditor against the standard smartphone-based solution for tasks with varied editing complexities and navigation difficulties. The results showed that EYEditor outperformed smartphones as either the path OR the task became more difficult. Yet, the advantage of EYEditor became less salient when both the editing and navigation was difficult. We discuss trade-offs and insights gained for future heads-up text-editing solutions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ghosh, Debjyoti and Foong, Pin Sym and Zhao, Shengdong and Liu, Can and Janaka, Nuwan and Erusu, Vinitha},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {voice interaction, text editing, mobile interaction, eyeditor, heads-up interaction, manual-input, re-speaking, smart glass, wearable interaction},
	pages = {1--13},
}

@inproceedings{mitchell_finnigan_no_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{No} {Powers}, {Man}!": {A} {Student} {Perspective} on {Designing} {University} {Smart} {Building} {Interactions}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376174},
	doi = {10.1145/3313831.3376174},
	abstract = {Smart buildings offer an opportunity for better performance and enhanced experience by contextualising services and interactions to the needs and practices of occupants. Yet, this vision is limited by established approaches to building management, delivered top-down through professional facilities management teams, opening up an interaction-gap between occupants and the spaces they inhabit. To address the challenge of how smart buildings might be more inclusively managed, we present the results of a qualitative study with student occupants of a smart building, with design workshops including building walks and speculative futuring. We develop new understandings of how student occupants conceptualise and evaluate spaces as they experience them, and of how building management practices might evolve with new sociotechnical systems that better leverage occupant agency. Our findings point to important directions for HCI research in this nascent area, including the need for HBI (Human-Building Interaction) design to challenge entrenched roles in building management.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mitchell Finnigan, Samantha and Clear, Adrian K.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {walking, sustainability, hbi, human-building interaction, speculative design, sustainable hci},
	pages = {1--14},
}

@inproceedings{lee_i_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{I} {Hear} {You}, {I} {Feel} {You}": {Encouraging} {Deep} {Self}-{Disclosure} through a {Chatbot}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376175},
	doi = {10.1145/3313831.3376175},
	abstract = {Chatbots have great potential to serve as a low-cost, effective tool to support people's self-disclosure. Prior work has shown that reciprocity occurs in human-machine dialog; however, whether reciprocity can be leveraged to promote and sustain deep self-disclosure over time has not been systematically studied. In this work, we design, implement and evaluate a chatbot that has self-disclosure features when it performs small talk with people. We ran a study with 47 participants and divided them into three groups to use different chatting styles of the chatbot for three weeks. We found that chatbot self-disclosure had a reciprocal effect on promoting deeper participant self-disclosure that lasted over the study period, in which the other chat styles without self-disclosure features failed to deliver. Chatbot self-disclosure also had a positive effect on improving participants' perceived intimacy and enjoyment over the study period. Finally, we reflect on the design implications of chatbots where deep self-disclosure is needed over time.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Yi-Chieh and Yamashita, Naomi and Huang, Yun and Fu, Wai},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {chatbot, conversation, mental well-being, self-disclosure},
	pages = {1--12},
}

@inproceedings{dmitrenko_caroma_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{CARoma} {Therapy}: {Pleasant} {Scents} {Promote} {Safer} {Driving}, {Better} {Mood}, and {Improved} {Well}-{Being} in {Angry} {Drivers}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376176},
	doi = {10.1145/3313831.3376176},
	abstract = {Driving is a task that is often affected by emotions. The effect of emotions on driving has been extensively studied. Anger is an emotion that dominates in such investigations. Despite the knowledge on strong links between scents and emotions, few studies have explored the effect of olfactory stimulation in a context of driving. Such an outcome provides HCI practitioners very little knowledge on how to design for emotions using olfactory stimulation in the car. We carried out three studies to select scents of different valence and arousal levels (i.e. rose, peppermint, and civet) and anger eliciting stimuli (i.e. affective pictures and on-road events). We used this knowledge to conduct the fourth user study investigating how the selected scents change the emotional state, well-being, and driving behaviour of drivers in an induced angry state. Our findings enable better decisions on what scents to choose when designing interactions for angry drivers.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dmitrenko, Dmitrijs and Maggioni, Emanuela and Brianza, Giada and Holthausen, Brittany E. and Walker, Bruce N. and Obrist, Marianna},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {smell, emotions, in-car user interfaces, multimodal interfaces, notification systems, odour stimulation, perception},
	pages = {1--13},
}

@inproceedings{hohman_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding and {Visualizing} {Data} {Iteration} in {Machine} {Learning}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376177},
	doi = {10.1145/3313831.3376177},
	abstract = {Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, Chameleon, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply system to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, find failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hohman, Fred and Wongsuphasawat, Kanit and Kery, Mary Beth and Patel, Kayur},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {visual analytics, data iteration, evolving datasets, interactive interfaces, machine learning iteration},
	pages = {1--13},
}

@inproceedings{swart_is_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Is {This} {An} {Ad}?: {Automatically} {Disclosing} {Online} {Endorsements} {On} {YouTube} {With} {AdIntuition}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376178},
	doi = {10.1145/3313831.3376178},
	abstract = {Undisclosed online endorsements on social media can be misleading to users who may not know when viewed content contains advertisements. Despite federal regulations requiring content creators to disclose online endorsements, studies suggest that less than 10\% do so in practice. To overcome this issue, we need knowledge of how to best detect online endorsements, knowledge about how prevalent online endorsements are in the wild, and ways to design systems to automatically disclose advertising content to viewers. To that end, we designed, implemented, and evaluated a tool called AdIntuition which automatically discloses when YouTube videos contain affiliate marketing, a type of social media endorsement. We evaluated AdIntuition with 783 users using a survey, field deployment, and diary study. We discuss our findings and recommendations for future measurements of and tools to detect and alert users about affiliate marketing content.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Swart, Michael and Lopez, Ylana and Mathur, Arunesh and Chetty, Marshini},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {social media, advertisements, browser extension, influencer},
	pages = {1--12},
}

@inproceedings{lambton-howard_unplatformed_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Unplatformed {Design}: {A} {Model} for {Appropriating} {Social} {Media} {Technologies} for {Coordinated} {Participation}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376179},
	doi = {10.1145/3313831.3376179},
	abstract = {Using existing social media technologies as a resource for design offers significant potential for sustainable and scalable ways of coordinating participation. We look at three exemplar projects in three distinct domains that have successfully coordinated participation through the configuration and augmentation of existing social media technologies: participatory future forecasting, participatory health research, and connectivist learning. In this paper we conceptualise social media technologies as material for design, that is, as the raw material with which coordinated participation is realized. From this we develop a model that proposes four material qualities of social media technologies, morphology, role, representation of activity and permeability, and point to how they can be productively employed in the design of coordination of participation.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lambton-Howard, Daniel and Olivier, Patrick and Vlachokyriakos, Vasilis and Celina, Hanna and Kharrufa, Ahmed},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {social media, materiality, design of participation},
	pages = {1--13},
}

@inproceedings{chen_doughnets_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{DoughNets}: {Visualising} {Networks} {Using} {Torus} {Wrapping}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376180},
	doi = {10.1145/3313831.3376180},
	abstract = {We investigate visualisations of networks on a 2-dimensional torus topology, like an opened-up and flattened doughnut. That is, the network is drawn on a rectangular area while "wrapping" specific links around the border. Previous work on torus drawings of networks has been mostly theoretical, limited to certain classes of networks, and not evaluated by human readability studies. We offer a simple interactive layout approach applicable to general graphs. We use this to find layouts affording better aesthetics in terms of conventional measures like more equal edge length and fewer crossings. In two controlled user studies we find that torus layout with either additional context or interactive panning provided significant performance improvement (in terms of error and time) over torus layout without either of these improvements, to the point that it is comparable to standard non-torus layout.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Kun-Ting and Dwyer, Tim and Marriott, Kim and Bach, Benjamin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {user study, graph visualization, network visualization, torus topology},
	pages = {1--11},
}

@inproceedings{kong_addressing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Addressing {Cognitive} and {Emotional} {Barriers} in {Parent}-{Clinician} {Communication} through {Behavioral} {Visualization} {Webtools}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376181},
	doi = {10.1145/3313831.3376181},
	abstract = {Effective communication between clinicians and parents of young children with developmental delays can decrease parents' anxiety, help them handle bad news, and improve their adherence to proposed interventions. However, parents have reported dissatisfaction regarding their current communication with clinicians, and they face cognitive and emotional challenges when discussing their child's developmental delays. In this paper, we present visualization as a facilitator of parent-clinician communication and how it could address existing communication challenges. Parents and clinicians anticipated visualization webtools would aid their communication by helping parents gain a better understanding of their child, acting as objective evidence, and highlighting the strength of the child as well as important medical concepts. In addition, visualization can act as a longitudinal record, helping parents track, explore, and share their child's developmental progress. Finally, we propose visualization as a tool to guide parents in their transition from feeling emotional and disempowered to advocating with confidence.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kong, Ha-Kyung and Karahalios, Karrie},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {visualization, clinical communication, developmental delays},
	pages = {1--12},
}

@inproceedings{taber_finsta_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{On} {Finsta}, {I} {Can} {Say} '{Hail} {Satan}'": {Being} {Authentic} but {Disagreeable} on {Instagram}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376182},
	doi = {10.1145/3313831.3376182},
	abstract = {We use personality theory to compare self-presentation between multiple Instagram accounts, investigating authenticity and consistency. Many studies claim social media promote inauthentic self-presentation focused on socially desirable traits. At the same time, affordances suggest that self-presentation should be relatively consistent within one social medium. For 88 participants, we examine personality traits for 'real Instagram' ('Rinsta') versus 'fake Instagram' ('Finsta') accounts, comparing these with people's offline traits using mixed-methods. Counterintuitively, we find Finsta accounts often present socially undesirable traits. Furthermore, different accounts on the same social medium reveal quite different styles of self-presentation. Overall Finstas are more Extraverted, less Conscientious, and less Agreeable than Rinstas, although equally Neurotic as offline. Interviews indicate trait differences arise from differing audience perceptions. A large anonymous Rinsta audience promotes a carefully curated self. In contrast, a small but trusted Finsta audience can engender more authentic, but negative self-presentation. We discuss design and theory implications.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Taber, Lee and Whittaker, Steve},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {social media, personality, affordances, finsta, instagram, rinsta, self-perception, self-presentation, traits},
	pages = {1--14},
}

@inproceedings{prpa_inhaling_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Inhaling and {Exhaling}: {How} {Technologies} {Can} {Perceptually} {Extend} {Our} {Breath} {Awareness}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376183},
	doi = {10.1145/3313831.3376183},
	abstract = {Attending to breath is a self-awareness practice that exists within many contemplative and reflective traditions and is recognized for its benefits to well-being. Our current technological landscape embraces a large body of systems that utilize breath data in order to foster self-awareness. This paper seeks to deepen our understanding of the design space of systems that perceptually extend breath awareness. Our contribution is twofold: (1) our analysis reveals how the underlying theoretical frameworks shape the system design and its evaluation, and (2) how system design features support perceptual extension of breath awareness. We review and critically analyze 31 breath-based interactive systems. We identify 4 theoretical frameworks and 3 design strategies for interactive systems that perceptually extend breath awareness. We reflect upon this design space from both a theoretical and system design perspective, and propose future design directions for developing systems that "listen to" breath and perceptually extend it.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Prpa, Mirjana and Stepanova, Ekaterina R. and Schiphorst, Thecla and Riecke, Bernhard E. and Pasquier, Philippe},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {soma design, breath, breathing regulation, breathing synchronization, mindfulness-based design, perceptually extending},
	pages = {1--15},
}

@inproceedings{richardson_reading_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Reading with the {Tongue}: {Individual} {Differences} {Affect} the {Perception} of {Ambiguous} {Stimuli} with the {BrainPort}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376184},
	doi = {10.1145/3313831.3376184},
	abstract = {There is an increasing interest in non-visual interfaces for HCI to take advantage of the information processing capability of the other sensory modalities. The BrainPort is a vision-to-tactile sensory substitution device that conveys information through electro-stimulation on the tongue. As the tongue is a horizontal surface, it makes for an interesting platform to study the brain's representation of space. But which way is up on the tongue? We provided participants with perceptually ambiguous stimuli and measured how often different perspectives were adopted; furthermore, whether camera orientation and gender had an effect. Additionally, we examined whether personality (trait extraversion and openness) could predict the perspective taken. We found that self-centered perspectives were predominantly adopted, and that trait openness may predict perspective. This research demonstrates how individual differences can affect the usability of sensory substitution devices, and highlights the need for flexible and customisable interfaces.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Richardson, Mike L. and Lloyd-Esenkaya, Tayfun and Petrini, Karin and Proulx, Michael J.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {individual differences in computing, sensory substitution, tactile interfaces, user preferences},
	pages = {1--10},
}

@inproceedings{khovanskaya_bottom-up_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Bottom-{Up} {Organizing} with {Tools} from {On} {High}: {Understanding} the {Data} {Practices} of {Labor} {Organizers}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376185},
	doi = {10.1145/3313831.3376185},
	abstract = {This paper provides insight into the use of data tools in the American labor movement by analyzing the practices of staff employed by unions to organize alongside union members. We interviewed 23 field-level staff organizers about how they use data tools to evaluate membership. We find that organizers work around and outside of these tools to develop access to data for union members and calibrate data representations to meet local needs. Organizers mediate between local and central versions of the data, and draw on their contextual knowledge to challenge campaign strategy. We argue that networked data tools can compound field organizers' lack of discretion, making it more difficult for unions to assess and act on the will of union membership. We show how the use of networked data tools can lead to less accurate data, and discuss how bottom-up approaches to data gathering can support more accurate membership assessments.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Khovanskaya, Vera and Sengers, Phoebe and Dombrowski, Lynn},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {activism, critical data studies, data-driven workplace, unions},
	pages = {1--13},
}

@inproceedings{trajkova_move_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Move {Your} {Body}: {Engaging} {Museum} {Visitors} with {Human}-{Data} {Interaction}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376186},
	doi = {10.1145/3313831.3376186},
	abstract = {Museums have embraced embodied interaction: its novelty generates buzz and excitement among their patrons, and it has enormous educational potential. Human-Data Interaction (HDI) is a class of embodied interactions that enables people to explore large sets of data using interactive visualizations that users control with gestures and body movements. In museums, however, HDI installations have no utility if visitors do not engage with them. In this paper, we present a quasi-experimental study that investigates how different ways of representing the user ("mode type") next-to a data visualization alters the way in which people engage with a HDI system. We consider four mode types: avatar, skeleton, camera overlay, and control. Our findings indicate that the mode type impacts the number of visitors that interact with the installation, the gestures that people do, and the amount of time that visitors spend observing the data on display and interacting with the system.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Trajkova, Milka and Alhakamy, A'aeshah and Cafaro, Francesco and Mallappa, Rashmi and Kankara, Sreekanth R.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {human-data interaction, public displays, informal learning, embodied interaction, museums},
	pages = {1--13},
}

@inproceedings{parviainen_experiential_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Experiential {Qualities} of {Whispering} with {Voice} {Assistants}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376187},
	doi = {10.1145/3313831.3376187},
	abstract = {We present a Research through Design project that explores how whispering influences the ways people experience and interact with voice assistants. The research project includes a co-speculation workshop and the use of a design probe, which culminated in the production of a design fiction short film. Our design-led inquiry contributes with experiential qualities of whispering with voice assistants: creepiness, trust, and intimacy. Furthermore, we present how whispering opens up new dimensions of how and when voice interaction could be used. We propose that designers of whispering voice assistants should reflect on how they facilitate the experiential qualities of creepiness, trust, and intimacy, and reflect on the potential challenges whispering brings to the relation between a user and a voice assistant.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Parviainen, Emmi and Søndergaard, Marie Louise Juul},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {voice assistants, voice interaction, research through design, design fiction, experiential qualities, whispering},
	pages = {1--13},
}

@inproceedings{robinson_tricks_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Tricks and {Treats}: {Designing} {Technology} to {Support} {Mobility} {Assistance} {Dogs}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376188},
	doi = {10.1145/3313831.3376188},
	abstract = {Assistance dogs are a key intervention to support the autonomy of people with tetraplegia. Previous research on assistive technologies have investigated ways to, ultimately, replace their labour using technology, for instance through the design of smart home environments. However, both the disability studies literature and our interviews suggest there is an immediate need to support these relationships, both in terms of training and bonding. Through a case study of an accessible dog treats dispenser, we investigate a technological intervention responding to these needs, detailing an appropriate design methodology and contributing insights into user requirements and preferences.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Robinson, Charlotte and Brulé, Emeline and Jackson, James and Torjussen, Alice and Kybett, Joshua and Appshaw, Tom},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {assistive technology, disability, assistance dog, service dog, tetraplegia},
	pages = {1--14},
}

@inproceedings{marky_3d-auth_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{3D}-{Auth}: {Two}-{Factor} {Authentication} with {Personalized} {3D}-{Printed} {Items}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376189},
	doi = {10.1145/3313831.3376189},
	abstract = {Two-factor authentication is a widely recommended security mechanism and already offered for different services. However, known methods and physical realizations exhibit considerable usability and customization issues. In this paper, we propose 3D-Auth, a new concept of two-factor authentication. 3D-Auth is based on customizable 3D-printed items that combine two authentication factors in one object. The object bottom contains a uniform grid of conductive dots that are connected to a unique embedded structure inside the item. Based on the interaction with the item, different dots turn into touch-points and form an authentication pattern. This pattern can be recognized by a capacitive touchscreen. Based on an expert design study, we present an interaction space with six categories of possible authentication interactions. In a user study, we demonstrate the feasibility of 3D-Auth items and show that the items are easy to use and the interactions are easy to remember.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Marky, Karola and Schmitz, Martin and Zimmermann, Verena and Herbers, Martin and Kunze, Kai and Mühlhäuser, Max},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {3d printing, capacitive sensing, two-factor authentication},
	pages = {1--12},
}

@inproceedings{han_hapbead_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{HapBead}: {On}-{Skin} {Microfluidic} {Haptic} {Interface} {Using} {Tunable} {Bead}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376190},
	doi = {10.1145/3313831.3376190},
	abstract = {On-skin haptic interfaces using soft elastomers which are thin and flexible have significantly improved in recent years. Many are focused on vibrotactile feedback that requires complicated parameter tuning. Another approach is based on mechanical forces created via piezoelectric devices and other methods for non-vibratory haptic sensations like stretching, twisting. These are often bulky with electronic components and associated drivers are complicated with limited control of timing and precision. This paper proposes HapBead, a new on-skin haptic interface that is capable of rendering vibration like tactile feedback using microfluidics. HapBead leverages a microfluidic channel to precisely and agilely oscillate a small bead via liquid flow, which then generates various motion patterns in channel that creates highly tunable haptic sensations on skin. We developed a proof-of-concept design to implement thin, flexible and easily affordable HapBead platform, and verified its haptic rendering capabilities via attaching it to users' fingertips. A study was carried out and confirmed that participants could accurately tell six different haptic patterns rendered by HapBead. HapBead enables new wearable display applications with multiple integrated functionalities such as on-skin haptic doodles, visuo-haptic displays and haptic illusions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Han, Teng and Bansal, Shubhi and Shi, Xiaochen and Chen, Yanjun and Quan, Baogang and Tian, Feng and Wang, Hongan and Subramanian, Sriram},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {haptics, microfluidics, fluid flow, wearable devices},
	pages = {1--10},
}

@inproceedings{turkay_see_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {See {No} {Evil}, {Hear} {No} {Evil}, {Speak} {No} {Evil}: {How} {Collegiate} {Players} {Define}, {Experience} and {Cope} with {Toxicity}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376191},
	doi = {10.1145/3313831.3376191},
	abstract = {Toxicity in online environments is a complex and a systemic issue. Collegiate esports communities seem to be particularly vulnerable to toxic behaviors. In esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce enjoyment which may cause them to leave the game. The aim of this study is to investigate how players define, experience and deal with toxicity in esports games that they play. Our findings from an interview study and five monthly follow ups with 19 participants from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and are inclined to normalize negative behaviors, rationalize it as part of the competitive game culture akin to traditional sports, and participate a form of gamer classism, believing that toxicity is more common in lower level play than in professional and collegiate esports. There are many coping mechanisms employed by collegiate esports players, including ignoring offenders, deescalating tense encounters, and using tools to mute offenders. Understanding the motivations behind collegiate esports players' engagement with toxicity may help the growing sport plot a positive trajectory towards healthy play.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Türkay, Selen and Formosa, Jessica and Adinolf, Sonam and Cuthbert, Robert and Altizer, Roger},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {competitive games, esports, interview study, player perceptions, toxicity},
	pages = {1--13},
}

@inproceedings{fernandez_camporro_live_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Live {Sketchnoting} {Across} {Platforms}: {Exploring} the {Potential} and {Limitations} of {Analogue} and {Digital} {Tools}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376192},
	doi = {10.1145/3313831.3376192},
	abstract = {Sketchnoting is the process of creating a visual record with combined text and imagery of an event or presentation. Although analogue tools are still the most common method for sketchnoting, the use of digital tools is increasing. We conducted a study to better understand the current practices, techniques, compromises and opportunities of creating both pen\&amp;paper and digital sketchnotes. Our research combines insights from semi-structured interviews with the findings from a within-subjects observational study where ten participants created real time sketchnotes of two video presentations on both paper and digital tablet. We report our key findings, categorised into six themes: insights into sense of space; trade-offs with flexibility; choice paradox and cognitive load; matters of perception, accuracy and texture; issues around confidence; and practicalities. We discuss those findings, the potential and limitations of different methods, and implications for the design of future digital sketchnoting tools.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fernández Camporro, Marina and Marquardt, Nicolai},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {sketching, digital ink, pen interaction, sketchnoting, tablet, visual note taking},
	pages = {1--12},
}

@inproceedings{poeller_power_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Power {Play}: {How} the {Need} to {Empower} or {Overpower} {Other} {Players} {Predicts} {Preferences} in {League} of {Legends}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376193},
	doi = {10.1145/3313831.3376193},
	abstract = {The power motive describes our need to have an impact on others. Relevant in contexts such as sports, politics, and business, the power motive could help explain experiences and behaviours in digital games. We present four studies connecting the power motive to role and champion type choices in the MOBA game League of Legends (LoL). In Study1 we demonstrate that overall power motive does not predict role preferences. In Study2 we develop a 6-item-scale distinguishing between two facets of power in game settings: prosociality (empowering others) and dominance (overpowering others). In Study3 we show that prosociality and dominance uniquely predict role preferences for Support and Top Lane. In Study4 we demonstrate that champion type choice (tank, fighter, slayer, controller) is uniquely predicted by dominance and prosociality. We provide insight on how the wish for vertical interactions with other players-the power motive-can influence player interactions in multiplayer games.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Poeller, Susanne and Baumann, Nicola and Mandryk, Regan L.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {digital games, explicit motives, motive disposition theory, player preferences, player types, power motive},
	pages = {1--13},
}

@inproceedings{bachynskyi_dynamics_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Dynamics of {Aimed} {Mid}-{Air} {Movements}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376194},
	doi = {10.1145/3313831.3376194},
	abstract = {Mid-air arm movements are ubiquitous in VR, AR, and gestural interfaces. While mouse movements have received some attention, the dynamics of mid-air movements are understudied in HCI. In this paper we present an exploratory analysis of the dynamics of aimed mid-air movements. We explore the 3rd order lag (3OL) and existing 2nd order lag (2OL) models for modeling these dynamics. For a majority of movements the 3OL model captures mid-air dynamics better, in particular acceleration. The models can effectively predict the complete time series of position, velocity and acceleration of aimed movements given an initial state and a target using three (2OL) or four (3OL) free parameters.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Bachynskyi, Myroslav and Müller, Jörg},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {aimed movements, control theory, mid-air movements, movement dynamics},
	pages = {1--12},
}

@inproceedings{gunther_therminator_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Therminator: {Understanding} the {Interdependency} of {Visual} and {On}-{Body} {Thermal} {Feedback} in {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376195},
	doi = {10.1145/3313831.3376195},
	abstract = {Recent advances have made Virtual Reality (VR) more realistic than ever before. This improved realism is attributed to today's ability to increasingly appeal to human sensations, such as visual, auditory or tactile. While research also examines temperature sensation as an important aspect, the interdependency of visual and thermal perception in VR is still underexplored. In this paper, we propose Therminator, a thermal display concept that provides warm and cold on-body feedback in VR through heat conduction of flowing liquids with different temperatures. Further, we systematically evaluate the interdependency of different visual and thermal stimuli on the temperature perception of arm and abdomen with 25 participants. As part of the results, we found varying temperature perception depending on the stimuli, as well as increasing involvement of users during conditions with matching stimuli.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Günther, Sebastian and Müller, Florian and Schön, Dominik and Elmoghazy, Omar and Mühlhäuser, Max and Schmitz, Martin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, haptics, temperature, thermal feedback},
	pages = {1--14},
}

@inproceedings{creed_multimodal_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Multimodal {Gaze} {Interaction} for {Creative} {Design}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376196},
	doi = {10.1145/3313831.3376196},
	abstract = {We present a new application ("Sakura") that enables people with physical impairments to produce creative visual design work using a multimodal gaze approach. The system integrates multiple features tailored for gaze interaction including the selection of design artefacts via a novel grid approach, control methods for manipulating canvas objects, creative typography, a new color selection approach, and a customizable guide technique facilitating the alignment of design elements. A user evaluation (N=24) found that non-disabled users were able to utilize the application to complete common design activities and that they rated the system positively in terms of usability. A follow-up study with physically impaired participants (N=6) demonstrated they were able to control the system when working towards a website design, rating the application as having a good level of usability. Our research highlights new directions in making creative activities more accessible for people with physical impairments.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Creed, Chris and Frutos-Pascual, Maite and Williams, Ian},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {gaze interaction, eye gaze design, eye gaze tracking, interface design},
	pages = {1--13},
}

@inproceedings{ackermans_effects_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {Effects} of {Explicit} {Intention} {Communication}, {Conspicuous} {Sensors}, and {Pedestrian} {Attitude} in {Interactions} with {Automated} {Vehicles}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376197},
	doi = {10.1145/3313831.3376197},
	abstract = {In this paper, we investigate the effect of an external human-machine interface (eHMI) and a conspicuous external vehicle appearance due to visible sensors on pedestrian interactions with automated vehicles (AVs). Recent research shows that AVs may need to explicitly communicate with the environment due to the absence of a driver. Furthermore, in interaction situations, an AV that looks different and conspicuous owing to an extensive sensor system may potentially lead to hesitation stemming from mistrust in automation. Thus, we evaluated in a virtual reality study how pedestrian attitude, the presence/absence of an eHMI, and a conspicuous sensor system affect their willingness to cross the road. Results recommend the use of an eHMI. A conspicuous appearance of automated-driving capability had no effect for the sample as a whole, although it led to more efficient crossing decisions for those with a more negative attitude towards AVs. Our findings contribute towards the effective design of future AV interfaces.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ackermans, Sander and Dey, Debargha and Ruijten, Peter and Cuijpers, Raymond H. and Pfleging, Bastian},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {automated driving, automated vehicles, ehmi, external appearance, pedestrians, vehicle-pedestrian interaction, visible sensors, vulnerable road users},
	pages = {1--14},
}

@inproceedings{yeo_watouch_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{WATouCH}: {Enabling} {Direct} {Input} on {Non}-{Touchscreen} {Using} {Smartwatch}'s {Photoplethysmogram} and {IMU} {Sensor} {Fusion}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376198},
	doi = {10.1145/3313831.3376198},
	abstract = {Interacting with non-touchscreens such as TV or public displays can be difficult and inefficient. We propose WATouCH, a novel method that localizes a smartwatch on a display and allows direct input by turning the smartwatch into a tangible controller. This low-cost solution leverages sensor fusion of the built-in inertial measurement unit (IMU) and photoplethysmogram (PPG) sensor on a smartwatch that is used for heart rate monitoring. Specifically, WATouCH tracks the smartwatch movement using IMU data and corrects its location error caused by drift using the PPG responses to a dynamic visual pattern on the display. We conducted a user study on two tasks – a point and click and line tracing task – to evaluate the system usability and user performance. Evaluation results suggested that our sensor fusion mechanism effectively confined IMU-based localization error, achieved encouraging targeting and tracing precision, was well received by the participants, and thus opens up new opportunities for interaction.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yeo, Hui-Shyong and Feng, Wenxin and Huang, Michael Xuelin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {smartwatch, direct input, public display, tangible input},
	pages = {1--10},
}

@inproceedings{klamka_watchstrap_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Watch+{Strap}: {Extending} {Smartwatches} with {Interactive} {StrapDisplays}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376199},
	doi = {10.1145/3313831.3376199},
	abstract = {While smartwatches are widely adopted these days, their input and output space remains fairly limited by their screen size. We present StrapDisplays-interactive watchbands with embedded display and touch technologies-that enhance commodity watches and extend their input and output capabilities. After introducing the physical design space of these StrapDisplays, we explore how to combine a smartwatch and straps in a synergistic Watch+Strap system. Specifically, we propose multiple interface concepts that consider promising content distributions, interaction techniques, usage types, and display roles. For example, the straps can enrich watch apps, display visualizations, provide glanceable feedback, or help avoiding occlusion issues. Further, we provide a modular research platform incorporating three StrapDisplay prototypes and a flexible web-based software architecture, demonstrating the feasibility of our approach. Early brainstorming sessions with 15 participants informed our design process, while later interviews with six experts supported our concepts and provided valuable feedback for future developments.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Klamka, Konstantin and Horak, Tom and Dachselt, Raimund},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {wearable device, smartwatch, mobile interaction, flexible displays, interactive watchband, mde, mobile visualization},
	pages = {1--15},
}

@inproceedings{matthews_high_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {High {Tempo} {Work}: {Design} {Challenges} for {Head}-{Worn} {Displays} in {Quick} {Service} {Restaurants}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376200},
	doi = {10.1145/3313831.3376200},
	abstract = {Quick service restaurants (QSRs) are high tempo work environments that require collaboration and communication between crew. In a number of respects, head-worn displays (HWDs) might seem a promising technology to support QSR crew, but on close inspection they raise challenging issues for design. We conducted fieldwork studies at two large QSRs to understand how work is organised, how existing systems are used, and how information is displayed to and communicated between crew. We observed the crew working both routinely and with improvisation, collaboratively and individually, physically and digitally. From our analysis of the field study, we identify tentative use cases for HWDs, but with these also design tensions-that is, opportunities coupled with challenges that appear difficult to circumvent even with modest design proposals. These tensions would require careful consideration if HWDs were to be deployed in in QSRs, given that HWDs are ubiquitous, potentially private, digital, mobile, and able to collect behavioural data.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Matthews, Ben and Salisbury, Isaac and Schlosser, Paul and Smith, Francine and Sanderson, Penelope},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {design tensions, fast food, fieldwork, head-worn display (hwd), quick service restaurant, smart glasses},
	pages = {1--12},
}

@inproceedings{zhou_users_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {User's {Role} in {Platform} {Infrastructuralization}: {WeChat} as an {Exemplar}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376201},
	doi = {10.1145/3313831.3376201},
	abstract = {Recent years have witnessed the rise of platforms such as Facebook and Google. Gigantic in scope and becoming omnipresent, these platforms are acquiring qualities of infrastructure, which is large-scale connected systems that support people's activities invisibly. Recent scholarship has identified WeChat, the most popular mobile social platform in China, as infrastructure. WeChat follows a platform logic to expand, and by conforming to the Chinese government's techno-nationalist focus, it has gradually become an infrastructure in China. We contribute to the understanding of platform infrastructuralization by taking WeChat as a case, highlighting the user's role in this process. We find user contributes to WeChat's infrastructuralization through a three-level interaction process: to practice, to appropriate, and to create. By calling out the user's role in platform infra-structuralization, we discuss how the CHI community can contribute to a better understanding of this phenomenon.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Rui and DiSalvo, Betsy},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {infrastructure, china, platform, social network, user, wechat},
	pages = {1--13},
}

@inproceedings{dogan_g-id_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {G-{ID}: {Identifying} {3D} {Prints} {Using} {Slicing} {Parameters}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376202},
	doi = {10.1145/3313831.3376202},
	abstract = {We present G-ID, a method that utilizes the subtle patterns left by the 3D printing process to distinguish and identify objects that otherwise look similar to the human eye. The key idea is to mark different instances of a 3D model by varying slicing parameters that do not change the model geometry but can be detected as machine-readable differences in the print. As a result, G-ID does not add anything to the object but exploits the patterns appearing as a by-product of slicing, an essential step of the 3D printing pipeline.We introduce the G-ID slicing and labeling interface that varies the settings for each instance, and the G-ID mobile app, which uses image processing techniques to retrieve the parameters and their associated labels from a photo of the 3D printed object. Finally, we evaluate our method's accuracy under different lighting conditions, when objects were printed with different filaments and printers, and with pictures taken from various positions and angles.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dogan, Mustafa Doga and Faruqi, Faraz and Churchill, Andrew Day and Friedman, Kenneth and Cheng, Leon and Subramanian, Sriram and Mueller, Stefanie},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {identification, personal fabrication, 3d printing, making, tags},
	pages = {1--13},
}

@inproceedings{meschtscherjakov_chase_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Chase {Lights} in the {Peripheral} {View}: {How} the {Design} of {Moving} {Patterns} on an {LED} {Strip} {Influences} the {Perception} of {Speed} in an {Automotive} {Context}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376203},
	doi = {10.1145/3313831.3376203},
	abstract = {LEDs on a strip, when turned on and off in a specific order, result in the perception of apparent motion (i.e. beta movement). In the automotive domain such chase lights have been used to alter drivers' perception of driving speed by manipulating the pixel speed of LEDs. We argue that the perceived velocity of beta movement in the peripheral view is not only based on the actual pixel speed but can be influenced by other factors such as frequency, width and brightness of lit LED segments. We conducted a velocity matching experiment (N=25) by systematically varying these three properties, in order to determine their influence on a participant's perceived velocity in a vehicle mock-up. Results show that a higher frequency and stronger brightness increased perceived velocity, whereas segment width had no influence. We discuss how findings may be applied when designing systems that use beta movement to influence the perception of ambient light velocity.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Meschtscherjakov, Alexander and Döttlinger, Christine and Kaiser, Tim and Tscheligi, Manfred},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {chase lights, moving patterns, peripheral vision, velocity perception},
	pages = {1--9},
}

@inproceedings{vanderheiden_morphic_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Morphic: {Auto}-{Personalization} on a {Global} {Scale}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376204},
	doi = {10.1145/3313831.3376204},
	abstract = {Users frequently have trouble finding and changing technology settings, even when adjusting those settings to personalize their technology devices may significantly improve their user experience. This paper describes the Morphic project, a cloud-based auto-personalization tool. Primarily designed for improving accessibility, the auto-personalization in Morphic may also help a broader audience. This paper describes: 1) the technical infrastructure needed to support cloud-based auto-personalization, 2) the interaction design approaches necessary to support users during the personalization of their settings, and 3) which settings and modifications have been most frequently used. This paper presents the evolution of the Morphic project, the building of the infrastructure, the formative evaluation of various interaction design approaches (NFC cards, physical keypads, on-screen buttons, and menus), and implications for researchers and developers. It also includes preliminary findings from six technology probes.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Vanderheiden, Gregg and Lazar, Jonathan and Jordan, J. Bern and Ding, Yao and Wood, Rachel E.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, screen reader, auto-personalization, internationalization, public computing, screen magnification, shared devices, universal usability, users with disabilities},
	pages = {1--12},
}

@inproceedings{rule_clinical_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Clinical {Documentation} as {End}-{User} {Programming}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376205},
	doi = {10.1145/3313831.3376205},
	abstract = {As healthcare providers have transitioned from paper to electronic health records they have gained access to increasingly sophisticated documentation aids such as custom note templates. However, little is known about how providers use these aids. To address this gap, we examine how 48 ophthalmologists and their staff create and use content-importing phrases — a customizable and composable form of note template — to document office visits across two years. In this case study, we find 1) content-importing phrases were used to document the vast majority of visits (95\%), 2) most content imported by these phrases was structured data imported by data-links rather than boilerplate text, and 3) providers primarily used phrases they had created while staff largely used phrases created by other people. We conclude by discussing how framing clinical documentation as end-user programming can inform the design of electronic health records and other documentation systems mixing data and narrative text.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Rule, Adam and Goldstein, Isaac H. and Chiang, Michael F. and Hribar, Michelle R.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {text input, electronic health record, end-user programming},
	pages = {1--13},
}

@inproceedings{lockton_meeting_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Meeting {Designers} {Where} {They} {Are}: {Using} {Industry} {Events} as a {Research} {Venue} for {HCI} and {Design} {Methods} {Development}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376206},
	doi = {10.1145/3313831.3376206},
	abstract = {There is much work in the CHI community about the 'industry-academia divide', and how to bridge it. One key crossover between HCI/UX scientists and practitioners is the development and use of tools and methods-boundary objects between academia and practice. Among other forms of collaboration, there is an underdeveloped opportunity for academics to make use of industry events (conferences, meetups, design jams) as a research venue in the context of tool and method development. This paper describes three cases from work in academia-industry engagement over the last decade, in which workshops or experiments have been run at industry events as a way of trialling and developing tools directly with practitioners. We discuss advantages of this approach and extract key insights and practical implications, highlighting how the CHI community might use this method more widely, gathering relevant research outcomes while contributing to knowledge exchange between academia and practice.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lockton, Dan and Lallemand, Carine},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {design tools, industry events, industry-academia engagement, method development, practitioners},
	pages = {1--13},
}

@inproceedings{rao_2across_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{2Across}: {A} {Comparison} of {Audio}-{Tactile} and {Screen}-{Reader} {Based} {Representations} of a {Crossword} {Puzzle}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376207},
	doi = {10.1145/3313831.3376207},
	abstract = {Crosswords are a popular recreational game that relies on the spatial relationship between words. As a player answers clues, they begin to organize words to form an intersecting grid. A good non-visual representation should convey the interrelation of words and support the user in building a practical spatial image of the crossword grid. This paper looks at two approaches to representing a crossword puzzle for visually impaired users: a screen reader based crossword, and an audio-tactile crossword puzzle. We evaluate the designs in a study with 10 visually impaired participants. The audio-tactile representation was found to support the practical use of the crossword's spatial structure while the screen reader based puzzle leveraged participant's prior experience in navigating websites. The paper discusses critical aspects of our study and presents a perspective on the use of multimodal interfaces for such spatial applications.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Rao, Hrishikesh V. and O'Modhrain, Sile},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, audio-tactile, refreshable braille display},
	pages = {1--12},
}

@inproceedings{varghese_utilizing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Utilizing {Participant} {Voice} in {Volunteer} {Training}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376208},
	doi = {10.1145/3313831.3376208},
	abstract = {Delivering training to volunteers is a huge challenge for non-governmental organisations (NGOs). Traditional classroom-based approaches that dominate training are problematic due to the limited participation they offer to trainees. Peer-led approaches however, have shown promise in helping NGOs utilise trainee experiences within training. Although technologies are playing an increasing role in training, their benefits are not well understood. We describe our experience of designing peer-led training for community volunteers in rural India. Working alongside an NGO involved in community regeneration and social action, we collaboratively delivered a ten-day training workshop, deploying audio technologies to engage the participants in sharing lived experiences. We draw on reflections from trainers and trainees on how utilising participant voice can enhance training. We highlight opportunities around the usage of audio technologies for engaging with participant voice, including the ability to reclaim trainee agency within training and to work within cultural barriers.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Varghese, Delvin and Rainey, Jay and Montague, Kyle and Bartindale, Tom and Olivier, Patrick and Baillie Smith, Matt},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {learning, ictd, hci4d, audio technologies, ngo, organizational training},
	pages = {1--14},
}

@inproceedings{li_conversation_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {Conversation} {Analysis} of {Non}-{Progress} and {Coping} {Strategies} with a {Banking} {Task}-{Oriented} {Chatbot}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376209},
	doi = {10.1145/3313831.3376209},
	abstract = {Task-oriented chatbots are becoming popular alternatives for fulfilling users' needs, but few studies have investigated how users cope with conversational 'non-progress' (NP) in their daily lives. Accordingly, we analyzed a three-month conversation log between 1,685 users and a task-oriented banking chatbot. In this data, we observed 12 types of conversational NP; five types of content that was unexpected and challenging for the chatbot to recognize; and 10 types of coping strategies. Moreover, we identified specific relationships between NP types and strategies, as well as signs that users were about to abandon the chatbot, including 1) three consecutive incidences of NP, 2) consecutive use of message reformulation or switching subjects, and 3) using message reformulation as the final strategy. Based on these findings, we provide design recommendations for task-oriented chatbots, aimed at reducing NP, guiding users through such NP, and improving user experiences to reduce the cessation of chatbot use.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Chi-Hsun and Yeh, Su-Fang and Chang, Tang-Jie and Tsai, Meng-Hsuan and Chen, Ken and Chang, Yung-Ju},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {conversation analysis, chatbot, breakdowns, coping strategies, non-progress},
	pages = {1--12},
}

@inproceedings{volkel_developing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Developing a {Personality} {Model} for {Speech}-{Based} {Conversational} {Agents} {Using} the {Psycholexical} {Approach}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376210},
	doi = {10.1145/3313831.3376210},
	abstract = {We present the first systematic analysis of personality dimensions developed specifically to describe the personality of speech-based conversational agents. Following the psycholexical approach from psychology, we first report on a new multi-method approach to collect potentially descriptive adjectives from 1) a free description task in an online survey (228 unique descriptors), 2) an interaction task in the lab (176 unique descriptors), and 3) a text analysis of 30,000 online reviews of conversational agents (Alexa, Google Assistant, Cortana) (383 unique descriptors). We aggregate the results into a set of 349 adjectives, which are then rated by 744 people in an online survey. A factor analysis reveals that the commonly used Big Five model for human personality does not adequately describe agent personality. As an initial step to developing a personality model, we propose alternative dimensions and discuss implications for the design of agent personalities, personality-aware personalisation, and future research.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Völkel, Sarah Theres and Schödel, Ramona and Buschek, Daniel and Stachl, Clemens and Winterhalter, Verena and Bühner, Markus and Hussmann, Heinrich},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {conversational agents, personality, big 5},
	pages = {1--14},
}

@inproceedings{andrade_introducing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Introducing the {Gamer} {Information}-{Control} {Framework}: {Enabling} {Access} to {Digital} {Games} for {People} with {Visual} {Impairment}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376211},
	doi = {10.1145/3313831.3376211},
	abstract = {In this paper, we present a foundation for understanding the elements that enable people with visual impairment to engage with digital games. This is defined by the gamer's relation- ships with information and with elements of control provided by the game, and is mediated through in-game metaphors and affordances when gamers interact as users or creators. This work complements previous research exploring the points of view of gamers with visual impairment by focusing on the games they play and prioritising the relationships between the key enablers of access to digital games. Using the framework to examine existing and missing components will enable de- signers to consider broader aspects of accessibility in game design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Andrade, Ronny and Rogerson, Melissa J. and Waycott, Jenny and Baker, Steven and Vetere, Frank},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {visual impairment, information, digital games, audiogames, control, framework},
	pages = {1--14},
}

@inproceedings{lee_mirrorpad_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{MirrorPad}: {Mirror} on {Touchpad} for {Direct} {Pen} {Interaction} in the {Laptop} {Environment}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376212},
	doi = {10.1145/3313831.3376212},
	abstract = {There are needs for pen interaction on a laptop, and the market sees many pen-enabled laptop products. Many of these laptops can be transformed into tablets, when pen interaction is needed. In a real situation, however, a workflow often requires both keyboard and pen interactions, and such a convertible feature may not be effective. In this study, we introduce MirrorPad, a novel interface device contained in a laptop for direct pen interaction. It is both a normal touchpad and a viewport for pen interaction with a mirrored region on the screen. We report findings and decisions obtained from the design iterations that we conducted with users to refine MirrorPad toward the final design. In the user study, MirrorPad showed the same performance as that of the laptop configuration during keyboard interaction and a performance similar to that of the tablet configuration during pen interaction. The user study results confirmed that MirrorPad effectively supports a workflow, which requires interspersed keyboard and pen interactions, thereby achieving its initial goal.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Sangyoon and Lim, Youn-kyung and Lee, Geehyuk},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {direct pen interaction, laptop environment, touchpad with display},
	pages = {1--9},
}

@inproceedings{yaqub_effects_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Effects of {Credibility} {Indicators} on {Social} {Media} {News} {Sharing} {Intent}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376213},
	doi = {10.1145/3313831.3376213},
	abstract = {In recent years, social media services have been leveraged to spread fake news stories. Helping people spot fake stories by marking them with credibility indicators could dissuade them from sharing such stories, thus reducing their amplification. We carried out an online study (N = 1,512) to explore the impact of four types of credibility indicators on people's intent to share news headlines with their friends on social media. We confirmed that credibility indicators can indeed decrease the propensity to share fake news. However, the impact of the indicators varied, with fact checking services being the most effective. We further found notable differences in responses to the indicators based on demographic and personal characteristics and social media usage frequency. Our findings have important implications for curbing the spread of misinformation via social media platforms.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yaqub, Waheeb and Kakhidze, Otari and Brockman, Morgan L. and Memon, Nasir and Patil, Sameer},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {social media, facebook, disinformation, fake news, misinformation, fact-check indicators, news headlines, news sharing},
	pages = {1--14},
}

@inproceedings{coles-kemp_too_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Too {Much} {Information}: {Questioning} {Security} in a {Post}-{Digital} {Society}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376214},
	doi = {10.1145/3313831.3376214},
	abstract = {Whilst user- and people-centered design are accepted routes for digital services, they are less commonly used in the design of technologies that control access to data and the security of information. The ubiquity of both technology and programmes such as "digital by default" as well as the weaving of digital systems into the everyday fabric of society, create an environment in which people and technology become enmeshed. Such an environment might be termed "post-digital" and its security is dependent on a people-centered approach to its design. In this paper we present a study that uses critical design techniques coupled with critical security analysis to examine how security might be approached in a post-digital context. We call for a paradigm shift towards a people-centered security practice and using a case study then make practical recommendations as to how this shift might be achieved.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Coles-Kemp, Lizzie and Jensen, Rikke Bjerg and Heath, Claude P. R.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {lived experience, critical security design, post-digital, post-digital security},
	pages = {1--14},
}

@inproceedings{watson_pip_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{PIP} {Kit}: {An} {Exploratory} {Investigation} into {Using} {Lifelogging} to {Support} {Disability} {Benefit} {Claimants}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376215},
	doi = {10.1145/3313831.3376215},
	abstract = {Disability assessment processes are complex and stressful, with claimants finding it challenging to prepare an effective account of their disabilities to support their claim. This project focuses on a disability benefit called Personal Independence Payment (PIP), which is received by millions of people with disabilities in the UK. We present a multi-stage exploratory investigation into how lifelogging could help address the challenges claimants have in accessing disability benefits. In the first study, benefit advisors participated in interviews and workshops to inform the design of PIP Kit, a highly customisable prototype elicitation diary to help disability claimants articulate their experiences. In the second study, PIP Kit was trialled by benefit claimants whilst making their actual PIP claims. We found that PIP Kit helped empower claimants in understanding the claim process and assisted in building arguments for their claims. We also have identified clear principles for supporting disability benefit claimants with technological interventions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Watson, Colin and Kirkham, Reuben and Kharrufa, Ahmed},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, disability, social security},
	pages = {1--14},
}

@inproceedings{marathe_officers_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Officers {Never} {Type}: {Examining} the {Persistence} of {Paper} in e-{Governance}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376216},
	doi = {10.1145/3313831.3376216},
	abstract = {The Global South has seen a proliferation of e-governance initiatives aimed at digitizing governmental service delivery. However, paper continues to remain the primary medium of bureaucracy. During ethnographic fieldwork at the CM Helpline, a state-wide e-governance initiative in central India, we observed that even tech-savvy bureaucrats who fully supported both the initiative and its paper-to-electronic transition ensured that paper continues to persist in abundance. Drawing upon scholarship from HCI, anthropology, and science \&amp; technology studies, we theorize this contradiction to uncover the circulations of power between people, paper, and electronic systems. We suggest that designers should recognize that new systems often disempower existing actors. The process of transition should integrate new systems into the existing ecosystem and plan for the graceful retirement of older technologies. In addition to machine errors, systems should be resilient to human errors. Finally, new systems should attend to sociocultural and historical specificities.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Marathe, Megh and Chandra, Priyank},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {design, bureaucracy, e-governance, paper, persistence, power, structural violence},
	pages = {1--13},
}

@inproceedings{li_swap_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Swap: {A} {Replacement}-{Based} {Text} {Revision} {Technique} for {Mobile} {Devices}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376217},
	doi = {10.1145/3313831.3376217},
	abstract = {Text revision is an important task to ensure the accuracy of text content. Revising text on mobile devices is cumbersome and time-consuming due to the imprecise caret control and the repetitive use of the backspace. We present Swap, a novel replacement-based technique to facilitate text revision on mobile devices. We conducted two user studies to validate the feasibility and the effectiveness of Swap compared to traditional text revision techniques. Results showed that Swap reduced efforts in caret control and repetitive backspace pressing during the text revision process. Most participants preferred to use the replacement-based technique rather than backspace and caret. They also commented that the new technique is easy to learn, and it makes text revision rapid and intuitive.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Yang and Sarcar, Sayan and Kim, Sunjun and Ren, Xiangshi},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {mobile device, backspace, caret control, text revision, virtual keyboard},
	pages = {1--12},
}

@inproceedings{wang_argulens_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{ArguLens}: {Anatomy} of {Community} {Opinions} {On} {Usability} {Issues} {Using} {Argumentation} {Models}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376218},
	doi = {10.1145/3313831.3376218},
	abstract = {In open-source software (OSS), the design of usability is often influenced by the discussions among community members on platforms such as issue tracking systems (ITSs). However, digesting the rich information embedded in issue discussions can be a major challenge due to the vast number and diversity of the comments. We propose and evaluate ArguLens, a conceptual framework and automated technique leveraging an argumentation model to support effective understanding and consolidation of community opinions in ITSs. Through content analysis, we anatomized highly discussed usability issues from a large, active OSS project, into their argumentation components and standpoints. We then experimented with supervised machine learning techniques for automated argument extraction. Finally, through a study with experienced ITS users, we show that the information provided by ArguLens supported the digestion of usability-related opinions and facilitated the review of lengthy issues. ArguLens provides the direction of designing valuable tools for high-level reasoning and effective discussion about usability.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Wenting and Arya, Deeksha and Novielli, Nicole and Cheng, Jinghui and Guo, Jin L.C.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {usability, online communities, argumentation analysis, issue discussion analysis, open source software},
	pages = {1--14},
}

@inproceedings{kaur_interpreting_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Interpreting {Interpretability}: {Understanding} {Data} {Scientists}' {Use} of {Interpretability} {Tools} for {Machine} {Learning}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376219},
	doi = {10.1145/3313831.3376219},
	abstract = {Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists' use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists' mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our findings in the social science literature.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {machine learning, interpretability, user-centric evaluation},
	pages = {1--14},
}

@inproceedings{klamka_rapid_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Rapid {Iron}-{On} {User} {Interfaces}: {Hands}-on {Fabrication} of {Interactive} {Textile} {Prototypes}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376220},
	doi = {10.1145/3313831.3376220},
	abstract = {Rapid prototyping of interactive textiles is still challenging, since manual skills, several processing steps, and expert knowledge are involved. We present Rapid Iron-On User Interfaces, a novel fabrication approach for empowering designers and makers to enhance fabrics with interactive functionalities. It builds on heat-activated adhesive materials consisting of smart textiles and printed electronics, which can be flexibly ironed onto the fabric to create custom interface functionality. To support rapid fabrication in a sketching-like fashion, we developed a handheld dispenser tool for directly applying continuous functional tapes of desired length as well as discrete patches. We introduce versatile compositions techniques that allow for creating complex circuits, utilizing commodity textile accessories and sketching custom-shaped I/O modules. We further contribute a comprehensive library of components for input, output, wiring and computing. Three example applications, results from technical experiments and expert reviews demonstrate the functionality, versatility and potential of this approach.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Klamka, Konstantin and Dachselt, Raimund and Steimle, Jürgen},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {prototyping, e-textile, fabrication, iron-on, wearable ui},
	pages = {1--14},
}

@inproceedings{peng_palette_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {Palette} of {Deepened} {Emotions}: {Exploring} {Emotional} {Challenge} in {Virtual} {Reality} {Games}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376221},
	doi = {10.1145/3313831.3376221},
	abstract = {Recent work introduced the notion of 'emotional challenge' promising for understanding more unique and diverse player experiences (PX). Although emotional challenge has immediately attracted HCI researchers' attention, the concept has not been experimentally explored, especially in virtual reality (VR), one of the latest gaming environments. We conducted two experiments to investigate how emotional challenge affects PX when separately from or jointly with conventional challenge in VR and PC conditions. We found that relatively exclusive emotional challenge induced a wider range of different emotions in both conditions, while the adding of emotional challenge broadened emotional responses only in VR. In both experiments, VR significantly enhanced the measured PX of emotional responses, appreciation, immersion and presence. Our findings indicate that VR may be an ideal medium to present emotional challenge and also extend the understanding of emotional (and conventional) challenge in video games.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Peng, Xiaolan and Huang, Jin and Denisova, Alena and Chen, Hui and Tian, Feng and Wang, Hongan},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {emotion, virtual reality, games, player experience, emotional challenge},
	pages = {1--13},
}

@inproceedings{correll_truncating_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Truncating the {Y}-{Axis}: {Threat} or {Menace}?},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376222},
	doi = {10.1145/3313831.3376222},
	abstract = {Bar charts with y-axes that don't begin at zero can visually exaggerate effect sizes. However, advice for whether or not to truncate the y-axis can be equivocal for other visualization types. In this paper we present examples of visualizations where this y-axis truncation can be beneficial as well as harmful, depending on the communicative and analytic intent. We also present the results of a series of crowd-sourced experiments in which we examine how y-axis truncation impacts subjective effect size across visualization types, and we explore alternative designs that more directly alert viewers to this truncation. We find that the subjective impact of axis truncation is persistent across visualizations designs, even for designs with explicit visual cues that indicate truncation has taken place. We suggest that designers consider the scale of the meaningful effect sizes and variation they intend to communicate, regardless of the visual encoding.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Correll, Michael and Bertini, Enrico and Franconeri, Steven},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {information visualization, deceptive visualization},
	pages = {1--12},
}

@inproceedings{pfau_bot_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Bot or {Not}? {User} {Perceptions} of {Player} {Substitution} with {Deep} {Player} {Behavior} {Models}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376223},
	doi = {10.1145/3313831.3376223},
	abstract = {Many online games suffer when players drop off due to lost connections or quitting prematurely, which leads to match terminations or game-play imbalances. While rule-based outcome evaluations or substitutions with bots are frequently used to mitigate such disruptions, these techniques are often perceived as unsatisfactory. Deep learning methods have successfully been used in deep player behavior modelling (DPBM) to produce non-player characters or bots which show more complex behavior patterns than those modelled using traditional AI techniques. Motivated by these findings, we present an investigation of the player-perceived awareness, believability and representativeness, when substituting disconnected players with DPBM agents in an online-multiplayer action game. Both quantitative and qualitative outcomes indicate that DPBM agent substitutes perform similarly to human players and that players were unable to detect substitutions. Notably, players were in fact able to detect substitution with agents driven by more traditional heuristics.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pfau, Johannes and Smeddinck, Jan David and Bikas, Ioannis and Malaka, Rainer},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {games, deep learning, games user research, game disruption prevention, neural networks, player modeling, player substitution},
	pages = {1--10},
}

@inproceedings{yamagami_decoding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Decoding {Intent} {With} {Control} {Theory}: {Comparing} {Muscle} {Versus} {Manual} {Interface} {Performance}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376224},
	doi = {10.1145/3313831.3376224},
	abstract = {Manual device interaction requires precise coordination which may be difficult for users with motor impairments. Muscle interfaces provide alternative interaction methods that may enhance performance, but have not yet been evaluated for simple (eg. mouse tracking) and complex (eg. driving) continuous tasks. Control theory enables us to probe continuous task performance by separating user input into intent and error correction to quantify how motor impairments impact device interaction. We compared the effectiveness of a manual versus a muscle interface for eleven users without and three users with motor impairments performing continuous tasks. Both user groups preferred and performed better with the muscle versus the manual interface for the complex continuous task. These results suggest muscle interfaces and algorithms that can detect and augment user intent may be especially useful for future design of interfaces for continuous tasks.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yamagami, Momona and Steele, Katherine M. and Burden, Samuel A.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, interaction, control theory, electromyography, motor impairments, muscle interfaces, user intent},
	pages = {1--12},
}

@inproceedings{storer_all_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{All} in the {Same} {Boat}": {Tradeoffs} of {Voice} {Assistant} {Ownership} for {Mixed}-{Visual}-{Ability} {Families}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376225},
	doi = {10.1145/3313831.3376225},
	abstract = {A growing body of evidence suggests Voice Assistants (VAs) are highly valued by people with vision impairments (PWVI) and much less so by sighted users. Yet, many are deployed in homes where both PWVI and sighted family members reside. Researchers have yet to study whether VA use and perceived benefits are affected in settings where one person has a visual impairment and others do not. We conducted six in-depth interviews with partners to understand patterns of domestic VA use in mixed-visual-ability families. Although PWVI were more motivated to acquire VAs, used them more frequently, and learned more proactively about their features, partners with vision identified similar benefits and disadvantages of having VAs in their home. We found that the universal usability of VAs both equalizes experience across abilities and presents complex tradeoffs for families-regarding interpersonal relationships, domestic labor, and physical safety-which are weighed against accessibility benefits for PWVI and complicate the decision to fully integrate VAs in the home.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Storer, Kevin M. and Judge, Tejinder K. and Branham, Stacy M.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {home, universal usability, mixed-visual-ability settings, vision impairment, voice assistant},
	pages = {1--14},
}

@inproceedings{weitekamp_unfabricate_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Unfabricate: {Designing} {Smart} {Textiles} for {Disassembly}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376227},
	doi = {10.1145/3313831.3376227},
	abstract = {Smart textiles development is combining computing and textile technologies to create tactile, functional objects such as smart garments, soft medical devices, and space suits. However, the field also combines the massive waste streams of both the digital electronics and textiles industries. The following work explores how HCI researchers might be poised to address sustainability and waste in future smart textiles development through interventions at design time. Specifically, we perform a design inquiry into techniques and practices for reclaiming and reusing smart textiles materials and explore how such techniques can be integrated into smart textiles design tools. Beginning with a practice in sustainable or "slow" fashion, unravelling a garment into yarn, the suite of explorations titled "Unfabricate" probes values of time and labor in crafting a garment; speculates how a smart textile garment may be designed with reuse in mind; and imagines how electronic and textile components may be given new life in novel uses.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Weitekamp, Daniel and Harpstead, Erik and Koedinger, Ken R. and Wu, Shanel and Devendorf, Laura},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {smart textiles, computer-aided design, weaving, sustainability, disassembly, knitting, unraveling},
	pages = {1--14},
}

@inproceedings{hsieh_bridging_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Bridging the {Virtual} and {Real} {Worlds}: {A} {Preliminary} {Study} of {Messaging} {Notifications} in {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376228},
	doi = {10.1145/3313831.3376228},
	abstract = {Virtual reality (VR) platforms provide their users with immersive virtual environments, but disconnect them from real-world events. The increasing length of VR sessions can therefore be expected to boost users' needs to obtain information about external occurrences such as message arrival. Yet, how and when to present these real-world notifications to users engaged in VR activities remains underexplored. We conducted an experiment to investigate individuals' receptivity during four VR activities (Loading, 360 Video, Treasure Hunt, Rhythm Game) to message notifications delivered using three types of displays (head-mounted, controller, and movable panel). While higher engagement generally led to higher perceptions that notifications were ill-timed and/or disruptive, the suitability of notification displays to VR activities was influenced by the time-sensitiveness of VR content, overlapping use of modalities for delivering alerts, the display locations, and a requirement that the display be moved for notifications to be seen. Specific design suggestions are also provided.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hsieh, Ching-Yu and Chiang, Yi-Shyuan and Chiu, Hung-Yu and Chang, Yung-Ju},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, eye-tracking, notification systems, interruptibility, receptivity},
	pages = {1--14},
}

@inproceedings{saxena_human-centered_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {Human}-{Centered} {Review} of {Algorithms} {Used} within the {U}.{S}. {Child} {Welfare} {System}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376229},
	doi = {10.1145/3313831.3376229},
	abstract = {The U.S. Child Welfare System (CWS) is charged with improving outcomes for foster youth; yet, they are overburdened and underfunded. To overcome this limitation, several states have turned towards algorithmic decision-making systems to reduce costs and determine better processes for improving CWS outcomes. Using a human-centered algorithmic design approach, we synthesize 50 peer-reviewed publications on computational systems used in CWS to assess how they were being developed, common characteristics of predictors used, as well as the target outcomes. We found that most of the literature has focused on risk assessment models but does not consider theoretical approaches (e.g., child-foster parent matching) nor the perspectives of caseworkers (e.g., case notes). Therefore, future algorithms should strive to be context-aware and theoretically robust by incorporating salient factors identified by past research. We provide the HCI community with research avenues for developing human-centered algorithms that redirect attention towards more equitable outcomes for CWS.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Saxena, Devansh and Badillo-Urquiola, Karla and Wisniewski, Pamela J. and Guha, Shion},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {algorithmic decision-making, child welfare system, human-centered algorithm design},
	pages = {1--15},
}

@inproceedings{joshi_micromentor_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{MicroMentor}: {Peer}-to-{Peer} {Software} {Help} {Sessions} in {Three} {Minutes} or {Less}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376230},
	doi = {10.1145/3313831.3376230},
	abstract = {While synchronous one-on-one help for software learning is rich and valuable, it can be difficult to find and connect with someone who can provide assistance. Through a formative user study, we explore the idea of fixed-duration, one-on-one help sessions and find that 3 minutes is often enough time for novice users to explain their problem and receive meaningful help from an expert. To facilitate this type of interaction, we developed MicroMentor, an on-demand help system that connects users via video chat for 3-minute help sessions. MicroMentor automatically attaches relevant supplementary materials and uses contextual information, such as command history and expertise, to encourage the most qualified users to accept incoming requests. These help sessions are recorded and archived, building a bank of knowledge that can further help a broader audience. Through a user study, we find MicroMentor to be useful and successful in connecting users for short teaching moments.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Joshi, Nikhita and Matejka, Justin and Anderson, Fraser and Grossman, Tovi and Fitzmaurice, George},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {mentoring, one-on-one help, quick help, software learning},
	pages = {1--13},
}

@inproceedings{jung_search_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {In {Search} of {Forms} for {Evocative} and {Generative} {Reflection}: {Exploratory} {Studies} and a {Design} {Proposal}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376231},
	doi = {10.1145/3313831.3376231},
	abstract = {Today an increasing number of personal informatics tools and platforms support intended behavior change and goal achievement through data-based self-reflection. The scope of self-reflection expands with emerging sources, goals, and challenges of human well-being, demanding for reframing recent computer-mediated reflective practice. This study investigates a broader range of contexts and forms of self-reflection that support navigating one's mind and goals beyond achieving preset goals. This paper describes contemporary issues on human well-being and two exploratory studies-one conducted in a traveling artists' residency and the other in a design studio class-which surveyed various triggers, contexts, and forms of self-reflection. By connecting the insights from the two studies, I propose evocative and generative reflection as an alternative perspective to tracking-based, goal-oriented reflection and discuss implications for the design for reflection with a focus on the creative dimension of human well-being.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jung, Heekyoung},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {reflection, creativity, well-being, reflective forms},
	pages = {1--13},
}

@inproceedings{epstein_will_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Will the {Crowd} {Game} the {Algorithm}? {Using} {Layperson} {Judgments} to {Combat} {Misinformation} on {Social} {Media} by {Downranking} {Distrusted} {Sources}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376232},
	doi = {10.1145/3313831.3376232},
	abstract = {How can social media platforms fight the spread of misinformation? One possibility is to use newsfeed algorithms to downrank content from sources that users rate as untrustworthy. But will laypeople be handicapped by motivated reasoning or lack of expertise, and thus unable to identify misinformation sites? And will they "game" this crowdsourcing mechanism in order to promote content that aligns with their partisan agendas? We conducted a survey experiment in which =984 Americans indicated their trust in numerous news sites. To study the tendency of people to game the system, half of the participants were told their responses would inform social media ranking algorithms. Participants trusted mainstream sources much more than hyper-partisan or fake news sources, and their ratings were highly correlated with professional fact-checker judgments. Critically, informing participants that their responses would influence ranking algorithms did not diminish these results, despite the manipulation increasing the political polarization of trust ratings.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Epstein, Ziv and Pennycook, Gordon and Rand, David},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {social media, crowdsourcing, misinformation},
	pages = {1--11},
}

@inproceedings{zhu_bishare_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{BISHARE}: {Exploring} {Bidirectional} {Interactions} {Between} {Smartphones} and {Head}-{Mounted} {Augmented} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376233},
	doi = {10.1145/3313831.3376233},
	abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Fengyuan and Grossman, Tovi},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {augmented reality, smartphones, cross-device computing, mixed-reality computing},
	pages = {1--14},
}

@inproceedings{park_magtouch_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{MagTouch}: {Robust} {Finger} {Identification} for a {Smartwatch} {Using} a {Magnet} {Ring} and a {Built}-in {Magnetometer}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376234},
	doi = {10.1145/3313831.3376234},
	abstract = {Completing tasks on smartwatches often requires multiple gestures due to the small size of the touchscreens and the lack of sufficient number of touch controls that are easily accessible with a finger. We propose to increase the number of functions that can be triggered with the touch gesture by enabling a smartwatch to identify which finger is being used. We developed MagTouch, a method that uses a magnetometer embedded in an off-the-shelf smartwatch. It measures the magnetic field of a magnet fixed to a ring worn on the middle finger. By combining the measured magnetic field and the touch location on the screen, MagTouch recognizes which finger is being used. The tests demonstrated that MagTouch can differentiate among the three fingers used to make contacts at a success rate of 95.03\%.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Park, Keunwoo and Kim, Daehwa and Heo, Seongkook and Lee, Geehyuk},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {touch, smartwatch, finger identification, magnetic},
	pages = {1--13},
}

@inproceedings{zhang_teddy_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Teddy: {A} {System} for {Interactive} {Review} {Analysis}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376235},
	doi = {10.1145/3313831.3376235},
	abstract = {Reviews are integral to e-commerce services and products. They contain a wealth of information about the opinions and experiences of users, which can help better understand consumer decisions and improve user experience with products and services. Today, data scientists analyze reviews by developing rules and models to extract, aggregate, and understand information embedded in the review text. However, working with thousands of reviews, which are typically noisy incomplete text, can be daunting without proper tools. Here we first contribute results from an interview study that we conducted with fifteen data scientists who work with review text, providing insights into their practices and challenges. Results suggest data scientists need interactive systems for many review analysis tasks. Towards a solution, we then introduce Teddy, an interactive system that enables data scientists to quickly obtain insights from reviews and improve their extraction and modeling pipelines.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Xiong and Engel, Jonathan and Evensen, Sara and Li, Yuliang and Demiralp, Çağatay and Tan, Wang-Chiew},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {data science, visualization, contextual interviews, interactive systems, review analysis, schema generation, sentiment analysis, text mining},
	pages = {1--13},
}

@inproceedings{olwal_e-textile_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {E-{Textile} {Microinteractions}: {Augmenting} {Twist} with {Flick}, {Slide} and {Grasp} {Gestures} for {Soft} {Electronics}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376236},
	doi = {10.1145/3313831.3376236},
	abstract = {E-textile microinteractions advance cord-based interfaces by enabling the simultaneous use of precise continuous control and casual discrete gestures. We leverage the recently introduced I/O Braid sensing architecture to enable a series of user studies and experiments which help design suitable interactions and a real-time gesture recognition pipeline. Informed by a gesture elicitation study with 36 participants, we developed a user-dependent classifier for eight discrete gestures with 94\% accuracy for 12 participants. In a formal evaluation we show that we can enable precise manipulation with the same architecture. Our quantitative targeting experiment suggests that twisting is faster than existing headphone button controls and is comparable in speed to a capacitive touch surface. Qualitative interview feedback indicates a preference for I/O Braid's interaction over that of in-line headphone controls. Our applications demonstrate how continuous and discrete gestures can be combined to form new, integrated e-textile microinteraction techniques for real-time continuous control, discrete actions and mode switching.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Olwal, Alex and Starner, Thad and Mainini, Gowa},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {wearables, e-textile, electronic textile, gestures, interactive fabric, microinteractions, smart textile, soft electronics},
	pages = {1--13},
}

@inproceedings{di_bartolomeo_evaluating_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Evaluating the {Effect} of {Timeline} {Shape} on {Visualization} {Task} {Performance}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376237},
	doi = {10.1145/3313831.3376237},
	abstract = {Timelines are commonly represented on a horizontal line, which is not necessarily the most effective way to visualize temporal event sequences. However, few experiments have evaluated how timeline shape influences task performance. We present the design and results of a controlled experiment run on Amazon Mechanical Turk (n=192) in which we evaluate how timeline shape affects task completion time, correctness, and user preference. We tested 12 combinations of 4 shapes — horizontal line, vertical line, circle, and spiral — and 3 data types — recurrent, non-recurrent, and mixed event sequences. We found good evidence that timeline shape meaningfully affects user task completion time but not correctness and that users have a strong shape preference. Building on our results, we present design guidelines for creating effective timeline visualizations based on user task and data types. A free copy of this paper, the evaluation stimuli and data, and code are available https://osf.io/qr5yu/},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Di Bartolomeo, Sara and Pandey, Aditeya and Leventidis, Aristotelis and Saffo, David and Syeda, Uzma Haque and Carstensdottir, Elin and Seif El-Nasr, Magy and Borkin, Michelle A. and Dunne, Cody},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {information visualization, controlled experiments, temporal event sequences, timelines},
	pages = {1--12},
}

@inproceedings{liang_oralcam_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{OralCam}: {Enabling} {Self}-{Examination} and {Awareness} of {Oral} {Health} {Using} a {Smartphone} {Camera}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376238},
	doi = {10.1145/3313831.3376238},
	abstract = {Due to a lack of medical resources or oral health awareness, oral diseases are often left unexamined and untreated, affecting a large population worldwide. With the advent of low-cost, sensor-equipped smartphones, mobile apps offer a promising possibility for promoting oral health. However, to the best of our knowledge, no mobile health (mHealth) solutions can directly support a user to self-examine their oral health condition. This paper presents OralCam, the first interactive app that enables end-users' self-examination of five common oral conditions (diseases or early disease signals) by taking smartphone photos of one's oral cavity. OralCam allows a user to annotate additional information (e.g. living habits, pain, and bleeding) to augment the input image, and presents the output hierarchically, probabilistically and with visual explanations to help a laymen user understand examination results. Developed on our in-house dataset that consists of 3,182 oral photos annotated by dental experts, our deep learning based framework achieved an average detection sensitivity of 0.787 over five conditions with high localization accuracy. In a week-long in-the-wild user study (N=18), most participants had no trouble using OralCam and interpreting the examination results. Two expert interviews further validate the feasibility of OralCam for promoting users' awareness of oral health.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liang, Yuan and Fan, Hsuan Wei and Fang, Zhujun and Miao, Leiying and Li, Wen and Zhang, Xuan and Sun, Weibin and Wang, Kun and He, Lei and Chen, Xiang 'Anthony'},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {deep learning, artificial intelligence, mobile health, oral health},
	pages = {1--13},
}

@inproceedings{silva_investigating_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Investigating the {Opportunities} for {Technologies} to {Enhance} {QoL} with {Stroke} {Survivors} and {Their} {Families}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376239},
	doi = {10.1145/3313831.3376239},
	abstract = {There are over 80 million stroke survivors globally, making it the main cause of long-term disability worldwide. Not only do the challenges associated with stroke affect the quality of life (QoL) of survivors, but also of their families. To explore these challenges and define design opportunities for technologies to improve the QoL of both stakeholders, we conducted semi-structured interviews with 10 survivors and one of their family members. We uncovered three major interlinked themes: strategies to cope with technological barriers, the (in)adequacy of assistive technologies, and limitations of the rehabilitation process. Findings highlight multiple design opportunities, including the need for meaningful patient-centered tools and methods to improve rehabilitation effectiveness, emotion-aware computing for family emotional support, and re-thinking the nature of assistive technologies to consider the perception of transitory stroke-related disabilities. We thus argue for a new class of dual-purpose technologies that fit survivors' abilities while promoting the regain of function.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Silva, Inês Santos and Guerreiro, João and Rosa, Marlene and Campos, Joana and Pascoal, Augusto Gil and Pinto, Sofia and Nicolau, Hugo},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {stroke rehabilitation, assistive technologies, quality of life},
	pages = {1--11},
}

@inproceedings{cobb_user_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {User {Experiences} with {Online} {Status} {Indicators}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376240},
	doi = {10.1145/3313831.3376240},
	abstract = {Online status indicators (OSIs) improve online communication by helping users convey and assess availability, but they also let users infer potentially sensitive information about one another. We surveyed 200 smartphone users to understand the extent to which users are aware of information shared via OSIs and the extent to which this shapes their behavior. Despite familiarity with OSIs, participants misunderstand many aspects of OSIs, and they describe carefully curating and seeking to control their self-presentation via OSIs. Some users further report leveraging OSI-conveyed information for problematic and malicious purposes. Drawing on existing constructs of app dependence (i.e., when users contort their behavior to meet an app's demands) and app enablement (i.e., when apps enable users to engage in behaviors they feel good about), we demonstrate that current OSI design patterns promote app dependence, and we call for a shift toward OSI designs that are more enabling for users.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cobb, Camille and Simko, Lucy and Kohno, Tadayoshi and Hiniker, Alexis},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, mobile apps, online status, social computing},
	pages = {1--12},
}

@inproceedings{heyer_opportunities_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Opportunities for {Enhancing} {Access} and {Efficacy} of {Peer} {Sponsorship} in {Substance} {Use} {Disorder} {Recovery}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376241},
	doi = {10.1145/3313831.3376241},
	abstract = {Substance use disorders (SUDs) are characterized by an inability to decrease a substance use (e.g., alcohol or opioids) despite negative repercussions. SUDs are clinically diagnosable, hazardous, and considered a public health issue. Sponsorship, a specialized type of peer mentorship, is vital in the recovery process and originates from 12-step fellowship programs such as Alcoholics Anonymous (AA) and Narcotics Anonymous (NA). To investigate sponsorship relationship practices and to identify design opportunities for digitally-mediated peer support, we conducted 27 in-depth interviews with members of AA and NA. We identified five key sponsorship relationship practices relevant for designing social computing tools to support sponsorship and recovery: 1) assessing dyadic compatibility, 2) managing sponsorship with or without technology, 3) establishing boundaries, 4) building a peer support network, and 5) managing anonymity. We identify social computing and digitally-mediated design opportunities and implications.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Heyer, Jeremy and Schmitt, Zachary and Dombrowski, Lynn and Yarosh, Svetlana},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {addiction, 12-step fellowships, peer health support, recovery, substance use disorders, technology for substance use},
	pages = {1--14},
}

@inproceedings{mueller_next_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Next {Steps} for {Human}-{Computer} {Integration}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376242},
	doi = {10.1145/3313831.3376242},
	abstract = {Human-Computer Integration (HInt) is an emerging paradigm in which computational and human systems are closely interwoven. Integrating computers with the human body is not new. however, we believe that with rapid technological advancements, increasing real-world deployments, and growing ethical and societal implications, it is critical to identify an agenda for future research. We present a set of challenges for HInt research, formulated over the course of a five-day workshop consisting of 29 experts who have designed, deployed and studied HInt systems. This agenda aims to guide researchers in a structured way towards a more coordinated and conscientious future of human-computer integration.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mueller, Florian Floyd and Lopes, Pedro and Strohmeier, Paul and Ju, Wendy and Seim, Caitlyn and Weigel, Martin and Nanayakkara, Suranga and Obrist, Marianna and Li, Zhuying and Delfa, Joseph and Nishida, Jun and Gerber, Elizabeth M. and Svanaes, Dag and Grudin, Jonathan and Greuter, Stefan and Kunze, Kai and Erickson, Thomas and Greenspan, Steven and Inami, Masahiko and Marshall, Joe and Reiterer, Harald and Wolf, Katrin and Meyer, Jochen and Schiphorst, Thecla and Wang, Dakuo and Maes, Pattie},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {augmentation, bodily extension, cyborg, fusion, implants, integration, symbiosis},
	pages = {1--15},
}

@inproceedings{wolf_jumpvr_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{JumpVR}: {Jump}-{Based} {Locomotion} {Augmentation} for {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376243},
	doi = {10.1145/3313831.3376243},
	abstract = {One of the great benefits of virtual reality (VR) is the implementation of features that go beyond realism. Common "unrealistic" locomotion techniques (like teleportation) can avoid spatial limitation of tracking, but minimize potential benefits of more realistic techniques (e.g. walking). As an alternative that combines realistic physical movement with hyper-realistic virtual outcome, we present JumpVR, a jump-based locomotion augmentation technique that virtually scales users' physical jumps. In a user study (N=28), we show that jumping in VR (regardless of scaling) can significantly increase presence, motivation and immersion compared to teleportation, while largely not increasing simulator sickness. Further, participants reported higher immersion and motivation for most scaled jumping variants than forward-jumping. Our work shows the feasibility and benefits of jumping in VR and explores suitable parameters for its hyper-realistic scaling. We discuss design implications for VR experiences and research.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wolf, Dennis and Rogers, Katja and Kunder, Christoph and Rukzio, Enrico},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, immersion, vr, hyper realism, jumping, super human},
	pages = {1--12},
}

@inproceedings{lee_autogain_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{AutoGain}: {Gain} {Function} {Adaptation} with {Submovement} {Efficiency} {Optimization}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376244},
	doi = {10.1145/3313831.3376244},
	abstract = {A well-designed control-to-display gain function can improve pointing performance with indirect pointing devices like trackpads. However, the design of gain functions is challenging and mostly based on trial and error. AutoGain is a novel method to individualize a gain function for indirect pointing devices in contexts where cursor trajectories can be tracked. It gradually improves pointing efficiency by using a novel submovement-level tracking+optimization technique that minimizes aiming error (undershooting/overshooting) for each submovement. We first show that AutoGain can produce, from scratch, gain functions with performance comparable to commercial designs, in less than a half-hour of active use. Second, we demonstrate AutoGain's applicability to emerging input devices (here, a Leap Motion controller) with no reference gain functions. Third, a one-month longitudinal study of normal computer use with AutoGain showed performance improvements from participants' default functions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Byungjoo and Nancel, Mathieu and Kim, Sunjun and Oulasvirta, Antti},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {pointing, cd gain functions, human performance, pointer acceleration, pointing facilitation, submovement},
	pages = {1--12},
}

@inproceedings{jensen_when_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {When the {Civic} {Turn} {Turns} {Digital}: {Designing} {Safe} and {Secure} {Refugee} {Resettlement}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376245},
	doi = {10.1145/3313831.3376245},
	abstract = {Across Europe, refugees are required to engage with the "civic turn" – a process of integrating refugees into the social and cultural aspects of the new land. Over a two-year period, we engaged 89 refugees settling in Sweden, to explore how accelerated and digitalised resettlement processes shape the civic turn. Framed within wider literature on transitioning and everyday insecurities, we show how this "digital turn" exacerbates existing barriers to resettlement experienced by refugees. By critically analysing these barriers, we reveal how the civic turn rests upon a series of everyday social and cultural practices and relations, which are largely ignored in digital service design. We show how this leads to a "vacuum" for our participants. We call on the HCI community to engage with this vacuum and understand resettlement as encompassing multiple digitally-mediated transitional phases of citizenry. We do so by focusing on the digitalisation processes shaping these transitions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jensen, Rikke Bjerg and Coles-Kemp, Lizzie and Talhouk, Reem},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {digital, everyday security, refugees, resettlement, transition},
	pages = {1--14},
}

@inproceedings{maddali_sociality_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Sociality and {Skill} {Sharing} in the {Garden}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376246},
	doi = {10.1145/3313831.3376246},
	abstract = {Gardening is an activity that involves a number of dimensions of increasing interest to HCI and CSCW researchers, including recreation, sustainability, and engagement with nature. This paper considers the garden setting in order to understand the role that collaborative and social computing technologies might play for practitioners engaging in outdoor skilled activities. We conducted participant observations with nine experienced gardeners aged 22-71 years. Through this process, we find that gardeners continuously configure their environments to accommodate their preferences for sociality. They share embodied skills and help others attune to sensory information in person, but also influence learning through the features in their garden that are observed by others. This paper provides an understanding of sociality in the garden, highlights skill sharing as a key domain for design in this space, and contributes design considerations for collaborative technologies in outdoor settings.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Maddali, Hanuma Teja and Lazar, Amanda},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {sociality, gardening, participant observation, skill sharing},
	pages = {1--13},
}

@inproceedings{dillen_keep_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Keep {Calm} and {Ride} {Along}: {Passenger} {Comfort} and {Anxiety} as {Physiological} {Responses} to {Autonomous} {Driving} {Styles}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376247},
	doi = {10.1145/3313831.3376247},
	abstract = {Autonomous vehicles have been rapidly progressing towards full autonomy using fixed driving styles, which may differ from individual passenger preferences. Violating these preferences may lead to passenger discomfort or anxiety. We studied passenger responses to different driving style parameters in a physical autonomous vehicle. We collected galvanic skin response, heart rate, and eye-movement patterns from 20 participants, along with self-reported comfort and anxiety scores. Our results show that the presence and proximity of a lead vehicle not only raised the level of all measured physiological responses, but also exaggerated the existing effect of the longitudinal acceleration and jerk parameters. Skin response was also found to be a significant predictor of passenger comfort and anxiety. By using multiple independent events to isolate different driving style parameters, we demonstrate a method to control and analyze such parameters in future studies.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dillen, Nicole and Ilievski, Marko and Law, Edith and Nacke, Lennart E. and Czarnecki, Krzysztof and Schneider, Oliver},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {affective computing, autonomous vehicles, empirical study, comfort, driving style, passengers, physiological sensing},
	pages = {1--13},
}

@inproceedings{hsu_autocomplete_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Autocomplete {Element} {Fields}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376248},
	doi = {10.1145/3313831.3376248},
	abstract = {Aggregate elements are ubiquitous in natural and man-made objects. Interactively authoring these elements with varying anisotropy and deformability can require high artistic skills and manual labor. To reduce input workload and enhance output quality, we present an autocomplete system that can help users distribute and align such elements over different domains. Through a brushing interface, users can place and mix a few elements, and let our system automatically populate more elements for the remaining output. Furthermore, aggregate elements often require proper direction/scalar fields for proper arrangements, but fully specifying such fields across entire domains can be difficult or inconvenient for ordinary users. To address this usability challenge, we formulate element fields that can smoothly orient all the elements based on partial user specifications without requiring full input fields in any step. We validate our prototype system with a pilot user study and show applications in design, collage, and modeling.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hsu, Chen-Yuan and Wei, Li-Yi and You, Lihua and Zhang, Jian Jun},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {interface, modeling, anisotropy, element, field, synthesis},
	pages = {1--13},
}

@inproceedings{wessely_sprayable_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Sprayable {User} {Interfaces}: {Prototyping} {Large}-{Scale} {Interactive} {Surfaces} with {Sensors} and {Displays}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376249},
	doi = {10.1145/3313831.3376249},
	abstract = {We present Sprayable User Interfaces: room-sized interactive surfaces that contain sensor and display elements created by airbrushing functional inks. Since airbrushing is inherently mobile, designers can create large-scale user interfaces on complex 3D geometries where existing stationary fabrication methods fail. To enable Sprayable User Interfaces, we developed a novel design and fabrication pipeline that takes a desired user interface layout as input and automatically generates stencils for airbrushing the layout onto a physical surface. After fabricating stencils from cardboard or projecting stencils digitally, designers spray each layer with an airbrush, attach a microcontroller to the user interface, and the interface is ready to be used. Our technical evaluation shows that Sprayable User Interfaces work on various geometries and surface materials, such as porous stone and rough wood. We demonstrate our system with several application examples including interactive smart home applications on a wall and a soft leather sofa, an interactive smart city application, and interactive architecture in public office spaces.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wessely, Michael and Sethapakdi, Ticha and Castillo, Carlos and Snowden, Jackson C. and Hanton, Ollie and Qamar, Isabel P. S. and Fraser, Mike and Roudaut, Anne and Mueller, Stefanie},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ubiquitous computing, fabrication, airbrush, printed electronics, spraying},
	pages = {1--12},
}

@inproceedings{kim_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding {Users}' {Perception} {Towards} {Automated} {Personality} {Detection} with {Group}-{Specific} {Behavioral} {Data}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376250},
	doi = {10.1145/3313831.3376250},
	abstract = {Thanks to advanced sensing and logging technology, automatic personality assessment (APA) with users' behavioral data in the workplace is on the rise. While previous work has focused on building APA systems with high accuracy, little research has attempted to understand users' perception towards APA systems. To fill this gap, we take a mixed-methods approach: we (1) designed a survey (n=89) to understand users'social workplace behavior both online and offline and their privacy concerns; (2) built a research probe that detects personality from online and offline data streams with up to 81.3\% accuracy, and deployed it for three weeks in Korea (n=32); and (3) conducted post-interviews (n=9). We identify privacy issues in sharing data and system-induced change in natural behavior as important design factors for APA systems. Our findings suggest that designers should consider the complex relationship between users' perception and system accuracy for a more user-centered APA design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Seoyoung and Thakur, Arti and Kim, Juho},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, user perception, behavior change, automatic personality assessment (apa), co-located group, tracking},
	pages = {1--12},
}

@inproceedings{shapiro_re-shape_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Re-{Shape}: {A} {Method} to {Teach} {Data} {Ethics} for {Data} {Science} {Education}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376251},
	doi = {10.1145/3313831.3376251},
	abstract = {Data has become central to the technologies and services that human-computer interaction (HCI) designers make, and the ethical use of data in and through these technologies should be given critical attention throughout the design process. However, there is little research on ethics education in computer science that explicitly addresses data ethics. We present and analyze Re-Shape, a method to teach students about the ethical implications of data collection and use. Re-Shape, as part of an educational environment, builds upon the idea of cultivating care and allows students to collect, process, and visualize their physical movement data in ways that support critical reflection and coordinated classroom activities about data, data privacy, and human-centered systems for data science. We also use a case study of Re-Shape in an undergraduate computer science course to explore prospects and limitations of instructional designs and educational technology such as Re-Shape that leverage personal data to teach data ethics.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Shapiro, Ben Rydal and Meng, Amanda and O'Donnell, Cody and Lou, Charlotte and Zhao, Edwin and Dankwa, Bianca and Hostetler, Andrew},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {information visualization, data literacy, care ethics, computer science education, data ethics, data privacy, data science education, interaction geography slicer, re-shape},
	pages = {1--13},
}

@inproceedings{kang_armath_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{ARMath}: {Augmenting} {Everyday} {Life} with {Math} {Learning}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376252},
	doi = {10.1145/3313831.3376252},
	abstract = {We introduce ARMath, a mobile Augmented Reality (AR) system that allows ch ildren to discover mathematical concepts in familiar, ord inary objects and engage with math problems in meaningful contexts. Leveraging advanced computer vision, ARMath recognizes everyday objects, visualizes their mathematical attributes, and turns them into tangible or virtual manipulatives. Using the manipulatives, children can solve problems that situate math operations or concepts in specific everyday contexts. Informed by four participatory design sessions with teachers and children, we developed five ARMath modules to support basic arithmetic and 2D geometry. We also conducted an exploratory evaluation of ARMath with 27 children (ages 5-8) at a local children's museum. Our findings demonstrate how ARMath engages children in math learning, how failures in AI can be used as learning opportunities, and challenges that children face when using ARMath.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kang, Seokbin and Shokeen, Ekta and Byrne, Virginia L. and Norooz, Leyla and Bonsignore, Elizabeth and Williams-Pierce, Caro and Froehlich, Jon E.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {learning, augmented reality, human-ai interaction},
	pages = {1--15},
}

@inproceedings{maayan_how_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {How {Domain} {Experts} {Create} {Conceptual} {Diagrams} and {Implications} for {Tool} {Design}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376253},
	doi = {10.1145/3313831.3376253},
	abstract = {Conceptual diagrams are used extensively to understand abstract relationships, explain complex ideas, and solve difficult problems. To illustrate concepts effectively, experts find appropriate visual representations and translate concepts into concrete shapes. This translation step is not supported explicitly by current diagramming tools. This paper investigates how domain experts create conceptual diagrams via semi-structured interviews with 18 participants from diverse backgrounds. Our participants create, adapt, and reuse visual representations using both sketches and digital tools. However, they had trouble using current diagramming tools to transition from sketches and reuse components from earlier diagrams. Our participants also expressed frustration with the slow feedback cycles and barriers to automation of their tools. Based on these results, we suggest four opportunities of diagramming tools — exploration support, representation salience, live engagement, and vocabulary correspondence — that together enable a natural diagramming experience. Finally, we discuss possibilities to leverage recent research advances to develop natural diagramming tools.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ma'ayan, Dor and Ni, Wode and Ye, Katherine and Kulkarni, Chinmay and Sunshine, Joshua},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {information visualization, conceptual diagramming, diagram authoring},
	pages = {1--14},
}

@inproceedings{jardine_experience_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {Experience} of {Guided} {Online} {Therapy}: {A} {Longitudinal}, {Qualitative} {Analysis} of {Client} {Feedback} in a {Naturalistic} {RCT}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376254},
	doi = {10.1145/3313831.3376254},
	abstract = {Internet-delivered Cognitive Behavioural Therapy (iCBT) is an effective treatment for depression and anxiety disorders. However longitudinal qualitative research into the client's subjective experience of this form of treatment ?in the wild' is relatively scarce. We present an analysis of secondary outcomes in a naturalistic RCT conducted within the UK's Improving Access to Psychological Therapies programme. We evaluated clients' expectations, experience, and context of usage of iCBT, across three timepoints. Results are discussed in terms of the creation of a therapeutic space online, the impact of hope, expectations and personal factors on the therapeutic experience, iCBT as "therapy on the go" and developing skills for life. While iCBT on the whole provides a positive, supportive and therapeutic experience for clients, the study identified managing expectations, polarized preferences, momentary help-seeking and long-term support as important aspects of the experience to consider in future design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jardine, Jacinta and Earley, Caroline and Richards, Derek and Timulak, Ladislav and Palacios, Jorge E. and Duffy, Daniel and Tierney, Karen and Doherty, Gavin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {user experience, mental health, icbt, longitudinal study},
	pages = {1--15},
}

@inproceedings{tabassum_smart_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Smart {Home} {Beyond} the {Home}: {A} {Case} for {Community}-{Based} {Access} {Control}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376255},
	doi = {10.1145/3313831.3376255},
	abstract = {As smart devices are becoming commonplace in homes, we need to explore the needs of not just the residents of the home, but also of secondary stakeholders who may be granted access to these devices from outside of the home. We conducted a mixed methods study, which included a survey of 163 smart home device owners and a follow-up interview with 13 individuals who currently share their smart home devices with others outside of their home. Nearly half (47.8\%) of our survey participants shared at least one smart home device with someone that did not live with them. Individuals sought greater safety and security by providing remote access to trusted family members or friends. By understanding users' perspectives about privacy and trust in relation to sharing smart home devices beyond the home, we build a case for community-based access control of smart home devices in the Internet of Things.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tabassum, Madiha and Kropczynski, Jess and Wisniewski, Pamela and Lipford, Heather Richter},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {community, smart home, access control},
	pages = {1--12},
}

@inproceedings{michael_race_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Race {Yourselves}: {A} {Longitudinal} {Exploration} of {Self}-{Competition} {Between} {Past}, {Present}, and {Future} {Performances} in a {VR} {Exergame}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376256},
	doi = {10.1145/3313831.3376256},
	abstract = {Participating in competitive races can be a thrilling experience for athletes, involving a rush of excitement and sensations of flow, achievement, and self-fulfilment. However, for non-athletes, the prospect of competition is often a scary one which affects intrinsic motivation negatively, especially for less fit, less competitive individuals. We propose a novel method making the positive racing experience accessible to non-athletes using a high-intensity cycling VR exergame: by recording and replaying all their previous gameplay sessions simultaneously, including a projected future performance, players can race against a crowd of "ghost" avatars representing their individual fitness journey. The experience stays relevant and exciting as every race adds a new competitor. A longitudinal study over four weeks and a cross-sectional study found that the new method improves physical performance, intrinsic motivation, and flow compared to a non-competitive exergame. Additionally, the longitudinal study provides insights into the longer-term effects of VR exergames.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Michael, Alexander and Lutteroth, Christof},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {exergame, intrinsic motivation, ghosts, longitudinal, performance, self-competition, virtual reality (vr)},
	pages = {1--17},
}

@inproceedings{mallari_i_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Do {I} {Look} {Like} a {Criminal}? {Examining} {How} {Race} {Presentation} {Impacts} {Human} {Judgement} of {Recidivism}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376257},
	doi = {10.1145/3313831.3376257},
	abstract = {Understanding how racial information impacts human decision making in online systems is critical in today's world. Prior work revealed that race information of criminal defendants, when presented as a text field, had no significant impact on users' judgements of recidivism. We replicated and extended this work to explore how and when race information influences users' judgements, with respect to the saliency of presentation. Our results showed that adding photos to the race labels had a significant impact on recidivism predictions for users who identified as female, but not for those who identified as male. The race of the defendant also impacted these results, with black defendants being less likely to be predicted to recidivate compared to white defendants. These results have strong implications for how system-designers choose to display race information, and cautions researchers to be aware of gender and race effects when using Amazon Mechanical Turk workers.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mallari, Keri and Inkpen, Kori and Johns, Paul and Tan, Sarah and Ramesh, Divya and Kamar, Ece},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {gender, bias, crowd work, human-ai collaboration, legal, mechanical turk, race, recidivism},
	pages = {1--13},
}

@inproceedings{lin_it_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {It {Is} {Your} {Turn}: {Collaborative} {Ideation} {With} a {Co}-{Creative} {Robot} through {Sketch}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376258},
	doi = {10.1145/3313831.3376258},
	abstract = {Co-creative systems have been widely explored in the field of computational creativity. However, existing AI partners of these systems are mostly virtual agents. As sketching on paper with embodied robots could be more engaging for designers' early-stage ideation and collaborative practices, we envision the possibility of Cobbie, a mobile robot that ideates iteratively with designers by generating creative and diverse sketches. To evaluate the differences in co-creativity and user experience between the co-creative robots and virtual agents, we conducted a comparative experiment and analyzed the data collected from quantitative scales, observation, and semi-structured interview. The results reveal that Cobbie is more satisfying in motivating exploration, provoking unexpected ideas and engaging designers in the collaborative ideation process. Based on these findings, we discussed the prospects of co-creative robots for future developments of human-AI collaborative systems.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lin, Yuyu and Guo, Jiahao and Chen, Yang and Yao, Cheng and Ying, Fangtian},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ideation, human-ai collaboration, co-creative system, creative robot, early-stage design},
	pages = {1--14},
}

@inproceedings{dogar_missit_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{MissIt}: {Using} {Missed} {Calls} for {Free}, {Extremely} {Low} {Bit}-{Rate} {Communication} in {Developing} {Regions}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376259},
	doi = {10.1145/3313831.3376259},
	abstract = {Mobile devices have become the primary mode for Internet access in developing countries. Yet typical data plans and SMS costs can be overwhelming for low income users in these countries. In this paper, we explore the design and usability of a free but extremely low bit rate communication channel to address this challenge. We propose, a data communication channel that uses to transmit messages between phones, thereby sacrificing performance in exchange for low cost. While the data rate of is extremely low (\&lt;1 bps), our prototype implementation and small scale user studies explore the feasibility of this idea for different types of messaging scenarios. Our results show that could be a viable option for messaging scenarios that require short, pre-determined responses (e.g., survey questions) while for traditional SMS-style messaging, a suitable user interface and other customizations are likely required to make it a viable option for users.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dogar, Fahad R. and Qazi, Ihsan Ayyub and Tariq, Ali Raza and Murtaza, Ghulam and Ahmad, Abeer and Stocking, Nathan},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ictd, missed-calls, networks},
	pages = {1--12},
}

@inproceedings{alexandrovsky_examining_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Examining {Design} {Choices} of {Questionnaires} in {VR} {User} {Studies}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376260},
	doi = {10.1145/3313831.3376260},
	abstract = {Questionnaires are among the most common research tools in virtual reality (VR) user studies. Transitioning from virtuality to reality for giving self-reports on VR experiences can lead to systematic biases. VR allows to embed questionnaires into the virtual environment which may ease participation and avoid biases. To provide a cohesive picture of methods and design choices for questionnaires in VR (inVRQ), we discuss 15 inVRQ studies from the literature and present a survey with 67 VR experts from academia and industry. Based on the outcomes, we conducted two user studies in which we tested different presentation and interaction methods of inVRQs and evaluated the usability and practicality of our design. We observed comparable completion times between inVRQs and questionnaires outside VR (nonVRQs) with higher enjoyment but lower usability for inVRQs. These findings advocate the application of inVRQs and provide an overview of methods and considerations that lay the groundwork for inVRQ design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Alexandrovsky, Dmitry and Putze, Susanne and Bonfert, Michael and Höffner, Sebastian and Michelmann, Pitt and Wenig, Dirk and Malaka, Rainer and Smeddinck, Jan David},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, user studies, research methods, vr, in-vr questionnaires, invrqs},
	pages = {1--21},
}

@inproceedings{liebling_unmet_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Unmet {Needs} and {Opportunities} for {Mobile} {Translation} {AI}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376261},
	doi = {10.1145/3313831.3376261},
	abstract = {Translation apps and devices are often presented in the context of providing assistance while traveling abroad. However, the spectrum of needs for cross-language communication is much wider. To investigate these needs, we conducted three studies with populations spanning socioeconomic status and geographic regions: (1) United States-based travelers, (2) migrant workers in India, and (3) immigrant populations in the United States. We compare frequent travelers' perception and actual translation needs with those of the two migrant communities. The latter two, with low language proficiency, have the greatest translation needs to navigate their daily lives. However, current mobile translation apps do not meet these needs. Our findings provide new insights on the usage practices and limitations of mobile translation tools. Finally, we propose design implications to help apps better serve these unmet needs.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liebling, Daniel J. and Lahav, Michal and Evans, Abigail and Donsbach, Aaron and Holbrook, Jess and Smus, Boris and Boran, Lindsey},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {immigrants, speech, mobile, emerging markets, machine translation, migrants},
	pages = {1--13},
}

@inproceedings{liao_button_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Button {Simulation} and {Design} via {FDVV} {Models}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376262},
	doi = {10.1145/3313831.3376262},
	abstract = {Designing a push-button with desired sensation and performance is challenging because the mechanical construction must have the right response characteristics. Physical simulation of a button's force-displacement (FD) response has been studied to facilitate prototyping; however, the simulations' scope and realism have been limited. In this paper, we extend FD modeling to include vibration (V) and velocity-dependence characteristics (V). The resulting FDVV models better capture tactility characteristics of buttons, including snap. They increase the range of simulated buttons and the perceived realism relative to FD models. The paper also demonstrates methods for obtaining these models, editing them, and simulating accordingly. This end-to-end approach enables the analysis, prototyping, and optimization of buttons, and supports exploring designs that would be hard to implement mechanically.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Liao, Yi-Chi and Kim, Sunjun and Lee, Byungjoo and Oulasvirta, Antti},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {simulation, haptic, modeling, button, fd model, fdvv model, force feedback, haptic rendering, input device, tactility, vibration},
	pages = {1--14},
}

@inproceedings{lu_exploring_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Exploring {Visual} {Information} {Flows} in {Infographics}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376263},
	doi = {10.1145/3313831.3376263},
	abstract = {Infographics are engaging visual representations that tell an informative story using a fusion of data and graphical elements. The large variety of infographic design poses a challenge for their high-level analysis. We use the concept of Visual Information Flow (VIF), which is the underlying semantic structure that links graphical elements to convey the information and story to the user. To explore VIF, we collected a repository of over 13K infographics. We use a deep neural network to identify visual elements related to information, agnostic to their various artistic appearances. We construct the VIF by automatically chaining these visual elements together based on Gestalt principles. Using this analysis, we characterize the VIF design space by a taxonomy of 12 different design patterns. Exploring in a real-world infographic dataset, we discuss the design space and potentials of VIF in light of this taxonomy.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lu, Min and Wang, Chufeng and Lanir, Joel and Zhao, Nanxuan and Pfister, Hanspeter and Cohen-Or, Daniel and Huang, Hui},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {design analysis, infographics, visual information flow},
	pages = {1--12},
}

@inproceedings{seymour_informing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Informing the {Design} of {Privacy}-{Empowering} {Tools} for the {Connected} {Home}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376264},
	doi = {10.1145/3313831.3376264},
	abstract = {Connected devices in the home represent a potentially grave new privacy threat due to their unfettered access to the most personal spaces in people's lives. Prior work has shown that despite concerns about such devices, people often lack sufficient awareness, understanding, or means of taking effective action. To explore the potential for new tools that support such needs directly we developed Aretha, a privacy assistant technology probe that combines a network disaggregator, personal tutor, and firewall, to empower end-users with both the knowledge and mechanisms to control disclosures from their homes. We deployed Aretha in three households over six weeks, with the aim of understanding how this combination of capabilities might enable users to gain awareness of data disclosures by their devices, form educated privacy preferences, and to block unwanted data flows. The probe, with its novel affordances-and its limitations-prompted users to co-adapt, finding new control mechanisms and suggesting new approaches to address the challenge of regaining privacy in the connected home.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Seymour, William and Kraemer, Martin J. and Binns, Reuben and Van Kleek, Max},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {network disaggregator, privacy-empowering technology, technology probe},
	pages = {1--14},
}

@inproceedings{gerling_virtual_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Virtual {Reality} {Games} for {People} {Using} {Wheelchairs}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376265},
	doi = {10.1145/3313831.3376265},
	abstract = {Virtual Reality (VR) holds the promise of providing engaging embodied experiences, but little is known about how people with disabilities engage with it. We explore challenges and opportunities of VR gaming for wheelchair users. First, we present findings from a survey that received 25 responses and gives insights into wheelchair users' motives to (non-) engage with VR and their experiences. Drawing from this survey, we derive design implications which we tested through implementation and qualitative evaluation of three full-body VR game prototypes with 18 participants. Our results show that VR gaming engages wheelchair users, though nuanced consideration is required for the design of embodied immersive experiences for minority bodies, and we illustrate how designers can create meaningful, positive experiences.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gerling, Kathrin and Dickinson, Patrick and Hicks, Kieran and Mason, Liam and Simeone, Adalberto L. and Spiel, Katta},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, accessibility, games},
	pages = {1--11},
}

@inproceedings{kurzhals_view_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {View} on the {Viewer}: {Gaze}-{Adaptive} {Captions} for {Videos}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376266},
	doi = {10.1145/3313831.3376266},
	abstract = {Subtitles play a crucial role in cross-lingual distribution of multimedia content and help communicate information where auditory content is not feasible (loud environments, hearing impairments, unknown languages). Established methods utilize text at the bottom of the screen, which may distract from the video. Alternative techniques place captions closer to related content (e.g., faces) but are not applicable to arbitrary videos such as documentations. Hence, we propose to leverage live gaze as indirect input method to adapt captions to individual viewing behavior. We implemented two gaze-adaptive methods and compared them in a user study (n=54) to traditional captions and audio-only videos. The results show that viewers with less experience with captions prefer our gaze-adaptive methods as they assist them in reading. Furthermore, gaze distributions resulting from our methods are closer to natural viewing behavior compared to the traditional approach. Based on these results, we provide design implications for gaze-adaptive captions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kurzhals, Kuno and Göbel, Fabian and Angerbauer, Katrin and Sedlmair, Michael and Raubal, Martin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {eye tracking, gaze input, gaze-responsive display, multimedia, subtitles, video captions},
	pages = {1--12},
}

@inproceedings{tigwell_emoji_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Emoji {Accessibility} for {Visually} {Impaired} {People}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376267},
	doi = {10.1145/3313831.3376267},
	abstract = {Emoji are graphical symbols that appear in many aspects of our lives. Worldwide, around 36 million people are blind and 217 million have a moderate to severe visual impairment. This portion of the population may use and encounter emoji, yet it is unclear what accessibility challenges emoji introduce. We first conducted an online survey with 58 visually impaired participants to understand how they use and encounter emoji online, and the challenges they experience. We then conducted 11 interviews with screen reader users to understand more about the challenges reported in our survey findings. Our interview findings demonstrate that technology is both an enabler and a barrier, emoji descriptors can hinder communication, and therefore the use of emoji impacts social interaction. Using our findings from both studies, we propose best practice when using emoji and recommendations to improve the future accessibility of emoji for visually impaired people.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tigwell, Garreth W. and Gorman, Benjamin M. and Menzies, Rachel},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, visual impairments, cmc, emoji},
	pages = {1--14},
}

@inproceedings{turmo_vidal_bodylights_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{BodyLights}: {Open}-{Ended} {Augmented} {Feedback} to {Support} {Training} {Towards} a {Correct} {Exercise} {Execution}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376268},
	doi = {10.1145/3313831.3376268},
	abstract = {Technologies targeting a correct execution of physical training exercises typically use pre-determined models for what they consider correct, automatizing instruction and feedback. This falls short on catering to diverse trainees and exercises. We explore an alternative design approach, in which technology provides open-ended feedback for trainers and trainees to use during training. With a personal trainer we designed the augmentation of 18 strength training exercises with BodyLights: 3D printed wearable projecting lights that augment body movement and orientation. To study them, 15 trainees at different skill levels trained three times with our personal trainer and BodyLights. Our findings show that BodyLights catered to a wide range of trainees and exercises, and supported understanding, executing and correcting diverse technique parameters. We discuss design features and methodological aspects that allowed this; and what open-ended feedback offered in comparison to current technology approaches to support training towards a correct exercise execution.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Turmo Vidal, Laia and Zhu, Hui and Riego-Delgado, Abraham},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {wearables, activity design, augmented feedback, correct performance, physical training, rtd, strength training},
	pages = {1--14},
}

@inproceedings{shahmiri_sharc_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{ShArc}: {A} {Geometric} {Technique} for {Multi}-{Bend}/{Shape} {Sensing}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376269},
	doi = {10.1145/3313831.3376269},
	abstract = {We present ShArc, a precision, geometric measurement technique for building multi-bend/shape sensors. ShArc sensors are made from flexible strips that can be dynamically formed into complex curves in a plane. They measure local curvature by noting the relative shift between the inner and outer layers of the sensor at many points and model shape as a series of connected arcs. Unlike jointed systems where angular errors sum with each joint measured, ShArc sensors do not accumulate angular error as more measurement points are added. This allows for inexpensive, robust sensors that can accurately model curves with multiple bends. To demonstrate the efficacy of this technique, we developed a capacitive ShArc sensor and evaluated its performance. We conclude with examples of how ShArc sensors can be employed in applications like gesture input devices, user interface controllers, human motion tracking and angular measurement of free-form objects.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Shahmiri, Fereshteh and Dietz, Paul H.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {bend, capacitive, multi-bend, sensor, shape, sharc},
	pages = {1--12},
}

@inproceedings{metatla_robots_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Robots for {Inclusive} {Play}: {Co}-{Designing} an {Educational} {Game} {With} {Visually} {Impaired} and {Sighted} {Children}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376270},
	doi = {10.1145/3313831.3376270},
	abstract = {Despite being included in mainstream schools, visually impaired children still face barriers to social engagement and participation. Games could potentially help, but games that cater for both visually impaired and sighted players are scarce. We used a co-design approach to design and evaluate a robot-based educational game that could be inclusive of both visually impaired and sighted children in the context of mainstream education. We ran a focus group discussion with visual impairment educators to understand barriers to inclusive play. And then a series of co-design workshops to engage visually impaired and sighted children and educators in learning about robot technology and exploring its potential to support inclusive play experiences. We present design guidelines and an evaluation workshop of a game prototype, demonstrating group dynamics conducive to collaborative learning experiences, including shared goal setting/execution, closely coupled division of labour, and interaction symmetry.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Metatla, Oussama and Bardot, Sandra and Cullen, Clare and Serrano, Marcos and Jouffrais, Christophe},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {co-design, education, games, inclusion, visual impairment},
	pages = {1--13},
}

@inproceedings{wang_cheat_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Cheat {Sheets} for {Data} {Visualization} {Techniques}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376271},
	doi = {10.1145/3313831.3376271},
	abstract = {This paper introduces the concept of 'cheat sheets' for data visualization techniques, a set of concise graphical explanations and textual annotations inspired by infographics, data comics, and cheat sheets in other domains. Cheat sheets aim to address the increasing need for accessible material that supports a wide audience in understanding data visualization techniques, their use, their fallacies and so forth. We have carried out an iterative design process with practitioners, teachers and students of data science and visualization, resulting six types of cheat sheet (anatomy, construction, visual patterns, pitfalls, false-friends and well-known relatives) for six types of visualization, and formats for presentation. We assess these with a qualitative user study using 11 participants that demonstrates the readability and usefulness of our cheat sheets.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zezhong and Sundin, Lovisa and Murray-Rust, Dave and Bach, Benjamin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {cheat sheet, visualization literacy},
	pages = {1--13},
}

@inproceedings{sheshadri_learn_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Learn with {Haptics}: {Improving} {Vocabulary} {Recall} with {Free}-{Form} {Digital} {Annotation} on {Touchscreen} {Mobiles}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376272},
	doi = {10.1145/3313831.3376272},
	abstract = {Mobile vocabulary learning interfaces typically present material only in auditory and visual channels, underutilizing the haptic modality. We explored haptic-integrated learning by adding free-form digital annotation to mobile vocabulary learning interfaces. Through a series of pilot studies, we identified three design factors: annotation mode, presentation sequence, and vibrotactile feedback, that influence recall in haptic-integrated vocabulary interfaces. These factors were then evaluated in a within-subject comparative study using a digital flashcard interface as baseline. Results using a 84-item vocabulary showed that the 'whole word' annotation mode is highly effective, yielding a 24.21\% increase in immediate recall scores and a 30.36\% increase in the 7-day delayed scores. Effects of presentation sequence and vibrotactile feedback were more transient; they affected the results of immediate tests, but not the delayed tests. We discuss the implications of these factors for designing future mobile learning applications.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sheshadri, Smitha and Zhao, Shengdong and Chen, Yang and Fjeld, Morten},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {haptics for learning, intersensory reinforced learning, mobile vocabulary learning, motoric engagement, multimodal learning},
	pages = {1--13},
}

@inproceedings{kurze_guess_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Guess the {Data}: {Data} {Work} to {Understand} {How} {People} {Make} {Sense} of and {Use} {Simple} {Sensor} {Data} from {Homes}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376273},
	doi = {10.1145/3313831.3376273},
	abstract = {Simple smart home sensors, e.g. for temperature or light, increasingly collect seemingly inconspicuous data. Prior work has shown that human sensemaking of such sensor data can reveal domestic activities. Such sensemaking presents an opportunity to empower people to understand the implications of simple smart home sensors. To investigate, we developed and field-tested the Guess the Data method, which enabled people to use and make sense of live data from their homes and to collectively interpret and reflect on anonymized data from the homes in our study. Our findings show how participants reconstruct behavior, both individually and collectively, expose the sensitive personal data of others, and use sensor data as evidence and for lateral surveillance within the household. We discuss the potential of our method as a participatory HCI method for investigating design of the IoT and implications created by doing data work on home sensors.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kurze, Albrecht and Bischof, Andreas and Totzauer, Sören and Storz, Michael and Eibl, Maximilian and Brereton, Margot and Berger, Arne},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, internet of things, smart home, iot, data work, networked sensing systems, personal data, sensor data},
	pages = {1--12},
}

@inproceedings{wang_please_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Please {Call} the {Specialism}: {Using} {WeChat} to {Support} {Patient} {Care} in {China}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376274},
	doi = {10.1145/3313831.3376274},
	abstract = {We examine how WeChat has been adopted to support nurse-patient communication in an IVF clinic in China. In this setting, the biggest challenge to delivering high-quality patient-centred care is the large number of patients. Nurses typically spend less than five minutes with each patient during clinical visits. To compensate for such minimal in-person consultation, nurse-facilitated patient groups were created on WeChat, to extend medical care and facilitate peer support. Through an ethnographic study, we examined how these groups fit into the clinic's communication ecosystem, and the challenges they raise for nurse-facilitators who receive thousands of messages daily. We propose a set of design suggestions aiming to make the work of the nurse-facilitator easier and more effective. In highlighting the opportunities and challenges of using chat to extend care beyond the clinic, we contribute to a burgeoning discussion of how chat can support patient care in the Global South.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Ding and Kale, Santosh D. and O'Neill, Jacki},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ethnography, healthcare, chat apps, wechat, nurse-patient communication, peer support},
	pages = {1--13},
}

@inproceedings{dove_monsters_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Monsters, {Metaphors}, and {Machine} {Learning}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376275},
	doi = {10.1145/3313831.3376275},
	abstract = {Machine learning (ML) poses complex challenges for user experience (UX) designers. Typically unpredictable and opaque, it may produce unforeseen outcomes detrimental to particular groups or individuals, yet simultaneously promise amazing breakthroughs in areas as diverse as medical diagnosis and universal translation. This results in a polarized view of ML, which is often manifested through a technology-as-monster metaphor. In this paper, we acknowledge the power and potential of this metaphor by resurfacing historic complexities in human-monster relations. We (re)introduce these liminal and ambiguous creatures, and discuss their relation to ML. We offer a background to designers' use of metaphor, and show how the technology-as-monster metaphor can generatively probe and (re)frame the questions ML poses. We illustrate the effectiveness of this approach through a detailed discussion of an early-stage generative design workshop inquiring into ML approaches to supporting student mental health and well-being.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dove, Graham and Fayard, Anne-Laure},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {machine learning, generative metaphor, monster theory, ux design},
	pages = {1--17},
}

@inproceedings{madaio_collective_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Collective {Support} and {Independent} {Learning} with a {Voice}-{Based} {Literacy} {Technology} in {Rural} {Communities}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376276},
	doi = {10.1145/3313831.3376276},
	abstract = {Access to literacy is critical to children's futures, but formal education may be insufficient for fostering early literacy, especially in low-resource contexts. Educational technologies used at home may be able to help, but it is unclear whether or how children (and families) will use such technologies at home in rural communities, particularly in low-literate families. In this paper, we investigate these questions with a voice-based literacy technology deployed with families in 8 rural communities in Côte d'Ivoire for 4 months. We use interviews and observations with 37 families to investigate motivations, methods, and barriers for rural families' engagement with a literacy technology accessible via feature phones. We contribute insights into how families view digital literacy as a learning goal, leverage networks of supporters, and over time, transition from explicit to implicit support for children's learning.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Madaio, Michael A. and Yarzebinski, Evelyn and Kamath, Vikram and Zinszer, Benjamin D. and Hannon-Cropp, Joelle and Tanoh, Fabrice and Akpe, Yapo Hermann and Seri, Axel Blahoua and Jasińska, Kaja K. and Ogan, Amy},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ictd, hci4d, ivr, educational technology, literacy},
	pages = {1--14},
}

@inproceedings{an_ta_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {TA} {Framework}: {Designing} {Real}-{Time} {Teaching} {Augmentation} for {K}-12 {Classrooms}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376277},
	doi = {10.1145/3313831.3376277},
	abstract = {Recently, the HCI community has seen increased interest in the design of teaching augmentation (TA): tools that extend and complement teachers' pedagogical abilities during ongoing classroom activities. Examples of TA systems are emerging across multiple disciplines, taking various forms: e.g., ambient displays, wearables, or learning analytics dashboards. However, these diverse examples have not been analyzed together to derive more fundamental insights into the design of teaching augmentation. Addressing this opportunity, we broadly synthesize existing cases to propose the TA framework. Our framework specifies a rich design space in five dimensions, to support the design and analysis of teaching augmentation. We contextualize the framework using existing designs cases, to surface underlying design trade-offs: for example, balancing actionability of presented information with teachers' needs for professional autonomy, or balancing unobtrusiveness with informativeness in the design of TA systems. Applying the TA framework, we identify opportunities for future research and design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {An, Pengcheng and Holstein, Kenneth and d'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {classroom, ambient intelligence, augmented intelligence, dashboards, k-12, orchestration, teacher},
	pages = {1--17},
}

@inproceedings{chapko_we_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{We} {Have} {Been} {Magnified} for {Years} - {Now} {You} {Are} under the {Microscope}!": {Co}-{Researchers} with {Learning} {Disabilities} {Created} an {Online} {Survey} to {Challenge} {Public} {Understanding} of {Learning} {Disabilities}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376278},
	doi = {10.1145/3313831.3376278},
	abstract = {Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chapko, Dorota and Frumiento, Pino and Edwards, Nalini and Emeh, Lizzie and Kennedy, Donald and McNicholas, David and Overton, Michaela and Snead, Mark and Steward, Robyn and Sutton, Jenny M. and Jeffreys, Evie and Long, Catherine and Croll-Knight, Jess and Connors, Ben and Castell-Ward, Sam and Coke, David and McPeake, Bethany and Renel, William and McGinley, Chris and Remington, Anna and Whittuck, Dora and Kieffer, John and Ewans, Sarah and Williams, Mark and Grierson, Mick},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {survey, design, disability, video, attitudes, participatory/inclusive research},
	pages = {1--17},
}

@inproceedings{stewart_beyond_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Beyond {Team} {Makeup}: {Diversity} in {Teams} {Predicts} {Valued} {Outcomes} in {Computer}-{Mediated} {Collaborations}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376279},
	doi = {10.1145/3313831.3376279},
	abstract = {In an increasingly globalized and service-oriented economy, people need to engage in computer-mediated collaborative problem solving (CPS) with diverse teams. However, teams routinely fail to live up to expectations, showcasing the need for technologies that help develop effective collaboration skills. We take a step in this direction by investigating how different dimensions of team diversity (demographic, personality, attitudes towards teamwork, prior domain experience) predict objective (e.g. effective solutions) and subjective (e.g. positive perceptions) collaborative outcomes. We collected data from 96 triads who engaged in a 30-minute CPS task via videoconferencing. We found that demographic diversity and differing attitudes towards teamwork predicted impressions of positive engagement, while personality diversity predicted learning outcomes. Importantly, these relationships were maintained after accounting for team makeup. None of the diversity measures predicted task performance. We discuss how our findings can be incorporated into technologies that aim to help diverse teams develop CPS skills.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Stewart, Angela E.B. and Amon, Mary Jean and Duran, Nicholas D. and D'Mello, Sidney K.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {diversity, collaborative problem solving, learning technologies, team makeup},
	pages = {1--13},
}

@inproceedings{kim_defining_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Defining {Haptic} {Experience}: {Foundations} for {Understanding}, {Communicating}, and {Evaluating} {HX}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376280},
	doi = {10.1145/3313831.3376280},
	abstract = {Haptic technology is maturing, with expectations and evidence that it will contribute to user experience (UX). However, we have very little understanding about how haptic technology can influence people's experience. Researchers and designers need a way to understand, communicate, and evaluate haptic technology's effect on UX. From a literature review and two studies - one with haptics novices, the other with expert hapticians - we developed a theoretical model of the factors that constitute a good haptic experience (HX). We define HX and propose its constituent factors: design parameters of Timeliness, Density, Intensity, and Timbre; the cross-cutting concern of Personalization; usability requirements of Utility, Causality, Consistency, and Saliency; and experiential factors of Harmony, Expressivity, Autotelics, Immersion, and Realism as guiding constructs important for haptic experience. This model will help guide design and research of haptic systems, inform language around haptics, and provide the basis for evaluative instruments, such as checklists, heuristics, or questionnaires.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Erin and Schneider, Oliver},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {user experience, haptics, design, scale development, vibrotactile},
	pages = {1--13},
}

@inproceedings{li_maravis_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{MaraVis}: {Representation} and {Coordinated} {Intervention} of {Medical} {Encounters} in {Urban} {Marathon}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376281},
	doi = {10.1145/3313831.3376281},
	abstract = {There is an increased use of Internet-of-Things and wearable sensing devices in the urban marathon to ensure effective response to unforeseen medical needs. However, the massive amount of real-time, heterogeneous movement and psychological data of runners impose great challenges on prompt medical incident analysis and intervention. Conventional approaches compile such data into one dashboard visualization to facilitate rapid data absorption but fail to support joint decision-making and operations in medical encounters. In this paper, we present MaraVis, a real-time urban marathon visualization and coordinated intervention system. It first visually summarizes real-time marathon data to facilitate the detection and exploration of possible anomalous events. Then, it calculates an optimal camera route with an arrangement of shots to guide offline effort to catch these events in time with a smooth view transition. We conduct a within-subjects study with two baseline systems to assess the efficacy of MaraVis.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Quan and Lin, Huanbin and Wei, Xiguang and Huang, Yangkun and Fan, Lixin and Du, Jian and Ma, Xiaojuan and Chen, Tianjian},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {anomaly detection, marathon visualization, shot chaining},
	pages = {1--12},
}

@inproceedings{blank_emotional_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Emotional {Footprints} of {Email} {Interruptions}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376282},
	doi = {10.1145/3313831.3376282},
	abstract = {Working in an environment with constant interruptions is known to affect stress, but how do interruptions affect emotional expression? Emotional expression can have significant impact on interactions among coworkers. We analyzed the video of 26 participants who performed an essay task in a laboratory while receiving either continual email interruptions or receiving a single batch of email. Facial videos of the participants were run through a convolutional neural network to determine the emotional mix via decoding of facial expressions. Using a novel co-occurrence matrix analysis, we showed that with batched email, a neutral emotional state is dominant with sadness being a distant second, and with continual interruptions, this pattern is reversed, and sadness is mixed with fear. We discuss the implications of these results for how interruptions can impact employees' well-being and organizational climate.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Blank, Christopher and Zaman, Shaila and Wesley, Amanveer and Tsiamyrtzis, Panagiotis and Da Cunha Silva, Dennis R. and Gutierrez-Osuna, Ricardo and Mark, Gloria and Pavlidis, Ioannis},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {convolutional neural network, emotions, co-occurence matrix, email interruptions, facial expressions},
	pages = {1--12},
}

@inproceedings{morales-martinez_nationality_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Nationality and {Gender} {Biases} in {Multicultural} {Online} {Learning} {Environments}: {The} {Effects} of {Anonymity}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376283},
	doi = {10.1145/3313831.3376283},
	abstract = {Online learning environments eliminate geographical barriers and enable new forms of collaboration between students at large scale. Self-presentation within such environments affects how students interact with learning content and with each other. We explore how anonymity/identifiability in user profile design impacts student interactions in a large multicultural classroom across two geographical locations. After triangulating 150,000 online interactions with questionnaires and focus groups, we provide three major findings. First, being identifiable had a significant impact on how students accessed and rated content created by their peers. Second, when identifiable, cultural differences became more prominent, leading some students to avoid content created by classmates of certain nationalities. Finally, when students interacted with their real identities, there were significant and negative gender effects which were absent when students were anonymous. These findings contribute to our understanding of social dynamics within multicultural learning environments, and raise practical implications for tool design.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Morales-Martinez, Gabriela and Latreille, Paul and Denny, Paul},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {online education, anonymity, computer-mediated communication, gender bias, identity, nationality bias, oles, online learning environments, peer ratings, peerwise, vles},
	pages = {1--14},
}

@inproceedings{abdulgalimov_designing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Designing for {Employee} {Voice}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376284},
	doi = {10.1145/3313831.3376284},
	abstract = {Employee voice and workplace democracy have a positive impact on employee wellbeing and the performance of organizations. In this paper, we conducted interviews with employees to identify facilitators and inhibitors for voice within the workplace and a corresponding set of appropriate qualities: Civility, Validity, Safety and Egalitarianism. We then operationalised these qualities as a set of design goals - Assured Anonymity, Constructive Moderation, Adequate Slowness and Controlled Access - in the design and development of a secure anonymous employee voice system. Our novel take on the Enterprise Social Network aims to foster good citizenship whilst also promoting frank yet constructive discussion. We reflect on a two-week deployment of our system, the diverse range of candid discussions that emerged around important workplace issues and the potential for change within the host organization. We conclude by reflecting on the ways in which our approach shaped discourse and supported the creation of a trusted environment for employee voice.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Abdulgalimov, Dinislam and Kirkham, Reuben and Nicholson, James and Vlachokyriakos, Vasilis and Briggs, Pam and Olivier, Patrick},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {workplace, anonymous online communities, cscw, employee voice, enterprise social networks},
	pages = {1--13},
}

@inproceedings{pilzer_supporting_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Supporting {Software} {Developers}' {Focused} {Work} on {Window}-{Based} {Desktops}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376285},
	doi = {10.1145/3313831.3376285},
	abstract = {Software developers, like other information workers, continuously switch tasks and applications to complete their work on their computer. Given the high fragmentation and complexity of their work, staying focused on the relevant pieces of information can become quite challenging in today's window-based environments, especially with the ever increasing monitor screen-size. To support developers in staying focused, we conducted a formative study with 18 professionals in which we examined their computer based and eye-gaze interaction with the window environment and devised a relevance model of open windows. Based on the results, we developed a prototype to dim irrelevant windows and reduce distractions, and evaluated it in a user study. Our results indicate that our model was able to predict relevant open windows with high accuracy and participants felt that integrating visual prominence into the desktop environment reduces clutter and distraction, which results in reduced window switching and an increase in focus.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pilzer, Jan and Rosenast, Raphael and Meyer, André N. and Huang, Elaine M. and Fritz, Thomas},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {focus, productivity, user interfaces, window management, window relevance},
	pages = {1--13},
}

@inproceedings{wang_movevr_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{MoveVR}: {Enabling} {Multiform} {Force} {Feedback} in {Virtual} {Reality} {Using} {Household} {Cleaning} {Robot}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376286},
	doi = {10.1145/3313831.3376286},
	abstract = {Haptic feedback can significantly enhance the realism and immersiveness of virtual reality (VR) systems. In this paper, we propose MoveVR, a technique that enables realistic, multiform force feedback in VR leveraging commonplace cleaning robots. MoveVR can generate tension, resistance, impact and material rigidity force feedback with multiple levels of force intensity and directions. This is achieved by changing the robot's moving speed, rotation, position as well as the carried proxies. We demonstrated the feasibility and effectiveness of MoveVR through interactive VR gaming. In our quantitative and qualitative evaluation studies, participants found that MoveVR provides more realistic and enjoyable user experience when compared to commercially available haptic solutions such as vibrotactile haptic systems.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Yuntao and Chen, Zichao (Tyson) and Li, Hanchuan and Cao, Zhengyi and Luo, Huiyi and Zhang, Tengxiang and Ou, Ke and Raiti, John and Yu, Chun and Patel, Shwetak and Shi, Yuanchun},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, human-robot interaction, vr, haptic feedback, force feedback, cleaning robot, robotics},
	pages = {1--12},
}

@inproceedings{nouwens_between_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Between {Scripts} and {Applications}: {Computational} {Media} for the {Frontier} of {Nanoscience}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376287},
	doi = {10.1145/3313831.3376287},
	abstract = {The popularity of computational notebooks heralds a return of software as computational media rather than turn-key applications. We believe this software model has potential beyond supporting just the computationally literate. We studied a biomolecular nano-design lab that works on a current frontier of science - RNA origami - whose researchers depend on computational tools to do their work, yet are not trained as programmers. Using a participatory design process, we developed a computational labbook to concretise what computational media could look like, using the principles of computability, malleability, shareability, and distributability suggested by previous work. We used this prototype to co-reflect with the nanoscientists about how it could transform their practice. We report on the computational culture specific to this research area; the scientists' struggles managing their computational environments; and their subsequent disempowerment yet dependence. Lastly, we discuss the generative potential and limitations of the four design principles for the future of computational media.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Nouwens, Midas and Borowski, Marcel and Fog, Bjarke and Klokmose, Clemens Nylandsted},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {participatory design, computational media, computational notebook, electronic laboratory notebook},
	pages = {1--13},
}

@inproceedings{davis_brainsourcing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Brainsourcing: {Crowdsourcing} {Recognition} {Tasks} via {Collaborative} {Brain}-{Computer} {Interfacing}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376288},
	doi = {10.1145/3313831.3376288},
	abstract = {This paper introduces brainsourcing: utilizing brain responses of a group of human contributors each performing a recognition task to determine classes of stimuli. We investigate to what extent it is possible to infer reliable class labels using data collected utilizing electroencephalography (EEG) from participants given a set of common stimuli. An experiment (N=30) measuring EEG responses to visual features of faces (gender, hair color, age, smile) revealed an improved F1 score of 0.94 for a crowd of twelve participants compared to an F1 score of 0.67 derived from individual participants and a random chance of 0.50. Our results demonstrate the methodological and pragmatic feasibility of brainsourcing in labeling tasks and opens avenues for more general applications using brain-computer interfacing in a crowdsourced setting.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Davis, Keith M. and Kangassalo, Lauri and Spapé, Michiel and Ruotsalo, Tuukka},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {crowdsourcing, brain-computer interfaces, brainsourcing},
	pages = {1--14},
}

@inproceedings{mohr_mixed_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Mixed {Reality} {Light} {Fields} for {Interactive} {Remote} {Assistance}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376289},
	doi = {10.1145/3313831.3376289},
	abstract = {Remote assistance represents an important use case for mixed reality. With the rise of handheld and wearable devices, remote assistance has become practical in the wild. However, spontaneous provisioning of remote assistance requires an easy, fast and robust approach for capturing and sharing of unprepared environments. In this work, we make a case for utilizing interactive light fields for remote assistance. We demonstrate the advantages of object representation using light fields over conventional geometric reconstruction. Moreover, we introduce an interaction method for quickly annotating light fields in 3D space without requiring surface geometry to anchor annotations. We present results from a user study demonstrating the effectiveness of our interaction techniques, and we provide feedback on the usability of our overall system.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mohr, Peter and Mori, Shohei and Langlotz, Tobias and Thomas, Bruce H. and Schmalstieg, Dieter and Kalkofen, Denis},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {interaction, augmented reality, mixed reality, remote assistance, 3d user interfaces, annotations, light field, telepresence},
	pages = {1--12},
}

@inproceedings{schaekermann_expert_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Expert {Discussions} {Improve} {Comprehension} of {Difficult} {Cases} in {Medical} {Image} {Assessment}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376290},
	doi = {10.1145/3313831.3376290},
	abstract = {Medical data labeling workflows critically depend on accurate assessments from human experts. Yet human assessments can vary markedly, even among medical experts. Prior research has demonstrated benefits of labeler training on performance. Here we utilized two types of labeler training feedback: highlighting incorrect labels for difficult cases ("individual performance" feedback), and expert discussions from adjudication of these cases. We presented ten generalist eye care professionals with either individual performance alone, or individual performance and expert discussions from specialists. Compared to performance feedback alone, seeing expert discussions significantly improved generalists' understanding of the rationale behind the correct diagnosis while motivating changes in their own labeling approach; and also significantly improved average accuracy on one of four pathologies in a held-out test set. This work suggests that image adjudication may provide benefits beyond developing trusted consensus labels, and that exposure to specialist discussions can be an effective training intervention for medical diagnosis.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Schaekermann, Mike and Cai, Carrie J. and Huang, Abigail E. and Sayres, Rory},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {adjudication, diagnosis, labeler training, medical images},
	pages = {1--13},
}

@inproceedings{baykal_collaborative_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Collaborative {Technologies} for {Children} with {Special} {Needs}: {A} {Systematic} {Literature} {Review}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376291},
	doi = {10.1145/3313831.3376291},
	abstract = {This paper presents a systematic literature review on collaborative technologies for children with special needs in ACM Digital Library. The aim of the review is to (1) reveal the current state of the art, (2) identify the types of technologies and contexts of use, the demographics and special needs of the target group, and the methodological approaches and theoretical groundings, and (3) define a future research agenda. The results of the systematic literature review show that collaborative technologies for children with special needs are increasingly gaining attention, mostly involve tangible and/or embodied interaction, and are often developed for use in the classroom. The target group that is most represented are boys between 6 to 12 years with Autism Spectrum Disorder. The results further show a wide range of evaluation criteria for measuring collaboration, an interchanging use of theoretical concepts and a lack of definitions for the concept collaboration, and a need for more demographically diverse studies.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Baykal, Gökçe Elif and Van Mechelen, Maarten and Eriksson, Eva},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {collaboration, collaborative learning, cci, collaborative technologies, special need, systematic literature review},
	pages = {1--13},
}

@inproceedings{wang_miniature_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Miniature {Haptics}: {Experiencing} {Haptic} {Feedback} through {Hand}-{Based} and {Embodied} {Avatars}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376292},
	doi = {10.1145/3313831.3376292},
	abstract = {We present Miniature Haptics, a new approach to providing realistic haptic experiences by applying miniaturized haptic feedback to hand-based, embodied avatars. By shrinking haptics to a much smaller scale, Miniature Haptics enables the exploration of new haptic experiences that are not practical to create at the full, human-body scale. Using Finger Walking in Place (FWIP) as an example avatar embodiment and control method, we first explored the feasibility of Miniature Haptics then conducted a human factors study to understand how people map their full-body skeletal model to their hands. To understand the user experience of Miniature Haptic, we developed a miniature football haptic display, and results from our user study show that Miniature Haptics significantly improved the realism and enjoyment of the experience and is preferred by users (p \&lt; 0.05). In addition, we present two miniature motion platforms supporting the haptic experiences of: 1) rapidly changing ground height for platform jumping games such as Super Mario Bros and 2) changing terrain slope. Overall, Miniature Haptics makes it possible to explore novel haptic experiences that have not been practical before.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Bo-Xiang and Wang, Yu-Wei and Chen, Yen-Kai and Tseng, Chun-Miao and Hsu, Min-Chien and Hsieh, Cheng An and Lee, Hsin-Ying and Chen, Mike Y.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {haptics, embodied avatar, embodiment illusion, finger walking},
	pages = {1--8},
}

@inproceedings{fan_digital_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Digital {Juries}: {A} {Civics}-{Oriented} {Approach} to {Platform} {Governance}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376293},
	doi = {10.1145/3313831.3376293},
	abstract = {As concerns have grown regarding harmful content spread on social media, platform mechanisms for content moderation have become increasingly significant. However, many existing platform governance structures lack formal processes for democratic participation by users of the platform. Drawing inspiration from constitutional jury trials in many legal systems, this paper proposes digital juries as a civics-oriented approach for adjudicating content moderation cases. Building on existing theoretical models of jury decision-making, we outline a 5-stage model characterizing the space of design considerations in a digital jury process. We implement two examples of jury designs involving blind-voting and deliberation. From users who participate in our jury implementations, we gather informed judgments of the democratic legitimacy of a jury process for content moderation. We find that digital juries are perceived as more procedurally just than existing common platform moderation practices, but also find disagreement over whether jury decisions should be enforced or used as recommendations.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fan, Jenny and Zhang, Amy X.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {social media, governance, civics, content moderation, democracy, institutional design, juries, online speech, platforms},
	pages = {1--14},
}

@inproceedings{mustafa_patriarchy_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Patriarchy, {Maternal} {Health} and {Spiritual} {Healing}: {Designing} {Maternal} {Health} {Interventions} in {Pakistan}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376294},
	doi = {10.1145/3313831.3376294},
	abstract = {We examine the opportunities and challenges in designing for maternal health in low-income, low-resource communities in patriarchal and religious contexts. Pakistan faces a crisis in maternal health with a maternal mortality ratio of 178 deaths per 100,000 live births, as compared to the developed-country average of just 12 deaths per 100,000. Through a 6-month long qualitative, empirical study we examine the prevalent beliefs and practices around maternal health in Pakistan, the access women have to health-care, the existing religious practices that influence them and the agency they exert in their own health-care decision making. We reveal the rampant misinformation among mothers and health workers, house-hold power dynamics that impact maternal health and the deep link between maternal health and religious beliefs. We also show how current maternal health care interventions fit poorly into this context and discuss alternate design recommendations for meeting the maternal health needs of these women.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mustafa, Maryam and Batool, Amna and Fatima, Beenish and Nawaz, Fareeda and Toyama, Kentaro and Raza, Agha Ali},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {hci4d, maternal health, patriarchy},
	pages = {1--13},
}

@inproceedings{gadiraju_brailleblocks_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{BrailleBlocks}: {Computational} {Braille} {Toys} for {Collaborative} {Learning}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376295},
	doi = {10.1145/3313831.3376295},
	abstract = {Braille literacy has fallen in recent years, and many blind children now grow up without learning Braille. However, learning Braille can increase employment chances and improve literacy skills. We introduce BrailleBlocks, a system to help visually impaired children learn and practice Braille alongside a sighted parent. BrailleBlocks comprises a set of tangible blocks and pegs, each block representing a Braille cell, and an associated application with games. The system automatically tracks and recognizes the blocks so that parents can follow along even if they cannot read Braille. We conducted a user study to test BrailleBlocks with five families, with five parents and six visually impaired children. The contributions of this work are a novel approach to Braille education toys, observations of how visually impaired children and sighted parents used this system together, their insights on current issues with Braille educational tools, and actionable feedback for future Braille-based learning tools.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gadiraju, Vinitha and Muehlbradt, Annika and Kane, Shaun K.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {children, accessibility, education, collaboration, blind, braille, visually impaired},
	pages = {1--12},
}

@inproceedings{henderson_investigating_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Investigating the {Necessity} of {Delay} in {Marking} {Menu} {Invocation}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376296},
	doi = {10.1145/3313831.3376296},
	abstract = {Delayed display of menu items is a core design component of marking menus, arguably to prevent visual distraction and foster the use of mark mode. We investigate these assumptions, by contrasting the original marking menu design with immediately-displayed marking menus. In three controlled experiments, we fail to reveal obvious and systematic performance or usability advantages to using delay and mark mode. Only in very constrained settings – after significant training and only two items to learn – did traditional marking menus show a time improvement of about 260 ms. Otherwise, we found an overall decrease in performance with delay, whether participants exhibited practiced or unpracticed behaviour. Our final study failed to demonstrate that an immediately-displayed menu interface is more visually disrupting than a delayed menu. These findings inform the costs and benefits of incorporating delay in marking menus, and motivate guidelines for situations in which its use is desirable.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Henderson, Jay and Malacria, Sylvain and Nancel, Mathieu and Lank, Edward},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {delay, marking menu},
	pages = {1--13},
}

@inproceedings{li_gotree_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{GoTree}: {A} {Grammar} of {Tree} {Visualizations}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376297},
	doi = {10.1145/3313831.3376297},
	abstract = {We present GoTree, a declarative grammar allowing users to instantiate tree visualizations by specifying three aspects: visual elements, layout, and coordinate system. Within the set of all possible tree visualization techniques, we identify a subset of techniques that are both "unit-decomposable" and "axis-decomposable" (terms we define). For tree visualizations within this subset, GoTree gives the user flexible and fine-grained control over the parameters of the techniques, supporting both explicit and implicit tree visualizations. We developed Tree Illustrator, an interactive authoring tool based on GoTree grammar. Tree Illustrator allows users to create a considerable number of tree visualizations, including not only existing techniques but also undiscovered and hybrid visualizations. We demonstrate the expressiveness and generative power of GoTree with a gallery of examples and conduct a qualitative study to validate the usability of Tree Illustrator.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Li, Guozheng and Tian, Min and Xu, Qinmei and McGuffin, Michael J. and Yuan, Xiaoru},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {"tree visualization, authoring tool, declarative grammar, hierarchical data visualization"},
	pages = {1--13},
}

@inproceedings{reynolds_measuring_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Measuring {Identity} {Confusion} with {Uniform} {Resource} {Locators}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376298},
	doi = {10.1145/3313831.3376298},
	abstract = {Uniform Resource Locators (URLs) unambiguously specify host identity on the web. URLs are syntactically complex, and although software can accurately parse identity from URLs, users are frequently exposed to URLs and expected to do the same. Unfortunately, incorrect assessment of identity from a URL can expose users to attacks, such as typosquatting and phishing. Our work studies how well users can correctly determine the host identity of real URLs from common services and obfuscated "look-alike" URLs. We observe that participants employ a wide range of URL parsing strategies, and can identify real URLs 93\% of time. However, only 40\% of obfuscated URLs were identified correctly. These mistakes highlighted several ways in which URLs were confusing to users and why their existing URL parsing strategies fall short. We conclude with future research directions for reliably conveying website identity to users.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Reynolds, Joshua and Kumar, Deepak and Ma, Zane and Subramanian, Rohan and Wu, Meishan and Shelton, Martin and Mason, Joshua and Stark, Emily and Bailey, Michael},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {usable security, phishing, url readability, authentication, server identity, url},
	pages = {1--12},
}

@inproceedings{pradhan_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding {Older} {Adults}' {Participation} in {Design} {Workshops}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376299},
	doi = {10.1145/3313831.3376299},
	abstract = {Design workshops are a popular means of including older adults in technology development. However, there are open questions around how to best scaffold this participation, particularly in supporting older adults to associate their designs with themselves, rather than designing for an "other older adult." By conducting workshops focusing on envisioning the future of internet of things (IoT) technologies at home, we provide an understanding of how older individuals participate in group activities to conceptualize technology for themselves. We find that at different stages of the design process, individuals shift in who they envision the end user of the technology: at first, they think about common older adult needs, then turn to designing for themselves. Individuals' attitudes towards technology also impact group dynamics along with final design ideas. Our discussion contributes to an understanding of how to support older adults in designing for themselves, new perspectives on aging-in-place technologies, and recommendations for configuring design workshops with older individuals.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pradhan, Alisha and Jelen, Ben and Siek, Katie A. and Chan, Joel and Lazar, Amanda},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {co-design, participatory design, older adults, iot, design workshops},
	pages = {1--15},
}

@inproceedings{fu_is_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Is {Too} {Much} {System} {Caution} {Counterproductive}? {Effects} of {Varying} {Sensitivity} and {Automation} {Levels} in {Vehicle} {Collision} {Avoidance} {Systems}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376300},
	doi = {10.1145/3313831.3376300},
	abstract = {Autonomous vehicle system performance is limited by uncertainties inherent in the driving environment and challenges in processing sensor data. Engineers thus face the design decision of biasing systems toward lower sensitivity to potential threats (more misses) or higher sensitivity (more false alarms). We explored this problem for Automatic Emergency Braking systems in Level 3 autonomous vehicles, where the driver is required to monitor the system for failures. Participants (N=48) drove through a simulated suburban environment and experienced detection misses, perfect performance, or false alarms. We found that driver vigilance was greater for less-sensitive braking systems, resulting in improved performance during a potentially fatal failure. In addition, regardless of system bias, greater levels of autonomy resulted in significantly worse driver performance. Our results demonstrate that accounting for the effects of system bias on driver vigilance and performance will be critical design considerations as vehicle autonomy levels increase.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Fu, Ernestine and Johns, Mishel and Hyde, David A. B. and Sibi, Srinath and Fischer, Martin and Sirkin, David},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {autonomous vehicles, simulation, automated emergency braking, controlled experiment, human machine interaction},
	pages = {1--13},
}

@inproceedings{yang_re-examining_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Re-{Examining} {Whether}, {Why}, and {How} {Human}-{AI} {Interaction} {Is} {Uniquely} {Difficult} to {Design}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376301},
	doi = {10.1145/3313831.3376301},
	abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Qian and Steinfeld, Aaron and Rosé, Carolyn and Zimmerman, John},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {sketching, user experience, prototyping, artificial intelligence},
	pages = {1--13},
}

@inproceedings{dylan_designing_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Designing {IoT} {Resources} to {Support} {Outdoor} {Play} for {Children}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376302},
	doi = {10.1145/3313831.3376302},
	abstract = {We describe a Research-through-Design (RtD) project that explores the Internet of Things (IoT) as a resource for children's free play outdoors. Based on initial insights from a design ethnography, we developed four RtD prototypes for social play in different scenarios of use outdoors, including congregating on a street or in a park to play physical games with IoT. We observed these prototypes in use by children in their free play in two community settings, and report on the qualitative analysis of our fieldwork. Our findings highlight the designs' material qualities that encouraged social and physical play under certain conditions, suggesting social affordances that are central to the success of IoT designs for free play outdoors. We provide directions for future research that addresses the challenges faced when deploying IoT with children, contributing new considerations for interaction design with children in outdoor settings and free play contexts.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dylan, Thomas and Wood, Gavin and Durrant, Abigail C. and Vines, John and Torres, Pablo E. and Ulrich, Philip I. N. and Cukurova, Mutlu and Carr, Amanda and Çerçi, Sena and Lawson, Shaun},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {children, internet of things, digital playing out, free play, outdoor play, pervasive play},
	pages = {1--12},
}

@inproceedings{strandholt_knock_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Knock on {Wood}: {Combining} {Redirected} {Touching} and {Physical} {Props} for {Tool}-{Based} {Interaction} in {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376303},
	doi = {10.1145/3313831.3376303},
	abstract = {When physical props serve as proxies for virtual tools used to manipulate the virtual environment, it is challenging to provide appropriate haptic feedback. Redirected tool-mediated manipulation addresses this challenge by distorting the mapping between physical and virtual tools to provide a sensation of manipulating the virtual environment, when the physical tool comes into contact with another physical prop. For example, a virtual hammer's position can be offset to ensure that physical impacts accompany each strike of a virtual nail. We demonstrate the idea by showing that it can be used to create sensations of impact and resistance when driving a virtual nail into a surface, when tightening a virtual screw, and when sawing through a virtual plank. The results of a user study indicate that the proposed approach is perceived as more realistic than interaction with a single physical prop or controller and no notable detriments to precision were observed.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Strandholt, Patrick L. and Dogaru, Oana A. and Nilsson, Niels C. and Nordahl, Rolf and Serafin, Stefania},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, passive haptics, redirected touching},
	pages = {1--13},
}

@inproceedings{chen_wearable_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Wearable {Microphone} {Jamming}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376304},
	doi = {10.1145/3313831.3376304},
	abstract = {We engineered a wearable microphone jammer that is capable of disabling microphones in its user's surroundings, including hidden microphones. Our device is based on a recent exploit that leverages the fact that when exposed to ultrasonic noise, commodity microphones will leak the noise into the audible range.Unfortunately, ultrasonic jammers are built from multiple transducers and therefore exhibit blind spots, i.e., locations in which transducers destructively interfere and where a microphone cannot be jammed. To solve this, our device exploits a synergy between ultrasonic jamming and the naturally occur- ring movements that users induce on their wearable devices (e.g., bracelets) as they gesture or walk. We demonstrate that these movements can blur jamming blind spots and increase jamming coverage. Moreover, current jammers are also directional, requiring users to point the jammer to a microphone; instead, our wearable bracelet is built in a ring-layout that al- lows it to jam in multiple directions. This is beneficial in that it allows our jammer to protect against microphones hidden out of sight.We evaluated our jammer in a series of experiments and found that: (1) it jams in all directions, e.g., our device jams over 87\% of the words uttered around it in any direction, while existing devices jam only 30\% when not pointed directly at the microphone; (2) it exhibits significantly less blind spots; and, (3) our device induced a feeling of privacy to participants of our user study. We believe our wearable provides stronger privacy in a world in which most devices are constantly eavesdropping on our conversations.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Yuxin and Li, Huiying and Teng, Shan-Yuan and Nagels, Steven and Li, Zhijing and Lopes, Pedro and Zhao, Ben Y. and Zheng, Haitao},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, wearable, jamming, microphone, ultrasound},
	pages = {1--12},
}

@inproceedings{aigner_embroidered_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Embroidered {Resistive} {Pressure} {Sensors}: {A} {Novel} {Approach} for {Textile} {Interfaces}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376305},
	doi = {10.1145/3313831.3376305},
	abstract = {We present a novel method for augmenting arbitrary fabrics with textile-based pressure sensors using an off-the-shelf embroidery machine. We apply resistive textiles and conductive yarns on top of a base fabric, to yield a flexible and versatile continuous sensing device, which is based on the widespread principle of force sensitive resistors. The patches can easily be attached to measurement and/or computing devices, e.g. for controlling accessories. In this paper, we investigate the impacts of related design and fabrication parameters, introduce five different pattern designs, and discuss their pros and cons. We present crucial insights and recommendations for design and manufacturing of embroidered pressure sensors. Our sensors show a very low activation threshold, as well as good dynamic range, signal-to-noise ratio, and part-to-part repeatability.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Aigner, Roland and Pointner, Andreas and Preindl, Thomas and Parzer, Patrick and Haller, Michael},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {embroidery, smart textiles, embroidered force sensitive resistance, space-filling patterns, textile sensor},
	pages = {1--13},
}

@inproceedings{xu_bitiptext_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{BiTipText}: {Bimanual} {Eyes}-{Free} {Text} {Entry} on a {Fingertip} {Keyboard}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376306},
	doi = {10.1145/3313831.3376306},
	abstract = {We present a bimanual text input method on a miniature fingertip keyboard, that invisibly resides on the first segment of a user's index finger on both hands. Text entry can be carried out using the thumb-tip to tap the tip of the index finger. The design of our keyboard layout followed an iterative process, where we first conducted a study to understand the natural expectation of the handedness of the keys in a QWERTY layout for users. Among a choice of 67,108,864 design variations, we identified 1295 candidates offering a good satisfaction for user expectations. Based on these results, we computed an optimized bimanual keyboard layout, while considering the joint optimization problems of word ambiguity and movement time. Our user evaluation revealed that participants achieved an average text entry speed of 23.4 WPM.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Xu, Zheer and Chen, Weihao and Zhao, Dongyang and Luo, Jiehui and Wu, Te-Yen and Gong, Jun and Yin, Sicheng and Zhai, Jialun and Yang, Xing-Dong},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {wearable, text entry, bimanual input, micro finger gesture},
	pages = {1--13},
}

@inproceedings{clarke_critical_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {Critical} {Catalog}: {Library} {Information} {Systems}, {Tricksterism}, and {Social} {Justice}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376307},
	doi = {10.1145/3313831.3376307},
	abstract = {In this paper, we describe the Critical Catalog, a grant-funded research through design project intended to investigate metadata elements, values, and organizational structures necessary to intentionally advocate for diversity and expose library users to resources from populations traditionally marginalized in literature and publishing. Drawing on principles from critical design, the prototype functions as a critical intervention intended to raise questions and stimulate debate, rather than a purely technical fix to deeply social concerns. A detailed reflective discussion of the design process reveals how existing infrastructural constraints shaped design decisions that led to increased advocacy and a stronger activist standpoint. We discuss the use of metadata as design material for social justice, the application of tricksterism in HCI, and how both practical limitations from professional contexts and imposed limitations based on identities and positions of power can lead to surprising places, meanings, and questions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Clarke, Rachel Ivy and Schoonmaker, Sayward},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {research through design, library catalogs, metadata, tricksterism, whiteness},
	pages = {1--13},
}

@inproceedings{morreale_my_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{My} {Library} {Has} {Just} {Been} {Obliterated}": {Producing} {New} {Norms} of {Use} {Via} {Software} {Update}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376308},
	doi = {10.1145/3313831.3376308},
	abstract = {Software updates are commonly perceived as tools for fixing flaws and improving functionality. In this paper, we problematise this view by showing how software updates may also be used by vendors to create new norms of use that control user behaviour and reduce their agency. We explore the nature and aftermath of a controversial software update that was released by Spotify in June 2019. By analysing almost 3,500 reactions to this update, we show how it removed and modified several features in ways that severely affected users' capability to organise, navigate, and maintain their music libraries, while it pushed modes of listening that delegate song selection to Spotify. Elaborating upon our results, we discuss how updates may be used as political tools that privilege certain forms of behaviour while restricting others. We also portray updates as sites where ongoing struggles and negotiations regarding user agency and digital ownership take place.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Morreale, Fabio and Eriksson, Maria},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {critical computing, music streaming, normative affordances, protocological power, psychological ownership, spotify},
	pages = {1--13},
}

@inproceedings{kornfield_energy_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{Energy} is a {Finite} {Resource}": {Designing} {Technology} to {Support} {Individuals} across {Fluctuating} {Symptoms} of {Depression}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376309},
	doi = {10.1145/3313831.3376309},
	abstract = {While the HCI field increasingly examines how digital tools can support individuals in managing mental health conditions, it remains unclear how these tools can accommodate these conditions' temporal aspects. Based on weekly interviews with five individuals with depression, conducted over six weeks, this study identifies design opportunities and challenges related to extending technology-based support across fluctuating symptoms. Our findings suggest that participants perceive events and contexts in daily life to have marked impact on their symptoms. Results also illustrate that ebbs and flows in symptoms profoundly affect how individuals practice depression self-management. While digital tools often aim to reach individuals while they feel depressed, we suggest they should also engage individuals when they are less symptomatic, leveraging their energy and motivation to build habits, establish plans and goals, and generate and organize content to prepare for symptom onset.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kornfield, Rachel and Zhang, Renwen and Nicholas, Jennifer and Schueller, Stephen M. and Cambo, Scott A. and Mohr, David C. and Reddy, Madhu},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {motivation, mental health, depression, digital interventions, personalization, tailoring, temporality},
	pages = {1--17},
}

@inproceedings{reitmaier_honest_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {An {Honest} {Conversation}: {Transparently} {Combining} {Machine} and {Human} {Speech} {Assistance} in {Public} {Spaces}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376310},
	doi = {10.1145/3313831.3376310},
	abstract = {There is widespread concern over the ways speech assistant providers currently use humans to listen to users' queries without their knowledge. We report two iterations of the TalkBack smart speaker, which transparently combines machine and human assistance. In the first, we created a prototype to investigate whether people would choose to forward their questions to a human answerer if the machine was unable to help. Longitudinal deployment revealed that most users would do so when given the explicit choice. In the second iteration we extended the prototype to draw upon spoken answers from previous deployments, combining machine efficiency with human richness. Deployment of this second iteration shows that this corpus can help provide relevant, human-created instant responses. We distil lessons learned for those developing conversational agents or other AI-infused systems about how to appropriately enlist human-in-the-loop information services to benefit users, task workers and system performance.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Reitmaier, Thomas and Robinson, Simon and Pearson, Jennifer and Kalarikalayil Raju, Dani and Jones, Matt},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {conversational agents, emergent users, public space interaction, speech appliances},
	pages = {1--12},
}

@inproceedings{luria_social_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Social {Boundaries} for {Personal} {Agents} in the {Interpersonal} {Space} of the {Home}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376311},
	doi = {10.1145/3313831.3376311},
	abstract = {The presence of voice activated personal assistants (VAPAs) in people's homes rises each year [31]. Industry efforts are invested in making interactions with VAPAs more personal by leveraging information from messages and calendars, and by accessing user accounts for 3rd party services. However, the use of personal data becomes more complicated in interpersonal spaces, such as people's homes. Should a shared agent access the information of many users? If it does, how should it navigate issues of privacy and control? Designers currently lack guidelines to help them design appropriate agent behaviors. We used Speed Dating to explore inchoate social mores around agent actions within a home, including issues of proactivity, interpersonal conflict, and agent prevarication. Findings offer new insights on how more socially sophisticated agents might sense, make judgements about, and navigate social roles and individuals. We discuss how our findings might impact future research and future agent behaviors.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Luria, Michal and Zheng, Rebecca and Huffman, Bennett and Huang, Shuangni and Zimmerman, John and Forlizzi, Jodi},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {conversational agents, interaction design, embodied agents, social robots, speed dating, voice activated personal assistants},
	pages = {1--12},
}

@inproceedings{sauve_change_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {Change} of {Perspective}: {How} {User} {Orientation} {Influences} the {Perception} of {Physicalizations}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376312},
	doi = {10.1145/3313831.3376312},
	abstract = {As physicalizations encode data in their physical 3D form, the orientation in which the user is viewing the physicalization may impact the way the information is perceived. However, this relation between user orientation and perception of physical properties is not well understood or studied. To investigate this relation, we conducted an experimental study with 20 participants who viewed 6 exemplars of physicalizations from 4 different perspectives. Our findings show that perception is directly influenced by user orientation as it affects (i) the number and type of clusters, (ii) anomalies and (iii) extreme values identified within a physicalization. Our results highlight the complexity and variability of the relation between user orientation and perception of physicalizations.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sauvé, Kim and Potts, Dominic and Alexander, Jason and Houben, Steven},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {data physicalization, physical visualization, user orientation},
	pages = {1--12},
}

@inproceedings{zhou_gripmarks_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Gripmarks: {Using} {Hand} {Grips} to {Transform} {In}-{Hand} {Objects} into {Mixed} {Reality} {Input}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376313},
	doi = {10.1145/3313831.3376313},
	abstract = {We introduce Gripmarks, a system that enables users to opportunistically use objects they are already holding as input surfaces for mixed reality head-mounted displays (HMD). Leveraging handheld objects reduces the need for users to free up their hands or acquire a controller to interact with their HMD. Gripmarks associate a particular hand grip with the shape primitive of the physical object without the need of object recognition or instrumenting the object. From the grip pose and shape primitive we can infer the surface of the object. With an activation gesture, we can enable the object for use as input to the HMD. With five gripmarks we demonstrate a recognition rate of 94.2\%; we show that our grip detection benefits from the physical constraints of holding an object. We explore two categories of input objects 1) tangible surfaces and 2) tangible tools and present two representative applications. We discuss the design and technical challenges for expanding the concept.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Qian and Sykes, Sarah and Fels, Sidney and Kin, Kenrick},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {mixed reality, grip recognition, gripmarks, tangible objects},
	pages = {1--11},
}

@inproceedings{williams_upcycled_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {Upcycled} {Home}: {Removing} {Barriers} to {Lightweight} {Modification} of the {Home}'s {Everyday} {Objects}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376314},
	doi = {10.1145/3313831.3376314},
	abstract = {The Internet-of-things (IoT) embeds computing in everyday objects, but has largely focused on new devices while ignoring the home's many existing possessions. We present a field study with 10 American families to understand how these possessions could be included in the smart home through upcycling. We describe three patterns for how families collaborate around home responsibilities; we explore families' mental models of home that may be in tension with existing IoT systems; and we identify ways that families can more easily imagine a smart home that includes their existing possessions. These insights can help us design an upcycled approach to IoT that supports users in reconfiguring objects (and social roles as mediated by objects) in a way that is sensitive to what will be displaced, discarded, or made obsolete. Our findings inform the design of future lightweight systems for the upcycled home.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Williams, Kristin and Pulivarthy, Rajitha and Hudson, Scott E. and Hammer, Jessica},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {smart home, iot, sustainability, division of labor, family coordination, internet-of-things, intersectionality, personal inventories, upcycle},
	pages = {1--13},
}

@inproceedings{strengers_adhering_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Adhering, {Steering}, and {Queering}: {Treatment} of {Gender} in {Natural} {Language} {Generation}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376315},
	doi = {10.1145/3313831.3376315},
	abstract = {Natural Language Generation (NLG) supports the creation of personalized, contextualized, and targeted content. However, the algorithms underpinning NLG have come under scrutiny for reinforcing gender, racial, and other problematic biases. Recent research in NLG seeks to remove these biases through principles of fairness and privacy. Drawing on gender and queer theories from sociology and Science and Technology studies, we consider how NLG can contribute towards the advancement of gender equity in society. We propose a conceptual framework and technical parameters for aligning NLG with feminist HCI qualities. We present three approaches: (1) adhering to current approaches of removing sensitive gender attributes, (2) steering gender differences away from the norm, and (3) queering gender by troubling stereotypes. We discuss the advantages and limitations of these approaches across three hypothetical scenarios; newspaper headlines, job advertisements, and chatbots. We conclude by discussing considerations for implementing this framework and related ethical and equity agendas.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Strengers, Yolande and Qu, Lizhen and Xu, Qiongkai and Knibbe, Jarrod},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {feminist hci, natural language generation},
	pages = {1--14},
}

@inproceedings{gero_mental_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Mental {Models} of {AI} {Agents} in a {Cooperative} {Game} {Setting}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376316},
	doi = {10.1145/3313831.3376316},
	abstract = {As more and more forms of AI become prevalent, it becomes increasingly important to understand how people develop mental models of these systems. In this work we study people's mental models of AI in a cooperative word guessing game. We run think-aloud studies in which people play the game with an AI agent; through thematic analysis we identify features of the mental models developed by participants. In a large-scale study we have participants play the game with the AI agent online and use a post-game survey to probe their mental model. We find that those who win more often have better estimates of the AI agent's abilities. We present three components for modeling AI systems, propose that understanding the underlying technology is insufficient for developing appropriate conceptual models (analysis of behavior is also necessary), and suggest future work for studying the revision of mental models over time.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gero, Katy Ilonka and Ashktorab, Zahra and Dugan, Casey and Pan, Qian and Johnson, James and Geyer, Werner and Ruiz, Maria and Miller, Sarah and Millen, David R. and Campbell, Murray and Kumaravel, Sadhana and Zhang, Wei},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {games, artificial intelligence, ai agents, conceptual models, mental models, think-aloud, word games},
	pages = {1--12},
}

@inproceedings{kumar_tagswipe_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{TAGSwipe}: {Touch} {Assisted} {Gaze} {Swipe} for {Text} {Entry}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376317},
	doi = {10.1145/3313831.3376317},
	abstract = {The conventional dwell-based methods for text entry by gaze are typically slow and uncomfortable. A swipe-based method that maps gaze path into words offers an alternative. However, it requires the user to explicitly indicate the beginning and ending of a word, which is typically achieved by tedious gaze-only selection. This paper introduces TAGSwipe, a bi-modal method that combines the simplicity of touch with the speed of gaze for swiping through a word. The result is an efficient and comfortable dwell-free text entry method. In the lab study TAGSwipe achieved an average text entry rate of 15.46 wpm and significantly outperformed conventional swipe-based and dwell-based methods in efficacy and user satisfaction.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kumar, Chandan and Hedeshy, Ramin and MacKenzie, I. Scott and Staab, Steffen},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {eye tracking, touch input, multimodal interaction, dwell-free typing, eye typing, swipe, word-level text entry},
	pages = {1--12},
}

@inproceedings{santhanam_studying_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Studying the {Effects} of {Cognitive} {Biases} in {Evaluation} of {Conversational} {Agents}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376318},
	doi = {10.1145/3313831.3376318},
	abstract = {Humans quite frequently interact with conversational agents. The rapid advancement in generative language modeling through neural networks has helped advance the creation of intelligent conversational agents. Researchers typically evaluate the output of their models through crowdsourced judgments, but there are no established best practices for conducting such studies. Moreover, it is unclear if cognitive biases in decision-making are affecting crowdsourced workers' judgments when they undertake these tasks. To investigate, we conducted a between-subjects study with 77 crowdsourced workers to understand the role of cognitive biases, specifically anchoring bias, when humans are asked to evaluate the output of conversational agents. Our results provide insight into how best to evaluate conversational agents. We find increased consistency in ratings across two experimental conditions may be a result of anchoring bias. We also determine that external factors such as time and prior experience in similar tasks have effects on inter-rater consistency.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Santhanam, Sashank and Karduni, Alireza and Shaikh, Samira},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {conversational agents, anchoring bias, experiment design, human evaluation},
	pages = {1--13},
}

@inproceedings{wehbe_personal_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Personal {Space} in {Play}: {Physical} and {Digital} {Boundaries} in {Large}-{Display} {Cooperative} and {Competitive} {Games}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376319},
	doi = {10.1145/3313831.3376319},
	abstract = {As multi-touch displays grow in size and shrink in price, they are more commonly used as gaming devices. When co-located users play games on a single, large display, establishing and maintaining their physical and digital territories poses a social challenge to their interaction. To gain insight into the mechanisms of establishing and maintaining users' physical and digital territories, we analyze territorial interactions in cooperative and competitive multiplayer gameplay. Participants reported weighing each game interaction based on perceived intent to determine how socially acceptable they deemed each behaviour. In light of our observations, we contribute and discuss implications for the design of multi-user, large display, co-located, touchscreen games that consider display properties, digital and physical space, permeability of boundaries, and asymmetry of play to create interactions between players.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wehbe, Rina R. and Dickson, Terence and Kuzminykh, Anastasia and Nacke, Lennart E. and Lank, Edward},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {collaboration and group work, digital territory, games and entertainment software, large displays, loosely-coupled interaction, physical territory, shared spaces},
	pages = {1--14},
}

@inproceedings{hettiachchi_hi_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{Hi}! {I} {Am} the {Crowd} {Tasker}" {Crowdsourcing} through {Digital} {Voice} {Assistants}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376320},
	doi = {10.1145/3313831.3376320},
	abstract = {Inspired by the increasing prevalence of digital voice assistants, we demonstrate the feasibility of using voice interfaces to deploy and complete crowd tasks. We have developed Crowd Tasker, a novel system that delivers crowd tasks through a digital voice assistant. In a lab study, we validate our proof-of-concept and show that crowd task performance through a voice assistant is comparable to that of a web interface for voice-compatible and voice-based crowd tasks for native English speakers. We also report on a field study where participants used our system in their homes. We find that crowdsourcing through voice can provide greater flexibility to crowd workers by allowing them to work in brief sessions, enabling multi-tasking, and reducing the time and effort required to initiate tasks. We conclude by proposing a set of design guidelines for the creation of crowd tasks for voice and the development of future voice-based crowdsourcing systems.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hettiachchi, Danula and Sarsenbayeva, Zhanna and Allison, Fraser and van Berkel, Niels and Dingler, Tilman and Marini, Gabriele and Kostakos, Vassilis and Goncalves, Jorge},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {crowdsourcing, voice user interface, digital voice assistants, smart speakers},
	pages = {1--14},
}

@inproceedings{nouwens_dark_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Dark {Patterns} after the {GDPR}: {Scraping} {Consent} {Pop}-{Ups} and {Demonstrating} {Their} {Influence}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376321},
	doi = {10.1145/3313831.3376321},
	abstract = {New consent management platforms (CMPs) have been introduced to the web to conform with the EU's General Data Protection Regulation, particularly its requirements for consent when companies collect and process users' personal data. This work analyses how the most prevalent CMP designs affect people's consent choices. We scraped the designs of the five most popular CMPs on the top 10,000 websites in the UK (n=680). We found that dark patterns and implied consent are ubiquitous; only 11.8\% meet our minimal requirements based on European law. Second, we conducted a field experiment with 40 participants to investigate how the eight most common designs affect consent choices. We found that notification style (banner or barrier) has no effect; removing the opt-out button from the first page increases consent by 22-23 percentage points; and providing more granular controls on the first page decreases consent by 8-20 percentage points. This study provides an empirical basis for the necessary regulatory action to enforce the GDPR, in particular the possibility of focusing on the centralised, third-party CMP services as an effective way to increase compliance.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Nouwens, Midas and Liccardi, Ilaria and Veale, Michael and Karger, David and Kagal, Lalana},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {controlled experiment, consent management platforms, dark patterns, gdpr, notice and consent, web scraper},
	pages = {1--13},
}

@inproceedings{zhang_withyou_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{WithYou}: {Automated} {Adaptive} {Speech} {Tutoring} {With} {Context}-{Dependent} {Speech} {Recognition}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376322},
	doi = {10.1145/3313831.3376322},
	abstract = {Learning to speak in foreign languages is hard. Speech shadowing has been rising as a proven way to practice speaking, which asks a learner to listen and repeat a native speech template as simultaneously as possible. However, shadowing can be hard to do because learners can frequently fail to follow the speech and unintentionally interrupt a practice session. Worse, as a technical way to evaluate shadowing performance in real-time has not been established, no automated solutions are available to help. In this paper, we propose a technical framework with context-dependent speech recognition to evaluate shadowing in real-time. We propose a shadowing tutor system called WithYou, which can automatically adjust the playback and the difficulty of a speech template when learners fail, so shadowing becomes smooth and tailored. Results from a user study show that WithYou provides greater speech improvements (14\%) than the conventional method (2.7\%) with a lower cognitive load.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Xinlei and Miyaki, Takashi and Rekimoto, Jun},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {language learning, speech recognition, computer assisted language learning (call), intelligent tutoring system, shadowing, speaking},
	pages = {1--12},
}

@inproceedings{zhang_thermalring_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{ThermalRing}: {Gesture} and {Tag} {Inputs} {Enabled} by a {Thermal} {Imaging} {Smart} {Ring}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376323},
	doi = {10.1145/3313831.3376323},
	abstract = {The heterogeneous and ubiquitous input demands in smart spaces call for an input device that can enable rich and spontaneous interactions. We propose ThermalRing, a thermal imaging smart ring using low-resolution thermal camera for identity-anonymous, illumination-invariant, and power-efficient sensing of both dynamic and static gestures. We also design ThermalTag, thin and passive thermal imageable tags that reflect the heat from the human hand. ThermalTag can be easily made and applied onto everyday objects by users. We develop sensing techniques for three typical input demands: drawing gestures for device pairing, click and slide gestures for device control, and tag scan gestures for quick access. The study results show that ThermalRing can recognize nine drawing gestures with an overall accuracy of 90.9\%, detect click gestures with an accuracy of 94.9\%, and identify among six ThermalTags with an overall accuracy of 95.0\%. Finally, we show the versatility and potential of ThermalRing through various applications.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Tengxiang and Zeng, Xin and Zhang, Yinshuai and Sun, Ke and Wang, Yuntao and Chen, Yiqiang},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {gesture recognition, interactive tags, smart ring, thermal imaging},
	pages = {1--13},
}

@inproceedings{wu_predicting_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Predicting and {Diagnosing} {User} {Engagement} with {Mobile} {UI} {Animation} via a {Data}-{Driven} {Approach}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376324},
	doi = {10.1145/3313831.3376324},
	abstract = {Animation, a common design element in user interfaces (UI), can impact user engagement (UE) with mobile applications. To avoid impairing UE due to improper design of animation, designers rely on resource-intensive evaluation methods like user studies or expert reviews. To alleviate this burden, we propose a data-driven approach to assisting designers in examining UE issues with their animation designs. We first crowdsource UE assessments of mobile UI animations. Based on the collected data, we then build a novel deep learning model that captures both spatial and temporal features of animations to predict their UE levels. Evaluations show that our model achieves a reasonable accuracy. We further leverage the animation feature encoded by our model and a sample set of expert reviews to derive potential UE issues of a particular animation. Finally, we develop a proof-of-concept tool and evaluate its potential usage in actual design practices with experts},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Ziming and Jiang, Yulun and Liu, Yiding and Ma, Xiaojuan},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {data-driven approach, mobile ui animation, user engagement},
	pages = {1--13},
}

@inproceedings{dey_color_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Color and {Animation} {Preferences} for a {Light} {Band} {EHMI} in {Interactions} {Between} {Automated} {Vehicles} and {Pedestrians}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376325},
	doi = {10.1145/3313831.3376325},
	abstract = {In this paper, we report user preferences regarding color and animation patterns to support the interaction between Automated Vehicles (AVs) and pedestrians through an external Human-Machine-Interface (eHMI). Existing concepts of eHMI differ – among other things – in their use of colors or animations to express an AV's yielding intention. In the absence of empirical research, there is a knowledge gap regarding which color and animation leads to highest usability and preferences in traffic negotiation situations. We conducted an online survey (N=400) to investigate the comprehensibility of a light band eHMI with a combination of 5 color and 3 animation patterns for a yielding AV. Results show that cyan is considered a neutral color for communicating a yielding intention. Additionally, a uniformly flashing or pulsing animation is preferred compared to any pattern that animates sideways. These insights can contribute in the future design and standardization of eHMIs.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dey, Debargha and Habibovic, Azra and Pfleging, Bastian and Martens, Marieke and Terken, Jacques},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {autonomous vehicles, interface, animation, automated vehicles, ehmi, pedestrians, color, vru},
	pages = {1--13},
}

@inproceedings{tomlinson_participatory_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {Participatory} {Simulation} of the {Accountable} {Capitalism} {Act}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376326},
	doi = {10.1145/3313831.3376326},
	abstract = {Interactive computing systems increasingly allow for experimental evaluations of fundamental issues in law, government, and society. In this paper, we describe a participatory simulation of the Accountable Capitalism Act, a bill proposed in 2018 by US Senator Elizabeth Warren. We present findings from an empirical study conducted using this system, relating to the impact of 1) interactive visualization and 2) the Accountable Capitalism Act legal framework on the behavior of participants acting as corporate directors. From this study, we draw lessons about research possibilities at the juncture of HCI and legal and policy studies. This study contributes an analysis and evaluation of a design probe used to investigate potential impacts of the Accountable Capitalism Act, experimental evidence from a study conducted using the design probe, and guidance for future participatory simulations that seek to inform the design of social institutions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tomlinson, Bill and Silberman, M. Six and Torrance, Andrew W. and Squire, Kurt and Atwal, Paramdeep S. and Mandalik, Ameya N. and Railkar, Sahil and Black, Rebecca W.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {law, business, corporations, participatory simulation},
	pages = {1--13},
}

@inproceedings{lee_guicomp_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{GUIComp}: {A} {GUI} {Design} {Assistant} with {Real}-{Time}, {Multi}-{Faceted} {Feedback}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376327},
	doi = {10.1145/3313831.3376327},
	abstract = {Users may face challenges while designing graphical user interfaces, due to a lack of relevant experience and guidance. This paper aims to investigate the issues users face during the design process, and how to resolve them. To this end, we conducted semi-structured interviews, based on which we built a GUI prototyping assistance tool called GUIComp. This tool can be connected to GUI design software as an extension, and it provides real-time, multi-faceted feedback on a user's current design. Additionally, we conducted two user studies, in which we asked participants to create mobile GUIs with or without GUIComp, and requested online workers to assess the created GUIs. The experimental results show that GUIComp facilitated iterative designs and the participants with GUIComp had better a user experience and produced more acceptable designs than those who did not use it.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Chunggi and Kim, Sanghoon and Han, Dongyun and Yang, Hongjun and Park, Young-Woo and Kwon, Bum Chul and Ko, Sungahn},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {design feedback, gui design},
	pages = {1--13},
}

@inproceedings{pretorius_searching_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Searching for {Mental} {Health}: {A} {Mixed}-{Methods} {Study} of {Young} {People}'s {Online} {Help}-{Seeking}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376328},
	doi = {10.1145/3313831.3376328},
	abstract = {Seeking help is often an important step in addressing mental health difficulties. Evidence suggests that positive help-seeking experiences contribute to an increased likelihood of future help-seeking and achieving improved outcomes. However, help-seeking is a complex process. Alongside traditional sources, digital technologies offer many pathways to help. Using a mixed methods approach across two studies, this paper explores key design factors for online mental health resources that can support young people's help-seeking. First, a large online survey (n=1308) highlighted challenges and identified common help-seeking scenarios, including information-seeking, person-centred approaches and crisis situations. Using survey data, personas were developed to represent different help-seekers - each characterised by a particular help-seeking scenario. The personas were then used in co-design workshops to facilitate further exploration of help-seeking needs. Four key design considerations were identified: connectedness, accessible information, personalisation, and immediacy. Based on our findings, we provide design recommendations that are grounded in existing theories of help-seeking.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pretorius, Claudette and McCashin, Darragh and Kavanagh, Naoise and Coyle, David},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {co-design, mental health, mixed methods, personas, behaviour, help-seeking, search, young people},
	pages = {1--13},
}

@inproceedings{wong-villacres_culture_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Culture in {Action}: {Unpacking} {Capacities} to {Inform} {Assets}-{Based} {Design}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376329},
	doi = {10.1145/3313831.3376329},
	abstract = {The field of Human-Computer Interaction (HCI) aims at securing a lasting impact for technology-based interventions in the context of social inequities. Increasingly, HCI scholars are proposing assets-based design as an effective approach towards this issue. Rather than starting from people's needs and deficits, this approach posits that design should start from a deep understanding of people's assets. A pending issue, however, is how to account for the situated nature of assets; that is, how to decide which asset to leverage and for what design purpose. Drawing from cultural sociology and shifting the emphasis from assets to capacities, we propose Swidler's theory of culture-in-action as an analytical lens for unpacking the complex relationship between capacities, goals, and structural limitations. Leveraging findings from a Participatory Design engagement with 35 Latino immigrant parents for envisioning parent-education technologies, we demonstrate the applicability of this lens. We contribute to HCI scholarship by further discussing 1) how to analyze capacities' design potential, and 2) the methodological particularities for collecting them.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wong-Villacres, Marisol and DiSalvo, Carl and Kumar, Neha and DiSalvo, Betsy},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {participatory design, culture, assets-based, capacities, immigrant parents},
	pages = {1--14},
}

@inproceedings{nebeling_mrat_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{MRAT}: {The} {Mixed} {Reality} {Analytics} {Toolkit}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376330},
	doi = {10.1145/3313831.3376330},
	abstract = {Significant tool support exists for the development of mixed reality (MR) applications; however, there is a lack of tools for analyzing MR experiences. We elicit requirements for future tools through interviews with 8 university research, instructional, and media teams using AR/VR in a variety of domains. While we find a common need for capturing how users perform tasks in MR, the primary differences were in terms of heuristics and metrics relevant to each project. Particularly in the early project stages, teams were uncertain about what data should, and even could, be collected with MR technologies. We designed the Mixed Reality Analytics Toolkit (MRAT) to instrument MR apps via visual editors without programming and enable rapid data collection and filtering for visualizations of MR user sessions. With MRAT, we contribute flexible interaction tracking and task definition concepts, an extensible set of heuristic techniques and metrics to measure task success, and visual inspection tools with in-situ visualizations in MR. Focusing on a multi-user, cross-device MR crisis simulation and triage training app as a case study, we then show the benefits of using MRAT, not only for user testing of MR apps, but also performance tuning throughout the design process.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Nebeling, Michael and Speicher, Maximilian and Wang, Xizi and Rajaram, Shwetha and Hall, Brian D. and Xie, Zijian and Raistrick, Alexander R. E. and Aebersold, Michelle and Happ, Edward G. and Wang, Jiayin and Sun, Yanan and Zhang, Lotus and Ramsier, Leah E. and Kulkarni, Rhea},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {augmented/virtual reality, interaction tracking, user testing},
	pages = {1--12},
}

@inproceedings{zarei_investigating_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Investigating the {Effects} of {Self}-{Avatars} and {Story}-{Relevant} {Avatars} on {Children}'s {Creative} {Storytelling}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376331},
	doi = {10.1145/3313831.3376331},
	abstract = {Storytelling is a critical step in the cognitive development of children. Particularly, this requires children to mentally project into the story context and to identify with the thoughts of the characters in their stories. We propose to support free imagination in creative storytelling through an enactment-based approach that allows children to embody an avatar and perform as the story character. We designed our story creation interface with two modes of avatar: the story-relevant avatar and the self-avatar, to investigate the effects of avatar design on the quality of children's creative products. In our study with 20 child participants, the results indicate that self-avatars can create a stronger sense of identification and embodied presence, while story-relevant avatars can provide a scaffold for mental projection.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zarei, Niloofar and Chu, Sharon Lynn and Quek, Francis and Rao, Nanjie 'Jimmy' and Brown, Sarah Anne},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, storytelling, creativity, embodied interaction, expressive writing},
	pages = {1--11},
}

@inproceedings{tyack_restorative_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Restorative {Play}: {Videogames} {Improve} {Player} {Wellbeing} {After} a {Need}-{Frustrating} {Event}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376332},
	doi = {10.1145/3313831.3376332},
	abstract = {People often use videogames to restore wellbeing after negative experiences in day-to-day life. Although some research suggests that play can restore wellbeing, few studies have investigated the means by which restoration occurs. We employed self-determination theory (SDT) to understand how and to what degree play improves wellbeing after a need-frustrating event, and how players understand experiences of competence in play. Sixty-five participants worked at a competence manipulation task prior to playing a competence-satisfying videogame. Competence, affect, and vitality improved during play, and in-game experiences of need frustration were observed to effectively predict post-play negative affect. Post-experiment interviews indicate that videogames are seen to support competence relative to perceived skill, extending our knowledge of how design can support competence and restoration. We demonstrate that play can restore wellbeing, present need frustration as a means to explain negative experiences with interactive systems, and discuss effects of design on competence.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tyack, April and Wyeth, Peta and Johnson, Daniel},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {self-determination theory, player experience, video games, need frustration, restoration, wellbeing},
	pages = {1--15},
}

@inproceedings{zhu_pneusleeve_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{PneuSleeve}: {In}-{Fabric} {Multimodal} {Actuation} and {Sensing} in a {Soft}, {Compact}, and {Expressive} {Haptic} {Sleeve}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376333},
	doi = {10.1145/3313831.3376333},
	abstract = {Integration of soft haptic devices into garments can improve their usability and wearability for daily computing interactions. In this paper, we introduce PneuSleeve, a fabric-based, compact, and highly expressive forearm sleeve which can render a broad range of haptic stimuli including compression, skin stretch, and vibration. The haptic stimuli are generated by controlling pneumatic pressure inside embroidered stretchable tubes. The actuation configuration includes two compression actuators on the proximal and distal forearm, and four uniformly distributed linear actuators around and tangent to the forearm. Further, to ensure a suitable grip force, two soft mutual capacitance sensors are fabricated and integrated into the compression actuators, and a closed-loop force controller is implemented. We physically characterize the static and dynamic behavior of the actuators, as well as the performance of closed-loop control. We quantitatively evaluate the psychophysical characteristics of the six actuators in a set of user studies. Finally, we show the expressiveness of PneuSleeve by evaluating combined haptic stimuli using subjective assessments.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Mengjia and Memar, Amirhossein H. and Gupta, Aakar and Samad, Majed and Agarwal, Priyanshu and Visell, Yon and Keller, Sean J. and Colonnese, Nicholas},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {haptics, pneumatic actuation, wearables, vibration, closed-loop haptic rendering, compression, multimodal haptic display, skin stretch},
	pages = {1--12},
}

@inproceedings{cesario_teenage_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Teenage {Visitor} {Experience}: {Classification} of {Behavioral} {Dynamics} in {Museums}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376334},
	doi = {10.1145/3313831.3376334},
	abstract = {Teenagers' engagement in museums is much talked about but little research has been done to understand their behavior and inform design. Findings from co-design sessions with teenagers suggested they value games and stories when thinking about enjoyable museum tours. Informed by these findings and working with a natural history museum, we designed: a story-based tour (Turning Point) and a game-based tour (Haunted Encounters), informed by similar content. The two strategies were evaluated with 78 teenagers (15-19 years old) visiting the museum as part of an educational school trip. We assessed teenagers' personality in class; qualitative and quantitative data on their engagement, experience, and usability of the apps were collected at the museum. The triangulation of quantitative and qualitative data show personality traits mapping into different behaviors. We offer implications for the design of museum apps targeted to teenagers, a group known as difficult to reach.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cesário, Vanessa and Petrelli, Daniela and Nisi, Valentina},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {co-design, storytelling, game, museums, mobile experience, teenagers, visitor experience},
	pages = {1--13},
}

@inproceedings{kaul_vibrotactile_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Vibrotactile {Funneling} {Illusion} and {Localization} {Performance} on the {Head}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376335},
	doi = {10.1145/3313831.3376335},
	abstract = {The vibrotactile funneling illusion is the sensation of a single (non-existing) stimulus somewhere in-between the actual stimulus locations. Its occurrence depends upon body location, distance between the actuators, signal synchronization, and intensity. Related work has shown that the funneling illusion may occur on the forehead. We were able to reproduce these findings and explored five further regions to get a more complete picture of the occurrence of the funneling illusion on the head. The results of our study (24 participants) show that the actuator distance, for which the funneling illusion occurs, strongly depends upon the head region. Moreover, we evaluated the centralizing bias (smaller perceived than actual actuator distances) for different head regions, which also showed widely varying characteristics. We computed a detailed heat map of vibrotactile localization accuracies on the head. The results inform the design of future tactile head-mounted displays that aim to support the funneling illusion.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kaul, Oliver Beren and Rohs, Michael and Simon, Benjamin and Demir, Kerem Can and Ferry, Kamillo},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {centralizing bias, funneling illusion, phantom sensation, tactile feedback},
	pages = {1--13},
}

@inproceedings{huang_modeling_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Modeling the {Endpoint} {Uncertainty} in {Crossing}-{Based} {Moving} {Target} {Selection}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376336},
	doi = {10.1145/3313831.3376336},
	abstract = {Modeling the endpoint uncertainty of moving target selection with crossing is essential to understand factors such as speed-accuracy trade-off and interaction efficiency in crossing-based user interfaces with dynamic contents. However, there have been few studies looking into this research topic in the HCI field. This paper presents a Quaternary-Gaussian model to quantitatively measure the endpoint uncertainty in crossing-based moving target selection. To validate this model, we conducted an experiment with discrete crossing tasks on five factors, i.e., initial distance, size, speed, orientation, and moving direction. Results showed that our model fit the data of μ and σ accurately with adjusted R2 of 0.883 and 0.920. We also demonstrated the validity of our model in predicting error rates in crossing-based moving target selection. We concluded with a set of implications for future designs.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Huang, Jin and Tian, Feng and Fan, Xiangmin and Tu, Huawei and Zhang, Hao and Peng, Xiaolan and Wang, Hongan},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {crossing-based selection, endpoint distribution, error rate, moving target selection},
	pages = {1--12},
}

@inproceedings{logler_i_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{I} {Feel} {Like} {This} is a {Bad} {Thing}": {Investigating} {Disassembly} in {Action} for {Novices}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376337},
	doi = {10.1145/3313831.3376337},
	abstract = {Materials are dynamic-they can be shaped and changed. Often however, our tools and technologies appear to fix materials in place. Disassembly is one practice that provides openings to explore and understand the dynamic nature of material. In this research, we investigate possibilities that emerge from disassembly. Specifically, we studied how novices disassembled a common digital artifact-desktop printers. We worked with 21 young people and family members across two evening workshops at a middle school. We report on the workshop interactions, categories of actions of disassembly, and four in-depth vignettes showcasing disassembly in action. In the discussion, we reflect on disassembly and permission, sustainability, the joy of disassembling, and design considerations in support of disassembly. Our contributions include: (1) extending existing theoretical framings about artifacts and materials; (2) an empirical study documenting the process by which novices disassemble; and (3) preliminary design and policy considerations that enable disassembly.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Logler, Nick and Pitt, Caroline and Gao, Xin and Hishikawa, Allison Marie and Yip, Jason and Friedman, Batya},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {play, design principles, making, disassembly, design theory, empowerment, materials, novices, unmaking},
	pages = {1--14},
}

@inproceedings{scott_human_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {"{Human}, {All} {Too} {Human}": {NOAA} {Weather} {Radio} and the {Emotional} {Impact} of {Synthetic} {Voices}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376338},
	doi = {10.1145/3313831.3376338},
	abstract = {The integration of text-to-speech into an open technology stack for low-power FM community radio stations is an opportunity to automate laborious processes and increase accessibility to information in remote communities. However, there are open questions as to the perceived contrast of synthetic voices with the local and intimate format of community radio. This paper presents an exploratory focus group on the topic, followed by a thematic analysis of public comments on YouTube videos of the synthetic voices used for broadcasting by National Oceanic and Atmospheric Administration (NOAA) Weather Radio. We find that despite observed reservations about the suitability of TTS for radio, there is significant evidence of anthropomorphism, nostalgia and emotional connection in relation to these voices. Additionally, introduction of a more "human sounding" synthetic voice elicited significant negative feedback. We identify pronunciation, speed, suitability to content and acknowledgment of limitations as more relevant factors in listeners' stated sense of connection.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Scott, Kristen M. and Ashby, Simone and Hanna, Julian},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {text-to-speech, anthropomorphism, noaa weather radio, synthetic speech, uncanny valley},
	pages = {1--9},
}

@inproceedings{lerner_privacy_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Privacy and {Activism} in the {Transgender} {Community}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376339},
	doi = {10.1145/3313831.3376339},
	abstract = {Transgender people are marginalized, facing specific privacy concerns and high risk of online and offline harassment, discrimination, and violence. They also benefit tremendously from technology. We conducted semi-structured interviews with 18 transgender people from 3 U.S. cities about their computer security and privacy experiences broadly construed. Participants frequently returned to themes of activism and prosocial behavior, such as protest organization, political speech, and role-modeling transgender identities, so we focus our analysis on these themes. We identify several prominent risk models related to visibility, luck, and identity that participants used to analyze their own risk profiles, often as distinct or extreme. These risk perceptions may heavily influence transgender people's defensive behaviors and self-efficacy, jeopardizing their ability to defend themselves or gain technology's benefits. We articulate design lessons emerging from these ideas, contrasting and relating them to lessons about other marginalized groups whenever possible.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lerner, Ada and He, Helen Yuxun and Kawakami, Anna and Zeamer, Silvia Catherine and Hoyle, Roberto},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, transgender, security, gender identity, presentation management, social networks, user-centered design},
	pages = {1--13},
}

@inproceedings{mayer_improving_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Improving {Humans}' {Ability} to {Interpret} {Deictic} {Gestures} in {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376340},
	doi = {10.1145/3313831.3376340},
	abstract = {Collaborative Virtual Environments (CVEs) offer unique opportunities for human communication. Humans can interact with each other over a distance in any environment and visual embodiment they want. Although deictic gestures are especially important as they can guide other humans' attention, humans make systematic errors when using and interpreting them. Recent work suggests that the interpretation of vertical deictic gestures can be significantly improved by warping the pointing arm. In this paper, we extend previous work by showing that models enable to also improve the interpretation of deictic gestures at targets all around the user. Through a study with 28 participants in a CVE, we analyzed the errors users make when interpreting deictic gestures. We derived a model that rotates the arm of a pointing user's avatar to improve the observing users' accuracy. A second study with 24 participants shows that we can improve observers' accuracy by 22.9\%. As our approach is not noticeable for users, it improves their accuracy without requiring them to learn a new interaction technique or distracting from the experience.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mayer, Sven and Reinhardt, Jens and Schweigert, Robin and Jelke, Brighten and Schwind, Valentin and Wolf, Katrin and Henze, Niels},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, correction model, deictic, ray tracing},
	pages = {1--14},
}

@inproceedings{chikersal_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding {Client} {Support} {Strategies} to {Improve} {Clinical} {Outcomes} in an {Online} {Mental} {Health} {Intervention}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376341},
	doi = {10.1145/3313831.3376341},
	abstract = {Online mental health interventions are increasingly important in providing access to, and supporting the effectiveness of, mental health treatment. While these technologies are effective, user attrition and early disengagement are key challenges. Evidence suggests that integrating a human supporter into such services mitigates these challenges, however, it remains under-studied how supporter involvement benefits client outcomes, and how to maximize such effects. We present our analysis of 234,735 supporter messages to discover how different support strategies correlate with clinical outcomes. We describe our machine learning methods for: (i) clustering supporters based on client outcomes; (ii) extracting and analyzing linguistic features from supporter messages; and (iii) identifying context-specific patterns of support. Our findings indicate that concrete, positive and supportive feedback from supporters that reference social behaviors are strongly associated with better outcomes; and show how their importance varies dependent on different client situations. We discuss design implications for personalized support and supporter interfaces.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Chikersal, Prerna and Belgrave, Danielle and Doherty, Gavin and Enrique, Angel and Palacios, Jorge E. and Richards, Derek and Thieme, Anja},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {ai, mental health, machine learning, cbt, data mining, digital behavioral intervention, support, unsupervised learning},
	pages = {1--16},
}

@inproceedings{desjardins_iot_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{IoT} {Data} in the {Home}: {Observing} {Entanglements} and {Drawing} {New} {Encounters}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376342},
	doi = {10.1145/3313831.3376342},
	abstract = {Internet of Things (IoT) technologies for the home are gaining in popularity, generating exponential data byproducts. Yet, everyday relationships between home dwellers and domestic IoT data often remain secondary interactions, preventing deeper understanding and awareness of data tracked in the home. Our paper offers a design ethnography and design inquiry which examine these human-data entanglements. Findings from working with 10 inhabitants who interact with their IoT data illustrate five characteristics of current data encounters: manifesting, inquiring, exposing, repositioning, and broadening. In response, we used speculative sketches to refine, refract and complicate these encounters. We argue that data do not have to be laborious, tidy or the byproduct of a service, but rather lively and affecting. We further suggest new modes of engagement with data which expand or step away from self-improvement and reflection: through diverse acts of noticing, by allowing data to remain invisible, and by embracing imaginative practices.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Desjardins, Audrey and Biggs, Heidi R. and Key, Cayla and Viny, Jeremy E.},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {home, internet of things, research-through-design, data, design ethnography, speculative},
	pages = {1--13},
}

@inproceedings{garzotto_interactive_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Interactive {Multisensory} {Environments} for {Primary} {School} {Children}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376343},
	doi = {10.1145/3313831.3376343},
	abstract = {Interactive Multi-Sensory Environments (iMSEs) are room-sized interactive installations equipped with digitally enriched physical materials and ambient embedded devices. These items can sense users' presence, gestures, movements, and manipulation, and react by providing gentle stimulation (e.g., light, sound, projections, blowing bubbles, tactile feel, aromas) to different senses. Most of prior research on iMSEs investigates their use for persons with disabilities (e.g., autism). Our work focuses on the use of iMSEs in primary education contexts and for mixed groups of young students, i.e., children with and without disability. The paper describes the latest version of an iMSE called Magic Room that has been installed in two local schools. We report two empirical studies devoted to understand how the Magic Room could be used in inclusive educational settings, and to explore its potential benefits.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Garzotto, Franca and Beccaluva, Eleonora and Gianotti, Mattia and Riccardi, Fabiano},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {children, primary school, well-being, embodied interaction, children with special needs, interactive multisensory environment, smart object, smart space},
	pages = {1--12},
}

@inproceedings{beneteau_parenting_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Parenting with {Alexa}: {Exploring} the {Introduction} of {Smart} {Speakers} on {Family} {Dynamics}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376344},
	doi = {10.1145/3313831.3376344},
	abstract = {Smart speakers have become pervasive in family homes, creating the potential for these devices to influence parent-child dynamics and parenting behaviors. We investigate the impact of introducing a smart speaker to 10 families with children, over four weeks. We use pre- and post- deployment interviews with the whole family and in-home audio capture of parent-child interactions with the smart speaker for our analysis. Despite the smart speaker causing occasional conflict in the home, we observed that parents lever-aged the smart speaker to further parenting goals. We found three forms of influence the smart speaker has on family dynamics: 1) fostering communication, 2) disrupting access, and 3) augmenting parenting. All of these influences arise from a communally accessible, stand-alone voice interface which democratizes family access to technology. We discuss design implications in furthering parenting practices and behaviors as the capabilities of the technology continue to improve.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Beneteau, Erin and Boone, Ashley and Wu, Yuxing and Kientz, Julie A. and Yip, Jason and Hiniker, Alexis},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {families, parental mediation, smart speakers, child development, parenting, voice interfaces},
	pages = {1--13},
}

@inproceedings{devendorf_making_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Making {Design} {Memoirs}: {Understanding} and {Honoring} {Difficult} {Experiences}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376345},
	doi = {10.1145/3313831.3376345},
	abstract = {Design is commonly understood as a storytelling practice, yet we have few narratives with which to describe the felt experiences of struggle, pain, and difficulty, beyond treating them as subjects to resolve. This work uses the praxis of embodied design as a way to bring more complex narratives to the community for contemplation—to engage and entangle personal and difficult stories within a public context. We propose the term Design Memoirs for these first-person practices and reflections. Design Memoirs are subjective and corporeal in nature, and provide a direct and observable way to reckon with felt experiences through, and for, design. We demonstrate Design Memoirs by drawing on our own experiences as mothers, caregivers, and corporeal subjects. Following Barad, we propose a practice of diffractive reading to locate resonances between Design Memoirs which render difficult autobiographical material addressable, shareable, and open for new interpretations. We present this strategy as a method for arriving at deeper understandings of difficult experiences.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Devendorf, Laura and Andersen, Kristina and Kelliher, Aisling},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {methodology, design research, design fiction, autobiographical design, design memoirs, motherhood},
	pages = {1--12},
}

@inproceedings{mohamed_influence_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {Influence} of {Decaying} the {Representation} of {Older} {Social} {Media} {Content} on {Simulated} {Hiring} {Decisions}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376346},
	doi = {10.1145/3313831.3376346},
	abstract = {Decaying representations gradually make social media content less visible to readers over time, which can help users disassociate from past online activities. We explore whether shrinking, one decaying representation, influences managers' assessments and simulated hiring decisions of job candidates, compared to seeing a full profile or an empty profile with no posts. Our 3 x 2 between-subjects crowdsourced survey (N = 360 US managers) shows that shrunk or empty profiles led to more positive decisions than profiles in their original full format. However, shrunk profiles also further contributed to more positive impressions of the candidates. Shrinking did not help the candidate of either gender more than the other and demographics of managers had limited impact on their assessment. Further, our managers regularly search job candidates' social media profiles in real life, suggesting that shrinking could support users' privacy. We finally present implications for individuals' privacy on social media.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mohamed, Reham and Chametka, Paulina and Chiasson, Sonia},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {online privacy, decaying representations, hiring context, online reputation management, online social networks},
	pages = {1--19},
}

@inproceedings{pierce_sensor_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Sensor {Illumination}: {Exploring} {Design} {Qualities} and {Ethical} {Implications} of {Smart} {Cameras} and {Image}/{Video} {Analytics}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376347},
	doi = {10.1145/3313831.3376347},
	abstract = {Drawing analogies between smart cameras and electric lighting, we highlight and extrapolate design trends towards always-on sensing in intimate contexts, and the functional expansion of smart cameras as general-purpose and multi-functional devices. Employing a research through design (RtD) approach, we extrapolate these trends using speculative scenarios, materialize the scenarios by designing and constructing lighting-inspired smart camera fixtures, and self-experiment with these fixtures to introduce and exacerbate privacy and security issues, and inspire creative workarounds and design opportunities for sensor-level regulation. We synthesize our insights by presenting 8 smart camera sensing design qualities for addressing privacy, security, and related social and ethical issues.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pierce, James and Wong, Richmond Y. and Merrill, Nick},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {privacy, smart home, research through design, security, iot},
	pages = {1--19},
}

@inproceedings{romat_dear_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Dear {Pictograph}: {Investigating} the {Role} of {Personalization} and {Immersion} for {Consuming} and {Enjoying} {Visualizations}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376348},
	doi = {10.1145/3313831.3376348},
	abstract = {Much of the visualization literature focuses on assessment of visual representations with regard to their effectiveness for understanding data. In the present work, we instead focus on making data visualization experiences more enjoyable, to foster deeper engagement with data. We investigate two strategies to make visualization experiences more enjoyable and engaging: personalization, and immersion. We selected pictographs (composed of multiple data glyphs) as this representation affords creative freedom, allowing people to craft symbolic or whimsical shapes of personal significance to represent data. We present the results of a qualitative study with 12 participants crafting pictographs using a large pen-enabled device and while immersed within a VR environment. Our results indicate that personalization and immersion both have positive impact on making visualizations more enjoyable experiences.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Romat, Hugo and Henry Riche, Nathalie and Hurter, Christophe and Drucker, Steven and Amini, Fereshteh and Hinckley, Ken},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {immersion, visualization, personalization, qualitative study},
	pages = {1--13},
}

@inproceedings{pandey_explore_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Explore, {Create}, {Annotate}: {Designing} {Digital} {Drawing} {Tools} with {Visually} {Impaired} {People}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376349},
	doi = {10.1145/3313831.3376349},
	abstract = {People often use text in their drawings to communicate their ideas. For visually impaired people, adding textual information to tactile graphics is challenging. Labeling in braille is a laborious process and clutters the drawings. Audio labels provide an alternative way to add text. However, digital drawing tools for visually impaired people have not examined the use of audio for creating labels. We conducted a study comprising three tasks with 11 visually impaired adults. Our goal was to understand how participants explored and created labeled tactile graphics (both braille and audio), and their interaction preferences. We find that audio labels were quicker to use and easier to create. However, braille labels enabled flexible exploration strategies. We also find that participants preferred multimodal interaction commands, and report hand postures and movements observed during the drawing process for designing recognizable interactions. Based on our findings, we derive design implications for digital drawing tools.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pandey, Maulishree and Subramonyam, Hariharan and Sasia, Brooke and Oney, Steve and O'Modhrain, Sile},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {accessibility, blind, drawing applications, tactile graphics},
	pages = {1--12},
}

@inproceedings{pena-araya_comparison_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {Comparison} of {Geographical} {Propagation} {Visualizations}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376350},
	doi = {10.1145/3313831.3376350},
	abstract = {Geographical propagation phenomena occur in multiple domains, such as in epidemiology and social media. Propagation dynamics are often complex, and visualizations play a key role in helping subject-matter experts understand and analyze them. However, there is little empirical data about the effectiveness of the various strategies used to visualize geographical propagation. To fill this gap, we conduct an experiment to evaluate the effectiveness of three strategies: an animated map, small-multiple maps, and a single map with glyphs. We compare them under five tasks that vary in one of the following dimensions: propagation scope, direction, speed, peaks, and spatial jumps. Our results show that small-multiple maps perform best overall, but that the effectiveness of each visualization varies depending on the task considered.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Peña-Araya, Vanessa and Bezerianos, Anastasia and Pietriga, Emmanuel},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {animation, geo-temporal data, propagation, small-multiples},
	pages = {1--14},
}

@inproceedings{tancred_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding {Women} {Modders} {Using} the {Serious} {Leisure} {Perspective}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376351},
	doi = {10.1145/3313831.3376351},
	abstract = {Modding, the act of custom creation in videogames, is a large enterprise comprising millions of people. Despite the large number of individuals creating mods, our understanding of who modders are and their motivation for modding is limited. This is especially true for minority groups, including women. In prior research with modding communities, women modders were consistently underrepresented. Using a mixed-method survey (N = 68) that incorporates the Serious Leisure Framework, this study begins to unravel women's participation in modding activities. We begin to identify who women modders are, examine what motivates them to mod, and investigate their modding practices. Results show that women modders value the creation of multiple mod types, including cosmetic, environmental and gameplay modification. They are primarily motivated by self-gratification and enjoyment. These findings create new insights into how women interact with gaming environments, as well as identifying those aspects of the experience that motivate women's engagement in modding.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tancred, Nicoletta and Turkay, Selen and Vickery, Nicole and Wyeth, Peta and McCoombe, Anna},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {video games, custom content, game modifications, modders, modding, serious leisure, women modding},
	pages = {1--13},
}

@inproceedings{mironcika_i_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {I {Am} {Not} an {Object}: {Reframing} {3D} {Body} {Scanning} for {Co}-{Design}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376352},
	doi = {10.1145/3313831.3376352},
	abstract = {3D scanning technologies provide designers with tools to generate a digital representation of the human body that can be used in the design of ultra-personalized apparel and wearables. However, prior work shows that the body scanning process can be an uncomfortable experience for users. In this work, we take a first-person perspective to identify frictions in the experience of being body scanned compared to having one's body measurements taken by a professional tailor. Based on our findings, we offer a reframing of body scanning as a collaborative process, and discuss implications for the design of tools and processes that shift agency in the generation of body data towards users. Our paper is relevant to design researchers and practitioners interested in taking a co-design approach to ultra-personalization.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mironcika, Svetlana and Hupfeld, Annika and Frens, Joep and Wensveen, Stephan},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {co-design, wearables, personalization, 3d body data visualization, 3d body scanning, autoethnography, personal data.},
	pages = {1--6},
}

@inproceedings{siu_virtual_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Virtual {Reality} {Without} {Vision}: {A} {Haptic} and {Auditory} {White} {Cane} to {Navigate} {Complex} {Virtual} {Worlds}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376353},
	doi = {10.1145/3313831.3376353},
	abstract = {Current Virtual Reality (VR) technologies focus on rendering visuospatial effects, and thus are inaccessible for blind or low vision users. We examine the use of a novel white cane controller that enables navigation without vision of large virtual environments with complex architecture, such as winding paths and occluding walls and doors. The cane controller employs a lightweight three-axis brake mechanism to provide large-scale shape of virtual objects. The multiple degrees-of-freedom enables users to adapt the controller to their preferred techniques and grip. In addition, surface textures are rendered with a voice coil actuator based on contact vibrations; and spatialized audio is determined based on the progression of sound through the geometry around the user. We design a scavenger hunt game that demonstrates how our device enables blind users to navigate a complex virtual environment. Seven out of eight users were able to successfully navigate the virtual room (6x6m) to locate targets while avoiding collisions. We conclude with design consideration on creating immersive non-visual VR experiences based on user preferences for cane techniques, and cane material properties.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Siu, Alexa F. and Sinclair, Mike and Kovacs, Robert and Ofek, Eyal and Holz, Christian and Cutrell, Edward},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, visual impairments, haptic feedback, 3d audio, auditory feedback, blindness, mobility, white cane},
	pages = {1--13},
}

@inproceedings{kotut_clash_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Clash of {Times}: {Respectful} {Technology} {Space} for {Integrating} {Community} {Stories} in {Intangible} {Exhibits}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376354},
	doi = {10.1145/3313831.3376354},
	abstract = {Emerging research in Human Computer Interaction (HCI) has considered the use of technology to preserve Intangible Cultural Heritage (ICH) while wrestling with the dilemma of local participation in the face of post-colonialism. There remains a need to understand how ICH is portrayed by museums and texts, how communities regard these representations, and how technology would affect preservation. We conducted a study in the North Rift region of Kenya to understand how ICH is preserved and disseminated by the museum in comparison with the community. The findings describe a respectful technology space where community needs and museum needs can co-exist. We also articulate social challenges that should be considered by designers when recommending or designing technological solutions. This paper concludes by recommending ways for researchers to smoothly integrate technology with ICH through community participation and an awareness of the respectful space.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kotut, Lindah and Bhatti, Neelma and Saaty, Morva and Haqq, Derek and Stelter, Timothy L. and McCrickard, D. Scott},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {hci4d, indigenous knowledge, intangible cultural heritage, post-colonial computing, respectful technology},
	pages = {1--13},
}

@inproceedings{porfirio_transforming_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Transforming {Robot} {Programs} {Based} on {Social} {Context}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376355},
	doi = {10.1145/3313831.3376355},
	abstract = {Social robots have varied effectiveness when interacting with humans in different interaction contexts. A robot programmed to escort individuals to a different location, for instance, may behave more appropriately in a crowded airport than a quiet library, or vice versa. To address these issues, we exploit ideas from program synthesis and propose an approach to transforming the structure of hand-crafted interaction programs that uses user-scored execution traces as input, in which end users score their paths through the interaction based on their experience. Additionally, our approach guarantees that transformations to a program will not violate task and social expectations that must be maintained across contexts. We evaluated our approach by adapting a robot program to both real-world and simulated contexts and found evidence that making informed edits to the robot's program improves user experience.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Porfirio, David and Sauppé, Allison and Albarghouthi, Aws and Mutlu, Bilge},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {human-robot interaction, interaction adaptation, model checking, program repair},
	pages = {1--12},
}

@inproceedings{markum_digital_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Digital {Technology}, {Meditative} and {Contemplative} {Practices}, and {Transcendent} {Experiences}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376356},
	doi = {10.1145/3313831.3376356},
	abstract = {Meditative and contemplative practices are common among U.S. adults, but the impact of digital technology use on these practices and on associated transcendent experiences is poorly understood. Through semi-structured interviews with sixteen experienced practitioners from a variety of traditions, we find that practitioners consider digital technology to be a mixed blessing. While they see its practical value, they are wary of its stimulation-based effects and find minimal usefulness in commercial meditation apps. They also feel that digital technology use may interfere with possible transcendent experiences. The practitioners, however, applied insights from their respective practices to strategically mitigate digital technology's negative effects in three ways: limiting its use to instrumental purposes, using technology interactions as grist for self-reflection, and integrating technology itself into a site for practice. Specific design recommendations are discussed.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Markum, Robert B. and Toyama, Kentaro},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {digital technology, meditative and contemplative practices, techno-spirituality, transcendent experiences},
	pages = {1--14},
}

@inproceedings{ryding_silent_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {The {Silent} {Conversation}: {Designing} for {Introspection} and {Social} {Play} in {Art} {Museums}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376357},
	doi = {10.1145/3313831.3376357},
	abstract = {This paper presents an attempt to design for a combination of social play and introspection using a ludic approach within an art museum setting. The field trial is described of a mobile web app called 'Never let me go', a two-player system enabling visitors to an art museum to create impromptu experiences in-situ for a companion. The study reveals that players used the app for communicating with each other during the visit, often without speaking. This led to deeply personal and introspective moments, as well as, lots of teasing and playing. The implications of allowing for social, personal and playful experiences in an art museum are discussed, as well as, the advantages and challenges of designing for improvisation.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ryding, Karin},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {social, play, mobile, experience, museums, affective, art, impromptu experience design, introspective, personalisation},
	pages = {1--10},
}

@inproceedings{yoshida_pocopo_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{PoCoPo}: {Handheld} {Pin}-{Based} {Shape} {Display} for {Haptic} {Rendering} in {Virtual} {Reality}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376358},
	doi = {10.1145/3313831.3376358},
	abstract = {We introduce PoCoPo, the first handheld pin-based shape display that can render various 2.5D shapes in hand in realtime. We designed the display small enough for a user to hold it in hand and carry it around, thereby enhancing the haptic experiences in a virtual environment. PoCoPo has 18 motor-driven pins on both sides of a cuboid, providing the sensation of skin contact on the user's palm and fingers. We conducted two user studies to understand the capability of PoCoPo. The first study showed that the participants were generally successful in distinguishing the shapes rendered by PoCoPo with an average success rate of 88.5\%. In the second study, we investigated the acceptable visual size of a virtual object when PoCoPo rendered a physical object of a certain size. The result led to a better understanding of the acceptable differences between the perceptions of visual size and haptic size.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Yoshida, Shigeo and Sun, Yuqian and Kuzuoka, Hideaki},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {virtual reality, handheld device, haptic device, shape display},
	pages = {1--13},
}

@inproceedings{jo_understanding_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Understanding {Parenting} {Stress} through {Co}-{Designed} {Self}-{Trackers}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376359},
	doi = {10.1145/3313831.3376359},
	abstract = {New parents often experience significant stress as they take on new roles and responsibilities. Stress management and mental wellbeing are two areas in which personal informatics (PI) research has gained attention, and there is an opportunity to investigate how parenting stress can be mitigated through PI practices. In this paper, we present the results of a co-designed technology probe study through which we deployed individualized self-trackers with new parents. We investigate the stress management topics new parents are interested in tracking and how — and with what goals—they engage in self-directed PI practices. Our findings indicate that PI practices can potentially enable parents to: re-discover positive aspects of their everyday lives; identify better-suited stress management strategies; and facilitate spousal communication about shared responsibilities. We discuss how self-tracking experiences for the mental wellness of parents can be better designed.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jo, Eunkyung and Toombs, Austin L. and Gray, Colin M. and Hong, Hwajung},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {co-design, self-tracking, personal informatics, parenting, new parents, stress management},
	pages = {1--13},
}

@inproceedings{schubhan_investigating_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Investigating {User}-{Created} {Gamification} in an {Image} {Tagging} {Task}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376360},
	doi = {10.1145/3313831.3376360},
	abstract = {Commonly, gamification is designed by developers and not by end-users. In this paper we investigate an approach where users take control of this process. Firstly, users were asked to describe their own gamification concepts which would motivate them to put more effort into an image tagging task. We selected this task as gamification has already been shown to be effective here in previous work. Based on these descriptions, an implementation was made for each concept and given to the creator. In a between-subjects study (n=71), our approach was compared to a no-gamification condition and two conditions with fixed gamification settings. We found that providing participants with an implementation of their own concept significantly increased the amount of generated tags compared to the other conditions. Although the quality of tags was lower, the number of usable tags remained significantly higher in comparison, suggesting the usefulness of this approach.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Schubhan, Marc and Altmeyer, Maximilian and Buchheit, Dominic and Lessel, Pascal},
	year = {2020},
	note = {event-place: Honolulu, HI, USA},
	keywords = {motivation, customization, bottom-up, replication, user-driven game design},
	pages = {1--12},
}

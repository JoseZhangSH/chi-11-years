@inproceedings{10.1145/3251721,
author = {Tsandilas, Theophanis},
title = {Session Details: Understanding &amp; Extending Touch Interfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251721},
doi = {10.1145/3251721},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702607,
author = {Bachynskyi, Myroslav and Palmas, Gregorio and Oulasvirta, Antti and Steimle, J\"{u}rgen and Weinkauf, Tino},
title = {Performance and Ergonomics of Touch Surfaces: A Comparative Study Using Biomechanical Simulation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702607},
doi = {10.1145/2702123.2702607},
abstract = {Although different types of touch surfaces have gained extensive attention in HCI,
this is the first work to directly compare them for two critical factors: performance
and ergonomics. Our data come from a pointing task (N=40) carried out on five common
touch surface types: public display (large, vertical, standing), tabletop (large,
horizontal, seated), laptop (medium, adjustably tilted, seated), tablet (seated, in
hand), and smartphone (single- and two-handed input). Ergonomics indices were calculated
from biomechanical simulations of motion capture data combined with recordings of
external forces. We provide an extensive dataset for researchers and report the first
analyses of similarities and differences that are attributable to the different postures
and movement ranges.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1817–1826},
numpages = {10},
keywords = {pointing study, touchscreen surfaces, touch input, fitts' law, comparative study, biomechanical simulation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702300,
author = {Deber, Jonathan and Jota, Ricardo and Forlines, Clifton and Wigdor, Daniel},
title = {How Much Faster is Fast Enough? User Perception of Latency &amp; Latency Improvements in Direct and Indirect Touch},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702300},
doi = {10.1145/2702123.2702300},
abstract = {This paper reports on two experiments designed to further our understanding of users'
perception of latency in touch- based systems. The first experiment extends previous
efforts to measure latency perception by reporting on a unified study in which direct
and indirect form-factors are compared for both tapping and dragging tasks. Our results
show significant effects from both form-factor and task, and inform system designers
as to what input latencies they should aim to achieve in a variety of system types.
A follow-up experiment investigates peoples' ability to perceive small improvements
to latency in direct and indirect form-factors for tapping and dragging tasks. Our
results provide guidance to system designers of the relative value of making improvements
in latency that reduce but do not fully eliminate lag from their systems.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1827–1836},
numpages = {10},
keywords = {latency, multi-touch, touch, direct vs indirect input, jnd study},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702439,
author = {Avrahami, Daniel},
title = {The Effect of Edge Targets on Touch Performance},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702439},
doi = {10.1145/2702123.2702439},
abstract = {Edge targets, such as buttons or menus along the edge of a screen, are known to afford
fast acquisition performance in desktop mousing environments. As the popularity of
touch-based devices continues to grow, understanding the affordances of edge targets
on touchscreen is needed. This paper describes results from two controlled experiments
that examine in detail the effect of edge targets on performance in touch devices.
The results show that on touch devices, a target's proximity to the edge may have
a significant negative effect on reaction time. We examine the effect in detail and
explore mitigating factors. We discuss potential explanations for the effect and propose
implications for the design of efficient interfaces for touch devices.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1837–1846},
numpages = {10},
keywords = {target acquisition, human performance, touch, edge targets},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702582,
author = {Tung, Ying-Chao and Cheng, Ta Yang and Yu, Neng-Hao and Wang, Chiuan and Chen, Mike Y.},
title = {FlickBoard: Enabling Trackpad Interaction with Automatic Mode Switching on a Capacitive-Sensing Keyboard},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702582},
doi = {10.1145/2702123.2702582},
abstract = {We present FlickBoard, which combines a touchpad and a keyboard into the same interaction
area to reduce hand movement between a separate keyboard and touchpad. Our main contribution
is automatic mode switching between typing and pointing, and the first system capable
of combining a trackpad and a keyboard into an single interaction area without the
need for external switches. We developed a prototype by embedding a 58x20 capacitive
sensing grid into a soft keyboard cover, and used machine learning to distinguish
between moving a cursor (touchpad mode) and entering text (keyboard mode). We conducted
experimental studies that show automatic mode switching classification accuracies
of 98% are achievable with our technology. Finally, our prototype has a thin profile
and can be placed over existing keyboards.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1847–1850},
numpages = {4},
keywords = {keyboard, co-located input devices, touchpad},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702500,
author = {Kato, Kunihiro and Miyashita, Homei},
title = {ExtensionSticker: A Proposal for a Striped Pattern Sticker to Extend Touch Interfaces and Its Assessment},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702500},
doi = {10.1145/2702123.2702500},
abstract = {In this study, we propose a striped pattern sticker called ExtensionSticker that allows
a touch input to be transferred from an external source by simply attaching the sticker
to a touch panel. This allows the user to input touches or continuous scrolling actions
by touching a sticker printed with stripes of conductive ink, without directly touching
the touch panel. This method could be applied to the sides or back of a touch panel,
or even the surface upon which a device is located as a touch interface, allowing
us to freely construct interfaces in shapes matching the demands of the user. This
paper also reports the results of evaluation experiments conducted to assess the recognition
accuracy of scroll and tap actions using the proposed method.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1851–1854},
numpages = {4},
keywords = {striped pattern sticker, conductive ink, capacitive touch panel, continuous touch input},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251722,
author = {Drucker, Steven},
title = {Session Details: Sharing &amp; Collaboration @ Work},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251722},
doi = {10.1145/3251722},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702233,
author = {Nebeling, Michael and Geel, Matthias and Syrotkin, Oleksiy and Norrie, Moira C.},
title = {MUBox: Multi-User Aware Personal Cloud Storage},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702233},
doi = {10.1145/2702123.2702233},
abstract = {Personal cloud services such as Dropbox are used increasingly to support collaborative
work, even though they typically have poor support for tracking files and users' activities
and collaborators often rely on other communication channels to be notified of changes.
We present a meta-cloud storage service, MUBox, that, independent of a particular
cloud storage service, provides improved support for collaboration. First, users can
switch to activity views that list user activities rather than files, which is an
example of an increasingly available feature in popular cloud storage clients. Second,
MUBox introduces multi-user aware folder views that embed information on the last
changes performed by collaborators. These folder views are enhanced based on a new
concept of shadow files which act as placeholders for files that have been moved or
renamed. A user study (N=16) with realistic folder exploration tasks shows that activity
views have a significant effect on the accuracy and confidence of users in workspace
awareness tasks, while shadow files significantly improve the speed, accuracy and
confidence of users in traceability tasks. We describe how existing services could
implement these features as well as a new concept for voting on changes to shared
folders that could improve asynchronous collaboration.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1855–1864},
numpages = {10},
keywords = {file traceability, personal cloud storage, collaborative work, workspace awareness},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702517,
author = {Wang, Dakuo and Olson, Judith S. and Zhang, Jingwen and Nguyen, Trung and Olson, Gary M.},
title = {DocuViz: Visualizing Collaborative Writing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702517},
doi = {10.1145/2702123.2702517},
abstract = {Collaborative writing is on the increase. In order to write well together, authors
often need to be aware of who has done what recently. We offer a new tool, DocuViz,
that displays the entire revision history of Google Docs, showing more than the one-step-at-a-time
view now shown in revision history and tracking changes in Word. We introduce the
tool and present cases in which the tool has the potential to be useful: To authors
themselves to see recent "seismic activity," indicating where in particular a co-author
might want to pay attention, to instructors to see who has contributed what and which
changes were made to comments from them, and to researchers interested in the new
patterns of collaboration made possible by simultaneous editing capabilities.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1865–1874},
numpages = {10},
keywords = {collaborative writing, concurrent editing., groupware, revision histories, collaboration, google docs, information visualizations, co-authoring},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702366,
author = {Blomkvist, Johan Kaj and Persson, Johan and \r{A}berg, Johan},
title = {Communication through Boundary Objects in Distributed Agile Teams},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702366},
doi = {10.1145/2702123.2702366},
abstract = {Personal communication between User-Centered Design (UCD) specialists and developers
is important for communicating user needs and design solutions in agile development.
In distributed projects where opportunities for personal communication are limited,
the design documentation is an important surrogate. This study has investigated the
perceived effectiveness of boundary objects in a distributed agile team, and their
role in communicating target user needs. Six in-depth interviews with UCD specialists
showed that the boundary objects rarely communicate underlying needs of the users
but rather focus on interaction with the system that is being developed. The used
boundary objects also do not work as stand-alone deliverables; they need to be explained
and elaborated. Making the boundary objects comprehensive enough to be stand-alone
is seen as too time consuming and not worth the effort. For agile projects with distributed
teams, this creates hand-over and follow-up problems.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1875–1884},
numpages = {10},
keywords = {agile development, boundary objects, distributed projects, communication, user-centered design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702307,
author = {Pritchard, Gary W. and Briggs, Pam and Vines, John and Olivier, Patrick},
title = {How to Drive a London Bus: Measuring Performance in a Mobile and Remote Workplace},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702307},
doi = {10.1145/2702123.2702307},
abstract = {This paper examines how London bus drivers have responded to performance monitoring
via a telematics device called Drivewell. This device calculates a score based on
various recordable driving-related events like abrupt braking or irregular turning
actions. Our qualitative methodology incorporated semi-structured interviews and ethnographic
fieldwork, in order to explore drivers' attitudes towards the system and its effect
on driving behaviour and working conditions. Our findings illustrate how bus operators
simultaneously accommodate and resist the demands Drivewell places upon them. Our
work also demonstrates how this digital intervention acts in conjunction with other
driver-related technologies, creating a unique digital ecosystem on the modern London
bus. Our research contributes to HCI understandings of digital surveillance and performance
monitoring in the modern workplace.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1885–1894},
numpages = {10},
keywords = {ethnography, telematics, workplace surveillance, event monitoring, public transport},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251723,
author = {Marlow, Jennifer},
title = {Session Details: Families and Their Use of Technology},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251723},
doi = {10.1145/3251723},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702325,
author = {Ammari, Tawfiq and Kumar, Priya and Lampe, Cliff and Schoenebeck, Sarita},
title = {Managing Children's Online Identities: How Parents Decide What to Disclose about Their Children Online},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702325},
doi = {10.1145/2702123.2702325},
abstract = {While extensive research has investigated the risks of children sharing their personal
information online, little work has investigated the implications of parents sharing
personal information about their children online. Drawing on 102 interviews with parents
in the U.S., we investigate how parents decide what to disclose about their children
on social network sites (SNSs). We find that mothers take on the responsibility of
sharing content about their children more than fathers do. Fathers are more restrictive
about sharing to broad and professional audiences and are concerned about sharing
content that could be perceived as sexually suggestive. Both mothers and fathers work
to leverage affordances of SNSs to limit oversharing. Building on prior work, we explore
parental disclosure management, which describes how parents decide what to share about
their children online. We also describe an emerging third shift of work that highlights
the additional work parents take on to manage children's identities online. We conclude
with theoretical and practical implications for designing SNSs to better support family
life online.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1895–1904},
numpages = {10},
keywords = {work, parenting, fathers, internet, mothers, social media},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702205,
author = {Ammari, Tawfiq and Schoenebeck, Sarita},
title = {Understanding and Supporting Fathers and Fatherhood on Social Media Sites},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702205},
doi = {10.1145/2702123.2702205},
abstract = {Fathers are taking on more childcare and household responsibilities than they used
to and many non-profit and government organizations have pushed for changes in policies
to support fathers. Despite this effort, little research has explored how fathers
go online related to their roles as fathers. Drawing on an interview study with 37
fathers, we find that they use social media to document and archive fatherhood, learn
how to be a father, and access social support. They also go online to support diverse
family needs, such as single fathers' use of Reddit instead of Facebook, fathers raised
by single mothers' search for role models online, and stay-at-home fathers' use of
father blogs. However, fathers are constrained by privacy concerns and perceptions
of judgment relating to sharing content online about their children. Drawing on theories
of fatherhood, we present theoretical and design ideas for designing online spaces
to better support fathers and fatherhood. We conclude with a call for a research agenda
to support fathers online.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1905–1914},
numpages = {10},
keywords = {social media, internet, parents, fathers},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702266,
author = {Hourcade, Juan Pablo and Mascher, Sarah L. and Wu, David and Pantoja, Luiza},
title = {Look, My Baby Is Using an IPad! An Analysis of YouTube Videos of Infants and Toddlers Using Tablets},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702266},
doi = {10.1145/2702123.2702266},
abstract = {We know very little about the use of computers by children under the age of three.
While few children in that age range used computers before the advent of smartphones
and tablets, these devices have made computers much more accessible to infants and
toddlers. In this paper, we provide a window into how these children are using tablets
through an analysis of relevant YouTube videos. A majority of children aged 12 to
17 months in the videos in our dataset showed at least moderate ability to use the
tablets. For children aged two, it was over 90 percent who displayed at least moderate
ability. Our analysis also includes trends in interaction styles, child and device
positioning, social aspects, and app genres. These findings point both to opportunities
for research and starting points for design.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1915–1924},
numpages = {10},
keywords = {mobile device, toddler, touchscreen, tablet, young child, android, baby, infant, ipad},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251724,
author = {Lee, Uichin},
title = {Session Details: Understanding Crowdwork in Many Domains},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251724},
doi = {10.1145/3251724},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702565,
author = {Lasecki, Walter S. and Kim, Juho and Rafter, Nick and Sen, Onkur and Bigham, Jeffrey P. and Bernstein, Michael S.},
title = {Apparition: Crowdsourced User Interfaces That Come to Life as You Sketch Them},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702565},
doi = {10.1145/2702123.2702565},
abstract = {Prototyping allows designers to quickly iterate and gather feedback, but the time
it takes to create even a Wizard-of-Oz prototype reduces the utility of the process.
In this paper, we introduce crowdsourcing techniques and tools for prototyping interactive
systems in the time it takes to describe the idea. Our Apparition system uses paid
microtask crowds to make even hard-to-automate functions work immediately, allowing
more fluid prototyping of interfaces that contain interactive elements and complex
behaviors. As users sketch their interface and describe it aloud in natural language,
crowd workers and sketch recognition algorithms translate the input into user interface
elements, add animations, and provide Wizard-of-Oz functionality. We discuss how design
teams can use our approach to reflect on prototypes or begin user studies within seconds,
and how, over time, Apparition prototypes can become fully-implemented versions of
the systems they simulate. Powering Apparition is the first self-coordinated, real-time
crowdsourcing infrastructure. We anchor this infrastructure on a new, lightweight
write-locking mechanism that workers can use to signal their intentions to each other.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1925–1934},
numpages = {10},
keywords = {rapid prototyping, crowdsourcing, human computation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702416,
author = {Laput, Gierad and Lasecki, Walter S. and Wiese, Jason and Xiao, Robert and Bigham, Jeffrey P. and Harrison, Chris},
title = {Zensors: Adaptive, Rapidly Deployable, Human-Intelligent Sensor Feeds},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702416},
doi = {10.1145/2702123.2702416},
abstract = {The promise of "smart" homes, workplaces, schools, and other environments has long
been championed. Unattractive, however, has been the cost to run wires and install
sensors. More critically, raw sensor data tends not to align with the types of questions
humans wish to ask, e.g., do I need to restock my pantry? Although techniques like
computer vision can answer some of these questions, it requires significant effort
to build and train appropriate classifiers. Even then, these systems are often brittle,
with limited ability to handle new or unexpected situations, including being repositioned
and environmental changes (e.g., lighting, furniture, seasons). We propose Zensors,
a new sensing approach that fuses real-time human intelligence from online crowd workers
with automatic approaches to provide robust, adaptive, and readily deployable intelligent
sensors. With Zensors, users can go from question to live sensor feed in less than
60 seconds. Through our API, Zensors can enable a variety of rich end-user applications
and moves us closer to the vision of responsive, intelligent environments.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1935–1944},
numpages = {10},
keywords = {computer vision, end-user programming, human computation, sensing, smart environments},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702605,
author = {Lasecki, Walter S. and Gordon, Mitchell and Leung, Winnie and Lim, Ellen and Bigham, Jeffrey P. and Dow, Steven P.},
title = {Exploring Privacy and Accuracy Trade-Offs in Crowdsourced Behavioral Video Coding},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702605},
doi = {10.1145/2702123.2702605},
abstract = {Coding behavioral video is an important method used by researchers to understand social
phenomenon. Unfortunately, traditional hand-coding approaches can take days or weeks
of time to complete. Recent work has shown that these tasks can be completed quickly
by leveraging the parallelism of large online crowds, but using the crowd introduces
new concerns about accuracy, reliability, privacy, and cost. To explore these issues,
we conducted interviews with 12 researchers who frequently code behavioral video,
to investigate common practices and challenges with video coding. We find accuracy
and privacy to be the researchers' primary concerns. To explore this more concretely,
we used sample videos to investigate whether crowds can accurately recognize instances
of commonly coded behaviors, and show that the crowd yields accurate results. Then,
we demonstrate a method for obfuscating participant identity with a video blur filter,
and find, as expected, that workers' ability to identify participants decreases as
blur level increases. The workers' ability to accurately and reliably code behaviors
also decreases, but not as steeply as the identity test. This trade-off between coding
quality and privacy protection suggests that researchers can use online crowds to
code for some key behaviors in video without compromising participant identity. We
conclude with a discussion of how researchers can balance privacy and accuracy on
their own data using a system we introduce called Incognito.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1945–1954},
numpages = {10},
keywords = {subjective coding, video, crowdsourcing, data analysis},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702151,
author = {Otterbacher, Jahna},
title = {Crowdsourcing Stereotypes: Linguistic Bias in Metadata Generated via GWAP},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702151},
doi = {10.1145/2702123.2702151},
abstract = {Games with a Purpose (GWAP) is a popular approach for metadata creation, enabling
institutions to collect descriptions of digital artifacts on a mass scale. Creating
metadata is challenging not only because one must recognize the artifact; the description
must then be encoded into natural language. Language behaviors are influenced by many
social factors, particularly when we are asked to describe other people. We consider
labels for images of people generated via the ESP Game. While ESP has been shown to
produce relevant labels, critics claim they are obvious and stereotypical. Based on
theories of linguistic biases, we examine whether there are systematic differences
in the ways players describe images of men versus women. Our first analysis considers
images of people generally, and reveals a tendency for women to be described with
subjective adjectives. A second analysis compares images depicting men and women within
each of six occupational roles. Images of women receive more labels related to appearance,
whereas those depicting men receive more occupation-related labels. Our work exposes
the presence of gender-based stereotypes through linguistic biases, illustrates the
forms in which they manifest, and raises important implications for those who design
systems or train algorithms using data produced via GWAP.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1955–1964},
numpages = {10},
keywords = {subjective language, linguistic bias, crowdsourcing, gender, stereotypes, metadata, games with a purpose},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251725,
author = {Irwin, Germaine},
title = {Session Details: Eco-Green: Encouraging Energy Conservation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251725},
doi = {10.1145/3251725},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702285,
author = {Simm, Will and Ferrario, Maria Angela and Friday, Adrian and Newman, Peter and Forshaw, Stephen and Hazas, Mike and Dix, Alan},
title = {Tiree Energy Pulse: Exploring Renewable Energy Forecasts on the Edge of the Grid},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702285},
doi = {10.1145/2702123.2702285},
abstract = {In many parts of the world, the electricity supply industry makes the task of dealing
with unpredictable spikes and dips in production and demand invisible to consumers,
maintaining a seemingly unlimited supply. A future increase in reliance on time-variable
renewable sources of electricity may lead to greater fluctuations in supply. We engaged
remote islanders as equal partners in a research project that investigated through
technology-mediated enquiry the topic of synchronising energy consumption with supply,
and together built a prototype renewable energy forecast display. A number of participants
described a change in their practices, saving high energy tasks for times when local
renewable energy was expected to be available, despite having no financial incentive
to do so. The main contributions of this paper are in: 1) the results of co-development
sessions exploring systems supporting synchronising consumption with supply and 2)
the findings arising from the deployment of the prototype.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1965–1974},
numpages = {10},
keywords = {social innovation, electricity, sustainability, energy, forecast, renewable energy},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702364,
author = {Sugarman, Valerie and Lank, Edward},
title = {Designing Persuasive Technology to Manage Peak Electricity Demand in Ontario Homes},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702364},
doi = {10.1145/2702123.2702364},
abstract = {When it comes to environmental sustainability, the time that electricity is consumed
matters. For example, using an air conditioner on a hot summer afternoon as the power
grid is strained necessitates the use of more polluting sources to meet demand. In
this paper, we analyze end-user response to two utility-driven conservation programs
in Ontario, Canada: Time-of-Use pricing and the peaksaver program. We find that time-of-use
pricing encourages shifting some electricity demand, but only when it is convenient.
We also find that while potentially effective at a larger scale, the peaksaver program
in its current form is unattractive to participants. These results are discussed in
the context of Fogg's Behavior Model for Persuasive Design, which allows us to explore
the design space for improvement to these programs and ground our design implications
for the design of technologies to encourage reduction of peak electricity demand.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1975–1984},
numpages = {10},
keywords = {sustainability, persuasive technology, peak electricity load, design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702318,
author = {Kjeldskov, Jesper and Skov, Mikael B. and Paay, Jeni and Lund, Dennis and Madsen, Tue and Nielsen, Michael},
title = {Eco-Forecasting for Domestic Electricity Use},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702318},
doi = {10.1145/2702123.2702318},
abstract = {Over the past decade we have seen an increased awareness about domestic energy consumption
and a growing focus on eco-feedback displays. In this paper we explore the concept
of providing forecasts in such displays as a supplement to information about past
usage. Our prototype, eForecast, extends the display of past electricity usage with
forecasts about expected usage, electricity price, availability of wind power, and
expected demand drops and peaks. Building on previous eco-feedback display research,
our approach specifically enables people to use electricity at more opportune times
-- when it is cheap, green, or when there is an abundance of capacity. We evaluated
eForecast in real world use in three domestic households for 22 weeks, where we explored
potentials and limitations of forecasting for shifting electricity consumption. In
this way, families were able to act in a more sustainable way -- without necessarily
reducing the amount of electricity consumed.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1985–1988},
numpages = {4},
keywords = {domestic, sustainability, forecasting, energy consumption},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702268,
author = {Yun, Ray and Aziz, Azizan and Scupelli, Peter and Lasternas, Bertrand and Zhang, Chenlu and Loftness, Vivian},
title = {Beyond Eco-Feedback: Adding Online Manual and Automated Controls to Promote Workplace Sustainability},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702268},
doi = {10.1145/2702123.2702268},
abstract = {Whereas eco-feedback has been widely studied in HCI and environmental psychology,
online manual control and automated control have been rarely studied with a focus
on their long-term quantitative impact and usability. To address this, an intervention
was tested with eighty office workers for twenty-seven weeks. Through the long-term
field test, it was found that the addition of online controls in the feedback intervention
led to more energy savings than feedback only and worked better for light and phone
usage than computer and monitor usage. The addition of automated control led to the
greatest savings but was less effective for efficient users than inefficient ones.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1989–1992},
numpages = {4},
keywords = {automated control, workplace, energy dashboard, online control, energy feedback, sustainability, behavior change},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702528,
author = {Mauriello, Matthew Louis and Norooz, Leyla and Froehlich, Jon E.},
title = {Understanding the Role of Thermography in Energy Auditing: Current Practices and the Potential for Automated Solutions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702528},
doi = {10.1145/2702123.2702528},
abstract = {The building sector accounts for 41% of primary energy consumption in the US, contributing
an increasing portion of the country's carbon dioxide emissions. With recent sensor
improvements and falling costs, auditors are increasingly using thermography-infrared
(IR) cameras-to detect thermal defects and analyze building efficiency. Research in
automated thermography has grown commensurately, aimed at reducing manual labor and
improving thermal models. Though promising, we could find no prior work exploring
the professional auditor's perspectives of thermography or reactions to emerging automation.
To address this gap, we present results from two studies: a semi-structured interview
with 10 professional energy auditors, which includes design probes of five automated
thermography scenarios, and an observational case study of a residential audit. We
report on common perspectives, concerns, and benefits related to thermography and
summarize reactions to our automated scenarios. Our findings have implications for
thermography tool designers as well as researchers working on automated solutions
in robotics, computer science, and engineering.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1993–2002},
numpages = {10},
keywords = {robotics, sustainable hci, thermography, energy audits, formative inquiry, design probes, human-robotic interaction},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251726,
author = {Chu, Hao-Hua},
title = {Session Details: Sports Tracking &amp; Training},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251726},
doi = {10.1145/3251726},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702243,
author = {Jensen, Mads M\o{}ller and Rasmussen, Majken K. and Mueller, Florian "Floyd" and Gr\o{}nb\ae{}k, Kaj},
title = {Keepin' It Real: Challenges When Designing Sports-Training Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702243},
doi = {10.1145/2702123.2702243},
abstract = {Using game elements and mechanics in sports training holds great potential for increasing
player enjoyment, but also introduces a risk of reducing training relevance. This
paper describes a novel training installation for individual handball training, called
"The Bouncer", and the design process behind three training games. In order to investigate
how game elements can affect the training experience, we conducted a study with 10
experienced amateur handball players, eliciting responses regarding the training relevance
of the games. Based on the study and our design insights, we propose three challenges
that designers of interactive sports-training games need to consider: 1) Maintaining
relevance when translating physical elements into digital representations. 2) Choosing
an appropriate level of sensing as game input. 3) Introducing points in training exercises
without reducing sport relevance. For the three challenges, we propose strategies
to help future designers of training games.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2003–2012},
numpages = {10},
keywords = {exergames, human-computer interaction, exertion interfaces, sports, interactive sports-training games, handball},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702542,
author = {Knaving, Kristina and Wo\'{z}niak, Pawe\l{} and Fjeld, Morten and Bj\"{o}rk, Staffan},
title = {Flow is Not Enough: Understanding the Needs of Advanced Amateur Runners to Design Motivation Technology},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702542},
doi = {10.1145/2702123.2702542},
abstract = {Motivation studies on running are often focused on how to convince non-runners to
run, mainly through designing for extrinsic motivations such as health concerns or
external reward systems. In contrast, we conducted a structured inquiry into understanding
how to design technology for those whom are already committed to running and participate
in organized races. Through interviews, focus groups, ethnographic observation, questionnaires,
and design-based research over the course of two years, we investigated the needs
of the advanced amateur runner community. An analysis of the gathered data led to
five design themes -- Festival, Competition, Practicalities, Togetherness, and Support
-- to inform future runner motivation technology. While flow theory appears to be
a convenient tool to understand support during a race, we observed a number of other
factors that need to be considered. Through combining the themes with previous research,
we conclude by presenting nine guidelines for designing technology for this domain.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2013–2022},
numpages = {10},
keywords = {engagement, running, intrinsic motivation, motivation, design guidelines},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702472,
author = {Mueller, Florian 'Floyd' and Muirhead, Matthew},
title = {Jogging with a Quadcopter},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702472},
doi = {10.1145/2702123.2702472},
abstract = {Jogging is a popular exertion activity. The abundance of jogging apps suggests to
us that joggers can appreciate the opportunity for technology to support the jogging
experience. We want to take this investigation a step further by exploring if, and
how, robotic systems can support the jogging experience. We designed and built a flying
robotic system, a quadcopter, as a jogging companion and studied its use with 13 individual
joggers. By analyzing their experiences, we derived three design dimensions that describe
a design space for flying robotic jogging companions: Perceived Control, Focus and
Bodily Interaction. Additionally, we articulate a series of design tactics, described
by these dimensions, to guide the design of future systems. With this work we hope
to inspire and guide designers interested in creating robotic systems to support exertion
experiences.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2023–2032},
numpages = {10},
keywords = {running, movement-based play, exertion, sports, quadcopter, jogging, whole-body interaction, robot},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702311,
author = {Kosmalla, Felix and Daiber, Florian and Kr\"{u}ger, Antonio},
title = {ClimbSense: Automatic Climbing Route Recognition Using Wrist-Worn Inertia Measurement Units},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702311},
doi = {10.1145/2702123.2702311},
abstract = {Today, sports and activity trackers are ubiquitous. Especially runners and cyclists
have a variety of possibilities to record and analyze their workouts. In contrast,
climbing did not find much attention in consumer electronics and human-computer interaction.
If quantified data similar to cycling or running data were available for climbing,
several applications would be possible, ranging from simple training diaries to virtual
coaches or usage analytics for gym operators. This paper introduces a system that
automatically recognizes climbed routes using wrist-worn inertia measurement units
(IMUs). This is achieved by extracting features of a recorded ascent and use them
as training data for the recognition system. To verify the recognition system, cross-validation
methods were applied to a set of ascent recordings that were assessed during a user
study with eight climbers in a local climbing gym. The evaluation resulted in a high
recognition rate, thus proving that our approach is possible and operational.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2033–2042},
numpages = {10},
keywords = {machine learning, climbing, sports technologies, inertial sensors},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251727,
author = {Wang, Rongrong},
title = {Session Details: Feeling &amp; Communicating Emotions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251727},
doi = {10.1145/3251727},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702288,
author = {Akshita and Alagarai Sampath, Harini and Indurkhya, Bipin and Lee, Eunhwa and Bae, Yudong},
title = {Towards Multimodal Affective Feedback: Interaction between Visual and Haptic Modalities},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702288},
doi = {10.1145/2702123.2702288},
abstract = {We explored how emotional cues presented in visual and haptic modalities interact.
We constructed an affective haptic dataset, and used the emotional visual stimuli
from the International Affective Picture System (IAPS). Participants were asked to
rate the visual stimuli, haptic stimuli and visualhaptic stimuli. Analysis of the
results indicates that the presence of haptic stimulus affects the arousal of the
visual stimulus, but does not affect the valence significantly. We further explored
this interaction in terms of the intensity, frequency, waveform and rhythm of the
haptic stimuli. We then provide a set of guidelines on visual-haptic interaction that
could be used in design of multimodal affective feedback.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2043–2052},
numpages = {10},
keywords = {haptics, multimodal affective feedback, visual haptic interaction},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inbook{10.1145/2702123.2702361,
author = {Obrist, Marianna and Subramanian, Sriram and Gatti, Elia and Long, Benjamin and Carter, Thomas},
title = {Emotions Mediated Through Mid-Air Haptics},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702361},
abstract = {Touch is a powerful vehicle for communication between humans. The way we touch (how)
embraces and mediates certain emotions such as anger, joy, fear, or love. While this
phenomenon is well explored for human interaction, HCI research is only starting to
uncover the fine granularity of sensory stimulation and responses in relation to certain
emotions. Within this paper we present the findings from a study exploring the communication
of emotions through a haptic system that uses tactile stimulation in mid-air. Here,
haptic descriptions for specific emotions (e.g., happy, sad, excited, afraid) were
created by one group of users to then be reviewed and validated by two other groups
of users. We demonstrate the non-arbitrary mapping between emotions and haptic descriptions
across three groups. This points to the huge potential for mediating emotions through
mid-air haptics. We discuss specific design implications based on the spatial, directional,
and haptic parameters of the created haptic descriptions and illustrate their design
potential for HCI based on two design ideas.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2053–2062},
numpages = {10}
}

@inproceedings{10.1145/2702123.2702219,
author = {Wilson, Graham and Davidson, Gavin and Brewster, Stephen A.},
title = {In the Heat of the Moment: Subjective Interpretations of Thermal Feedback During Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702219},
doi = {10.1145/2702123.2702219},
abstract = {Research has shown that thermal feedback can be an engaging and convincing means of
conveying experimenter-predefined meanings, e.g., material properties or message types.
However, thermal perception is subjective and its meaning in interaction can be ambiguous.
Interface designers may not be sure how users could na\"{\i}vely interpret thermal feedback
during interaction. Little is also known about how users would choose thermal cues
to convey their own meanings. The research in this paper tested subjective interpretations
of thermal stimuli in three different scenarios: social media activity, a colleague's
presence and the extent of use of digital content. Participants were also asked to
assign their own thermal stimuli to personal experiences, to help us understand what
kinds of stimuli people associate with different meanings. The results showed strong
agreement among participants concerning what warmth (presence, activity, quality)
and cool mean (absence, poor quality). Guidelines for the design of thermal feedback
are presented to help others create effective thermal interfaces.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2063–2072},
numpages = {10},
keywords = {thermal feedback, mobile interaction, interaction design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702510,
author = {Valtchanov, Deltcho and Hancock, Mark},
title = {EnviroPulse: Providing Feedback about the Expected Affective Valence of the Environment},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702510},
doi = {10.1145/2702123.2702510},
abstract = {Interacting with nature is beneficial to a person's mental-state, but it can sometimes
be difficult to find environments that will induce positive affect (e.g., when planning
a run). In this paper, we describe EnviroPulse-a system for auto-matically determining
and communicating the expected affective valence (EAV) of environments to individuals.
We describe a prototype that allows this to be used in real-time on a smartphone,
but EnviroPulse could easily be incorporated into GPS systems, mapping services, or
image-based systems. Our work differs from existing work in af-fective computing in
that, rather than detecting a user's affect directly, we automatically determine the
EAV of the environment through visual analysis. We present results that suggest our
system can determine the EAV of envi-ronments. We also introduce real-time affective
visual feedback of the calculated EAV of the images, and present results from an informal
study suggesting that real-time visual feedback can be used for induction of affect.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2073–2082},
numpages = {10},
keywords = {human factors, affective computing, mobile interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251728,
author = {Jacucci, Giulio},
title = {Session Details: Critical Design},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251728},
doi = {10.1145/3251728},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702438,
author = {Pierce, James and Sengers, Phoebe and Hirsch, Tad and Jenkins, Tom and Gaver, William and DiSalvo, Carl},
title = {Expanding and Refining Design and Criticality in HCI},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702438},
doi = {10.1145/2702123.2702438},
abstract = {The term 'critical design' is on the upswing in HCI. We analyze how discourses around 'critical design' are diverging in Design and HCI. We argue that this divergence undermines
HCI's ability to learn from and appropriate the design approaches signaled by this
term. Instead, we articulate two ways to broaden and deepen connections between Design
and HCI: (1) develop a broader collective understanding of what these design approaches
can be, without forcing them to be about 'criticality' or 'critical design,' narrowly
construed; and (2) shape a variation of design criticism to better meet Design practices,
terms, and ways of knowing.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2083–2092},
numpages = {10},
keywords = {critical design, expanded design practice, design criticism, speculative design, design thinking, critical theory},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702400,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Koefoed Hansen, Lone},
title = {Immodest Proposals: Research Through Design and Knowledge},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702400},
doi = {10.1145/2702123.2702400},
abstract = {The paper offers theoretical support for research through design (RtD) by arguing
that in order to legitimize and make use of research through design as research, HCI
researchers need to explore and clarify how RtD objects might contribute to knowledge.
Leveraging the tradition of aesthetics in the arts and humanities, we argue that while
the intentions of the object's designer are important and while annotations are a
good mechanism to articulate them, the critical reception of objects is equally foundational
to RtD's broader knowledge impacts within HCI. Such a scholarly critical reception
is needed precisely because of the potential inexhaustibility of design objects' meanings;
their inability to be paraphrased simply and adequately. Offering a multilevel analysis
of the (critical) design fiction Menstruation Machine by Sputniko!, the paper explores
how design objects co-produce knowledge, by working through complex design problem
spaces in non-reductive ways, proposing new connections and distinctions, and embodying
design ideas and processes across time and minds.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2093–2102},
numpages = {10},
keywords = {research through design, hci, epistemology, criticism},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702405,
author = {Pierce, James and Paulos, Eric},
title = {Making Multiple Uses of the Obscura 1C Digital Camera: Reflecting on the Design, Production, Packaging and Distribution of a Counterfunctional Device},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702405},
doi = {10.1145/2702123.2702405},
abstract = {This paper describes and explains details of the design, production and packaging
of a counterfunctional device: The Obscura 1C Digital Camera. We further describe
a small-scale distribution of Obscura 1C packages into everyday contexts. The paper
then reflects on the various types of conceptual, imaginary and firsthand uses made
of the Obscura 1C. These include its uses for everyday audiences as a unique camera
and as a conceptually usable device. But we also prioritize uses particular to the
HCI and design audience. These include using the Obscura 1C to articulate the concepts
of inhibitive interfaces, counterfunctionality, and enabling limitations. The Obscura
1C is further used to articulate how abstract ideas can be translated into material
forms, to rethink the role of packaging in user studies, and to draw attention to
how discursive design objects are packaged and presented.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2103–2112},
numpages = {10},
keywords = {research through design, limitations, design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702435,
author = {Bae, Jae-eul and Lim, Youn-kyung and Bang, Jin-bae and Kim, Myung-suk},
title = {Pause Moment Experience in SNS Communication},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702435},
doi = {10.1145/2702123.2702435},
abstract = {The evolution of SNS applications has focused on the increasing pace of communication.
Accordingly, adopting pause moment design for the SNS domain becomes significant,
considering its worth for mental well-being and diversity of experience. Nonetheless,
the vision is currently controversial, as it is lacking in attempts to examine the
worth of pause moment design for SNS communication. Therefore, we discussed the benefits
of pause moment design as an SNS application, based on the case of Ripening Room.
From observation, we have identified three benefits of pause moment design; preserving
room for solitude, expanding time experience, and providing additional indirect cues
for communication. Nevertheless, the benefits also imply limitations of the current
design, thus require following attempts to adopt a pause moment design for the SNS
domain.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2113–2116},
numpages = {4},
keywords = {slow technology, sns, pause moment design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251729,
author = {Izadi, Shahram},
title = {Session Details: HMDs in Augmented &amp; Virtual Reality},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251729},
doi = {10.1145/3251729},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702305,
author = {Zheng, Xianjun Sam and Foucault, Cedric and Matos da Silva, Patrik and Dasari, Siddharth and Yang, Tao and Goose, Stuart},
title = {Eye-Wearable Technology for Machine Maintenance: Effects of Display Position and Hands-Free Operation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702305},
doi = {10.1145/2702123.2702305},
abstract = {Exciting developments in eye-wearable technology and its potential industrial applications
warrant a thorough understanding of its advantages and drawbacks through empirical
evidence. We conducted an experiment to investigate what characteristics of eye-wearable
technology impact user performance in machine maintenance, which included a representative
set of car maintenance tasks involving Locate, Manipulate, and Compare actions. Participants
were asked to follow instructions displayed on one of four technologies: a peripheral
eye-wearable display, a central eye-wearable display, a tablet, or a paper manual.
We found a significant effect of display position: the peripheral eye-wearable display
resulted in longer completion time than the central display; but no effect for hands-free
operation. The technology effects were also modulated by different Tasks and Action
types. We discuss the human factors implications for designing more effective eye-wearable
technology, including display position, issues of monocular display, and how the physical
proximity of the technology affects users' reliance level.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2125–2134},
numpages = {10},
keywords = {eye-wearable technology, wearable computing, smartglasses, machine maintenance, action type, task guidance},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702450,
author = {Dobbelstein, David and Hock, Philipp and Rukzio, Enrico},
title = {Belt: An Unobtrusive Touch Input Device for Head-Worn Displays},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702450},
doi = {10.1145/2702123.2702450},
abstract = {Belt is a novel unobtrusive input device for wearable displays that incorporates a
touch surface encircling the user's hip. The wide input space is leveraged for a horizontal
spatial mapping of quickly accessible information and applications. We discuss social
implications and interaction capabilities for unobtrusive touch input and present
our hardware implementation and a set of applications that benefit from the quick
access time. In a qualitative user study with 14 participants we found out that for
short interactions (2-4 seconds), most of the surface area is considered as appropriate
input space, while for longer interactions (up to 10 seconds), the front areas above
the trouser pockets are preferred.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2135–2138},
numpages = {4},
keywords = {spatial mapping, unobtrusive, touch, wearable input},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702161,
author = {Lauber, Felix and Cook, Sophia and Butz, Andreas},
title = {Content Destabilization for Head-Mounted Displays},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702161},
doi = {10.1145/2702123.2702161},
abstract = {With recent progress in display technology, visual see-through head-mounted displays
are beginning to enter our everyday lives. Especially in cars they may replace head-up
displays, as they can theoretically perfectly imitate them but are more flexible to
use. However, prior work has shown that both screen- and vehicle-stabilized content
suffer from drawbacks such as occlusion or technological limitations. As a potential
alternative, we propose three concept alternatives, in which head rotation is used
to manipulate the displayed content differently from both of the known stabilization
techniques. In a qualitative user study, we identify the best concept proposal and
then evaluate it against the established content stabilization techniques. The presented
concept is perceived to be more applicable for the proposed use case and effectively
reduces some of the known problems of both stabilization techniques.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2139–2142},
numpages = {4},
keywords = {head-mounted display, head-up display, automotive user interface, content stabilization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702382,
author = {McGill, Mark and Boland, Daniel and Murray-Smith, Roderick and Brewster, Stephen},
title = {A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702382},
doi = {10.1145/2702123.2702382},
abstract = {We identify usability challenges facing consumers adopting Virtual Reality (VR) head-mounted
displays (HMDs) in a survey of 108 VR HMD users. Users reported significant issues
in interacting with, and being aware of their real-world context when using a HMD.
Building upon existing work on blending real and virtual environments, we performed
three design studies to address these usability concerns. In a typing study, we show
that augmenting VR with a view of reality significantly corrected the performance
impairment of typing in VR. We then investigated how much reality should be incorporated
and when, so as to preserve users' sense of presence in VR. For interaction with objects
and peripherals, we found that selectively presenting reality as users engaged with
it was optimal in terms of performance and users' sense of presence. Finally, we investigated
how this selective, engagement-dependent approach could be applied in social environments,
to support the user's awareness of the proximity and presence of others.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2143–2152},
numpages = {10},
keywords = {augmented virtuality, engagement, virtual reality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702143,
author = {Apostolopoulos, Ilias and Coming, Daniel S. and Folmer, Eelke},
title = {Accuracy of Pedometry on a Head-Mounted Display},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702143},
doi = {10.1145/2702123.2702143},
abstract = {The accuracy of pedometry varies depending on where an inertial sensor is located
on the body. Motivated by the increasing popularity of wearable computing, this paper
investigates the accuracy with which pedometry can be achieved on a head-mounted device:
something previous research has not investigated. A study with 16 subjects compares
the accuracy of pedometry for walking and running with an inertial sensor located
at the head, pocket and hand/arm. Our study did not detect a significant difference
in step counting accuracy between sensor locations, which demonstrates the feasibility
of pedometry-based apps for head-mounted displays.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2153–2156},
numpages = {4},
keywords = {dead reckoning, head-mounted display, activity tracking, glass, pedometry, wearable computing, accelerometers},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702253,
author = {Schmidt, Dominik and Kovacs, Rob and Mehta, Vikram and Umapathi, Udayan and K\"{o}hler, Sven and Cheng, Lung-Pan and Baudisch, Patrick},
title = {Level-Ups: Motorized Stilts That Simulate Stair Steps in Virtual Reality},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702253},
doi = {10.1145/2702123.2702253},
abstract = {We present "Level-Ups", computer-controlled stilts that allow virtual reality users
to experience walking up and down steps. Each Level-Up unit is a self-contained device
worn like a boot. Its main functional element is a vertical actuation mechanism mounted
to the bottom of the boot that extends vertically. Unlike traditional solutions that
are integrated with locomotion devices, Level-Ups allow users to walk around freely
("real-walking"). We present Level-Ups in a demo environment based on a head-mounted
display, optical motion capture, and integrated with two different game engines. In
a user study, participants rated the realism of stepping onto objects 6.0 out of 7.0
when wearing Level-Ups compared to 3.5 without.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2157–2160},
numpages = {4},
keywords = {head-mounted display, real-walking, virtual reality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251730,
author = {Zhao, Shengdong},
title = {Session Details: Tangible Interaction with Phones},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251730},
doi = {10.1145/3251730},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702414,
author = {Laput, Gierad and Brockmeyer, Eric and Hudson, Scott E. and Harrison, Chris},
title = {Acoustruments: Passive, Acoustically-Driven, Interactive Controls for Handheld Devices},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702414},
doi = {10.1145/2702123.2702414},
abstract = {We introduce Acoustruments: low-cost, passive, and power-less mechanisms, made from
plastic, that can bring rich, tangible functionality to handheld devices. Through
a structured exploration, we identified an expansive vocabulary of design primitives,
providing building blocks for the construction of tangible interfaces utilizing smartphones'
existing audio functionality. By combining design primitives, familiar physical mechanisms
can all be constructed from passive elements. On top of these, we can create end-user
applications with rich, tangible interactive functionalities. Our experiments show
that Acoustruments can achieve 99% accuracy with minimal training, is robust to noise,
and can be rapidly prototyped. Acoustruments adds a new method to the toolbox HCI
practitioners and researchers can draw upon, while introducing a cheap and passive
method for adding interactive controls to consumer products.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2161–2170},
numpages = {10},
keywords = {mobile and handheld devices, acoustic sensing, fabrication, mechanisms and controls},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702277,
author = {Corsten, Christian and Cherek, Christian and Karrer, Thorsten and Borchers, Jan},
title = {HaptiCase: Back-of-Device Tactile Landmarks for Eyes-Free Absolute Indirect Touch},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702277},
doi = {10.1145/2702123.2702277},
abstract = {Using a smartphone for touch input to control apps and games mirrored to a distant
screen is difficult, as the user cannot see where she is touching while looking at
the distant display. We present HaptiCase, an interaction technique that provides
back-of-device tactile landmarks that the user senses with her fingers to estimate
the location of her finger in relation to the touchscreen. By pinching the thumb resting
above the touch- screen to a finger at the back, the finger position is transferred
to the front as the thumb touches the screen. In a study, we compared touch performance
of different landmark layouts with a regular landmark-free mobile device. Using a
land- mark design of dots on a 3x5 grid significantly improves eyes-free tapping accuracy
and allows targets to be as small as 17.5 mm---a 14% reduction in target size---to
cover 99% of all touches. When users can look at the touchscreen, land- marks have
no significant effect on performance. HaptiCase is low-cost, requires no electronics,
and works with unmodified software.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2171–2180},
numpages = {10},
keywords = {tactile feedback, back-of-device interaction, eyes-free touch},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702326,
author = {Park, Young-Woo and Park, Joohee and Nam, Tek-Jin},
title = {The Trial of Bendi in a Coffeehouse: Use of a Shape-Changing Device for a Tactile-Visual Phone Conversation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702326},
doi = {10.1145/2702123.2702326},
abstract = {We present Bendi, a shape-changing device for a tactile-visual phone conversation.
Bendi enables users to deliver shape-changing movements (e.g., upward or downward
bending, left or right tilting, and shrinking) from the user's joystick input to the
other party's device in real time during phone conversations. We conducted a user
study to observe how seven couples used it over three days in a coffeehouse. Our field
trial of Bendi in a coffeehouse showed the private and natural uses, and integrated
uses of tactile and visual expressions along with the uses of the vocabularies developed
through Bendi. In addition, there were active uses even in negative and serious conversational
context with its pleasant tactile feelings and movement representations. Lastly, we
discuss issues for the future designs and real-world deployment of shape-changing
mobile devices for daily use.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2181–2190},
numpages = {10},
keywords = {tactile-visual, coffeehouse, shape-changing interface, phone conversation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702169,
author = {Sato, Munehiko and Yoshida, Shigeo and Olwal, Alex and Shi, Boxin and Hiyama, Atsushi and Tanikawa, Tomohiro and Hirose, Michitaka and Raskar, Ramesh},
title = {SpecTrans: Versatile Material Classification for Interaction with Textureless, Specular and Transparent Surfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702169},
doi = {10.1145/2702123.2702169},
abstract = {Surface and object recognition is of significant importance in ubiquitous and wearable
computing. While various techniques exist to infer context from material properties
and appearance, they are typically neither designed for real-time applications nor
for optically complex surfaces that may be specular, textureless, and even transparent.
These materials are, however, becoming increasingly relevant in HCI for transparent
displays, interactive surfaces, and ubiquitous computing. We present SpecTrans, a
new sensing technology for surface classification of exotic materials, such as glass,
transparent plastic, and metal. The proposed technique extracts optical features by
employing laser and multi-directional, multi-spectral LED illumination that leverages
the material's optical properties. The sensor hardware is small in size, and the proposed
classification method requires significantly lower computational cost than conventional
image-based methods, which use texture features or reflectance analysis, thereby providing
real-time performance for ubiquitous computing. Our evaluation of the sensing technique
for nine different transparent materials, including air, shows a promising recognition
rate of 99.0%. We demonstrate a variety of possible applications using SpecTrans'
capabilities.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2191–2200},
numpages = {10},
keywords = {context-aware mobile computing, ubiquitous computing, multi-spectral sensing, sensors, material classification, laser speckle},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251731,
author = {Gross, Tom},
title = {Session Details: UI Impact on Performance &amp; Decisions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251731},
doi = {10.1145/3251731},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702479,
author = {Jung, Malte F. and Sirkin, David and G\"{u}r, Turgut M. and Steinert, Martin},
title = {Displayed Uncertainty Improves Driving Experience and Behavior: The Case of Range Anxiety in an Electric Car},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702479},
doi = {10.1145/2702123.2702479},
abstract = {We explore the impact of the displayed precision of instrumentation estimates of range
and state-of-charge on drivers' attitudes towards an all-electric vehicle (EV), on
their driving experience, and driving behavior under varying conditions of resource
availability. Participants (N=73) completed a 19-mile long drive through highway,
rural town and mountain road conditions in an EV that displayed high vs. low remaining
range, and gave estimates of that range with high and low information ambiguity. We
found that an ambiguous display of range preserved drivers' feelings of trust towards
the vehicle, despite encountering situations intended to induce severe range anxiety.
Furthermore, compared to drivers facing an unambiguous display of range, drivers presented
with an ambiguous range display reported improved driving experience, and exhibited
driving behavior better adapted to road and remaining range conditions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2201–2210},
numpages = {10},
keywords = {trust in automated systems, information display, car, range anxiety, ambiguity., progress bar, electric vehicle},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702239,
author = {Zhang, Yunfeng and Bellamy, Rachel K.E. and Kellogg, Wendy A.},
title = {Designing Information for Remediating Cognitive Biases in Decision-Making},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702239},
doi = {10.1145/2702123.2702239},
abstract = {Software is playing an increasingly important role in supporting human decision-making.
Previous HCI research on decision support systems (DSS) has improved the information
visualization aspect of DSS information design, but has somewhat overlooked the cognitive
aspect of decision-making, namely that human reasoning is heuristic and reflects systematic
errors or cognitive biases. We report on an empirical study of two cognitive biases:
conservatism and loss aversion. Two remediation techniques recommended by previous
research were tested: the expected return method, an actuarial-inspired approach presenting
objective metrics; and bootstrapping, a technique successful in improving judgment
consistency. The results show that the two biases can occur simultaneously and can
have a huge impact on decision-making. The results also show that the two debiasing
techniques are only partly effective. These findings suggest a need for more research
on debiasing, and indicate some directions for exploring debiasing techniques and
building decision support systems.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2211–2220},
numpages = {10},
keywords = {loss aversion, multiple-cue probability learning, cognitive bias, decision support system, intelligent assistance, conservatism, decision making},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702422,
author = {Jokinen, Jussi P.P. and Silvennoinen, Johanna M. and Per\"{a}l\"{a}, Piia M.H. and Saariluoma, Pertti},
title = {Quick Affective Judgments: Validation of a Method for Primed Product Comparisons},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702422},
doi = {10.1145/2702123.2702422},
abstract = {A method for primed product comparisons was developed, based on the methodological
considerations of emotional appraisal process and affective mental contents. The method
was implemented as a computer tool, which was utilised in two experiments (N = 18
for both). Ten adjectives served as primes, and five drinking glass pictures as stimuli.
Participants' task was to choose a preference between two glasses, given the priming
adjective. The results validate the method by providing test-retest reliability measures
and showing convergence with questionnaires. Further, different evaluation times between
the primes and the stimuli reveal the existence of different mental processes associated
with various aspects of product experience, as predicted by appraisal theory. The
results have various implications for experience research and development in HCI,
as they demonstrate how the method can be used for product evaluation and the analysis
of the mental processes, which users use to evaluate the products.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2221–2230},
numpages = {10},
keywords = {product experience, affective mental contents, primed product comparisons},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702360,
author = {Cramer, Henriette},
title = {Effects of Ad Quality &amp; Content-Relevance on Perceived Content Quality},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702360},
doi = {10.1145/2702123.2702360},
abstract = {Native advertising, ads that are highly cohesive with actual content in format and
style, is a pervasive online trend. We report on a two-stage Mechanical Turk experiment
exploring the effects of perceived quality of native ads on perceptions of site quality.
First, a set of native ads was rated (N=98) for perceived annoyance and trust. Second,
we compare four conditions of an aggregation of news headlines (N=237): 'no ads', 'low quality ads', 'high quality ads + content-relevant', 'high-quality ads + not
content-relevant'. Our results indicate that native ads, which in isolation have been
rated as high quality, could still have a negative effect on perceived site credibility
and perceived site quality if they are too content-relevant. In addition to the effect
of ad quality alone (e.g. non-annoying, trustworthy ads), there is an additional impact
for ads that are too similar to content; avoiding confusion is important for quality
perceptions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2231–2234},
numpages = {4},
keywords = {content relevance, advertising, ads, quality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251732,
author = {Smeddinck, Jan},
title = {Session Details: Player Performance &amp; Experience in Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251732},
doi = {10.1145/3251732},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702606,
author = {Harteveld, Casper and Sutherland, Steven C.},
title = {The Goal of Scoring: Exploring the Role of Game Performance in Educational Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702606},
doi = {10.1145/2702123.2702606},
abstract = {In this paper the role of game performance as an assessment tool is explored and an
approach is presented for designing and assessing learning-centered game scores. In
recent years, attention has shifted from focusing on games for learning to games for
assessment. The research question this paper tries to address is how valid games are
as an assessment tool, and more specifically, how valid the use of game scores are
as a measure of assessment. To explore this use, we looked at the role of game performance
in a game where the goals were designed based on its learning objectives. We hypothesized
that because of this design the scores could be used as a measure of learning. The
results of our mixed-methods study confirmed this hypothesis. However, the scores
are influenced by factors such as computer skills and age. Further analysis revealed
that the design of the game and the game-based training were also of influence. These
insights will help in designing better predictive game scores in the future.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2235–2244},
numpages = {10},
keywords = {education, game design, game-based training, game-based assessment, game analytics},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702204,
author = {Iacovides, Ioanna and Cox, Anna L.},
title = {Moving Beyond Fun: Evaluating Serious Experience in Digital Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702204},
doi = {10.1145/2702123.2702204},
abstract = {Games are normally considered to be "fun", though recently there is growing interest
in how gameplay can promote empathy and encourage reflection through "serious experience".
However, when looking beyond enjoyment, it is not clear how to actually evaluate serious
experience. We present an evaluation of four games that were submitted to a student
game design competition; the competition challenged teams to design a game that inspired
curiosity around human error and blame culture within the context of healthcare. The
entries were judged by a panel of six experts and subjected to a round of play testing
by twelve participants. Methods included gameplay observation, questionnaires, post-play
interviews and follow-up email questions. We discuss the utility of these methods,
with particular emphasis on how they enabled a consideration of the immediate and
longer term impact of serious experience on players.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2245–2254},
numpages = {10},
keywords = {critical play, negative experience, evaluation, games, serious experience, engagement, positive experience},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702242,
author = {Vicencio-Moreira, Rodrigo and Mandryk, Regan L. and Gutwin, Carl},
title = {Now You Can Compete With Anyone: Balancing Players of Different Skill Levels in a First-Person Shooter Game},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702242},
doi = {10.1145/2702123.2702242},
abstract = {When player skill levels differ widely in a competitive First-Person Shooter (FPS)
game, enjoyment suffers: weaker players become frustrated and stronger players become
less engaged. Player balancing techniques attempt to assist the weaker player and
make games more competitive, but these techniques have limitations for deployment
when skill levels vary substantially. We developed new player balancing schemes to
deal with a range of FPS skill difference, and tested these techniques in one-on-one
deathmatches using a commercial-quality FPS game developed with the UDK engine. Our
results showed that the new balancing schemes are extremely effective at balancing,
even for players with large skill differences. Surprisingly, the techniques that were
most effective at balancing were also rated as most enjoyable by both players -- even
though these schemes were the most noticeable. Our study is the first to show that
player balancing can work well in realistic FPS games, providing developers with a
way to increase the audience for this popular genre. In addition, our results demonstrate
the idea that successful balancing is as much about the way the technique is applied
as it is about the specific manipulation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2255–2264},
numpages = {10},
keywords = {game balancing, first-person shooters, player balancing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702447,
author = {Johnson, Daniel and Nacke, Lennart E. and Wyeth, Peta},
title = {All about That Base: Differing Player Experiences in Video Game Genres and the Unique Case of MOBA Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702447},
doi = {10.1145/2702123.2702447},
abstract = {Video games provide unique interactive player experiences (PX) often categorised into
different genres. Prior research has looked at different game genres, but rarely through
a PX lens. Especially, PX in the emerging area of massive online battle arena (MOBA)
games is not well understood by researchers in the field. We address this knowledge
gap by presenting a PX study of different game genres, which we followed up with a
second semi-structured interview study about PX in MOBA games. Among the results of
our analyses are that games that are likely played with other players, such as MOBA
games, stimulate less immersion and presence for players. Additionally, while challenge
and frustration are significantly higher in this genre, players get a sense of satisfaction
from teamwork, competition and mastery of complex gameplay interactions. Our study
is the first to contribute a comprehensive insight into key motivators of MOBA players
and how PX in this genre is different from other genres.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2265–2274},
numpages = {10},
keywords = {games, player experience, self-determination theory},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251733,
author = {Reinecke, Katharina},
title = {Session Details: Neighborhoods &amp; Disadvantaged Communities},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251733},
doi = {10.1145/3251733},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702157,
author = {Strohmayer, Angelika and Comber, Rob and Balaam, Madeline},
title = {Exploring Learning Ecologies among People Experiencing Homelessness},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702157},
doi = {10.1145/2702123.2702157},
abstract = {Non-homeless youths outperform their homeless peers in school even if they live in
extreme poverty. This disadvantage can have long-term consequences for engagement
with and navigation of wider society. In this paper we examine how differences in
achievement could be tackled outside of school through the re-envisioning of ecologies
of digital education. Through interviews, design workshops, and a street visit with
a total of 20 homeless young adults during a three-week engagement with a centre for
people of low social stability in Bucharest, Romania, we examine the perceptions of
education among street involved youth or adults. We identify the core values, aspirations,
opportunities and barriers for education among these people, including survival, friendship,
learning networks, and curiosity. These findings resulted in five implications for
design: learning "happens", learning "works", designing for distanced learning, designing
for the social politics of learning, and designing artefacts of everyday learning.
These show the importance and necessity of educational reform in the field of HCI.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2275–2284},
numpages = {10},
keywords = {learning, homeless, local learning ecology, self-organised learning environments, education, learning networks},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702189,
author = {Dillahunt, Tawanna R. and Malone, Amelia R.},
title = {The Promise of the Sharing Economy among Disadvantaged Communities},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702189},
doi = {10.1145/2702123.2702189},
abstract = {The digital-sharing economy presents opportunities for individuals to find temporary
employment, generate extra income, increase reciprocity, enhance social interaction,
and access resources not otherwise attainable. Although the sharing economy is profitable,
little is known about its use among the unemployed or those struggling financially.
This paper describes the results of a participatory-design based workshop to investigate
the perception and feasibility of finding temporary employment and sharing spare resources
using sharing-economy applications. Specifically, this study included 20 individuals
seeking employment in a U.S. city suffering economic decline. We identify success
factors of the digital-sharing economy to these populations, identify shortcomings
and propose mitigation strategies based on prior research related to trust, social
capital and theories of collective efficacy. Finally, we contribute new principles
that may foster collaborative consumption within this population and identify new
concepts for practical employment applications among these populations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2285–2294},
numpages = {10},
keywords = {neighborgoods, taskrabbit, airbnb, marginalized populations, sustainability, lyft, sharing economy, unemployment},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702449,
author = {M\"{u}ller, Claudia and Hornung, Dominik and Hamm, Theodor and Wulf, Volker},
title = {Practice-Based Design of a Neighborhood Portal: Focusing on Elderly Tenants in a City Quarter Living Lab},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702449},
doi = {10.1145/2702123.2702449},
abstract = {This paper contributes to the current discourse on practice-based research in HCI
paying particular attention to the overall temporal and situational conditions which
frame an R&amp;D project. We present a Living Lab study situated in an arbitrary neighborhood
of a German city which develops ICT support to foster informal help and social interaction
with a special, but not exclusive, focus on elderly tenants. We demonstrate that practice-based,
long-term research in a city quarter goes beyond those challenges already described
in the current Living Lab and PD literature. The long-term study's positioning in
a real-world context is contoured not only by a high diversity of stakeholders and
their individual interests and motivation for participation but also by their individual
skill sets and learning needs. These distinct and often contradictive perspectives
have to be permanently counterbalanced. Thus attention has to be focused on how related
strategies and decisions impact on the design of the project as well as on the final
ICT product. To enable all tenants, irrespective of age and technical skill, to participate
in a long-term ICT-based community development project, we applied the format of 'experience-based
PD workshops' to foster confidence in ICT usage and encourage the competency of the
elderly and non-tech-savvy tenants.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2295–2304},
numpages = {10},
keywords = {elderly people, action research, practice, city quarter, methodology, participatory design, living lab},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702534,
author = {Pater, Jessica A. and Miller, Andrew D. and Mynatt, Elizabeth D.},
title = {This Digital Life: A Neighborhood-Based Study of Adolescents' Lives Online},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702534},
doi = {10.1145/2702123.2702534},
abstract = {In this paper, we present the results of a multi-year study of the social computing
practices of 179 adolescents (Mage=12.4 years, SD=1.3; range: 10-14) living in a majority-minority
lower-income urban neighborhood in the Southeast U.S. We investigate shifting social
media practices using annual surveys and focus groups. We describe participants' social
media use and motivations and show how that use has shifted over time. We show how
participants identify social pressures and influences as well as specific behaviors
including computer-mediated risky behaviors and self-harm. We discuss the implications
of our findings for the CHI research community, including methodological challenges
and the need for further study of computer-mediated harmful behaviors in youth populations.
By demonstrating how large-scale trends are enacted on the ground, we describe participants'
uses, motivations and behaviors as they deal with the increasing influence of technology
in their social lives.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2305–2314},
numpages = {10},
keywords = {hyperlocal anonymous app, survey, adolescents, mobile, technology trends, self-harm, social computing, teens, cyberbullying},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251734,
author = {Egelman, Serge},
title = {Session Details: Enhanced Security with Passwords &amp; CAPTCHAs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251734},
doi = {10.1145/3251734},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702241,
author = {Al-Ameen, Mahdi Nasrullah and Wright, Matthew and Scielzo, Shannon},
title = {Towards Making Random Passwords Memorable: Leveraging Users' Cognitive Ability Through Multiple Cues},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702241},
doi = {10.1145/2702123.2702241},
abstract = {Given the choice, users produce passwords reflecting common strategies and patterns
that ease recall but offer uncertain and often weak security. System-assigned passwords
provide measurable security but suffer from poor memorability. To address this usability-security
tension, we argue that systems should assign random passwords but also help with memorization
and recall. We investigate the feasibility of this approach with CuedR, a novel cued-recognition
authentication scheme that provides users with multiple cues (visual, verbal, and
spatial) and lets them choose the cues that best fit their learning process for later
recognition of system-assigned keywords. In our lab study, all 37 of our participants
could log in within three attempts one week after registration (mean login time: 38.0
seconds). A pilot study on using multiple CuedR passwords also showed 100% recall
within three attempts. Based on our results, we suggest appropriate applications for
CuedR, such as financial and e-commerce accounts.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2315–2324},
numpages = {10},
keywords = {cued-recognition, authentication, usable security},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702457,
author = {Dandapat, Sourav Kumar and Pradhan, Swadhin and Mitra, Bivas and Roy Choudhury, Romit and Ganguly, Niloy},
title = {ActivPass: Your Daily Activity is Your Password},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702457},
doi = {10.1145/2702123.2702457},
abstract = {This paper explores the feasibility of automatically extracting passwords from a user's
daily activity logs, such as her Facebook activity, phone activity etc. As an example,
a smartphone might ask the user: "Today morning from whom did you receive an SMS?"
In this paper, we observe that infrequent activities (i.e., outliers) can be memorable
and unpredictable. Building on this observation, we have developed an end to end system
ActivPass and experimented with 70 users. With activity logs from Facebook, browsing
history, call logs, and SMSs, the system achieves 95% success (authenticates legitimate
users) and is compromised in 5.5% cases (authenticates impostors). While this level
of security is obviously inadequate for serious authentication systems, certain practices
such as password sharing can immediately be thwarted from the dynamic nature of passwords.
With security improvements in the future, activity-based authentication could fill
in for the inadequacies in today's password-based systems.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2325–2334},
numpages = {10},
keywords = {outliers, dynamic authentication, password sharing, activity-based password},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702127,
author = {Meutzner, Hendrik and Gupta, Santosh and Kolossa, Dorothea},
title = {Constructing Secure Audio CAPTCHAs by Exploiting Differences between Humans and Machines},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702127},
doi = {10.1145/2702123.2702127},
abstract = {To prevent abuses of Internet services, CAPTCHAs are used to distinguish humans from
programs where an audio-based scheme is beneficial to support visually impaired people.
Previous studies show that most audio CAPTCHAs, albeit hard to solve for humans, are
lacking security strength. In this work we propose an audio CAPTCHA that is far more
robust against automated attacks than it is reported for current CAPTCHA schemes.
The CAPTCHA exhibits a good trade-off between human usability and security. This is
achieved by exploiting the fact that the human capabilities of language understanding
and speech recognition are clearly superior compared to current machines. We evaluate
the CAPTCHA security by using a state-of-the-art attack and assess the intelligibility
by means of a large-scale listening experiment.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2335–2338},
numpages = {4},
keywords = {humans vs. machines, visual impairment, user studies, usability, web accessibility, security, audio captcha},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702202,
author = {von Zezschwitz, Emanuel and De Luca, Alexander and Janssen, Philipp and Hussmann, Heinrich},
title = {Easy to Draw, but Hard to Trace? On the Observability of Grid-Based (Un)Lock Patterns},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702202},
doi = {10.1145/2702123.2702202},
abstract = {We performed a systematic evaluation of the shoulder surfing susceptibility of the
Android pattern (un)lock. The results of an online study (n=298) enabled us to quantify
the influence of pattern length, line visibility, number of knight moves, number of
overlaps and number of intersections on observation resistance. The results show that
all parameters have a highly significant influence, with line visibility and pattern
length being most important. We discuss implications for real-world patterns and present
a linear regression model that can predict the observability of a given pattern. The
model can be used to provide proactive security measurements for (un)lock patterns,
in analogy to password meters.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2339–2342},
numpages = {4},
keywords = {observability, security, authentication, pattern},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702365,
author = {Song, Youngbae and Cho, Geumhwan and Oh, Seongyeol and Kim, Hyoungshick and Huh, Jun Ho},
title = {On the Effectiveness of Pattern Lock Strength Meters: Measuring the Strength of Real World Pattern Locks},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702365},
doi = {10.1145/2702123.2702365},
abstract = {We propose an effective pattern lock strength meter to help users choose stronger
pattern locks on Android devices. To evaluate the effectiveness of the proposed meter
with a real world dataset (i.e., with complete ecological validity), we created an
Android application called EnCloud that allows users to encrypt their Dropbox files.
101 pattern locks generated by real EnCloud users were collected and analyzed, where
some portion of the users were provided with the meter support. Our statistical analysis
indicates that about 10% of the pattern locks that were generated without the meter
support could be compromised through just 16 guessing attempts. As for the pattern
locks that were generated with the meter support, that number goes up to 48 guessing
attempts, showing significant improvement in security. Our recommendation is to implement
a strength meter in the next version of Android.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2343–2352},
numpages = {10},
keywords = {security, password, pattern lock, password strength meter},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251735,
author = {Takagi, Hironobu},
title = {Session Details: Accessibility at Home &amp; on The Go},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251735},
doi = {10.1145/3251735},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702437,
author = {Zhong, Yu and Lasecki, Walter S. and Brady, Erin and Bigham, Jeffrey P.},
title = {RegionSpeak: Quick Comprehensive Spatial Descriptions of Complex Images for Blind Users},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702437},
doi = {10.1145/2702123.2702437},
abstract = {Blind people often seek answers to their visual questions from remote sources, however,
the commonly adopted single-image, single-response model does not always guarantee
enough bandwidth between users and sources. This is especially true when questions
concern large sets of information, or spatial layout, e.g., where is there to sit
in this area, what tools are on this work bench, or what do the buttons on this machine
do? Our RegionSpeak system addresses this problem by providing an accessible way for
blind users to (i) combine visual information across multiple photographs via image
stitching, em (ii) quickly collect labels from the crowd for all relevant objects
contained within the resulting large visual area in parallel, and (iii) then interactively
explore the spatial layout of the objects that were labeled. The regions and descriptions
are displayed on an accessible touchscreen interface, which allow blind users to interactively
explore their spatial layout. We demonstrate that workers from Amazon Mechanical Turk
are able to quickly and accurately identify relevant regions, and that asking them
to describe only one region at a time results in more comprehensive descriptions of
complex images. RegionSpeak can be used to explore the spatial layout of the regions
identified. It also demonstrates broad potential for helping blind users to answer
difficult spatial layout questions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2353–2362},
numpages = {10},
keywords = {stitching, visual questions, crowdsourcing, accessibility},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702421,
author = {Shilkrot, Roy and Huber, Jochen and Meng Ee, Wong and Maes, Pattie and Nanayakkara, Suranga Chandima},
title = {FingerReader: A Wearable Device to Explore Printed Text on the Go},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702421},
doi = {10.1145/2702123.2702421},
abstract = {Accessing printed text in a mobile context is a major challenge for the blind. A preliminary
study with blind people reveals numerous difficulties with existing state-of-the-art
technologies including problems with alignment, focus, accuracy, mobility and efficiency.
In this paper, we present a finger-worn device, FingerReader, that assists blind users
with reading printed text on the go. We introduce a novel computer vision algorithm
for local-sequential text scanning that enables reading single lines, blocks of text
or skimming the text with complementary, multimodal feedback. This system is implemented
in a small finger-worn form factor, that enables a more manageable eyes-free operation
with trivial setup. We offer findings from three studies performed to determine the
usability of the FingerReader.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2363–2372},
numpages = {10},
keywords = {text reading, assistive technology, wearable interface},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702511,
author = {Branham, Stacy M. and Kane, Shaun K.},
title = {Collaborative Accessibility: How Blind and Sighted Companions Co-Create Accessible Home Spaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702511},
doi = {10.1145/2702123.2702511},
abstract = {In recent decades, great technological strides have been made toward enabling people
who are blind to live independent, successful lives. However, there has been relatively
little progress towards understanding the social, collaborative needs of this population,
particularly in the domestic setting. We conducted semi-structured interviews in the
homes of 10 pairs of close companions in which one partner was blind and one was not.
We found that partners engaged in collaborative accessibility by taking active roles
in co-creating an accessible environment. Due to their different visual abilities,
however, partners sometimes encountered difficulties managing divergent needs and
engaging in shared experiences. We describe outstanding challenges to creating accessible
shared home spaces and outline new research and technology opportunities for supporting
collaborative accessibility in the home.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2373–2382},
numpages = {10},
keywords = {home, collaboration, blindness, accessibility, vision impairment, interpersonal relationships},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251736,
author = {Tang, John},
title = {Session Details: Telepresence Video, Robots, and Walls},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251736},
doi = {10.1145/3251736},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702160,
author = {Higuchi, Keita and Chen, Yinpeng and Chou, Philip A. and Zhang, Zhengyou and Liu, Zicheng},
title = {ImmerseBoard: Immersive Telepresence Experience Using a Digital Whiteboard},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702160},
doi = {10.1145/2702123.2702160},
abstract = {ImmerseBoard is a system for remote collaboration through a digital whiteboard that
gives participants a 3D immersive experience, enabled only by an RGBD camera (Microsoft
Kinect) mounted on the side of a large touch display. Using 3D processing of the depth
images, life-sized rendering, and novel visualizations, ImmerseBoard emulates writing
side-by-side on a physical whiteboard, or alternatively on a mirror. User studies
involving three tasks show that compared to standard video conferencing with a digital
whiteboard, ImmerseBoard provides participants with a quantitatively better ability
to estimate their remote partners' eye gaze direction, gesture direction, intention,
and level of agreement. Moreover, these quantitative capabilities translate qualitatively
into a heightened sense of being together and a more enjoyable experience. ImmerseBoard's
form factor is suitable for practical and easy installation in homes and offices.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2383–2392},
numpages = {10},
keywords = {collaboration, immersive experience, telepresence},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702448,
author = {Avellino, Ignacio and Fleury, C\'{e}dric and Beaudouin-Lafon, Michel},
title = {Accuracy of Deictic Gestures to Support Telepresence on Wall-Sized Displays},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702448},
doi = {10.1145/2702123.2702448},
abstract = {This paper presents a controlled experiment assessing the accuracy when interpreting
remote users showing a shared object on a large wall-sized display, either by looking
at it or by looking and pointing at it. We analyze both distance and angle errors
and how they are sensitive to the relative position be- tween the remote viewer and
the video feed. We show that the remote user can accurately determine the target,
that eye gaze alone is more accurate than combined with the hand, and that the relative
position between the viewer and the video feed has little effect on accuracy. These
findings can inform the design of future telepresence systems for wall-sized displays.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2393–2396},
numpages = {4},
keywords = {remote collaboration, wall-sized display, pointing, telepresence},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702526,
author = {Johnson, Steven and Rae, Irene and Mutlu, Bilge and Takayama, Leila},
title = {Can You See Me Now? How Field of View Affects Collaboration in Robotic Telepresence},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702526},
doi = {10.1145/2702123.2702526},
abstract = {Robotic telepresence systems-videoconferencing systems that allow a remote user to
drive around in another location-are an emerging technology for supporting geographically-distributed
teams. Thus far, many of these systems rely on affordances designed for stationary
systems, such as a single, narrow-view camera to provide vision for the remote user.
Teleoperation has offered some solutions to this via an augmented field-of-view, but
how these solutions support task outcomes in collaborative mobile telepresence tasks
has yet to be understood. To investigate this, we conducted a three condition (field-of-view:
narrow (45°) vs. wide-angle (180°) vs. panoramic (360°)) between-participants controlled
laboratory experiment. We asked participants (N=24) to collaborate with a confederate
via a robotic telepresence system while using one of these views in a redecoration
task. Our results showed that wider views supported task efficiency and fewer collisions,
but were perceived as more difficult to use.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2397–2406},
numpages = {10},
keywords = {telepresence, teleoperation, situation awareness, robot-mediated collaboration, field-of-view, remote collaboration},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251737,
author = {Mueller, Florian "Floyd"},
title = {Session Details: Experience Design for Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251737},
doi = {10.1145/3251737},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702330,
author = {Butler, Eric and Andersen, Erik and Smith, Adam M. and Gulwani, Sumit and Popovi\'{c}, Zoran},
title = {Automatic Game Progression Design through Analysis of Solution Features},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702330},
doi = {10.1145/2702123.2702330},
abstract = {A long-term goal of game design research is to achieve end-to-end automation of much
of the design process, one aspect of which is creating effective level progressions.
A key difficulty is getting the player to practice with interesting combinations of
learned skills while maintaining their engagement. Although recent work in task generation
and sequencing has reduced this effort, we still lack end-to-end automation of the
entire content design process. We approach this goal by incorporating ideas from intelligent
tutoring systems and proposing progression strategies that seek to achieve mastery
of not only base concepts but arbitrary combinations of these concepts. The input
to our system is a model of what the player needs to do to complete each level, expressed
as either an imperative procedure for producing solutions or a representation of features
common to all solutions. The output is a progression of levels that can be adjusted
by changing high-level parameters. We apply our framework to a popular math puzzle
game and present results from 2,377 players showing that our automatic level progression
is comparable to expert-crafted progression after a few design iterations based on
a key engagement metric.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2407–2416},
numpages = {10},
keywords = {procedural content generation, education, games},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702577,
author = {Rooksby, John and Rost, Mattias and Morrison, Alistair and Chalmers, Matthew},
title = {Pass the Ball: Enforced Turn-Taking in Activity Tracking},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702577},
doi = {10.1145/2702123.2702577},
abstract = {We have developed a mobile application called Pass The Ball that enables users to
track, reflect on, and discuss physical activity with others. We followed an iterative
design process, trialling a first version of the app with 20 people and a second version
with 31. The trials were conducted in the wild, on users' own devices. The second
version of the app enforced a turn-taking system that meant only one member of a group
of users could track their activity at any one time. This constrained tracking at
the individual level, but more successfully led users to communicate and interact
with each other. We discuss the second trial with reference to two concepts: social-relatedness
and individual-competence. We discuss six key lessons from the trial, and identify
two high-level design implications: attend to "practices" of tracking; and look within
and beyond "collaboration" and "competition" in the design of activity trackers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2417–2426},
numpages = {10},
keywords = {activity tracking, mobile health, game},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702377,
author = {Darzentas, Dimitrios Paris and Brown, Michael A. and Flintham, Martin and Benford, Steve},
title = {The Data Driven Lives of Wargaming Miniatures},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702377},
doi = {10.1145/2702123.2702377},
abstract = {We present an ethnographic study of the practice of miniature wargaming in order to
shed light onto the complex lives of physical things and the ways in which they acquire
data footprints. We take an extended view of the practice, revealing how people invest
great effort into crafting miniatures, playing with them, curating and telling stories
about them, and passing them on. Throughout, we emphasise the use of both traditional
and digital technologies to build rich data footprints. In discussing our findings,
we adopt a "thing-centric" perspective that focuses on the extended lifetimes of the
miniatures themselves. This enables us to identify opportunities for digital augmentation
in support of capturing "life away from the table" and a need for HCI to focus on
designing trajectories of things.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2427–2436},
numpages = {10},
keywords = {artefacts, objects, provenance, ethnography, trajectories, internet of things, wargames},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702455,
author = {Bachour, Khaled and Wetzel, Richard and Flintham, Martin and Huynh, Trung Dong and Rodden, Tom and Moreau, Luc},
title = {Provenance for the People: An HCI Perspective on the W3C PROV Standard through an Online Game},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702455},
doi = {10.1145/2702123.2702455},
abstract = {In the information age, tools for examining the validity of data are invaluable. Provenance
is one such tool, and the PROV model proposed by the World Wide Web Consortium in
2013 offers a means of expressing provenance in a machine readable format. In this
paper, we examine from a user's standpoint notions of provenance, the accessibility
of the PROV model, and the general attitudes towards history and the verifiability
of information in modern data society. We do this through the medium of an online-game
designed to explore these issues and present the findings of the study along with
a discussion of some of its implications.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2437–2446},
numpages = {10},
keywords = {user study, prov standard, serious game, provenance},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251738,
author = {Mueller, Stefanie},
title = {Session Details: Digital &amp; Materials Fabrication},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251738},
doi = {10.1145/3251738},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702337,
author = {Giaccardi, Elisa and Karana, Elvin},
title = {Foundations of Materials Experience: An Approach for HCI},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702337},
doi = {10.1145/2702123.2702337},
abstract = {A growing number of HCI scholars have started to take materiality as an entry point
for acquiring a deeper understanding of the possibilities and constraints of design.
Steadily moving beyond a distinction between the physical and the digital, a few have
also started to look at materials as part of the unfolding of social and cultural
practices. Yet, to date, relatively little is known about how these practices develop
within the situated experience of materials, and how this situational whole can be
supported by design. By contributing to both growing materiality scholarship and emerging
practice-oriented approaches in HCI, this paper articulates a framework of materials
experience that discusses how materials shape ways of doing and ultimately, practice,
and how this is rooted in the experience of those materials.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2447–2456},
numpages = {10},
keywords = {practice, theory, materiality, materials experience, interaction design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702487,
author = {Ramakers, Raf and Todi, Kashyap and Luyten, Kris},
title = {PaperPulse: An Integrated Approach for Embedding Electronics in Paper Designs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702487},
doi = {10.1145/2702123.2702487},
abstract = {We present PaperPulse, a design and fabrication approach that enables designers without
a technical background to produce standalone interactive paper artifacts by augmenting
them with electronics. With PaperPulse, designers overlay pre-designed visual elements
with widgets available in our design tool. PaperPulse provides designers with three
families of widgets designed for smooth integration with paper, for an overall of
20 different interactive components. We also contribute a logic demonstration and
recording approach, Pulsation, that allows for specifying functional relationships
between widgets. Using the final design and the recorded Pulsation logic, PaperPulse
generates layered electronic circuit designs, and code that can be deployed on a microcontroller.
By following automatically generated assembly instructions, designers can seamlessly
integrate the microcontroller and widgets in the final paper artifact.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2457–2466},
numpages = {10},
keywords = {paper electronics, fabrication, tangible interfaces, paper-crafts, design tools, pbd},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702245,
author = {Nissen, Bettina and Bowers, John},
title = {Data-Things: Digital Fabrication Situated within Participatory Data Translation Activities},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702245},
doi = {10.1145/2702123.2702245},
abstract = {This paper explores a design-led approach to digital fabrication which situates it
in participatory data translation activities to demonstrate that this technology can
find application beyond its use as tool for manufacture. We present two contrasting
design contexts in which, respectively, data from conference twitter conversations
and craft practitioners' movements are translated into interactively generated and
fabricated physical artefacts. We argue that direct involvement in such digital fabrication
activities can help people invest meaning into artefacts and facilitate social interaction
and reflection upon their activities, while encouraging practitioners to incorporate
new forms into their own work. On this basis, we reconsider digital fabrication within
data translation activities as situated along an extended 'trajectory of use' in which
reflective, meaningful 'data-things' can be created.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2467–2476},
numpages = {10},
keywords = {3d printing, data materialisation, craft, research through design, making, digital fabrication, data translation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702547,
author = {Devendorf, Laura and Ryokai, Kimiko},
title = {Being the Machine: Reconfiguring Agency and Control in Hybrid Fabrication},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702547},
doi = {10.1145/2702123.2702547},
abstract = {This paper details the design and evaluation of Being the Machine, a portable digital
fabrication system that places digital fabrication activity outside of the traditional
fab lab environment. Being the Machine invites people to (re)consider materials found
in their everyday and personal environment as part of the fabrication activity. We
expand the design space involving hybrid (physical-digital) fabrication by describing
how our system draws from art to support critical and reflective modes of making.
In interaction with our system, participants distributed control between human and
machine actors to support their preferred mode of making. These patterns reveal new
opportunities and challenges for future hybrid fabrication systems, and suggest that
designing for qualities of experience, like meditation and reflection, could support
meaningful making experiences for many different kinds of makers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2477–2486},
numpages = {10},
keywords = {hybrid fabrication, everyday materials, 3d printing, art},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251739,
author = {Wilson, Max},
title = {Session Details: Tactile Notifications for Phones &amp; Wearables},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251739},
doi = {10.1145/3251739},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702341,
author = {Alvina, Jessalyn and Zhao, Shengdong and Perrault, Simon T. and Azh, Maryam and Roumen, Thijs and Fjeld, Morten},
title = {OmniVib: Towards Cross-Body Spatiotemporal Vibrotactile Notifications for Mobile Phones},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702341},
doi = {10.1145/2702123.2702341},
abstract = {Previous works illustrate that one's palm can reliably recognize 10 or more spatiotemporal
vibrotactile patterns. However, recognition of the same patterns on other body parts
is unknown. In this paper, we investigate how users perceive spatiotemporal vibrotactile
patterns on the arm, palm, thigh, and waist. Results of the first two experiments
indicate that precise recognition of either position or orientation is difficult across
multiple body parts. Nonetheless, users were able to distinguish whether two vibration
pulses were from the same location when played in quick succession. Based on this
finding, we designed eight spatiotemporal vibrotactile patterns and evaluated them
in two additional experiments. The results demonstrate that these patterns can be
reliably recognized (&gt;80%) across the four tested body parts, both in the lab and
in a more realistic context.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2487–2496},
numpages = {10},
keywords = {mobile device, palm, arm, tactile feedback, waist, notification, spatiotemporal vibrotactile pattern, thigh},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702350,
author = {Roumen, Thijs and Perrault, Simon T. and Zhao, Shengdong},
title = {NotiRing: A Comparative Study of Notification Channels for Wearable Interactive Rings},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702350},
doi = {10.1145/2702123.2702350},
abstract = {We conducted an empirical investigation of wearable interactive rings on the noticeability
of four instantaneous notification channels (light, vibration, sound, poke) and a
channel with gradually increased temperature (thermal) during five levels of physical
activity (laying down, sitting, standing, walking, and running). Results showed that
vibration was the most reliable and fastest channel to convey notification, followed
by poke and sound which shared similar noticeability. The noticeability of these three
channels was not affected by the level of physical activity. The other two channels,
light and thermal, were less noticeable and were affected by the level of physical
activity. Our post-experimental survey indicates that while noticeability has a significant
influence on user preference, each channel has its own unique advantages that make
it suitable for different notification scenarios.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2497–2500},
numpages = {4},
keywords = {sound, light, ring, activity, vibration, notification, wearable computing, poke, heat},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702459,
author = {Ion, Alexandra and Wang, Edward Jay and Baudisch, Patrick},
title = {Skin Drag Displays: Dragging a Physical Tactor across the User's Skin Produces a Stronger Tactile Stimulus than Vibrotactile},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702459},
doi = {10.1145/2702123.2702459},
abstract = {We propose a new type of tactile displays that drag a physical tactor across the skin
in 2D. We call this skin drag. We demonstrate how this allows us to communicate geometric
shapes or characters to users. The main benefit of our approach is that it simultaneously
produces two types of stimuli, i.e., (1) it moves a tactile stimulus across skin locations
and (2) it stretches the user's skin. Skin drag thereby combines the essential stimuli
produced by vibrotactile and skin stretch. In our study, skin drag allowed participants
to recognize tactile shapes significantly better than a vibrotactile array of comparable
size. We present two arm-worn prototype devices that implement our concept.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2501–2504},
numpages = {4},
keywords = {eyes-free, hands-free, wearable, haptics},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702190,
author = {Pfeiffer, Max and D\"{u}nte, Tim and Schneegass, Stefan and Alt, Florian and Rohs, Michael},
title = {Cruise Control for Pedestrians: Controlling Walking Direction Using Electrical Muscle Stimulation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702190},
doi = {10.1145/2702123.2702190},
abstract = {Pedestrian navigation systems require users to perceive, interpret, and react to navigation
information. This can tax cognition as navigation information competes with information
from the real world. We propose actuated navigation, a new kind of pedestrian navigation
in which the user does not need to attend to the navigation task at all. An actuation
signal is directly sent to the human motor system to influence walking direction.
To achieve this goal we stimulate the sartorius muscle using electrical muscle stimulation.
The rotation occurs during the swing phase of the leg and can easily be counteracted.
The user therefore stays in control. We discuss the properties of actuated navigation
and present a lab study on identifying basic parameters of the technique as well as
an outdoor study in a park. The results show that our approach changes a user's walking
direction by about 16°/m on average and that the system can successfully steer users
in a park with crowded areas, distractions, obstacles, and uneven ground.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2505–2514},
numpages = {10},
keywords = {electrical muscle stimulation, pedestrian navigation, actuated navigation, haptic feedback, wearable devices},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702128,
author = {Lopes, Pedro and Jonell, Patrik and Baudisch, Patrick},
title = {Affordance++: Allowing Objects to Communicate Dynamic Use},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702128},
doi = {10.1145/2702123.2702128},
abstract = {We propose extending the affordance of objects by allowing them to communicate dynamic
use, such as (1) motion (e.g., spray can shakes when touched), (2) multi-step processes
(e.g., spray can sprays only after shaking), and (3) behaviors that change over time
(e.g., empty spray can does not allow spraying anymore). Rather than enhancing objects
directly, however, we implement this concept by enhancing the user. We call this affordance++.
By stimulating the user's arms using electrical muscle stimulation, our prototype
allows objects not only to make the user actuate them, but also perform required movements
while merely approaching the object, such as not to touch objects that do not "want"
to be touched. In our user study, affordance++ helped participants to successfully
operate devices of poor natural affordance, such as a multi-functional slicer tool
or a magnetic nail sweeper, and to stay away from cups filled with hot liquids.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2515–2524},
numpages = {10},
keywords = {electrical muscle stimulation, affordance},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251740,
author = {Spano, Davide},
title = {Session Details: Automation and Interactive Feedback},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251740},
doi = {10.1145/3251740},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702521,
author = {Dehais, Frederic and Peysakhovich, Vsevolod and Scannella, S\'{e}bastien and Fongue, Jennifer and Gateau, Thibault},
title = {"Automation Surprise" in Aviation: Real-Time Solutions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702521},
doi = {10.1145/2702123.2702521},
abstract = {Conflicts between the pilot and the automation, when pilots detect but do not understand
them, cause "automation surprise" situations and jeopardize flight safety. We conducted
an experiment in a 3-axis motion flight simulator with 16 pilots equipped with an
eye-tracker to analyze their behavior and eye movements during the occurrence of such
a situation. The results revealed that this conflict engages participant's attentional
abilities resulting in excessive and inefficient visual search patterns. This experiment
confirmed the crucial need to design solutions for detecting the occurrence of conflictual
situations and to assist the pilots. We therefore proposed an approach to formally
identify the occurrence of "automation surprise" conflicts based on the analysis of
"silent mode changes" of the autopilot. A demonstrator was implemented and allowed
for the automatic trigger of messages in the cockpit that explains the autopilot behavior.
We implemented a real-time demonstrator that was tested as a proof-of-concept with
7 subjects facing 3 different conflicts with automation. The results shown the efficacy
of this approach which could be implemented in existing cockpits.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2525–2534},
numpages = {10},
keywords = {formal conflict detection, attentional process, eye tracking, human-computer interaction, automation surprise},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702609,
author = {Sutherland, Steven C. and Harteveld, Casper and Young, Michael E.},
title = {The Role of Environmental Predictability and Costs in Relying on Automation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702609},
doi = {10.1145/2702123.2702609},
abstract = {There is a growing need to understand how automated decision aids are implemented
and relied upon by users. Past research has focused on factors associated with the
user and automation technology to explain reliance. The purpose of the present study
was determining how the predictability of the environment affects reliance. In this
paper, we present the results from an experiment using a digital game where participants
had access to a free environmental cue of varying predictive validity. Some participants
also had access to automated advice at varying costs. We found that participants underutilized
automated advice in more predictable environments and when advice was more costly;
however, when costs were low and the environment was less predictable, participants
tended to overutilize automated advice. These findings provide insights for a more
complete model of automation use, and offer a framework for understanding automation
biases by considering how automation use compares to a model of optimality.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2535–2544},
numpages = {10},
keywords = {games as research method, expert advice, automated decision aids, decision-making, reliance on automation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702228,
author = {Schwarz, Julia and Mankoff, Jennifer and Hudson, Scott E.},
title = {An Architecture for Generating Interactive Feedback in Probabilistic User Interfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702228},
doi = {10.1145/2702123.2702228},
abstract = {Increasingly natural, sensed, and touch-based input is being integrated into devices.
Along the way, both custom and more general solutions have been developed for dealing
with the uncertainty that is associated with these forms of input. However, it is
difficult to provide dynamic, flexible, and continuous feedback about uncertainty
using traditional interactive infrastructure. Our contribution is a general architecture
with the goal of providing support for continual feedback about uncertainty. Our architecture
is based on prior work in modeling uncertainty using Monte Carlo sampling, and tracks
multiple interfaces -- one for each plausible and differentiable sequence of input
that the user may have intended. Importantly, it considers how the presentation of
uncertainty can be organized and implemented in a general way. Our primary contribution
is a method for reducing the number of alternative interfaces and fusing possible
interfaces into a single interface that both communicates uncertainty and allows for
disambiguation. We demonstrate the value of this result through a collection of 11
new and existing feedback techniques along with two applications demonstrating the
use of the feedback architecture.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2545–2554},
numpages = {10},
keywords = {systems &amp; toolkits, uncertain interfaces, probabilistic input},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702178,
author = {Li, Hanchuan and Ye, Can and Sample, Alanson P.},
title = {IDSense: A Human Object Interaction Detection System Based on Passive UHF RFID},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702178},
doi = {10.1145/2702123.2702178},
abstract = {In order to enable unobtrusive human object interaction detection, we propose a minimalistic
approach to instrumenting everyday objects with passive (i.e. battery-free) UHF RFID
tags. By measuring the changes in the physical layer of the communication channel
between the RFID tag and reader (such as RSSI, RF phase, and read rate) we are able
to classify, in real time, tag/object motion events along with two types of touch
events. Through a user study, we demonstrate that our real-time classification engine
is able to simultaneously track 20 objects and identify four movement classes with
93% accuracy. To demonstrate how robust this general-purpose interaction mechanism
is, we investigate three usage scenarios 1) interactive storytelling with toys 2)
inference of daily activities in the home 3) identification of customer browsing habits
in a retail setting.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2555–2564},
numpages = {10},
keywords = {object interaction, rfid, touch interface, activity detection},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251741,
author = {Schiphorst, Thecla},
title = {Session Details: Art &amp; Performance},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251741},
doi = {10.1145/3251741},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702544,
author = {Pan, Yue and Stolterman, Erik},
title = {What If HCI Becomes a Fashion Driven Discipline?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702544},
doi = {10.1145/2702123.2702544},
abstract = {Recent research shows that fashion already exists in the HCI domain and influences
and affects design and designers' thinking and practices throughout the design process.
In this note, we draw our insights from fashion related research within HCI and interaction
design, provide some observations about fashion-related design and research practices,
raise questions about our field as moving forward towards fashion driven discipline.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2565–2568},
numpages = {4},
keywords = {practice, design, research, fashion},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702538,
author = {Oppermann, Leif and Putschli, Clemens and Brosda, Constantin and Lobunets, Oleksandr and Prioville, Fabien},
title = {The Smartphone Project: An Augmented Dance Performance},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702538},
doi = {10.1145/2702123.2702538},
abstract = {The Smartphone Project (TSP) is an interactive dance-performance in a professional
setting that exploits the communication channels provided by smartphone-apps as a
new material in the dance-theatre domain. We present an account of the experience
and its staging. Based on an initial study with 36 participants from the audience,
we present results and discuss lessons learned from this project that might guide
similar future work.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2569–2572},
numpages = {4},
keywords = {dance, material, mixed reality, performance, smartphone, theatre, augmented reality, audience interaction, art},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702257,
author = {Reeves, Stuart and Greiffenhagen, Christian and Flintham, Martin and Benford, Steve and Adams, Matt and Row Farr, Ju and Tandavantij, Nicholas},
title = {I'd Hide You: Performing Live Broadcasting in Public},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702257},
doi = {10.1145/2702123.2702257},
abstract = {We present a study of a mixed reality game called 'I'd Hide You' that involves live
video streaming from the city streets. We chart the significant challenges facing
performers on the streets who must simultaneously engage in the game, stream compelling
video footage featuring themselves, and interact with a remote online audience. We
reveal how these street performers manage four key tensions: between their body and
camera; between the demands of online audiences and what takes place on-the-street;
between what appears 'frontstage' on camera versus what happens 'backstage'; and balancing
being a player of the game with being a performer. By reflecting on how they achieve
this, we are able to draw out wider lessons for future interfaces aimed at supporting
people broadcasting video of themselves to online audiences while engaged in games,
sports and other demanding real-world activities.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2573–2582},
numpages = {10},
keywords = {public settings, live broadcasting, camerawork, video},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702187,
author = {Hook, Jonathan and Clarke, Rachel and McCarthy, John and Anderson, Kate and Dudman, Jane and Wright, Peter},
title = {Making the Invisible Visible: Design to Support the Documentation of Participatory Arts Experiences},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702187},
doi = {10.1145/2702123.2702187},
abstract = {We explore how digital technology might support the documentation of experiences of
participatory arts engagement. During a fourteen session workshop series, we worked
with artists, project managers, support workers and participants to explore the integration
of digital media capture and presentation technologies into participatory arts workshops,
and the implications that this would have for the experiences and practices of key
stakeholders involved. We contribute insight into the social and practical challenges
faced when using digital technology to create documentation of participatory arts.
Our findings highlight the importance of situating documentation, sense making and
re-telling of experiences in sensitive contexts such as participatory arts within
the practices of skilled interpreters that are mindful of the complexities involved.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2583–2592},
numpages = {10},
keywords = {documentation, experience-centered design, socially engaged art, participatory arts, action research},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702220,
author = {Lee, Seung Ah and Bumbacher, Engin and Chung, Alice M. and Cira, Nate and Walker, Byron and Park, Ji Young and Starr, Barry and Blikstein, Paulo and Riedel-Kruse, Ingmar H.},
title = {Trap It! A Playful Human-Biology Interaction for a Museum Installation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702220},
doi = {10.1145/2702123.2702220},
abstract = {We developed Trap it!, a human-biology interaction (HBI) medium encompassing a touchscreen
interface, microscopy, and light projection. Users can interact with living cells
by drawing on a touchscreen displaying the microscope view of the cells. These drawings
are projected onto the microscopy field as light patterns, prompting observable movement
in phototactic responses. The system design enables stable and robust HBI and a wide
variety of programmed activities (art, games, and experiments). We investigated its
affordances as an exhibit in a science museum in both facilitated and unfacilitated
contexts. Overall, it had a low barrier of entry and fostered rich communication among
visitors. Visitors were particularly excited upon realizing that the interaction involved
real organisms, an understanding that was facilitated by the eyepiece on the physical
system. With the results from user study, we provide our observations, insights and
guidelines for designing HBI as a permanent museum exhibit.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2593–2602},
numpages = {10},
keywords = {human-biology interaction, interactive biology, biotic processing unit, tangible interactive microbiology, interactive microscope, biotic game},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251742,
author = {Shami, N. Sadat},
title = {Session Details: Bridging People &amp; Beliefs with Social Media},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251742},
doi = {10.1145/3251742},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702193,
author = {Zhang, Amy X. and Counts, Scott},
title = {Modeling Ideology and Predicting Policy Change with Social Media: Case of Same-Sex Marriage},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702193},
doi = {10.1145/2702123.2702193},
abstract = {Social media has emerged as a prominent platform where people can express their feelings
about social and political issues of our time. We study the many voices discussing
an issue within a constituency and how they reflect ideology and may signal the outcome
of important policy decisions. Focusing on the issue of same-sex marriage legalization,
we examine almost 2 million public Twitter posts related to same-sex marriage in the
U.S. states over the course of 4 years starting from 2011. Among other findings, we
find evidence of moral culture wars between ideologies and show that constituencies
that express higher levels of emotion and have fewer actively engaged participants
often precede legalization efforts that fail. From our measures, we build statistical
models to predict the outcome of potential policy changes, with our best model achieving
87% accuracy. We also achieve accuracies of 70%, comparable to public opinion surveys,
many months before a policy decision. We discuss how these analyses can augment traditional
political science techniques as well as assist activists and policy analysts in understanding
discussions on important issues at a population scale.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2603–2612},
numpages = {10},
keywords = {social media, same-sex marriage, public policy, political science},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702410,
author = {Birnholtz, Jeremy and Merola, Nicholas Aaron Ross and Paul, Arindam},
title = {"Is It Weird to Still Be a Virgin": Anonymous, Locally Targeted Questions on Facebook Confession Boards},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702410},
doi = {10.1145/2702123.2702410},
abstract = {People have long sought answers to questions online, typically using either anonymous
or pseudonymous forums or social network platforms that primarily use real names.
Systems that allow anonymous communication afford freedom to explore identity and
discuss taboo topics, but can result in negative disinhibited behavior such as cyberbullying.
Identifiable communication systems allows one to reach a known audience and avoid
negative disinhibition, but can constrain behavior with concerns about privacy and
reputation. One persistent design issue is understanding how to leverage the benefits
of anonymity without suffering its drawbacks. This paper presents a case study analysis
of question asking on Facebook confession boards (FCBs), a tool popular on some college
campuses. FCBs present a unique configuration in which members of an offline community
(e.g., a university) anonymously submit content to a moderator who posts it to a Facebook
page where others in the community can view it and respond. Response is via identifiable
Facebook comments and likes. Our results show users asking about taboo and stigmatized
topics with local others, and receiving relevant responses with little cyberbullying
or negativity.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2613–2622},
numpages = {10},
keywords = {social support, facebook, anonymity, identity},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702317,
author = {Kim, Jae Won and Kim, Dongwoo and Keegan, Brian and Kim, Joon Hee and Kim, Suin and Oh, Alice},
title = {Social Media Dynamics of Global Co-Presence During the 2014 FIFA World Cup},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702317},
doi = {10.1145/2702123.2702317},
abstract = {Sporting championships and other media events can induce very strong feelings of co-presence
that can change communication patterns within large communities. Live tweeting reactions
to media events provide high-resolution data with time-stamps to understand these
behavioral dynamics. We employ a computational focus group method to identify a population
of 790,744 international Twitter users, and we track their behavior before, during,
and after the 2014 FIFA World Cup. We pick, in particular, a set of Twitter users
who specified the teams that they are supporting, such that we can identify communities
of fans of the teams, as well as the entire community of World Cup fans. The structure,
dynamics, and content of communication of these communities of users are analyzed
to compare behavior outside of the matches to behavior during the event and to examine
behavioral responses across languages. Specifically, the temporal patterns of the
tweeting volume, topics, retweet- ing, and mentioning behaviors are analyzed. We find
there are similarities in the responses to media events, characteristic changes in
activity patterns of users, and substantial differences in linguistic features. These
findings have implications for designing more resilient socio-technical systems during
crises and developing better models of complex social behavior.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2623–2632},
numpages = {10},
keywords = {social sensor, dual screening, social tv, second screen, collective attention, twitter, world cup},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702152,
author = {Mejova, Yelena and Borge-Holthoefer, Javier and Weber, Ingmar},
title = {Bridges into the Unknown: Personalizing Connections to Little-Known Countries},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702152},
doi = {10.1145/2702123.2702152},
abstract = {How are you related to Malawi? Do recent events on the Comoros effect you in any subtle
way? Who in your extended social network is in Croatia? We seldom ask ourselves these
questions, yet a "long tail" of content beyond our everyday knowledge is waiting to
be explored. In this work we propose a recommendation task of creating interest in
little-known content by building personalized "bridges" to users. We consider an example
task of interesting users in little-known countries, and propose a system which aggregates
a user's Twitter profile, network, and tweets to create an interest model, which is
then matched to a library of knowledge about the countries. We perform a user study
of 69 participants and conduct 11 in-depth interviews in order to evaluate the efficacy
of the proposed approach and gather qualitative insight into the effect of multi-faceted
use of Twitter on the perception of the bridges. We find the increase in interest
concerning little-known content to greatly depend on the pre-existing disposition
to it. Additionally, we discover a set of vital properties good bridges must possess,
including recency, novelty, emotiveness, and a proper selection of language. Using
the proposed approach we aim to harvest the "invisible connections" to make explicit
the idea of a "small world" where even a faraway country is more closely connected
to you than you might have imagined.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2633–2642},
numpages = {10},
keywords = {personalization, recommendation, serendipity, filter bubble},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251743,
author = {de Oliveira, Rodrigo},
title = {Session Details: Quantified Self for Humans &amp; Pets},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251743},
doi = {10.1145/3251743},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702196,
author = {Hollis, Victoria and Konrad, Artie and Whittaker, Steve},
title = {Change of Heart: Emotion Tracking to Promote Behavior Change},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702196},
doi = {10.1145/2702123.2702196},
abstract = {Preventable behaviors contribute to many life threatening health problems. Behavior-change
technologies have been deployed to modify these, but such systems typically draw on
traditional behavioral theories that overlook affect. We examine the importance of
emotion tracking for behavior change. First, we conducted interviews to explore how
emotions influence unwanted behaviors. Next, we deployed a system intervention, in
which 35 participants logged information for a self-selected, unwanted behavior (e.g.,
smoking or overeating) over 21 days. 16 participants engaged in standard behavior
tracking using a Fact-Focused system to record objective information about goals.
19 participants used an Emotion-Focused system to record emotional consequences of
behaviors. Emotion-Focused logging promoted more successful behavior change and analysis
of logfiles revealed mechanisms for success: greater engagement of negative affect
for unsuccessful days and increased insight were key to motivating change. We present
design implications to improve behavior-change technologies with emotion tracking.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2643–2652},
numpages = {10},
keywords = {lifestyle, field experiment, user studies, emotions, everyday life, behavior change},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702230,
author = {Stawarz, Katarzyna and Cox, Anna L. and Blandford, Ann},
title = {Beyond Self-Tracking and Reminders: Designing Smartphone Apps That Support Habit Formation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702230},
doi = {10.1145/2702123.2702230},
abstract = {Habit formation is an important part of behavior change interventions: to ensure an
intervention has long-term effects, the new behavior has to turn into a habit and
become automatic. Smartphone apps could help with this process by supporting habit
formation. To better understand how, we conducted a 4-week study exploring the influence
of different types of cues and positive reinforcement on habit formation and reviewed
the functionality of 115 habit formation apps. We discovered that relying on reminders
supported repetition but hindered habit development, while the use of event-based
cues led to increased automaticity; positive reinforcement was ineffective. The functionality
review revealed that existing apps focus on self-tracking and reminders, and do not
support event-based cues. We argue that apps, and technology-based interventions in
general, have the potential to provide real habit support, and present design guidelines
for interventions that could support habit formation through contextual cues and implementation
intentions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2653–2662},
numpages = {10},
keywords = {behavior change, habit formation, smartphone apps},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702260,
author = {Lawson, Shaun and Kirman, Ben and Linehan, Conor and Feltwell, Tom and Hopkins, Lisa},
title = {Problematising Upstream Technology through Speculative Design: The Case of Quantified Cats and Dogs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702260},
doi = {10.1145/2702123.2702260},
abstract = {There is growing interest in technology that quantifies aspects of our lives. This
paper draws on critical practice and speculative design to explore, question and problematise
the ultimate consequences of such technology using the quantification of companion
animals (pets) as a case study. We apply the concept of "moving upstream" to study
such technology and use a qualitative research approach in which both pet owners,
and animal behavioural experts, were presented with, and asked to discuss, speculative
designs for pet quantification applications, the design of which were extrapolated
from contemporary trends. Our findings indicate a strong desire among pet owners for
technology that has little scientific justification, whilst our experts caution that
the use of technology to augment human-animal communication has the potential to disimprove
animal welfare, undermine human-animal bonds, and create human-human conflicts. Our
discussion informs wider debates regarding quantification technology.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2663–2672},
numpages = {10},
keywords = {personal informatics, the quantified dog., design fiction, critical design, animal-computer interaction},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702562,
author = {Mancini, Clara and Harris, Rob and Aengenheister, Brendan and Guest, Claire},
title = {Re-Centering Multispecies Practices: A Canine Interface for Cancer Detection Dogs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702562},
doi = {10.1145/2702123.2702562},
abstract = {We report on participatory design research where interaction designers, and canine
behavioral specialists, together with their cancer detection dogs, teamed up to better
support the dogs' life-saving work. We discuss interspecies communication challenges
in cancer detection training, requiring the dogs to use human signaling conventions
that perturb their detection work. We describe our effort to develop a technology
that could resolve those challenges, and how in the process our design focus gradually
shifted from a human-centered to a canine-centered interaction model. The resulting
interface, based on honest signaling, re-centers cancer detection practices on the
dogs themselves, enabling them to better express their potential as cancer detection
workers; it also provides a model for re-thinking human-computer interactions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2673–2682},
numpages = {10},
keywords = {cancer detection with dogs, honest signaling, interspecies communication, aci, canine-centered interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251744,
author = {Bach, Benjamin},
title = {Session Details: Visualizing Statistics &amp; Graphs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251744},
doi = {10.1145/3251744},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702262,
author = {Zgraggen, Emanuel and Drucker, Steven M. and Fisher, Danyel and DeLine, Robert},
title = {(S|qu)Eries: Visual Regular Expressions for Querying and Exploring Event Sequences},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702262},
doi = {10.1145/2702123.2702262},
abstract = {Many different domains collect event sequence data and rely on finding and analyzing
patterns within it to gain meaningful insights. Current systems that support such
queries either provide limited expressiveness, hinder exploratory workflows or present
interaction and visualization models which do not scale well to large and multi-faceted
data sets. In this paper we present (s|qu)eries (pronounced "Squeries"), a visual
query interface for creating queries on sequences (series) of data, based on regular
expressions. (s|qu)eries is a touch-based system that exposes the full expressive
power of regular expressions in an approachable way and interleaves query specification
with result visualizations. Being able to visually investigate the results of different
query-parts supports debugging and encourages iterative query-building as well as
exploratory work-flows. We validate our design and implementation through a set of
informal interviews with data scientists that analyze event sequences on a daily basis.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2683–2692},
numpages = {10},
keywords = {visual query languages, gesture interfaces, event sequences, visual analytics, query interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702347,
author = {Wacharamanotham, Chat and Subramanian, Krishna and V\"{o}lkel, Sarah Theres and Borchers, Jan},
title = {Statsplorer: Guiding Novices in Statistical Analysis},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702347},
doi = {10.1145/2702123.2702347},
abstract = {Each step of statistical analysis requires researchers to make decisions based on
both statistical knowledge and the knowledge of their own data. For novice analysts,
this is cognitively demanding and can lead to mistakes and misinterpretations of the
results. We present Statsplorer, a software that helps novices learn and perform inferential
statistical tests. It lets the user kick-start data analysis from their research questions.
Statsplorer automatically tests necessary statistical assumptions and uses visualizations
to guide the user in both selecting statistical tests and interpreting the results.
We compared Statsplorer with a statistics lecture and investigated how Statsplorer
prepares novices for learning statistics in an AB/BA crossover experiment. The results
indicates that using Statsplorer prior to the lecture leads to significantly better
test scores in understanding statistical assumptions and choosing appropriate statistical
tests. Statsplorer is open-source and is available online at: http://hci.rwth-aachen.de/statsplorer.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2693–2702},
numpages = {10},
keywords = {data visualization, inferential statistics, data analysis},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702237,
author = {Vuillemot, Romain and Perin, Charles},
title = {Investigating the Direct Manipulation of Ranking Tables for Time Navigation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702237},
doi = {10.1145/2702123.2702237},
abstract = {We introduce a novel time navigation technique to update ranking tables by direct
manipulation. The technique allows users to drag a table's cells to change the time
period, while a line chart overlays on top of the table to provide an overview of
the changes. The line chart is also a visual hint to control the pace at which data
are updated. We explore the design and usability of this technique for table variations
in size, time spans and data variability. We report the results of a usability study,
using academic citation rankings and economic complexity datasets, and discuss design
implications coming with real-world scenarios such as missing data and affordance.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2703–2706},
numpages = {4},
keywords = {information visualization, temporal navigation, ranking tables},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702585,
author = {Matejka, Justin and Anderson, Fraser and Fitzmaurice, George},
title = {Dynamic Opacity Optimization for Scatter Plots},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702585},
doi = {10.1145/2702123.2702585},
abstract = {Scatterplots are an effective and commonly used technique to show the relationship
between two variables. However, as the number of data points increases, the chart
suffers from "over-plotting" which obscures data points and makes the underlying distribution
of the data difficult to discern. Reducing the opacity of the data points is an effective
way to address over-plotting, however, setting the individual point opacity is a manual
task performed by the chart designer. We present a user-driven model of opacity scaling
for scatter plots built from crowd-sourced responses to opacity scaling tasks using
several synthetic data distributions, and then test our model on a collection of real-world
data sets.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2707–2710},
numpages = {4},
keywords = {overplotting, scatter plots, opacity, visualization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702376,
author = {Ragan, Eric D. and Goodall, John R. and Tung, Albert},
title = {Evaluating How Level of Detail of Visual History Affects Process Memory},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702376},
doi = {10.1145/2702123.2702376},
abstract = {Visual history tools provide visual representations of the workflow during data analysis
tasks. While there is an established need for reviewing analytic processes, and many
visual history tools provide visualizations to do so, it is not well known how helpful
the tools actually are for process recall. Through a controlled experiment, we evaluated
how the presence of a visual history aid and varying levels of visual detail affect
process memory. Participants conducted an analysis task using a visual text-document
analysis tool. We evaluated their memories of the process both immediately after the
analysis and then again one week later. Results showed that even visual history views
with reduced data-resolution were effective for aiding process memory. Further, even
without inclusion of any data in the visual history aids, the visual cues alone from
the final workspace were enough to improve memory of the main themes of analyses.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2711–2720},
numpages = {10},
keywords = {process memory, visual history, analytic provenance},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251745,
author = {Jones, Matt},
title = {Session Details: Understanding Everyday Use of Mobile Phones},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251745},
doi = {10.1145/3251745},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702162,
author = {Lord, Carolynne and Hazas, Mike and Clear, Adrian K. and Bates, Oliver and Whittam, Rosalind and Morley, Janine and Friday, Adrian},
title = {Demand in My Pocket: Mobile Devices and the Data Connectivity Marshalled in Support of Everyday Practice},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702162},
doi = {10.1145/2702123.2702162},
abstract = {This paper empirically explores the role that mobile devices have come to play in
everyday practice, and how this links to demand for network connectivity and online
services. After a preliminary device-logging period, thirteen participants were interviewed
about how they use their iPhones or iPads. Our findings build a picture of how, through
use of such devices, a variety of daily practices have come to depend upon a working
data connection, which sometimes surges, but is at least always a trickle. This aims
to inform the sustainable design of applications, services and infrastructures for
smartphones and tablets. By focusing our analysis in this way, we highlight a little-explored
challenge for sustainable HCI and discuss ideas for (re)designing around the principle
of 'light-weight' data 'needs'.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2729–2738},
numpages = {10},
keywords = {practices, network demand, mobile devices, sustainability, energy},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702486,
author = {Carrascal, Juan Pablo and Church, Karen},
title = {An In-Situ Study of Mobile App &amp; Mobile Search Interactions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702486},
doi = {10.1145/2702123.2702486},
abstract = {When trying to satisfy an information need, smartphone users frequently transition
from mobile search engines to mobile apps and vice versa. However, little is known
about the nature of these transitions nor how mobile search and mobile apps interact.
We report on a 2-week, mixed-method study involving 18 Android users, where we collected
real-world mobile search and mobile app usage data alongside subjective insights on
why certain interactions between apps and mobile search occur. Our results show that
when people engage with mobile search they tend to interact with more mobile apps
and for longer durations. We found that certain categories of apps are used more intensely
alongside mobile search. Furthermore we found differences in app usage before and
after mobile search and show how mobile app interactions can both prompt mobile search
and enable users to take action. We conclude with a discussion on what these patterns
mean for mobile search and how we might design mobile search experiences that take
these app interactions into account.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2739–2748},
numpages = {10},
keywords = {mobile search, mobile apps, user study},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702182,
author = {Bentley, Frank R. and Chen, Ying-Yu},
title = {The Composition and Use of Modern Mobile Phonebooks},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702182},
doi = {10.1145/2702123.2702182},
abstract = {Over the past decade, the mobile phonebook has evolved from a relatively short list
of people that one calls and texts to a many-hundred person list of aggregated contacts
from around the web. This is happening at a time when an increasing number of mobile
applications are relying on the mobile phonebook to create one's social network in
their services. Through a large-scale study of the phonebooks of 200 diverse participants,
containing 65,940 contacts, we set out to understand today's mobile contact lists.
Our participants reported that they did not recognize the names of 29% of their contacts
and we found that the most frequently contacted five contacts represent greater than
80% of all calls and text messages with phonebook contacts. We conclude with implications
for the design of mobile applications that rely on phonebook data.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2749–2758},
numpages = {10},
keywords = {mobile, phonebook, communication},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251746,
author = {Rukzio, Enrico},
title = {Session Details: GUI Size, Resolution &amp; Layout},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251746},
doi = {10.1145/3251746},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702406,
author = {Reda, Khairi and Johnson, Andrew E. and Papka, Michael E. and Leigh, Jason},
title = {Effects of Display Size and Resolution on User Behavior and Insight Acquisition in Visual Exploration},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702406},
doi = {10.1145/2702123.2702406},
abstract = {Large high-resolution displays are becoming increasingly common in research settings,
providing data scientists with visual interfaces for the analysis of large datasets.
Numerous studies have demonstrated unique perceptual and cognitive benefits afforded
by these displays in visual analytics and information visualization tasks. However,
the effects of these displays on knowledge discovery in exploratory visual analysis
are still poorly understood. We present the results of a small-scale study to better
understand how display size and resolution affect insight. Analyzing participants'
verbal statements, we find preliminary evidence that larger displays with more pixels
can significantly increase the number of discoveries reported during visual exploration,
while yielding broader, more integrative insights. Furthermore, we find important
differences in how participants performed the same visual exploration task using displays
of varying sizes. We tie these results to extant work and propose explanations by
considering the cognitive and interaction costs associated with visual exploration.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2759–2768},
numpages = {10},
keywords = {large high-resolution displays, cognitive biases, exploratory visual analysis, visualization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702390,
author = {Lischke, Lars and Mayer, Sven and Wolf, Katrin and Sahami Shirazi, Alireza and Henze, Niels},
title = {Subjective and Objective Effects of Tablet's Pixel Density},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702390},
doi = {10.1145/2702123.2702390},
abstract = {Pixel densities are increasing rapidly. We can observe this trend in particular for
mobile devices like smartphones and tablets. Previous work revealed an effect of pixel
density on subjective feedback and objective performance only for low resolution cathode
ray tube screens. It is unclear if this effect persists for the four times higher
pixel densities of current mobile devices. Therefore, we conducted a study to compare
four pixel densities with 359, 180, 120, and 90 pixels per inch. While participants
performed three tasks involving images, text and videos on a tablet, we measured perceived
effort, perceived visual quality, task completion time, error rate, and body pose.
Our results show that the effect of the pixel density highly depends on the content.
We found that only for text, the four pixel densities have clearly different perceived
media qualities. Pixel density seems to have a smaller effect on perceived media quality
for images and videos and we found no effect on objective measures. Results show that
text should be displayed in high resolution, while this is less important for images
and videos.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2769–2772},
numpages = {4},
keywords = {pixel density, resolution, tablet},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702132,
author = {Malacria, Sylvain and Aceituno, Jonathan and Quinn, Philip and Casiez, G\'{e}ry and Cockburn, Andy and Roussel, Nicolas},
title = {Push-Edge and Slide-Edge: Scrolling by Pushing Against the Viewport Edge},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702132},
doi = {10.1145/2702123.2702132},
abstract = {Edge-scrolling allows users to scroll a viewport while simultaneously dragging near
or beyond a window's edge. Common implementations rely on rate control, mapping the
distance between the pointer and the edge of the viewport to the scrolling velocity.
While ubiquitous in operating systems, edge-scrolling has received little attention,
even though previous works suggest that (1) rate control may be suboptimal for isotonic
pointing devices like mice and trackpads and (2) space beyond the window's edge might
be scarce, limiting scrolling control. To address these problems, we developed Push-edge
scrolling (and Slide-edge scrolling, its inertial variant), two novel position-based
techniques that allow scrolling by "pushing" against the viewport edge. A controlled
experiment shows that our techniques reduce overshoots and offer performance improvements
by up to 13% over traditional edge-scrolling.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2773–2776},
numpages = {4},
keywords = {rate control, autoscroll, inertia, position control, edge-scroll},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702375,
author = {Guillon, Maxime and Leitner, Fran\c{c}ois and Nigay, Laurence},
title = {Investigating Visual Feedforward for Target Expansion Techniques},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702375},
doi = {10.1145/2702123.2702375},
abstract = {Target expansion techniques facilitate the pointing task by enlarging the effective
sizes of targets. When the target expansion is applied to both the motor and visual
spaces, the visual feedforward mechanism is key: Indeed it provides a visual aid to
the user on the effective expanded targets prior to the execution or completion of
the pointing task, enabling the user to take full advantage of the target expansion
technique. Focusing on feedforward mechanisms, we introduce a design space that allows
us to describe, classify and design target expansion techniques. To do so we first
introduce and characterize the concept of atomic feedforward mechanism along three
design axes. We then describe a target expansion technique as a combination of atomic
feedforward mechanisms using a matrix-based notation. We provide an analytical exploration
of the design space by classifying existing techniques and by designing six new techniques.
We also provide a first experimental exploration of the design space in the context
of distant pointing. The experimental protocol includes an innovative target layout
for handling non-centroidal target expansion. The results show that feedforward dynamicity
increases movement time and decreases subjective usability, while explicit expansion
observability efficiently supports error prevention for distant pointing.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2777–2786},
numpages = {10},
keywords = {target expansion, feedforward, distant pointing, pointing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702198,
author = {Xu, Pengfei and Fu, Hongbo and Tai, Chiew-Lan and Igarashi, Takeo},
title = {GACA: Group-Aware Command-Based Arrangement of Graphic Elements},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702198},
doi = {10.1145/2702123.2702198},
abstract = {Many graphic applications rely on command-based arrangement tools to achieve precise
layouts. Traditional tools are designed to operate on a single group of elements that
are distributed consistently with the arrangement axis implied by a command. This
often demands a process with repeated element selections and arrangement commands
to achieve 2D layouts involving multiple rows and/or columns of well aligned and/or
distributed elements. Our work aims to reduce the numbers of selection operation and
command invocation, since such reductions are particularly beneficial to professional
designers who design lots of layouts. Our key idea is that an issued arrangement command
is in fact very informative, instructing how to automatically decompose a 2D layout
into multiple 1D groups, each of which is compatible with the command. We present
a parameter-free, command-driven grouping approach so that users can easily predict
our grouping results. We also design a simple user interface with pushpins to enable
explicit control of grouping and arrangement. Our user study confirms the intuitiveness
of our technique and its performance improvement over traditional command-based arrangement
tools.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2787–2795},
numpages = {9},
keywords = {group-aware, arrangement commands, alignment, layout editing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251747,
author = {Kazakos, Konstantinos},
title = {Session Details: Kids Social, Emotional &amp; Special Needs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251747},
doi = {10.1145/3251747},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702385,
author = {Slov\'{a}k, Petr and Gilad-Bachrach, Ran and Fitzpatrick, Geraldine},
title = {Designing Social and Emotional Skills Training: The Challenges and Opportunities for Technology Support},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702385},
doi = {10.1145/2702123.2702385},
abstract = {Social and emotional skills are crucial for all aspects of our everyday life. However,
understanding how digital technology can facilitate the development and learning of
such skills is yet an under-researched area in HCI. To start addressing this gap,
this paper reports on a series of interviews and design workshops with the leading
researchers and developers of 'Social and Emotional Learning' (SEL) curricula. SEL
is a subfield of educational psychology with a long history of teaching such skills,
and a range of evidence based curricula that are widely deployed in primary and secondary
schools. We identify the shared challenges across existing curricula that digital
technology might help address: the support for out-of-session learning, scaffolding
for parental engagement, and feedback for the curricula developers. We argue how this
presents an opportunity for mutually beneficial collaborations, with the potential
for significant real-world impact of novel HCI systems, and can inform HCI work on
supporting social and emotional skills development in other domains.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2797–2800},
numpages = {4},
keywords = {sel, social and emotional skills, education},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702471,
author = {Carter, Elizabeth J. and Hyde, Jennifer},
title = {Designing Autism Research for Maximum Impact},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702471},
doi = {10.1145/2702123.2702471},
abstract = {In recent decades, rates of autism spectrum disorder (ASD) have risen dramatically,
and research into assistive technologies for this population has similarly escalated.
For technology to be adopted, technologists need to communicate with practitioners
across fields and match methodological and evaluation standards. We provide a set
of recommendations for researchers to bridge the gap between fields and maximize the
impact of their research, including instructions on how to identify and describe research
participants and how to avoid research confounds and challenges specific to this population.
We also advocate that researchers in ASD maintain a nimble, adaptable approach when
performing experiments.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2801–2804},
numpages = {4},
keywords = {autism, methodology, asd, user studies},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702324,
author = {Ammari, Tawfiq and Schoenebeck, Sarita},
title = {Networked Empowerment on Facebook Groups for Parents of Children with Special Needs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702324},
doi = {10.1145/2702123.2702324},
abstract = {Theories of empowerment explain how people gain personal and political control to
take action to improve their lives. However, empowerment theories were developed prior
to the Internet and fail to account for the speed and scale that people can find one
another online. One domain where empowerment is critical is caring for children with
special needs, in which parents are required to navigate a complex maze of services
and processes to access care for their child. We conducted 43 interviews with parents
of children with special needs to investigate whether using social media sites helps
them to perform this caregiving work. Critically, parents are able to do this through
almost real-time access to other parents on Facebook. This work introduces the concept
of networked empowerment, that describes how parents find other parents, access resources,
and explore new ways for promoting health advocacy among caregivers at a local and
national level. We conclude with design implications for facilitating faster and better
access to information and support for caregivers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2805–2814},
numpages = {10},
keywords = {parents, disabilities, special needs, children, empowerment, social media},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702144,
author = {Kim, Jeeeun and Yeh, Tom},
title = {Toward 3D-Printed Movable Tactile Pictures for Children with Visual Impairments},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702144},
doi = {10.1145/2702123.2702144},
abstract = {Many children's books contain movable pictures with elements that can be physically
opened, closed, pushed, pulled, spun, flipped, or swung. But these tangible, interactive
reading experiences are inaccessible to children with visual impairments. This paper
presents a set of 3D-printable models designed as building blocks for creating movable
tactile pictures that can be touched, moved, and understood by children with visual
impairments. Examples of these models are canvases, connectors, hinges, spinners,
sliders, lifts, walls, and cutouts. They can be used to compose movable tactile pictures
to convey a range of spatial concepts, such as in/out, up/down, and high/low. The
design and development of these models were informed by three formative studies including
1) a survey on popular moving mechanisms in children's books and 3D-printed parts
to implement them, 2) two workshops on the process creating movable tactile pictures
by hand (e.g., Lego, Play-Doh), and 3) creation of wood-based prototypes and an informal
testing on sighted preschoolers. Also, we propose a design language based on XML and
CSS for specifying the content and structure of a movable tactile picture. Given a
specification, our system can generate a 3D-printable model. We evaluate our approach
by 1) transcribing six children's books, and 2) conducting six interviews on domain
experts including four teachers for the visually impaired, one blind adult, two publishers
at the National Braille Press, a renowned tactile artist, and a librarian.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2815–2824},
numpages = {10},
keywords = {tactile pictures, 3d printing, movables, 3d modeling},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702475,
author = {Derboven, Jan and Van Mechelen, Maarten and Slegers, Karin},
title = {Multimodal Analysis in Participatory Design with Children: A Primary School Case Study},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702475},
doi = {10.1145/2702123.2702475},
abstract = {We describe a multimodal method for the analysis of co-design outcomes in participatory
design (PD) with children. The multimodal approach we take allows researchers to treat
both verbal (notes, writings) and tangible material out-comes as complementary ways
of communicating design ideas. We argue that an integrated approach in which both
PD outcomes are compared and contrasted can result in a richer analysis, in which
underlying values can be identified more clearly. To illustrate the method, we describe
a PD process with primary school children.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2825–2828},
numpages = {4},
keywords = {participatory design, values, multimodality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702519,
author = {Derboven, Jan and Zaman, Bieke and Vissers, Jorick and Geerts, David and De Grooff, Dirk},
title = {The Fun and the Serious in an Educational Game: The Monkey Tales Case},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702519},
doi = {10.1145/2702123.2702519},
abstract = {We describe a study of Monkey Tales, an educational game targeted at primary school
children. Starting from the assumption that all meaning is socially constructed, we
focus our attention on the way an educational game, and its balance between fun and
serious aspects, is constructed in public texts (game manufacturer's communication
and game reviews) and in individual use (the way players and their parents talk about
the game). Through an analysis of public texts and individual use, we show how the
balance between the fun and the serious in Monkey Tales is constructed in different
ways.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2829–2832},
numpages = {4},
keywords = {fun-serious balance, discourse, educational games},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251748,
author = {Vines, John},
title = {Session Details: HCI for Civic Engagement},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251748},
doi = {10.1145/3251748},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702255,
author = {Harding, Mike and Knowles, Bran and Davies, Nigel and Rouncefield, Mark},
title = {HCI, Civic Engagement &amp; Trust},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702255},
doi = {10.1145/2702123.2702255},
abstract = {There is a widespread belief that pervasive technologies will encourage and facilitate
partnerships between citizens and civic authorities, enabling individuals to play
a greater role in civic planning, service delivery and infrastructure management.
However, at present sustained use and perceived value of civic engagement technologies
remains low because the design space is poorly understood by system developers who
focus almost exclusively on empowering citizens rather than adopting an informed,
inclusive approach that addresses the needs of both citizens and civic authorities,
and helps establish trusted relationships between these different stakeholders. We
report on an extensive study of civic engagement in the domain of public infrastructure
maintenance and provide insights into the civic management processes to support future
design of trusted civic engagement interactions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2833–2842},
numpages = {10},
keywords = {civic engagement, citizen participation, crowdsourcing, trust},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702352,
author = {Kim, Juho and Ko, Eun-Young and Jung, Jonghyuk and Lee, Chang Won and Kim, Nam Wook and Kim, Jihee},
title = {Factful: Engaging Taxpayers in the Public Discussion of a Government Budget},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702352},
doi = {10.1145/2702123.2702352},
abstract = {While a government budget determines how taxpayers' money is allocated to various
programs and stakeholders that compete for limited resources, the extensiveness and
complexity of the budget and its process hinder taxpayers from understanding the budget
information and participating in the public discussion. To engage taxpayers in the
public discussion around budgetary issues, we leverage news articles containing budgetary
information for design opportunities. We present Factful, a web-based annotative article
reading interface that enhances the article with fact-checking support and contextual
budgetary information by processing open government data. In our lab study, participants
using Factful discussed more critically with more fact-based supporting statements.
They built a rich context surrounding the relevant budget facts beyond what was presented
in the article. Factful presents a simple yet powerful model for supporting fact-oriented
budgetary discussions online by leveraging open government data.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2843–2852},
numpages = {10},
keywords = {open government data, fact-checking, discussion support, budget, deliberative democracy, annotation tool},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702176,
author = {Crivellaro, Clara and Comber, Rob and Dade-Robertson, Martyn and Bowen, Simon J. and Wright, Peter C. and Olivier, Patrick},
title = {Contesting the City: Enacting the Political Through Digitally Supported Urban Walks},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702176},
doi = {10.1145/2702123.2702176},
abstract = {We present a method for the situated discovery and articulation of issues at the intersection
between the politics of place making and city planning. We describe the construction
and use of designed tools, such as historical political archives; counterfactual maps;
and cards to invite situated dialogue between the social and institutional practices
and mechanisms that produce our cities. Grounded in an account of the political as
vernacular and embodied, our analysis advance understandings on the politics of design,
and on the complex interrelationship between places and political spaces. We outline
how HCI can adopt methods and develop sensitivities to support democratic practices
and publics envisioning their urban futures.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2853–2862},
numpages = {10},
keywords = {walking, place, digital media, politics},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702558,
author = {Taylor, Alex S. and Lindley, Si\^{a}n and Regan, Tim and Sweeney, David and Vlachokyriakos, Vasillis and Grainger, Lillie and Lingel, Jessica},
title = {Data-in-Place: Thinking through the Relations Between Data and Community},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702558},
doi = {10.1145/2702123.2702558},
abstract = {We present findings from a year-long engagement with a street and its community. The
work explores how the production and use of data is bound up with place, both in terms
of physical and social geography. We detail three strands of the project. First, we
consider how residents have sought to curate existing data about the street in the
form of an archive with physical and digital components. Second, we report endeavours
to capture data about the street's environment, especially of vehicle traffic. Third,
we draw on the possibilities afforded by technologies for polling opinion. We reflect
on how these engagements have: materialised distinctive relations between the community
and their data; surfaced flows and contours of data, and spatial, temporal and social
boundaries; and enacted a multiplicity of 'small worlds'. We consider how such a conceptualisation
of data-in-place is relevant to the design of technology.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2863–2872},
numpages = {10},
keywords = {place, community, data-in-place, data, digital civics},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251749,
author = {De Luca, Alexander},
title = {Session Details: Security Feedback &amp; Warnings},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251749},
doi = {10.1145/3251749},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702249,
author = {Egelman, Serge and Peer, Eyal},
title = {Scaling the Security Wall: Developing a Security Behavior Intentions Scale (SeBIS)},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702249},
doi = {10.1145/2702123.2702249},
abstract = {Despite the plethora of security advice and online education materials offered to
end-users, there exists no standard measurement tool for end-user security behaviors.
We present the creation of such a tool. We surveyed the most common computer security
advice that experts offer to end-users in order to construct a set of Likert scale
questions to probe the extent to which respondents claim to follow this advice. Using
these questions, we iteratively surveyed a pool of 3,619 computer users to refine
our question set such that each question was applicable to a large percentage of the
population, exhibited adequate variance between respondents, and had high reliability
(i.e., desirable psychometric properties). After performing both exploratory and confirmatory
factor analysis, we identified a 16-item scale consisting of four sub-scales that
measures attitudes towards choosing passwords, device securement, staying up-to-date,
and proactive awareness.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2873–2882},
numpages = {10},
keywords = {security behavior, psychometrics, individual differences},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702322,
author = {Anderson, Bonnie Brinton and Kirwan, C. Brock and Jenkins, Jeffrey L. and Eargle, David and Howard, Seth and Vance, Anthony},
title = {How Polymorphic Warnings Reduce Habituation in the Brain: Insights from an FMRI Study},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702322},
doi = {10.1145/2702123.2702322},
abstract = {Research on security warnings consistently points to habituation as a key reason why
users ignore security warnings. However, because habituation as a mental state is
difficult to observe, previous research has examined habituation indirectly by observing
its influence on security behaviors. This study addresses this gap by using functional
magnetic resonance imaging (fMRI) to open the "black box" of the brain to observe
habituation as it develops in response to security warnings. Our results show a dramatic
drop in the visual processing centers of the brain after only the second exposure
to a warning, with further decreases with subsequent exposures. To combat the problem
of habituation, we designed a polymorphic warning that changes its appearance. We
show in two separate experiments using fMRI and mouse cursor tracking that our polymorphic
warning is substantially more resistant to habituation than conventional warnings.
Together, our neurophysiological findings illustrate the considerable influence of
human biology on users' habituation to security warnings.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2883–2892},
numpages = {10},
keywords = {functional magnetic resonance imaging (fmri), security warnings, habituation, mouse cursor tracking},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702442,
author = {Felt, Adrienne Porter and Ainslie, Alex and Reeder, Robert W. and Consolvo, Sunny and Thyagaraja, Somas and Bettes, Alan and Harris, Helen and Grimes, Jeff},
title = {Improving SSL Warnings: Comprehension and Adherence},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702442},
doi = {10.1145/2702123.2702442},
abstract = {Browsers warn users when the privacy of an SSL/TLS connection might be at risk. An
ideal SSL warning would empower users to make informed decisions and, failing that,
guide confused users to safety. Unfortunately, users struggle to understand and often
disregard real SSL warnings. We report on the task of designing a new SSL warning,
with the goal of improving comprehension and adherence. We designed a new SSL warning
based on recommendations from warning literature and tested our proposal with microsurveys
and a field experiment. We ultimately failed at our goal of a well-understood warning.
However, nearly 30% more total users chose to remain safe after seeing our warning.
We attribute this success to opinionated design, which promotes safety with visual
cues. Subsequently, our proposal was released as the new Google Chrome SSL warning.
We raise questions about warning comprehension advice and recommend that other warning
designers use opinionated design.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2893–2902},
numpages = {10},
keywords = {warnings, tls/ssl, design, https, ssl, google consumer surveys, microsurveys, security},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702586,
author = {Shay, Richard and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith and Forget, Alain and Komanduri, Saranga and Mazurek, Michelle L. and Melicher, William and Segreti, Sean M. and Ur, Blase},
title = {A Spoonful of Sugar? The Impact of Guidance and Feedback on Password-Creation Behavior},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702586},
doi = {10.1145/2702123.2702586},
abstract = {Users often struggle to create passwords under strict requirements. To make this process
easier, some providers present real-time feedback during password creation, indicating
which requirements are not yet met. Other providers guide users through a multi-step
password-creation process. Our 6,435-participant online study examines how feedback
and guidance affect password security and usability. We find that real-time password-creation
feedback can help users create strong passwords with fewer errors. We also find that
although guiding participants through a three-step password-creation process can make
creation easier, it may result in weaker passwords. Our results suggest that service
providers should present password requirements with feedback to increase usability.
However, the presentation of feedback and guidance must be carefully considered, since
identical requirements can have different security and usability effects depending
on presentation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2903–2912},
numpages = {10},
keywords = {passwords, authentication, security policy, password-composition policies, usable security},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251750,
author = {Obrist, Marianna},
title = {Session Details: Wellness &amp; Wearables},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251750},
doi = {10.1145/3251750},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702482,
author = {Tholander, Jakob and Nylander, Stina},
title = {Snot, Sweat, Pain, Mud, and Snow: Performance and Experience in the Use of Sports Watches},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702482},
doi = {10.1145/2702123.2702482},
abstract = {We have conducted interviews with ten elite and recreational athletes to understand
their experiences and engagement with endurance sport and personal and wearable sports
technology. The athletes emphasized the experiential aspects of doing sports and the
notion of feeling was repeatedly used to talk about their activities. Technology played
both an instrumental role in measuring performance and feeding bio-data back to them,
and an experiential role in supporting and enhancing the sport experience. To guide
further interaction design research in the sports domain, we suggest two interrelated
ways of looking at sports performances and experiences, firstly through the notion
of a measured sense of performance, and secondly as a lived-sense of performance.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2913–2922},
numpages = {10},
keywords = {sports, experience, feeling, performance, heart rate monitors},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702384,
author = {Patel, Misha and O'Kane, Aisling Ann},
title = {Contextual Influences on the Use and Non-Use of Digital Technology While Exercising at the Gym},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702384},
doi = {10.1145/2702123.2702384},
abstract = {The use of wearable technology will become significantly more prevalent in the coming
years, with major companies releasing devices such as the Samsung Gear Fit. With sensors,
such as pedometers and heart rate monitors, embedded in these devices it is possible
to use them for fitness purposes. However, little is known about how wearable adopters
actually use wearable and existing technologies during exercise. In an exploratory
situated study of technology use and non-use in the context of the gym, fitness informatics
adopters showed varied practices related to distraction, appropriating technology
into their routines, and information needs. We discuss this variance in relation to
individual differences and the impact of the physical nature of the gym. Although
further research might show other influencing factors such as the social context,
we make a case for the use of situated studies to uncover tensions that lead to use
and non-use of technology that arise in the different unfolding situations of using
wearables in everyday life, including at the gym, which is a surprisingly complex
context.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2923–2932},
numpages = {10},
keywords = {situated studies, in the wild, context, wearables, gym, personal informatics, fitness, activity tracker, exercise, health},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702197,
author = {Khot, Rohit Ashok and Lee, Jeewon and Aggarwal, Deepti and Hjorth, Larissa and Mueller, Florian 'Floyd'},
title = {TastyBeats: Designing Palatable Representations of Physical Activity},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702197},
doi = {10.1145/2702123.2702197},
abstract = {In this paper, we introduce palatable representations that besides improving the understanding
of physical activity through abstract visualization also provide an appetizing drink
to celebrate the experience of being physically active. By designing such palatable
representations, our aim is to offer novel opportunities for reflection on one's physical
activities. We present TastyBeats, a fountain-based interactive system that creates
a fluidic spectacle of mixing sport drinks based on heart rate data of physical activity,
which the user can later consume to replenish the loss of body fluids due to the physical
activity. We articulate our experiences in designing the system as well as learning
gained through field deployments of the system in participants' homes for a period
of two weeks. We found that our system increased participants' awareness of physical
activity and facilitated a shared social experience, while the prepared drink was
treated as a hedonic reward that motivated participants to exercise more. Ultimately,
with this work, we aim to inspire and guide design thinking on palatable representations,
which we believe opens up new interaction possibilities to support physical activity
experience.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2933–2942},
numpages = {10},
keywords = {personal informatics, physical activity, palatable representation, quantified self, fluidic interfaces, human-food interaction (hfi)},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702374,
author = {Tajadura-Jim\'{e}nez, Ana and Basia, Maria and Deroy, Ophelia and Fairhurst, Merle and Marquardt, Nicolai and Bianchi-Berthouze, Nadia},
title = {As Light as Your Footsteps: Altering Walking Sounds to Change Perceived Body Weight, Emotional State and Gait},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702374},
doi = {10.1145/2702123.2702374},
abstract = {An ever more sedentary lifestyle is a serious problem in our society. Enhancing people's
exercise adherence through technology remains an important research challenge. We
propose a novel approach for a system supporting walking that draws from basic findings
in neuroscience research. Our shoe-based prototype senses a person's footsteps and
alters in real-time the frequency spectra of the sound they produce while walking.
The resulting sounds are consistent with those produced by either a lighter or heavier
body. Our user study showed that modified walking sounds change one's own perceived
body weight and lead to a related gait pattern. In particular, augmenting the high
frequencies of the sound leads to the perception of having a thinner body and enhances
the motivation for physical activity inducing a more dynamic swing and a shorter heel
strike. We here discuss the opportunities and the questions our findings open.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2943–2952},
numpages = {10},
keywords = {evaluation method, multimodal interfaces, auditory body perception, interaction styles, sonifica-tion, emotion},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251751,
author = {Halvey, Martin},
title = {Session Details: Task Interruption &amp; Resumption},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251751},
doi = {10.1145/3251751},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702539,
author = {Mariakakis, Alexander and Goel, Mayank and Aumi, Md Tanvir Islam and Patel, Shwetak N. and Wobbrock, Jacob O.},
title = {SwitchBack: Using Focus and Saccade Tracking to Guide Users' Attention for Mobile Task Resumption},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702539},
doi = {10.1145/2702123.2702539},
abstract = {Smartphones and tablets are often used in dynamic environments that force users to
break focus and attend to their surroundings, creating a form of "situational impairment."
Current mobile devices have no ability to sense when users divert or restore their
attention, let alone provide support for resuming tasks. We therefore introduce SwitchBack,
a system that allows mobile device users to resume tasks more efficiently. SwitchBack
is built upon Focus and Saccade Tracking (FAST), which uses the front-facing camera
to determine when the user is looking and how their eyes are moving across the screen.
In a controlled study, we found that FAST can identify how many lines the user has
read in a body of text within a mean absolute percent error of just 3.9%. We then
tested SwitchBack in a dual focus-of-attention task, finding that SwitchBack improved
average reading speed by 7.7% in the presence of distractions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2953–2962},
numpages = {10},
keywords = {reading, gaze-tracking, situational impairments, mobile},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702340,
author = {Jo, Jaemin and Kim, Bohyoung and Seo, Jinwook},
title = {EyeBookmark: Assisting Recovery from Interruption during Reading},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702340},
doi = {10.1145/2702123.2702340},
abstract = {In this paper, we present gaze-based bookmarking, EyeBookmark, to mitigate the deleterious
effect of interruption during reading. The key idea of EyeBookmark is to provide a
visual cue to help people decide where to resume reading. We design four highlighting
methods and conduct a controlled user study with a proof-of-concept design to verify
the usefulness of EyeBookmark. The user study demonstrates not only that participants
preferred our highlighting methods but also that such highlighting methods significantly
reduced the time taken to resume reading after interruption regardless of the difficulty
of text.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2963–2966},
numpages = {4},
keywords = {reading, interruption, eye-tracking},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702367,
author = {Lottridge, Danielle M. and Rosakranse, Christine and Oh, Catherine S. and Westwood, Sean J. and Baldoni, Katherine A. and Mann, Abrey S. and Nass, Clifford I.},
title = {The Effects of Chronic Multitasking on Analytical Writing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702367},
doi = {10.1145/2702123.2702367},
abstract = {Chronic multitaskers perform worse on core multitasking skills: memory management,
cognitive filtering and task switching, likely due to their inability to filter irrelevant
stimuli [17]. Our experiment examines effects of chronic multitasking with task-relevant
and irrelevant distractors on analytical writing quality. We found a general switch
cost and, when controlling for that cost, effects of chronic multitasking habits:
heavy multitaskers write worse essays in the irrelevant condition and better essays
in the relevant condition. Our study changes multitasking research paradigms in two
fundamental ways: it studied a realistic writing scenario including access to both
irrelevant and relevant distractors. We found that the effect of chronic multitasking
is complex; heavy multitaskers are seduced by unrelated distractors but able to integrate
multiple sources of relevant information.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2967–2970},
numpages = {4},
keywords = {multitasking, chronic multitasking, analytical writing, media multitasking index, distractors},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702156,
author = {Borst, Jelmer P. and Taatgen, Niels A. and van Rijn, Hedderik},
title = {What Makes Interruptions Disruptive? A Process-Model Account of the Effects of the Problem State Bottleneck on Task Interruption and Resumption},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702156},
doi = {10.1145/2702123.2702156},
abstract = {In this paper we present a computational cognitive model of task interruption and
resumption, focusing on the effects of the problem state bottleneck. Previous studies
have shown that the disruptiveness of interruptions is for an important part determined
by three factors: interruption duration, interrupting-task complexity, and moment
of interruption. However, an integrated theory of these effects is still missing.
Based on previous research into multitasking, we propose a first step towards such
a theory in the form of a process model that attributes these effects to problem state
requirements of both the interrupted and the interrupting task. Subsequently, we tested
two predictions of this model in two experiments. The experiments confirmed that problem
state requirements are an important predictor for the disruptiveness of interruptions.
This suggests that interfaces should be designed to a) interrupt users at low-problem
state moments and b) maintain the problem state for the user when interrupted.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2971–2980},
numpages = {10},
keywords = {computational model, problem state, working memory, interruptions, multitasking},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702593,
author = {Z\"{u}ger, Manuela and Fritz, Thomas},
title = {Interruptibility of Software Developers and Its Prediction Using Psycho-Physiological Sensors},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702593},
doi = {10.1145/2702123.2702593},
abstract = {Interruptions of knowledge workers are common and can cause a high cost if they happen
at inopportune moments. With recent advances in psycho-physiological sensors and their
link to cognitive and emotional states, we are interested whether such sensors might
be used to measure interruptibility of a knowledge worker. In a lab and a field study
with a total of twenty software developers, we examined the use of psycho-physiological
sensors in a real-world context. The results show that a Naive Bayes classifier based
on psycho-physiological features can be used to automatically assess states of a knowledge
worker's interruptibility with high accuracy in the lab as well as in the field. Our
results demonstrate the potential of these sensors to avoid expensive interruptions
in a real-world context. Based on brief interviews, we further discuss the usage of
such an interruptibility measure and interruption support for software developers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2981–2990},
numpages = {10},
keywords = {psycho-physiological, interruptibility, lab/field study},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251752,
author = {Baudisch, Patrick},
title = {Session Details: Using Random Body Parts for Input},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251752},
doi = {10.1145/3251752},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702391,
author = {Weigel, Martin and Lu, Tong and Bailly, Gilles and Oulasvirta, Antti and Majidi, Carmel and Steimle, J\"{u}rgen},
title = {ISkin: Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702391},
doi = {10.1145/2702123.2702391},
abstract = {We propose iSkin, a novel class of skin-worn sensors for touch input on the body.
iSkin is a very thin sensor overlay, made of biocompatible materials, and is flexible
and stretchable. It can be produced in different shapes and sizes to suit various
locations of the body such as the finger, forearm, or ear. Integrating capacitive
and resistive touch sensing, the sensor is capable of detecting touch input with two
levels of pressure, even when stretched by 30% or when bent with a radius of 0.5cm.
Furthermore, iSkin supports single or multiple touch areas of custom shape and arrangement,
as well as more complex widgets, such as sliders and click wheels. Recognizing the
social importance of skin, we show visual design patterns to customize functional
touch sensors and allow for a visually aesthetic appearance. Taken together, these
contributions enable new types of on-body devices. This includes finger-worn devices,
extensions to conventional wearable devices, and touch input stickers, all fostering
direct, quick, and discreet input for mobile computing.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2991–3000},
numpages = {10},
keywords = {wearable computing, flexible sensor, stretchable, touch input, mobile computing, on-body input, electronic skin},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702464,
author = {Chan, Liwei and Hsieh, Chi-Hao and Chen, Yi-Ling and Yang, Shuo and Huang, Da-Yuan and Liang, Rong-Hao and Chen, Bing-Yu},
title = {Cyclops: Wearable and Single-Piece Full-Body Gesture Input Devices},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702464},
doi = {10.1145/2702123.2702464},
abstract = {This paper presents Cyclops, a single-piece wearable device that sees its user's whole
body postures through an ego-centric view of the user that is obtained through a fisheye
lens at the center of the user's body, allowing it to see only the user's limbs and
interpret body postures effectively. Unlike currently available body gesture input
systems that depend on external cameras or distributed motion sensors across the user's
body, Cyclops is a single-piece wearable device that is worn as a pendant or a badge.
The main idea proposed in this paper is the observation of limbs from a central location
of the body. Owing to the ego-centric view, Cyclops turns posture recognition into
a highly controllable computer vision problem. This paper demonstrates a proof-of-concept
device, and an algorithm for recognizing static and moving bodily gestures based on
motion history images (MHI) and a random decision forest (RDF). Four example applications
of interactive bodily workout, a mobile racing game that involves hands and feet,
a full-body virtual reality system, and interaction with a tangible toy are presented.
The experiment on the bodily workout demonstrates that, from a database of 20 body
workout gestures that were collected from 20 participants, Cyclops achieved a recognition
rate of 79% using MHI and simple template matching, which increased to 92% with the
more advanced machine learning approach of RDF.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3001–3009},
numpages = {9},
keywords = {full-body gesture input, ego-centric view, posture recognition, single-point wearable devices},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702518,
author = {Holz, Christian and Buthpitiya, Senaka and Knaust, Marius},
title = {Bodyprint: Biometric User Identification on Mobile Devices Using the Capacitive Touchscreen to Scan Body Parts},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702518},
doi = {10.1145/2702123.2702518},
abstract = {Recent mobile phones integrate fingerprint scanners to authenticate users biometrically
and replace passwords, making authentication more convenient for users. However, due
to their cost, capacitive fingerprint scanners have been limited to top-of-the-line
phones, a result of the required resolution and quality of the sensor. We present
Bodyprint, a biometric authentication system that detects users' biometric features
using the same type of capacitive sensing, but uses the touchscreen as the image sensor
instead. While the input resolution of a touchscreen is ~6 dpi, the surface area is
larger, allowing the touch sensor to scan users' body parts, such as ears, fingers,
fists, and palms by pressing them against the display. Bodyprint compensates for the
low input resolution with an increased false rejection rate, but does not compromise
on authentication precision: In our evaluation with 12 participants, Bodyprint classified
body parts with 99.98% accuracy and identifies users with 99.52% accuracy with a retry
likelihood of 26.82% to prevent false positives, thereby bringing reliable biometric
user authentication to a vast number of commodity devices.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3011–3014},
numpages = {4},
keywords = {phones, capacitive touchscreen, user identification, mobile devices, biometric au-thentication, fingerprints.},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702572,
author = {Kao, Hsin-Liu (Cindy) and Dementyev, Artem and Paradiso, Joseph A. and Schmandt, Chris},
title = {NailO: Fingernails as an Input Surface},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702572},
doi = {10.1145/2702123.2702572},
abstract = {We present NailO, a nail-mounted gestural input surface. Using capacitive sensing
on printed electrodes, the interface can distinguish on-nail finger swipe gestures
with high accuracy (&gt;92%). NailO works in real-time: we miniaturized the system to
fit on the fingernail, while wirelessly transmitting the sensor data to a mobile phone
or PC. NailO allows one-handed and always-available input, while being unobtrusive
and discrete. Inspired by commercial nail stickers, the device blends into the user's
body, is customizable, fashionable and even removable. We show example applications
of using the device as a remote controller when hands are busy and using the system
to increase the input space of mobile phones.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3015–3018},
numpages = {4},
keywords = {printed electronics, wearable electronics, beauty technology, capacitive touch, gesture recognition},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702308,
author = {Fukahori, Koumei and Sakamoto, Daisuke and Igarashi, Takeo},
title = {Exploring Subtle Foot Plantar-Based Gestures with Sock-Placed Pressure Sensors},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702308},
doi = {10.1145/2702123.2702308},
abstract = {We propose subtle foot-based gestures named foot plantar-based (FPB) gestures that
are used with sock-placed pressure sensors. In this system, the user can control a
computing device by changing his or her foot plantar distributions, e.g., pressing
the floor with his/her toe. Because such foot movement is subtle, it is suitable for
use especially in a public space such as a crowded train. In this study, we first
conduct a guessability study to design a user-defined gesture set for interaction
with a computing device. Then, we implement a gesture recognizer with a machine learning
technique. To avoid unexpected gesture activations, we also collect foot plantar pressure
patterns made during daily activities such as walking, as negative training data.
Additionally, we evaluate the unobservability of FPB gestures by using crowdsourcing.
Finally, we conclude with several applications to further illustrate the utility of
FPB gestures.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3019–3028},
numpages = {10},
keywords = {foot plantar sensing device, hands-free interaction, user-defined gesture, sock-placed interface},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251753,
author = {Robert, Jacob},
title = {Session Details: Brain &amp; Physiological Data Use for HCI},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251753},
doi = {10.1145/3251753},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702454,
author = {Fairclough, Stephen H. and Karran, Alexander J. and Gilleade, Kiel},
title = {Classification Accuracy from the Perspective of the User: Real-Time Interaction with Physiological Computing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702454},
doi = {10.1145/2702123.2702454},
abstract = {The accurate classification of psychophysiological data is an important determinant
of the quality when interacting with a physiological computing system. Previous research
has focused on classification accuracy of psychophysiological data in purely mathematical
terms but little is known about how accuracy metrics relate to users' perceptions
of accuracy during real-time interaction. A group of 14 participants watched a series
of movie trailers and were asked to subjectively indicate their level of interest
in a binary high/low fashion. Psychophysiological data (EEG, ECG and SCL) were used
to create a binary classification of interest via a Support Vector Machine (SVM) algorithm.
After a period of training, participants received real-time feedback from the classification
algorithm and perceptions of accuracy were assessed. The purpose of the study was
to compare mathematical classification accuracy with the perceived accuracy of the
system as experienced by the users. Results indicated that perceived accuracy was
subject to a number of psychological biases resulting from expectations, entrainment
and development of trust. The F1 score was generally a significant predictor of perceived
accuracy.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3029–3038},
numpages = {10},
keywords = {psychophysiology, eeg, tagging media, physiological computing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702315,
author = {Maior, Horia A. and Pike, Matthew and Sharples, Sarah and Wilson, Max L.},
title = {Examining the Reliability of Using FNIRS in Realistic HCI Settings for Spatial and Verbal Tasks},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702315},
doi = {10.1145/2702123.2702315},
abstract = {Recent efforts have shown that functional near-infrared spectroscopy (fNIRS) has potential
value for brain sensing in HCI user studies. Research has shown that, although large
head movement significantly affects fNIRS data, typical keyboard use, mouse movement,
and non-task-related verbalisations do not affect measurements during Verbal tasks.
This work aims to examine the Reliability of fNIRS, by 1) confirming these prior findings,
and 2) significantly extending our understanding of how artefacts affect recordings
during Spatial tasks, since much of user interfaces and interaction is inherently
spatial. Our results show that artefacts have a significantly different impact during
Verbal and Spatial tasks. We contribute clearer insights into using fNIRS as a tool
within HCI user studies.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3039–3042},
numpages = {4},
keywords = {human cognition, functional near-infrared spectroscopy, fnirs, brain-computer interface, bci},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251754,
author = {Tian, Feng},
title = {Session Details: Software Engineering Tools},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251754},
doi = {10.1145/3251754},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702589,
author = {Baker, Catherine M. and Milne, Lauren R. and Ladner, Richard E.},
title = {StructJumper: A Tool to Help Blind Programmers Navigate and Understand the Structure of Code},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702589},
doi = {10.1145/2702123.2702589},
abstract = {It can be difficult for a blind developer to understand and navigate through a large
amount of code quickly, as they are unable to skim as easily as their sighted counterparts.
To help blind developers overcome this problem, we present StructJumper, an Eclipse
plugin that creates a hierarchical tree based on the nesting structure of a Java class.
The programmer can use the TreeView to get an overview of the code structure of the
class (including all the methods and control flow statements) and can quickly switch
between the TreeView and the Text Editor to get an idea of where they are within the
nested structure. To evaluate StructJumper, we had seven blind programmers complete
three tasks with and without our tool. We found that the users thought they would
use StructJumper and there was a trend that they were faster completing the tasks
with StructJumper.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3043–3052},
numpages = {10},
keywords = {screen reader, navigation, blind programmers, code structure, accessibility},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702319,
author = {Ou, Jibin and Vechev, Martin and Hilliges, Otmar},
title = {An Interactive System for Data Structure Development},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702319},
doi = {10.1145/2702123.2702319},
abstract = {Data structure algorithms are of fundamental importance in teaching and software development,
yet are difficult to understand. We propose a new approach for understanding, debugging
and developing heap manipulating data structures. The key technical idea of our work
is to combine deep parametric abstraction techniques emerging from the area of static
analysis with interactive abstraction manipulation. Our approach bridges program analysis
with HCI and enables new capabilities not possible before: i) online automatic visualization
of the data structure in a way which captures its essential operation, thus enabling
powerful local reasoning, and ii) fine grained pen and touch gestures allowing for
interactive control of the abstraction -- at any point the developer can pause the
program, graphically interact with the data, and continue program execution. These
features address some of the most pressing challenges in developing data structures.
We implemented our approach in a Java-based system called FluiEdt and evaluated it
with $27$ developers. The results indicate that FluiEdt is more effective in helping
developers find data structure errors than existing state of the art IDEs (e.g. Eclipse)
or pure visualization based approaches.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3053–3062},
numpages = {10},
keywords = {debugging, software development, program analysis},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702302,
author = {Lerner, Sorin and Foster, Stephen R. and Griswold, William G.},
title = {Polymorphic Blocks: Formalism-Inspired UI for Structured Connectors},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702302},
doi = {10.1145/2702123.2702302},
abstract = {We present a novel block-based UI called Polymorphic Blocks, in which a connector's
shape visually represents the structure of the data being passed through the connector.
We use Polymorphic Blocks to add visual type information to block-based programming
environments like Blockly or Scratch. We also use Polymorphic Blocks to represent
logical proofs. In this context, if we erase all symbols, our UI becomes a puzzle
game, where solving the puzzle amounts to building a proof. We show through a user
study that our Logical Puzzle Game is faster, more fun, and more engaging than an
equivalent pen-and-paper interface.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3063–3072},
numpages = {10},
keywords = {games, block-based programming environments, proofs},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251755,
author = {Geerts, David},
title = {Session Details: HCI at Home},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251755},
doi = {10.1145/3251755},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702540,
author = {Desjardins, Audrey and Wakkary, Ron and Odom, William},
title = {Investigating Genres and Perspectives in HCI Research on the Home},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702540},
doi = {10.1145/2702123.2702540},
abstract = {The home and domestic experiences have been studied from multiple points of view and
disciplines, with an array of methodologies in the past twenty-five years in HCI.
Given the attention to the home and the volume of research, what further areas of
research might there be? Based on a critical analysis of 121 works on the topic, we
present seven genres of domestic technology research in HCI: social routines in the
home, ongoing domestic practices, the home as a testing ground, smart homes, contested
values of a home, the home as a site for interpretation, and speculative visions of
the home. We articulate dominant research perspectives in HCI, and we offer two complementary
perspectives about how to investigate the domestic experience in future research:
the material perspective and the first person perspective.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3073–3082},
numpages = {10},
keywords = {home, critical analysis, reflective hci, domestic},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702602,
author = {Brotman, Ryan and Burleson, Winslow and Forlizzi, Jodi and Heywood, William and Lee, Jisoo},
title = {Building Change: Constructive Design of Smart Domestic Environments for Goal Achievement},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702602},
doi = {10.1145/2702123.2702602},
abstract = {This paper presents the constructive design research (CDR) of smart domestic environments
comprised of smart home infrastructure, smart domestic artifacts and digital services.
CDR is an approach that focuses on imagining futures and learning through the making
and testing of prototypes to construct new knowledge about how people engage with
the world. While the body of research on smart domestic environments includes a wealth
of human-centered research, the use of CDR is marginal. Our work demonstrates how
such a process engages residents in activities to imagine why people might value smart
domestic environments and how they might want to interact with them. Through goal
setting activities, paper prototyping, and field-testing of resident designed technology
probes, we present use cases, design principles and experiential insights. After sharing
these findings, we introduce the emergence of smart domestic environments as possessing
persuasive, personified and artful qualities.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3083–3092},
numpages = {10},
keywords = {domestic technologies, internet of things, prototyping, smart homes, constructive design, persuasive technologies, participatory design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702218,
author = {Chetty, Marshini and Kim, Hyojoon and Sundaresan, Srikanth and Burnett, Sam and Feamster, Nick and Edwards, W. Keith},
title = {UCap: An Internet Data Management Tool For The Home},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702218},
doi = {10.1145/2702123.2702218},
abstract = {Internet Service Providers (ISPs) have introduced "data caps", or quotas on the amount
of data that a customer can download during a billing cycle. Under this model, Internet
users who reach a data cap can be subject to degraded performance, extra fees, or
even temporary interruption of Internet service. For this reason, users need better
visibility into and control over their Internet usage to help them understand what
uses up data and control how these quotas are reached. In this paper, we present the
design and implementation of a tool, called uCap, to help home users manage Internet
data. We conducted a field trial of uCap in 21 home networks in three countries and
performed an in-depth qualitative study of ten of these homes. We present the results
of the evaluation and implications for the design of future Internet data management
tools.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3093–3102},
numpages = {10},
keywords = {data caps, home networking tools, bandwidth caps},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702278,
author = {Neate, Timothy and Jones, Matt and Evans, Michael},
title = {Mediating Attention for Second Screen Companion Content},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702278},
doi = {10.1145/2702123.2702278},
abstract = {There is increasing interest in providing content to users on secondary devices while
they watch TV. This material, termed companion content, can be anything from textual
information, to interactive quiz games. It can be delivered throughout a broadcast
and often directly relates to specific scenes in a show. This new scenario has exposed
a challenging design space for creators of both the content and the enabling technology.
A key question when introducing content on a secondary device is how much it detracts
from, or enhances, the show the user is currently engaged with. To examine this, we
investigated methods for mediating attention from the TV and onto a secondary device.
By examining a typical use case we have been able to gain new insights into how best
to design additional stimuli to alert users to companion content from both a broadcasting,
and an HCI perspective.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3103–3106},
numpages = {4},
keywords = {tv, companion content, attention, second screens, alerts},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251756,
author = {Monroy-Hernandez, Andres},
title = {Session Details: Voting &amp; Volunteerism},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251756},
doi = {10.1145/3251756},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702557,
author = {Hou, Youyang and Lampe, Cliff},
title = {Social Media Effectiveness for Public Engagement: Example of Small Nonprofits},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702557},
doi = {10.1145/2702123.2702557},
abstract = {Social media sites are increasingly adopted by small nonprofit organizations (NPOs)
to help them meet their public engagement goals. However, several characteristics
of small organizations make it hard for them to effectively use social media sites.
We present findings from interviews with 26 small NPOs' social media professionals
on how they use multiple social media sites to support public engagement. Small NPOs
use multiple social media sites to engage with different stakeholders toward various
ends. However, these NPOs are not using social media to its full potential with regard
to community-building and action mobilization. Several challenges in small NPOs, such
as ineffective measurement of social media performance, deficient organizational resources,
and lack of control over work, lead to strong tensions between social media engagement
strategies and outcomes. Drawing on these findings, we present several practical implications
for the design of successful public engagement social media tools.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3107–3116},
numpages = {10},
keywords = {nonprofit organization, organization, social media},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702378,
author = {Kim, Sunyoung and Mankoff, Jennifer and Paulos, Eric},
title = {Exploring Barriers to the Adoption of Mobile Technologies for Volunteer Data Collection Campaigns},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702378},
doi = {10.1145/2702123.2702378},
abstract = {Volunteer campaigns for data collection make it possible for non-profit organizations
to extend their ability to monitor and respond to critical environmental and societal
issues. Yet mobile data collection technologies that have the potential to lower the
costs and increase the accuracy of volunteer-collected data are not commonly used
in these campaigns. In this paper we conduct a series of studies that reveal the complex
issues affecting technology adoption in this domain. First, we surveyed and interviewed
existing volunteering campaigns to map out current technology usage within volunteer
campaigns. Next, we provided two organizations with a customizable tool for data collection
(Sensr) and studied its use and non-use across six real volunteer-driven campaigns
over six months. Our study explored success and failure across the first few phases
of the campaign lifecycle (campaign creation, initial deployment, and adoption). Our
results highlight the impact of resource constraints, cognitive factors, the depth
of volunteer engagement, and stakeholders' perspective on technology as important
factors contributing to the adoption and usage of mobile data collection technologies.
We use these findings to argue for specific design features to accelerate the adoption
and use of such tools in volunteer data collection campaigns.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3117–3126},
numpages = {10},
keywords = {citizen science, public participation, nonprofit organizations, mobile technology, data collection},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702263,
author = {Koeman, Lisa and Kalnikait\'{e}, Vaiva and Rogers, Yvonne},
title = {"Everyone Is Talking about It!": A Distributed Approach to Urban Voting Technology and Visualisations},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702263},
doi = {10.1145/2702123.2702263},
abstract = {The deployment of technology interventions, such as public displays and mobile apps,
in community settings has been found to engage people in sharing and comparing their
opinions. Our research is concerned with how to extend this to community-wide participation
by devising and deploying multiple voting devices and visualisations. We present an
in-the-wild study where a number of shopkeepers along a street participated by placing
a novel voting device in their shops to collect locals' opinions. Results were displayed
outside the shops, on the pavement. This distributed set-up was found to promote public
debate on local issues, particularly around the perceived divide between people on
either end of the street. We outline our design process and describe the impact of
distributing voting devices and situated visualisations in a local community. },
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3127–3136},
numpages = {10},
keywords = {public visualisations, design, opinion gathering technology, in-the-wild study},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702458,
author = {Boulus-R\o{}dje, Nina and Bjorn, Pernille},
title = {Design Challenges in Supporting Distributed Knowledge: An Examination of Organizing Elections},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702458},
doi = {10.1145/2702123.2702458},
abstract = {This paper identifies the design challenges for creating collaborative technologies
supporting the practices of organizing elections. We ethnographically investigate
the distributed nature of knowledge as enacted between heterogeneous groups over the
course of three elections in Denmark. We 1) identify fundamental characteristics of
elections, 2) provide a comprehensive account of the distributed nature of knowledge
in organizing and executing elections, and 3) point to new challenging areas for human-computer
interaction (HCI) design supporting distributed collaborative knowledge practices.
We found that organizational pattern of elections complicates the embodiment of nomadic
knowledge, which is crucial for managing the effective organization of an election.
Thus, one of the relevant design challenges is finding out how to support the timely
distribution of large amounts of information, while still ensuring it is appropriately
divided and delivered to various groups participating in planning and executing elections.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3137–3146},
numpages = {10},
keywords = {denmark, embodiment, voting, nomadic knowledge, organizing election, knowledge practice},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251757,
author = {Gou, Liang},
title = {Session Details: Socio-Political Interactions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251757},
doi = {10.1145/3251757},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702298,
author = {Pine, Kathleen H. and Liboiron, Max},
title = {The Politics of Measurement and Action},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702298},
doi = {10.1145/2702123.2702298},
abstract = {Contemporary decisions about the management of populations, public services, security,
and the environment are increasingly made through knowledge gleaned from "big data"
and its attendant infrastructures and algorithms. Though often described as "raw,"
this data is produced by techniques of measurement that are imbued with judgments
and values that dictate what is counted and what is not, what is considered the best
unit of measurement, and how different things are grouped together and "made" into
a measureable entity. In this paper, we analyze these politics of measurement and
how they relate to action through two case studies involving high stake public health
measurements where experts intentionally leverage measurement to change definitions
of harm and health. That is, they use measurement for activism. The case studies offer
a framework for thinking about of how the politics of measurement are present in user
interfaces. It is usually assumed that the human element has been scrubbed from the
database and that significant political and subjective interventions come from the
analysis or use of data after the fact. Instead, we argue that human-computer interactions
start before the data reaches the computer because various measurement interfaces
are the invisible premise of data and databases, and these measurements are political.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3147–3156},
numpages = {10},
keywords = {data, measurement, science and technology studies, evaluation, quantification, politics},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702203,
author = {Green, David Philip and Bowen, Simon J. and Newell, Christopher and Schofield, Guy and Bartindale, Tom and Crivellaro, Clara and Sheikh, Alia and Wright, Peter and Olivier, Patrick},
title = {Beyond Participatory Production: Digitally Supporting Grassroots Documentary},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702203},
doi = {10.1145/2702123.2702203},
abstract = {We conducted a study to explore the values and qualities of 'grassroots documentaries',
framed around the production of two parallel documentary films with a London-based
opera company. A team of professional filmmakers produced one film and the other was
an exploratory form of grassroots documentary. We studied the different production
activities through observations, interviews and a reflective workshop at the end of
the study and evaluated the resulting films. Our analysis reveals critical insights
that could inform the next generation of technological systems to support user-generated
video content (UGVC) production, particularly in collaborative contexts such as grassroots
communities.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3157–3166},
numpages = {10},
keywords = {grassroots, video, collaboration, production, documentary, participation, creativity, film, ugvc, ugc},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702403,
author = {Semaan, Bryan and Faucett, Heather and Robertson, Scott P. and Maruyama, Misa and Douglas, Sara},
title = {Designing Political Deliberation Environments to Support Interactions in the Public Sphere},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702403},
doi = {10.1145/2702123.2702403},
abstract = {Little is known about the challenges and successes people face when piecing together
multiple social media to interact in the online public sphere when: seeking information,
disseminating information, and engaging in political discussions. We interviewed 29
US citizens and conducted 17 talk-out-loud sessions with people who were using one
or more social media technologies, such as Facebook and Twitter, to interact in the
online public sphere. We identified a number of challenges and workarounds related
to public sphere interactions, and used our findings to formulate requirements for
new political environments that support the interactions in the public sphere. Through
evolving requirements generation, we developed a new political deliberation technology,
dubbed Poli, which is an integrated social media environment with the potential to
enable more effective interactions in the public sphere. We discuss several remaining
questions and limitations to our tool that will drive future work.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3167–3176},
numpages = {10},
keywords = {design, political deliberation, public sphere, social media},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702291,
author = {Brooker, Phil and Vines, John and Sutton, Selina and Barnett, Julie and Feltwell, Tom and Lawson, Shaun},
title = {Debating Poverty Porn on Twitter: Social Media as a Place for Everyday Socio-Political Talk},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702291},
doi = {10.1145/2702123.2702291},
abstract = {This paper presents an empirical investigation of how people appropriated Twitter
for socio-political talk in response to a television (TV) portrayal of people supported
by state welfare and benefits. Our findings reveal how online discussion during, and
in-between, TV broadcasts was characterised by distinctly different qualities, topics
and user behaviours. These findings offer design opportunities for social media services
to (i) support more balanced real-time commentaries of politically-charged media,
(ii) actively promote discussion to continue after, and between, programming; and
(iii) incorporate different motivations and attitudes towards socio-political concerns,
as well as different practices of communicating those concerns. We contribute to the
developing HCI literature on how social media intersects with political and civic
engagement and specifically highlight the ways in which Twitter interacts with other
forms of media as a site of everyday socio-political talk and debate.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3177–3186},
numpages = {10},
keywords = {social media, politics, television, welfare, live-tweeting},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251758,
author = {Czerwinski, Mary},
title = {Session Details: Understanding Health through Online Behavior},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251758},
doi = {10.1145/3251758},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702280,
author = {Tsugawa, Sho and Kikuchi, Yusuke and Kishino, Fumio and Nakajima, Kosuke and Itoh, Yuichi and Ohsaki, Hiroyuki},
title = {Recognizing Depression from Twitter Activity},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702280},
doi = {10.1145/2702123.2702280},
abstract = {In this paper, we extensively evaluate the effectiveness of using a user's social
media activities for estimating degree of depression. As ground truth data, we use
the results of a web-based questionnaire for measuring degree of depression of Twitter
users. We extract several features from the activity histories of Twitter users. By
leveraging these features, we construct models for estimating the presence of active
depression. Through experiments, we show that (1) features obtained from user activities
can be used to predict depression of users with an accuracy of 69%, (2) topics of
tweets estimated with a topic model are useful features, (3) approximately two months
of observation data are necessary for recognizing depression, and longer observation
periods do not contribute to improving the accuracy of estimation for current depression;
sometimes, longer periods worsen the accuracy.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3187–3196},
numpages = {10},
keywords = {twitter, social media, machine learning, depression},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702153,
author = {Abbar, Sofiane and Mejova, Yelena and Weber, Ingmar},
title = {You Tweet What You Eat: Studying Food Consumption Through Twitter},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702153},
doi = {10.1145/2702123.2702153},
abstract = {Food is an integral part of our lives, cultures, and well-being, and is of major interest
to public health. The collection of daily nutritional data involves keeping detailed
diaries or periodic surveys and is limited in scope and reach. Alternatively, social
media is infamous for allowing its users to update the world on the minutiae of their
daily lives, including their eating habits. In this work we examine the potential
of Twitter to provide insight into US-wide dietary choices by linking the tweeted
dining experiences of 210K users to their interests, demographics, and social networks.
We validate our approach by relating the caloric values of the foods mentioned in
the tweets to the state-wide obesity rates, achieving a Pearson correlation of 0.77
across the 50 US states and the District of Columbia. We then build a model to predict
county-wide obesity and diabetes statistics based on a combination of demographic
variables and food names mentioned on Twitter. Our results show significant improvement
over previous CHI research (Culotta 2014). We further link this data to societal and
economic factors, such as education and income, illustrating that areas with higher
education levels tweet about food that is significantly less caloric. Finally, we
address the somewhat controversial issue of the social nature of obesity (Christakis
&amp; Fowler 2007) by inducing two social networks using mentions and reciprocal following
relationships.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3197–3206},
numpages = {10},
keywords = {dietary health, social networks, obesity, food, twitter},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702154,
author = {Cordeiro, Felicia and Bales, Elizabeth and Cherry, Erin and Fogarty, James},
title = {Rethinking the Mobile Food Journal: Exploring Opportunities for Lightweight Photo-Based Capture},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702154},
doi = {10.1145/2702123.2702154},
abstract = {Food choices are among the most frequent and important health decisions in everyday
life, but remain notoriously difficult to capture. This work examines opportunities
for lightweight photo-based capture in mobile food journals. We first report on a
survey of 257 people, examining how they define healthy eating, their experiences
and challenges with existing food journaling methods, and their ability to interpret
nutritional information that can be captured in a food journal. We then report on
interviews and a field study with 27 participants using a lightweight, photo-based
food journal for between 4 to 8 weeks. We discuss mismatches between motivations and
current designs, challenges of current approaches to food journaling, and opportunities
for photos as an alternative to the pervasive but often inappropriate emphasis on
quantitative tracking in mobile food journals.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3207–3216},
numpages = {10},
keywords = {self-tracking, personal informatics, photos, food journals},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702566,
author = {Mamykina, Lena and Nakikj, Drashko and Elhadad, Noemie},
title = {Collective Sensemaking in Online Health Forums},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702566},
doi = {10.1145/2702123.2702566},
abstract = {Online health communities collect vast amounts of information and opinions in regards
to health and wellness management. However, these opinions are usually stored within
lengthy and loosely structured discussion threads; synthesizing information in these
threads can be challenging. In this mixed-methods study, grounded in the theoretical
perspective of collective sensemaking, we examined patterns of communication within
an online diabetes community TuDiabetes. The results of the study suggest that members
of TuDiabetes often construct shared meaning through deep discussions, back and forth
negotiation of perspectives, and resolution of conflicts in opinions. However, unlike
participants of other sensemaking communities, members of TuDiabetes often value multiplicity
of opinions rather than consensus. We use study results to draw implications for the
design of computing platforms for facilitating collective sensemaking that promote
construction of shared knowledge yet embrace diversity of opinions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3217–3226},
numpages = {10},
keywords = {online health communities, collective sensemaking, diabetes},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251759,
author = {Lee, Bongshin},
title = {Session Details: Natural User Interfaces for InfoVis},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251759},
doi = {10.1145/3251759},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702180,
author = {Jansen, Yvonne and Dragicevic, Pierre and Isenberg, Petra and Alexander, Jason and Karnik, Abhijit and Kildal, Johan and Subramanian, Sriram and Hornb\ae{}k, Kasper},
title = {Opportunities and Challenges for Data Physicalization},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702180},
doi = {10.1145/2702123.2702180},
abstract = {Physical representations of data have existed for thousands of years. Yet it is now
that advances in digital fabrication, actuated tangible interfaces, and shape-changing
displays are spurring an emerging area of research that we call Data Physicalization.
It aims to help people explore, understand, and communicate data using computer-supported
physical data representations. We call these representations physicalizations, analogously
to visualizations -- their purely visual counterpart. In this article, we go beyond
the focused research questions addressed so far by delineating the research area,
synthesizing its open challenges and laying out a research agenda.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3227–3236},
numpages = {10},
keywords = {physical visualization, data physicalization, visualization, shape-changing interfaces, tangible user interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702604,
author = {Taher, Faisal and Hardy, John and Karnik, Abhijit and Weichel, Christian and Jansen, Yvonne and Hornb\ae{}k, Kasper and Alexander, Jason},
title = {Exploring Interactions with Physically Dynamic Bar Charts},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702604},
doi = {10.1145/2702123.2702604},
abstract = {Visualizations such as bar charts help users reason about data, but are mostly screen-based,
rarely physical, and almost never physical and dynamic. This paper investigates the
role of physically dynamic bar charts and evaluates new interactions for exploring
and working with datasets rendered in dynamic physical form. To facilitate our exploration
we constructed a 10x10 interactive bar chart and designed interactions that supported
fundamental visualisation tasks, specifically; annotation, filtering, organization,
and navigation. The interactions were evaluated in a user study with 17 participants.
Our findings identify the preferred methods of working with the data for each task
i.e. directly tapping rows to hide bars, highlight the strengths and limitations of
working with physical data, and discuss the challenges of integrating the proposed
interactions together into a larger data exploration system. In general, physical
interactions were intuitive, informative, and enjoyable, paving the way for new explorations
in physical data visualizations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3237–3246},
numpages = {10},
keywords = {physical visualizations, tangible user interfaces, shape displays, information visualization, shape-changing interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702248,
author = {Stusak, Simon and Schwarz, Jeannette and Butz, Andreas},
title = {Evaluating the Memorability of Physical Visualizations},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702248},
doi = {10.1145/2702123.2702248},
abstract = {Physical Visualizations are currently mostly used in casual contexts, e.g., as artistic
data sculptures. However, their measurable benefits for traditional information visualization
are largely unexplored. As a step in this direction, we compared the memorability
of physical visualizations to that of digital visualizations. We conducted a user
study with 40 participants in which we measured the recall of three types of information
immediately after exploration and with a delay of two weeks. The results show that
the physical visualization led to significantly less information decay within this
time span. Our results build on known effects from cognitive psychology and provide
a first indicator for measurable benefits of physical visualizations regarding memorability.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3247–3250},
numpages = {4},
keywords = {evaluation, memorability, physical visualization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702590,
author = {Ottley, Alvitta and Yang, Huahai and Chang, Remco},
title = {Personality as a Predictor of User Strategy: How Locus of Control Affects Search Strategies on Tree Visualizations},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702590},
doi = {10.1145/2702123.2702590},
abstract = {Individual differences matter. While this has been the theme for many recent works
in the Visualization and HCI communities, the mystery of how to develop personalized
visualizations remains. This is largely because very little is known about how users
actually use visualizations to solve problems and even less is known about how individual
differences affect these problem-solving strategies. In this paper, we provide evidence
that strategies are indeed influenced by individual differences. We demonstrate how
the personality trait locus of control impacts strategies on hierarchical visualizations,
and we introduce design recommendations for personalized visualizations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3251–3254},
numpages = {4},
keywords = {individual differences, personality, locus of control, visualization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702129,
author = {Tsandilas, Theophanis and Bezerianos, Anastasia and Jacob, Thibaut},
title = {SketchSliders: Sketching Widgets for Visual Exploration on Wall Displays},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702129},
doi = {10.1145/2702123.2702129},
abstract = {We introduce a mobile sketching interface for exploring multi-dimensional datasets
on wall displays. We demonstrate the idea of SketchSliders, range sliders that users
can freely sketch on a mobile surface to customize their exploration. A small combination
of sketches and gestures allows the creation of complex interactive sliders, such
as circular sliders for periodic data, slider branches for detailed interaction, and
fisheye transformation sliders. We augment sliders with a suite of tools, such as
markers, slider cursors, and approximate views of data distributions. Our designs
are inspired by a design study with three visualization experts and validated through
a user study with six experts using our system. Our findings indicate that our sketching
interface accommodates a wide range of exploration strategies, helping users customize
as well as focus their visual explorations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3255–3264},
numpages = {10},
keywords = {wall displays, data visualization, sketching interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251760,
author = {Hanrahan, Benjamin},
title = {Session Details: UX Methods 4},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251760},
doi = {10.1145/3251760},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702168,
author = {Dittmar, Anke and Hensch, Maximilian},
title = {Two-Level Personas for Nested Design Spaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702168},
doi = {10.1145/2702123.2702168},
abstract = {The persona approach is often treated as a single user-centered design method, but
there are variations and adaptations for different design contexts which go beyond
local customization. The paper discusses a set of dimensions and success criteria
for describing the different persona uses, presenting a new framework. It then specifically
investigates personas in the context of end-user development. Professional designers
need to consider the design space for potential end-user tools. In addition they need
to understand that their users are often designers themselves (they are designer-users),
requiring that they also consider the design spaces of their users. Two-level personas
are introduced to make professional designers more aware of such nested design spaces.
A two-level persona consists of one first-level persona and a set of second-level
personas to additionally represent complex designer-user relationships. The effectiveness
of the approach is investigated in an exploratory empirical study. The results suggest
that two-level personas add value when designing end-user design tools.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3265–3274},
numpages = {10},
keywords = {user-centered design, personas, two-level personas, empirical studies., end-user development, design spaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702493,
author = {Clarke, Michael F.},
title = {The Work of Mad Men That Makes the Methods of Math Men Work: Practically Occasioned Segment Design},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702493},
doi = {10.1145/2702123.2702493},
abstract = {This study concerns the practical methods used to design segmentation models for digital
advertising. I illuminate some of the collaborative activities workers rely on to
create these web analytics based groupings. This work remains overlooked as the popularity
of automation and statistical methods for segmenting customers continues to grow.
I explain some of the ways the advertising customer is present as a background expectancy
while workers make segment composition decisions. This approach is meant to complement
established evaluative, technical, and statistical methods used to create segments
and personas in design and marketing. This may inspire similar approaches to designing
for specific groups of people while working with large data sets. Incorporating these
customer-orienting practices in design and advertising processes could lead to novel
approaches for both segment targeting and customer relationship management (CRM) software.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3275–3284},
numpages = {10},
keywords = {design, segmentation, ethnomethodology, personas, ethnography},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702579,
author = {Gray, Colin M. and Toombs, Austin L. and Gross, Shad},
title = {Flow of Competence in UX Design Practice},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702579},
doi = {10.1145/2702123.2702579},
abstract = {UX and design culture are beginning to dominate corporate priorities, but despite
the current hype there is often a disconnect between the organizational efficiencies
desired by executives and the knowledge of how UX can or should address these issues.
This exploratory study addresses this space by reframing the concept of competence
in UX to include the flow of competence between individual designers and the companies
in which they work. Our reframing resulted in a preliminary schema based on interviews
conducted with six design practitioners, which allows this flow to be traced in a
performative way on the part of individuals and groups over time. We then trace this
flow of individual and organizational competence through three case studies of UX
adoption. Opportunities for use of this preliminary schema as a generative, rhetorical
tool for HCI researchers to further interrogate UX adoption are considered, including
accounting for factors that affect adoption.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3285–3294},
numpages = {10},
keywords = {competence, interaction design, practice-led research},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702147,
author = {Baumer, Eric P.S.},
title = {Usees},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702147},
doi = {10.1145/2702123.2702147},
abstract = {HCI has developed a powerful vocabulary for thinking about, and methods for engaging
with, users. Similarly, recent work has advanced complementary understanding of technology
non-use. However, other spaces of interaction with technology may occur that sit uncomfortably
between these two poles. This paper presents two case studies highlighting individuals
who neither are clearly users of a system nor are clearly non-users. Based on these
cases, the paper develops the concept of usee to help account for such situations
that lie between existing analytic categories.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3295–3298},
numpages = {4},
keywords = {usees, non-use, users},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251761,
author = {Fjeld, Morten},
title = {Session Details: Augmented &amp; Virtual Reality in the Real World},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251761},
doi = {10.1145/3251761},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702389,
author = {Simeone, Adalberto L. and Velloso, Eduardo and Gellersen, Hans},
title = {Substitutional Reality: Using the Physical Environment to Design Virtual Reality Experiences},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702389},
doi = {10.1145/2702123.2702389},
abstract = {Experiencing Virtual Reality in domestic and other uncontrolled settings is challenging
due to the presence of physical objects and furniture that are not usually defined
in the Virtual Environment. To address this challenge, we explore the concept of Substitutional
Reality in the context of Virtual Reality: a class of Virtual Environments where every
physical object surrounding a user is paired, with some degree of discrepancy, to
a virtual counterpart. We present a model of potential substitutions and validate
it in two user studies. In the first study we investigated factors that affect participants'
suspension of disbelief and ease of use. We systematically altered the virtual representation
of a physical object and recorded responses from 20 participants. The second study
investigated users' levels of engagement as the physical proxy for a virtual object
varied. From the results, we derive a set of guidelines for the design of future Substitutional
Reality experiences.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3307–3316},
numpages = {10},
keywords = {passive haptics, substitutional reality, virtual reality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702222,
author = {Miksik, Ondrej and Vineet, Vibhav and Lidegaard, Morten and Prasaath, Ram and Nie\ss{}ner, Matthias and Golodetz, Stuart and Hicks, Stephen L. and P\'{e}rez, Patrick and Izadi, Shahram and Torr, Philip H.S.},
title = {The Semantic Paintbrush: Interactive 3D Mapping and Recognition in Large Outdoor Spaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702222},
doi = {10.1145/2702123.2702222},
abstract = {We present an augmented reality system for large scale 3D reconstruction and recognition
in outdoor scenes. Unlike existing prior work, which tries to reconstruct scenes using
active depth cameras, we use a purely passive stereo setup, allowing for outdoor use
and extended sensing range. Our system not only produces a map of the 3D environment
in real-time, it also allows the user to draw (or 'paint') with a laser pointer directly
onto the reconstruction to segment the model into objects. Given these examples our
system then learns to segment other parts of the 3D map during online acquisition.
Unlike typical object recognition systems, ours therefore very much places the user 'in the loop' to segment particular objects of interest, rather than learning from
predefined databases. The laser pointer additionally helps to 'clean up' the stereo
reconstruction and final 3D map, interactively. Using our system, within minutes,
a user can capture a full 3D map, segment it into objects of interest, and refine
parts of the model during capture. We provide full technical details of our system
to aid replication, as well as quantitative evaluation of system components. We demonstrate
the possibility of using our system for helping the visually impaired navigate through
spaces. Beyond this use, our system can be used for playing large-scale augmented
reality games, shared online to augment streetview data, and used for more detailed
car and person navigation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3317–3326},
numpages = {10},
keywords = {augmented reality, visually impaired, 3d reconstruction, laser pointer interaction, stereo, semantic segmentation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702214,
author = {Tung, Ying-Chao and Hsu, Chun-Yen and Wang, Han-Yu and Chyou, Silvia and Lin, Jhe-Wei and Wu, Pei-Jung and Valstar, Andries and Chen, Mike Y.},
title = {User-Defined Game Input for Smart Glasses in Public Space},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702214},
doi = {10.1145/2702123.2702214},
abstract = {Smart glasses, such as Google Glass, provide always-available displays not offered
by console and mobile gaming devices, and could potentially offer a pervasive gaming
experience. However, research on input for games on smart glasses has been constrained
by the available sensors to date. To help inform design directions, this paper explores
user-defined game input for smart glasses beyond the capabilities of current sensors,
and focuses on the interaction in public settings. We conducted a user-defined input
study with 24 participants, each performing 17 common game control tasks using 3 classes
of interaction and 2 form factors of smart glasses, for a total of 2448 trials. Results
show that users significantly preferred non-touch and non-handheld interaction over
using handheld input devices, such as in-air gestures. Also, for touch input without
handheld devices, users preferred interacting with their palms over wearable devices
(51% vs 20%). In addition, users preferred interactions that are less noticeable due
to concerns with social acceptance, and preferred in-air gestures in front of the
torso rather than in front of the face (63% vs 37%).},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3327–3336},
numpages = {10},
keywords = {guessability, wearable, public space, game, user-defined, pervasive gaming, control, smart glasses, input},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702490,
author = {Mohr, Peter and Kerbl, Bernhard and Donoser, Michael and Schmalstieg, Dieter and Kalkofen, Denis},
title = {Retargeting Technical Documentation to Augmented Reality},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702490},
doi = {10.1145/2702123.2702490},
abstract = {We present a system which automatically transfers printed technical documentation,
such as handbooks, to three-dimensional Augmented Reality. Our system identifies the
most frequent forms of instructions found in printed documentation, such as image
sequences, explosion diagrams, textual annotations and arrows indicating motion. The
analysis of the printed documentation works automatically, with minimal user input.
The system only requires the documentation itself and a CAD model or 3D scan of the
object described in the documentation. The output is a fully interactive Augmented
Reality application, presenting the information from the printed documentation in
3D, registered to the real object.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3337–3346},
numpages = {10},
keywords = {augmented reality, retargeting, virtual reality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251762,
author = {Henze, Niels},
title = {Session Details: Gesture Elicitation &amp; Recognition},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251762},
doi = {10.1145/3251762},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702583,
author = {Ruiz, Jaime and Vogel, Daniel},
title = {Soft-Constraints to Reduce Legacy and Performance Bias to Elicit Whole-Body Gestures with Low Arm Fatigue},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702583},
doi = {10.1145/2702123.2702583},
abstract = {Participant biases can influence proposed gestures in elicitation studies. There is
a legacy bias from previous experience with, or even knowledge of, existing input
devices, interfaces, and technologies. There is also a performance bias, where the
artificial study setting does not encourage consideration of long-term aspects such
as fatigue. These biases make it especially difficult to uncover gestures appropriate
for whole-body gestural input. We propose using soft constraints to correct for legacy
and performance biases by penalizing physical movements. We use wrist weights as a
soft constraint to elicit whole-body gestures with low arm fatigue. We show soft constraints
encourage a wider range of gestures using subtler arm movements or alternate body
parts and lower consumed endurance for arm movements.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3347–3350},
numpages = {4},
keywords = {whole-body gestures, elicitation studies},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702505,
author = {Fuccella, Vittorio and Costagliola, Gennaro},
title = {Unistroke Gesture Recognition Through Polyline Approximation and Alignment},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702505},
doi = {10.1145/2702123.2702505},
abstract = {We present a novel gesture recognizer suitable for fast prototyping of gesture-based
applications. The recognizer uses a nearest neighbor approach, and requires a small
number of samples for each class. The similarity between two gestures is calculated
through a three steps procedure: firstly, each gesture is approximated to a polyline,
in order to extract its main movements; then, the two polylines are aligned to obtain
an equal number of segments from both of them; lastly, the distance is found by summing
the contribution of each pair of segments. We tested the recognizer on two different
datasets and found that it performs more accurately than a state-of-art method.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3351–3354},
numpages = {4},
keywords = {unistroke gestures, gesture-based interaction, polyrec, gesture recognition},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702610,
author = {Lu, Hao and Li, Yang},
title = {Gesture On: Enabling Always-On Touch Gestures for Fast Mobile Access from the Device Standby Mode},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702610},
doi = {10.1145/2702123.2702610},
abstract = {A significant percentage of mobile interaction involves short-period usages that originate
from the standby mode-users wake up a device by pressing the power button, unlock
the device by authenticating themselves, and then search for a target app or functionality
on the device. These additional steps preceding a target task imposes significant
overhead on users for each mobile device access. To address the issue, we developed
Gesture On, a system that enables gesture shortcuts in the standby mode by which a
user can draw a gesture on the touchscreen before the screen is turned on. Based on
the gesture, our system directly brings up a target item onto the screen that bypasses
all these additional steps in a mobile access. This paper examines several challenges
in realizing Gesture On, including robustly rejecting accidental touches when the
device is in standby, battery consumption incurred for continuous sensing and gesture-based
user authentication methods for automatically device unlocking. Our analyses based
on a set of user data indicated that Gesture On demonstrates a feasible approach for
leveraging the standby mode for fast access to mobile content.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3355–3364},
numpages = {10},
keywords = {power efficiency, standby mode, gesture-based interaction, mobile computing, gesture recognition},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702357,
author = {Smith, Brian A. and Bi, Xiaojun and Zhai, Shumin},
title = {Optimizing Touchscreen Keyboards for Gesture Typing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702357},
doi = {10.1145/2702123.2702357},
abstract = {Despite its growing popularity, gesture typing suffers from a major problem not present
in touch typing: gesture ambiguity on the Qwerty keyboard. By applying rigorous mathematical
optimization methods, this paper systematically investigates the optimization space
related to the accuracy, speed, and Qwerty similarity of a gesture typing keyboard.
Our investigation shows that optimizing the layout for gesture clarity (a metric measuring
how unique word gestures are on a keyboard) drastically improves the accuracy of gesture
typing. Moreover, if we also accommodate gesture speed, or both gesture speed and
Qwerty similarity, we can still reduce error rates by 52% and 37% over Qwerty, respectively.
In addition to investigating the optimization space, this work contributes a set of
optimized layouts such as GK-D and GK-T that can immediately benefit mobile device
users.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3365–3374},
numpages = {10},
keywords = {text entry, word-gesture keyboard, gesture typing, shape writing, touchscreen keyboard optimization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702184,
author = {Putze, Felix and Amma, Christoph and Schultz, Tanja},
title = {Design and Evaluation of a Self-Correcting Gesture Interface Based on Error Potentials from EEG},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702184},
doi = {10.1145/2702123.2702184},
abstract = {Any user interface which automatically interprets the user's input using natural modalities
like gestures makes mistakes. System behavior depending on such mistakes will confuse
the user and lead to an erroneous interaction flow. The automatic detection of error
potentials in electroencephalographic data recorded from a user allows the system
to detect such states of confusion and automatically bring the interaction back on
track. In this work, we describe the design of such a self-correcting gesture interface,
implement different strategies to deal with detected errors, use a simulation approach
to analyze performance and costs of those strategies and execute a user study to evaluate
user satisfaction. We show that self-correction significantly improves gesture recognition
accuracy at lower costs and with higher acceptance than manual correction.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3375–3384},
numpages = {10},
keywords = {gesture recognition, adaptive interface, user study, self-correction, error-potentials, simulation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251763,
author = {Lee, Joonhwan},
title = {Session Details: Programming Environments},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251763},
doi = {10.1145/3251763},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702495,
author = {Vigo, Markel and Jay, Caroline and Stevens, Robert},
title = {Constructing Conceptual Knowledge Artefacts: Activity Patterns in the Ontology Authoring Process},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702495},
doi = {10.1145/2702123.2702495},
abstract = {Ontologies are complex knowledge representation artefacts used widely across biomedical,
media and industrial domains. They are used for defining terminologies and providing
metadata, especially for linked open data, and as such their use is rapidly increasing,
but so far development tools have not benefited from empirical research into the ontology
authoring process. This paper presents the results of a study that identifies common
activity patterns through analysis of eye-tracking data and the event logs of the
popular authoring tool, Prot\'{e}g\'{e}. Informed by the activity patterns discovered, we
propose design guidelines for bulk editing, efficient reasoning and increased situational
awareness. Methodological implications go beyond the remit of knowledge artefacts:
we establish a method for studying the usability of software designed for highly specialised
complex domains.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3385–3394},
numpages = {10},
keywords = {activity patterns, ontologies, semantic web, knowledge representation, authoring tools, complex domains},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702433,
author = {Zhang, Yuhao and Tudorache, Tania and Horridge, Matthew and Musen, Mark A.},
title = {Helping Users Bootstrap Ontologies: An Empirical Investigation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702433},
doi = {10.1145/2702123.2702433},
abstract = {An ontology is a machine processable artifact that captures knowledge about some domain
of interest. Ontologies are used in various domains including healthcare, science,
and commerce. In this paper we examine the ontology bootstrapping problem. Specifically,
we look at an approach that uses both competency questions and knowledge source reuse
via recommendations to address the "cold start problem" that is, the task of creating
an ontology from scratch. We describe this approach, an implementation of it, and
we present an evaluation in the form of a controlled user study. We find that the
approach leads users into creating significantly more detailed initial ontologies
that have a greater domain coverage than ontologies produced without this support.
Furthermore, in spite of a more involved workflow, the usability and user satisfaction
of the bootstrapping approach is as good as a state-of-the-art ontology editor with
no additional support.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3395–3398},
numpages = {4},
keywords = {bootstrapping, authoring, user study, ontologies, competency questions},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702587,
author = {Chang, Kerry Shih-Ping and Myers, Brad A.},
title = {A Spreadsheet Model for Handling Streaming Data},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702587},
doi = {10.1145/2702123.2702587},
abstract = {We present a spreadsheet model for working with streaming data. Our prototype tool
presents techniques to let the user stream data from web services and web input elements
to a spreadsheet without preprogramming those sources into the tool. Spreadsheet cells
record metadata about where and when the data came from, allowing the user to view
and manipulate streaming data using temporal information. Starting and pausing a data
stream in the spreadsheet can be controlled programmatically using values computed
by spreadsheet cells, making the spreadsheet program highly dynamic and interactive.
We demonstrate the range of our design with a series of examples highlighting its
ability to create different kinds of applications that process real-time data from
the web using simple spreadsheet formulas.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3399–3402},
numpages = {4},
keywords = {web services, live programming, spreadsheets, streaming data, end-user pro-gramming},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702140,
author = {Kato, Jun and Nakano, Tomoyasu and Goto, Masataka},
title = {TextAlive: Integrated Design Environment for Kinetic Typography},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702140},
doi = {10.1145/2702123.2702140},
abstract = {This paper presents TextAlive, a graphical tool that allows interactive editing of
kinetic typography videos in which lyrics or transcripts are animated in synchrony
with the corresponding music or speech. While existing systems have allowed the designer
and casual user to create animations, most of them do not take into account synchronization
with audio signals. They allow predefined motions to be applied to objects and parameters
to be tweaked, but it is usually impossible to extend the predefined set of motion
algorithms within these systems. We therefore propose an integrated design environment
featuring (1) GUIs that designers can use to create and edit animations synchronized
with audio signals, (2) integrated tools that programmers can use to implement animation
algorithms, and (3) a framework for bridging the interfaces for designers and programmers.
A preliminary user study with designers, programmers, and casual users demonstrated
its capability in authoring various kinetic typography videos.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3403–3412},
numpages = {10},
keywords = {live programming, creativity support tool, animation, kinetic typography, integrated design environment},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702441,
author = {Rajanen, Mikko and Iivari, Netta},
title = {Power, Empowerment and Open Source Usability},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702441},
doi = {10.1145/2702123.2702441},
abstract = {Open source software (OSS) projects are often seen as participatory and egalitarian
settings where people collaboratively develop software to serve their needs as well
as the needs of others. In this paper, however, we argue that power and politics also
characterize OSS development, and that this has serious implications for OSS usability.
The existing Human-Computer Interaction (HCI) research on OSS usability has already
shown that power and politics play a role; this study offers a theoretical treatment
of the matter. A theoretical framework on power and empowerment is utilized in analyzing
empirical data on OSS usability as well as the existing body of knowledge on the topic.
With the help of this framework, HCI research can address the aspects of power and
empowerment in OSS usability in a more systematic and comprehensive manner.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3413–3422},
numpages = {10},
keywords = {open source software, power, usability, empowerment},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251764,
author = {Odom, Will},
title = {Session Details: Digital Collections, Practice &amp; Legacy},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251764},
doi = {10.1145/3251764},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702380,
author = {Watkins, Rebecca D. and Sellen, Abigail and Lindley, Si\^{a}n E.},
title = {Digital Collections and Digital Collecting Practices},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702380},
doi = {10.1145/2702123.2702380},
abstract = {Reference is increasingly made to 'digital collections', yet this term encompasses
accumulated digital objects of varying form, purpose and value. We review social science
literature on material collections and draw from in-depth interviews with 20 people
in the UK in order to offer a clearer understanding of what constitutes a digital
collection and what does not. We develop a taxonomy that presents three distinct types
of digital collection and demonstrate ways in which the affordances of digital environments
may facilitate or impede meaningful practices of acquisition, curation and exhibition
in each case. Through doing so, we present a framework for design in support of collecting
practices and the development of more meaningful and valued digital collections.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3423–3432},
numpages = {10},
keywords = {digital possessions, digital collections, curation, exhibition, acquisition},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702238,
author = {Gruning, Jane and Bullard, Julia and Ocepek, Melissa},
title = {Medium, Access, and Obsolescence: What Kinds of Objects Are Lasting Objects?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702238},
doi = {10.1145/2702123.2702238},
abstract = {This paper presents findings from a field study of records managers that provides
context for understanding how people see objects on varying media as long-lasting
objects (or not). Part of the mandate of the profession of records management is long-term
preservation of digital and paper records. At the site of the fieldwork for this study,
research participants' tasks primarily consisted of examining individual case files
to determine if the files should be kept or destroyed under the relevant rules set
by higher-level management according to legal requirements. Close observation of work
practices showed that application of records management rules varied depending on
the medium of the records, despite the policy that records on varying media are equal
in importance. The results of the study suggest that the perceived accessibility and
obsolescence of digital objects deserve more attention in the exploration of the place
of digital objects in human lives over the long-term.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3433–3442},
numpages = {10},
keywords = {field study, obsolescence, digital preservation, ethnography, records management, digital objects},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702460,
author = {van Gennip, Dom\'{e}nique and van den Hoven, Elise and Markopoulos, Panos},
title = {Things That Make Us Reminisce: Everyday Memory Cues as Opportunities for Interaction Design},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702460},
doi = {10.1145/2702123.2702460},
abstract = {Interactive devices can support personal remembering to benefit well-being. These
designs require insight into what brings the past to mind, and how people relate to
such cues. Prior work focused on mementos in the home; instead, this paper presents
a diary and interview study of involuntary memory cueing in everyday life. Data was
collected from fifteen adult individuals, using sentence completion diaries, combined
with debriefing interviews. Qualitative analysis of the data showed that these participants
were relying on everyday physical objects like food items for cueing memories during
everyday life, locations and (repeated) activities, while digital items and photos
were shown to be less frequent stimulants. Meaningful relations to memory cues can
be partially explained from a memory cueing perspective. We discuss how design for
remembering can benefit from our insights, through careful trade-offs in timing, exposure
to cues, and supporting a process of personal attachment with items invoking memories.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3443–3452},
numpages = {10},
keywords = {remembering, diary study, interaction design, memories, memory cueing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702297,
author = {Gulotta, Rebecca and Sciuto, Alex and Kelliher, Aisling and Forlizzi, Jodi},
title = {Curatorial Agents: How Systems Shape Our Understanding of Personal and Familial Digital Information},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702297},
doi = {10.1145/2702123.2702297},
abstract = {As people increasingly turn to digital channels to share, store, and reflect on their
lives and experiences, the processes by which they manage the diverse collection of
information generated over the course of their lives are changing. These processes,
once a matter of hands-on curation and personal meaning making, are now deeply rooted
in interactions with digital systems. In this work, we drew from prior research from
personalization, memory, and information management to create four interactive, provocative
systems. Through sessions with 12 adults from Pittsburgh, PA we used a combination
of these systems and interviews to examine how systems might play a role in the near
and long term resurfacing of personal and familial digital information. Findings point
to an opportunity to create systems that can openly mediate the curation and transmission
of digital content, and ways to draw meaning from the differences between how systems
and people recall and represent their experiences.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3453–3462},
numpages = {10},
keywords = {memory, digital legacy, personalization, metadata, research through design, curation, reflection, agency, identity},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251765,
author = {Wang, Hao-Chuan},
title = {Session Details: Multilingual Communication},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251765},
doi = {10.1145/3251765},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702498,
author = {Gao, Ge and Yamashita, Naomi and Hautasaari, Ari M.J. and Fussell, Susan R.},
title = {Improving Multilingual Collaboration by Displaying How Non-Native Speakers Use Automated Transcripts and Bilingual Dictionaries},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702498},
doi = {10.1145/2702123.2702498},
abstract = {Conversational grounding, or establishing mutual knowledge that messages have been
understood as intended, can be difficult to achieve when some conversational participants
are using a non-native language. These difficulties in grounding can be challenging
for native speakers to detect. In this paper, we examine the value of signaling potential
grounding problems to native speakers (NS) by displaying how non-native speakers (NNS)
use automated transcripts and bilingual dictionaries. We conducted a laboratory experiment
in which NS and NNS of English collaborated via audio conferencing on a map navigation
task. Triads of one NS guider, one NS follower, and one NNS follower performed the
task using one of three awareness displays: (a) a no awareness display that showed
only the automated transcripts, (b) a general awareness display that showed whether
each follower was reading the automated transcripts and/or translating a word; or
(c) a detailed awareness display that showed which line of the transcripts a follower
was reading and/or which words he/she was translating. NS guiders and NNS followers
collaborated most successfully with the detailed awareness display, while NS guiders
and NS followers performed equally across conditions. Our findings suggest several
ways to improve systems to support multilingual collaboration.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3463–3472},
numpages = {10},
keywords = {awareness display, translation, automated speech recognition (asr), multilingual, collaboration},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702407,
author = {Hara, Kotaro and Iqbal, Shamsi T.},
title = {Effect of Machine Translation in Interlingual Conversation: Lessons from a Formative Study},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702407},
doi = {10.1145/2702123.2702407},
abstract = {Language barrier is the primary challenge for effective cross-lingual conversations.
Spoken language translation (SLT) is perceived as a cost-effective alternative to
less affordable human interpreters, but little research has studied how people interact
with such technology. Using a prototype translator application, we performed a formative
evaluation to elicit how people interact with the technology and adapt their conversation
style. We conducted two sets of studies with a total of 23 pairs (46 participants).
Participants worked on storytelling tasks to simulate natural conversations with 3
different interface settings. Our findings show that collocutors naturally adapt their
style of speech production and comprehension to compensate for inadequacies in SLT.
We conclude the paper with design guidelines that emerged from the analysis.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3473–3482},
numpages = {10},
keywords = {automatic speech recognition, multilingual communication, spoken language translation, machine translation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702541,
author = {Steichen, Ben and Freund, Luanne},
title = {Supporting the Modern Polyglot: A Comparison of Multilingual Search Interfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702541},
doi = {10.1145/2702123.2702541},
abstract = {The unrelenting rise in online user diversification has generated tremendous new challenges
for search system providers. Among these, the need to address multiple user language
abilities and preferences is paramount. The majority of research on multilingual search
has so far focused on improving retrieval and translation techniques in cross-language
information retrieval. However, less research has focused on the human-computer interaction
aspects of multilingual search, particularly in terms of multilingual result display
interfaces. To address this research gap, this paper presents a comparison of 5 different
search interface designs for multilingual search. We analyze and evaluate these interfaces
through a crowd-based experiment involving 885 participants. Our results show that
the common approach of interleaving multilingual results is in fact the least preferred,
whereas single-page displays with clear language separation are most preferred. In
addition, we show that user proficiency and search content type play an important
role in user preferences, and that different interfaces elicit different user behaviors.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3483–3492},
numpages = {10},
keywords = {evaluation, multilingual search, multilingual interfaces, crowd-sourcing, human-computer information retrieval},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702339,
author = {Plimmer, Beryl and He, Liang and Zaman, Tariq and Karunanayaka, Kasun and Yeo, Alvin W. and Jengan, Garen and Blagojevic, Rachel and Do, Ellen Yi-Luen},
title = {New Interaction Tools for Preserving an Old Language},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702339},
doi = {10.1145/2702123.2702339},
abstract = {The Penan people of Malaysian Borneo were traditionally nomads of the rainforest.
They would leave messages in the jungle for each other by shaping natural objects
into language tokens and arranging these symbols in specific ways -- much like words
in a sentence. With settlement, the language is being lost as it is not being used
by the younger generation. We report here, a tangible system designed to help the
Penan preserve their unique object writing language. The key features of the system
are that: its tangibles are made of real objects; it works in the wild; and new tangibles
can be fabricated and added to the system by the users. Our evaluations show that
the system is engaging and encourages intergenerational knowledge transfer and thus
has the potential to help preserve this language.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3493–3502},
numpages = {10},
keywords = {fabrication, tui, capacitive tangibles, preservation of language},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251766,
author = {Thissen, Maarten},
title = {Session Details: Empowering Users},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251766},
doi = {10.1145/3251766},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702551,
author = {Edge, Darren and Gulwani, Sumit and Milic-Frayling, Natasa and Raza, Mohammad and Adhitya Saputra, Reza and Wang, Chao and Yatani, Koji},
title = {Mixed-Initiative Approaches to Global Editing in Slideware},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702551},
doi = {10.1145/2702123.2702551},
abstract = {Good alignment and repetition of objects across presentation slides can facilitate
visual processing and contribute to audience understanding. However, creating and
maintaining such consistency during slide design is difficult. To solve this problem,
we present two complementary tools: (1) StyleSnap, which increases the alignment and
repetition of objects by adaptively clustering object edge positions and allowing
parallel editing of all objects snapped to the same spatial extent; and (2) FlashFormat,
which infers the least-general generalization of editing examples and applies it throughout
the selected range. In user studies of repetitive styling task performance, StyleSnap
and FlashFormat were 4-5 times and 2-3 times faster respectively than conventional
editing. Both use a mixed-initiative approach to improve the consistency of slide
decks and generalize to any situations involving direct editing across disjoint visual
spaces.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3503–3512},
numpages = {10},
keywords = {snapping, programming by example, presentations, least-general generalization, layout editing, visual consistency},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702523,
author = {Jones, William and Capra, Robert and Diekema, Anne and Teevan, Jaime and P\'{e}rez-Qui\~{n}ones, Manuel and Dinneen, Jesse David and Hemminger, Bradley},
title = {"For Telling" the Present: Using the Delphi Method to Understand Personal Information Management Practices},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702523},
doi = {10.1145/2702123.2702523},
abstract = {Researchers have been studying personal information management (PIM) for many years,
but little exists by way of practical advice for how individuals should manage their
own information. We employed the Delphi Method to engage PIM researchers with expertise
in a variety of relevant areas in a five-round extended dialog about PIM practices.
Participants identified key everyday choices of PIM, suggested alternatives, and identified
pros and cons of each alternative. Our contributions include: 1) a set of 36 PIM practices,
along with pros, cons, and recommendations for or against each practice, 2) directions
of future research and development including "near-future" improvements in tool support
and 3) a detailed description of how we applied the Delphi Method to study PIM and
how it might be used more widely in HCI research as a complement to more established
methods of inquiry.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3513–3522},
numpages = {10},
keywords = {pim, personal information management, delphi method},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251767,
author = {Ma, Xiaojuan},
title = {Session Details: Accessibility for Vision Impaired Users},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251767},
doi = {10.1145/3251767},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702334,
author = {Ahmed, Tousif and Hoyle, Roberto and Connelly, Kay and Crandall, David and Kapadia, Apu},
title = {Privacy Concerns and Behaviors of People with Visual Impairments},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702334},
doi = {10.1145/2702123.2702334},
abstract = {Various technologies have been developed to help make the world more accessible to
visually impaired people, and recent advances in low-cost wearable and mobile computing
are likely to drive even moreadvances. However, the unique privacy and security needs
of visually impaired people remain largely unaddressed. We conducted an exploratory
user study with 14 visually impaired participants to understand the techniques they
currently use for protecting privacy, their remaining privacy concerns,and how new
technologies may be able to help. The interviews explored privacy not only in the
physical world (e.g., bystanders overhearing private conversations) and the online
world (e.g., determining if a URL is legitimate), but also in the interface between
the two (e.g. bystanders `shoulder-surfing' data from screens). The study revealed
serious concerns that are not adequately solved by current technology, and suggested
new directions for improving the privacy of this significant fraction of the population.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3523–3532},
numpages = {10},
keywords = {privacy, visually impaired people, wearable technology},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702261,
author = {Waddington, Jonathan and Linehan, Conor and Gerling, Kathrin and Hicks, Kieran and Hodgson, Timothy L.},
title = {Participatory Design of Therapeutic Video Games for Young People with Neurological Vision Impairment},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702261},
doi = {10.1145/2702123.2702261},
abstract = {Neurological Vision Impairment (NVI) detrimentally impacts upon quality of life, as
daily activities such as reading and crossing the road often become significantly
impaired. Therapy strategies for NVI based on visual scanning of on-screen stimuli
have recently been demonstrated as effective at improving functional vision. However,
these strategies are repetitive, monotonous and unsuitable for use with children and
young adults. This project explores the design of a game-based therapy programme that
aims to support participant engagement and adherence. We first outline requirements
for this software, before reporting on the iterative design process undertaken in
collaboration with young people, therapists and teachers at a centre for vision impairment.
Our work provides insights into the participatory design of games in collaboration
with young people with special needs, and reflects upon the tension of balancing game
challenge, therapy goals, and accessibility. Furthermore, it highlights the potential
of games to empower special populations by providing a medium through which to communicate
the subjective experience of specific impairments.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3533–3542},
numpages = {10},
keywords = {therapy, games, vision, rehabilitation, young people},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702578,
author = {Flatla, David R. and Andrade, Alan R. and Teviotdale, Ross D. and Knowles, Dylan L. and Stewart, Craig},
title = {ColourID: Improving Colour Identification for People with Impaired Colour Vision},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702578},
doi = {10.1145/2702123.2702578},
abstract = {Being able to identify colours is a fundamental human activity; colour identification
helps us work, get dressed, prepare food, and keep safe. But for the 5% of the world
with impaired colour vision (ICV), colour identification is often a challenge, resulting
in frustration and confusion with sometimes dangerous consequences. Colour namer tools
have been proposed as a solution, however these are often slow to use and imprecise.
To address these shortcomings, we developed three new colour identification techniques
(ColourNames, ColourMeters, ColourPopper) using a new colour name dictionary based
on the largest colour naming experiment to date. We compared our techniques to colour
namers using participants with ICV in desktop and mobile conditions, and found that
ColourNames and ColourPopper resulted in ~99% colour identification accuracy (10%
higher than the colour namer), ColourMeters and ColourPopper were three times faster,
and ColourPopper had lower perceived effort and was ranked significantly higher. With
the benefits provided by our new colour identification techniques, people with ICV
are one step closer to seeing the world like everyone else.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3543–3552},
numpages = {10},
keywords = {colour identification, colour vision deficiency, colour namers, colourblindness, impaired colour vision},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251768,
author = {Hecht, Brent},
title = {Session Details: Interactive &amp; Multi-Surface Maps},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251768},
doi = {10.1145/3251768},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702480,
author = {Oskamp, Matthew and Bortolaso, Christophe and Harrap, Robin and Graham, T.C. Nicholas},
title = {TerraGuide: Design and Evaluation of a Multi-Surface Environment for Terrain Visibility Analysis},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702480},
doi = {10.1145/2702123.2702480},
abstract = {Terrain visibility analysis is a challenging task that is currently supported by complex
digital tools with cumbersome interfaces. In this paper, we present TerraGuide, a
novel multi-surface environment for exploratory terrain analysis. TerraGuide provides
three tightly coupled displays including a real-time viewshed, a 3D panoramic view,
and a helicopter view controlled by an optically tracked tablet. A user study compared
these techniques and identified users' strategies in solving a complex terrain analysis
problem. Users overwhelmingly adopted a bi-manual use of the tabletop viewshed and
tablet-based helicopter techniques. This paper gives insight into how multi-surface
environments can be designed to allow complementary use of and fluid switching between
techniques.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3553–3562},
numpages = {10},
keywords = {terrain analysis, digital tabletop, multi-surface environment},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702172,
author = {Willett, Wesley and Jenny, Bernhard and Isenberg, Tobias and Dragicevic, Pierre},
title = {Lightweight Relief Shearing for Enhanced Terrain Perception on Interactive Maps},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702172},
doi = {10.1145/2702123.2702172},
abstract = {We explore interactive relief shearing, a set of non-intrusive, direct manipulation
interactions that expose depth and shape information in terrain maps using ephemeral
animations. Reading and interpreting topography and relief on terrain maps is an important
aspect of map use, but extracting depth information from 2D maps is notoriously difficult.
Modern mapping software attempts to alleviate this limitation by presenting digital
terrain using 3D views. However, 3D views introduce occlusion, complicate distance
estimations, and typically require more complex interactions. In contrast, our approach
reveals depth information via shearing animations on 2D maps, and can be paired with
existing interactions such as pan and zoom. We examine explicit, integrated, and hybrid
interactions for triggering relief shearing and present a version that uses device
tilt to control depth effects. Our evaluation shows that these interactive techniques
improve depth perception when compared to standard 2D and perspective views.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3563–3572},
numpages = {10},
keywords = {terrain maps, depth perception, interaction, relief shearing, plan oblique relief},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702130,
author = {Lobo, Mar\'{\i}a-Jes\'{u}s and Pietriga, Emmanuel and Appert, Caroline},
title = {An Evaluation of Interactive Map Comparison Techniques},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702130},
doi = {10.1145/2702123.2702130},
abstract = {Geovisualization applications typically organize data into layers. These layers hold
different types of geographical features, describe different characteristics of the
same features, or represent those features at different points in time. Layers can
be composited in various ways, most often employing a juxtaposition or superimposition
strategy, to produce maps that users can explore interactively. From an HCI perspective,
one of the main challenges is to design interactive compositions that optimize the
legibility of the resulting map and that ease layer comparison. We characterize five
representative techniques, and empirically evaluate them using a set of real-world
maps in which we purposefully introduce six types of differences amenable to inter-layer
visual comparison. We discuss the merits of these techniques in terms of visual interference,
user attention and scanning strategy. Our results can help inform the design of map-based
visualizations for supporting geo-analysis tasks in many application areas.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3573–3582},
numpages = {10},
keywords = {geovisualization, interference, composite visualization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702536,
author = {Fechner, Thore and Wilhelm, Dennis and Kray, Christian},
title = {Ethermap: Real-Time Collaborative Map Editing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702536},
doi = {10.1145/2702123.2702536},
abstract = {Real-time synchronization is increasingly available in web-based environments for
editing textual data, and this has changed how groups of people collaborate. We present
a novel approach for real-time collaborative editing of geo-data. We introduce Ethermap,
an open source web-application that implements this approach and enables multiple
users to map data concurrently. It supports synchronous and collaborative mapping
in several ways: it visually highlights mapping activities, it allows for fine-grained
reviewing of all changes, and it enhances text-based communication with cross-modal
references to geo-objects. We report on key results from a multi-tiered evaluation
of Ethermap based on a user-study and on expert interviews. The concept of real-time
collaborative editing was received favorably by users and experts. Participants of
the study learned to use Ethermap quickly, and successfully completed a collaborative
mapping task. Experts and users agreed that, given the right scenario (e.g., disaster
mapping, teaching, planning), the approach could benefit the process of working on
geo-data collaboratively.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3583–3592},
numpages = {10},
keywords = {synchronous interaction, collaboration, mapping, real-time},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251769,
author = {Jung, Malte},
title = {Session Details: Robot Personalities},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251769},
doi = {10.1145/3251769},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702415,
author = {Strait, Megan and Vujovic, Lara and Floerke, Victoria and Scheutz, Matthias and Urry, Heather},
title = {Too Much Humanness for Human-Robot Interaction: Exposure to Highly Humanlike Robots Elicits Aversive Responding in Observers},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702415},
doi = {10.1145/2702123.2702415},
abstract = {People tend to anthropomorphize agents that look and/or act human, and further, they
tend to evaluate such agents more positively. This, in turn, has motivated the development
of robotic agents that are humanlike in appearance and/or behavior. Yet, some agents
-- often those with highly humanlike appearances -- have been found to elicit the
opposite, wherein they are evaluated more negatively than their less humanlike counterparts.
These trends are captured by Masahiro Mori's uncanny valley hypothesis, which describes
a (uncanny) valley in emotional responding - a switch from affinity to dislike - elicited
by agents that are ``too humanlike'. However, while the valley phenomenon has been
repeatedly observed via subjective measures, it remains unknown as to whether such
evaluations reflect a potential impact to a person's behavior (i.e., aversion). We
attempt to address this gap in the literature via a novel experimental paradigm employing
both traditional subjective ratings, as well as measures of peoples' behavioral and
phsyiological responding. The results show that not only do people rate highly humanlike
robots as uncanny, but moreover, they exhibit greater avoidance of such encounters
than encounters with less humanlike and human agents. Thus, the findings not only
support Mori's hypothesis, but further, they indicate the valley should be taken as
a serious consideration for peoples' interactions with humanlike agents.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3593–3602},
numpages = {10},
keywords = {anthropomorphism, embodied conversational agents, situation selection/modification, virtual agents, attentional deployment, human-robot interaction, emotion regulation, uncanny valley},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702592,
author = {Andrist, Sean and Mutlu, Bilge and Tapus, Adriana},
title = {Look Like Me: Matching Robot Personality via Gaze to Increase Motivation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702592},
doi = {10.1145/2702123.2702592},
abstract = {Socially assistive robots are envisioned to provide social and cognitive assistance
where they will seek to motivate and engage people in therapeutic activities. Due
to their physicality, robots serve as a powerful technology for motivating people.
Prior work has shown that effective motivation requires adaption to user needs and
characteristics, but how robots might successfully achieve such adaptation is still
unknown. In this paper, we present work on matching a robot's personality-expressed
via its gaze behavior-to that of its users. We confirmed in an online study with 22
participants that the robot's gaze behavior can successfully express either an extroverted
or introverted personality. In a laboratory study with 40 participants, we demonstrate
the positive effect of personality matching on a user's motivation to engage in a
repetitive task. These results have important implications for the design of adaptive
robot behaviors in assistive human-robot interaction.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3603–3612},
numpages = {10},
keywords = {gaze, motivation, similarity-attraction, compliance, human-robot interaction (hri), personality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702181,
author = {Saupp\'{e}, Allison and Mutlu, Bilge},
title = {The Social Impact of a Robot Co-Worker in Industrial Settings},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702181},
doi = {10.1145/2702123.2702181},
abstract = {Across history and cultures, robots have been envisioned as assistants working alongside
people. Following this vision, an emerging family of products-collaborative manufacturing
robots-is enabling human and robot workers to work side by side as collaborators in
manufacturing tasks. Their introduction presents an opportunity to better understand
people's interactions with and perceptions of a robot "co-worker" in a real-world
setting to guide the design of these products. In this paper, we present findings
from an ethnographic field study at three manufacturing sites and a Grounded Theory
analysis of observations and interviews. Our results show that, even in this safety-critical
manufacturing setting, workers relate to the robot as a social entity and rely on
cues to understand the robot's actions, which we observed to be critical for workers
to feel safe when near the robot. These findings contribute to our understanding of
interactions with robotic products in real-world settings and offer important design
implications.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3613–3622},
numpages = {10},
keywords = {social cues, sociality, technology adoption, collaborative robots, computer-supported collaborative work, design guidelines, human-robot collaboration, manufacturing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702552,
author = {Walther-Franks, Benjamin and Smeddinck, Jan and Szmidt, Peter and Haidu, Andrei and Beetz, Michael and Malaka, Rainer},
title = {Robots, Pancakes, and Computer Games: Designing Serious Games for Robot Imitation Learning},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702552},
doi = {10.1145/2702123.2702552},
abstract = {Autonomous manipulation robots can be valuable aids as interactive agents in the home,
yet it has proven extremely difficult to program their behavior. Imitation learning
uses data on human demonstrations to build behavioral models for robots. In order
to cover a wide range of action strategies, data from many individuals is needed.
Acquiring such large amounts of data can be a challenge. Tools for data capturing
in this domain must thus implement a good user experience. We propose to use human
computation games in order to gather data on human manual behavior. We demonstrate
the idea with a strategy game that is operated via a natural user interface. A comparison
between using the game for action execution and demonstrating actions in a virtual
environment shows that people interact longer and have a better experience when playing
the game.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3623–3632},
numpages = {10},
keywords = {programming by demonstration, human computation games},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251770,
author = {Li, Yang},
title = {Session Details: Mid-Air Gestures and Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251770},
doi = {10.1145/3251770},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702179,
author = {Sharp, Toby and Keskin, Cem and Robertson, Duncan and Taylor, Jonathan and Shotton, Jamie and Kim, David and Rhemann, Christoph and Leichter, Ido and Vinnikov, Alon and Wei, Yichen and Freedman, Daniel and Kohli, Pushmeet and Krupka, Eyal and Fitzgibbon, Andrew and Izadi, Shahram},
title = {Accurate, Robust, and Flexible Real-Time Hand Tracking},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702179},
doi = {10.1145/2702123.2702179},
abstract = {We present a new real-time hand tracking system based on a single depth camera. The
system can accurately reconstruct complex hand poses across a variety of subjects.
It also allows for robust tracking, rapidly recovering from any temporary failures.
Most uniquely, our tracker is highly flexible, dramatically improving upon previous
approaches which have focused on front-facing close-range scenarios. This flexibility
opens up new possibilities for human-computer interaction with examples including
tracking at distances from tens of centimeters through to several meters (for controlling
the TV at a distance), supporting tracking using a moving depth camera (for mobile
scenarios), and arbitrary camera placements (for VR headsets). These features are
achieved through a new pipeline that combines a multi-layered discriminative reinitialization
strategy for per-frame pose estimation, followed by a generative model-fitting stage.
We provide extensive technical details and a detailed qualitative and quantitative
analysis.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3633–3642},
numpages = {10},
keywords = {hand tracking, depth camera, computer vision},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702136,
author = {Sridhar, Srinath and Feit, Anna Maria and Theobalt, Christian and Oulasvirta, Antti},
title = {Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702136},
doi = {10.1145/2702123.2702136},
abstract = {This paper investigates an emerging input method enabled by progress in hand tracking:
input by free motion of fingers. The method is expressive, potentially fast, and usable
across many settings as it does not insist on physical contact or visual feedback.
Our goal is to inform the design of high-performance input methods by providing detailed
analysis of the performance and anatomical characteristics of finger motion. We conducted
an experiment using a commercially available sensor to report on the speed, accuracy,
individuation, movement ranges, and individual differences of each finger. Findings
show differences of up to 50% in movement times and provide indices quantifying the
individuation of single fingers. We apply our findings to text entry by computational
optimization of multi-finger gestures in mid-air. To this end, we define a novel objective
function that considers performance, anatomical factors, and learnability. First investigations
of one optimization case show entry rates of 22 words per minute (WPM). We conclude
with a critical discussion of the limitations posed by human factors and performance
characteristics of existing markerless hand trackers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3643–3652},
numpages = {10},
keywords = {freehand input, fitts' law, mid-air interaction, text entry},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702133,
author = {Haque, Faizan and Nancel, Mathieu and Vogel, Daniel},
title = {Myopoint: Pointing and Clicking Using Forearm Mounted Electromyography and Inertial Motion Sensors},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702133},
doi = {10.1145/2702123.2702133},
abstract = {We describe a mid-air, barehand pointing and clicking interaction technique using
electromyographic (EMG) and inertial measurement unit (IMU) input from a consumer
armband device. The technique uses enhanced pointer feedback to convey state, a custom
pointer acceleration function tuned for angular inertial motion, and correction and
filtering techniques to minimize side-effects when combining EMG and IMU input. By
replicating a previous large display study using a motion capture pointing technique,
we show the EMG and IMU technique is only 430 to 790 ms slower and has acceptable
error rates for targets greater than 48 mm. Our work demonstrates that consumer-level
EMG and IMU sensing is practical for distant pointing and clicking on large displays.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3653–3656},
numpages = {4},
keywords = {electromyography, pointing, large displays},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702601,
author = {Song, Jie and Pece, Fabrizio and S\"{o}r\"{o}s, G\'{a}bor and Koelle, Marion and Hilliges, Otmar},
title = {Joint Estimation of 3D Hand Position and Gestures from Monocular Video for Mobile Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702601},
doi = {10.1145/2702123.2702601},
abstract = {We present a machine learning technique to recognize gestures and estimate metric
depth of hands for 3D interaction, relying only on monocular RGB video input. We aim
to enable spatial interaction with small, body-worn devices where rich 3D input is
desired but the usage of conventional depth sensors is prohibitive due to their power
consumption and size. We propose a hybrid classification-regression approach to learn
and predict a mapping of RGB colors to absolute, metric depth in real time. We also
classify distinct hand gestures, allowing for a variety of 3D interactions. We demonstrate
our technique with three mobile interaction scenarios and evaluate the method quantitatively
and qualitatively.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3657–3660},
numpages = {4},
keywords = {gesture recognition, mobile interaction, machine learning},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702371,
author = {Withana, Anusha and Peiris, Roshan and Samarasekara, Nipuna and Nanayakkara, Suranga},
title = {ZSense: Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702371},
doi = {10.1145/2702123.2702371},
abstract = {In this paper we present zSense, which provides greater input expressivity for spatially
limited devices such as smart wearables through a shallow depth gesture recognition
system using non-focused infrared sensors. To achieve this, we introduce a novel Non-linear
Spatial Sampling (NSS) technique that significantly cuts down the number of required
infrared sensors and emitters. These can be arranged in many different configurations;
for example, number of sensor emitter units can be as minimal as one sensor and two
emitters. We implemented different configurations of zSense on smart wearables such
as smartwatches, smartglasses and smart rings. These configurations naturally fit
into the flat or curved surfaces of such devices, providing a wide scope of zSense
enabled application scenarios. Our evaluations reported over 94.8% gesture recognition
accuracy across all configurations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3661–3670},
numpages = {10},
keywords = {shallow depth gesture recognition, smart wearables, interacting with small devices, compressive sensing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}


@inproceedings{10.1145/3250911,
author = {De Angeli, Antonella},
title = {Session Details: Visualization and Aesthetics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250911},
doi = {10.1145/3250911},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557152,
author = {\v{S}imbelis, Vygandas and Lundstr\"{o}m, Anders and H\"{o}\"{o}k, Kristina and Solsona, Jordi and Lewandowski, Vincent},
title = {Metaphone: Machine Aesthetics Meets Interaction Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557152},
doi = {10.1145/2556288.2557152},
abstract = {Through our art project, Metaphone, we explored a particular form of aesthetics referred
to in the arts tradition as machine aesthetics. The Metaphone machine collects the
participant's bio-data, Galvanic Skin Response (GSR) and Heart Rate (HR), creating
a process of movement, painting and sound. The machine behaves in machine-like, aesthetically
evocative ways: a shaft on two large wheels rotates on the floor, carrying paint that
is dripped onto a large sheet of aquarelle paper on the floor according to bio-sensor
data. A soundscape rhythmically follows the bio-sensor data, but also has its own
machine-like sounds. Six commentators were invited to interact with the machine. They
reported a strangely relaxing atmosphere induced by the machine. Based on these experiences
we discuss how different art styles can help to describe aesthetics in interaction
design generally, and how machine aesthetics in particular can be used to create interesting,
sustained, stylistically coherent interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {affective computing, bodily interaction, interaction design, interactive arts, machine aesthetics, media arts},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557052,
author = {Reinecke, Katharina and Gajos, Krzysztof Z.},
title = {Quantifying Visual Preferences around the World},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557052},
doi = {10.1145/2556288.2557052},
abstract = {Website aesthetics have been recognized as an influential moderator of people's behavior
and perception. However, what users perceive as "good design" is subject to individual
preferences, questioning the feasibility of universal design guidelines. To better
understand how people's visual preferences differ, we collected 2.4 million ratings
of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds.
We address several gaps in the knowledge about design preferences of previously understudied
groups. Among other findings, our results show that the level of colorfulness and
visual complexity at which visual appeal is highest strongly varies: Females, for
example, liked colorful websites more than males. A high education level generally
lowers this preference for colorfulness. Russians preferred a lower visual complexity,
and Macedonians liked highly colorful designs more than any other country in our dataset.
We contribute a computational model and estimates of peak appeal that can be used
to support rapid evaluations of website design prototypes for specific target groups.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {adaptation, colorfulness, modeling, personalization, website aesthetics, complexity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557419,
author = {Sonderegger, Andreas and Uebelbacher, Andreas and Pugliese, Manuela and Sauer, Juergen},
title = {The Influence of Aesthetics in Usability Testing: The Case of Dual-Domain Products},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557419},
doi = {10.1145/2556288.2557419},
abstract = {An experimental study examined whether the effects of aesthetic appeal on usability
test outcomes are moderated by usage domain. The aesthetic appeal of a cell phone
was experimentally manipulated in both home- and work-based usage domains. The two
usage domains were modeled in a usability laboratory. 60 participants completed a
series of typical cell phone user tasks. Dependent measures such as performance, perceived
usability, and emotion were taken. The results showed that aesthetic appeal had a
positive effect on perceived usability but a negative effect on performance. The effects
of aesthetic appeal on usability test outcomes were not moderated by usage domain.
The results of this study imply that it may be sufficient to test dual-domain products
in only one of their usage domains.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {usability test, user performance, product aesthetics, perceived usability, usage domain},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557241,
author = {Kong, Nicholas and Hearst, Marti A. and Agrawala, Maneesh},
title = {Extracting References between Text and Charts via Crowdsourcing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557241},
doi = {10.1145/2556288.2557241},
abstract = {News articles, reports, blog posts and academic papers often include graphical charts
that serve to visually reinforce arguments presented in the text. To help readers
better understand the relation between the text and the chart, we present a crowdsourcing
pipeline to extract the references between them. Specifically, we give crowd workers
paragraph-chart pairs and ask them to select text phrases as well as the corresponding
visual marks in the chart. We then apply automated clustering and merging techniques
to unify the references generated by multiple workers into a single set. Comparing
the crowdsourced references to a set of gold standard references using a distance
measure based on the F1 score, we find that the average distance between the raw set
of references produced by a single worker and the gold standard is 0.54 (out of a
max of 1.0). When we apply clustering and merging techniques the average distance
between the unified set of references and the gold standard reduces to 0.39; an improvement
of 27%. We conclude with an interactive document viewing application that uses the
extracted references; readers can select phrases in the text and the system highlights
the related marks in the chart.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–40},
numpages = {10},
keywords = {interactive documents, visualization, crowdsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250912,
author = {Chen, Yunan},
title = {Session Details: Stress},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250912},
doi = {10.1145/3250912},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557361,
author = {Mark, Gloria and Wang, Yiran and Niiya, Melissa},
title = {Stress and Multitasking in Everyday College Life: An Empirical Study of Online Activity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557361},
doi = {10.1145/2556288.2557361},
abstract = {While HCI has focused on multitasking with information workers, we report on multitasking
among Millennials who grew up with digital media - focusing on college students. We
logged computer activity and used biosensors to measure stress of 48 students for
7 days for all waking hours, in their in situ environments. We found a significant
positive relationship with stress and daily time spent on computers. Stress is positively
associated with the amount of multitasking. Conversely, stress is negatively associated
with Facebook and social media use. Heavy multitaskers use significantly more social
media and report lower positive affect than light multitaskers. Night habits affect
multitasking the following day: late-nighters show longer duration of computer use
and those ending their activities earlier in the day multitask less. Our study shows
that college students multitask at double the frequency compared to studies of information
workers. These results can inform designs for stress management of college students.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {41–50},
numpages = {10},
keywords = {social media, multitasking, computer logging, stress, millennial generation, biosensors, in situ study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557165,
author = {Hernandez, Javier and Paredes, Pablo and Roseway, Asta and Czerwinski, Mary},
title = {Under Pressure: Sensing Stress of Computer Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557165},
doi = {10.1145/2556288.2557165},
abstract = {Recognizing when computer users are stressed can help reduce their frustration and
prevent a large variety of negative health conditions associated with chronic stress.
However, measuring stress non-invasively and continuously at work remains an open
challenge. This work explores the possibility of using a pressure-sensitive keyboard
and a capacitive mouse to discriminate between stressful and relaxed conditions in
a laboratory study. During a 30 minute session, 24 participants performed several
computerized tasks consisting of expressive writing, text transcription, and mouse
clicking. During the stressful conditions, the large majority of the participants
showed significantly increased typing pressure (&gt;79% of the participants) and more
contact with the surface of the mouse (75% of the participants). We discuss the potential
implications of this work and provide recommendations for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {51–60},
numpages = {10},
keywords = {capacitive mouse, affective computing, stress measurement, pressure-sensitive keyboard},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557243,
author = {Sun, David and Paredes, Pablo and Canny, John},
title = {MouStress: Detecting Stress from Mouse Motion},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557243},
doi = {10.1145/2556288.2557243},
abstract = {Stress causes and exacerbates many physiological and mental health problems. Routine
and unobtrusive monitoring of stress would enable a variety of treatments, from break-taking
to calming exercises. It may also be a valuable tool for assessing effects (frustration,
difficulty) of using interfaces or applications. Custom sensing hardware is a poor
option, because of the need to buy/wear/use it continuously, even before stress-related
problems are evident. Here we explore stress measurement from common computer mouse
operations. We use a simple model of arm-hand dynamics that captures muscle stiffness
during mouse movement. We show that the within-subject mouse-derived stress measure
is quite strong, even compared to concurrent physiological sensor measurements. While
our study used fixed mouse tasks, the stress signal was still strong even when averaged
across widely varying task geometries. We argue that mouse sensing "in the wild" may
be feasible, by analyzing frequently-performed operations of particular geometries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {61–70},
numpages = {10},
keywords = {affective interfaces, mouse interaction, stress modeling},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557038,
author = {Tan, Chiew Seng Sean and Sch\"{o}ning, Johannes and Luyten, Kris and Coninx, Karin},
title = {Investigating the Effects of Using Biofeedback as Visual Stress Indicator during Video-Mediated Collaboration},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557038},
doi = {10.1145/2556288.2557038},
abstract = {During remote video-mediated assistance, instructors often guide workers through problems
and instruct them to perform unfamiliar or complex operations. However, the workers'
performance might deteriorate due to stress. We argue that informing biofeedback to
the instructor, can improve communication and lead to lower stress. This paper presents
a thorough investigation on mental workload and stress perceived by twenty participants,
paired up in an instructor-worker scenario, performing remote video-mediated tasks.
The interface conditions differ in task, facial and biofeedback communication. Two
self-report measures are used to assess mental workload and stress. Results show that
pairs reported lower mental workload and stress when instructors are using the biofeedback
as compared to using interfaces with facial view. Significant correlations were found
on task performance with reducing stress (i.e. increased task engagement and decreased
worry) for instructors and declining mental workload (i.e. increased performance)
for workers. Our findings provide insights to advance video-mediated interfaces for
remote collaborative work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {71–80},
numpages = {10},
keywords = {stress, cscw, video-mediated collaboration, biofeedback},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250913,
author = {McGookin, David},
title = {Session Details: Social Local Mobile},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250913},
doi = {10.1145/3250913},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557102,
author = {Kobsa, Alfred and Knijnenburg, Bart P. and Livshits, Benjamin},
title = {Let's Do It at My Place Instead? Attitudinal and Behavioral Study of Privacy in Client-Side Personalization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557102},
doi = {10.1145/2556288.2557102},
abstract = {Many users welcome personalized services, but are reluctant to provide the information
about themselves that personalization requires. Performing personalization exclusively
at the client side (e.g., on one's smartphone) may conceptually increase privacy,
because no data is sent to a remote provider. But does client-side personalization
(CSP) also increase users' perception of privacy?We developed a causal model of privacy
attitudes and behavior in personalization, and validated it in an experiment that
contrasted CSP with personalization at three remote providers: Amazon, a fictitious
company, and the "Cloud". Participants gave roughly the same amount of personal data
and tracking permissions in all four conditions. A structural equation modeling analysis
reveals the reasons: CSP raises the fewest privacy concerns, but does not lead in
terms of perceived protection nor in resulting self-anticipated satisfaction and thus
privacy-related behavior. Encouragingly, we found that adding certain security features
to CSP is likely to raise its perceived protection significantly. Our model predicts
that CSP will then also sharply improve on all other privacy measures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {81–90},
numpages = {10},
keywords = {attitudes, structural equation modeling (sem), personalization, privacy, behaviors, client-side},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557400,
author = {Tan, Joshua and Nguyen, Khanh and Theodorides, Michael and Negr\'{o}n-Arroyo, Heidi and Thompson, Christopher and Egelman, Serge and Wagner, David},
title = {The Effect of Developer-Specified Explanations for Permission Requests on Smartphone User Behavior},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557400},
doi = {10.1145/2556288.2557400},
abstract = {In Apple's iOS 6, when an app requires access to a protected resource (e.g., location
or photos), the user is prompted with a permission request that she can allow or deny.
These permission request dialogs include space for developers to optionally include
strings of text to explain to the user why access to the resource is needed. We examine
how app developers are using this mechanism and the effect that it has on user behavior.
Through an online survey of 772 smartphone users, we show that permission requests
that include explanations are significantly more likely to be approved. At the same
time, our analysis of 4,400 iOS apps shows that the adoption rate of this feature
by developers is relatively small: around 19% of permission requests include developer-specified
explanations. Finally, we surveyed 30 iOS developers to better understand why they
do or do not use this feature.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {91–100},
numpages = {10},
keywords = {smartphones, access control, usability, privacy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557400_R50249,
author = {Edwards, John S.},
title = {Review ID:R50249 for DOI: 10.1145/2556288.2557400},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557400_R50249}
}

@inproceedings{10.1145/2556288.2557121,
author = {Patil, Sameer and Schlegel, Roman and Kapadia, Apu and Lee, Adam J.},
title = {Reflection or Action? How Feedback and Control Affect Location Sharing Decisions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557121},
doi = {10.1145/2556288.2557121},
abstract = {Owing to the ever-expanding size of social and professional networks, it is becoming
cumbersome for individuals to configure information disclosure settings. We used location
sharing systems to unpack the nature of discrepancies between a person's disclosure
settings and contextual choices. We conducted an experience sampling study (N = 35)
to examine various factors contributing to such divergence. We found that immediate
feedback about disclosures without any ability to control the disclosures evoked feelings
of oversharing. Moreover, deviation from specified settings did not always signal
privacy violation; it was just as likely that settings prevented information disclosure
considered permissible in situ. We suggest making feedback more actionable or delaying
it sufficiently to avoid a knee-jerk reaction. Our findings also make the case for
proactive techniques for detecting potential mismatches and recommending adjustments
to disclosure settings, as well as selective control when sharing location with socially
distant recipients and visiting atypical locations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {101–110},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557347,
author = {Zhang, Bo and Wu, Mu and Kang, Hyunjin and Go, Eun and Sundar, S. Shyam},
title = {Effects of Security Warnings and Instant Gratification Cues on Attitudes toward Mobile Websites},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557347},
doi = {10.1145/2556288.2557347},
abstract = {In order to address the increased privacy and security concerns raised by mobile communications,
designers of mobile applications and websites have come up with a variety of warnings
and appeals. While some interstitials warn about potential risk to personal information
due to an untrusted security certificate, others attempt to take users' minds away
from privacy concerns by making tempting, time-sensitive offers. How effective are
they? We conducted an online experiment (N = 220) to find out. Our data show that
both these strategies raise red flags for users - appeals to instant gratification
make users more leery of the site and warnings make them perceive greater threat to
personal data. Yet, users tend to reveal more information about their social media
accounts when warned about an insecure site. This is probably because users process
these interstitials based on cognitive heuristics triggered by them. These findings
hold important implications for the design of cues in mobile interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {111–114},
numpages = {4},
keywords = {trust, mobile interface, information disclosure, security, online privacy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557417,
author = {Shami, N. Sadat and Nichols, Jeffrey and Chen, Jilin},
title = {Social Media Participation and Performance at Work: A Longitudinal Study},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557417},
doi = {10.1145/2556288.2557417},
abstract = {The use of social media at work is gaining traction, and there is evidence to suggest
that various benefits accrue from its use. Yet the relationship between using social
media at work and employee performance is not clear. Through a study of 75,747 employees
of a large global company over the course of 3 years, we find that some social media
usage (number of forum posts, forum post length, and status update length) was positively
associated with performance ratings. This study is one of the first to show the relationship
among different forms of social media use and employee performance ratings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {115–118},
numpages = {4},
keywords = {work, performance, social media, social software},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250914,
author = {Rouncefield, Mark},
title = {Session Details: Coordination and Collaboration},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250914},
doi = {10.1145/3250914},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557388,
author = {Schuler, Richard P. and Grandhi, Sukeshini A. and Mayer, Julia M. and Ricken, Stephen T. and Jones, Quentin},
title = {The Doing of Doing Stuff: Understanding the Coordination of Social Group-Activities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557388},
doi = {10.1145/2556288.2557388},
abstract = {This paper explores how the adoption of mobile and social computing technologies has
impacted upon the way in which we coordinate social group-activities. We present a
diary study of 36 individuals that provides an overview of how group coordination
is currently performed as well as the challenges people face. Our findings highlight
that people primarily use open-channel communication tools (e.g., text messaging,
phone calls, email) to coordinate because the alternatives are seen as either disrupting
or curbing to the natural conversational processes. Yet the use of open-channel tools
often results in conversational overload and a significant disparity of work between
coordinating individuals. This in turn often leads to a sense of frustration and confusion
about coordination details. We discuss how the findings argue for a significant shift
in our thinking about the design of coordination support systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {119–128},
numpages = {10},
keywords = {diary study, conversation, communication, coordination theory, common ground, qualitative research, mobile coordination, social group-activity, language action theory},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557229,
author = {Goyal, Nitesh and Leshed, Gilly and Cosley, Dan and Fussell, Susan R.},
title = {Effects of Implicit Sharing in Collaborative Analysis},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557229},
doi = {10.1145/2556288.2557229},
abstract = {When crime analysts collaborate to solve crime cases, they need to share insights
in order to connect the clues, identify a pattern, and attribute the crime to the
right culprit. We designed a collaborative analysis tool to explore the value of implicitly
sharing insights and notes, without requiring analysts to explicitly push information
or request it from each other. In an experiment, pairs of remote individuals played
the role of crime analysts solving a set of serial killer crimes with both partners
having some, but not all, relevant clues. When implicit sharing of notes was available,
participants remembered more clues related to detecting the serial killer, and they
perceived the tool as more useful compared to when implicit sharing was not available.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {129–138},
numpages = {10},
keywords = {collaborative analysis, implicit sharing, sensemaking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557158,
author = {Andr\'{e}, Paul and Kraut, Robert E. and Kittur, Aniket},
title = {Effects of Simultaneous and Sequential Work Structures on Distributed Collaborative Interdependent Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557158},
doi = {10.1145/2556288.2557158},
abstract = {Distributed online groups have great potential for generating interdependent and complex
products like encyclopedia articles or product design. However, coordinating multiple
group members to work together effectively while minimizing process losses remains
an open challenge. We conducted an experiment comparing the effectiveness of two coordination
strategies (simultaneous vs. sequential work) on a complex creative task as the number
of group members increased. Our results indicate that, contrary to prior work, a sequential
work structure was more effective than a simultaneous work structure as the size of
the group increased. A mediation analysis suggests that social processes such as territoriality
partially accounts for these results. A follow up experiment giving workers specific
roles mitigated the detrimental effects of the simultaneous work structure. These
results have implications for small group theory and crowdsourcing research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {139–148},
numpages = {10},
keywords = {coordination, small groups, interdependence, group size},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557126,
author = {Woodruff, Allison},
title = {Necessary, Unpleasant, and Disempowering: Reputation Management in the Internet Age},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557126},
doi = {10.1145/2556288.2557126},
abstract = {In this paper, we report on a qualitative study of how users manage their reputation
online. We focus particularly on people who are bothered by content online about themselves
and how they manage reputation damage and repair. We describe how users view reputation
management chores as necessary but unpleasant, and how they feel disempowered to repair
their online reputation. Participants were unable to identify feasible repair mechanisms
and ultimately failed to resolve their problems. Given the current state of dysfunction
indicated by our findings, we advocate for increased HCI research attention to this
area.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {149–158},
numpages = {10},
keywords = {reputation management, privacy, online reputation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250915,
author = {Li, Yang},
title = {Session Details: Watches and Small Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250915},
doi = {10.1145/3250915},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556955,
author = {Chen, Xiang 'Anthony' and Grossman, Tovi and Wigdor, Daniel J. and Fitzmaurice, George},
title = {Duet: Exploring Joint Interactions on a Smart Phone and a Smart Watch},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556955},
doi = {10.1145/2556288.2556955},
abstract = {The emergence of smart devices (e.g., smart watches and smart eyewear) is redefining
mobile interaction from the solo performance of a smart phone, to a symphony of multiple
devices. In this paper, we present Duet -- an interactive system that explores a design
space of interactions between a smart phone and a smart watch. Based on the devices'
spatial configurations, Duet coordinates their motion and touch input, and extends
their visual and tactile output to one another. This transforms the watch into an
active element that enhances a wide range of phone-based interactive tasks, and enables
a new class of multi-device gestures and sensing techniques. A technical evaluation
shows the accuracy of these gestures and sensing techniques, and a subjective study
on Duet provides insights, observations, and guidance for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–168},
numpages = {10},
keywords = {smart phone, joint interaction, duet, smart watch.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2556955_R50153,
author = {UBEDA, JOSE CARLOS MORENO},
title = {Review ID:R50153 for DOI: 10.1145/2556288.2556955},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2556955_R50153}
}

@inproceedings{10.1145/2556288.2557138,
author = {Oakley, Ian and Lee, Doyoung},
title = {Interaction on the Edge: Offset Sensing for Small Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557138},
doi = {10.1145/2556288.2557138},
abstract = {The touch screen interaction paradigm, currently dominant in mobile devices, begins
to fail when very small systems are considered. Specifically, "fat fingers", a term
referring to the fact that users' extremities physically obstruct their view of screen
content and feedback, become particularly problematic. This paper presents a novel
solution for this issue based on sensing touches to the perpendicular edges of a device
featuring a front-mounted screen. The use of such offset contact points ensures that
both a user's fingers and the device screen remain clearly in view throughout a targeting
operation. The configuration also supports a range of novel interaction scenarios
based on the touch, grip and grasp patterns it affords. To explore the viability of
this concept, this paper describes EdgeTouch, a small (6 cm) hardware prototype instantiating
this multi-touch functionality. User studies characterizing targeting performance,
typical user grasps and exploring input affordances are presented. The results show
that targets of 7.5-22.5 degrees in angular size are acquired in 1.25-1.75 seconds
and with accuracy rates of 3%-18%, promising results considering the small form factor
of the device. Furthermore, grasps made with between two and five fingers are robustly
identifiable. Finally, we characterize the types of input users envisage performing
with EdgeTouch, and report occurrence rates for key interactions such as taps, holds,
strokes and multi-touch and compound input. The paper concludes with a discussion
of the interaction scenarios enabled by offset sensing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {169–178},
numpages = {10},
keywords = {edge-of-device input, mobile devices, touch, pointing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557239,
author = {Weigel, Martin and Mehta, Vikram and Steimle, J\"{u}rgen},
title = {More than Touch: Understanding How People Use Skin as an Input Surface for Mobile Computing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557239},
doi = {10.1145/2556288.2557239},
abstract = {This paper contributes results from an empirical study of on-skin input, an emerging
technique for controlling mobile devices. Skin is fundamentally different from off-body
touch surfaces, opening up a new and largely unexplored interaction space. We investigate
characteristics of the various skin-specific input modalities, analyze what kinds
of gestures are performed on skin, and study what are preferred input locations. Our
main findings show that (1) users intuitively leverage the properties of skin for
a wide range of more expressive commands than on conventional touch surfaces; (2)
established multi-touch gestures can be transferred to on-skin input; (3) physically
uncomfortable modalities are deliberately used for irreversible commands and expressing
negative emotions; and (4) the forearm and the hand are the most preferred locations
on the upper limb for on-skin input. We detail on users' mental models and contribute
a first consolidated set of on-skin gestures. Our findings provide guidance for developers
of future sensors as well as for designers of future applications of on-skin input.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {179–188},
numpages = {10},
keywords = {skin gestures, mobile computing, deformable surface, touch input, on-skin input, elicitation study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557258,
author = {Huang, Da-Yuan and Tsai, Ming-Chang and Tung, Ying-Chao and Tsai, Min-Lun and Yeh, Yen-Ting and Chan, Liwei and Hung, Yi-Ping and Chen, Mike Y.},
title = {TouchSense: Expanding Touchscreen Input Vocabulary Using Different Areas of Users' Finger Pads},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557258},
doi = {10.1145/2556288.2557258},
abstract = {We present TouchSense, which provides additional touchscreen input vocabulary by distinguishing
the areas of users' finger pads contacting the touchscreen. It requires minimal touch
input area and minimal movement, making it especially ideal for wearable devices such
as smart watches and smart glasses. For example, users of a calculator application
on a smart watch could tap normally to enter numbers, and tap with the right side
of their fingers to enter the operators (e.g. , -, =). Results from two human-factor
studies showed that users could tap a touchscreen with five or more distinct areas
of their finger pads. Also, they were able to tap with more distinct areas closer
to their fingertips. We developed a TouchSense smart watch prototype using inertial
measurement sensors, and developed two example applications: a calculator and a text
editor. We also collected user feedback via an explorative study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {189–192},
numpages = {4},
keywords = {small-screen devices, smart watch, single-tap mode switching, input modality, augmented finger input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557017,
author = {Xiao, Robert and Laput, Gierad and Harrison, Chris},
title = {Expanding the Input Expressivity of Smartwatches with Mechanical Pan, Twist, Tilt and Click},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557017},
doi = {10.1145/2556288.2557017},
abstract = {Smartwatches promise to bring enhanced convenience to common communication, creation
and information retrieval tasks. Due to their prominent placement on the wrist, they
must be small and otherwise unobtrusive, which limits the sophistication of interactions
we can perform. This problem is particularly acute if the smartwatch relies on a touchscreen
for input, as the display is small and our fingers are relatively large. In this work,
we propose a complementary input approach: using the watch face as a multi-degree-of-freedom,
mechanical interface. We developed a proof of concept smartwatch that supports continuous
2D panning and twist, as well as binary tilt and click. To illustrate the potential
of our approach, we developed a series of example applications, many of which are
cumbersome -- or even impossible -- on today's smartwatch devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {193–196},
numpages = {4},
keywords = {wearable computing, smart clothing, buttons, touchscreens, on-body interfaces, watch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250916,
author = {Hancock, Mark},
title = {Session Details: The Third Dimension},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250916},
doi = {10.1145/3250916},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557125,
author = {\v{C}opi\v{c} Pucihar, Klen and Coulton, Paul and Alexander, Jason},
title = {The Use of Surrounding Visual Context in Handheld AR: Device vs. User Perspective Rendering},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557125},
doi = {10.1145/2556288.2557125},
abstract = {The magic lens paradigm, a commonly used descriptor for handheld Augmented Reality
(AR), presents the user with dual views: the augmented view (magic lens) that appears
on the device, and the real view of the surroundings (what the user can see around
the perimeter of the device). The augmented view is typically implemented by rendering
the video captured by the rear-facing camera directly onto the device's screen. This
results in dual perspectives - the real world being captured from the device's perspective
rather than the user's perspective (what an observer would see looking through a transparent
glass pane). These differences manifest themselves in misaligned and/or incorrectly
scaled transparency resulting in the dual-view problem.This paper presents two user
studies comparing (a) device-perspective and (b) fixed Point-of-View (POV) user-perspective
magic lenses to analyze the effect of the dual-view problem on the use of the surrounding
visual context. The results confirm that the dual-view problem, a result of dual perspective,
has a significant effect on the use of information from the surrounding visual context.
The study also highlights that magnification and not the dual-view problem is the
key factor explaining the correlation between magic lens size and the increased intensity
of the magic lens type effect. From the results, we derive design guidelines for future
magic lenses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {197–206},
numpages = {10},
keywords = {dual-view, dual views, ar, user-perspective, magic lens},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557283,
author = {Schild, Jonas and LaViola, Joseph J. and Masuch, Maic},
title = {Altering Gameplay Behavior Using Stereoscopic 3D Vision-Based Video Game Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557283},
doi = {10.1145/2556288.2557283},
abstract = {We explore the potential of stereoscopic 3D (S3D) vision in offering distinct gameplay
using an S3D-specific game called Deepress3D. Our game utilizes established S3D design
principles for optimizing GUI design, visual comfort and game mechanics which rely
on depth perception in time-pressured spatial conflicts. The game collects detailed
S3D player metrics and allows players to choose between different, evenly matched
strategies. We conducted a between subjects study comparing S3D and monoscopic versions
of Deepress3D that examined player behavior and performance and measured user-reported
data on presence, simulator sickness, and game experience. Confirming previous results,
stereo users reported higher spatial presence. More importantly, for the first time,
our game metrics indicate that S3D vision can measurably change player behavior depending
on actual game content and level design, without necessarily affecting performance
or emotional experience. These findings indicate the potential for optimizing applications
for stereo users distinguishing them as a distinct group in HCI research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {207–216},
numpages = {10},
keywords = {simulator sickness, player behavior, user experience, stereoscopic 3d, gameplay metrics, game design, spatial presence},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557089,
author = {Mauderer, Michael and Conte, Simone and Nacenta, Miguel A. and Vishwanath, Dhanraj},
title = {Depth Perception with Gaze-Contingent Depth of Field},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557089},
doi = {10.1145/2556288.2557089},
abstract = {Blur in images can create the sensation of depth because it emulates an optical property
of the eye; namely, the limited depth of field created by the eye's lens. When the
human eye looks at an object, this object appears sharp on the retina, but objects
at different distances appear blurred. Advances in gaze-tracking technologies enable
us to reproduce dynamic depth of field in regular displays, providing an alternative
way of conveying depth. In this paper we investigate gaze-contingent depth of field
as a method to produce realistic 3D images, and analyze how effectively people can
use it to perceive depth. We found that GC DOF increases subjective perceived realism
and depth and can contribute to the perception of ordinal depth and distance between
objects, but it is limited in its accuracy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–226},
numpages = {10},
keywords = {eye tracking, blur, gaze-contingent display, three-dimensional graphics and realism, depth perception, depth cues, depth-of-field},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557134,
author = {Valkov, Dimitar and Giesler, Alexander and Hinrichs, Klaus H.},
title = {Imperceptible Depth Shifts for Touch Interaction with Stereoscopic Objects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557134},
doi = {10.1145/2556288.2557134},
abstract = {While touch technology has proven its usability for 2D interaction and has already
become a standard input modality for many devices, the challenges to exploit its applicability
with stereoscopically rendered content have barely been studied. In this paper we
exploit the properties of the visual perception to allow users to touch stereoscopically
displayed objects when the input is constrained to a 2D surface. Therefore, we have
extended and generalized recent evaluations on the user's ability to discriminate
small induced object shifts while reaching out to touch a virtual object, and we propose
a practical interaction technique, the attracting shift technique, suitable for numerous
application scenarios where shallow depth interaction is sufficient. In addition,
our results indicate that slight object shifts during touch interaction make the virtual
scene appear perceptually more stable compared to a static scene. As a consequence,
applications have to manipulate the virtual objects to make them appear static for
the user.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {227–236},
numpages = {10},
keywords = {experimentation, human factors},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250917,
author = {Subramanian, Sriram},
title = {Session Details: Audio Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250917},
doi = {10.1145/3250917},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557206,
author = {Adams, Alexander Travis and Gonzalez, Berto and Latulipe, Celine},
title = {SonicExplorer: Fluid Exploration of Audio Parameters},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557206},
doi = {10.1145/2556288.2557206},
abstract = {In digital music production, the phrase "in the box" refers to the increasing replacement
of extraneous hardware devices with compatible software components. As controls move
from hard to soft, we have seen an increase in usability issues for musicians and
sound engineers dealing with a large number of temporal inputs and both continuous
and discrete controls. We present the SonicExplorer application, which we developed
to give users a new interface for exploring and manipulating audio. SonicExplorer
leverages users' spatial and color perception to enhance exploration by visualizing
the parameter space and providing implicit memory cues. The application also leverages
bimanual input to aid in fluid exploration of multidimensional audio parameter spaces,
and to minimize the need for switching between parameters.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {237–246},
numpages = {10},
keywords = {color memory cues, spatial memory cues, bimanual interaction, parameter exploration, audio},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557000,
author = {M\"{u}ller, J\"{o}rg and Geier, Matthias and Dicke, Christina and Spors, Sascha},
title = {The BoomRoom: Mid-Air Direct Interaction with Virtual Sound Sources},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557000},
doi = {10.1145/2556288.2557000},
abstract = {In this paper we present a system that allows to "touch", grab and manipulate sounds
in mid-air. Further, arbitrary objects can seem to emit sound. We use spatial sound
reproduction for sound rendering and computer vision for tracking. Using our approach,
sounds can be heard from anywhere in the room and always appear to originate from
the same (possibly moving) position, regardless of the listener's position. We demonstrate
that direct "touch" interaction with sound is an interesting alternative to indirect
interaction mediated through controllers or visual interfaces. We show that sound
localization is surprisingly accurate (11.5 cm), even in the presence of distractors.
We propose to leverage the ventriloquist effect to further increase localization accuracy.
Finally, we demonstrate how affordances of real objects can create synergies of auditory
and visual feedback. As an application of the system, we built a spatial music mixing
room.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {247–256},
numpages = {10},
keywords = {spatial sound reproduction, mid-air, gestural interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557253,
author = {Bryan, Nicholas J. and Mysore, Gautham J. and Wang, Ge},
title = {ISSE: An Interactive Source Separation Editor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557253},
doi = {10.1145/2556288.2557253},
abstract = {Traditional audio editing tools do not facilitate the task of separating a single
mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal,
etc.). Such ability, however, would be very useful for a wide variety of audio applications
such as music remixing, audio denoising, and audio-based forensics. To address this
issue, we present ISSE - an interactive source separation editor. ISSE is a new open-source,
freely available, and cross-platform audio editing tool that enables a user to perform
source separation by painting on time-frequency visualizations of sound, resulting
in an interactive machine learning system. The system brings to life our previously
proposed interaction paradigm and separation algorithm that learns from user-feedback
to perform separation. For evaluation, we conducted user studies and compared results
between inexperienced and expert users. For a variety of real-world tasks, we found
that inexperienced users can achieve good separation quality with minimal instruction
and expert users can achieve state-of-the-art separation quality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {257–266},
numpages = {10},
keywords = {source separation, interactive machine learning, audio interface, intelligent user interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557168,
author = {Marentakis, Georgios and Liepins, Rudolfs},
title = {Evaluation of Hear-through Sound Localization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557168},
doi = {10.1145/2556288.2557168},
abstract = {Listening and interacting with audio commonly relies on using earphones which limit
the ability of users to perceive their auditory environment. Earphone sets that integrate
miniature microphones on their exterior can, however, be used to hear-through the
auditory environment. We present an evaluation study in which sound localization when
wearing such a hear-through system is compared to normal earphones, open headphones
and unblocked ears. Although localization performance is improved compared to open
headphones, we find that it is compromised in comparison to listening without earphones
because confusions of sound direction increase and localization judgment distributions
are more dispersed and show a weaker correlation to the test directions. The implications
of the results to human computer interaction and possible improvements to hear-through
system design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {267–270},
numpages = {4},
keywords = {auditory augmented reality, hear-through systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250918,
author = {Hazas, Mike},
title = {Session Details: Sustainability and Everyday Practices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250918},
doi = {10.1145/3250918},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557318,
author = {Normark, Maria and Tholander, Jakob},
title = {Performativity in Sustainable Interaction: The Case of Seasonal Grocery Shopping in Ecofriends},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557318},
doi = {10.1145/2556288.2557318},
abstract = {The EcoFriends application was developed as an attempt to support grocery shopping
adjusted to vegetables? seasonality through a performative approach to interaction
and interactive applications. The design aimed at critical reflection and inspiration
among users, rather than achieving a certain kind of persuasion. This guided the practical
design to be modelled around open-endedness and social voices to challenge ideas and
points of view. We argue that research addressing design for interactions about value-laden
concepts such as sustainable action need to find ways of supporting various knowledge
discourses, by distinguishing between performative and representational technologies.
The approach allowed us to identify a number of design challenges regarding interactive
technology and interaction design in relation to aspects of knowledge and truth, trust,
negotiation and responsibility.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {271–280},
numpages = {10},
keywords = {mobile interaction, sustainable interaction, performative design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250919,
author = {de Paula, Rogerio},
title = {Session Details: Studying Online Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250919},
doi = {10.1145/3250919},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557213,
author = {Zhu, Haiyi and Kraut, Robert E. and Kittur, Aniket},
title = {The Impact of Membership Overlap on the Survival of Online Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557213},
doi = {10.1145/2556288.2557213},
abstract = {If the people belong to multiple online communities, their joint membership can influence
the survival of each of the communities to which they belong. Communities with many
joint memberships may struggle to get enough of their members' time and attention,
but find it easy to import best practices from other communities. In this paper, we
study the effects of membership overlap on the survival of online communities. By
analyzing the historical data of 5673 Wikia communities, we find that higher levels
of membership overlap are positively associated with higher survival rates of online
communities. Furthermore, we find that it is beneficial for young communities to have
shared members who play a central role in other mature communities. Our contributions
are two-fold. Theoretically, by examining the impact of membership overlap on the
survival of online communities we identified an important mechanism underlying the
success of online communities. Practically, our findings may guide community creators
on how to effectively manage their members, and tool designers on how to support this
task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–290},
numpages = {10},
keywords = {survival analysis, membership overlap, online communities},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557201,
author = {Matthews, Tara and Chen, Jilin and Whittaker, Steve and Pal, Aditya and Zhu, Haiyi and Badenes, Hernan and Smith, Barton},
title = {Goals and Perceived Success of Online Enterprise Communities: What is Important to Leaders &amp; Members?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557201},
doi = {10.1145/2556288.2557201},
abstract = {Online communities are successful only if they achieve their goals, but there has
been little direct study of goals. We analyze novel data characterizing the goals
of enterprise online communities, assessing the importance of goals for leaders, how
goals influence member perceptions of community value, and how goals relate to success
measures proposed in the literature. We find that most communities have multiple goals
and common goals are learning, reuse of resources, collaboration, networking, influencing
change, and innovation. Leaders and members agree that all of these goals are important,
but their perceptions of success on goals do not align with each other, or with commonly
used behavioral success measures. We conclude that simple behavioral measures and
leader perceptions are not good success metrics, and propose alternatives based on
specific goals members and leaders judge most important.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {291–300},
numpages = {10},
keywords = {enterprise, workplace, metrics, goals, online communities},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557348,
author = {Zhu, Haiyi and Chen, Jilin and Matthews, Tara and Pal, Aditya and Badenes, Hernan and Kraut, Robert E.},
title = {Selecting an Effective Niche: An Ecological View of the Success of Online Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557348},
doi = {10.1145/2556288.2557348},
abstract = {Online communities serve various important functions, but many fail to thrive. Research
on community success has traditionally focused on internal factors. In contrast, we
take an ecological view to understand how the success of a community is influenced
by other communities. We measured a community's relationship with other communities
- its "niche" - through four dimensions: topic overlap, shared members, content linking,
and shared offline organizational affiliation. We used a mixed-method approach, combining
the quantitative analysis of 9495 online enterprise communities and interviews with
community members. Our results show that too little or too much overlap in topic with
other communities causes a community's activity to suffer. We also show that this
main result is moderated in predictable ways by whether the community shares members
with, links to content in, or shares an organizational affiliation with other communities.
These findings provide new insight on community success, guiding online community
designers on how to effectively position their community in relation to others.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {301–310},
numpages = {10},
keywords = {topic overlap, workplace, success, online communities},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557313,
author = {Halfaker, Aaron and Geiger, R. Stuart and Terveen, Loren G.},
title = {Snuggle: Designing for Efficient Socialization and Ideological Critique},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557313},
doi = {10.1145/2556288.2557313},
abstract = {Wikipedia, the encyclopedia "anyone can edit", has become increasingly less so. Recent
academic research and popular discourse illustrates the often aggressive ways newcomers
are treated by veteran Wikipedians. These are complex sociotechnical issues, bound
up in infrastructures based on problematic ideologies. In response, we worked with
a coalition of Wikipedians to design, develop, and deploy Snuggle, a new user interface
that served two critical functions: making the work of newcomer socialization more
effective, and bringing visibility to instances in which Wikipedians? current practice
of gatekeeping socialization breaks down. Snuggle supports positive socialization
by helping mentors quickly find newcomers whose good-faith mistakes were reverted
as damage. Snuggle also supports ideological critique and reflection by bringing visibility
to the consequences of viewing newcomers through a lens of suspiciousness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {311–320},
numpages = {10},
keywords = {design, wikipedia, critique, algorithms, activism},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250920,
author = {Moscovich, Tomer},
title = {Session Details: Image and Animation Authoring},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250920},
doi = {10.1145/3250920},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557062,
author = {Nakajima, Makoto and Sakamoto, Daisuke and Igarashi, Takeo},
title = {Offline Painted Media for Digital Animation Authoring},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557062},
doi = {10.1145/2556288.2557062},
abstract = {We present an animation creation workflow for integrating offline physical, painted
media into the digital authoring of Flash-style animations. Generally, animators create
animations with standardized digital authoring software. However, the results tend
to lack the individualism or atmosphere of physical media. In contrast, illustrators
have skills in painting physical media but have limited experience in animation. To
incorporate their skills, we present a workflow that integrates the offline painting
and digital animation creation processes in a labor-saving manner. First, a user makes
a rough sketch of the visual elements and defines their movements using our digital
authoring software with a sketch interface. Then these images are exported to printed
pages, and users can paint using offline physical media. Finally, the work is scanned
and imported back into the digital content, forming a composite animation that combines
digital and physical media. We present an implementation of this system to demonstrate
its workflow. We also discuss the advantages of using physical media in digital animations
through design evaluations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {321–330},
numpages = {10},
keywords = {creativity support tool, offline painted media, workflow, animation authoring},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557411,
author = {Mangano, Nicolas and LaToza, Thomas D. and Petre, Marian and van der Hoek, Andr\'{e}},
title = {Supporting Informal Design with Interactive Whiteboards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557411},
doi = {10.1145/2556288.2557411},
abstract = {Whiteboards serve an important role in supporting informal design, providing a fluid
and flexible medium for collaborative design. Interactive whiteboards offer the potential
for enhanced support for manipulating content, managing sketches, and distributed
work, but little is known about how this support affects the practice of informal
design. To understand the opportunities and challenges, we first conducted a literature
review, identifying 14 behaviors that occur during informal design. We then designed
an interactive whiteboard system to support all of these behaviors and deployed the
system to three groups of designers. Through usage logs and interviews, we examined
the effects of interactivity on whiteboard use across a wide spectrum of design behaviors,
identifying ways in which interactive whiteboards support the practices used in physical
whiteboards and where they enable designers to work more effectively.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {331–340},
numpages = {10},
keywords = {interactive whiteboard, design, sketching, informal design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557327,
author = {Benjamin, William and Chandrasegaran, Senthil and Ramanujan, Devarajan and Elmqvist, Niklas and Vishwanathan, SVN and Ramani, Karthik},
title = {Juxtapoze: Supporting Serendipity and Creative Expression in Clipart Compositions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557327},
doi = {10.1145/2556288.2557327},
abstract = {Juxtapoze is a clipart composition workflow that supports creative expression and
serendipitous discoveries in the shape domain. We achieve creative expression by supporting
a workflow of searching, editing, and composing: the user queries the shape database
using strokes, selects the desired search result, and finally modifies the selected
image before composing it into the overall drawing. Serendipitous discovery of shapes
is facilitated by allowing multiple exploration channels, such as doodles, shape filtering,
and relaxed search. Results from a qualitative evaluation show that Juxtapoze makes
the process of creating image compositions enjoyable and supports creative expression
and serendipity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {341–350},
numpages = {10},
keywords = {shape search, clipart composition, serendipity, sketching, creative expression},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556987,
author = {Kazi, Rubaiat Habib and Chevalier, Fanny and Grossman, Tovi and Zhao, Shengdong and Fitzmaurice, George},
title = {Draco: Bringing Life to Illustrations with Kinetic Textures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556987},
doi = {10.1145/2556288.2556987},
abstract = {We present Draco, a sketch-based interface that allows artists and casual users alike
to add a rich set of animation effects to their drawings, seemingly bringing illustrations
to life. While previous systems have introduced sketch-based animations for individual
objects, our contribution is a unified framework of motion controls that allows users
to seamlessly add coordinated motions to object collections. We propose a framework
built around kinetic textures, which provide continuous animation effects while preserving
the unique timeless nature of still illustrations. This enables many dynamic effects
difficult or not possible with previous sketch-based tools, such as a school of fish
swimming, tree leaves blowing in the wind, or water rippling in a pond. We describe
our implementation and illustrate the repertoire of animation effects it supports.
A user study with professional animators and casual users demonstrates the variety
of animations, applications and creative possibilities our tool provides.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {351–360},
numpages = {10},
keywords = {kinetic textures, sketching, animation, direct manipulation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250921,
author = {Gutwin, Carl},
title = {Session Details: Studying and Designing Gameplay},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250921},
doi = {10.1145/3250921},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557317,
author = {Kriglstein, Simone and Wallner, G\"{u}nter and Pohl, Margit},
title = {A User Study of Different Gameplay Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557317},
doi = {10.1145/2556288.2557317},
abstract = {With the rising interest in multiplayer gaming, gameplay statistics have become an
increasingly important aspect of the overall game experience for many players. As
a part of this trend, visualizations have gained great popularity among players, in
particular heatmaps since they allow them to reenact the course of a game and to develop
new strategies. In this paper we report results of a user study conducted with 29
players (i) to investigate how players use heatmaps and two further graphical representations
that use clustering algorithms to interpret gameplay and (ii) to assess the three
representations in regard to time efficiency, correctness, suitability, and player
preference. Our results show that heatmaps were mainly used to detect hot spots while
the cluster representations proved useful to compare variables, allowing the players
to uncover relationships between them and in turn allowing a deeper insight into the
gameplay data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {361–370},
numpages = {10},
keywords = {evaluation, heatmap, games, visualization, clustering},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557345,
author = {Cairns, Paul and Li, Jing and Wang, Wendy and Nordin, A. Imran},
title = {The Influence of Controllers on Immersion in Mobile Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557345},
doi = {10.1145/2556288.2557345},
abstract = {The controls for digital games understandably have an important part in building up
the gaming experiences that people have. Whilst there is substantial work on innovative
controllers for consoles, like the XBox Kinect, relatively little has been done to
understand the effect of the different control mechanisms that can be used to play
games on mobile devices like smartphones. A well-defined framework of naturalness
has emerged as potentially useful concept in area of game controllers. This paper
reports two experiments that look at how the naturalness of the game controls influences
the experience of immersion in mobile games. It seems that where there is an a prior
natural mapping, this will improve immersion in the game but in the absence of a prior
mapping, naturalness alone is not sufficient to account for immersion. This opens
up the need for a more thorough investigation of this area.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {371–380},
numpages = {10},
keywords = {mobile games, natural mappings, immersion, gaming experience, controllers},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557326,
author = {Tan, Chek Tien and Leong, Tuck Wah and Shen, Songjia},
title = {Combining Think-Aloud and Physiological Data to Understand Video Game Experiences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557326},
doi = {10.1145/2556288.2557326},
abstract = {Think-aloud protocols are commonly used to evaluate player experiences of video games
but suffer from a lack of objectivity and timeliness. On the other hand, quantitative
captures of physiological data are effective; providing detailed, unbiased and continuous
responses of players, but lack contexts for interpretation. This paper documents how
both approaches could be used together in practice by comparing video-cued retrospective
think-aloud data and physiological data collected during a video gameplay experiment.
We observed that many interesting physiological responses did not feature in participants'
think-aloud data, and conversely, reports of interesting experiences were sometimes
not observed in the collected physiological data. Through learnings from our experiment,
we present some of the challenges when combining these approaches and offer some guidelines
as to how qualitative and quantitative data can be used together to gain deeper insights
into player experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {381–390},
numpages = {10},
keywords = {psychophysiology, think-aloud, game user research},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557104,
author = {Goh, Wooi Boon and Chen, Ming and Trinh, Cuong Hong and Tan, Jacquelyn and Shou, Wei},
title = {The MOY Framework for Collaborative Play Design in Integrated Shared and Private Interactive Spaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557104},
doi = {10.1145/2556288.2557104},
abstract = {A novel Mine-Ours-Yours (MOY) interaction design framework is proposed for designing
collaborative play activities in environments that combine both private and shared
interactive spaces. A collaborative game designed on a system that integrates multiple
mobile devices with an interactive tabletop was presented to demonstrate the implementation
of the proposed MOY framework. Observations from field trials involving two groups
of children were used to summarize the collaborative behaviors that are likely to
be observed under the different interaction design configurations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {391–400},
numpages = {10},
keywords = {interaction design, cooperative design patterns, collaborative play, multi-touch interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250922,
author = {Oakley, Ian},
title = {Session Details: Force Input and Haptic Feedback},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250922},
doi = {10.1145/3250922},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557260,
author = {McLachlan, Ross and Boland, Daniel and Brewster, Stephen},
title = {Transient and Transitional States: Pressure as an Auxiliary Input Modality for Bimanual Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557260},
doi = {10.1145/2556288.2557260},
abstract = {A novel investigation of pressure input is presented where it is characterised as
a transient modality, one that has a natural inverse, bounce-back and a state that
only persists during interaction. Three empirical studies are described that evaluate
pressure for use as a non-dominant hand input modality, where the ability to target
and maintain pressure while simultaneously performing a dominant-hand targeting task
is investigated. Pressure accuracy was high (93%) and the impact on dominant-hand
targeting was low. Mean pressure accuracy when selecting targets by releasing pressure
was also high (89%) as was selecting targets by applying pressure from a non-zero
starting point (94.4%). The ability to accurately maintain pressure over time was
better with larger target pressures. Example applications and design guidelines are
presented that enable designers to exploit the transient properties of pressure input
in interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {401–410},
numpages = {10},
keywords = {bimanual interaction, non-dominant hand, pressure input, transience},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557252,
author = {Hachisu, Taku and Fukumoto, Masaaki},
title = {VacuumTouch: Attractive Force Feedback Interface for Haptic Interactive Surface Using Air Suction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557252},
doi = {10.1145/2556288.2557252},
abstract = {We present VacuumTouch, a novel haptic interface architecture for touch screens that
provides attractive force feedback to the user's finger. VacuumTouch consists of an
air pump and solenoid air valves that connect to the surface of the touch screen and
suck the air above the surface where the user's finger makes contact. VacuumTouch
does not require the user to hold or attach additional devices to provide the attractive
force, which allows for easy interaction with the surface. This paper introduces the
implementation of the VacuumTouch architecture and some applications for enhancement
of the graphical user interface, namely a suction button, a suction slider, and a
suction dial. The quantitative evaluation was conducted with the suction dial and
showed that the attractive force provided by VacuumTouch improved the performance
of the dial menu interface and its potential effects. At the end of this paper, we
discuss the current prototype's advantages and limitations, as well as possible improvements
and potential capabilities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {411–420},
numpages = {10},
keywords = {air suction, interactive surface, attractive force, vacuumtouch, haptic interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557019,
author = {Pedersen, Esben Warming and Hornb\ae{}k, Kasper},
title = {Expressive Touch: Studying Tapping Force on Tabletops},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557019},
doi = {10.1145/2556288.2557019},
abstract = {This paper investigates users' ability to perform force-sensitive tapping and explores
its potential as an input modality in touch-based systems. We study force-sensitive
tapping using Expressive Touch, a tabletop interface that infers tapping force from
the sound waves created by the users' finger upon impact. The first part of the paper
describes the implementation details of Expressive Touch and shows how existing tabletop
interfaces can be augmented to reliably detect tapping force across the entire surface.
The second part of the paper reports on the results of three studies of force-sensitive
tapping. First, we use a classic psychophysic task to gain insights into participants'
perception of tapping force (Study 1). Results show that although participants tap
with different absolute tapping forces, they have a similar perception of relative
tapping force. Second, we investigate participants' ability to control tapping force
(Study 2) and find that users can produce two force levels with 99% accuracy. For
six levels of force, accuracy drops to 58%. Third, we investigate the usability of
force tapping by studying participants' reactions to seven force-sensitive touch applications
(Study 3).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {421–430},
numpages = {10},
keywords = {acoustic sensing, expressive touch, force, tabletop computing, tapping, touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557146,
author = {Rendl, Christian and Greindl, Patrick and Probst, Kathrin and Behrens, Martin and Haller, Michael},
title = {Presstures: Exploring Pressure-Sensitive Multi-Touch Gestures on Trackpads},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557146},
doi = {10.1145/2556288.2557146},
abstract = {In this paper, we present Presstures, an extension to current multi-touch operations
that enriches common multi-finger gestures with pressure information. By using the
initially applied pressure level for implicit mode switching, a gesture can be enhanced
with different functionalities to enlarge the interaction space for multi-touch. To
evaluate the feasibility of our concept, we conducted an experiment, which indicates
good human sensorimotor skills for performing multi-touch gestures with a few number
of pressure levels and without any additional feedback. Based on the experimental
results, we discuss implications for the design of pressure-sensitive multi-touch
gestures, and propose application scenarios that make optimal use of our concept.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {431–434},
numpages = {4},
keywords = {pressure, multi-touch gestures, force, pressure gestures},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557040,
author = {Kangas, Jari and Akkil, Deepak and Rantala, Jussi and Isokoski, Poika and Majaranta, P\"{a}ivi and Raisamo, Roope},
title = {Gaze Gestures and Haptic Feedback in Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557040},
doi = {10.1145/2556288.2557040},
abstract = {Anticipating the emergence of gaze tracking capable mobile devices, we are investigating
the use of gaze as an input modality in handheld mobile devices. We conducted a study
of combining gaze gestures with vibrotactile feedback. Gaze gestures were used as
an input method in a mobile device and vibrotactile feedback as a new alternative
way to give confirmation of interaction events. Our results show that vibrotactile
feedback significantly improved the use of gaze gestures. The tasks were completed
faster and rated easier and more comfortable when vibrotactile feedback was provided.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {435–438},
numpages = {4},
keywords = {gaze tracking, haptic feedback, gaze interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250923,
author = {Tscheligi, Manfred},
title = {Session Details: Hackerspaces, Making and Breaking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250923},
doi = {10.1145/3250923},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557132,
author = {Lindtner, Silvia and Hertz, Garnet D. and Dourish, Paul},
title = {Emerging Sites of HCI Innovation: Hackerspaces, Hardware Startups &amp; Incubators},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557132},
doi = {10.1145/2556288.2557132},
abstract = {In this paper, we discuss how a flourishing scene of DIY makers is turning visions
of tangible and ubiquitous computing into products. Drawing on long-term multi-sited
ethnographic research and active participation in DIY making, we provide insights
into the social, material, and economic processes that undergird this transition from
prototypes to products. The contribution of this paper is three-fold. First, we show
how DIY maker practice is illustrative of a broader "return to" and interest in physical
materials. This has implications for HCI research that investigates questions of materiality.
Second, we shed light on how hackerspaces and hardware start-ups are experimenting
with new models of manufacturing and entrepreneurship. We argue that we have to take
seriously these maker practices, not just as hobbyist or leisure practice, but as
a professionalizing field functioning in parallel to research and industry labs. Finally,
we end with reflections on the role of HCI researchers and designers as DIY making
emerges as a site of HCI innovation. We argue that HCI is positioned to provide critical
reflection, paired with a sensibility for materials, tools and design methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {439–448},
numpages = {10},
keywords = {materiality, china, making cultures, manufacturing, diy, make, iot, hackerspace, critical making},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557332,
author = {Jackson, Steven J. and Kang, Laewoo},
title = {Breakdown, Obsolescence and Reuse: HCI and the Art of Repair},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557332},
doi = {10.1145/2556288.2557332},
abstract = {This paper describes an integrated program of theoretical, ethnographic, and building
work meant to explore post-humanist alternatives to questions around HCI creativity
and design. We review recent theories in the humanities, social sciences, and HCI
that argue for different ways of framing the relationship between human agents and
the object world around them. We then describe a program of ethnographic work with
artists who feature found and broken technologies as central methods and topics of
work. Finally, we describe an installation and self-study project of our own, 'Scale,'
that extends these lines of analysis through collaborative acts of building with broken
and discarded technologies. We argue that such integrated programs of work offer one
useful model for leveraging the theoretical, ethnographic and material dimensions
of HCI work; and that the distinct 'propensities' of found and broken objects can
challenge and extend HCI notions of creativity and design itself.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {449–458},
numpages = {10},
keywords = {design, ethnography, art, repair, agency},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557338,
author = {Hudson, Scott E.},
title = {Printing Teddy Bears: A Technique for 3D Printing of Soft Interactive Objects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557338},
doi = {10.1145/2556288.2557338},
abstract = {This paper considers the design, construction, and example use of a new type of 3D
printer which fabricates three-dimensional objects from soft fibers (wool and wool
blend yarn). This printer allows the substantial advantages of additive manufacturing
techniques (including rapid turn-around prototyping of physical objects and support
for high levels of customization and configuration) to be employed with a new class
of material. This material is a form of loose felt formed when fibers from an incoming
feed of yarn are entangled with the fibers in layers below it. The resulting objects
recreate the geometric forms specified in the solid models which specify them, but
are soft and flexible -- somewhat reminiscent in character to hand knitted materials.
This extends 3D printing from typically hard and precise forms into a new set of forms
which embody a different aesthetic of soft and imprecise objects, and provides a new
capability for researchers to explore the use of this class of materials in interactive
devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {459–468},
numpages = {10},
keywords = {soft materials, interactive devices, computational crafts, additive manufacturing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557267,
author = {Murer, Martin and Jacobsson, Mattias and Skillgate, Siri and Sundstr\"{o}m, Petra},
title = {Taking Things Apart: Reaching Common Ground and Shared Material Understanding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557267},
doi = {10.1145/2556288.2557267},
abstract = {In this note we discuss and argue about how taking things apart and disassembling
can be meaningful practices in explorative design projects. In particular, we report
on an explorative design exercise about taking apart an unfamiliar device. Relating
to this design situation, we provide accounts for how collaborative hands-on experience
can support reaching common ground and acquiring shared material understanding in
an interdisciplinary design team through establishing a material brief. In the end
we reflect and discuss how this may complement our practices regarding materials and
interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {469–472},
numpages = {4},
keywords = {exploration, artifacts, material, disassembling},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557221,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Toombs, Austin},
title = {"now That's Definitely a Proper Hack": Self-Made Tools in Hackerspaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557221},
doi = {10.1145/2556288.2557221},
abstract = {Cultures of making - that is, social practices of hacking, DIY, tinkering, repair,
and craft - continue to rise in prominence, and design researchers have taken note,
because of their implications for sustainability, democratization, and alternative
models of innovation, design, participation, and education. We contribute to this
agenda by exploring our findings on self-made tools, which we encountered in a 9-month
ethnographic study of a hackerspace. Self-made tools embody issues raised in two discourses
that are of interest in design research on making: tools and adhocism. In this paper,
we explore ways that tools and adhocism interface with each other, using our findings
as a material to think with. We find that this juxtaposition of concepts helps explain
a highly generative creative practice - tool-making - within the hackerspace we studied.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–476},
numpages = {4},
keywords = {tools, maker culture, hci, hackerspaces, hackers, design, ad hoc},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250924,
author = {Busse, Daniela},
title = {Session Details: Activity Recognition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250924},
doi = {10.1145/3250924},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557220,
author = {Min, Jun-Ki and Doryab, Afsaneh and Wiese, Jason and Amini, Shahriyar and Zimmerman, John and Hong, Jason I.},
title = {Toss 'n' Turn: Smartphone as Sleep and Sleep Quality Detector},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557220},
doi = {10.1145/2556288.2557220},
abstract = {The rapid adoption of smartphones along with a growing habit for using these devices
as alarm clocks presents an opportunity to use this device as a sleep detector. This
adds value to UbiComp and personal informatics in terms of user context and new performance
data to collect and visualize, and it benefits healthcare as sleep is correlated with
many health issues. To assess this opportunity, we collected one month of phone sensor
and sleep diary entries from 27 people who have a variety of sleep contexts. We used
this data to construct models that detect sleep and wake states, daily sleep quality,
and global sleep quality. Our system classifies sleep state with 93.06% accuracy,
daily sleep quality with 83.97% accuracy, and overall sleep quality with 81.48% accuracy.
Individual models performed better than generally trained models, where the individual
models require 3 days of ground truth data and 3 weeks of ground truth data to perform
well on detecting sleep and sleep quality, respectively. Finally, the features of
noise and movement were useful to infer sleep quality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {477–486},
numpages = {10},
keywords = {sensors, sleep, machine learning, smartphone},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557383,
author = {Fritz, Thomas and Huang, Elaine M. and Murphy, Gail C. and Zimmermann, Thomas},
title = {Persuasive Technology in the Real World: A Study of Long-Term Use of Activity Sensing Devices for Fitness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557383},
doi = {10.1145/2556288.2557383},
abstract = {Persuasive technology to motivate healthy behavior is a growing area of research within
HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking
health- and fitness-related activities arguably represents the first widespread adoption
of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems
allows us to learn about their value and use in truly "in the wild" contexts and understand
how practices evolve over long-term, naturalistic use. We present a study with 30
participants who had adopted wearable activity-tracking devices of their own volition
and had continued to use them for between 3 and 54 months. The findings, which both
support and contrast with those of previous research, paint a picture of the evolving
benefits and practices surrounding these emerging technologies over long periods of
use. They also serve as the basis for design implications for personal informatics
technologies for long-term health and fitness support.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {487–496},
numpages = {10},
keywords = {persuasive technology, behavior change, wearable sensing, personal informatics, activity monitoring, health},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557147,
author = {Y\"{u}r\"{u}ten, Onur and Zhang, Jiyong and Pu, Pearl H.Z.},
title = {Predictors of Life Satisfaction Based on Daily Activities from Mobile Sensor Data},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557147},
doi = {10.1145/2556288.2557147},
abstract = {In recent years much research work has been dedicated to detecting user activity patterns
from sensor data such as location, movement and proximity. However, how daily activities
are correlated to people's happiness (such as their satisfaction from work and social
lives) is not well explored. In this work, we propose an approach to investigate the
relationship between users' daily activity patterns and their life satisfaction level.
From a well-known longitudinal dataset collected by mobile devices, we extract various
activity features through location and proximity information, and compute the entropies
of these data to capture the regularities of the behavioral patterns of the participants.
We then perform component analysis and structural equation modeling to identify key
behavior contributors to self-reported satisfaction scores. Our results show that
our analytical procedure can identify meaningful assumptions of causality between
activities and satisfaction. Particularly, keeping regularity in daily activities
can significantly improve the life satisfaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {497–500},
numpages = {4},
keywords = {handheld devices and mobile computing, ubiquitous computing/smart environments, analysis methods},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250925,
author = {Schoenebeck, Sarita Yardi},
title = {Session Details: Managing Income},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250925},
doi = {10.1145/3250925},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556961,
author = {Vines, John and Dunphy, Paul and Monk, Andrew},
title = {Pay or Delay: The Role of Technology When Managing a Low Income},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556961},
doi = {10.1145/2556288.2556961},
abstract = {This paper reports on a qualitative study of 38 low-income individuals living in the
North East of England. The participants' experiences of money, banking and the role
digital technology plays in their financial practices were identified through semi-structured
interviews in people's homes and group workshops. A grounded theory analysis of these
data characterises how technology both helped and hindered participants to keep close
control of their finances. These findings suggest design opportunities for future
digital banking technologies that extend the already sophisticated practices of individuals
managing a low income, focusing on: delaying, prioritising, planning, watching, and
hiding monetary transactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {501–510},
numpages = {10},
keywords = {financial inclusion, low income, banking technologies, qualitative study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557358,
author = {Smith-Clarke, Christopher and Mashhadi, Afra and Capra, Licia},
title = {Poverty on the Cheap: Estimating Poverty Maps Using Aggregated Mobile Communication Networks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557358},
doi = {10.1145/2556288.2557358},
abstract = {Governments and other organisations often rely on data collected by household surveys
and censuses to identify areas in most need of regeneration and development projects.
However, due to the high cost associated with the data collection process, many developing
countries conduct such surveys very infrequently and include only a rather small sample
of the population, thus failing to accurately capture the current socio-economic status
of the country's population. In this paper, we address this problem by means of a
methodology that relies on an alternative source of data from which to derive up to
date poverty indicators, at a very fine level of spatio-temporal granularity. Taking
two developing countries as examples, we show how to analyse the aggregated call detail
records of mobile phone subscribers and extract features that are strongly correlated
with poverty indexes currently derived from census data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {511–520},
numpages = {10},
keywords = {data4d, socio-economics, ict4d, call detail records},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556975,
author = {Kaye, Joseph Jofish and McCuistion, Mary and Gulotta, Rebecca and Shamma, David A.},
title = {Money Talks: Tracking Personal Finances},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556975},
doi = {10.1145/2556288.2556975},
abstract = {How do people keep track of their money? In this paper we present a preliminary scoping
study of how 14 individuals in the San Francisco Bay Area earn, save, spend and understand
money and their personal and family finances. We describe the practices we developed
for exploring the sensitive topic of money, and then discuss three sets of findings.
The first is the emotional component of the relationship people have with their finances.
Second, we discuss the tools and processes people used to keep track of their financial
situation. Finally we discuss how people account for the unknown and unpredictable
nature of the future through their financial decisions. We conclude by discussing
the future of studies of money and finance in HCI, and reflect on the opportunities
for improving tools to aid people in managing and planning their finances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {521–530},
numpages = {10},
keywords = {money, finance, banking, interviews},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557123,
author = {Dillahunt, Tawanna R.},
title = {Fostering Social Capital in Economically Distressed Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557123},
doi = {10.1145/2556288.2557123},
abstract = {Past Information and Communication Technology (ICT) literature suggests that engaging
in meaningful activities with ICTs may be related to socio-economic security, social
inclusion, empowerment, and increased social capital. However, we identify a pervasive
lack of understanding in existing literature, which raises an important research question:
how can we build social capital where little social capital exists? We conducted a
preliminary study to explore whether and if so, how, individuals in an economically
distressed population with limited social capital use technologies to increase social
capital and achieve socio-economic security. We contribute details about barriers
affecting social capital (e.g., difficulties finding and making the right connections
and an overall lack of trust within communities). We also suggest ways in which ICTs
can assist populations that could benefit most from increased social capital and economic
security.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {531–540},
numpages = {10},
keywords = {sustainability, social capital, economic mobility, ict4d},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250926,
author = {Isenberg, Petra},
title = {Session Details: Designing and Understanding Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250926},
doi = {10.1145/3250926},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557408,
author = {Setlur, Vidya and Mackinlay, Jock D.},
title = {Automatic Generation of Semantic Icon Encodings for Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557408},
doi = {10.1145/2556288.2557408},
abstract = {Authors use icon encodings to indicate the semantics of categorical information in
visualizations. The default icon libraries found in visualization tools often do not
match the semantics of the data. Users often manually search for or create icons that
are more semantically meaningful. This process can hinder the flow of visual analysis,
especially when the amount of data is large, leading to a suboptimal user experience.
We propose a technique for automatically generating semantically relevant icon encodings
for categorical dimensions of data points. The algorithm employs natural language
processing in order to find relevant imagery from the Internet. We evaluate our approach
on Mechanical Turk by generating large libraries of icons using Tableau Public workbooks
that represent real analytical effort by people out in the world. Our results show
that the automatic algorithm does nearly as well as the manually created icons, and
particularly has higher user satisfaction for larger cardinalities of data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {541–550},
numpages = {10},
keywords = {image retrieval., icon encodings, natural language processing (nlp), visualization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557200,
author = {Albers, Danielle and Correll, Michael and Gleicher, Michael},
title = {Task-Driven Evaluation of Aggregation in Time Series Visualization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557200},
doi = {10.1145/2556288.2557200},
abstract = {Many visualization tasks require the viewer to make judgments about aggregate properties
of data. Recent work has shown that viewers can perform such tasks effectively, for
example to efficiently compare the maximums or means over ranges of data. However,
this work also shows that such effectiveness depends on the designs of the displays.
In this paper, we explore this relationship between aggregation task and visualization
design to provide guidance on matching tasks with designs. We combine prior results
from perceptual science and graphical perception to suggest a set of design variables
that influence performance on various aggregate comparison tasks. We describe how
choices in these variables can lead to designs that are matched to particular tasks.
We use these variables to assess a set of eight different designs, predicting how
they will support a set of six aggregate time series comparison tasks. A crowd-sourced
evaluation confirms these predictions. These results not only provide evidence for
how the specific visualizations support various tasks, but also suggest using the
identified design variables as a tool for designing visualizations well suited for
various types of tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {551–560},
numpages = {10},
keywords = {perceptual study, time series visualization, information visualization, visualization design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557195,
author = {Glueck, Michael and Khan, Azam and Wigdor, Daniel J.},
title = {Dive in! Enabling Progressive Loading for Real-Time Navigation of Data Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557195},
doi = {10.1145/2556288.2557195},
abstract = {We introduce Splash, a framework reducing development overhead for both data curators
and visualization developers of client-server visualization systems. Splash streamlines
the process of creating a multiple level-of-detail version of the data and facilitates
progressive data download, thereby enabling real-time, on-demand navigation with existing
visualization toolkits. As a result, system responsiveness is increased and the user
experience is improved. We demonstrate the benefit of progressive loading for user
interaction on slower networks. Additionally, case study evaluations of Splash with
real-world data curators suggest that Splash supports iterative refinement of visualizations
and promotes the use of exploratory data analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {561–570},
numpages = {10},
keywords = {progressive-loading, data visualization, real-time interaction, client-server},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557131,
author = {Ferreira, Nivan and Fisher, Danyel and Konig, Arnd Christian},
title = {Sample-Oriented Task-Driven Visualizations: Allowing Users to Make Better, More Confident Decisions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557131},
doi = {10.1145/2556288.2557131},
abstract = {We often use datasets that reflect samples, but many visualization tools treat data
as full populations. Uncertain visualizations are good at representing data distributions
emerging from samples, but are more limited in allowing users to carry out decision
tasks. This is because tasks that are simple on a traditional chart (e.g. "compare
two bars") become a complex probabilistic task on a chart with uncertainty. We present
guidelines for creating visual annotations for solving tasks with uncertainty, and
an implementation that addresses five core tasks on a bar chart. A preliminary user
study shows promising results: that users have a justified confidence in their answers
with our system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {571–580},
numpages = {10},
keywords = {boxplot, uncertainty visualization, incremental visualization, error bars, user study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250927,
author = {Muller, Michael},
title = {Session Details: Crowdfunding and Crowd Storage},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250927},
doi = {10.1145/3250927},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557110,
author = {Greenberg, Michael D. and Gerber, Elizabeth M.},
title = {Learning to Fail: Experiencing Public Failure Online through Crowdfunding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557110},
doi = {10.1145/2556288.2557110},
abstract = {Online crowdfunding platforms like Kickstarter are gaining attention among novice
creatives as an effective platform for funding their ventures and engaging in creative
work with others. However, a focus on financial success of crowdfunding has obscured
the fact that over 58% of crowdfunding projects fail to achieve their funding goals.
This population of failed creatives however, gives us an audience to study public
creative failure in an online environment. We draw inspiration from work in organizational
behavior on failure, and work in Human Computer Interaction (HCI) on online behavior,
to study online public failure. Using a mixed-methods approach with data scraped from
Kickstarter and interview data with failed crowdfunding project creators, we answer
the following question: What do project creators on crowdfunding platforms learn and
change through the process of failing? We find that creators who relaunch their projects
succeed 43% of the time, and that most individuals find failure to be a positive experience.
We conclude the paper with a series of design implications for future creative platforms
where public failure is part of the creative process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {581–590},
numpages = {10},
keywords = {crowdfunding, feedback, crowdsourcing, failure},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557045,
author = {Xu, Anbang and Yang, Xiao and Rao, Huaming and Fu, Wai-Tat and Huang, Shih-Wen and Bailey, Brian P.},
title = {Show Me the Money! An Analysis of Project Updates during Crowdfunding Campaigns},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557045},
doi = {10.1145/2556288.2557045},
abstract = {Hundreds of thousands of crowdfunding campaigns have been launched, but more than
half of them have failed. To better understand the factors affecting campaign outcomes,
this paper targets the content and usage patterns of project updates -- communications
intended to keep potential funders aware of a campaign's progress. We analyzed the
content and usage patterns of a large corpus of project updates on Kickstarter, one
of the largest crowdfunding platforms. Using semantic analysis techniques, we derived
a taxonomy of the types of project updates created during campaigns, and found discrepancies
between the design intent of a project update and the various uses in practice (e.g.
social promotion). The analysis also showed that specific uses of updates had stronger
associations with campaign success than the project's description. Design implications
were formulated from the results to help designers better support various uses of
updates in crowdfunding campaigns.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {591–600},
numpages = {10},
keywords = {updates, crowdfunding, crowdsouring},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557159,
author = {Bigham, Jeffrey P. and Lasecki, Walter S.},
title = {Crowd Storage: Storing Information on Existing Memories},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557159},
doi = {10.1145/2556288.2557159},
abstract = {This paper introduces the concept of crowd storage, the idea that digital files can
be stored and retrieved later from the memories of people in the crowd. Similar to
human memory, crowd storage is ephemeral, which means that storage is temporary and
the quality of the stored information degrades over time. Crowd storage may be preferred
over storing information directly in the cloud, or when it is desirable for information
to degrade inline with normal human memories. To explore and validate this idea, we
created WeStore, a system that stores and then later retrieves digital files in the
existing memories of crowd workers. WeStore does not store information directly, but
rather encrypts the files using details of the existing memories elicited from individuals
within the crowd as cryptographic keys. The fidelity of the retrieved information
is tied to how well the crowd remembers the details of the memories they provided.
We demonstrate that crowd storage is feasible using an existing crowd marketplace
(Amazon Mechanical Turk), explore design considerations important for building systems
that use crowd storage, and outline ideas for future research in this area.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {601–604},
numpages = {4},
keywords = {memory, crowdsourcing, storage},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250928,
author = {Takeuchi, Yuichiro},
title = {Session Details: Novel Approaches to Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250928},
doi = {10.1145/3250928},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557250,
author = {Hazzard, Adrian and Benford, Steve and Burnett, Gary},
title = {Walk This Way: Musically Guided Walking Experiences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557250},
doi = {10.1145/2556288.2557250},
abstract = {Musical soundtracks will be important features of future locative experiences from
tours to games. We present a study designed to uncover potential relationships between
higher-level musical structures such as harmony, melody, timbre, dynamic intensity
and punctuation and users' spatial experiences. We observed twenty-two participants
exploring an open field while listening to four contrasting musical compositions,
and then interviewed them afterwards. We report their different approaches to interpreting
the music, strategies for mapping zones, choice of stopping destinations, and their
awareness and appreciation of the music. Our discussion of these findings in relation
to the literature leads us to propose six initial principles to guide the composition
of mobile and locative soundtracks, and also to articulate a three-layer framework
of global, regional and local attachment to help guide the attachment of musical features
to different regions within a locative experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {605–614},
numpages = {10},
keywords = {music composition, attachment, design, conceptual metaphors, location based experiences},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557021,
author = {Heller, Florian and Kr\"{a}mer, Aaron and Borchers, Jan},
title = {Simplifying Orientation Measurement for Mobile Audio Augmented Reality Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557021},
doi = {10.1145/2556288.2557021},
abstract = {Audio augmented reality systems overlay the physical world with a virtual audio space.
Today's smartphones provide enough processing power to create the impression of virtual
sound sources being located in the real world. To achieve this, information about
the user's location and orientation is necessary which requires additional hardware.
In a real-world installation, however, we observed that instead of turning their head
to localize sounds, users tend to turn their entire body. Therefore, we suggest to
simply measure orientation of the user's body - or even just the mobile device she
is holding - to generate the spatial audio.To verify this approach, we present two
studies: Our first study in examines the user's head, body, and mobile device orientation
when moving through an audio augmented reality system in a lab setting. Our second
study analyzes the user experience in a real-world installation when using head, body,
or device orientation to control the audio spatialization. We found that when navigating
close to sound sources head tracking is necessary, but that it can potentially be
replaced by device tracking in larger or more explorative usage scenarios. These findings
help reduce the technical complexity of mobile audio augmented reality systems (MAARS),
and enable their wider dissemination as mobile software-only apps.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {615–624},
numpages = {10},
keywords = {binaural rendering, presence, mobile devices, audio augmented reality, spatial audio, orientation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557259,
author = {Fosh, Lesley and Benford, Steve and Reeves, Stuart and Koleva, Boriana},
title = {Gifting Personal Interpretations in Galleries},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557259},
doi = {10.1145/2556288.2557259},
abstract = {The designers of mobile guides for museums and galleries face three major challenges:
fostering rich interpretation, delivering deep personalization, and enabling a coherent
social visit. We propose an approach to tackling all three simultaneously by inviting
visitors to design an interpretation that is specifically tailored for a friend or
loved one that they then experience together. We describe a trial of this approach
at a contemporary art gallery, revealing how visitors designed personal and sometimes
provocative experiences for people they knew well. We reveal how pairs of visitors
negotiated these experiences together, showing how our approach could deliver intense
experiences for both, but also required them to manage social risk. By interpreting
our findings through the lens of 'gift giving' we shed new light on ongoing explorations
of interpretation, personalization and social visiting within HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {625–634},
numpages = {10},
keywords = {visiting, mobile guides, interpretation, collaboration, gifting, personalization, galleries, museums},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557270,
author = {Wein, Leonard},
title = {Visual Recognition in Museum Guide Apps: Do Visitors Want It?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557270},
doi = {10.1145/2556288.2557270},
abstract = {In this paper, visual recognition (VisRec) is evaluated as a method to access background
information on artworks in mobile museum guide applications (apps) by means of a field
experiment. While museums and previous research have explored technical aspects, it
is unclear whether visitors actually want to use VisRec. A prototype featuring VisRec,
QR codes and number codes was developed and assessed with a usability study in two
museums (N=89). The prototype confirms the efficacy of the recently introduced ORB-algorithm
for VisRec. Compared to previous literature, the results highlight the context-dependency
of perceived usability and variability in the importance of usability factors. The
results reveal a clear preference for VisRec among participants (53%); only 14% preferred
QR codes. Ease of use, enjoyability and distance are identified as the main factors.
This provides strong evidence to further explore the potential of VisRec to improve
visitors' museum experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {635–638},
numpages = {4},
keywords = {mobile applications, visual recognition, museum guide, access methods, usability test},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556994,
author = {Robinson, Simon and Pearson, Jennifer S. and Jones, Matt},
title = {A Billion Signposts: Repurposing Barcodes for Indoor Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556994},
doi = {10.1145/2556288.2556994},
abstract = {Barcodes are all around us--on books, groceries and other products--but these everyday
markers are typically used for a single focused purpose. In this paper we explore
the concept of "piggybacking" on ubiquitous markers to facilitate indoor navigation.
Our initial probe--BookMark--allows library visitors to scan any nearby book to provide
a custom map to the location of a desired item. In contrast to previous indoor navigation
systems, our approach repurposes existing markers on physical items that are already
in the navigation space, meaning that no additional infrastructure is required. We
evaluated the BookMark probe in a large university library, showing its potential
with real library users. In addition, we illustrate how the general technique shows
further potential in other similar barcode-rich environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {639–642},
numpages = {4},
keywords = {piggybacking, barcodes, libraries, indoor navigation, reuse},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250929,
author = {Kjeldskov, Jesper},
title = {Session Details: Interfaces for Care and Support},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250929},
doi = {10.1145/3250929},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557103,
author = {Matthews, Mark and Gay, Geri and Doherty, Gavin},
title = {Taking Part: Role-Play in the Design of Therapeutic Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557103},
doi = {10.1145/2556288.2557103},
abstract = {Gaining an understanding of user needs is a central component of HCI design approaches
such as user-centred design and participatory design. In some settings, such as mental
health care, access to end-users is often constrained. This is a particular difficulty
given that the experience of those with mental illness can be difficult for researchers
to understand, and is further complicated by its associated stigma. In addition, the
therapeutic setting is outside the common experience of most people and protected
from outside intrusion. Although role-play has been used in varied ways in HCI, rarely
has it been defined with sufficient clarity to enable others to deploy it in a nuanced
manner. We argue that role-play is particularly suited for use in mental healthcare
settings and, when used judiciously, can address some of the difficulties associated
with working in this setting. This paper details a range of role-play formats appropriated
from therapeutic role-play, drawing upon the HCI and mental health literature, therapist
input and our experience of using role-play for a number of purposes at different
stages of the development process. We consider how and why role-play can be used to
generate empathy, gain understanding of therapy, provide feedback on designs before
clinical use and help train therapists in using technology in the treatment room.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {643–652},
numpages = {10},
keywords = {healthcare, therapy, design, mental health, role-play},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557297,
author = {Adams, Phil and Baumer, Eric PS and Gay, Geri},
title = {Staccato Social Support in Mobile Health Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557297},
doi = {10.1145/2556288.2557297},
abstract = {Social support plays an important role in health systems. While significant work has
explored the role of social support in CMC environments, less analysis has considered
social support in mobile health systems. This paper describes socially supportive
messages in VERA, a mobile application for sharing health decisions and behaviors.
The short and bursty interactions in social awareness streams [36] afford a particular
style of social support, for which we offer the label staccato social support. Results
indicate that, in comparison to previous work, staccato social support is characterized
by a greater prevalence of esteem support, which builds respect and confidence. We
further note the presence of 'following up', a positive behavior that contributes
to supportive interactions, likely via social pressure and accountability [7,38].
These findings suggest design recommendations to developers of mobile social support
systems and contribute to understanding technologically mediated social support for
health.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {653–662},
numpages = {10},
keywords = {user experience, social support, mobile health},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557194,
author = {Jacobs, Maia L. and Clawson, James and Mynatt, Elizabeth D.},
title = {My Journey Compass: A Preliminary Investigation of a Mobile Tool for Cancer Patients},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557194},
doi = {10.1145/2556288.2557194},
abstract = {Health information management for cancer care is a challenging and personal process
that changes over time based on one's needs, goals, and health status. While technologies
supporting health information management appear promising, we do not fully understand
how health information tools fit into patients? daily lives. To better understand
the opportunities and usage barriers of these tools, we designed and deployed a mobile,
tablet-based health management aid: My Journey Compass. After one month of use, we
interviewed twelve breast cancer patients to investigate their initial patterns of
adoption, adaptation, use and non-use. We found that developing a tool that was customizable,
mobile, and integrated into the patients' healthcare system resulted in a set of surprising
uses by breast cancer patients for a wide variety of tasks. Our study demonstrates
the potential for health management tools to improve the cancer care experience and
for HCI research to influence existing healthcare systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {663–672},
numpages = {10},
keywords = {cancer navigation, breast cancer, mobile health},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557333,
author = {Threatt, Anthony L. and Merino, Jessica and Green, Keith Evan and Walker, Ian and Brooks, Johnell O. and Healy, Stan},
title = {An Assistive Robotic Table for Older and Post-Stroke Adults: Results from Participatory Design and Evaluation Activities with Clinical Staff},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557333},
doi = {10.1145/2556288.2557333},
abstract = {An inevitable new frontier for the CHI community is the development of complex, larger-scale,
cyber-physical artifacts where advancements in design, computing and robotics converge.
Presented here is a design exemplar: the Assistive, Robotic Table (ART), the key component
of our envisioned home suite of networked, robotic furnishings for hospitals and homes,
promoting wellbeing and independent living. We begin with the motivations for ART,
and present our iterative, five-phase, participatory design-and-evaluation process
involving clinicians at a rehabilitation hospital, focusing here on the final usability
study. From our wide-ranging design-research activities, which may be characterized
as research through design, we found ART to be promising but also challenging. As
a design exemplar, ART offers invaluable lessons to the CHI community as it comes
to design larger-scale, cyber-physical artifacts cultivating interactions across people
and their surroundings that define places of social, cultural and psychological significance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {673–682},
numpages = {10},
keywords = {eldercare, ethnography, human-robot interaction design, assistive robotics, design research, healthcare},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250930,
author = {Satchell, Christina},
title = {Session Details: Research through Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250930},
doi = {10.1145/3250930},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556960,
author = {Vines, John and Denman-Cleaver, Tess and Dunphy, Paul and Wright, Peter and Olivier, Patrick},
title = {Experience Design Theatre: Exploring the Role of Live Theatre in Scaffolding Design Dialogues},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556960},
doi = {10.1145/2556288.2556960},
abstract = {While theatre has been used in HCI as a tool for engaging participants in design processes,
the specific benefits of using live theatre over other communicative mediums, remains
underexplored. In this paper we introduce Experience Design Theatre (EDT) as an approach
to undertaking experience-centered design with multiple parties in the early stages
of design. EDT was motivated by a need to involve several diverse groups of people
in the design of a digitally coordinated care service - NetCarers. We used live theatre
as a way to engage small groups of participants in dialogues around the design of
NetCarers, to qualify their contributions in a refined performance, and to communicate
their concerns and aspirations to domain experts. We highlight key benefits to using
live theatre in experience-centered design and offer insights for researchers undertaking
similar work in the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {683–692},
numpages = {10},
keywords = {intergenerational, experience-centered design, care, theatre, ageing, older people},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557222,
author = {Seok, Jin-min and Woo, Jong-bum and Lim, Youn-kyung},
title = {Non-Finito Products: A New Design Space of User Creativity for Personal User Experience},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557222},
doi = {10.1145/2556288.2557222},
abstract = {Conventional wisdom says that to be successful, an idea must be concrete, complete,
and certain. However, what if unfinished ideas work? This CHI paper proposes a new
design space we call non-finito products for the HCI community. This new design space
is about intentionally unfinished products and how they foster new creations by end-users
as they are actually used to help people solve their own problems. The central idea
comes from the background of the growing complexity associated with IT advancement
and from the new way of dealing with it, with the assistance of user creativity in
the actual use of the products. This paper begins with the exploration of non-finito
products as a new design space for the end-user's creativity in the personal user
experience. We then defined and proposed non-finito products. We discussed three case
studies that will help to understand the design space of non-finito products, and
we framed the new design space by revealing the beneficial contexts and values. Finally,
we suggested the implications of designing non-finito products. We believe that non-finito
products will open a new design space in HCI, prompt a new means of replacing value-destroying
complexity with value-creating version, and help to make a product better fit to user
experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {693–702},
numpages = {10},
keywords = {non-finito product, user experience, design perspective, unfinished product, user creativity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557098,
author = {Blythe, Mark},
title = {Research through Design Fiction: Narrative in Real and Imaginary Abstracts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557098},
doi = {10.1145/2556288.2557098},
abstract = {This paper reflects on the uses of prototypes in "Research through Design" and considers
"Design Fiction" as a technique for exploring the potential value of new design work.
It begins with an analysis of Research through Design abstracts in the ACM digital
library and identifies an emerging language and structure of papers in this emerging
field. The abstracts: frame a problem space, introduce a study, often involving the
deployment of a prototype, and conclude with considerations, reflections and discussion.
This format is then pastiched in a series of design fictions written for a project
investigating new and emerging forms of reproduction in Art. The fictions take the
form of "imaginary abstracts" which summarize findings of papers that have not been
written about prototypes that do not exist. It is argued that framing concept designs
as fictional studies can provide a space for research focused critique and development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {703–712},
numpages = {10},
keywords = {research through design, design fiction, prototypes},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557261,
author = {Dachtera, Juri and Randall, Dave and Wulf, Volker},
title = {Research on Research: Design Research at the Margins: Academia, Industry and End-Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557261},
doi = {10.1145/2556288.2557261},
abstract = {Design research processes often take place in publicly funded projects. Besides designers
and users, public funding increasingly requires industry partners to participate in
such projects. We present empirical insights from a joint research project in order
to assess the claims connected with such funding structures and to report on challenges
for design research within them. We identify three themes of conflict between academic
and industry partners and elaborate on the sources of them. The presentation of our
results builds on the distinction between 'academia' and 'industry', which is frequently
applied by political funding agencies. The analysis of the respective stakeholders'
actual interests, however, will prove such a dichotomy to be misleading and simplistic.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {713–722},
numpages = {10},
keywords = {design research, joint research, mode2-research},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250931,
author = {Irani, Pourang},
title = {Session Details: Pointing and Cursors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250931},
doi = {10.1145/3250931},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556997,
author = {Gilliot, J\'{e}r\'{e}mie and Casiez, G\'{e}ry and Roussel, Nicolas},
title = {Impact of Form Factors and Input Conditions on Absolute Indirect-Touch Pointing Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556997},
doi = {10.1145/2556288.2556997},
abstract = {Absolute indirect interaction maps the absolute position of a device's end-effector
to the absolute position of a remote on-screen object.Despite its long-time use with
graphics tablets and growing use in research prototypes, little is known on the influence
of form factors and input conditions on pointing performance with such a mapping.
The input and display can have different sizes and aspect ratios, for example. The
on-screen targets can vary in size. Users can look solely at the display or at the
input device as well. They can also hold the input device in certain cases, or let
it rest on a table. This paper reports on two experiments designed to investigate
the influence of all these factors on absolute indirect-touch pointing performance.
We also provide design guidelines for interaction in these situations based on the
observed impacting factors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {723–732},
numpages = {10},
keywords = {performance, absolute pointing, form factors, input conditions, indirect touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557410,
author = {Mott, Martez E. and Wobbrock, Jacob O.},
title = {Beating the Bubble: Using Kinematic Triggering in the Bubble Lens for Acquiring Small, Dense Targets},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557410},
doi = {10.1145/2556288.2557410},
abstract = {We present the Bubble Lens, a new target acquisition technique that remedies the limitations
of the Bubble Cursor to increase the speed and accuracy of acquiring small, dense
targets--precisely those targets for which the Bubble Cursor degenerates to a point
cursor. When targets are large and sparse, the Bubble Lens behaves like the Bubble
Cursor. But when targets are small and dense, the Bubble Lens automatically magnifies
nearby targets, making them larger in both visual- and motor-space. Importantly, magnification
is not governed by an explicit user-invoked mode-switch. Rather, magnification is
activated through kinematic triggering, a technique that continuously examines an
unfolding velocity profile to automatically trigger mode changes based on observed
features. In a first study, we found the Bubble Cursor performed poorly when targets
had an effective size smaller than 10 pixels. Using this threshold for the Bubble
Lens in a second study, we found that the Bubble Lens significantly outperformed the
Bubble Cursor, decreasing movement time by 10.2% and error rates by 37.9%, making
the Bubble Lens the fastest current pointing technique.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {733–742},
numpages = {10},
keywords = {bubble cursor, lensing, target acquisition, pointing techniques, pointing facilitation, mouse pointing, zooming, kinematics, magnification},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557406,
author = {Pasqual, Phillip T. and Wobbrock, Jacob O.},
title = {Mouse Pointing Endpoint Prediction Using Kinematic Template Matching},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557406},
doi = {10.1145/2556288.2557406},
abstract = {We present a new method of predicting the endpoints of mouse movements. While prior
approaches to endpoint prediction have relied upon normative kinematic laws, regression,
or control theory, our approach is straightforward but kinematically rich. Our key
insight is to regard the unfolding velocity profile of a pointing movement as a 2-D
stroke gesture and to use template matching to predict the endpoint based on prior
observed movements. We call our technique kinematic template matching (KTM), which
is simple to implement, user-adaptable, and kinematically expressive. In a study of
17 able-bodied participants evaluated over movement amplitudes ranging from 100-800
pixels, we found KTM to predict endpoints that were within 83 pixels of the true endpoint
at 50% of the way through the movement, within 48 pixels at 75%, and within 39 pixels
at 90%, using 1000 templates per participant. These accuracies make KTM as successful
an approach to endpoint prediction as any prior technique, while being easier to implement
and understand than most.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {743–752},
numpages = {10},
keywords = {mouse pointing, target prediction, endpoint prediction, template matching, kinematics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557095,
author = {Su, Xiaojun and Au, Oscar Kin-Chung and Lau, Rynson W.H.},
title = {The Implicit Fan Cursor: A Velocity Dependent Area Cursor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557095},
doi = {10.1145/2556288.2557095},
abstract = {We present the Implicit Fan Cursor (IFC) - a novel target pointing technique using
a cursor with a fan-shape activation area. The IFC couples the cursor's activation
area with its velocity, i.e., the speed and direction of the mouse motion, behaving
like a 2D spotlight cursor at low speed and a circular area cursor at high speed.
Thus, it enables the user to precisely acquire distant targets at low speed and easily
acquire nearest targets at high speed, without explicit mode switching. This technique
minimizes cursor movement, while taking into consideration of the precision of cursor
movement at different speeds. It also ensures that only one target is captured at
any time. The results of our controlled experiments show that the IFC outperforms
the point cursor and the area cursor techniques, particularly in terms of cursor moving
distance, and that its performance can be accurately modeled using the Fitts' law.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {753–762},
numpages = {10},
keywords = {implicit fan cursor, fitts' law, velocity-aware pointing, area cursor},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250932,
author = {Yarosh, Svetlana},
title = {Session Details: Always Connected: Email and Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250932},
doi = {10.1145/3250932},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557381,
author = {Mazmanian, Melissa and Erickson, Ingrid},
title = {The Product of Availability: Understanding the Economic Underpinnings of Constant Connectivity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557381},
doi = {10.1145/2556288.2557381},
abstract = {Constant connectivity and total availability to clients is the rule rather than the
exception in many contemporary workplaces. Enabled by developments in information
and communication technologies (ICTs), total availability of employees is possible
and presumed. Scholars have explored how new technological affordances, cultural shifts,
individual personality traits, and/or the development of social expectations that
reinforce norms of constant connectivity have led to this state of affairs. We argue
that a key factor has been overlooked in current scholarship about stress, intensive
work, and constant connectivity. That is, current economic conditions are creating
a marketplace in which firms increasing sell the availability of their employees as
part of the services offered by the firm. In this paper we use qualitative data to
illustrate how total availability is an integral aspect of the 'product' offered by
professional service firms and is becoming increasingly prevalent in other service
industries. We conclude with a discussion of how the HCI community might address this
situation as a design challenge. Drawing on the work of Goffman and Perlow, we suggest
that designers attend to the ways in which organizations might maintain front stage
impressions of total availability while collectively managing individual time to restrict
total availability behind the scenes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {763–772},
numpages = {10},
keywords = {time and temporality, markets of availability, service work, knowledge work, economic constraints, mobile technology},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556983,
author = {Schoenebeck, Sarita Yardi},
title = {Giving up Twitter for Lent: How and Why We Take Breaks from Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556983},
doi = {10.1145/2556288.2556983},
abstract = {Social media use is widespread, but many people worry about overuse. This paper explores
how and why people take breaks from social media. Using a mixed methods approach,
we pair data from users who tweeted about giving up Twitter for Lent with an interview
study of social media users. We find that 64% of users who proclaim that they are
giving up Twitter for Lent successfully do so. Among those who fail, 31% acknowledge
their failure; the other 69% simply return. We observe hedging patterns (e.g. "I thought
about giving up Twitter for Lent but"?) that surfaced uncertainty about social media
behavior. Interview participants were concerned about the tradeoffs of spending time
on social media versus doing other things and of spending time on social media rather
than in "real life." We discuss gaps in related theory that might help reduce users'
anxieties and open design problems related to designing systems and services that
can help users manage their own social media use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {773–782},
numpages = {10},
keywords = {willpower, breaks, Twitter, media refusal, internet, social media, self-control},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557182,
author = {Rector, Kyle and Hailpern, Joshua},
title = {MinEMail: SMS Alert System for Managing Critical Emails},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557182},
doi = {10.1145/2556288.2557182},
abstract = {Email is the primary method of digital communication for most people, but the overwhelming
quantity has led to a poverty of attention. Existing manual and automatic solutions
that aim to save important emails from falling through the cracks have begun to address
this problem, but may increase user workload, sacrifice efficiency, or fail to identify
high value communications. In response, we developed MinEMail, an alert system that
uses a text message (SMS) to remind and notify users of critical emails that may have
been missed or forgotten. MinEMail provides an alert infrastructure as well as accurately
labeling and predicting which emails are critical, and when and how they need to be
addressed. To motivate our system, we also present an up-front study with 777 participants
that aims to understand the state and limitations of email and SMS in enterprise.
We conduct an experience sampling study of over 3000 emails in order to construct
MinEMail's predictive models. Finally, we present the results from a 15 user ecologically
valid real-world deployment of MinEMail in enterprise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {783–792},
numpages = {10},
keywords = {email, personal information management, information overload, sms},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557013,
author = {Grevet, Catherine and Choi, David and Kumar, Debra and Gilbert, Eric},
title = {Overload is Overloaded: Email in the Age of Gmail},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557013},
doi = {10.1145/2556288.2557013},
abstract = {The term email overload has two definitions: receiving a large volume of incoming
email, and having emails of different status types (to do, to read, etc). Whittaker
and Sidner proposed the latter definition in 1996, noticing that email inboxes were
far more complex than simply containing incoming messages. Sixteen years after Whittaker
and Sidner, we replicate and extend their work with a qualitative analysis of Google's
Gmail. We find that email overload, both in terms of volume and of status, is still
a problem today. Our contributions are 1) updating the state of email overload, 2)
extending our understanding of overload in the context of Gmail and 3) comparing personal
with work email accounts: while work email tends to be status overloaded, personal
email is also type overloaded. These comparisons between work and personal email suggest
new avenues for email research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {793–802},
numpages = {10},
keywords = {work and personal email, qualitative study, organization, email overload, management strategies},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250933,
author = {Wakkary, Ron},
title = {Session Details: Smart Homes and Sustainability},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250933},
doi = {10.1145/3250933},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557420,
author = {Ur, Blase and McManus, Elyse and Pak Yong Ho, Melwyn and Littman, Michael L.},
title = {Practical Trigger-Action Programming in the Smart Home},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557420},
doi = {10.1145/2556288.2557420},
abstract = {We investigate the practicality of letting average users customize smart-home devices
using trigger-action ("if, then") programming. We find trigger-action programming
can express most desired behaviors submitted by participants in an online study. We
identify a class of triggers requiring machine learning that has received little attention.
We evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com,
finding that real users have written a large number of unique trigger-action interactions.
Finally, we conduct a 226-participant usability test of trigger-action programming,
finding that inexperienced users can quickly learn to create programs containing multiple
triggers or actions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {803–812},
numpages = {10},
keywords = {home automation, condition-action programming, internet of things, smart home, end-user programming},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557167,
author = {Costanza, Enrico and Fischer, Joel E. and Colley, James A. and Rodden, Tom and Ramchurn, Sarvapali D. and Jennings, Nicholas R.},
title = {Doing the Laundry with Agents: A Field Trial of a Future Smart Energy System in the Home},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557167},
doi = {10.1145/2556288.2557167},
abstract = {Future energy systems that rely on renewable energy may bring about a radical shift
in how we use energy in our homes. We developed and prototyped a future scenario with
highly variable, real-time electricity prices due to a grid that mainly relies on
renewables. We designed and deployed an agent-based interactive system that enables
users to effectively operate the washing machine in this scenario. The system is used
to book timeslots of washing machine use so that the agent can help to minimize the
cost of a wash by charging a battery at times when electricity is cheap. We carried
out a deployment in 10 households in order to uncover the socio-technical challenges
around integrating new technologies into everyday routines. The findings reveal tensions
that arise when deploying a rationalistic system to manage contingently and socially
organized domestic practices. We discuss the trade-offs between utility and convenience
inherent in smart grid applications; and illustrate how certain design choices position
applications along this spectrum.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {813–822},
numpages = {10},
keywords = {autonomous agents, demand response, energy, field trial, real-time pricing, smart grid},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557380,
author = {Yang, Rayoung and Newman, Mark W. and Forlizzi, Jodi},
title = {Making Sustainability Sustainable: Challenges in the Design of Eco-Interaction Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557380},
doi = {10.1145/2556288.2557380},
abstract = {The smart home is here. One area where smart home devices promise to deliver great
benefits is in the control of home heating, ventilation, and cooling (HVAC) systems.
In this paper, we seek to inform the design of future heating and cooling systems
by investigating users' experiences with the Nest Learning Thermostat, a commercially
available smart home device. We conducted a qualitative study where we compared people's
interactions with conventional thermostats with interactions with the Nest. A key
finding was that the Nest impacted users' pattern of HVAC control, but only for a
while, and caused new problems in unrealized energy savings. In leveraging these findings,
we create a set of design implications for Eco-Interaction, the design of features
and human-system interactions with the goal of saving energy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {823–832},
numpages = {10},
keywords = {thermostat, eco-interaction, sustainability, smart home},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250934,
author = {Wang, Hao-Chuan},
title = {Session Details: Multilingual Communication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250934},
doi = {10.1145/3250934},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557203,
author = {Hale, Scott A.},
title = {Global Connectivity and Multilinguals in the Twitter Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557203},
doi = {10.1145/2556288.2557203},
abstract = {This article analyzes the global connectivity of the Twitter retweet and mentions
network and the role of multilingual users engaging with content in multiple languages.
The network is heavily structured by language with most mentions and retweets directed
to users writing in the same language. Users writing in multiple languages are more
active, authoring more tweets than monolingual users. These multilingual users play
an important bridging role in the global connectivity of the network. The mean level
of insularity from speakers in each language does not correlate straightforwardly
with the size of the user base as predicted by previous research. Finally, the English
language does play more of a bridging role than other languages, but the role played
collectively by multilingual users across different languages is the largest bridging
force in the network.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {833–842},
numpages = {10},
keywords = {information diffusion, cross-language, social network analysis, social media, multilingual, micro-blogs, information discovery},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557303,
author = {Gao, Ge and Yamashita, Naomi and Hautasaari, Ari MJ and Echenique, Andy and Fussell, Susan R.},
title = {Effects of Public vs. Private Automated Transcripts on Multiparty Communication between Native and Non-Native English Speakers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557303},
doi = {10.1145/2556288.2557303},
abstract = {Real-time transcripts generated by automated speech recognition (ASR) technologies
have the potential to facilitate communication between native speakers (NS) and non-native
speakers (NNS). Previous studies of ASR have focused on how transcripts aid NNS speech
comprehension. In this study, we examine whether transcripts benefit multiparty real-time
conversation between NS and NNS. We hypothesized that ASR transcripts would be more
beneficial when the transcripts were publicly shared by all group members as opposed
to when they were seen only by the NNS. To test our hypothesis, we conducted a lab
experiment in which 14 groups of native and non-native speakers engaged in a story-telling
task. Half of the groups received private transcripts that were available only to
the NNS; the other half received publicly shared transcripts that were available to
all group members. NS spoke more clearly, and both NS and NNS rated the quality of
communication higher, when transcripts were publicly shared. These findings inform
the design of future tools to support multilingual group communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {843–852},
numpages = {10},
keywords = {multilingual communication, automated speech recognition, real-time transcripts},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557256,
author = {Kovacs, Geza and Miller, Robert C.},
title = {Smart Subtitles for Vocabulary Learning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557256},
doi = {10.1145/2556288.2557256},
abstract = {Language learners often use subtitled videos to help them learn. However, standard
subtitles are geared more towards comprehension than vocabulary learning, as translations
are nonliteral and are provided only for phrases, not vocabulary. This paper presents
Smart Subtitles, which are interactive subtitles tailored towards vocabulary learning.
Smart Subtitles can be automatically generated from common video sources such as subtitled
DVDs. They provide features such as vocabulary definitions on hover, and dialog-based
video navigation. In our pilot study with intermediate learners studying Chinese,
participants correctly defined over twice as many new words in a post-viewing vocabulary
test when they used Smart Subtitles, compared to dual Chinese-English subtitles. Learners
spent the same amount of time watching clips with each tool, and enjoyed viewing videos
with Smart Subtitles as much as with dual subtitles. Learners understood videos equally
well using either tool, as indicated by self-assessments and independent evaluations
of their summaries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {853–862},
numpages = {10},
keywords = {subtitles, language learning, interactive videos},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557209,
author = {Li, Na and Rosson, Mary Beth},
title = {Using Annotations in Online Group Chats},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557209},
doi = {10.1145/2556288.2557209},
abstract = {Annotating documents has long been a widely used strategy for distilling important
contents and externalizing related thoughts and ideas in context. No one has studied
the activity of annotating dynamic texts, such as online chat, although online conversation
is an important communication media for global companies. In this paper, we investigate
Instant Annotation (IA), a real-time annotation-enhanced chat tool. We contrast the
use of the enhanced chat tool to a standard chat tool for multilingual groups doing
a brainstorming and decision-making task. Results show that group satisfaction and
perceived control of the conversation are enhanced for the participants who used IA.
We also report new patterns of annotation use and discuss design implications for
group chat tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {863–866},
numpages = {4},
keywords = {evaluation, instant annotation, conversation control, design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250935,
author = {Adar, Eytan},
title = {Session Details: Interactive Visualization and Visual Elements},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250935},
doi = {10.1145/3250935},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557010,
author = {Bach, Benjamin and Pietriga, Emmanuel and Fekete, Jean-Daniel},
title = {Visualizing Dynamic Networks with Matrix Cubes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557010},
doi = {10.1145/2556288.2557010},
abstract = {Designing visualizations of dynamic networks is challenging, both because the data
sets tend to be complex and because the tasks associated with them are often cognitively
demand- ing. We introduce the Matrix Cube, a novel visual representation and navigation
model for dynamic networks, inspired by the way people comprehend and manipulate physical
cubes. Users can change their perspective on the data by rotating or decomposing the
3D cube. These manipulations can produce a range of different 2D visualizations that
emphasize specific aspects of the dynamic network suited to particular analysis tasks.
We describe Matrix Cubes and the interactions that can be performed on them in the
Cubix system. We then show how two domain experts, an astronomer and a neurologist,
used Cubix to explore and report on their own network data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {877–886},
numpages = {10},
keywords = {interaction, dynamic networks, metaphors, information visualization, multiple views},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557379,
author = {Perin, Charles and Vuillemot, Romain and Fekete, Jean-Daniel},
title = {A Table! Improving Temporal Navigation in Soccer Ranking Tables},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557379},
doi = {10.1145/2556288.2557379},
abstract = {This article introduces A Table!, an enhanced soccer ranking table providing temporal
navigation by combining two novel interaction techniques. Ranking tables order soccer
teams represented as rows, according to values of columns containing attributes e.g.,
accumulated points, or number of scored goals. Because they represent a snapshot of
a championship at a time t, tables are regularly updated with new results. Such updates
usually change the rows order, which makes the tracking of a specified team over time
difficult. We observed that the tables available on the web do not support tracking
such changes very well, are generally hard to read, and lack interactions. This contrasts
with the extensive use of comments on temporal trends found in soccer analysts articles.
To better support such analyzes, the two interactive techniques presented allow exploration
of time, and are designed to preserve users' flow: DRAG-CELL is based on direct manipulation
of values to browse ranks; VIZ-RANK uses a transient line chart of team ranks to visually
explore a championship. An on-line evaluation with 143 participants shows that each
technique efficiently supports a set of important temporal tasks not supported by
current ranking tables. This paves the way for introducing efficient advanced visual
exploration techniques to millions of soccer enthusiasts who use tables everyday.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {887–896},
numpages = {10},
keywords = {soccer, visualization, ranking tables, temporal navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557231,
author = {Rzeszotarski, Jeffrey M. and Kittur, Aniket},
title = {Kinetica: Naturalistic Multi-Touch Data Visualization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557231},
doi = {10.1145/2556288.2557231},
abstract = {Over the last several years there has been an explosion of powerful, affordable, multi-touch
devices. This provides an outstanding opportunity for novel data visualization techniques
that leverage new interaction methods and minimize their barriers to entry. In this
paper we describe an approach for multivariate data visualization that uses physics-based
affordances that are easy to intuit, constraints that are easy to apply and visualize,
and a consistent view as data is manipulated in order to promote data exploration
and interrogation. We provide a framework for exploring this problem space, and an
example proof of concept system called Kinetica. We describe the results of a user
study that suggest users of Kinetica were able to explore multiple dimensions of data
at once, identify outliers, and discover trends with minimal training.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {897–906},
numpages = {10},
keywords = {multivariate data, physics, visualization, multi-touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557224,
author = {Hong, Sungsoo (Ray) and Kim, Yea-Seul and Yoon, Jong-Chul and Aragon, Cecilia R.},
title = {Traffigram: Distortion for Clarification via Isochronal Cartography},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557224},
doi = {10.1145/2556288.2557224},
abstract = {Most geographic maps visually represent physical distance; however, travel time can
in some cases be more important than distance because it directly indicates availability.
The technique of creating maps from temporal data is known as isochronal cartography,
and is a form of distortion for clarification. In an isochronal map, congestion expands
areas, while ideal travel conditions make the map shrink in comparison to the actual
distance scale of a traditional map. Although there have been many applications of
this technique, detailed user studies of its efficacy remain scarce, and there are
conflicting views on its practical value. To attempt to settle this issue, we utilized
a user-centered design process to determine which features of isochronal cartography
might be most usable in practice. We developed an interactive cartographic visualization
system, Traffigram, that features a novel combination of efficient isochronal map
algorithms and an interface designed to give map users a quick and seamless experience
while preserving geospatial integrity and aesthetics. We validated our design choices
with multiple usability studies. We present our results and discuss implications for
design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {907–916},
numpages = {10},
keywords = {information visualization, map user interface, time-space map, geographic visualization, map usage, isochrones},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250936,
author = {Nacke, Lennart},
title = {Session Details: Understanding and Designing Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250936},
doi = {10.1145/3250936},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557341,
author = {Smith, Gillian},
title = {Understanding Procedural Content Generation: A Design-Centric Analysis of the Role of PCG in Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557341},
doi = {10.1145/2556288.2557341},
abstract = {Games that use procedural content generation (PCG) do so in a wide variety of ways
and for different reasons. One of the most common reasons cited by PCG system creators
and game designers is improving replayability by providing a means for automatically
creating near-infinite amounts of content, the player can come back and replay the
game and refine her strategies over a long period. However, this notion of replayability
is both overly broad and incomplete as a motivation. This paper contributes an analytical
framework and associated common vocabulary for understanding the role of PCG in games
from a design standpoint, with an aim of unpacking some of the broad justifications
for PCG use in games, and bringing together technical concerns in designing PCG systems
with design concerns related to creating engaging playable experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {917–926},
numpages = {10},
keywords = {game ai, mda framework, game design, procedural content generation, game design theory.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557078,
author = {Mekler, Elisa D. and Bopp, Julia Ayumi and Tuch, Alexandre N. and Opwis, Klaus},
title = {A Systematic Review of Quantitative Studies on the Enjoyment of Digital Entertainment Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557078},
doi = {10.1145/2556288.2557078},
abstract = {Enjoyment has been identified as a central component of the player experience (PX),
but various, overlapping concepts within PX make it difficult to develop valid measures
and a common understanding of game enjoyment. We conducted a systematic review of
87 quantitative studies, analyzing different operationalizations and measures of game
enjoyment, its determinants, and how these were related to other components of PX,
such as flow, presence and immersion. Results suggest that game enjoyment describes
the positive cognitive and affective appraisal of the game experience, and may in
part be associated with the support of player needs and values. Further, we outline
that enjoyment is distinct from flow in that it may occur independently of challenge
and cognitive involvement, and argue that enjoyment may be understood as the valence
of the player experience. We conclude with a discussion of methodological challenges
and point out opportunities for future research on game enjoyment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {927–936},
numpages = {10},
keywords = {enjoyment, digital games, player experience, flow},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557308,
author = {Vicencio-Moreira, Rodrigo and Mandryk, Regan L. and Gutwin, Carl and Bateman, Scott},
title = {The Effectiveness (or Lack Thereof) of Aim-Assist Techniques in First-Person Shooter Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557308},
doi = {10.1145/2556288.2557308},
abstract = {Aim-assistance techniques have been shown to work for player balancing in 2D environments,
but little information exists about how well these techniques will work in a 3D FPS
game. We carried out three studies of the performance of five different aim assists
in an Unreal-based game world. The assists worked well in a target-range scenario
(study 1), but their performance was reduced when game elements were introduced in
a walkthrough map (study 2). We systematically examined the relationships between
realistic game elements and assist performance (study 3). These studies show that
two techniques -- bullet magnetism and area cursor -- worked well in a wide variety
of situations. Other techniques that worked well were too perceptible, and some previously-successful
techniques did not work well in any game-like scenario. Our studies are the first
to provide empirical evidence of the performance of aim assist techniques in 3D environments,
and the first to identify the complexities in using these techniques in real FPS games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {937–946},
numpages = {10},
keywords = {first-person shooter games, game balancing, aim assistance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557245,
author = {Bonsignore, Elizabeth and Moulder, Vicki and Neustaedter, Carman and Hansen, Derek and Kraus, Kari and Druin, Allison},
title = {Design Tactics for Authentic Interactive Fiction: Insights from Alternate Reality Game Designers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557245},
doi = {10.1145/2556288.2557245},
abstract = {This paper presents insights from designers of Alternate Reality Games (ARGs) regarding
the design tactics they employ to integrate participatory storytelling and "authentic
fiction" into the transmedia experiences they create. Our approach was motivated by
recent efforts in HCI to more closely align the development of interaction design
theory to the craft knowledge and experiences of designers themselves. The resulting
insights enhance our understanding of design approaches that a diverse group of ARG
producers follow to create interactive, participatory narratives. We outline narrative-specific
themes to support designers who craft similar interactive experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {947–950},
numpages = {4},
keywords = {narrative design, alternate reality games, transmedia},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557107,
author = {Silpasuwanchai, Chaklam and Ren, Xiangshi},
title = {Jump and Shoot! Prioritizing Primary and Alternative Body Gestures for Intense Gameplay},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557107},
doi = {10.1145/2556288.2557107},
abstract = {Motion gestures enable natural and intuitive input in video games. However, game gestures
designed by developers may not always be the optimal gestures for players. A key challenge
in designing appropriate game gestures lies in the interaction-intensive nature of
video games, i.e., several actions/commands may need to be executed concurrently using
different body parts. This study analyzes user preferences in game gestures, with
the aim of accommodating high interactivity during gameplay. Two user-elicitation
studies were conducted: first, to determine user preferences, participants were asked
to define gestures for common game actions/commands; second, to develop effective
combined-gestures, participants were asked to define possible game gestures using
each body part (one and two hands, one and two legs, head, eyes, and torso). Our study
presents a set of suitable and alternative body parts for common game actions/commands.
We also present some simultaneously applied game gestures that assist interaction
in highly interactive game situations (e.g., selecting a weapon with the feet while
shooting with the hand). Interesting design implications are further discussed, e.g.,
transferability between hand and leg gestures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {951–954},
numpages = {4},
keywords = {user-defined approach, games, interactivity, motion gestures, concurrent gestures},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250937,
author = {Reinecke, Katharina},
title = {Session Details: Personal Values and Preferences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250937},
doi = {10.1145/3250937},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557398,
author = {Gou, Liang and Zhou, Michelle X. and Yang, Huahai},
title = {KnowMe and ShareMe: Understanding Automatically Discovered Personality Traits from Social Media and User Sharing Preferences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557398},
doi = {10.1145/2556288.2557398},
abstract = {There is much recent work on using the digital footprints left by people on social
media to predict personal traits and gain a deeper understanding of individuals. Due
to the veracity of social media, imperfections in prediction algorithms, and the sensitive
nature of one's personal traits, much research is still needed to better understand
the effectiveness of this line of work, including users' preferences of sharing their
computationally derived traits. In this paper, we report a two- part study involving
256 participants, which (1) examines the feasibility and effectiveness of automatically
deriving three types of personality traits from Twitter, including Big 5 personality,
basic human values, and fundamental needs, and (2) investigates users' opinions of
using and sharing these traits. Our findings show there is a potential feasibility
of automatically deriving one's personality traits from social media with various
factors impacting the accuracy of models. The results also indicate over 61.5% users
are willing to share their derived traits in the workplace and that a number of factors
significantly influence their sharing preferences. Since our findings demonstrate
the feasibility of automatically inferring a user's personal traits from social media,
we discuss their implications for designing a new generation of privacy-preserving,
hyper-personalized systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {955–964},
numpages = {10},
keywords = {social media, basic values, big 5 personality, fundamental needs, personality traits, privacy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557403,
author = {Bakhshi, Saeideh and Shamma, David A. and Gilbert, Eric},
title = {Faces Engage Us: Photos with Faces Attract More Likes and Comments on Instagram},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557403},
doi = {10.1145/2556288.2557403},
abstract = {Photos are becoming prominent means of communication online. Despite photos' pervasive
presence in social media and online world, we know little about how people interact
and engage with their content. Understanding how photo content might signify engagement,
can impact both science and design, influencing production and distribution. One common
type of photo content that is shared on social media, is the photos of people. From
studies of offline behavior, we know that human faces are powerful channels of non-verbal
communication. In this paper, we study this behavioral phenomena online. We ask how
presence of a face, it's age and gender might impact social engagement on the photo.
We use a corpus of 1 million Instagram images and organize our study around two social
engagement feedback factors, likes and comments. Our results show that photos with
faces are 38% more likely to receive likes and 32% more likely to receive comments,
even after controlling for social network reach and activity. We find, however, that
the number of faces, their age and gender do not have an effect. This work presents
the first results on how photos with human faces relate to engagement on large scale
image sharing communities. In addition to contributing to the research around online
user behavior, our findings offer a new line of future work using visual analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {965–974},
numpages = {10},
keywords = {gender, content, demographics, image, mobile, image sharing community, photo, instagram, engagement, social media, age, face detection, faces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557247,
author = {Kim, Auk and Gweon, Gahgene},
title = {Photo Sharing of the Subject, by the Owner, for the Viewer: Examining the Subject's Preference},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557247},
doi = {10.1145/2556288.2557247},
abstract = {Photo sharing activities on social networking sites concern not only the person sharing
the information (owner) and the person receiving the information (viewer) but also
the person who is in the photo (subject). In our exploratory lab study, we asked 29
participants about their comfort level in allowing a photo owner to share a picture
containing both the participant (subject) and the owner. Our results show that the
photo subject feels more comfortable in sharing a photo when i) the "closeness between
the subject and the owner (SO closeness)" is higher, and ii) the "closeness between
the subject and the viewer (SV closeness)" is higher. In addition, we observed that
both SV and SO closeness are important in determining the subject's picture sharing
preference level.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {975–978},
numpages = {4},
keywords = {closeness, information sharing preference},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557285,
author = {Figueiredo, Flavio and Almeida, Jussara M. and Benevenuto, Fabr\'{\i}cio and Gummadi, Krishna P.},
title = {Does Content Determine Information Popularity in Social Media? A Case Study of Youtube Videos' Content and Their Popularity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557285},
doi = {10.1145/2556288.2557285},
abstract = {We here investigate what drives the popularity of information on social media platforms.
Focusing on YouTube, we seek to understand the extent to which content by itself determines
a video's popularity. Using mechanical turk as experimental platform, we asked users
to evaluate pairs of videos, and compared users' relative perception of the videos'
content against their relative popularity reported by YouTube. We found that in most
evaluations users could not reach consensus on which video had better content as their
perceptions tend to be very subjective. Nevertheless, when consensus was reached,
the video with preferred content almost always achieved greater popularity on YouTube,
highlighting the importance of content in driving information popularity on social
media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {979–982},
numpages = {4},
keywords = {content popularity, user study, social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556995,
author = {Hsieh, Gary and Chen, Jilin and Mahmud, Jalal U. and Nichols, Jeffrey},
title = {You Read What You Value: Understanding Personal Values and Reading Interests},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556995},
doi = {10.1145/2556288.2556995},
abstract = {This paper presents an experiment on the relationship between personal values and
reading interests of online articles. Results suggest that individuals' values can
predict their topical interests. For example, holding stronger universalism values
predict interests towards environmental articles, whereas holding stronger achievement
values predict interest towards work-related articles. Findings demonstrate the possibility
of targeting based on individuals' personal values, but also highlight certain challenges
and limitations when applying this approach for online content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {983–986},
numpages = {4},
keywords = {reading interest, twitter, content targeting, personal values},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557179,
author = {O'Kane, Aisling Ann and Rogers, Yvonne and Blandford, Ann E.},
title = {Gaining Empathy for Non-Routine Mobile Device Use through Autoethnography},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557179},
doi = {10.1145/2556288.2557179},
abstract = {In this paper, we report on autoethnography as a method to access non-routine usage
of mobile devices, such as during business trips, vacations, etc. Autoethnography,
a self-study method with the researcher as participant, was employed for the evaluation
of a wrist blood pressure monitor used by people with conditions such as hypertension.
The findings from the study were surprising, especially with respect to the environmental
and social impact on the use of the technology. Although the autoethnographic method
can be disruptive for the researcher, it enables them to understand and empathize
with the experiences mobile device users can face in difficult to access contexts.
This method allows HCI researchers to better understand user experiences with mobile
devices, including mobile medical technology, especially during non-routine times
that can be difficult to study in-situ with traditional user studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {987–990},
numpages = {4},
keywords = {empathy, autoethnography, mobile, healthcare., context},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250938,
author = {O'Malley, Claire},
title = {Session Details: Enabling Interactive Performances},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250938},
doi = {10.1145/3250938},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557251,
author = {Silang Maranan, Diego and Fdili Alaoui, Sarah and Schiphorst, Thecla and Pasquier, Philippe and Subyen, Pattarawut and Bartram, Lyn},
title = {Designing for Movement: Evaluating Computational Models Using LMA Effort Qualities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557251},
doi = {10.1145/2556288.2557251},
abstract = {While single-accelerometers are a common consumer embedded sensors, their use in representing
movement data as an intelligent resource remains scarce. Accelerometers have been
used in movement recognition systems, but rarely to assess expressive qualities of
movement. We present a prototype of wearable system for the real-time detection and
classification of movement quality using acceleration data. The system applies Laban
Movement Analysis (LMA) to recognize Laban Effort qualities from acceleration input
using a Machine Learning software that generates classifications in real time. Existing
LMA-recognition systems rely on motion capture data and video data, and can only be
deployed in controlled settings. Our single-accelerometer system is portable and can
be used under a wide range of environmental conditions. We evaluate the performance
of the system, present two applications using the system in the digital arts and discuss
future directions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {991–1000},
numpages = {10},
keywords = {movement analysis, movement-based interaction., movement recognition, laban effort analysis},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557050,
author = {Unander-Scharin, Carl and Unander-Scharin, \r{A}sa and H\"{o}\"{o}k, Kristina},
title = {The Vocal Chorder: Empowering Opera Singers with a Large Interactive Instrument},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557050},
doi = {10.1145/2556288.2557050},
abstract = {With The Vocal Chorder, a large interactive instrument to create accompaniment, opera
singers can get more power over the performance. The device allows performers to interactively
accompany themselves through pushing, leaning on and bending steel wires. The design
was guided by the unique needs of the solo-singer, explored through autobiographical
design and material explorations, some on stage, and later tested by other singers.
We discuss how designing for opera and for the stage requires extraordinary durability
and how opera performances can change with a bodily-oriented instrument such as The
Vocal Chorder. Through a designerly exploration, we arrived at a device that offered
(1) a tool for singers to take control over the rhythmical pace and overall artistic
and aesthetic outcome of their performances, (2) an enriched sense of embodiment between
their voice and the overall performance; and (3) a means to empower opera singers
on stage.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1001–1010},
numpages = {10},
keywords = {empowerment, appropriation, interactive instruments, embodiment, opera, autobiographical design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557187,
author = {H\"{a}kkil\"{a}, Jonna R. and Posti, Maaret and Schneegass, Stefan and Alt, Florian and Gultekin, Kunter and Schmidt, Albrecht},
title = {Let Me Catch This! Experiencing Interactive 3D Cinema through Collecting Content with a Mobile Phone},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557187},
doi = {10.1145/2556288.2557187},
abstract = {The entertainment industry is going through a transformation, and technology development
is affecting how we can enjoy and interact with the entertainment media content in
new ways. In our work, we explore how to enable interaction with content in the context
of 3D cinemas. This allows viewers to use their mobile phone to retrieve, for example,
information on the artist of the soundtrack currently playing or a discount coupon
on the watch the main actor is wearing. We are particularly interested in the user
experience of the interactive 3D cinema concept, and how different interactive elements
and interaction techniques are perceived. We report on the development of a prototype
application utilizing smart phones and on an evaluation in a cinema context with 20
participants. Results emphasize that designing for interactive cinema experiences
should drive for holistic and positive user experiences. Interactive content should
be tied together with the actual video content, but integrated into contexts where
it does not conflict with the immersive experience with the movie.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1011–1020},
numpages = {10},
keywords = {interactive cinema, user studies, user experience, 3d, mobile phone interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557049,
author = {Swift, Ben and Sorensen, Andrew and Martin, Michael and Gardner, Henry},
title = {Coding Livecoding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557049},
doi = {10.1145/2556288.2557049},
abstract = {Livecoding is an artistic programming practice in which an artist's low-level interaction
can be observed with sufficiently high fidelity to allow for transcription and analysis.
This paper presents the first reported "coding" of livecoding videos. From an identified
corpus of videos available on the web, we coded performances of two different livecoding
artists, recording both the (textual) programming edit events and the musical effect
of these edits. Our analysis includes a novel, transition-matrix visualisation of
the textual and musical dimensions of this data to create a "performer fingerprint".
We show how detailed transcriptions of livecoding videos can be made which, we hope,
will provide a foundation for further research into describing and understanding livecoding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1021–1024},
numpages = {4},
keywords = {creativity support tools, end-user programming},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557226,
author = {Martin, Charles and Gardner, Henry and Swift, Ben},
title = {Exploring Percussive Gesture on IPads with Ensemble Metatone},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557226},
doi = {10.1145/2556288.2557226},
abstract = {Percussionists are unique among western classical instrumentalists in that their artistic
practice is defined by an approach to interaction rather than their instruments. While
percussionists are accustomed to exploring non-traditional objects to create music,
these objects have yet to encompass touch-screen computing devices to any great extent.
The proliferation and popularity of these devices now presents an opportunity to explore
their use in combining computer-generated sound together with percussive interaction
in a musical ensemble.This paper examines Ensemble Metatone, a group formed to explore
the "infiltration" of iPad-based musical instruments into a free-improvisation percussion
ensemble. We discuss the design approach for two different iPad percussion instruments
and the methodology for exploring them with the group over a series of rehearsals
and performances. Qualitative analysis of discussions throughout this process shows
that the musicians developed a vocabulary of gestures and musical interactions to
make musical sense of these new instruments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1025–1028},
numpages = {4},
keywords = {music, expression, multitouch, gesture, percussion, user experience},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250939,
author = {Chen, Nicholas},
title = {Session Details: Battery Life and Energy Harvesting},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250939},
doi = {10.1145/3250939},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557271,
author = {Athukorala, Kumaripaba and Lagerspetz, Eemil and von K\"{u}gelgen, Maria and Jylh\"{a}, Antti and Oliner, Adam J. and Tarkoma, Sasu and Jacucci, Giulio},
title = {How Carat Affects User Behavior: Implications for Mobile Battery Awareness Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557271},
doi = {10.1145/2556288.2557271},
abstract = {Mobile devices have limited battery life, and numerous battery management applications
are available that aim to improve it. This paper examines a large-scale mobile battery
awareness application, called Carat, to see how it changes user behavior with long-term
use. We conducted a survey of current Carat Android users and analyzed their interaction
logs. The results show that long-term Carat users save more battery, charge their
devices less often, learn to manage their battery with less help from Carat, have
a better understanding of how Carat works, and may enjoy competing against other users.
Based on these findings, we propose a set of guidelines for mobile battery awareness
applications: battery awareness applications should make the reasoning behind their
recommendations understandable to the user, be tailored to retain long-term users,
take the audience into account when formulating feedback, and distinguish third-party
and system applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1029–1038},
numpages = {10},
keywords = {energy awareness, user behavior, smartphone, user retention},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557225,
author = {Ryokai, Kimiko and Su, Peiqi and Kim, Eungchan and Rollins, Bob},
title = {EnergyBugs: Energy Harvesting Wearables for Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557225},
doi = {10.1145/2556288.2557225},
abstract = {EnergyBugs are energy harvesting wearables with features that invite children to move
their bodies to generate tiny, yet usable amounts of electricity. EnergyBugs not only
convert children's kinetic energy into usable electrical energy, but also let children
power a specially designed LED lamp with the energy the children have personally harvested.
EnergyBugs therefore turn the electrical energy into a tangible object that children
can manipulate and think with. Two studies of EnergyBugs with 34 elementary school
children have revealed that children carefully observed and negotiated the use of
personally harvested energy with their classmates, as well as developed emotional
connections to energy. In particular, moving their own bodies to generate energy led
the children to more actively ask questions about energy from new perspectives. We
report our iterative design process and discuss the implications of our results for
HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1039–1048},
numpages = {10},
keywords = {energy harvesting, tangible uis, children, human-powered microgeneration, wearable, kinetic energy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557041,
author = {Mikkonen, Jussi and Gowrishankar, Ramyah and Oksanen, Miia and Raittinen, Harri and Kolinummi, Arto},
title = {OJAS: Open Source Bi-Directional Inductive Power Link},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557041},
doi = {10.1145/2556288.2557041},
abstract = {We present the design, development and evaluation of a bi-directional inductive power
transfer circuit for prototyping purposes in the watt-range. Our device does not require
any configuration and is intended for the development of wearable and tangible systems.
Our approach allows a bi-directional power flow without any change in the circuit,
such that the same circuit can be used for charging and discharging a battery. The
contribution of this work is an enabling technology for researchers and practitioners
in the fields of Wearable Electronics, Ubiquitous Computing and Human-Computer Interaction
interested in exploring new interactions powered by watt-range inductive links. It
enables smaller battery sizes, and therefore lighter devices, as the power can be
distributed in a way that has not been feasible before. We discuss the motivations,
technical details and the workshop evaluating our inductive approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1049–1058},
numpages = {10},
keywords = {prototyping, bi-directional inductive power, wearable electronics, smart garments},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557135,
author = {Kihm, Jaeyeon and Guimbreti\`{e}re, Fran\c{c}ois V. and Karl, Julia and Manohar, Rajit},
title = {Using Asymmetric Cores to Reduce Power Consumption for Interactive Devices with Bi-Stable Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557135},
doi = {10.1145/2556288.2557135},
abstract = {Low power "helper" cores have been increasingly included on application processors
to accomplish low intensity tasks such as music playing and motion sensing with minimum
energy consumption. Recently, Guimbreti\`{e}re et al. [1] demonstrated that such helper
cores can also be used to execute simple user interface tasks. We revisit this approach
by implementing a similar system on an off-the-shelf application processor (TI OMAP4).
Our study shows that in the case of high event rate interactions (pen inking and virtual
keyboard), significant battery life gains (\texttimes{}1.7 and \texttimes{}2.3 respectively) can be achieved
with the helper core executing the interface. Having the helper core only dis-patch
input events incurs a 18% penalty relative to the maximum savings rate, but allows
for simplified deployment since it merely requires a change in toolkit infrastructure.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1059–1062},
numpages = {4},
keywords = {energy efficiency, user interface system, bi-stable display, asymmetric architecture, pen interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250940,
author = {Izadi, Shahram},
title = {Session Details: Mid-Air Gestures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250940},
doi = {10.1145/3250940},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557130,
author = {Hincapi\'{e}-Ramos, Juan David and Guo, Xiang and Moghadasian, Paymahn and Irani, Pourang},
title = {Consumed Endurance: A Metric to Quantify Arm Fatigue of Mid-Air Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557130},
doi = {10.1145/2556288.2557130},
abstract = {Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the
upper limbs, a condition casually termed as the gorilla-arm effect. Designers have
often associated limitations of their mid-air interactions with arm fatigue, but do
not possess a quantitative method to assess and therefore mitigate it. In this paper
we propose a novel metric, Consumed Endurance (CE), derived from the biomechanical
structure of the upper arm and aimed at characterizing the gorilla-arm effect. We
present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based
skeleton tracking system, and demonstrate that CE correlates strongly with the Borg
CR10 scale of perceived exertion. We show how designers can use CE as a complementary
metric for evaluating existing and designing novel mid-air interactions, including
tasks with repetitive input such as mid-air text-entry. Finally, we propose a series
of guidelines for the design of fatigue-efficient mid-air interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1063–1072},
numpages = {10},
keywords = {seato mid-air keyboard, gorilla-arm, mid-air text-entry, endurance, mid-air interactions, consumed endurance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556964,
author = {Markussen, Anders and Jakobsen, Mikkel R\o{}nne and Hornb\ae{}k, Kasper},
title = {Vulture: A Mid-Air Word-Gesture Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556964},
doi = {10.1145/2556288.2556964},
abstract = {Word-gesture keyboards enable fast text entry by letting users draw the shape of a
word on the input surface. Such keyboards have been used extensively for touch devices,
but not in mid-air, even though their fluent gestural input seems well suited for
this modality. We present Vulture, a word-gesture keyboard for mid-air operation.
Vulture adapts touch based word-gesture algorithms to work in mid-air, projects users'
movement onto the display, and uses pinch as a word delimiter. A first 10-session
study suggests text-entry rates of 20.6 Words Per Minute (WPM) and finds hand-movement
speed to be the primary predictor of WPM. A second study shows that with training
on a few phrases, participants do 28.1 WPM, 59% of the text-entry rate of direct touch
input. Participants' recall of trained gestures in mid-air was low, suggesting that
visual feedback is important but also limits performance. Based on data from the studies,
we discuss improvements to Vulture and some alternative designs for mid-air text entry.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1073–1082},
numpages = {10},
keywords = {freehand interaction, shape writing, word-gesture keyboard, mid-air interaction, in-air interaction, text entry},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557151,
author = {Wacharamanotham, Chat and Todi, Kashyap and Pye, Marty and Borchers, Jan},
title = {Understanding Finger Input above Desktop Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557151},
doi = {10.1145/2556288.2557151},
abstract = {Using the space above desktop input devices adds a rich new input channel to desktop
interaction. Input in this elevated layer has been previously used to modify the granularity
of a 2D slider, navigate layers of a 3D body scan above a multitouch table and access
vertically stacked menus. However, designing these interactions is challenging because
the lack of haptic and direct visual feedback easily leads to input errors. For bare
finger input, the user's fingers needs to reliably enter and stay inside the interactive
layer, and engagement techniques such as midair clicking have to be disambiguated
from leaving the layer. These issues have been addressed for interactions in which
users operate other devices in midair, but there is little guidance for the design
of bare finger input in this space.In this paper, we present the results of two user
studies that inform the design of finger input above desktop devices. Our studies
show that 2 cm is the minimum thickness of the above-surface volume that users can
reliably remain within. We found that when accessing midair layers, users do not automatically
move to the same height. To address this, we introduce a technique that dynamically
determines the height at which the layer is placed, depending on the velocity profile
of the user's initial finger movement into midair. Finally, we propose a technique
that reliably distinguishes clicking from homing movements, based on the user's hand
shape. We structure the presentation of our findings using Buxton's three-state input
model, adding additional states and transitions for above-surface interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1083–1092},
numpages = {10},
keywords = {finger input, thickness, height, near-surface, midair},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557122,
author = {Kulshreshth, Arun and LaViola, Joseph J.},
title = {Exploring the Usefulness of Finger-Based 3D Gesture Menu Selection},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557122},
doi = {10.1145/2556288.2557122},
abstract = {Counting using one's fingers is a potentially intuitive way to enumerate a list of
items and lends itself naturally to gesture-based menu systems. In this paper, we
present the results of the first comprehensive study on Finger-Count menus to investigate
its usefulness as a viable option for 3D menu selection tasks. Our study compares
3D gesture-based finger counting (Finger Count menus) with two gesture-based menu
selection techniques (Hand-n-Hold, Thumbs-Up), derived from existing motion-controlled
video game menu selection strategies, as well as 3D Marking menus. We examined selection
time, selection accuracy and user preference for all techniques. We also examined
the impact of different spatial layouts for menu items and different menu depths.
Our results indicate that Finger-Count menus are significantly faster than the other
menu techniques we tested and are the most liked by participants. Additionally, we
found that while Finger-Count menus and 3D Marking menus have similar selection accuracy,
Finger-Count menus are almost twice as fast compared to 3D Marking menus.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1093–1102},
numpages = {10},
keywords = {selection, hand-n-hold menu, user study, gesture recognition, depth camera, video games, thumbs-up menu, 3d interaction, menu selection, finger-count menu, 3d marking menu},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250941,
author = {Cao, Xiang},
title = {Session Details: Touch and Stylus Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250941},
doi = {10.1145/3250941},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557037,
author = {Ng, Albert and Annett, Michelle and Dietz, Paul and Gupta, Anoop and Bischof, Walter F.},
title = {In the Blink of an Eye: Investigating Latency Perception during Stylus Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557037},
doi = {10.1145/2556288.2557037},
abstract = {While pen computing has become increasingly more popular, device responsiveness, or
latency, still plagues such interaction. Although there have been advances in digitizer
technology over the last few years, commercial end-to-end latencies are unfortunately
similar to those found with touchscreens, i.e., 65 - 120 milliseconds. We report on
a prototype stylus-enabled device, the High Performance Stylus System (HPSS), designed
to display latencies as low as one millisecond while users ink or perform dragging
tasks.To understand the role of latency while inking with a stylus, psychophysical
just-noticeable difference experiments were conducted using the HPSS. While participants
performed dragging and scribbling tasks, very low levels of latency could be discriminated,
i.e., ~1 versus 2 milliseconds while dragging and ~7 versus 40 milliseconds while
scribbling. The HPSS and our experimentation have provided further motivation for
the implementation of latency saving measures in pen-based hardware and software systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1103–1112},
numpages = {10},
keywords = {pen, perception, pen computing, latency, stylus, psychophysics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557028,
author = {Spindler, Martin and Schuessler, Martin and Martsch, Marcel and Dachselt, Raimund},
title = {Pinch-Drag-Flick vs. Spatial Input: Rethinking Zoom &amp; Pan on Mobile Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557028},
doi = {10.1145/2556288.2557028},
abstract = {The multi-touch-based pinch to zoom, drag and flick to pan metaphor has gained wide
popularity on mobile displays, where it is the paradigm of choice for navigating 2D
documents. But is finger-based navigation really the gold standard' In this paper,
we present a comprehensive user study with 40 participants, in which we systematically
compared the Pinch-Drag-Flick approach with a technique that relies on spatial manipulation,
such as lifting a display up/down to zoom. While we solely considered known techniques,
we put considerable effort in implementing both input strategies on popular consumer
hardware (iPhone, iPad). Our results show that spatial manipulation can significantly
outperform traditional Pinch-Drag-Flick. Given the carefully optimized prototypes,
we are confident to have found strong arguments that future generations of mobile
devices could rely much more on spatial interaction principles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1113–1122},
numpages = {10},
keywords = {multi-touch input, user study, spatial input, mobile displays, spatially aware displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557302,
author = {Ren, Yi and Li, Yang and Lank, Edward},
title = {InkAnchor: Enhancing Informal Ink-Based Note Taking on Touchscreen Mobile Phones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557302},
doi = {10.1145/2556288.2557302},
abstract = {Although touchscreen mobile phones are widely used for recording informal text notes
(e.g., grocery lists, reminders and directions), the lack of efficient mechanisms
for combining informal graphical content with text is a persistent challenge. In this
paper, we present InkAnchor, a digital ink editor that allows users to easily create
ink-based notes by finger drawing and writing on a mobile phone touchscreen. InkAnchor
incorporates flexible anchoring, focus-plus-context input, content chunking, and lightweight
editing mechanisms to support the capture of informal notes and annotations. We describe
the design and evaluation of InkAnchor through a series of user studies, which revealed
that the integrated support enabled by InkAnchor is a significant improvement over
current mobile note taking applications on a range of mobile note-taking tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1123–1132},
numpages = {10},
keywords = {drawing, multi-scale sketching, digital ink, mobile interaction, note taking, multi-touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557033,
author = {Wilson, Graham and Carter, Thomas and Subramanian, Sriram and Brewster, Stephen A.},
title = {Perception of Ultrasonic Haptic Feedback on the Hand: Localisation and Apparent Motion},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557033},
doi = {10.1145/2556288.2557033},
abstract = {Ultrasonic haptic feedback is a promising means of providing tactile sensations in
mid-air without encumbering the user with an actuator. However, controlled and rigorous
HCI research is needed to understand the basic characteristics of perception of this
new feedback medium, and so how best to utilise ultrasonic haptics in an interface.
This paper describes two experiments conducted into two fundamental aspects of ultrasonic
haptic perception: 1) localisation of a static point and 2) the perception of motion.
Understanding these would provide insight into 1) the spatial resolution of an ultrasonic
interface and 2) what forms of feedback give the most convincing illusion of movement.
Results show an average localisation error of 8.5mm, with higher error along the longitudinal
axis. Convincing sensations of motion were produced when travelling longer distances,
using longer stimulus durations and stimulating multiple points along the trajectory.
Guidelines for feedback design are given.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1133–1142},
numpages = {10},
keywords = {localisation, perception, haptic feedback, ultrasound},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250942,
author = {Zimmerman, John},
title = {Session Details: Quantified Self},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250942},
doi = {10.1145/3250942},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557372,
author = {Choe, Eun Kyoung and Lee, Nicole B. and Lee, Bongshin and Pratt, Wanda and Kientz, Julie A.},
title = {Understanding Quantified-Selfers' Practices in Collecting and Exploring Personal Data},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557372},
doi = {10.1145/2556288.2557372},
abstract = {Researchers have studied how people use self-tracking technologies and discovered
a long list of barriers including lack of time and motivation as well as difficulty
in data integration and interpretation. Despite the barriers, an increasing number
of Quantified-Selfers diligently track many kinds of data about themselves, and some
of them share their best practices and mistakes through Meetup talks, blogging, and
conferences. In this work, we aim to gain insights from these "extreme users," who
have used existing technologies and built their own workarounds to overcome different
barriers. We conducted a qualitative and quantitative analysis of 52 video recordings
of Quantified Self Meetup talks to understand what they did, how they did it, and
what they learned. We highlight several common pitfalls to self-tracking, including
tracking too many things, not tracking triggers and context, and insufficient scientific
rigor. We identify future research efforts that could help make progress toward addressing
these pitfalls. We also discuss how our findings can have broad implications in designing
and developing self-tracking technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1143–1152},
numpages = {10},
keywords = {quantified self, health, self-tracking, self-experimentation., per-sonal informatics, personal analytics, self-monitoring},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557223,
author = {Jang, Amy and MacLean, Diana L. and Heer, Jeffrey},
title = {BodyDiagrams: Improving Communication of Pain Symptoms through Drawing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557223},
doi = {10.1145/2556288.2557223},
abstract = {Thousands of people use the Internet to discuss pain symptoms. While communication
between patients and physicians involves both verbal and physical interactions, online
discussions of symptoms typically comprise text only. We present BodyDiagrams, an
online interface for expressing symptoms via drawings and text. BodyDiagrams augment
textual descriptions with pain diagrams drawn over a reference body and annotated
with severity and temporal metadata. The resulting diagrams can easily be shared to
solicit feedback and advice. We also conduct a two-phase user study to assess BodyDiagrams'
communicative efficacy. In the first phase, users describe pain symptoms using BodyDiagrams
and a text-only interface; in the second phase, medical professionals evaluate these
descriptions. We find that patients are significantly more confident that their BodyDiagrams
will be correctly interpreted, while medical professionals rated BodyDiagrams as significantly
more informative than text descriptions. Both groups indicated a preference for using
diagrams to communicate physical symptoms in the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1153–1162},
numpages = {10},
keywords = {health, drawing, pain diagrams, symptom communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557039,
author = {Rooksby, John and Rost, Mattias and Morrison, Alistair and Chalmers, Matthew},
title = {Personal Tracking as Lived Informatics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557039},
doi = {10.1145/2556288.2557039},
abstract = {This paper characterises the use of activity trackers as "lived informatics". This
characterisation is contrasted with other discussions of personal informatics and
the quantified self. The paper reports an interview study with activity tracker users.
The study found: people do not logically organise, but interweave various activity
trackers, sometimes with ostensibly the same functionality; that tracking is often
social and collaborative rather than personal; that there are different styles of
tracking, including goal driven tracking and documentary tracking; and that tracking
information is often used and interpreted with reference to daily or short term goals
and decision making. We suggest there will be difficulties in personal informatics
if we ignore the way that personal tracking is enmeshed with everyday life and people's
outlook on their future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1163–1172},
numpages = {10},
keywords = {qualitative methods, activity tracking, data},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250943,
author = {Huang, Elaine},
title = {Session Details: Sustainability Perspectives},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250943},
doi = {10.1145/3250943},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556968,
author = {Bates, Oliver and Hazas, Mike and Friday, Adrian and Morley, Janine and Clear, Adrian K.},
title = {Towards an Holistic View of the Energy and Environmental Impacts of Domestic Media and IT},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556968},
doi = {10.1145/2556288.2556968},
abstract = {To date, research in sustainable HCI has dealt with eco-feedback, usage and recycling
of appliances within the home, and longevity of portable electronics such as mobile
phones. However, there seems to be less awareness of the energy and greenhouse emissions
impacts of domestic consumer electronics and information technology. Such awareness
is needed to inform HCI sustainability researchers on how best to prioritise efforts
around digital media and IT. Grounded in inventories, interview and plug energy data
from 33 undergraduate student participants, our findings provide the context for assessing
approaches to reducing the energy and carbon emissions of media and IT in the home.
In the paper, we use the findings to discuss and inform more fruitful directions that
sustainable HCI research might take, and we quantify how various strategies might
have modified the energy and emissions impacts for our participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1173–1182},
numpages = {10},
keywords = {embodied emissions, home energy, life cycle assessment, sustainability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557374,
author = {Brereton, Margot and Roe, Paul and Schroeter, Ronald and Lee Hong, Anita},
title = {Beyond Ethnography: Engagement and Reciprocity as Foundations for Design Research out Here},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557374},
doi = {10.1145/2556288.2557374},
abstract = {This paper explores an emerging paradigm for HCI design research based primarily upon
engagement, reciprocity and doing. Much HCI research begins with an investigatory
and analytic ethnographic approach before translating to design. Design may come much
later in the process and may never benefit the community that is researched. However
in many settings it is difficult for researchers to access the privileged ethnographer
position of observer and investigator. Moreover rapid ethnographic research often
does not seem the best or most appropriate course of action. We draw upon a project
working with a remote Australian Aboriginal community to illustrate an alternative
approach in Indigenous research, where the notion of reciprocity is first and foremost.
We argue that this can lead to sustainable designs, valid research and profound innovation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1183–1186},
numpages = {4},
keywords = {participatory action research, ict4d, postcolonial hci},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250944,
author = {Gajos, Krzysztof},
title = {Session Details: Navigating Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250944},
doi = {10.1145/3250944},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557106,
author = {Al-Hajri, Abir and Miller, Gregor and Fong, Matthew and Fels, Sidney S.},
title = {Visualization of Personal History for Video Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557106},
doi = {10.1145/2556288.2557106},
abstract = {We present an investigation of two different visualizations of video history: Video
Timeline and Video Tiles. Video Timeline extends the commonly employed list-based
visualization for navigation history by applying size to indicate heuristics and occupying
the full screen with a two-sided timeline. Video Tiles visualizes history items in
a grid-based layout by following pre-defined templates based on items' heuristics
and ordering, utilizing screen space more effectively at the expense of a clearer
temporal location. The visualizations are compared against the state-of-the-art method
(a filmstrip-based visualization), with ten participants tasked with sharing their
previously-seen affective intervals. Our study shows that our visualizations are perceived
as intuitive and both outperform and are strongly preferred to the current method.
Based on these results, Video Timeline and Video Tiles provide an effective addition
to video viewers to help manage the growing quantity of video. They provide users
with insight into their navigation patterns, allowing them to quickly find previously-seen
intervals, leading to efficient clip sharing, simpler authoring and video summarization.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1187–1196},
numpages = {10},
keywords = {navigation, history, visualization, video},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557382,
author = {Hunter, Seth E. and Maes, Pattie and Tang, Anthony and Inkpen, Kori M. and Hessey, Susan M.},
title = {WaaZam! Supporting Creative Play at a Distance in Customized Video Environments},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557382},
doi = {10.1145/2556288.2557382},
abstract = {We present the design, and evaluation of WaaZam, a video mediated communication system
designed to support creative play in customized environments. Users can interact together
in virtual environments composed of digital assets layered in 3D space. The goal of
the project is to support creative play and increase social engagement during video
sessions of geographically separated families. We try to understand the value of customization
for individual families with children ages 6-12. We present interviews with creativity
experts, a pilot study and a formal evaluation of families playing together in four
conditions: separate windows, merged windows, digital play sets, and customized digital
environments. We found that playing in the same video space enables new activities
and increases social engagement for families. Customization allows families to modify
scenes for their needs and support more creative play activities that embody the imagination
of the child.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1197–1206},
numpages = {10},
keywords = {video mediated communication, remote play, shared experiences at a distance, family play, composited video, play at a distance, customized video environments},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557304,
author = {Freeman, Dustin and Santosa, Stephanie and Chevalier, Fanny and Balakrishnan, Ravin and Singh, Karan},
title = {LACES: Live Authoring through Compositing and Editing of Streaming Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557304},
doi = {10.1145/2556288.2557304},
abstract = {Video authoring activity typically consists of three phases: planning (pre-production),
capture (production) and processing (post-production). The status quo is that these
phases occur separately, and the latter two have a significant amount of "slack time",
where the camera operator is watching the scene unfold during capture, and the editor
is re-watching and navigating through recorded footage during post-production. While
this process is well suited to creating polished or professional video, video clips
produced by casual video makers as seen in online forums could benefit from some editing
without the overhead of current authoring tools. We introduce LACES, a tablet-based
system enabling simple video manipulations in the midst of filming. Seamless in-situ
integration of video capture and manipulation forms a novel workflow, allowing greater
spontaneity and exploration of video creation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1207–1216},
numpages = {10},
keywords = {video production, video editing, compositing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557249,
author = {Craggs, Barnaby and Kilgallon Scott, Myles and Alexander, Jason},
title = {ThumbReels: Query Sensitive Web Video Previews Based on Temporal, Crowdsourced, Semantic Tagging},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557249},
doi = {10.1145/2556288.2557249},
abstract = {During online search, the user's expectations often differ from those of the author.
This is known as the "intention gap" and is particularly problematic when searching
for and discriminating between online video content. An author uses description and
meta-data tags to label their content, but often cannot predict alternate interpretations
or appropriations of their work. To address this intention gap, we present ThumbReels,
a concept for query-sensitive video previews generated from crowdsourced, temporally
defined semantic tagging. Further, we supply an open-source tool that supports on-the-fly
temporal tagging of videos, whose output can be used for later search queries. A first
user study validates the tool and concept. We then present a second study that shows
participants found ThumbReels to better represent search terms than contemporary preview
techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1217–1220},
numpages = {4},
keywords = {metadata, thumbreels, video, video summarisation, video surrogates, thumbnails, crowdsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557082,
author = {Nicholson, James and Huber, Mark and Jackson, Daniel and Olivier, Patrick},
title = {Panopticon as an ELearning Support Search Tool},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557082},
doi = {10.1145/2556288.2557082},
abstract = {We present an evaluation of Panopticon, a video surrogate system, as an online eLearning
support search tool for finding information within video lectures. A comparison was
made with a standard video player (YouTube) in two scenarios with two classes of users:
revision students and independent learners. Results showed that users of Panopticon
were significantly faster at finding information within the lecture videos than users
of the YouTube player. It was also found that videos predominantly featuring a talking
lecturer took longest to navigate, presenting design implications for lectures to
be uploaded to open eLearning platforms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1221–1224},
numpages = {4},
keywords = {video browsing, elearning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250945,
author = {Irani, Lilly},
title = {Session Details: Crowds and Creativity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250945},
doi = {10.1145/3250945},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557378,
author = {Yu, Lixiu and Kittur, Aniket and Kraut, Robert E.},
title = {Searching for Analogical Ideas with Crowds},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557378},
doi = {10.1145/2556288.2557378},
abstract = {Seeking solutions from one domain to solve problems in another is an effective process
of innovation. This process of analogy searching is difficult for both humans and
machines. In this paper, we present a novel approach for re-presenting a problem in
terms of its abstract structure, and then allowing people to use this structural representation
to find analogies. We propose a crowdsourcing process that helps people navigate a
large dataset to find analogies. Through two experiments, we show the benefits of
using abstract structural representations to search for ideas that are analogous to
a source problem, and that these analogies result in better solutions than alternative
approaches. This work provides a useful method for finding analogies, and can streamline
innovation for both novices and professional designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1225–1234},
numpages = {10},
keywords = {crowdsourcing, schema, analogy searching, creativity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557394,
author = {Zhao, Zhenpeng and Badam, Sriram Karthik and Chandrasegaran, Senthil and Park, Deok Gun and Elmqvist, Niklas L.E. and Kisselburgh, Lorraine and Ramani, Karthik},
title = {SkWiki: A Multimedia Sketching System for Collaborative Creativity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557394},
doi = {10.1145/2556288.2557394},
abstract = {We present skWiki, a web application framework for collaborative creativity in digital
multimedia projects, including text, hand-drawn sketches, and photographs. skWiki
overcomes common drawbacks of existing wiki software by providing a rich viewer/editor
architecture for all media types that is integrated into the web browser itself, thus
avoiding dependence on client-side editors. Instead of files, skWiki uses the concept
of paths as trajectories of persistent state over time. This model has intrinsic support
for collaborative editing, including cloning, branching, and merging paths edited
by multiple contributors. We demonstrate skWiki's utility using a qualitative, sketching-based
user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1235–1244},
numpages = {10},
keywords = {collaborative editing, creativity, wikis, sketching},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557371,
author = {Yu, Lixiu and Kittur, Aniket and Kraut, Robert E.},
title = {Distributed Analogical Idea Generation: Inventing with Crowds},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557371},
doi = {10.1145/2556288.2557371},
abstract = {Harnessing crowds can be a powerful mechanism for increasing innovation. However,
current approaches to crowd innovation rely on large numbers of contributors generating
ideas independently in an unstructured way. We introduce a new approach called distributed
analogical idea generation, which aims to make idea generation more effective and
less reliant on chance. Drawing from the literature in cognitive science on analogy
and schema induction, our approach decomposes the creative process in a structured
way amenable to using crowds. In three experiments we show that distributed analogical
idea generation leads to better ideas than example-based approaches, and investigate
the conditions under which crowds generate good schemas and ideas. Our results have
implications for improving creativity and building systems for distributed crowd innovation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1245–1254},
numpages = {10},
keywords = {innovation, crowdsourcing, schema, creativity, analogy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557375,
author = {Chilton, Lydia B. and Kim, Juho and Andr\'{e}, Paul and Cordeiro, Felicia and Landay, James A. and Weld, Daniel S. and Dow, Steven P. and Miller, Robert C. and Zhang, Haoqi},
title = {Frenzy: Collaborative Data Organization for Creating Conference Sessions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557375},
doi = {10.1145/2556288.2557375},
abstract = {Organizing conference sessions around themes improves the experience for attendees.
However, the session creation process can be difficult and time-consuming due to the
amount of expertise and effort required to consider alternative paper groupings. We
present a collaborative web application called Frenzy to draw on the efforts and knowledge
of an entire program committee. Frenzy comprises (a) interfaces to support large numbers
of experts working collectively to create sessions, and (b) a two-stage process that
decomposes the session-creation problem into meta-data elicitation and global constraint
satisfaction. Meta-data elicitation involves a large group of experts working simultaneously,
while global constraint satisfaction involves a smaller group that uses the meta-data
to form sessions.We evaluated Frenzy with 48 people during a deployment at the CSCW
2014 program committee meeting. The session making process was much faster than the
traditional process, taking 88 minutes instead of a full day. We found that meta-data
elicitation was useful for session creation. Moreover, the sessions created by Frenzy
were the basis of the CSCW 2014 schedule.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1255–1264},
numpages = {10},
keywords = {communitysourcing, crowdsourcing, groupware},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250946,
author = {Golbeck, Jennifer},
title = {Session Details: Interacting with the Web},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250946},
doi = {10.1145/3250946},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557036,
author = {Benson, Edward and Karger, David R.},
title = {End-Users Publishing Structured Information on the Web: An Observational Study of What, Why, and How},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557036},
doi = {10.1145/2556288.2557036},
abstract = {End-users are accustomed to filtering and browsing styled collections of data on professional
web sites, but they have few ways to create and publish such information architectures
for themselves. This paper presents a full-lifecycle analysis of the Exhibit framework
- an end-user tool which provides such functionality - to understand the needs, capabilities,
and practices of this class of users. We include interviews, as well as analysis of
over 1,800 visualizations and 200,000 web interactions with these visualizations.
Our analysis reveals important findings about this user population which generalize
to the task of providing better end-user structured content publication tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1265–1274},
numpages = {10},
keywords = {web design, information architectures, web content editing, faceted browsing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557265,
author = {Seckler, Mirjam and Heinz, Silvia and Bargas-Avila, Javier A. and Opwis, Klaus and Tuch, Alexandre N.},
title = {Designing Usable Web Forms: Empirical Evaluation of Web Form Improvement Guidelines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557265},
doi = {10.1145/2556288.2557265},
abstract = {This study reports a controlled eye tracking experiment (N = 65) that shows the combined
effectiveness of 20 guidelines to improve interactive online forms when applied to
forms found on real company websites. Results indicate that improved web forms lead
to faster completion times, fewer form submission trials, and fewer eye movements.
Data from subjective questionnaires and interviews further show increased user satisfaction.
Overall, our findings highlight the importance for web designers to improve their
web forms using UX guidelines.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1275–1284},
numpages = {10},
keywords = {web forms, internet, world wide web, form evaluation, form interaction, form guidelines},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557149,
author = {Chiravirakul, Pawitra and Payne, Stephen J.},
title = {Choice Overload in Search Engine Use?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557149},
doi = {10.1145/2556288.2557149},
abstract = {Search engines typically return so many results that choosing from the list might
be predicted to suffer from the effects of "choice overload". Preliminary work has
reported just such an effect [12]. In this paper a series of three experiments was
conducted to investigate the choice overload effect in search engine use. Participants
were given search tasks and presented with either six or twenty-four returns to choose
from. The results revealed that the choice behaviour was strongly influenced by the
ranking of returns, and that choice satisfaction was affected by the number of options
and the decision time. The main results, from the third experiment, showed that large
sets of options yielded a positive effect on participants' satisfaction when they
made a decision without time limit. When time was more strongly constrained, choices
from small sets led to relatively higher satisfaction. Our studies show how user satisfaction
with found information can be affected by processing strategies that are influenced
by search engine design features.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1285–1294},
numpages = {10},
keywords = {decision behaviour, search engines, choice satisfaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250947,
author = {Blythe, Mark},
title = {Session Details: Music, Dance, and Television},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250947},
doi = {10.1145/3250947},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557298,
author = {Hoare, Michaela and Benford, Steve and Jones, Rachel and Milic-Frayling, Natasa},
title = {Coming in from the Margins: Amateur Musicians in the Online Age},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557298},
doi = {10.1145/2556288.2557298},
abstract = {HCI is increasingly interested in amateurism, but the wider literature suggests that
the amateur is a complex and distinctive phenomenon. An interview study reveals the
nature of the amateur in the digital age. Even though operating non-professionally
at a micro-scale, amateur musicians employ a plethora of online services to sustain
local fanbases, reach out to new fans, collaborate internationally, and actively promote
both digital and material products. Our findings lead to recommendations for event-oriented
promotion tools; community-oriented analytics; tangible and embedded products; and
limited-edition digital experiences. We conclude that HCI needs to recognise the amateur
as an important class of user, one who is serious about their leisure, and who is
also distinct from the professional as from the novice and hobbyist.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1295–1304},
numpages = {10},
keywords = {music, social media, diy, amateur, community, sharing, craft, tangible, promotion, distribution},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557369,
author = {Barkhuus, Louise and Engstr\"{o}m, Arvid and Zoric, Goranka},
title = {Watching the Footwork: Second Screen Interaction at a Dance and Music Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557369},
doi = {10.1145/2556288.2557369},
abstract = {Interactive mobile technologies have become part of audience experiences of live performances
in terms of both general media sharing and specific (sometimes official) extra content.
At the same time, high bandwidth affords streaming of live events to mobile devices.
We take advantage of these technologies in our high resolution, panoramic image video
stream and study a scenario of audience members viewing the very same live event they
are watching on a tablet. The video stream on the tablet is navigational and enables
audience members to pan and zoom in the real-time video feed. We studied audience
interaction and impressions in three performances of a dance and music show and found
distinct uses of the second screen video stream. We emphasize that despite initial
reluctance, the observed utilization of the technology opened up for new potential
practices. Our study shows how working with perceived conflict in technology can still
open up design space for interactive technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1305–1314},
numpages = {10},
keywords = {mobile entertainment, interactive television, second screen interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557048,
author = {Hamilton, William A. and Garretson, Oliver and Kerne, Andruid},
title = {Streaming on Twitch: Fostering Participatory Communities of Play within Live Mixed Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557048},
doi = {10.1145/2556288.2557048},
abstract = {Previously, video streaming sites were at the fringes of online social media. In the
past two years, live streams of video games, on sites such as Twitch.tv, have become
very popular. Live streams serve as meeting grounds for player communities. The Twitch
streaming medium combines broadcast video with open IRC chat channels. In conjunction
with gameplay, viewer participation and community building gain emphasis. Twitch streams
range in size and nature, from intimate communities with fifty viewers, to massive
broadcasts with tens of thousands. In this paper, we present an ethnographic investigation
of the live streaming of video games on Twitch.We find that Twitch streams act as
virtual third places, in which informal communities emerge, socialize, and participate.
Over time, stream communities form around shared identities drawn from streams? contents
and participants? shared experiences. We describe processes through which stream communities
form, the motivations of members, and emergent issues in the medium. Finally, we draw
from our findings to derive implications for design of live mixed-media environments
to support participatory online communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1315–1324},
numpages = {10},
keywords = {live streaming, third places, online communities, ethnography, video games, twitch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557315,
author = {Juhlin, Oskar and Engstr\"{o}m, Arvid and \"{O}nnevall, Elin},
title = {Long Tail TV Revisited: From Ordinary Camera Phone Use to pro-Am Video Production},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557315},
doi = {10.1145/2556288.2557315},
abstract = {Pro-Am live video producers broadcast events on a regular basis. They are here selected
for an ethnographic study since their continuous content generation can teach us something
of what it takes for amateurs, who currently struggle with mastering the video medium,
to become proficient producers. We learn from media theory that Pro-Ams are distinguished
from professionals in terms of inherent skills and identities, and have therefore
focused on these characteristics. We add to this research by showing on-going challenges
that the former face in their production, i.e. how their learning practices, such
as learning through instructions, are situated and related to particular settings.
Learning and development of skills were done as organizations, rather than as individuals.
Furthermore, the recurrent nature of both events and broadcasts appears to be an important
condition for establishing the terms needed to carry out a production, and to learn
the skills of a producer. This understanding may explain in part why accounts in previous
research, of single users struggling with the affordances of live video, point to
such difficulties in mastering the medium. The findings guide design to better support
activities contiguous with the set-up of the production, rather than the broadcast
per se.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1325–1334},
numpages = {10},
keywords = {user-generated content, media studies, identity, live video, video, camera phones, ethnography, organization theory, negotiation, mimicking, learning, pro-am},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250948,
author = {schraefel, m.c.},
title = {Session Details: Social Media and Health},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250948},
doi = {10.1145/3250948},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557139,
author = {Culotta, Aron},
title = {Estimating County Health Statistics with Twitter},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557139},
doi = {10.1145/2556288.2557139},
abstract = {Understanding the relationships among environment, behavior, and health is a core
concern of public health researchers. While a number of recent studies have investigated
the use of social media to track infectious diseases such as influenza, little work
has been done to determine if other health concerns can be inferred. In this paper,
we present a large-scale study of 27 health-related statistics, including obesity,
health insurance coverage, access to healthy foods, and teen birth rates. We perform
a linguistic analysis of the Twitter activity in the top 100 most populous counties
in the U.S., and find a significant correlation with 6 of the 27 health statistics.
When compared to traditional models based on demographic variables alone, we find
that augmenting models with Twitter-derived information improves predictive accuracy
for 20 of 27 statistics, suggesting that this new methodology can complement existing
approaches.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1335–1344},
numpages = {10},
keywords = {natural language processing, social media, public health},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557145,
author = {Murnane, Elizabeth L. and Counts, Scott},
title = {Unraveling Abstinence and Relapse: Smoking Cessation Reflected in Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557145},
doi = {10.1145/2556288.2557145},
abstract = {Analysis of smokers' posts and behaviors on Twitter reveals factors impacting abstinence
and relapse during cessation attempts. Combining automatic and crowdsourced techniques,
we detect users trying to quit smoking and analyze tweet and network data from a sample
of 653 individuals over a two-year window of quitting. Guided by theory and practice,
we derive behavioral, social, and emotional measures to compare users who abstain
and relapse. We also examine the cessation process, demonstrating that Twitter can
help chronicle how some people go about quitting. Among other results, we show that
those who fail in their smoking cessation are far heavier posters and use relatively
less positive language, while those who succeed are more social in both network ties
and in directed communication. We conclude with insights on how intelligent intervention
systems can harness these signals to provide tailored behavior change support.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1345–1354},
numpages = {10},
keywords = {health, behavior, social media, cessation, twitter, smoking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557293,
author = {Huh, Jina and Pratt, Wanda},
title = {Weaving Clinical Expertise in Online Health Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557293},
doi = {10.1145/2556288.2557293},
abstract = {Many patients visit online health communities to receive support. In face-to-face
support groups, health professionals facilitate peer-patients exchanging experience
while adding their clinical expertise when necessary. However, the large scale of
online health communities makes it challenging for such health professional moderators'
involvement to happen. To address this challenge of delivering clinical expertise
to where patients need them, we explore the idea of semi-automatically providing clinical
expertise in online health communities. We interviewed 14 clinicians showing them
example peer-patient conversation threads. From the interviews, we examined the ideal
practice of clinicians providing expertise to patients. The clinicians continuously
assessed when peer-patients were providing appropriate support, what kinds of clinical
help they could give online, and when to defer to patients' healthcare providers.
The findings inform requirements for building a semi-automated system delivering clinical
expertise in online health communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1355–1364},
numpages = {10},
keywords = {moderator, support group, health informatics, online health communities},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557214,
author = {De Choudhury, Munmun and Morris, Meredith Ringel and White, Ryen W.},
title = {Seeking and Sharing Health Information Online: Comparing Search Engines and Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557214},
doi = {10.1145/2556288.2557214},
abstract = {Search engines and social media are two of the most com-monly used online services;
in this paper, we examine how users appropriate these platforms for online health
activi-ties via both large-scale log analysis and a survey of 210 people. While users
often turn to search engines to learn about serious or highly stigmatic conditions,
a surprising amount of sensitive health information is also sought and shared via
social media, in our case the public social plat-form Twitter. We contrast what health
content people seek via search engines vs. share on social media, as well as why they
choose a particular platform for online health activi-ties. We reflect on the implications
of our results for design-ing search engines, social media, and social search tools
that better support people's health information seeking and sharing needs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1365–1376},
numpages = {12},
keywords = {twitter, search engine, social search, health, social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250949,
author = {Weibel, Nadir},
title = {Session Details: On and above the Surface},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250949},
doi = {10.1145/3250949},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557336,
author = {Kim, David and Izadi, Shahram and Dostal, Jakub and Rhemann, Christoph and Keskin, Cem and Zach, Christopher and Shotton, Jamie and Large, Timothy and Bathiche, Steven and Nie\ss{}ner, Matthias and Butler, D. Alex and Fanello, Sean and Pradeep, Vivek},
title = {RetroDepth: 3D Silhouette Sensing for High-Precision Input on and above Physical Surfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557336},
doi = {10.1145/2556288.2557336},
abstract = {We present RetroDepth, a new vision-based system for accurately sensing the 3D silhouettes
of hands, styluses, and other objects, as they interact on and above physical surfaces.
Our setup is simple, cheap, and easily reproducible, comprising of two infrared cameras,
diffuse infrared LEDs, and any off-the-shelf retro-reflective material. The retro-reflector
aids image segmentation, creating a strong contrast between the surface and any object
in proximity. A new highly efficient stereo matching algorithm precisely estimates
the 3D contours of interacting objects and the retro-reflective surfaces. A novel
pipeline enables 3D finger, hand and object tracking, as well as gesture recognition,
purely using these 3D contours. We demonstrate high-precision sensing, allowing robust
disambiguation between a finger or stylus touching, pressing or interacting above
the surface. This allows many interactive scenarios that seamlessly mix together freehand
3D interactions with touch, pressure and stylus input. As shown, these rich modalities
of input are enabled on and above any retro-reflective surface, including custom "physical
widgets" fabricated by users. We compare our system with Kinect and Leap Motion, and
conclude with limitations and future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1377–1386},
numpages = {10},
keywords = {depth sensing, vision-based uis, stereo matching, 3D contours, nui, contour classification, stylus, touch, 3D input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557120,
author = {Goel, Mayank and Lee, Brendan and Islam Aumi, Md. Tanvir and Patel, Shwetak and Borriello, Gaetano and Hibino, Stacie and Begole, Bo},
title = {SurfaceLink: Using Inertial and Acoustic Sensing to Enable Multi-Device Interaction on a Surface},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557120},
doi = {10.1145/2556288.2557120},
abstract = {We present SurfaceLink, a system where users can make natural surface gestures to
control association and information transfer among a set of devices that are placed
on a mutually shared surface (e.g., a table). SurfaceLink uses a combination of on-device
accelerometers, vibration motors, speakers and microphones (and, optionally, an off-device
contact microphone for greater sensitivity) to sense gestures performed on the shared
surface. In a controlled evaluation with 10 participants, SurfaceLink detected the
presence of devices on the same surface with 97.7% accuracy, their relative arrangement
with 89.4% accuracy, and various single- and multi-touch surface gestures with an
average accuracy of 90.3%. A usability analysis showed that SurfaceLink has advantages
over current multi-device interaction techniques in a number of situations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1387–1396},
numpages = {10},
keywords = {multi-device interaction, surface interaction, acoustic sensing, mobile phones, inertial sensing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557276,
author = {Pan, Ye and Steptoe, William and Steed, Anthony},
title = {Comparing Flat and Spherical Displays in a Trust Scenario in Avatar-Mediated Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557276},
doi = {10.1145/2556288.2557276},
abstract = {We report on two experiments that investigate the influence of display type and viewing
angle on how people place their trust during avatar-mediated interaction. By monitoring
advice seeking behavior, our first experiment demonstrates that if participants observe
an avatar at an oblique viewing angle on a flat display, they are less able to discriminate
between expert and non-expert advice than if they observe the avatar face-on. We then
introduce a novel spherical display and a ray-traced rendering technique that can
display an avatar that can be seen correctly from any viewing direction. We expect
that a spherical display has advantages over a flat display because it better supports
non-verbal cues, particularly gaze direction, since it presents a clear and undistorted
viewing aspect at all angles. Our second experiment compares the spherical display
to a flat display. Whilst participants can discriminate expert advice regardless of
display, a negative bias towards the flat screen emerges at oblique viewing angles.
This result emphasizes the ability of the spherical display to be viewed qualitatively
similarly from all angles. Together the experiments demonstrate how trust can be altered
depending on how one views the avatar.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1397–1406},
numpages = {10},
keywords = {spherical displays, avatars, trust, mixed reality, telecommunication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557173,
author = {Gong, Nan-Wei and Steimle, J\"{u}rgen and Olberding, Simon and Hodges, Steve and Gillian, Nicholas Edward and Kawahara, Yoshihiro and Paradiso, Joseph A.},
title = {PrintSense: A Versatile Sensing Technique to Support Multimodal Flexible Surface Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557173},
doi = {10.1145/2556288.2557173},
abstract = {We present a multimodal on-surface and near-surface sensing technique for planar,
curved and flexible surfaces. Our technique leverages temporal multiplexing of signals
coming from a universal interdigitated electrode design, which is printed as a single
conductive layer on a flexible substrate. It supports sensing of touch and proximity
input, and moreover is capable of capturing several levels of pressure and flexing.
We leverage recent developments in conductive inkjet printing as a way to prototype
electrode patterns, and combine this with our hardware module for supporting the full
range of sensing methods. As the technique is low-cost and easy to implement, it is
particularly well-suited for prototyping touch- and hover-based user interfaces, including
curved and deformable ones.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1407–1410},
numpages = {4},
keywords = {"interactive surface, flexible sensor, touch input, conductive inkjet printed electronics", multimodal input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557316,
author = {Jota, Ricardo and Lopes, Pedro and Wigdor, Daniel and Jorge, Joaquim},
title = {Let's Kick It: How to Stop Wasting the Bottom Third of Your Large Screen Display},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557316},
doi = {10.1145/2556288.2557316},
abstract = {Large-scale touch surfaces have been widely studied in literature and adopted for
public installations such as interactive billboards. However, current designs do not
take into consideration that touching the interactive surface at different heights
is not the same; for body-height displays, the bottom portion of the screen is within
easier reach of the foot than the hand. We explore the design space of foot input
on vertical surfaces, and propose three distinct interaction modalities: hand, foot
tapping, and foot gesturing. Our design exploration pays particular attention to areas
of the touch surface that were previously overlooked: out of hand's reach and close
to the floor. We instantiate our design space with a working prototype of an interactive
surface, in which we are able to distinguish between finger and foot tapping and extend
the input area beyond the bottom of the display to support foot gestures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1411–1414},
numpages = {4},
keywords = {foot interaction, large-scale display, kick, floor input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250950,
author = {Butz, Andreas},
title = {Session Details: Interactive Whiteboards and Public Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250950},
doi = {10.1145/3250950},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557001,
author = {M\"{u}ller, J\"{o}rg and Eberle, Dieter and Tollmar, Konrad},
title = {Communiplay: A Field Study of a Public Display Mediaspace},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557001},
doi = {10.1145/2556288.2557001},
abstract = {We present Communiplay, a public display media space. People passing by see their
own contour mirrored on a public display and can start to play with virtual objects.
At the same time, they see others playing at remote displays within the same virtual
space. We are interested whether people would use such a public display media space,
and if so, how and why. We evaluate Communiplay in a field study in six connected
locations and find a remote honey-pot effect, i.e. people interacting at one location
attract people at other locations. The conversion rate (percentage of passers-by starting
to interact) rose by +136% when people saw others playing at remote locations. We
also provide the first quantification of the (local) honey-pot effect (in our case
it raised the conversion rate by +604% when people saw others playing at the same
location). We conclude that the integration of multiple public displays into a media
space is a promising direction for public displays and can make them more attractive
and valuable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1415–1424},
numpages = {10},
keywords = {public displays, media space, in-the-wild study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556970,
author = {Fortin, Claude and Neustaedter, Carman and Hennessy, Kate},
title = {Posting for Community and Culture: Considerations for the Design of Interactive Digital Bulletin Boards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556970},
doi = {10.1145/2556288.2556970},
abstract = {The next decade is likely to see a shift in digital public displays moving from non-interactive
to interactive content. This will likely create a need for digital bulletin boards
and for a better understanding of how such displays should be designed to encourage
community members to interact with them. Our study addresses this by exploring community
bulletin boards as a ubiquitous type of participatory non-digital display "in the
wild". Our results highlight how they are used for content of local and contextual
relevance, and how cultures of participation, personalization, location, the tangible
character of architecture, access, control and flexibility might affect community
members' level of engagement with them. Our analysis suggests entry points as design
considerations intrinsically linked to the users' sense of agency within a delineated
space. Overlaps with related work are identified throughout to provide further validation
of previous findings in this area of research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1425–1434},
numpages = {10},
keywords = {urban computing, digital bulletin boards, entry points, large public displays, observation, cultures of participation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557186,
author = {Greis, Miriam and Alt, Florian and Henze, Niels and Memarovic, Nemanja},
title = {I Can Wait a Minute: Uncovering the Optimal Delay Time for Pre-Moderated User-Generated Content on Public Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557186},
doi = {10.1145/2556288.2557186},
abstract = {Public displays have advanced from isolated and non interactive "ad" displays which
show images and videos to displays that are networked, interactive, and open to a
wide variety of content and applications. Prior work has shown large potential of
user-generated content on public displays. However, one of the problems with user-generated
content on public displays is moderation as content may be explicit or troublesome
for a particular location. In this work we explore the expectations of users with
regard to content moderation on public displays. An online survey revealed that people
not only think that display content should be moderated but also that a delay of up
to 10 minutes is acceptable if display content is moderated. In a subsequent in the
wild deployment we compared different moderation delays. We found that a moderation
delay significantly decreases the number of user-generated posts while at the same
time there is no significant effect on users' decision to repeatedly post on the display.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1435–1438},
numpages = {4},
keywords = {twitter, public displays, content moderation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250951,
author = {Ju, Wendy},
title = {Session Details: Human-Robot Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250951},
doi = {10.1145/3250951},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557057,
author = {Saupp\'{e}, Allison and Mutlu, Bilge},
title = {Design Patterns for Exploring and Prototyping Human-Robot Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557057},
doi = {10.1145/2556288.2557057},
abstract = {Robotic products are envisioned to offer rich interactions in a range of environments.
While their specific roles will vary across applications, these products will draw
on fundamental building blocks of interaction, such as greeting people, narrating
information, providing instructions, and asking and answering questions. In this paper,
we explore how such building blocks might serve as interaction design patterns that
enable design exploration and prototyping for human-robot interaction. To construct
a pattern library, we observed human interactions across different scenarios and identified
seven patterns, such as question-answer pairs. We then designed and implemented Interaction
Blocks, a visual authoring environment that enabled prototyping of robot interactions
using these patterns. Design sessions with designers and developers demonstrated the
promise of using a pattern language for designing robot interactions, confirmed the
usability of our authoring environment, and provided insights into future research
on tools for human-robot interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1439–1448},
numpages = {10},
keywords = {prototyping, interaction design, human-robot interaction, design patterns, design sessions, design exploration, authoring environment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557180,
author = {Pereira, Andr\'{e} and Prada, Rui and Paiva, Ana},
title = {Improving Social Presence in Human-Agent Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557180},
doi = {10.1145/2556288.2557180},
abstract = {Humans have a tendency to consider media devices as social beings. Social agents and
artificial opponents can be examined as one instance of this effect. With today's
technology it is already possible to create artificial agents that are perceived as
socially present. In this paper, we start by identifying the factors that influence
perceptions of social presence in human-agent interactions. By taking these factors
into account and by following previously defined guidelines for building socially
present artificial opponents, a case study was created in which a social robot plays
the Risk board game against three human players. An experiment was performed to ascertain
whether the agent created in this case study is perceived as socially present. The
experiment suggested that by following the guidelines for creating socially present
artificial board game opponents, the perceived social presence of users towards the
artificial agent improves.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1449–1458},
numpages = {10},
keywords = {board games, social presence, human-robot interaction (hri), artificial opponents},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557274,
author = {Lohse, Manja and Rothuis, Reinier and Gallego-P\'{e}rez, Jorge and Karreman, Daphne E. and Evers, Vanessa},
title = {Robot Gestures Make Difficult Tasks Easier: The Impact of Gestures on Perceived Workload and Task Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557274},
doi = {10.1145/2556288.2557274},
abstract = {Gestures are important non-verbal signals in human communication. Research with virtual
agents and robots has started to add to the scientific knowledge about gestures but
many questions with respect to the use of gestures in human-computer interaction are
still open. This paper investigates the influence of robot gestures on the users'
perceived workload and task performance (i.e. information recall) in a direction-giving
task. We conducted a 2 x 2 (robot gestures vs. no robot gestures x easy vs. difficult
task) experiment. The results indicate that robot gestures increased user performance
and decreased perceived workload in the difficult task but not in the easy task. Thus,
robot gestures are a promising means to improve human-robot interaction particularly
in challenging tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1459–1466},
numpages = {8},
keywords = {perceived workload, gestures, task performance, human-robot interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557174,
author = {Bidwell, Jonathan and Holloway, Alexandra and Davidoff, Scott},
title = {Measuring Operator Anticipatory Inputs in Response to Time-Delay for Teleoperated Human-Robot Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557174},
doi = {10.1145/2556288.2557174},
abstract = {Many tasks call for efficient user interaction under time delay-controlling space
instruments, piloting remote aircraft and operating search and rescue robots. In this
paper we identify an underexplored design opportunity for building robotic teleoperation
user interfaces following an evaluation of operator performance during a time-delayed
robotic arm block-stacking task in twenty-two participants. More delay resulted in
greater operator hesitation and a decreased ratio of active to inactive input. This
ratio can serve as a useful proxy for measuring an operator's ability to anticipate
the outcome of their control inputs before receiving delayed visual feedback. High
anticipatory input ratio (AIR) scores indicate times when robot operators enter commands
before waiting for visual feedback. Low AIR scores highlight when operators must wait
for visual feedback before continuing. We used this measurement to help us identify
particular sub-tasks where operators would likely benefit from additional support.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1467–1470},
numpages = {4},
keywords = {human-robot interface, teleoperation, time delay, metric},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557395,
author = {Lee, Hee Rin and \v{S}abanovic, Selma and Stolterman, Erik},
title = {Stay on the Boundary: Artifact Analysis Exploring Researcher and User Framing of Robot Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557395},
doi = {10.1145/2556288.2557395},
abstract = {In recent years, HCI researchers have increased their focus on studying the power
relationships between researchers and users, and developing methodologies for eliciting
design ideas that are sensitive to existing epistemic hierarchies in technology design.
The differential value given to expert versus lay knowledge is a central factor in
these debates. We apply Artifact Analysis, developed to help designers handle the
complexity of digital artifacts, as a method to explore how experts and non-experts
understand and frame robots, a technology characterized by significant complexity.
Our results show that both non-expert users and expert researchers have knowledge
that is significant to future robot development, but they focus on different aspects
of the technology - users address mediated and interaction complexity while researchers
focus on internal and external complexity. We also found that robots function as boundary
objects between experts and users, and suggest that one task designers can perform
is to "stay on the boundary" and mediate between the different ways in which experts
and non-experts frame emerging technology to develop designs that benefit from insights
from both user and researcher perspectives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1471–1474},
numpages = {4},
keywords = {artifact analysis, epistemic hierarchy, boundary objects},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250952,
author = {Cranor, Lorrie},
title = {Session Details: Emergency Response},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250952},
doi = {10.1145/3250952},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557002,
author = {Al-Akkad, Amro and Ramirez, Leonardo and Boden, Alexander and Randall, Dave and Zimmermann, Andreas},
title = {Help Beacons: Design and Evaluation of an Ad-Hoc Lightweight s.o.s. System for Smartphones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557002},
doi = {10.1145/2556288.2557002},
abstract = {We present the design and evaluation of a lightweight mobile S.O.S. system that facilitates
ad-hoc communication between first responders and victims in emergency situations.
Our approach leverages established protocols and standards in unforeseen ways to provide
a platform supporting the creation of short-lived communication links. The system
comprises two mobile applications: one victim application that allows the broadcasting
of distress signals by a novel use of Wi-Fi SSIDs; and a responder application that
allows first responders to discover and trace the people broadcasting the signals.
The main difference of our system with other platforms enabling communication in crisis
situations is that our system is independent from existing network infrastructure
and runs on off-the-shelf, commercially available smartphones. We describe the results
of our evaluation process in the context of both a design evaluation during a real-world
emergency response exercise and of two user workshops in preparation for an upcoming
large-scale exercise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1485–1494},
numpages = {10},
keywords = {emergency response, mobile computing, ad-hoc communication, smartphones},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557140,
author = {Leavitt, Alex and Clark, Joshua A.},
title = {Upvoting Hurricane Sandy: Event-Based News Production Processes on a Social News Site},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557140},
doi = {10.1145/2556288.2557140},
abstract = {This paper uses the case of Hurricane Sandy and reddit's topical community (subreddit)
/r/sandy to examine the production and curation of news content around events on a
social news site. Through qualitative analysis, we provide a coded topology of produced
content and describe how types of networked gatekeeping impact the framing of a crisis
situation. This study also examines, through quantitative modeling, what kind of information
becomes negotiated and voted as relevant. We suggest that highly scored content shared
in a social news setting focused more on human-interest media and perspective-based
citizen journalism than professional news reports. We conclude by discussing how the
mechanisms of social news sites conflict with the social norms and culture of reddit
to produce differing expectations around news.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1495–1504},
numpages = {10},
keywords = {networked gatekeeping, mixed methods, news production, news framing, reddit, social news site, crisis communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557227,
author = {Hughes, Amanda L. and St. Denis, Lise A. A. and Palen, Leysia and Anderson, Kenneth M.},
title = {Online Public Communications by Police &amp; Fire Services during the 2012 Hurricane Sandy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557227},
doi = {10.1145/2556288.2557227},
abstract = {Social media and other online communication tools are a subject of great interest
in mass emergency response. Members of the public are turning to these solutions to
seek and offer emergency information. Emergency responders are working to determine
what social media policies should be in terms of their "public information" functions.
We report on the online communications from all the coastal fire and police departments
within a 100 mile radius of Hurricane Sandy's US landfall. Across four types of online
communication media, we collected data from 840 fire and police departments. Findings
indicate that few departments used these online channels in their Sandy response efforts,
and that communications differed between fire and police departments and across media
type. However, among the highly engaged departments, there is evidence that they bend
and adapt policies about what constitutes appropriate public communication in the
face of emergency demands; therefore, we propose that flexibility is important in
considering future emergency online communication policy. We conclude with design
recommendations for making online communication media more "listenable" for both emergency
managers and members of the public.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1505–1514},
numpages = {10},
keywords = {risk communication, emergency, social computing, crisis informatics, social media, microblogging, disaster},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557188,
author = {Betz, Matthias and Wulf, Volker},
title = {EmergencyMessenger: A Text Based Communication Concept for Indoor Firefighting},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557188},
doi = {10.1145/2556288.2557188},
abstract = {Finding and rescuing missing or injured people or fighting fire inside burning buildings
is a central challenge for fire brigades. To ensure the safety of indoor work, monitoring
the operations of firefighting units is crucial. As in most countries, firefighters
in Germany utilize radio sets to establish voice communication between indoor operating
units and the supervisory structure outside. Based on findings from a long term ethnographic
study in cooperation with different German fire brigades over a time span of more
than 5 years we analyzed the advantages and disadvantages of the current voice over
radio communication tactics and techniques. We designed and evaluated a complementary
text based communication device the EMERGENCY-MESSENGER to support the time critical
work of indoor units working under harsh conditions, wearing Self-Contained-Breathing-Apparatus
(SCBA). We conducted 13 full scale training missions including extensive debriefings
to design and evaluate the communication concept and the corresponding device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1515–1524},
numpages = {10},
keywords = {cooperation, communication, monitoring, messaging, firefighting, security, safety, autonomy, text, indoor},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251008,
author = {Bigham, Jeffrey},
title = {Session Details: Sensemaking and Information in Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251008},
doi = {10.1145/3251008},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556959,
author = {Hailpern, Joshua M. and Huberman, Bernardo A.},
title = {Odin: Contextual Document Opinions on the Go},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556959},
doi = {10.1145/2556288.2556959},
abstract = {Information overload is a systemic problem for knowledge workers in enterprise. For
a long time, information was scarce and therefore valuable. While, the explosion of
digital information has made information plentiful, time to read and process that
content is now scarce. This problem is only exacerbated by our increased mobility,
and the expectation to be "on top" of the continuous barrage of documents while on
the go. Knowledge workers in enterprise need solutions that are designed with quick
methods for finding what to read in a large collection of documents (e.g. financial
reports, legal documents, news), and ways of presenting it within small visual real
estate. Unlike reviews, document collections are long, more varied, and context is
extremely important. In response, we present Odin, a mobile web-based window onto
a user's document corpus. Rather than performing corpus summarization, Odin users
can quickly find opinions and documents that are Aligned or Divergent from the corpus'
consensus, or those that are the most Relevant given the overall corpus' of opinions.
Odin presents this information through a simple and intuitive mobile interface. To
the authors' knowledge, this is the first UI/system (and support algorithm) to allow
mobile users to place documents and their opinions in context through alignment rather
than raw word count or sentiment. Positive results from two evaluations are also presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1525–1534},
numpages = {10},
keywords = {mobile, opinions, interaction, divergence, interface, economics of attention, consensus, alignment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557083,
author = {D\"{o}rk, Marian and Comber, Rob and Dade-Robertson, Martyn},
title = {Monadic Exploration: Seeing the Whole through Its Parts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557083},
doi = {10.1145/2556288.2557083},
abstract = {Monadic exploration is a new approach to interacting with relational information spaces
that challenges the distinction between the whole and its parts. Building on the work
of sociologists Gabriel Tarde and Bruno Latour we turn to the concept of the monad
as a useful lens on online communities and collections that expands the possibility
for creating meaning in their navigation. While existing interfaces tend to emphasize
either the structure of the whole or details of a part, monadic exploration brings
these opposing perspectives closer together in continuous movements between partially
overlapping points of view. We present a visualization that reflects a given node's
relative position within a network using radial displacements and visual folding.
To investigate the potential of monadic exploration we report on an iterative design
process of a web-based visualization of a highly cross-referenced book and its six-month
deployment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1535–1544},
numpages = {10},
keywords = {philosophy, theory, information seeking, network visualization, exploratory search, information visualization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557192,
author = {Yue, Zhen and Litt, Eden and Cai, Carrie J. and Stern, Jeff and Baxter, Kathy K. and Guan, Zhiwei and Sharma, Nikhil and Zhang, Guangqiang (George)},
title = {Photographing Information Needs: The Role of Photos in Experience Sampling Method-Style Research},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557192},
doi = {10.1145/2556288.2557192},
abstract = {The Experience Sampling Method (ESM) enables researchers to capture information about
participants' experiences in the moment. Adding an end-of-day retrospective survey
also allows participants to elaborate on those experiences. Although the use of photos
in retrospective interviews and surveys for memory elicitation is well known, little
research has investigated the use of photos in ESM studies. As smartphone adoption
increases facilitating ESM studies and making photo sharing easier, researchers need
to continuously evaluate the method and investigate the role of photos in such studies.
We conducted a large-scale ESM and retrospective survey study via Android smartphones
with more than 1,000 US participants, and analyzed participants' photo submissions,
including how photo use correlated with participants' data quality and what, if any,
value photos added for researchers. Our study sheds light on the role of photos in
ESM and retrospective studies that researchers can reference when constructing future
study designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1545–1554},
numpages = {10},
keywords = {photo-elicitation, retrospective study method, experience sampling method, information need},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557284,
author = {Vigo, Markel and Jay, Caroline and Stevens, Robert},
title = {Design Insights for the next Wave Ontology Authoring Tools},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557284},
doi = {10.1145/2556288.2557284},
abstract = {Ontologies have been employed across scientific and business domains for some time,
and the proliferation of linked data means the number and range of potential authors
is set to increase significantly. Ontologies using the Web Ontology Language (OWL)
are complex artefacts, however: the authoring process requires not only knowledge
of the application domain, but also skills in programming and logics. To date, there
has been no systematic attempt to understand the effectiveness of existing tools,
or explore what users really require to build successful ontologies. Here we address
this shortfall, presenting insights from an interview study with 15 ontology authors.
We identify the problems reported by authors, and the strategies they employ to solve
them. We map the data to a set of design recommendations, which describe how tools
of the future can support ontology authoring. A key challenge is dealing with information
overload: improving the user's ability to navigate, populate and debug large ontologies
will revolutionise the engineering process, and open ontology authoring up to a new
generation of users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1555–1558},
numpages = {4},
keywords = {semantic web, ontologies, authoring tools},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557337,
author = {Sun, Maoyuan and Bradel, Lauren and North, Chris L. and Ramakrishnan, Naren},
title = {The Role of Interactive Biclusters in Sensemaking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557337},
doi = {10.1145/2556288.2557337},
abstract = {Visual exploration of relationships within large, textual datasets is an important
aid for human sensemaking. By understanding computed, structural relationships between
entities of different types (e.g., people and locations), users can leverage domain
expertise and intuition to determine the importance and relevance of these relationships
for tasks, such as intelligence analysis. Biclusters are a potentially desirable method
to facilitate this, because they reveal coordinated relationships that can represent
meaningful relationships. Bixplorer, a visual analytics prototype, supports interactive
exploration of textual datasets in a spatial workspace with biclusters. In this paper,
we present results of a study that analyzes how users interact with biclusters to
solve an intelligence analysis problem using Bixplorer. We found that biclusters played
four principal roles in the analytical process: an effective starting point for analysis,
a revealer of two levels of connections, an indicator of potentially important entities,
and a useful label for clusters of organized information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1559–1562},
numpages = {4},
keywords = {biclustering, intelligence analysis, visual interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251009,
author = {Zhao, Shengdong},
title = {Session Details: Presentation Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251009},
doi = {10.1145/3251009},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557161,
author = {Li, Xiang and Rekimoto, Jun},
title = {SmartVoice: A Presentation Support System for Overcoming the Language Barrier},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557161},
doi = {10.1145/2556288.2557161},
abstract = {In most cases, speeches or presentations at an international event are required to
be given in a common language (e.g. English). However, for people who are not proficient
in that common language, delivering presentations fluently is very difficult. Simultaneous
translation seems to be a solution, but besides its high cost, simultaneous translation
undermines the nature of the presentation by substituting the real voice of the lecturer
as well as his/her emotions. In this paper, we propose "SmartVoice", a presentation
support system, which aims to overcome language barriers. By tracking the lip motion
of the lecturer, SmartVoice controls the playback of the narration, which is a sound
data prepared in advance or created automatically using a voice synthesizer. SmartVoice
also controls the intonation of the sound based on the position and shape of the lecturer's
mouth. As the lecturer can talk at his/her own pace with the voice automatically following,
it appears as if he/she talks in his/her own voice. In our user evaluation, we confirmed
that audiences find it difficult to distinguish between the narration generated by
SmartVoice and that by a real voice. We also discuss the possibility of applying SmartVoice
to fields other than multi-language presentation support, such as Automated Dialogue
Replacement and language study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1563–1570},
numpages = {8},
keywords = {language barrier, user interface, face tracking, lip sync, facial actions, presentation support},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557286,
author = {Trinh, Ha and Yatani, Koji and Edge, Darren},
title = {PitchPerfect: Integrated Rehearsal Environment for Structured Presentation Preparation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557286},
doi = {10.1145/2556288.2557286},
abstract = {Rehearsal is a critical component of preparing to give an oral presentation, yet it
is frequently abbreviated, performed in ways that are inefficient or ineffective,
or simply omitted. We conducted an exploratory study to understand the relationship
between the theory and practice of presentation rehearsal, classifying our qualitative
results into five themes to motivate more structured rehearsal support deeply integrated
in slide presentation software. In a within-subject study (N=12) comparing against
participants' existing rehearsal practices, we found that our resulting PitchPerfect
system significantly improved overall presentation quality and content coverage as
well as provided greater support for content mastery, time management, and confidence
building.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1571–1580},
numpages = {10},
keywords = {slideware, powerpoint, presentation rehearsal},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557254,
author = {Chi, Pei-Yu and Lee, Bongshin and Drucker, Steven M.},
title = {DemoWiz: Re-Performing Software Demonstrations for a Live Presentation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557254},
doi = {10.1145/2556288.2557254},
abstract = {Showing a live software demonstration during a talk can be engaging, but it is often
not easy: presenters may struggle with (or worry about) unexpected software crashes
and encounter issues such as mismatched screen resolutions or faulty network connectivity.
Furthermore, it can be difficult to recall the steps to show while talking and operating
the system all at the same time. An alternative is to present with pre-recorded screencast
videos. It is, however, challenging to precisely match the narration to the video
when using existing video players. We introduce DemoWiz, a video presentation system
that provides an increased awareness of upcoming actions through glanceable visualizations.
DemoWiz supports better control of timing by overlaying visual cues and enabling lightweight
editing. A user study shows that our design significantly improves the presenters'
perceived ease of narration and timing compared to a system without visualizations
that was similar to a standard playback control. Furthermore, nine (out of ten) participants
preferred DemoWiz over the standard playback control with the last expressing no preference.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1581–1590},
numpages = {10},
keywords = {software demo, presentation, video, demonstration, demo},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557389,
author = {Pschetz, Larissa and Yatani, Koji and Edge, Darren},
title = {TurningPoint: Narrative-Driven Presentation Planning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557389},
doi = {10.1145/2556288.2557389},
abstract = {Once upon a time, people told stories unencumbered by slides. What modern presentations
gain through visual slide support, however, is often at the expense of storytelling.
We present TurningPoint, a probe to investigate the potential use of narrative-driven
talk planning in slideware. Our study of TurningPoint reveals a delicate balance between
narrative templates focusing author attention in ways that save time, and fixating
attention in ways that limit experimentation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1591–1594},
numpages = {4},
keywords = {storytelling, narrative templates, slide presentations},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251010,
author = {Huh, Jina},
title = {Session Details: Personal Health and Wellbeing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251010},
doi = {10.1145/3251010},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557236,
author = {Joshi, Anirudha and Rane, Mandar and Roy, Debjani and Emmadi, Nagraj and Srinivasan, Padma and Kumarasamy, N. and Pujari, Sanjay and Solomon, Davidson and Rodrigues, Rashmi and Saple, D.G. and Sen, Kamalika and Veldeman, Els and Rutten, Romain},
title = {Supporting Treatment of People Living with HIV / AIDS in Resource Limited Settings with IVRs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557236},
doi = {10.1145/2556288.2557236},
abstract = {We developed an interactive voice response (IVR) system called TAMA (Treatment Advice
by Mobile Alerts) that provides treatment support to people living with HIV / AIDS
(PLHA) in developing countries, who are on antiret-roviral therapy (ART). We deployed
TAMA with 54 PLHA in 5 HIV clinics in India for a period of 12 weeks. During the study,
we gathered feedback about TAMA's design and usage. Additionally, we conducted detailed
qualitative interviews and analysed usage logs. We found that TAMA was usable and
viable in the real life settings of PLHA and it had many desirable effects on their
treatment adherence. We developed insights that inform the design of TAMA and some
of these can be generalised to design of other long-term, frequent-use IVR applications
for users in developing countries in the healthcare domain and beyond.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1595–1604},
numpages = {10},
keywords = {tama, hiv, aids, treatment support, ivr, developing countries, healthcare, frequent-use applications},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557119,
author = {Brown, Deana and Ayo, Victoria and Grinter, Rebecca E.},
title = {Reflection through Design: Immigrant Women's Self-Reflection on Managing Health and Wellness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557119},
doi = {10.1145/2556288.2557119},
abstract = {Women comprise nearly half of the immigrant population worldwide and are susceptible
to a wider range of health challenges compared to immigrant men. We present the findings
of four participatory design sessions with immigrant women from the Caribbean to identify
health and wellness challenges they faced and to conceptualize technologies to help
them manage these issues. Stress, dietary challenges (specifically obesity), mental
health, and domestic abuse, as identified by the women, form the focal themes for
the design sessions. Their design approaches emphasized rebuilding the support structure,
reducing stressors through entertainment and relaxation and encouraging positive gradational
lifestyle changes. In conceiving health and wellness technologies for immigrant women,
our work highlights opportunities for HCI to consider the role of others (and who
benefits) and to reflect on the role of design and the underlying values and themes
designs encompass. Finally, we emphasize how the technologies conceived by these women
support rather than replace social solutions to the health and wellness challenges
faced by these and other immigrant women.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1605–1614},
numpages = {10},
keywords = {participatory design, culture, caribbean, health and wellness, immigrant women},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557077,
author = {Haimson, Oliver L. and Brubaker, Jed R. and Hayes, Gillian R.},
title = {DDFSeeks Same: Sexual Health-Related Language in Online Personal Ads for Men Who Have Sex with Men},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557077},
doi = {10.1145/2556288.2557077},
abstract = {The HIV/AIDS crisis of the 1980s fundamentally changed sexual practices of men who
have sex with men (MSM) in the U.S., including increased usage of sexual health-related
(SHR) language in personal advertisements. Analyzing online personal ads from Craigslist,
we found a substantial increase in SHR language, from ~23% in 1988 to over 53% today,
echoing continuing concern about rising HIV rates. We argue that SHR language in Craigslist
ads can be used as a sensor to provide insight into HIV epidemiology as well as discourse
among particular communities. We show a positive significant relationship between
prevalence rate of HIV in an ad's location and use of SHR language in that location.
Analysis highlights the opportunity for SHR information found in Craigslist personal
ads to serve as a data source for HIV prevention research. More broadly, we argue
for mining large-scale user-generated content to inform HCI design of health and other
systems, and explore use of such data to examine temporal changes in language to facilitate
improved user-interface design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1615–1624},
numpages = {10},
keywords = {personal ads, digital identity, lgbt, health informatics, online dating, computational linguistics, craigslist, hiv/aids},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557108,
author = {Vlahovic, Tatiana A. and Wang, Yi-Chia and Kraut, Robert E. and Levine, John M.},
title = {Support Matching and Satisfaction in an Online Breast Cancer Support Community},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557108},
doi = {10.1145/2556288.2557108},
abstract = {Research suggests that online health support benefits chronically ill users. Their
satisfaction might be an indicator that they perceive group interactions as beneficial
and a precursor to group commitment. We examined whether receiving emotional and informational
support is satisfying in its own right, or whether satisfaction depends on matches
between what users sought and what they received. Two studies collected judgments
in a breast cancer support community of support users sought, support they received,
and their expressed satisfaction. While receiving emotional or informational support
in general positively predicted satisfaction, users expressed less satisfaction when
they sought informational support but received emotional support. There was also a
tendency for users to express more satisfaction when they sought and received informational
support. On the other hand, users were equally satisfied with emotional and informational
support after seeking emotional support. Implications for membership commitment and
interventions in online support groups are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1625–1634},
numpages = {10},
keywords = {social support, computer-mediated communication, breast cancer, support groups, health informatics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251011,
author = {Harrison, Steve},
title = {Session Details: Design Theory},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251011},
doi = {10.1145/3251011},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557342,
author = {Dalsgaard, Peter and Dindler, Christian},
title = {Between Theory and Practice: Bridging Concepts in HCI Research},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557342},
doi = {10.1145/2556288.2557342},
abstract = {We present the notion of "bridging concepts" as a particular form of intermediary
knowledge in HCI research, residing between theory and practice. We argue that bridging
concepts address the challenge of facilitating exchange between theory and practice
in HCI, and we compare it to other intermediary forms of knowledge such as strong
concepts and conceptual constructs. We propose that bridging concepts have three defining
constituents: a theoretical foundation, a set of design articulations and a range
of exemplars that demonstrate the scope and potential of their application. These
constituents specify how bridging concepts, as a form of knowledge, are accountable
to both theory and practice. We present an analysis of the concept of "peepholes"
as an example of a bridging concept aimed at spurring user curiosity and engagement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1635–1644},
numpages = {10},
keywords = {interaction design theory, analytical frameworks, engagement, experience-oriented design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557264,
author = {Gray, Colin M.},
title = {Evolution of Design Competence in UX Practice},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557264},
doi = {10.1145/2556288.2557264},
abstract = {There has been increasing interest in the adoption of UX within corporate environments,
and what competencies translate into effective UX design. This paper addresses the
space between pedagogy and UX practice through the lens of competence, with the goal
of understanding how students are initiated into the practice community, how their
perception of competence shifts over time, and what factors influence this shift.
A 12-week longitudinal data collection, including surveys and interviews, documents
this shift, with participants beginning internships and full-time positions in UX.
Students and early professionals were asked to assess their level of competence and
factors that influenced competence. A co-construction of identity between the designer
and their environment is proposed, with a variety of factors relating to tool and
representational knowledge, complexity, and corporate culture influencing perceptions
of competence in UX over time. Opportunities for future research, particularly in
building an understanding of competency in UX based on this preliminary framing of
early UX practice are addressed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1645–1654},
numpages = {10},
keywords = {competence, design capability, expertise, ux practice, identity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557216,
author = {Darlow, Adam and Goldin, Gideon and Sloman, Steven},
title = {Causal Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557216},
doi = {10.1145/2556288.2557216},
abstract = {In this paper we present two design guidelines, causal order and continuity, to be
used as rules of thumb for designing intuitive interactions based on principles of
causal reasoning. We propose that designing interactions to behave like real-world
systems of cause and effect makes them more intuitive. Using these basic principles
avoids the limitations inherent to specific metaphors. In three experiments, participants
solved puzzles using variations of a novel graphical interface. Participants using
interfaces that were consistent with the causal guidelines consistently solved the
puzzle faster than participants using inconsistent interfaces. We also discuss common
interactions already consistent with the causal guidelines as well as areas where
the guidelines are likely to apply successfully. The causal order guidelines provide
specific utility while also demonstrating how principles of causal psychology can
be applied to help interface designers better convey the functionality of their interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1655–1664},
numpages = {10},
keywords = {design guidelines, graphical interfaces, psychology, gui, interaction design, causal reasoning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557080,
author = {Nielsen, Lene and Storgaard Hansen, Kira},
title = {Personas is Applicable: A Study on the Use of Personas in Denmark},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557080},
doi = {10.1145/2556288.2557080},
abstract = {The persona method is gaining widespread use and support. Many researchers have reported
from single cases and novel domains how they have used the method. Few have conducted
literature studies in order to identify and discuss the different understandings of
the method. Fewer still have reported on ethnographic studies of practice. This paper
falls within the last category, reporting on a study on how practitioners in Denmark
use the method, and their perceptions of benefits and challenges when using the method.
Finally, different casts of personas obtained from the involved companies are analyzed.
The findings are compared to reported studies of practice. Contrary to the existing
findings the study reports that the method is well integrated into existing practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1665–1674},
numpages = {10},
keywords = {scenarios, application, personas, practice-study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251012,
author = {Lyons, Kent},
title = {Session Details: Novel Keyboards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251012},
doi = {10.1145/3251012},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557362,
author = {Zhang, Haimo and Li, Yang},
title = {GestKeyboard: Enabling Gesture-Based Interaction on Ordinary Physical Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557362},
doi = {10.1145/2556288.2557362},
abstract = {Stroke gestures are intuitive and efficient but often require gesture-capable input
hardware such as a touchscreen. In this paper, we present GestKeyboard, a novel technique
for gesturing over an ordinary, unmodified physical keyboard that remains the major
input modality for existing desktop and laptop computers. We discuss an exploratory
study for understanding the design space of gesturing on a physical keyboard and our
algorithms for detecting gestures in a modeless way, without interfering with the
keyboard's major functionality such as text entry and shortcuts activation. We explored
various features for detecting gestures from a keyboard event stream. Our experiment
based on the data collected from 10 participants indicated it is feasible to reliably
detect gestures from normal keyboard use, 95% detection accuracy within a maximum
latency of 200ms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1675–1684},
numpages = {10},
keywords = {gesture detection, modeless interaction, physical keyboard},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557263,
author = {L\"{u}, Hao and Fogarty, James A. and Li, Yang},
title = {Gesture Script: Recognizing Gestures and Their Structure Using Rendering Scripts and Interactively Trained Parts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557263},
doi = {10.1145/2556288.2557263},
abstract = {Gesture-based interactions have become an essential part of the modern user interface.
However, it remains challenging for developers to create gestures for their applications.
This paper studies unistroke gestures, an important category of gestures defined by
their single-stroke trajectories. We present Gesture Script, a tool for creating unistroke
gesture recognizers. Gesture Script enhances example-based learning with interactive
declarative guidance through rendering scripts and interactively trained parts. The
structural information from the rendering scripts allows Gesture Script to synthesize
gesture variations and generate a more accurate recognizer that also automatically
extracts gesture attributes needed by applications. The results of our study with
developers show that Gesture Script preserves the threshold of familiar example based
gesture tools, while raising the ceiling of the recognizers created in such tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1685–1694},
numpages = {10},
keywords = {gesture recognition, interactive machine learning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557030,
author = {Taylor, Stuart and Keskin, Cem and Hilliges, Otmar and Izadi, Shahram and Helmes, John},
title = {Type-Hover-Swipe in 96 Bytes: A Motion Sensing Mechanical Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557030},
doi = {10.1145/2556288.2557030},
abstract = {We present a new type of augmented mechanical keyboard, capable of sensing rich and
expressive motion gestures performed both on and directly above the device. Our hardware
comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed
between the keys of a regular mechanical keyboard. This results in coarse but high
frame-rate motion data. We extend a machine learning algorithm, traditionally used
for static classification only, to robustly support dynamic, temporal gestures. We
propose the use of motion signatures a technique that utilizes pairs of motion history
images and a random forest based classifier to robustly recognize a large set of motion
gestures on and directly above the keyboard. Our technique achieves a mean per-frame
classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training
cross-validation. We detail our hardware and gesture recognition algorithm, provide
performance and accuracy numbers, and demonstrate a large set of gestures designed
to be performed with our device. We conclude with qualitative feedback from users,
discussion of limitations and areas for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1695–1704},
numpages = {10},
keywords = {input devices, keyboard, gesture recognition},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557269,
author = {Nicolau, Hugo and Montague, Kyle and Guerreiro, Tiago and Guerreiro, Jo\~{a}o and Hanson, Vicki L.},
title = {B#: Chord-Based Correction for Multitouch Braille Input},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557269},
doi = {10.1145/2556288.2557269},
abstract = {Braille has paved its way into mobile touchscreen devices, providing faster text input
for blind people. This advantage comes at the cost of accuracy, as chord typing over
a flat surface has proven to be highly error prone. A misplaced finger on the screen
translates into a different or unrecognized character. However, the chord itself gathers
information that can be leveraged to improve input performance. We present B#, a novel
correction system for multitouch Braille input that uses chords as the atomic unit
of information rather than characters. Experimental results on data collected from
11 blind people revealed that B# is effective in correcting errors at character-level,
thus providing opportunities for instant corrections of unrecognized chords; and at
word-level, where it outperforms a popular spellchecker by providing correct suggestions
for 72% of incorrect words (against 38%). We finish with implications for designing
chord-based correction system and avenues for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1705–1708},
numpages = {4},
keywords = {touchscreen, chord, error correction, mobile, braille},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557024,
author = {Leiva, Luis A. and Sanchis-Trilles, Germ\'{a}n},
title = {Representatively Memorable: Sampling the Right Phrase Set to Get the Text Entry Experiment Right},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557024},
doi = {10.1145/2556288.2557024},
abstract = {In text entry experiments, memorability is a desired property of the phrases used
as stimuli. Unfortunately, to date there is no automated method to achieve this effect.
As a result, researchers have to use either manually curated English-only phrase sets
or sampling procedures that do not guarantee phrases being memorable. In response
to this need, we present a novel sampling method based on two core ideas: a multiple
regression model over language-independent features, and the statistical analysis
of the corpus from which phrases will be drawn. Our results show that researchers
can finally use a method to successfully curate their own stimuli targeting potentially
any language or domain. The source code as well as our phrase sets are publicly available.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1709–1712},
numpages = {4},
keywords = {sampling, representativeness, text entry, memorability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251013,
author = {Hornbaek, Kasper},
title = {Session Details: DIY and Hacking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251013},
doi = {10.1145/3251013},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557391,
author = {Qi, Jie and Buechley, Leah},
title = {Sketching in Circuits: Designing and Building Electronics on Paper},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557391},
doi = {10.1145/2556288.2557391},
abstract = {The field of new methods and techniques for building electronics is quickly growing
- from research in new materials for circuit building, to modular toolkits, and more
recently to untoolkits, which aim to incorporate more off-the-shelf parts. However,
the standard mediums for circuit design and construction remain the breadboard, protoboard,
and printed circuit board (PCB). As an alternative, we introduce a method in which
circuits are hand-made on ordinary paper substrates, connected with conductive foil
tape and off-the-shelf circuit components with the aim of supporting the durability,
scalability, and accessibility needs of novice and expert circuit builders alike.
We also used electrified notebooks to investigate how the circuit design and build
process would be affected by the constraints and affordances of the bound book. Our
ideas and techniques were evaluated through a series of workshops, through which we
found our methods supported a wide variety of approaches and results - both technical
and expressive - to electronics design and construction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1713–1722},
numpages = {10},
keywords = {sketchbooks, paper computing, toolkits, circuit prototyping},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557309,
author = {Mellis, David A. and Buechley, Leah},
title = {Do-It-Yourself Cellphones: An Investigation into the Possibilities and Limits of High-Tech Diy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557309},
doi = {10.1145/2556288.2557309},
abstract = {This paper describes our do-it-yourself cellphone and our use of it to investigate
the possibilities and limits of high-tech DIY practice. We describe our autobiographical
approach -- making the phone and using it in our daily lives -- and our work disseminating
the cellphone in workshops and online. This informs a discussion of the implications
of technology for DIY practice. We suggest an understanding of DIY as an individual's
ability to combine existing technologies into a desired product, enabled and limited
by ecosystems of industrial actors and individuals. We distinguish different pathways
into high-tech DIY practice, consider the relationship between prototyping and production,
and discuss the effect of technology on DIY's relevance and tools, and on notions
of transparency. We conclude by reflecting on the relationship between DIY and empowerment:
the extent to which making devices gives people control over the technology in their
lives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1723–1732},
numpages = {10},
keywords = {digital fabrication, prototyping, cellphone, microcontrollers, diy, electronics, toolkits},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557046,
author = {Ishiguro, Yoshio and Poupyrev, Ivan},
title = {3D Printed Interactive Speakers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557046},
doi = {10.1145/2556288.2557046},
abstract = {We propose technology for designing and manufacturing interactive 3D printed speakers.
With the proposed technology, sound reproduction can easily be integrated into vari-ous
objects at the design stage and little assembly is required. The speaker can take
the shape of anything from an abstract spiral to a rubber duck, opening new opportunities
in product design. Furthermore, both audible sound and inaudible ultrasound can be
produced with the same design, allowing for identifying and tracking 3D printed objects
in space using common integrated microphones. The design of 3D printed speakers is
based on electrostatic loudspeaker technology first explored in the early 1930s but
not broadly applied until now. These speakers are simpler than common electromagnetic
speakers, while allowing for sound reproduction at 60 dB levels with arbitrary directivity
ranging from focused to omnidirectional. Our research of 3D printed speakers contributes
to the growing body of work exploring functional 3D printing in interactive applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1733–1742},
numpages = {10},
keywords = {audio, tangible, speakers, ultrasonic, tracking, additive manufacturing, 3d printing, rapid prototyping},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557150,
author = {Hodges, Steve and Villar, Nicolas and Chen, Nicholas and Chugh, Tushar and Qi, Jie and Nowacka, Diana and Kawahara, Yoshihiro},
title = {Circuit Stickers: Peel-and-Stick Construction of Interactive Electronic Prototypes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557150},
doi = {10.1145/2556288.2557150},
abstract = {We present a novel approach to the construction of electronic prototypes which can
support a variety of interactive devices. Our technique, which we call circuit stickers,
involves adhering physical interface elements such as LEDs, sounders, buttons and
sensors onto a cheap and easy-to-make substrate which provides electrical connectivity.
This assembly may include control electronics and a battery for standalone operation,
or it can be interfaced to a microcontroller or PC. In this paper we illustrate different
points in the design space and demonstrate the technical feasibility of our approach.
We have found circuit stickers to be versatile and low-cost, supporting quick and
easy construction of physically flexible interactive prototypes. Building extra copies
of a device is straightforward. We believe this technology has potential for design
exploration, research proto-typing, education and for hobbyist projects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1743–1746},
numpages = {4},
keywords = {conductive inkjet, tangible interfaces, silver ink, solderless electronics, rapid prototyping, physical computing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251014,
author = {Brumby, Duncan},
title = {Session Details: User Models and Prediction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251014},
doi = {10.1145/3251014},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557355,
author = {Nicosia, Max and Oulasvirta, Antti and Kristensson, Per Ola},
title = {Modeling the Perception of User Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557355},
doi = {10.1145/2556288.2557355},
abstract = {This paper studies how users perceive their own performance in two alternative user
interfaces. We extend methodology from psychophysics to the study of interactive performance
and conduct two experiments in order to create a model of users' perception of their
own performance. In our studies, two interfaces are sequentially used in a pointing
task, and users are asked to rate in which interface their performance was higher.
We first differentiate the effects of objective performance (speed and accuracy) versus
interface qualities (distance between elements and width of elements) on perceived
performance. We then derive a model that predicts the amount of change required in
an interface for users to reliably detect a difference. The model is useful as a heuristic
for predicting if a new interface design is better enough for users to reliably appreciate
the obtained gain in user performance. We validate the model via a separate user study,
and conclude by discussing how to apply our findings to design problems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1747–1756},
numpages = {10},
keywords = {psychophysics, perception of user performance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557191,
author = {Zade, Himanshu and Adimoolam, Santosh Arvind and Gollapudi, Sai and Dey, Anind K. and Choppella, Venkatesh},
title = {Edit Distance modulo Bisimulation: A Quantitative Measure to Study Evolution of User Models},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557191},
doi = {10.1145/2556288.2557191},
abstract = {When a user learns to use a new device, her understanding of it evolves. A progressive
comparison of the evolving user models towards the device target model, for analysing
learning, involves determining the behavioral proximity between them. To quantify
the gap between a user model and a target model, we introduce an edit distance metric
for measuring their behavioral proximity using a bisimulation-based equivalence relation.
We define edit distance to be the minimum number of edges and states with incident
edges required to be deleted from and/or added to a user model to make it bisimilar
to the target model. We propose an algorithm to compute edit distance between two
models and employ the heuristic procedure on experimental data for computing edit
distance between target and user models. The data is organised into two experiments
depending on the device the user interacted with: (a) a simple device resembling a
vending machine and (b) a close to real-world vehicle transmission model. The results
validate our proposed metric as edit distance converges with progressive user learning,
increases for erroneous learning, and remains unchanged indicating no learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1757–1766},
numpages = {10},
keywords = {learning, finite state machines, behavioral proximity.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557422,
author = {Trafton, J. Gregory and Ratwani, Raj M.},
title = {The Law of Unintended Consequences: The Case of External Subgoal Support},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557422},
doi = {10.1145/2556288.2557422},
abstract = {Many interfaces have been designed to prevent or reduce errors. These interfaces may,
in fact, reduce the error rate of specific error classes, but may also have unintended
consequences. In this paper, we show a series of studies where a better interface
did not reduce the number of errors but instead shifted errors from one error class
(omissions) to another error class (perseverations). We also show that having access
to progress tracking (a progress bar) does not reduce the number of errors. We propose
and demonstrate a solution -- a predictive error system -- that reduces errors based
on the error class, not on the type of interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1767–1776},
numpages = {10},
keywords = {interface subgoal support, computer human interaction, error prediction, progress tracking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556990,
author = {Nancel, Mathieu and Cockburn, Andy},
title = {Causality: A Conceptual Model of Interaction History},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556990},
doi = {10.1145/2556288.2556990},
abstract = {Simple history systems such as Undo and Redo permit retrieval of earlier or later
interaction states, but advanced systems allow powerful capabilities to reuse or reapply
combinations of commands, states, or data across interaction contexts. Whether simple
or powerful, designing interaction history mechanisms is challenging. We begin by
reviewing existing history systems and models, observing a lack of tools to assist
designers and researchers in specifying, contemplating, combining, and communicating
the behaviour of history systems. To resolve this problem, we present CAUSALITY, a
conceptual model of interaction history that clarifies the possibilities for temporal
interactions. The model includes components for the work artifact (such as the text
and formatting of a Word document), the system context (such as the settings and parameters
of the user interface), the linear timeline (the commands executed in real time),
and the branching chronology (a structure of executed commands and their impact on
the artifact and/or context, which may be navigable by the user). We then describe
and exemplify how this model can be used to encapsulate existing user interfaces and
reveal limitations in their behaviour, and we also show in a conceptual evaluation
how the model stimulates the design of new and innovative opportunities for interacting
in time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1777–1786},
numpages = {10},
keywords = {conceptual model, paradoxes, history systems, undo},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251015,
author = {Kientz, Julie},
title = {Session Details: Engage and Educate Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251015},
doi = {10.1145/3251015},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557280,
author = {Hyde, Jennifer and Kiesler, Sara and Hodgins, Jessica K. and Carter, Elizabeth J.},
title = {Conversing with Children: Cartoon and Video People Elicit Similar Conversational Behaviors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557280},
doi = {10.1145/2556288.2557280},
abstract = {Interactive animated characters have the potential to engage and educate children,
but there is little research on children's interactions with animated characters and
real people. We conducted an experiment with 69 children between the ages of 4 and
10 years to investigate how they might engage in conversation differently if their
interactive partner appeared as a cartoon character or as a person. A subset of the
participants interacted with characters that displayed exaggerated and damped facial
motion. The children completed two conversations with an adult confederate who appeared
once as herself through video and once as a cartoon character. We measured how much
the children spoke and compared their gaze and gesture patterns. We asked them to
rate their conversations and indicate their preferred partner. There was no difference
in children's conversation behavior with the cartoon character and the person on video,
even among those who preferred the person and when the cartoon exhibited altered motion.
These results suggest that children will interact with animated characters as they
would another person.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1787–1796},
numpages = {10},
keywords = {agent, children, behavior, avatar, conversation, facial motion, animated character},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557128,
author = {Hashish, Yasmeen and Bunt, Andrea and Young, James E.},
title = {Involving Children in Content Control: A Collaborative and Education-Oriented Content Filtering Approach},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557128},
doi = {10.1145/2556288.2557128},
abstract = {We present an approach to content control where parents and children collaboratively
configure restrictions and filters, an approach that focuses on education rather than
simple rule setting. We conducted an initial exploratory qualitative study with results
highlighting the importance that parents place on avoiding inappropriate content.
Building on these findings, we designed an initial prototype which allows parents
and children to work together to select appropriate applications, providing an opportunity
for parents to educate their children on what is appropriate. A second qualitative
study with parents and children in the six to eight year-old age group revealed a
favorable response to this approach. Our results suggest that parents felt that this
approach helped facilitate discussions with their children and made the education
more enjoyable and approachable, and that children may have also learned from the
interaction. In addition, the approach provided some parents with insights into their
children's interests and understanding of their notions of appropriate and inappropriate
content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1797–1806},
numpages = {10},
keywords = {parental control strategies, collaborative content filtering, children and technology},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557205,
author = {Tewari, Anuj and Canny, John},
title = {What Did Spot Hide? A Question-Answering Game for Preschool Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557205},
doi = {10.1145/2556288.2557205},
abstract = {Early literacy is critical to child development, and determines a child's later educational
and life opportunities. Moreover, preschool children are incessantly inquisitive,
and will readily engage in question answering and asking activities if given the opportunity.
We argue here that question asking/answering technologies can play a major role in
early literacy. We describe the design and evaluation of a conversational agent called
Spot, with the goal of engaging children in a 20-questions game. Towards this goal,
we conducted a feasibility study to determine if children's questions are "on-topic"
and suitable for ASR/dialogue systems. We evaluated Spot's performance at conducting
a game of 20-questions against that of a human partner.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1807–1816},
numpages = {10},
keywords = {question-answering, conversational agents, games, preschool literacy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557402,
author = {Hamidi, Foad and Baljko, Melanie},
title = {Rafigh: A Living Media Interface for Speech Intervention},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557402},
doi = {10.1145/2556288.2557402},
abstract = {Digital games can engage children in therapeutic and learning activities. Incorporating
living media in these designs can create feelings of empathy and caring in users.
We present, Rafigh, a living media interface designed to motivate children with speech
disorders to use their speech to care for a living mushroom colony. The mushrooms'
growth is used to communicate how much speech is used during interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1817–1820},
numpages = {4},
keywords = {speech intervention, living media interfaces, embedded computing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557031,
author = {Gossen, Tatiana and H\"{o}bel, Juliane and N\"{u}rnberger, Andreas},
title = {A Comparative Study about Children's and Adults' Perception of Targeted Web Search Engines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557031},
doi = {10.1145/2556288.2557031},
abstract = {In this paper we describe an eye-tracking study where we compare children's and adults'
search behavior and perception of search interface elements on search engine results
pages (SERPs) during an informational and a navigational search with Google and a
search engine for children. Our first results indicate that children employ an exhaustive
scanning strategy combined with cued visual jumps. Then they navigate to the next
result page and only then modify their query. Adults only scan the first three results,
following the F-shaped strategy, and immediately reformulate the query. Children pay
less attention to textual summaries and more to thumbnails than adults do. Children
take notice of a navigational menu with categories while adults do not.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1821–1824},
numpages = {4},
keywords = {children, search engine, eye-tracker, user study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251016,
author = {Dragicevic, Pierre},
title = {Session Details: Studying Visualization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251016},
doi = {10.1145/3251016},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557112,
author = {Alper, Basak E. and Henry Riche, Nathalie and Hollerer, Tobias},
title = {Structuring the Space: A Study on Enriching Node-Link Diagrams with Visual References},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557112},
doi = {10.1145/2556288.2557112},
abstract = {Exploring large visualizations that do not fit in the screen raises orientation and
navigation challenges. Structuring the space with additional visual references such
as grids or contour lines provide spatial landmarks that may help viewers form a mental
model of the space. However, previous studies report mixed results regarding their
utility. While some evidence showed that grid and other visual embellishments improve
memorability, experiments with contour lines suggest otherwise. In this work, we describe
an evaluation framework to capture the impact of introducing visual references in
node-link diagrams. We present the results of three controlled experiments that deepen
our understanding on enriching large visualization spaces with visual structures.
In particular, we provide the first tangible evidence that contour lines have significant
benefits when navigating large node-link diagrams.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1825–1834},
numpages = {10},
keywords = {revisitation, information visualization, network diagrams, navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557141,
author = {Carenini, Giuseppe and Conati, Cristina and Hoque, Enamul and Steichen, Ben and Toker, Dereck and Enns, James},
title = {Highlighting Interventions and User Differences: Informing Adaptive Information Visualization Support},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557141},
doi = {10.1145/2556288.2557141},
abstract = {There is increasing evidence that the effectiveness of information visualization techniques
can be impacted by the particular needs and abilities of each user. This suggests
that it is important to investigate information visualization systems that can dynamically
adapt to each user. In this paper, we address the question of how to adapt. In particular,
we present a study to evaluate a variety of visual prompts, called "interventions",
that can be performed on a visualization to help users process it. Our results show
that some of the tested interventions perform better than a condition in which no
intervention is provided, both in terms of task performance as well as subjective
user ratings. We also discuss findings on how intervention effectiveness is influenced
by individual differences and task complexity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1835–1844},
numpages = {10},
keywords = {adaptive information visualization, user characteristics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}


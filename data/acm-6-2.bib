@inbook{10.1145/3290605.3300231,
author = {Colusso, Lucas and Jones, Ridley and Munson, Sean A. and Hsieh, Gary},
title = {A Translational Science Model for HCI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300231},
abstract = {Using scientific discoveries to inform design practice is an important, but difficult,
objective in HCI. In this paper, we provide an overview of Translational Science in
HCI by triangulating literature related to the research-practice gap with interview
data from many parties engaged (or not) in translating HCI knowledge. We propose a
model for Translational Science in HCI based on the concept of a continuum to describe
how knowledge progresses (or stalls) through multiple steps and translations until
it can influence design practice. The model offers a conceptual framework that can
be used by researchers and practitioners to visualize and describe the progression
of HCI knowledge through a sequence of translations. Additionally, the model may facilitate
a precise identification of translational barriers, which allows devising more effective
strategies to increase the use of scientific findings in design practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300232,
author = {Sambasivan, Nithya and Batool, Amna and Ahmed, Nova and Matthews, Tara and Thomas, Kurt and Gayt\'{a}n-Lugo, Laura Sanely and Nemer, David and Bursztein, Elie and Churchill, Elizabeth and Consolvo, Sunny},
title = {"They Don't Leave Us Alone Anywhere We Go": Gender and Digital Abuse in South Asia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300232},
abstract = {South Asia faces one of the largest gender gaps online globally, and online safety
is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better
understand the gendered risks and coping practices online in South Asia, we present
a qualitative study of the online abuse experiences and coping practices of 199 people
who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using
a feminist analysis. We found that a majority of our participants regularly contended
with online abuse, experiencing three major abuse types: cyberstalking, impersonation,
and personal content leakages. Consequences of abuse included emotional harm, reputation
damage, and physical and sexual violence. Participants coped through informal channels
rather than through technological protections or law enforcement. Altogether, our
findings point to opportunities for designs, policies, and algorithms to improve women's
safety online in South Asia.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300233,
author = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric},
title = {Guidelines for Human-AI Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300233},
abstract = {Advances in artificial intelligence (AI) frame opportunities and challenges for user
interface design. Principles for human-AI interaction have been discussed in the human-computer
interaction community for over two decades, but more study and innovation are needed
in light of advances in AI and the growing uses of AI technologies in human-facing
applications. We propose 18 generally applicable design guidelines for human-AI interaction.
These guidelines are validated through multiple rounds of evaluation including a user
study with 49 design practitioners who tested the guidelines against 20 popular AI-infused
products. The results verify the relevance of the guidelines over a spectrum of interaction
scenarios and reveal gaps in our knowledge, highlighting opportunities for further
research. Based on the evaluations, we believe the set of design guidelines can serve
as a resource to practitioners working on the design of applications and features
that harness AI technologies, and to researchers interested in the further development
of human-AI interaction design principles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300234,
author = {Cai, Carrie J. and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S. and Stumpe, Martin C. and Terry, Michael},
title = {Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300234},
abstract = {Machine learning (ML) is increasingly being used in image retrieval systems for medical
decision making. One application of ML is to retrieve visually similar medical images
from past patients (e.g. tissue from biopsies) to reference when making a medical
decision with a new patient. However, no algorithm can perfectly capture an expert's
ideal notion of similarity for every case: an image that is algorithmically determined
to be similar may not be medically relevant to a doctor's specific diagnostic needs.
In this paper, we identified the needs of pathologists when searching for similar
images retrieved using a deep learning algorithm, and developed tools that empower
users to cope with the search algorithm on-the-fly, communicating what types of similarity
are most important at different moments in time. In two evaluations with pathologists,
we found that these tools increased the diagnostic utility of images found and increased
user trust in the algorithm. The tools were preferred over a traditional interface,
without a loss in diagnostic accuracy. We also observed that users adopted new strategies
when using refinement tools, re-purposing them to test and understand the underlying
algorithm and to disambiguate ML errors from their own errors. Taken together, these
findings inform future human-ML collaborative systems for expert decision-making.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300235,
author = {Spence, Jocelyn and Bedwell, Benjamin and Coleman, Michelle and Benford, Steve and Koleva, Boriana N. and Adams, Matt and Row Farr, Ju and Tandavanitj, Nick and L\o{}vlie, Anders Sundnes},
title = {Seeing with New Eyes: Designing for In-the-Wild Museum Gifting},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300235},
abstract = {This paper presents the GIFT smartphone app, an artist-led Research through Design
project benefitting from a three-day in-the-wild deployment. The app takes as its
premise the generative potential of combining the contexts of gifting and museum visits.
Visitors explore the museum, searching for objects that would most appeal to the gift-receiver
they have in mind, then photographing those objects and adding audio messages for
their receivers describing the motivation for their choices. This paper charts the
designers' key aim of creating a new frame of mind using voice, and the most striking
findings discovered during in-the-wild deployment in a museum -- 'seeing with new
eyes' and fostering personal connections. We discuss empathy, motivation, and bottom-up
personalisation in the productive space revealed by this combination of contexts.
We suggest that this work reveals opportunities for designers of gifting services
as well as those working in cultural heritage.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300236,
author = {Schofield, Tom and Foster Smith, Daniel and Bozoglu, G\"{o}n\"{u}l and Whitehead, Christopher},
title = {Design and Plural Heritages: Composing Critical Futures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300236},
abstract = {We make theoretical and methodological contributions to the CHI community by introducing
comparisons between contemporary Critical Heritage research and some forms of experimental
design practice. Beginning by identifying three key approaches in contemporary heritage
research: Critical Heritage, Plural Heritages and Future Heritage we introduce these
in turn, while exploring their significance for thinking about design, knowledge and
diversity. We discuss our efforts to apply ideas integrating Critical Heritage and
design through the adoption of known Research through Design techniques in a research
project in Istanbul, Turkey describing the design of our study and how this was productive
of sensory and speculative reflection on the past. Finally, we reflect on the usefulness
of such methods in developing new interactive technologies in heritage contexts and
go on to propose a series of recommendations for a future Critical Heritage Design
practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300237,
author = {Mallavarapu, Aditi and Lyons, Leilah and Uzzo, Stephen and Thompson, Wren and Levy-Cohen, Rinat and Slattery, Brian},
title = {Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Simulation at a Museum},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300237},
abstract = {Immersive open-ended museum exhibits promote ludic engagement and can be a powerful
draw for visitors, but these qualities may also make learning more challenging. We
describe our efforts to help visitors engage more deeply with an interactive exhibit's
content by giving them access to visualizations of data skimmed from their use of
the exhibit. We report on the motivations and challenges in designing this reflective
tool, which positions visitors as a "human in the loop" to understand and manage their
engagement with the exhibit. We used an iterative design process and qualitative methods
to explore how and if visitors could (1) access and (2) comprehend the data visualizations,
(3) reflect on their prior engagement with the exhibit, (4)plan their future engagement
with the exhibit, and (5) act on their plans. We further discuss the essential design
challenges and the opportunities made possible for visitors through data-driven reflection
tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300238,
author = {Hiniker, Alexis and Froehlich, Jon E. and Zhang, Mingrui and Beneteau, Erin},
title = {Anchored Audio Sampling: A Seamless Method for Exploring Children's Thoughts During Deployment Studies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300238},
abstract = {Many traditional HCI methods, such as surveys and interviews, are of limited value
when working with preschoolers. In this paper, we present anchored audio sampling
(AAS), a remote data collection technique for extracting qualitative audio samples
during field deployments with young children. AAS offers a developmentally sensitive
way of understanding how children make sense of technology and situates their use
in the larger context of daily life. AAS is defined by an anchor event, around which
audio is collected. A sliding window surrounding this anchor captures both antecedent
and ensuing recording, providing the researcher insight into the activities that led
up to the event of interest as well as those that followed. We present themes from
three deployments that leverage this technique. Based on our experiences using AAS,
we have also developed a reusable open-source library for embedding AAS into any Android
application.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300239,
author = {Harris, John and Hancock, Mark},
title = {To Asymmetry and Beyond! Improving Social Connectedness by Increasing Designed Interdependence in Cooperative Play},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300239},
abstract = {Social play can have numerous health benefits but research has shown that not all
multiplayer games are effective at promoting social engagement. Asymmetric cooperative
games have shown promise in this regard but the design and dynamics of this unique
style of play is not yet well understood. To address this, we present the results
of two player experience studies using our custom prototype game Beam Me 'Round, Scotty!
2: the first comparing symmetric cooperative play (e.g., where players have the same
interface, goals, mechanics, etc.) to asymmetric cooperative play (e.g., where players
have differing roles, abilities, interfaces, etc.) and the second comparing the effect
of increasing degrees of interdependence between play partners. Our results not only
indicate that asymmetric cooperative games may enhance players' perceptions of connectedness,
social engagement, immersion, and comfort with a game's controls, but also demonstrate
how to further improve these outcomes via deliberate mechanical design changes, such
as changes in cooperative action timing and direction of dependence.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300240,
author = {Fl\'{o}rez-Aristiz\'{a}bal, Leandro and Cano, Sandra and Collazos, C\'{e}sar A. and Solano, Andr\'{e}s F. and Brewster, Stephen},
title = {DesignABILITY: Framework for the Design of Accessible Interactive Tools to Support Teaching to Children with Disabilities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300240},
abstract = {Developing educational tools aimed at children with disabilities is a challenging
process for designers and developers because existing methodologies or frameworks
do not provide any pedagogical information and/or do not take into account the particular
needs of users with some type of impairment. In this study, we propose a framework
for the design of tools to support teaching to children with disabilities. The framework
provides the necessary stages for the development of tools (hardware-based or software-based)
and must be adapted for a specific disability and educational goal. For this study,
the framework was adapted to support literacy teaching and contributes to the design
of educational/interactive technology for deaf people while making them part of the
design process and taking into account their particular needs. The experts' evaluation
of the framework shows that it is well structured and may be adapted for other types
of disabilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300241,
author = {Shigeyama, Jotaro and Hashimoto, Takeru and Yoshida, Shigeo and Narumi, Takuji and Tanikawa, Tomohiro and Hirose, Michitaka},
title = {Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering Based on Computational Perception Model},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300241},
abstract = {Humans can estimate the shape of a wielded object through the illusory feeling of
the mass properties of the object obtained using their hands. Even though the shape
of hand-held objects influences immersion and realism in virtual reality (VR), it
is difficult to design VR controllers for rendering desired shapes according to the
perceptions derived from the illusory effects of mass properties and shape perception.
We propose Transcalibur, which is a hand-held VR controller that can render a 2D shape
by changing its mass properties on a 2D planar area. We built a computational perception
model using a data-driven approach from the collected data pairs of mass properties
and perceived shapes. This enables Transcalibur to easily and effectively provide
convincing shape perception based on complex illusory effects. Our user study showed
that the system succeeded in providing the perception of various desired shapes in
a virtual environment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300242,
author = {Zhang, Xujing and Braley, Sean and Rubens, Calvin and Merritt, Timothy and Vertegaal, Roel},
title = {LightBee: A Self-Levitating Light Field Display for Hologrammatic Telepresence},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300242},
abstract = {LightBee is a novel "hologrammatic" telepresence system featuring a self-levitating
light field display. It consists of a drone that flies a projection of a remote user's
head through 3D space. The movements of the drone are controlled by the remote user's
head movements, offering unique support for non-verbal cues, especially physical proxemics.
The light field display is created by a retro-reflective sheet that is mounted on
the cylindrical quadcopter. 45 smart projectors, one per 1.3 degrees, are mounted
in a ring, each projecting a video stream rendered from a unique perspective onto
the retroreflector. This creates a light field that naturally provides motion parallax
and stereoscopy without requiring any headset nor stereo glasses. LightBee allows
multiple local users to experience their own unique and correct perspective of the
remote user's head. The system is currently one-directional: 2 small cameras mounted
on the drone allow the remote user to observe the local scene.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300243,
author = {Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel},
title = {TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300243},
abstract = {Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with
standard input controllers. We propose exploiting the affordances and input capabilities
when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations
gained during semi-structured interviews with general users, and those experienced
with 3D software, are used to define a set of design dimensions and guidelines. These
are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's
precise touch input capability, physical shape, metaphorical associations, and natural
compatibility with barehand mid-air input can be used in VR. For example, transforming
objects with touch input, "cutting" objects by using the tablet as a physical "knife",
navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving
bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with
users, with results validating the approach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300244,
author = {Gupta, Aakar and Ji, Cheng and Yeo, Hui-Shyong and Quigley, Aaron and Vogel, Daniel},
title = {RotoSwype: Word-Gesture Typing Using a Ring},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300244},
abstract = {We propose RotoSwype, a technique for word-gesture typing using the orientation of
a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering
the hand with a device, a desirable quality in many scenarios, including virtual or
augmented reality. The method is evaluated using two arm positions: with the hand
raised up with the palm parallel to the ground; and with the hand resting at the side
with the palm facing the body. A five-day study finds both hand positions achieved
speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%,
outperforming previous comparable techniques.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300245,
author = {Iravantchi, Yasha and Goel, Mayank and Harrison, Chris},
title = {BeamBand: Hand Gesture Sensing with Ultrasonic Beamforming},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300245},
abstract = {BeamBand is a wrist-worn system that uses ultrasonic beamforming for hand gesture
sensing. Using an array of small transducers, arranged on the wrist, we can ensem-ble
acoustic wavefronts to project acoustic energy at spec-ified angles and focal lengths.
This allows us to interro-gate the surface geometry of the hand with inaudible sound
in a raster-scan-like manner, from multiple view-points. We use the resulting, characteristic
reflections to recognize hand pose at 8 FPS. In our user study, we found that BeamBand
supports a six-class hand gesture set at 94.6% accuracy. Even across sessions, when
the sensor is removed and reworn later, accuracy remains high: 89.4%. We describe
our software and hardware, and future ave-nues for integration into devices such as
smartwatches and VR controllers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300246,
author = {Guerreiro, Jo\~{a}o and Ahmetovic, Dragan and Sato, Daisuke and Kitani, Kris and Asakawa, Chieko},
title = {Airport Accessibility and Navigation Assistance for People with Visual Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300246},
abstract = {People with visual impairments often have to rely on the assistance of sighted guides
in airports, which prevents them from having an independent travel experience. In
order to learn about their perspectives on current airport accessibility, we conducted
two focus groups that discussed their needs and experiences in-depth, as well as the
potential role of assistive technologies. We found that independent navigation is
a main challenge and severely impacts their overall experience. As a result, we equipped
an airport with a Bluetooth Low Energy (BLE) beacon-based navigation system and performed
a real-world study where users navigated routes relevant for their travel experience.
We found that despite the challenging environment participants were able to complete
their itinerary independently, presenting none to few navigation errors and reasonable
timings. This study presents the first systematic evaluation posing BLE technology
as a strong approach to increase the independence of visually impaired people in airports.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300247,
author = {Perrault, Simon T. and Zhang, Weiyu},
title = {Effects of Moderation and Opinion Heterogeneity on Attitude towards the Online Deliberation Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300247},
abstract = {Online deliberation offers a way for citizens to collectively discuss an issue and
provide input for policymakers. The overall experience of online deliberation can
be affected by multiple factors. We decided to investigate the effects of moderation
and opinion heterogeneity on the perceived deliberation experience, by running the
first online deliberation experiment in Singapore. Our study took place in three months
with three phases. In phase 1, our 2,006 participants answered a survey, that we used
to create groups of different opinion heterogeneity. During the second phase, 510
participants discussed about the population issue on the online platform we developed.
We gathered data on their online deliberation experience during phase 3. We found
out that higher levels of moderation negatively impact the experience of deliberation
on perceived procedural fairness, validity claim and policy legitimacy; and that high
opinion heterogeneity is important in order to get a fair assessment of the deliberation
experience.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300248,
author = {Wang, Anran and Gollakota, Shyamnath},
title = {MilliSonic: Pushing the Limits of Acoustic Motion Tracking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300248},
abstract = {Recent years have seen interest in device tracking and localization using acoustic
signals. State-of-the-art acoustic motion tracking systems however do not achieve
millimeter accuracy and require large separation between microphones and speakers,
and as a result, do not meet the requirements for many VR/AR applications. Further,
tracking multiple concurrent acoustic transmissions from VR devices today requires
sacrificing accuracy or frame rate. We present MilliSonic, a novel system that pushes
the limits of acoustic based motion tracking. Our core contribution is a novel localization
algorithm that can provably achieve sub-millimeter 1D tracking accuracy in the presence
of multipath, while using only a single beacon with a small 4-microphone array.Further,
MilliSonic enables concurrent tracking of up to four smartphones without reducing
frame rate or accuracy. Our evaluation shows that MilliSonic achieves 0.7mm median
1D accuracy and a 2.6mm median 3D accuracy for smartphones, which is 5x more accurate
than state-of-the-art systems. MilliSonic enables two previously infeasible interaction
applications: a) 3D tracking of VR headsets using the smartphone as a beacon and b)
fine-grained 3D tracking for the Google Cardboard VR system using a small microphone
array.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300249,
author = {Hahn, Nathan and Iqbal, Shamsi T. and Teevan, Jaime},
title = {Casual Microtasking: Embedding Microtasks in Facebook},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300249},
abstract = {Microtasks enable people with limited time and context to contribute to a larger task.
In this paper we explore casual microtasking, where microtasks are embedded into other
primary activities so that they are available to be completed when convenient. We
present a casual microtasking experience that inserts writing microtasks from an existing
microwriting tool into the user's Facebook feed. From a two-week deployment of the
system with nine people, we observe that casual microtasking enabled participants
to get things done during their breaks, and that they tended to do so only after first
engaging with Facebook's social content. Participants were most likely to complete
the writing microtasks during periods of the day associated with low focus, and would
occasionally use them as a springboard to open the original document in Word. These
findings suggest casual microtasking can help people leverage spare micromoments to
achieve meaningful micro-goals, and even encourage them to return to work.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300250,
author = {Holloway, Leona and Marriott, Kim and Butler, Matthew and Borning, Alan},
title = {Making Sense of Art: Access for Gallery Visitors with Vision Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300250},
abstract = {While there is widespread recognition of the need to provide people with vision impairments
(PVI) equitable access to cultural institutions such as art galleries, this is not
easy. We present the results of a collaboration with a regional art gallery who wished
to open their collection to PVIs in the local community. We describe a novel model
that provides three different ways of accessing the gallery, depending upon visual
acuity and mobility: virtual tours, self-guided tours and guided tours. As far as
possible the model supports autonomous exploration by PVIs. It was informed by a value
sensitive design exploration of the values and value conflicts of the primary stakeholders.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300251,
author = {Wilson, Cara and Brereton, Margot and Ploderer, Bernd and Sitbon, Laurianne},
title = {Co-Design Beyond Words: 'Moments of Interaction' with Minimally-Verbal Children on the Autism Spectrum},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300251},
abstract = {Existing co-design methods support verbal children on the autism spectrum in the design
process, while their minimally-verbal peers are overlooked. We describe Co-Design
Beyond Words (CDBW), an approach which merges existing co-design methods with practice-based
methods from Speech and Language Therapy which are child-led and interests-based.
These emphasise the rich detail that can be conveyed in the moment, through recognising
occurrences of, for example, Joint Attention, Turn Taking and Imitation. We worked
in an autism-specific primary school over 20 weeks with ten children, aged 5 to 8.
We co-designed a playful prototype, the TangiBall, using the three iterative phases
of CDBW; the Foundation Phase (preparation for interaction), the Interaction Phase
(designing-and-reflecting in the moment) and the Reflection Phase (reflection-on-action).
We contribute a novel co-design approach and present moments of interaction, the micro
instances in design in which minimally-verbal children on the spectrum can convey
meaning beyond words, through their actions, interactions, and attentional foci. These
moments of interaction provide design insight, shape design direction, and reveal
unique strengths, interests, and abilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300252,
author = {Nontasil, Pawarat and Payne, Stephen J.},
title = {Emotional Utility and Recall of the Facebook News Feed},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300252},
abstract = {We report a laboratory study (N=53) in which participants browsed their own Facebook
news feeds for 10-15 minutes, choosing exactly when to quit, and later rated the overall
emotional utility of the episode before attempting to recall threads. Finally, the
emotional utility of each encountered thread was rated while looking over a recording
of the interaction. We report that Facebook browsing was, overall, an emotionally
positive experience; that recall of threads exhibited classic primacy and recency
serial order effects; that recalled threads were both more positive and more valenced
(less neutral) on average, than forgotten threads; and that overall emotional valence
judgments were predicted, statistically, by the peak and end thread judgments. We
find no evidence that local quit decisions were driven by the emotional utility of
threads. In the light of these findings, we discuss the suggestion that emotional
utility might partly explain the attractiveness of reading the news feed, and that
an emotional memory bias might further increase the attractiveness of the newsfeed
in prospect.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300253,
author = {Rifat, Mohammad Rashidujjaman and Prottoy, Hasan Mahmud and Ahmed, Syed Ishtiaque},
title = {The Breaking Hand: Skills, Care, and Sufferings of the Hands of an Electronic Waste Worker in Bangladesh},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300253},
abstract = {While repair work has recently been getting increasing attention in HCI, recycling
practices have still remained relatively understudied, especially in the context of
the Global South. To this end, building on our eight-month-long ethnography, this
paper reports the electronic waste (`e-waste', henceforth) recycling practices among
the e-waste recycler (`bhangari') communities in Dhaka, Bangladesh. In doing so, this
paper offers the work of the bhangaris through an articulation of their hands and
their uses. Drawing from a rich body of scholarly work on social science, we define
and contextualize three characteristics of the hand of a bhangari: knowledge, care,
and skills and collaboration. Our study also highlights the pains and sufferings involved
in this profession. By explaining bhangari work through the hand, we also discuss
its implications for design, and its connection to HCI's broader interest in sustainability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300254,
author = {Wang, Ruolin and Yu, Chun and Yang, Xing-Dong and He, Weijie and Shi, Yuanchun},
title = {EarTouch: Facilitating Smartphone Use for Visually Impaired People in Mobile and Public Scenarios},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300254},
abstract = {Interacting with a smartphone using touch input and speech output is challenging for
visually impaired people in mobile and public scenarios, where only one hand may be
available for input (e.g., while holding a cane) and using the loudspeaker for speech
output is constrained by environmental noise, privacy, and social concerns. To address
these issues, we propose EarTouch, a one-handed interaction technique that allows
the users to interact with a smartphone using the ear to perform gestures on the touchscreen.
Users hold the phone to their ears and listen to speech output from the ear speaker
privately. We report how the technique was designed, implemented, and evaluated through
a series of studies. Results show that EarTouch is easy, efficient, fun and socially
acceptable to use.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300255,
author = {Lee, Sangyoon and Lee, Jaeyeon and Lee, Geehyuk},
title = {Diagnosing and Coping with Mode Errors in Korean-English Dual-Language Keyboard},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300255},
abstract = {In countries where languages with non-Latin characters are prevalent, people use a
keyboard with two language modes namely, the native language and English, and often
experience mode errors. To diagnose the mode error problem, we conducted a field study
and observed that 78% of the mode errors occurred immediately after application switching.
We implemented four methods (Auto-switch, Preview, Smart-toggle, and Preview &amp; Smart-toggle)
based on three strategies to deal with the mode error problem and conducted field
studies to verify their effectiveness. In the studies considering Korean-English dual
input, Auto-switch was ineffective. On the contrary, Preview significantly reduced
the mode errors from 75.1% to 41.3%, and Smart-toggle saved typing cost for recovering
from mode errors. In Preview &amp; Smart-toggle, Preview reduced mode errors and Smart-toggle
handled 86.2% of the mode errors that slipped past Preview. These results suggest
that Preview &amp; Smart-toggle is a promising method for preventing mode errors for the
Korean-English dual-input environment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300256,
author = {Habib, Hana and Shah, Neil and Vaish, Rajan},
title = {Impact of Contextual Factors on Snapchat Public Sharing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300256},
abstract = {Public sharing is integral to online platforms. This includes the popular multimedia
messaging application Snapchat, on which public sharing is relatively new and unexplored
in prior research. In mobile-first applications, sharing contexts are dynamic. However,
it is unclear how context impacts users' sharing decisions. As platforms increasingly
rely on user-generated content, it is important to also broadly understand user motivations
and considerations in public sharing. We explored these aspects of content sharing
through a survey of 1,515 Snapchat users. Our results indicate that users primarily
have intrinsic motivations for publicly sharing Snaps, such as to share an experience
with the world, but also have considerations related to audience and sensitivity of
content. Additionally, we found that Snaps shared publicly were contextually different
from those privately shared. Our findings suggest that content sharing systems can
be designed to support sharing motivations, yet also be sensitive to private contexts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300257,
author = {Mott, Martez E. and Wobbrock, Jacob O.},
title = {Cluster Touch: Improving Touch Accuracy on Smartphones for People with Motor and Situational Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300257},
abstract = {We present Cluster Touch, a combined user-independent and user-specific touch offset
model that improves the accuracy of touch input on smartphones for people with motor
impairments, and for people experiencing situational impairments while walking. Cluster
Touch combines touch examples from multiple users to create a shared user-independent
touch model, which is then updated with touch examples provided by an individual user
to make it user-specific. Owing to this combination, Cluster Touch allows people to
quickly improve the accuracy of their smartphones by providing only 20 touch examples.
In a user study with 12 people with motor impairments and 12 people without motor
impairments, but who were walking, Cluster Touch improved touch accuracy by 14.65%
for the former group and 6.81% for the latter group over the native touch sensor.
Furthermore, in an offline analysis of existing mobile interfaces, Cluster Touch improved
touch accuracy by 8.21% and 4.84% over the native touch sensor for the two user groups,
respectively.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300258,
author = {Wang, Shang and Sonmez Unal, Deniz and Walker, Erin},
title = {MindDot: Supporting Effective Cognitive Behaviors in Concept Map-Based Learning Environments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300258},
abstract = {While prior research has revealed the promising impact of concept mapping on learning,
few have comprehensively modeled different cognitive behaviors during concept mapping.
In addition, existing concept mapping tools lack effective feedback to support better
learning behaviors. This work presents MindDot, a concept map-based learning environment
that facilitates the cognitive process of comparing and integrating related concepts
via two forms of support. A hyperlink support and an expert template. Study results
suggested that both types of support had positive impact on the development of comparative
strategies and that hyperlink support enhanced learning. We further evaluated the
cognitive learning progress at a fine-grained level with two forms of visualizations.
We then extracted several behavioral patterns that provided insights about the cognitive
progress in learning. Lastly, we derive design recommendations that we hope will inspire
future intelligent tutoring systems that automatically evaluate students' learning
behaviors and foster them in developing effective learning behaviors},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300259,
author = {D\"{o}rrenb\"{a}cher, Judith and Hassenzahl, Marc},
title = {Changing Perspective: A Co-Design Approach to Explore Future Possibilities of Divergent Hearing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300259},
abstract = {Conventional hearing aids frame hearing impairment almost exclusively as a problem.
In the present paper, we took an alternative approach by focusing on positive future
possibilities of 'divergent hearing'. To this end, we developed a method to speculate
simultaneously about not-yet-experienced positive meanings and not-yet-existing technology.
First, we gathered already existing activities in which divergent hearing was experienced
as an advantage rather than as a burden. These activities were then condensed into 'Prompts of Positive Possibilities' (PPP), such as 'Creating a shelter to feel safe
in". In performative sessions, participants were given these PPPs and 'Open Probes'
to enact novel everyday activities. This led to 26 possible meanings and according
devices, such as "Being able to listen back into the past with a rewinder". The paper
provides valuable insights into the interests and expectations of people with divergent
hearing as well as a methodological contribution to a possibility-driven design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300260,
author = {Hazzard, Adrian and Greenhalgh, Chris and Kallionpaa, Maria and Benford, Steve and Veinberg, Anne and Kanga, Zubin and McPherson, Andrew},
title = {Failing with Style: Designing for Aesthetic Failure in Interactive Performance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300260},
abstract = {Failure is a common artefact of challenging experiences, a fact of life for interactive
systems but also a resource for aesthetic and improvisational performance. We present
a study of how three professional pianists performed an interactive piano composition
that included playing hidden codes within the music so as to control their path through
the piece and trigger system actions. We reveal how apparent failures to play the
codes occurred for diverse reasons including mistakes in their playing, limitations
of the system, but also deliberate failures as a way of controlling the system, and
how these failures provoked aesthetic and improvised responses from the performers.
We propose that creative and performative interfaces should be designed to enable
aesthetic failures and introduce a taxonomy that compares human approaches to failure
with approaches to capable systems, revealing new creative design strategies of gaming,
taming, riding and serving the system.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300261,
author = {Yang, Diyi and Yao, Zheng and Seering, Joseph and Kraut, Robert},
title = {The Channel Matters: Self-Disclosure, Reciprocity and Social Support in Online Cancer Support Groups},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300261},
abstract = {People with health concerns go to online health support groups to obtain help and
advice. To do so, they frequently disclose personal details, many times in public.
Although research in non-health settings suggests that people self-disclose less in
public than in private, this pattern may not apply to health support groups where
people want to get relevant help. Our work examines how the use of private and public
channels influences members' self-disclosure in an online cancer support group, and
how channels moderate the influence of self-disclosure on reciprocity and receiving
support. By automatically measuring people's self-disclosure at scale, we found that
members of cancer support groups revealed more negative self-disclosure in the public
channels compared to the private channels. Although one's self-disclosure leads others
to self-disclose and to provide support, these effects were generally stronger in
the private channel. These channel effects probably occur because the public channels
are the primary venue for support exchange, while the private channels are mainly
used for follow-up conversations. We discuss theoretical and practical implications
of our work.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300262,
author = {Mason, Liam and Gerling, Kathrin and Dickinson, Patrick and De Angeli, Antonella},
title = {Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300262},
abstract = {Playful technology has the potential to support physical activity (PA) among wheelchair
users, but little is known about design considerations for this audience, who experience
significant access barriers. In this paper, we lever-age the Integrated Behavioural
Model (IBM) to understand wheelchair users' perspectives on PA, technology, and play.First,
we present findings from an interview study with eight physically active wheelchair
users. Second, we build on the interviews in a survey that received 44 responses from
a broader group of wheelchair users. Results show that the anticipation of positive
experiences was the strongest predictor of engagement with PA, and that accessibility
concerns act as barriers both in terms of PA participation and technology use. We
present four design goals - emphasizing enjoyment,involving others, building knowledge
and enabling flexibility - to make our findings actionable for researchers and designers
wishing to create accessible playful technology to support PA.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300263,
author = {Dagan, Ella and M\'{a}rquez Segura, Elena and Altarriba Bertran, Ferran and Flores, Miguel and Isbister, Katherine},
title = {Designing 'True Colors': A Social Wearable That Affords Vulnerability},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300263},
abstract = {Vulnerability is a common experience in everyday life and is frequently perceived
as a flaw to be excised in technology design. Yet, research indicates it is an essential
aspect of wholehearted living among others. In this paper, we present the design and
deployment of 'True Colors', a novel wearable device intended to support social interaction
in a live action roleplay game (LARP) setting. We describe the Research-through-Design
process that helped us to discover and articulate the possibility space of vulnerability
in the design of social wearables, as support for producing a sense of social empowerment
and connection among wearers within the LARP. We draw conclusions that may be of value
to others designing wearables and related technologies aimed at supporting co-located
social interaction in games/play.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300264,
author = {Odom, William and Wakkary, Ron and Hol, Jeroen and Naus, Bram and Verburg, Pepijn and Amram, Tal and Chen, Amy Yo Sue},
title = {Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300264},
abstract = {We describe the design and deployment of Olly, a domestic music player that enables
people to re-experience digital music they listened to in the past. Olly uses its
owner's Last.FM listening history metadata archive to occasionally select a song from
their past, but offers no user control over what is selected or when. We deployed
Olly in 3 homes for 15 months to explore how its slow pace might support experiences
of reflection and reminiscence. Findings revealed that Olly became highly integrated
in participants lives with sustained engagement over time. They drew on Olly to reflect
on past life experiences and reactions indicated an increase in perceived value of
their Last.FM archive. Olly also provoked reflections on the temporalities of personal
data and technology. Findings are interpreted to present opportunities for future
HCI research and practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300265,
author = {Devendorf, Laura and Andersen, Kristina and Rosner, Daniela K. and Wakkary, Ron and Pierce, James},
title = {From HCI to HCI-Amusement: Strategies for Engaging What New Technology Makes Old},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300265},
abstract = {Notions of what counts as a contribution to HCI continue to be contested as our field
expands to accommodate perspectives from the arts and humanities. This paper aims
to advance the position of the arts and further contribute to these debates by actively
exploring what a "non-contribution" would look like in HCI. We do this by taking inspiration
from Fluxus, a collective of artists in the 1950's and 1960's who actively challenged
and reworked practices of fine arts institutions by producing radically accessible,
ephemeral, and modest works of "art-amusement." We use Fluxus to develop three analogous
forms of "HCI-amusements," each of which shed light on dominant practices and values
within HCI by resisting to fit into its logics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300266,
author = {Antle, Alissa N. and McLaren, Elgin-Skye and Fiedler, Holly and Johnson, Naomi},
title = {Evaluating the Impact of a Mobile Neurofeedback App for Young Children at School and Home},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300266},
abstract = {About 18% of children in industrialized countries suffer from anxiety. We designed
a mobile neurofeedback app, called Mind-Full, based on existing design guidelines.
Our goal was for young children in lower socio-economic status schools to improve
their ability to self-regulate anxiety by using Mind-Full. In this paper we report
on quantitative outcomes from a sixteen-week field evaluation with 20 young children
(aged 5 to 8). Our methodological contribution includes using a control group, validated
measures of anxiety and stress, and assessing transfer and maintenance. Results from
teacher and parent behavioral surveys indicated gains in children's ability to self-regulate
anxiety at school and home; a decrease in anxious behaviors at home; and cortisol
tests showed variable improvement in physiological stress levels. We contribute to
HCI for mental health with evidence that it is viable to use a mobile app in lower
socio-economic status schools to improve children's mental health.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300267,
author = {Gu, Jianzhe and Breen, David E. and Hu, Jenny and Zhu, Lifeng and Tao, Ye and Van de Zande, Tyson and Wang, Guanyun and Zhang, Yongjie Jessica and Yao, Lining},
title = {Geodesy: Self-Rising 2.5D Tiles by Printing along 2D Geodesic Closed Path},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300267},
abstract = {Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding
to allow for space- and material-saving 2D printed sheets morphing into 3D shapes
when heated. However, to our knowledge, all the known examples are either origami-based
models with obvious folding hinges, or beam-based models with holes on the morphing
surfaces. Morphing continuous double-curvature surfaces remains a challenge, both
in terms of a tailored toolpath-planning strategy and a computational model that simulates
it. Additionally, neither approach takes surface texture as a design parameter in
its computational pipeline. To extend the design space of FDM-based 4D printing, in
Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface
textures. We suggest a unique tool path - printing thermoplastics along 2D closed
geodesic paths to form a surface with one raised continuous double-curvature tiles
when exposed to heat. The design space is further extended to more complex geometries
composed of a network of rising tiles (i.e., surface textures). Both design components
and the computational pipeline are explained in the paper, followed by several printed
geometric examples.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300268,
author = {McCormack, Jon and Gifford, Toby and Hutchings, Patrick and Llano Rodriguez, Maria Teresa and Yee-King, Matthew and d'Inverno, Mark},
title = {In a Silent Way: Communication Between AI and Improvising Musicians Beyond Sound},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300268},
abstract = {Collaboration is built on trust, and establishing trust with a creative Artificial
Intelligence is difficult when the decision process or internal state driving its
behaviour isn't exposed. When human musicians improvise together, a number of extra-musical
cues are used to augment musical communication and expose mental or emotional states
which affect musical decisions and the effectiveness of the collaboration. We developed
a collaborative improvising AI drummer that communicates its confidence through an
emoticon-based visualisation. The AI was trained on musical performance data, as well
as real-time skin conductance, of musicians improvising with professional drummers,
exposing both musical and extra-musical cues to inform its generative process. Uni-
and bi-directional extra-musical communication with real and false values were tested
by experienced improvising musicians. Each condition was evaluated using the FSS-2
questionnaire, as a proxy for musical engagement. The results show a positive correlation
between extra-musical communication of machine internal state and human musical engagement.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300269,
author = {Echeverria, Vanessa and Martinez-Maldonado, Roberto and Buckingham Shum, Simon},
title = {Towards Collaboration Translucence: Giving Meaning to Multimodal Group Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300269},
abstract = {Collocated, face-to-face teamwork remains a pervasive mode of working, which is hard
to replicate online. Team members' embodied, multimodal interaction with each other
and artefacts has been studied by researchers, but due to its complexity, has remained
opaque to automated analysis. However, the ready availability of sensors makes it
increasingly affordable to instrument work spaces to study teamwork and groupwork.
The possibility of visualising key aspects of a collaboration has huge potential for
both academic and professional learning, but a frontline challenge is the enrichment
of quantitative data streams with the qualitative insights needed to make sense of
them. In response, we introduce the concept of collaboration translucence, an approach
to make visible selected features of group activity. This is grounded both theoretically
(in the physical, epistemic, social and affective dimensions of group activity), and
contextually (using domain-specific concepts). We illustrate the approach from the
automated analysis of healthcare simulations to train nurses, generating four visual
proxies that fuse multimodal data into higher order patterns.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300270,
author = {Braun, Michael and Mainz, Anja and Chadowitz, Ronee and Pfleging, Bastian and Alt, Florian},
title = {At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300270},
abstract = {This paper investigates personalized voice characters for in-car speech interfaces.
In particular, we report on how we designed different personalities for voice assistants
and compared them in a real world driving study. Voice assistants have become important
for a wide range of use cases, yet current interfaces are using the same style of
auditory response in every situation, despite varying user needs and personalities.
To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt,
and Butler) and compared them to a baseline (Default) in a between-subject study in
real traffic conditions. Our results show higher likability and trust for assistants
that correctly match the user's personality while we observed lower likability, trust,
satisfaction, and usefulness for incorrectly matched personalities, each in comparison
with the Default character. We discuss design aspects for voice assistants in different
automotive use cases.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300271,
author = {Brown, Anna and Chouldechova, Alexandra and Putnam-Hornstein, Emily and Tobin, Andrew and Vaithianathan, Rhema},
title = {Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-Making in Child Welfare Services},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300271},
abstract = {Algorithmic decision-making systems are increasingly being adopted by government public
service agencies. Researchers, policy experts, and civil rights groups have all voiced
concerns that such systems are being deployed without adequate consideration of potential
harms, disparate impacts, and public accountability practices. Yet little is known
about the concerns of those most likely to be affected by these systems. We report
on workshops conducted to learn about the concerns of affected communities in the
context of child welfare services. The workshops involved 83 study participants including
families involved in the child welfare system, employees of child welfare agencies,
and service providers. Our findings indicate that general distrust in the existing
system contributes significantly to low comfort in algorithmic decision-making. We
identify strategies for improving comfort through greater transparency and improved
communication strategies. We discuss the implications of our study for accountable
algorithm design for child welfare applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300272,
author = {Romat, Hugo and Henry Riche, Nathalie and Hinckley, Ken and Lee, Bongshin and Appert, Caroline and Pietriga, Emmanuel and Collins, Christopher},
title = {ActiveInk: (Th)Inking with Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300272},
abstract = {During sensemaking, people annotate insights: underlining sentences in a document
or circling regions on a map. They jot down their hypotheses: drawing correlation
lines on scatterplots or creating personal legends to track patterns. We present ActiveInk,
a system enabling people to seamlessly transition between exploring data and externalizing
their thoughts using pen and touch. ActiveInk enables the natural use of pen for active
reading behaviors, while supporting analytic actions by activating any of these ink
strokes. Through a qualitative study with eight participants, we contribute observations
of active reading behaviors during data exploration and design principles to support
sensemaking.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300273,
author = {Kittley-Davies, Jacob and Alqaraawi, Ahmed and Yang, Rayoung and Costanza, Enrico and Rogers, Alex and Stein, Sebastian},
title = {Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300273},
abstract = {Computer vision and pattern recognition are increasingly being employed by smartphone
and tablet applications targeted at lay-users. An open design challenge is to make
such systems intelligible without requiring users to become technical experts. This
paper reports a lab study examining the role of visual feedback. Our findings indicate
that the stage of processing from which feedback is derived plays an important role
in users' ability to develop coherent and correct understandings of a system's operation.
Participants in our study showed a tendency to misunderstand the meaning being conveyed
by the feedback, relating it to processing outcomes and higher level concepts, when
in reality the feedback represented low level features. Drawing on the experimental
results and the qualitative data collected, we discuss the challenges of designing
interactions around pattern matching algorithms.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300274,
author = {Freeman, Guo and Bardzell, Jeffrey and Bardzell, Shaowen and Liu, Szu-Yu (Cyn) and Lu, Xi and Cao, Diandian},
title = {Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300274},
abstract = {What makes a city meaningful to its residents? What attracts people to live in a city
and to care for it? Today, we might see such questions as concerns for HCI, given
the emerging agendas of smart and connected cities, IoT, and ubiquitous computing:
city residents' perceptions of and attitudes towards smart city technologies will
play a role in technology acceptance. Theories of "placemaking" from humanist geography
and urban planning address themselves to such concerns, and they have been taken up
in HCI and urban informatics research. This theory offers ideas for developing community
attachment, heightening the legibility of the city, and intensifying lived experiences
in the city. We add to this body of research with an analysis of several initiatives
of City Yeast, a community-based design collective in Taiwan that proposes the metaphor
of fermentation as an approach to placemaking. We unpack how this approach shapes
their design practice and link its implications to urban informatics research in HCI.
We suggest that smart cities can also be pursued by leveraging the knowledge of city
residents and helping to facilitate their participation in acts of perceiving, envisioning,
and improving their local communities, including but not limited to smart and connected
technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300275,
author = {Pierce, James},
title = {Smart Home Security Cameras and Shifting Lines of Creepiness: A Design-Led Inquiry},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300275},
abstract = {Through a design-led inquiry focused on smart home security cameras, this research
develops three key concepts for research and design pertaining to new and emerging
digital consumer technologies. Digital leakage names the propensity for digital information
to be shared, stolen, and misused in ways unbeknownst or even harmful to those to
whom the data pertains or belongs. Hole-and-corner applications are those functions
connected to users' data, devices, and interactions yet concealed from or downplayed
to them, often because they are non-beneficial or harmful to them. Foot-in-the-door
devices are product and services with functional offerings and affordances that work
to normalize and integrate a technology, thus laying groundwork for future adoption
of features that might have earlier been rejected as unacceptable or unnecessary.
Developed and illustrated through a set of design studies and explorations, this paper
shows how these concepts may be used analytically to investigate issues such as privacy
and security, anticipatorily to speculate about the future of technology development
and use, and generatively to synthesize design concepts and solutions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300276,
author = {Findlater, Leah and Chinh, Bonnie and Jain, Dhruv and Froehlich, Jon and Kushalnagar, Raja and Lin, Angela Carey},
title = {Deaf and Hard-of-Hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300276},
abstract = {To investigate preferences for mobile and wearable sound awareness systems, we conducted
an online survey with 201 DHH participants. The survey explores how demographic factors
affect perceptions of sound awareness technologies, gauges interest in specific sounds
and sound characteristics, solicits reactions to three design scenarios (smartphone,
smartwatch, head-mounted display) and two output modalities (visual, haptic), and
probes issues related to social context of use. While most participants were highly
interested in being aware of sounds, this interest was modulated by communication
preference--that is, for sign or oral communication or both. Almost all participants
wanted both visual and haptic feedback and 75% preferred to have that feedback on
separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other
findings related to sound type, full captions vs. keywords, sound filtering, notification
styles, and social context provide direct guidance for the design of future mobile
and wearable sound awareness systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300277,
author = {Myers, Chelsea M. and Furqan, Anushay and Zhu, Jichen},
title = {The Impact of User Characteristics and Preferences on Performance with an Unfamiliar Voice User Interface},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300277},
abstract = {Voice User Interfaces (VUIs) are increasing in popularity. However, their invisible
nature with no or limited visuals makes it difficult for users to interact with unfamiliar
VUIs. We analyze the impact of user characteristics and preferences on how users interact
with a VUI-based calendar, DiscoverCal. While recent VUI studies analyze user behavior
through self-reported data, we extend this research by analyzing both VUI usage data
and self-reported data to observe correlations between both data types. Results from
our user study (n=50) led to four key findings: 1) programming experience did not
have a wide-spread impact on performance metrics while 2) assimilation bias did, 3)
participants with more technical confidence exhibited a trial-and-error approach,
and 4) desiring more guidance from our VUI correlated with performance metrics that
indicate cautious users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300278,
author = {Strasnick, Evan and Follmer, Sean and Agrawala, Maneesh},
title = {Pinpoint: A PCB Debugging Pipeline Using Interruptible Routing and Instrumentation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300278},
abstract = {Difficulties in accessing, isolating, and iterating on the components and connections
of a printed circuit board (PCB) create unique challenges in PCB debugging. Manual
probing methods are slow and error prone, and even dedicated PCB testing equipment
remains limited by its inability to modify the circuit during testing. We present
Pinpoint, a tool that facilitates in-circuit PCB debugging through techniques such
as programmatically probing signals, dynamically disconnecting components and subcircuits
to test in isolation, and splicing in new elements to explore potential modifications.
Pinpoint automatically instruments a PCB design and generates designs for a physical
jig board that interfaces the user's PCB to our custom testing hardware and to software
tools. We evaluate Pinpoint's ability to facilitate the debugging of various PCB issues
by instrumenting and testing different classes of boards, as well as by characterizing
its technical limitations and by soliciting feedback through a guided exploration
with PCB designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300279,
author = {Kou, Yubo and Gray, Colin M.},
title = {A Practice-Led Account of the Conceptual Evolution of UX Knowledge},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300279},
abstract = {The contours of user experience (UX) design practice have been shaped by a diverse
array of practitioners and disciplines, resulting in a diffuse and decentralized body
of UX-specific disciplinary knowledge. The rapidly shifting space that UX knowledge
occupies, in conjunction with a long-existing research-practice gap, presents unique
challenges and opportunities to UX educators and aspiring UX designers. In this paper,
we analyzed a corpus of question and answer communication on UX Stack Exchange using
a practice-led approach, identifying and documenting practitioners' conceptions of
UX knowledge over a nine year period. Specifically, we used natural language processing
techniques and qualitative content analysis to identify a disciplinary vocabulary
invoked by UX designers in this online community, as well as conceptual trajectories
spanning over nine years which could shed light on the evolution of UX practice. We
further describe the implications of our findings for HCI research and UX education.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300280,
author = {Kong, Ha-Kyung and Zhu, Wenjie and Liu, Zhicheng and Karahalios, Karrie},
title = {Understanding Visual Cues in Visualizations Accompanied by Audio Narrations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300280},
abstract = {It is often assumed that visual cues, which highlight specific parts of a visualization
to guide the audience's attention, facilitate visualization storytelling and presentation.
This assumption has not been systematically studied. We present an in-lab experiment
and a Mechanical Turk study to examine the effects of integral and separable visual
cues on the recall and comprehension of visualizations that are accompanied by audio
narration. Eye-tracking data in the in-lab experiment confirm that cues helped the
viewers focus on relevant parts of the visualization faster. We found that in general,
visual cues did not have a significant effect on learning outcomes, but for specific
cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly
improved comprehension. Based on these results, we discuss how presenters might select
visual cues depending on the role of the cues and the visualization type.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300281,
author = {van Berkel, Niels and Goncalves, Jorge and Koval, Peter and Hosio, Simo and Dingler, Tilman and Ferreira, Denzil and Kostakos, Vassilis},
title = {Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300281},
abstract = {Mobile self-reports are a popular technique to collect participant labelled data in
the wild. While literature has focused on increasing participant compliance to self-report
questionnaires, relatively little work has assessed response accuracy. In this paper,
we investigate how participant context can affect response accuracy and help identify
strategies to improve the accuracy of mobile self-report data. In a 3-week study we
collect over 2,500 questionnaires containing both verifiable and non-verifiable questions.
We find that response accuracy is higher for questionnaires that arrive when the phone
is not in ongoing or very recent use. Furthermore, our results show that long completion
times are an indicator of a lower accuracy. Using contextual mechanisms readily available
on smartphones, we are able to explain up to 13% of the variance in participant accuracy.
We offer actionable recommendations to assist researchers in their future deployments
of mobile self-report studies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300282,
author = {Kayukawa, Seita and Higuchi, Keita and Guerreiro, Jo\~{a}o and Morishima, Shigeo and Sato, Yoichi and Kitani, Kris and Asakawa, Chieko},
title = {BBeep: A Sonic Collision Avoidance System for Blind Travellers and Nearby Pedestrians},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300282},
abstract = {We present an assistive suitcase system, BBeep, for supporting blind people when walking
through crowded environments. BBeep uses pre-emptive sound notifications to help clear
a path by alerting both the user and nearby pedestrians about the potential risk of
collision. BBeep triggers notifications by tracking pedestrians, predicting their
future position in real-time, and provides sound notifications only when it anticipates
a future collision. We investigate how different types and timings of sound affect
nearby pedestrian behavior. In our experiments, we found that sound emission timing
has a significant impact on nearby pedestrian trajectories when compared to different
sound types. Based on these findings, we performed a real-world user study at an international
airport, where blind participants navigated with the suitcase in crowded areas. We
observed that the proposed system significantly reduces the number of imminent collisions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300283,
author = {Vorvoreanu, Mihaela and Zhang, Lingyi and Huang, Yun-Han and Hilderbrand, Claudia and Steine-Hanson, Zoe and Burnett, Margaret},
title = {From Gender Biases to Gender-Inclusive Design: An Empirical Investigation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300283},
abstract = {In recent years, research has revealed gender biases in numerous software products.
But although some researchers have found ways to improve gender participation in specific
software projects, general methods focus mainly on detecting gender biases -- not
fixing them. To help fill this gap, we investigated whether the GenderMag bias detection
method can lead directly to designs with fewer gender biases. In our 3-step investigation,
two HCI researchers analyzed an industrial software product using GenderMag; we derived
design changes to the product using the biases they found; and ran an empirical study
of participants using the original product versus the new version. The results showed
that using the method in this way did improve the software's inclusiveness: women
succeeded more often in the new version than in the original; men's success rates
improved too; and the gender gap entirely disappeared.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300284,
author = {Pollmann, Kathrin and Stefani, Oilver and Bengsch, Amelie and Peissner, Matthias and Vukeli\'{c}, Mathias},
title = {How to Work in the Car of the Future? A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300284},
abstract = {Autonomous driving provides new opportunities for the use of time during a car ride.
One such important scenario is working. We conducted a neuroergonomical study to compare
three configurations of a car interior (based on lighting, visual stimulation, sound)
regarding their potential to support productive work. We assessed participants? concentration,
performance and workload with subjective, behavioral and EEG measures while they carried
out two different concentration tasks during simulated autonomous driving. Our results
show that a configuration with a large-area, bright light with high blue components,
and reduced visual and auditory stimuli promote performance, quality, efficiency,
increased concentration and lower cognitive workload. Increased visual and auditory
stimulation paired with linear, darker light with very few blue components resulted
in lower performance, reduced subjective concentration, and higher cognitive workload,
but did not differ from a normal car configuration. Our multi-method approach thus
reveals possible car interior configurations for an ideal workspace.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300285,
author = {Zhang, Yang and Pahud, Michel and Holz, Christian and Xia, Haijun and Laput, Gierad and McGuffin, Michael and Tu, Xiao and Mittereder, Andrew and Su, Fei and Buxton, William and Hinckley, Ken},
title = {Sensing Posture-Aware Pen+Touch Interaction on Tablets},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300285},
abstract = {Many status-quo interfaces for tablets with pen + touch input capabilities force users
to reach for device-centric UI widgets at fixed locations, rather than sensing and
adapting to the user-centric posture. To address this problem, we propose sensing
techniques that transition between various nuances of mobile and stationary use via
postural awareness. These postural nuances include shifting hand grips, varying screen
angle and orientation, planting the palm while writing or sketching, and detecting
what direction the hands approach from. To achieve this, our system combines three
sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and
3) electric field sensors around the screen bezel for grasp and hand proximity detection.
We show how these sensors enable posture-aware pen+touch techniques that adapt interaction
and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-,
and grip-centric frames of reference.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300286,
author = {Arora, Jatin and Saini, Aryan and Mehra, Nirmita and Jain, Varnit and Shrey, Shwetank and Parnami, Aman},
title = {VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300286},
abstract = {Often Virtual Reality (VR) experiences are limited by the design of standard controllers.
This work aims to liberate a VR developer from these limitations in the physical realm
to provide an expressive match to the limitless possibilities in the virtual realm.
VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation
enabled controllers for VR, by offering a set of feature bricks that emulate as well
as extend the capabilities of default controllers. Based on the LEGO platform, the
toolkit provides a modular, scalable solution for enabling passive haptics in VR.
We demonstrate the versatility of our designs through a rich set of applications including
re-implementations of artifacts from recent research. We share a VR Integration package
for integration with Unity VR IDE, the CAD models for the feature bricks, for easy
deployment of VirtualBricks within the community.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300287,
author = {Sethapakdi, Ticha and McCann, James},
title = {Painting with CATS: Camera-Aided Texture Synthesis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300287},
abstract = {We present CATS, a digital painting system that synthesizes textures from live video
in real-time, short-cutting the typical brush- and texture- gathering workflow. Through
the use of boundary-aware texture synthesis, CATS produces strokes that are non-repeating
and blend smoothly with each other. This allows CATS to produce paintings that would
be difficult to create with traditional art supplies or existing software. We evaluated
the effectiveness of CATS by asking artists to integrate the tool into their creative
practice for two weeks; their paintings and feedback demonstrate that CATS is an expressive
tool which can be used to create richly textured paintings.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300288,
author = {Petford, Julian and Carson, Iain and Nacenta, Miguel A. and Gutwin, Carl},
title = {A Comparison of Notification Techniques for Out-of-View Objects in Full-Coverage Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300288},
abstract = {Full-coverage displays can place visual content anywhere on the interior surfaces
of a room (e.g., a weather display near the coat stand). In these settings, digital
artefacts can be located behind the user and out of their field of view - meaning
that it can be difficult to notify the user when these artefacts need attention. Although
much research has been carried out on notification, little is known about how best
to direct people to the necessary location in room environments. We designed five
diverse attention-guiding techniques for full-coverage display rooms, and evaluated
them in a study where participants completed search tasks guided by the different
techniques. Our study provides new results about notification in full-coverage displays:
we showed benefits of persistent visualisations that could be followed all the way
to the target and that indicate distance-to-target. Our findings provide useful information
for improving the usability of interactive full-coverage environments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300289,
author = {Cassidy, Brendan and Read, Janet C. and MacKenzie, I. Scott},
title = {An Evaluation of Radar Metaphors for Providing Directional Stimuli Using Non-Verbal Sound},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300289},
abstract = {We compared four audio-based radar metaphors for providing directional stimuli to
users of AR headsets. The metaphors are clock face, compass, white noise, and scale.
Each metaphor, or method, signals the movement of a virtual arm in a radar sweep.
In a user study, statistically significant differences were observed for accuracy
and response time. Beat-based methods (clock face, compass) elicited responses biased
to the left of the stimulus location, and non-beat-based methods (white noise, scale)
produced responses biased to the right of the stimulus location. The beat methods
were more accurate than the non-beat methods. However, the non-beat methods elicited
quicker responses. We also discuss how response accuracy varies along the radar sweep
between methods. These observations contribute design insights for non-verbal, non-visual
directional prompting.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8}
}

@inbook{10.1145/3290605.3300290,
author = {Gulay, Emrecan and Lucero, Andr\'{e}s},
title = {Integrated Workflows: Generating Feedback Between Digital and Physical Realms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300290},
abstract = {As design thinking shifted away from conventional methods with the rapid adoption
of computer-aided design and fabrication technologies, architects have been seeking
ways to initiate a comprehensive dialogue between the virtual and the material realms.
Current methodologies do not offer embodied workflows that utilize the feedback obtained
through a subsequent transition process between physical and digital design. Therefore,
narrowing the separation between these two platforms remains as a research problem.
This literature review elaborates the divide between physical and digital design,
testing and manufacturing techniques in the morphological process of architectural
form. We first review the digital transformation in the architectural design discourse.
Then, we proceed by introducing a variety of methods that are integrating digital
and physical workflows and suggesting an alternative approach. Our work unveils that
there is a need for empirical research with a focus on integrated approaches to create
intuitively embodied experiences for architectural designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300291,
author = {Hope, Alexis and D'Ignazio, Catherine and Hoy, Josephine and Michelson, Rebecca and Roberts, Jennifer and Krontiris, Kate and Zuckerman, Ethan},
title = {Hackathons as Participatory Design: Iterating Feminist Utopias},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300291},
abstract = {Breastfeeding is not only a public health issue, but also a matter of economic and
social justice. This paper presents an iteration of a participatory design process
to create spaces for re-imagining products, services, systems, and policies that support
breastfeeding in the United States. Our work contributes to a growing literature around
making hackathons more inclusive and accessible, designing participatory processes
that center marginalized voices, and incorporating systems- and relationship-based
approaches to problem solving. By presenting an honest assessment of the successes
and shortcomings of the first iteration of a hackathon, we explain how we re-structured
the second "Make the Breast Pump Not Suck" hackathon in service of equity and systems
design. Key to our re-imagining of conventional innovation structures is a focus on
experience design, where joy and play serve as key strategies to help people and institutions
build relationships across lines of difference. We conclude with a discussion of design
principles applicable not only to designers of events, but to social movement researchers
and HCI scholars trying to address oppression through the design of technologies and
socio-technical systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300292,
author = {Saha, Manaswi and Saugstad, Michael and Maddali, Hanuma Teja and Zeng, Aileen and Holland, Ryan and Bower, Steven and Dash, Aditya and Chen, Sage and Li, Anthony and Hara, Kotaro and Froehlich, Jon},
title = {Project Sidewalk: A Web-Based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300292},
abstract = {We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers
to remotely label pedestrian-related accessibility problems by virtually walking through
city streets in Google Street View. To train, engage, and sustain users, we apply
basic game design principles such as interactive onboarding, mission-based tasks,
and progress dashboards. In an 18-month deployment study, 797 online users contributed
205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral
and labeling quality differences between paid crowdworkers and volunteers, investigate
the effects of label type, label severity, and majority vote on accuracy, and analyze
common labeling errors. To complement these findings, we report on an interview study
with three key stakeholder groups (N=14) soliciting reactions to our tool and methods.
Our findings demonstrate the potential of virtually auditing urban accessibility and
highlight tradeoffs between scalability and quality compared to traditional approaches.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300293,
author = {Piazentin Ono, Jorge and Gjoka, Arvi and Salamon, Justin and Dietrich, Carlos and Silva, Claudio T.},
title = {HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300293},
abstract = {The sport data tracking systems available today are based on specialized hardware
(high-definition cameras, speed radars, RFID) to detect and track targets on the field.
While effective, implementing and maintaining these systems pose a number of challenges,
including high cost and need for close human monitoring. On the other hand, the sports
analytics community has been exploring human computation and crowdsourcing in order
to produce tracking data that is trustworthy, cheaper and more accessible. However,
state-of-the-art methods require a large number of users to perform the annotation,
or put too much burden into a single user. We propose HistoryTracker, a methodology
that facilitates the creation of tracking data for baseball games by warm-starting
the annotation process using a vast collection of historical data. We show that HistoryTracker
helps users to produce tracking data in a fast and reliable way.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300294,
author = {Pruksachatkun, Yada and Pendse, Sachin R. and Sharma, Amit},
title = {Moments of Change: Analyzing Peer-Based Cognitive Support in Online Mental Health Forums},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300294},
abstract = {Clinical psychology literature indicates that reframing ir- rational thoughts can
help bring positive cognitive change to those suffering from mental distress. Through
data from an online mental health forum, we study how these cognitive processes play
out in peer-to-peer conversations. Acknowledging the complexity of measuring cognitive
change, we first provide an operational definition of a "moment of change" based on
sentiment change in online conversations. Using this definition, we propose a predictive
model that can identify whether a conversation thread or a post is associated with
a moment of cognitive change. Consistent with psychological literature, we find that
markers of language associated with sentiment and and affect are the most predictive.
Further, cultural differences play an important role: predictive models trained on
one country generalize poorly to others. To understand how a moment of change happens,
we build a model that explicitly tracks topic and associated sentiment in a forum
thread.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300295,
author = {Dragicevic, Pierre and Jansen, Yvonne and Sarma, Abhraneel and Kay, Matthew and Chevalier, Fanny},
title = {Increasing the Transparency of Research Papers with Explorable Multiverse Analyses},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300295},
abstract = {We present explorable multiverse analysis reports, a new approach to statistical reporting
where readers of research papers can explore alternative analysis options by interacting
with the paper itself. This approach draws from two recent ideas: i) multiverse analysis,
a philosophy of statistical reporting where paper authors report the outcomes of many
different statistical analyses in order to show how fragile or robust their findings
are; and ii) explorable explanations, narratives that can be read as normal explanations
but where the reader can also become active by dynamically changing some elements
of the explanation. Based on five examples and a design space analysis, we show how
combining those two ideas can complement existing reporting approaches and constitute
a step towards more transparent research papers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300296,
author = {Wauck, Helen C. and Mekler, Elisa D. and Fu, Wai-Tat},
title = {A Player-Centric Approach to Designing Spatial Skill Training Games},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300296},
abstract = {Certain video games show promise as tools for training spatial skills, one of the
strongest predictors of future success in STEM. However, little is known about the
gaming preferences of those who would benefit the most from such interventions: low
spatial skill students. To provide guidance on how to design training games for this
population, we conducted a survey of 350 participants from three populations: online
college-age, students from a low SES high school, and students from a high SES high
school. Participants took a timed test of spatial skills and then answered questions
about their demographics, gameplay habits, preferences, and motivations. The only
predictors of spatial skill were gender and population: female participants from online
and low SES high school populations had the lowest spatial skill. In light of these
findings, we provide design recommendations for game-based spatial skill interventions
targeting low spatial skill students.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300297,
author = {Ma, Xiao and Cheng, Justin and Iyer, Shankar and Naaman, Mor},
title = {When Do People Trust Their Social Groups?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300297},
abstract = {Trust facilitates cooperation and supports positive outcomes in social groups, including
member satisfaction, information sharing, and task performance. Extensive prior research
has examined individuals' general propensity to trust, as well as the factors that
contribute to their trust in specific groups. Here, we build on past work to present
a comprehensive framework for predicting trust in groups. By surveying 6,383 Facebook
Groups users about their trust attitudes and examining aggregated behavioral and demographic
data for these individuals, we show that (1) an individual's propensity to trust is
associated with how they trust their groups, (2) smaller, closed, older, more exclusive,
or more homogeneous groups are trusted more, and (3) a group's overall friendship-network
structure and an individual's position within that structure can also predict trust.
Last, we demonstrate how group trust predicts outcomes at both individual and group
level such as the formation of new friendship ties.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300298,
author = {Choi, In Kwon and Childers, Taylor and Raveendranath, Nirmal Kumar and Mishra, Swati and Harris, Kyle and Reda, Khairi},
title = {Concept-Driven Visual Analytics: An Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300298},
abstract = {Visualization tools facilitate exploratory data analysis, but fall short at supporting
hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations
might support a concept-driven analysis style, where users can optionally share their
hypotheses and conceptual models in natural language, and receive customized plots
depicting the fit of their models to the data. We report on how participants leveraged
these unique affordances for visual analysis. We found that a majority of participants
articulated meaningful models and predictions, utilizing them as entry points to sensemaking.
We contribute an abstract typology representing the types of models participants held
and externalized as data expectations. Our findings suggest ways for rearchitecting
visual analytics tools to better support hypothesis- and model-based reasoning, in
addition to their traditional role in exploratory analysis. We discuss the design
implications and reflect on the potential benefits and challenges involved.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300299,
author = {Baumgartner, Juergen and Frei, Naomi and Kleinke, Mascha and Sauer, Juergen and Sonderegger, Andreas},
title = {Pictorial System Usability Scale (P-SUS): Developing an Instrument for Measuring Perceived Usability},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300299},
abstract = {We have developed a pictorial multi-item scale, called P-SUS (Pictorial System Usability
Scale), which aims to measure the perceived usability of mobile devices. The scale
is based on the established verbal usability questionnaire SUS (System Usability Scale).
A user-centred design process was employed to develop and refine its 10 pictorial
items. The scale was tested in a first validation study (N=60) using student participants.
Psychometric properties (convergent validity, criterion-related validity, sensitivity,
and reliability), as well as the motivation to fill in the scale were assessed. The
results indicated satisfactory convergent validity for about two-thirds of the items.
Furthermore, strong correlations were obtained for the sum scores between verbal and
pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal
questionnaire. The P-SUS represents a first attempt to provide a pictorial usability
scale for the evaluation of (mobile) devices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300300,
author = {Feltwell, Tom and Wood, Gavin and Rowland, Scarlett and Long, Kiel S. and Elsden, Chris and Brooker, Phillip and Vines, John and Briggs, Pamela and Barnett, Julie and Lawson, Shaun},
title = {Designing Second-Screening Experiences for Social Co-Selection and Critical Co-Viewing of Reality TV},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300300},
abstract = {Public commentary related to reality TV can be overwhelmed by thoughtless reactions
and negative sentiments, which often problematically reinforce the cultural stereotyping
typically employed in such media. We describe the design, and month-long evaluation,
of a mobile "second-screening" application, Screenr, which uses co-voting and live
textual tagging to encourage more critical co-viewing in these contexts. Our findings
highlight how Screenr supported interrogation of the production qualities and claims
of shows, promoted critical discourse around the motivations of programmes, and engaged
participants in reflecting on their own assumptions and views. We situate our results
within the context of existing second-screening co-viewing work, discuss implications
for such technologies to support critical engagement with socio-political media, and
provide design implications for future digital technologies in this domain.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300301,
author = {Lee, Jaeyeon and Sinclair, Mike and Gonzalez-Franco, Mar and Ofek, Eyal and Holz, Christian},
title = {TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300301},
abstract = {Recent hand-held controllers have explored a variety of haptic feedback sensations
for users in virtual reality by producing both kinesthetic and cutaneous feedback
from virtual objects. These controllers are grounded to the user's hand and can only
manipulate objects through arm and wrist motions, not using the dexterity of their
fingers as they would in real life. In this paper, we present TORC, a rigid haptic
controller that renders virtual object characteristics and behaviors such as texture
and compliance. Users hold and squeeze TORC using their thumb and two fingers and
interact with virtual objects by sliding their thumb on TORC's trackpad. During the
interaction, vibrotactile motors produce sensations to each finger that represent
the haptic feel of squeezing, shearing or turning an object. Our evaluation showed
that using TORC, participants could manipulate virtual objects more precisely (e.g.,
position and rotate objects in 3D) than when using a conventional VR controller.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300302,
author = {Vashistha, Aditya and Garg, Abhinav and Anderson, Richard and Raza, Agha Ali},
title = {Threats, Abuses, Flirting, and Blackmail: Gender Inequity in Social Media Voice Forums},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300302},
abstract = {HCI4D researchers and practitioners have leveraged voice forums to enable people with
literacy, socioeconomic, and connectivity barriers to access, report, and share information.
Although voice forums have received impassioned usage from low-income, low-literate,
rural, tribal, and disabled communities in diverse HCI4D contexts, the participation
of women in these services is almost non-existent. In this paper, we investigate the
reasons for the low participation of women in social media voice forums by examining
the use of Sangeet Swara in India and Baang in Pakistan by marginalized women and
men. Our mixed-methods approach spanning content analysis of audio posts, quantitative
analysis of interactions between users, and qualitative interviews with users indicate
gender inequity due to deep-rooted patriarchal values. We found that women on these
forums faced systemic discrimination and encountered abusive content, flirts, threats,
and harassment. We discuss design recommendations to create social media voice forums
that foster gender equity in use of these services.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300303,
author = {Yip, Jason C. and Sobel, Kiley and Gao, Xin and Hishikawa, Allison Marie and Lim, Alexis and Meng, Laura and Ofiana, Romaine Flor and Park, Justin and Hiniker, Alexis},
title = {Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300303},
abstract = {In HCI, adult concerns about technologies for children have been studied extensively.
However, less is known about what children themselves find concerning in everyday
technologies. We examine children's technology-related fears by probing their use
of the colloquial term "creepy." To understand children's perceptions of "creepy technologies,"
we conducted four participatory design sessions with children (ages 7 - 11) to design
and evaluate creepy technologies, followed by interviews with the same children. We
found that children's fear reactions emphasized physical harm and threats to their
relationships (particularly with attachment figures). The creepy signals from technology
the children described include: deception, lack of control, mimicry, ominous physical
appearance, and unpredictability. Children acknowledged trusted adults will mediate
the relationship between creepy technology signals and fear responses. Our work contributes
a close examination of what children mean when they say a technology is "creepy."
By treating these concerns as principal design considerations, developers can build
systems that are more transparent about the risks they produce and more sensitive
to the fears they may unintentionally raise.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300304,
author = {Lee, David T. and Hamedian, Emily S. and Wolff, Greg and Liu, Amy},
title = {Causeway: Scaling Situated Learning with Micro-Role Hierarchies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300304},
abstract = {While educational technologies such as MOOCs have helped scale content-based learning,
scaling situated learning is still challenging. The time it takes to define a real-world
project and to mentor learners is often prohibitive, especially given the limited
contributions that novices are able to make. This paper introduces micro-role hierarchies,
a form of coordination that integrates workflows and hierarchies to help short-term
novices predictably contribute to complex projects. Individuals contribute through
micro-roles, small experiential assignments taking roughly 2 hours. These micro-roles
support execution of the desired work process, but also sequence into learning pathways,
resulting in a learning dynamic similar to moving up an organizational hierarchy.
We demonstrate micro-role hierarchies through Causeway, a platform for learning web
development while building websites for nonprofits. We carry out a proof-of-concept
study in which learners built static websites for refugee resettlement agencies in
2 hour long roles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300305,
author = {Swearngin, Amanda and Li, Yang},
title = {Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300305},
abstract = {Tapping is an immensely important gesture in mobile touchscreen interfaces, yet people
still frequently are required to learn which elements are tappable through trial and
error. Predicting human behavior for this everyday gesture can help mobile app designers
understand an important aspect of the usability of their apps without having to run
a user study. In this paper, we present an approach for modeling tappability of mobile
interfaces at scale. We conducted large-scale data collection of interface tappability
over a rich set of mobile apps using crowdsourcing and computationally investigated
a variety of signifiers that people use to distinguish tappable versus not-tappable
elements. Based on the dataset, we developed and trained a deep neural network that
predicts how likely a user will perceive an interface element as tappable versus not
tappable. Using the trained tappability model, we developed TapShoe, a tool that automatically
diagnoses mismatches between the tappability of each element as perceived by a human
user---predicted by our model, and the intended or actual tappable state of the element
specified by the developer or designer. Our model achieved reasonable accuracy: mean
precision 90.2% and recall 87.0%, in matching human perception on identifying tappable
UI elements. The tappability model and TapShoe were well received by designers via
an informal evaluation with 7 professional interaction designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300306,
author = {Shakil, Asma and Lutteroth, Christof and Weber, Gerald},
title = {CodeGazer: Making Code Navigation Easy and Natural With Gaze Input},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300306},
abstract = {Navigating source code, an activity common in software development, is time consuming
and in need of improvement. We present CodeGazer, a prototype for source code navigation
using eye gaze for common navigation functions. These functions include actions such
as "Go to Definition'' and "Find All Usages'' of an identifier, navigate to files
and methods, move back and forth between visited points in code and scrolling. We
present user study results showing that many users liked and even preferred the gaze-based
navigation, in particular the "Go to Definition'' function. Gaze-based navigation
is also holding up well in completion time when compared to traditional methods. We
discuss how eye gaze can be integrated into traditional mouse &amp; keyboard applications
in order to make "look up'' tasks more natural.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300307,
author = {Chivukula, Shruthi Sai and Gray, Colin M. and Brier, Jason A.},
title = {Analyzing Value Discovery in Design Decisions Through Ethicography},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300307},
abstract = {HCI scholarship is increasingly concerned with the ethical impact of socio-technical
systems. Current theoretically driven approaches that engage with ethics generally
prescribe only abstract approaches by which designers might consider values in the
design process. However, there is little guidance on methods that promote value discovery,
which might lead to more specific examples of relevant values in specific design contexts.
In this paper, we elaborate a method for value discovery, identifying how values impact
the designer's decision making. We demonstrate the use of this method, called Ethicography,
in describing value discovery and use throughout the design process. We present analysis
of design activity by user experience (UX) design students in two lab protocol conditions,
describing specific human values that designers considered for each task, and visualizing
the interplay of these values. We identify opportunities for further research, using
the Ethicograph method to illustrate value discovery and translation into design solutions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300308,
author = {Sharif, Mahmood and Roundy, Kevin A. and Dell'Amico, Matteo and Gates, Christopher and Kats, Daniel and Bauer, Lujo and Christin, Nicolas},
title = {A Field Study of Computer-Security Perceptions Using Anti-Virus Customer-Support Chats},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300308},
abstract = {Understanding users' perceptions of suspected computer-security problems can help
us tailor technology to better protect users. To this end, we conducted a field study
of users' perceptions using 189,272 problem descriptions sent to the customer-support
desk of a large anti-virus vendor from 2015 to 2018. Using qualitative methods, we
analyzed 650 problem descriptions to study the security issues users faced and the
symptoms that led users to their own diagnoses. Subsequently, we investigated to what
extent and for what types of issues user diagnoses matched those of experts. We found,
for example, that users and experts were likely to agree for most issues, but not
for attacks (e.g., malware infections), for which they agreed only in 44% of the cases.
Our findings inform several user-security improvements, including how to automate
interactions with users to resolve issues and to better communicate issues to users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300309,
author = {Kim, Nam Wook and Im, Hyejin and Henry Riche, Nathalie and Wang, Alicia and Gajos, Krzysztof and Pfister, Hanspeter},
title = {DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300309},
abstract = {Many personal informatics systems allow people to collect and manage personal data
and reflect more deeply about themselves. However, these tools rarely offer ways to
customize how the data is visualized. In this work, we investigate the question of
how to enable people to determine the representation of their data. We analyzed the
Dear Data project to gain insights into the design elements of personal visualizations.
We developed DataSelfie, a novel system that allows individuals to gather personal
data and design custom visuals to represent the collected data. We conducted a user
study to evaluate the usability of the system as well as its potential for individual
and collaborative sensemaking of the data.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300310,
author = {Williamson, Julie R. and McGill, Mark and Outram, Khari},
title = {PlaneVR: Social Acceptability of Virtual Reality for Aeroplane Passengers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300310},
abstract = {Virtual reality (VR) headsets allow wearers to escape their physical surroundings,
immersing themselves in a virtual world. Although escape may not be realistic or acceptable
in many everyday situations, air travel is one context where early adoption of VR
could be very attractive. While travelling, passengers are seated in restricted spaces
for long durations, reliant on limited seat-back displays or mobile devices. This
paper explores the social acceptability and usability of VR for in-flight entertainment.
In an initial survey, we captured respondents' attitudes towards the social acceptability
of VR headsets during air travel. Based on the survey results, we developed a VR in-flight
entertainment prototype and evaluated this in a focus group study. Our results discuss
methods for improving the acceptability of VR in-flight, including using mixed reality
to help users transition between virtual and physical environments and supporting
interruption from other co-located people.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300311,
author = {Huber, Bernd and Shin, Hijung Valentina and Russell, Bryan and Wang, Oliver and Mysore, Gautham J.},
title = {B-Script: Transcript-Based B-Roll Video Editing with Recommendations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300311},
abstract = {In video production, inserting B-roll is a widely used technique to enrich the story
and make a video more engaging. However, determining the right content and positions
of B-roll and actually inserting it within the main footage can be challenging, and
novice producers often struggle to get both timing and content right. We present B-Script,
a system that supports B-roll video editing via interactive transcripts. B-Script
has a built-in recommendation system trained on expert-annotated data, recommending
users B-roll position and content. To evaluate the system, we conducted a within-subject
user study with 110 participants, and compared three interface variations: a timeline-based
editor, a transcript-based editor, and a transcript-based editor with recommendations.
Users found it easier and were faster to insert B-roll using the transcript-based
interface, and they created more engaging videos when recommendations were provided.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300312,
author = {Fernando, Piyum and Weiler, Jennifer and Kuznetsov, Stacey},
title = {A Rough Sketch of the Freehand Drawing Process: Blending the Line between Action and Artifact},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300312},
abstract = {Dynamic elements of the drawing process (e.g., order of compilation, speed, length,
and pressure of strokes) are considered important because they can reveal the technique,
process, and emotions of the artist. To explore how sensing, visualizing, and sharing
these aspects of the creative process might shape art making and art viewing experiences,
we designed a research probe which unobtrusively tracks and visualizes the movement
and pressure of the artist's pencil on an easel. Using our probe, we conducted studies
with artists and art viewers, which reveal digital and physical representations of
creative process as a means of reflecting on a multitude of factors about the finished
artwork, including technique, style, and the emotions of the artists. We conclude
by discussing future directions for HCI systems that sense and visualize aspects of
the creative process in digitally-mediated arts, as well as the social considerations
of sharing and curating intimate process information.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300313,
author = {Tian, Feng and Fan, Xiangmin and Fan, Junjun and Zhu, Yicheng and Gao, Jing and Wang, Dakuo and Bi, Xiaojun and Wang, Hongan},
title = {What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300313},
abstract = {Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability
that severely affects patients' quality of life. Although early interventions can
provide significant benefits, PD diagnosis is often delayed due to both the mildness
of early signs and the high requirements imposed by traditional screening and diagnosis
methods. In this paper, we explore the feasibility and accuracy of detecting motor
impairment in early PD via sensing and analyzing users' common touch gestural interactions
on smartphones. We investigate four types of common gestures, including flick, drag,
pinch, and handwriting gestures, and propose a set of features to capture PD motor
signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study,
our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating
early PD subjects from healthy controls. Our work constitutes an important step towards
unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300314,
author = {Spaa, Anne and Durrant, Abigail and Elsden, Chris and Vines, John},
title = {Understanding the Boundaries between Policymaking and HCI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300314},
abstract = {There is a growing body of literature in HCI examining the intersection between policymaking
and technology research. However, what it means to engage in policymaking in our field,
or the ways in which evidence from HCI studies is translated into policy, is not well
understood. We report on interviews with 11 participants working at the intersection
of technology research and policymaking. Analysis of this data highlights how evidence
is understood and made sense of in policymaking processes, what forms of evidence
are privileged over others, and the work that researchers engage in to meaningfully
communicate their work to policymaking audiences. We discuss how our findings pose
challenges for certain traditions of research in HCI, yet also open up new policy
opportunities for those engaging in more speculative research practices. We conclude
by discussing three ways forward that the HCI community can explore to increase engagement
with policymaking contexts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300315,
author = {Ogbonnaya-Ogburu, Ihudiya Finda and Toyama, Kentaro and Dillahunt, Tawanna R.},
title = {Towards an Effective Digital Literacy Intervention to Assist Returning Citizens with Job Search},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300315},
abstract = {Returning citizens (formerly incarcerated individuals) face great challenges finding
employment, and these are exacerbated by the need for digital literacy in modern job
search. Through 23 semi-structured interviews and a pilot digital literacy course
with returning citizens in the Greater Detroit area, we explore tactics and needs
with respect to job search and digital technology. Returning citizens exhibit great
diversity, but overall, we find our participants to have striking gaps in digital
literacy upon release, even as they are quickly introduced to smartphones by friends
and family. They tend to have employable skills and ability to use offline social
networks to find opportunities, but have little understanding of formal job search
processes, online or offline. They mostly mirror mainstream use of mobile technology,
but they have various reasons to avoid social media. These and other findings lead
to recommendations for digital literacy programs for returning citizens.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300316,
author = {Kim, Soomin and Lee, Joonhwan and Gweon, Gahgene},
title = {Comparing Data from Chatbot and Web Surveys: Effects of Platform and Conversational Style on Survey Response Quality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300316},
abstract = {This study aims to explore the feasibility of a text-based virtual agent as a new
survey method to overcome the web survey's common response quality problems, which
are caused by respondents' inattention. To this end, we conducted a 2 (platform: web
vs. chatbot) \texttimes{} 2 (conversational style: formal vs. casual) experiment. We used satisficing
theory to compare the responses' data quality. We found that the participants in the
chatbot survey, as compared to those in the web survey, were more likely to produce
differentiated responses and were less likely to satisfice; the chatbot survey thus
resulted in higher-quality data. Moreover, when a casual conversational style is used,
the participants were less likely to satisfice-although such effects were only found
in the chatbot condition. These results imply that conversational interactivity occurs
when a chat interface is accompanied by messages with effective tone. Based on an
analysis of the qualitative responses, we also showed that a chatbot could perform
part of a human interviewer's role by applying effective communication strategies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300317,
author = {Matsubayashi, Atsushi and Makino, Yasutoshi and Shinoda, Hiroyuki},
title = {Direct Finger Manipulation of 3D Object Image with Ultrasound Haptic Feedback},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300317},
abstract = {In this study, we prototype and examine a system that allows a user to manipulate
a 3D virtual object with multiple fingers without wearing any device. An autostereoscopic
display produces a 3D image and a depth sensor measures the movement of the fingers.
When a user touches a virtual object, haptic feedback is provided by ultrasound phased
arrays. By estimating the cross section of the finger in contact with the virtual
object and by creating a force pattern around it, it is possible for the user to recognize
the position of the surface relative to the finger. To evaluate our system, we conducted
two experiments to show that the proposed feedback method is effective in recognizing
the object surface and thereby enables the user to grasp the object quickly without
seeing it.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300318,
author = {Martin-Niedecken, Anna Lisa and Rogers, Katja and Turmo Vidal, Laia and Mekler, Elisa D. and M\'{a}rquez Segura, Elena},
title = {ExerCube vs. Personal Trainer: Evaluating a Holistic, Immersive, and Adaptive Fitness Game Setup},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300318},
abstract = {Today's spectrum of playful fitness solutions features systems that are clearly game-first
or fitness-first in design; hardly any sufficiently incorporate both areas. Consequently,
existing applications and evaluations often lack in focus on attractiveness and effectiveness,
which should be addressed on the levels of body, controller, and game scenario following
a holistic design approach. To contribute to this topic and as a proof-of-concept,
we designed the ExerCube, an adaptive fitness game setup. We evaluated participants'
multi-sensory and bodily experiences with a non-adaptive and an adaptive ExerCube
version and compared them with personal training to reveal insights to inform the
next iteration of the ExerCube. Regarding flow, enjoyment and motivation, the ExerCube
is on par with personal training. Results further reveal differences in perception
of exertion, types and quality of movement, social factors, feedback, and audio experiences.
Finally, we derive considerations for future research and development directions in
holistic fitness game setups.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300319,
author = {Sleeper, Manya and Matthews, Tara and O'Leary, Kathleen and Turner, Anna and Woelfer, Jill Palzkill and Shelton, Martin and Oplinger, Andrew and Schou, Andreas and Consolvo, Sunny},
title = {Tough Times at Transitional Homeless Shelters: Considering the Impact of Financial Insecurity on Digital Security and Privacy},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300319},
abstract = {Addressing digital security and privacy issues can be particularly difficult for users
who face challenging circumstances. We performed semi-structured interviews with residents
and staff at 4 transitional homeless shelters in the U.S. San Francisco Bay Area (n=15
residents, 3 staff) to explore their digital security and privacy challenges. Based
on these interviews, we outline four tough times themes --- challenges experienced
by our financially insecure participants that impacted their digital security and
privacy --- which included: (1) limited financial resources, (2) limited access to
reliable devices and Internet, (3) untrusted relationships, and (4) ongoing stress.
We provide examples of how each theme impacts digital security and privacy practices
and needs. We then use these themes to provide a framework outlining opportunities
for technology creators to better support users facing security and privacy challenges
related to financial insecurity.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300320,
author = {Candello, Heloisa and Pinhanez, Claudio and Pichiliani, Mauro and Cavalin, Paulo and Figueiredo, Flavio and Vasconcelos, Marisa and Do Carmo, Haylla},
title = {The Effect of Audiences on the User Experience with Conversational Interfaces in Physical Spaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300320},
abstract = {How does the presence of an audience influence the social interaction with a conversational
system in a physical space? To answer this question, we analyzed data from an art
exhibit where visitors interacted in natural language with three chatbots representing
characters from a book. We performed two studies to explore the influence of audiences.
In Study 1, we did fieldwork cross-analyzing the reported perception of the social
interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances
and/or strangers), and control variables such as the visitor's familiarity with the
book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings,
identifying dialogue patterns and how they correlated with the audience conditions.
Some significant effects were found, suggesting that conversational systems in physical
spaces should be designed based on whether other people observe the user or not.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300321,
author = {An, Pengcheng and Bakker, Saskia and Ordanovski, Sara and Taconis, Ruurd and Paffen, Chris L.E. and Eggen, Berry},
title = {Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300321},
abstract = {Reflecting on their performance during classroom-teaching is an important competence
for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on
the spot. But RiA is also challenging, demanding extra thinking in teachers' already
intensive routines. Little is known on how HCI systems can facilitate teachers' RiA
during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system
that uses spatially distributed lamps to depict teachers' ongoing performance on how
they have divided their time and attention over students in the classroom. Empirical
qualitative data from eleven teachers in 22 class periods show that this ambient information
facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical
grounding and field evaluation, we contribute empirical knowledge about how an HCI
system enhanced teachers' process of RiA as well as a set of design principles for
unobtrusively supporting RiA.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300322,
author = {Kery, Mary Beth and John, Bonnie E. and O'Flaherty, Patrick and Horvath, Amber and Myers, Brad A.},
title = {Towards Effective Foraging by Data Scientists to Find Past Analysis Choices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300322},
abstract = {Data scientists are responsible for the analysis decisions they make, but it is hard
for them to track the process by which they achieved a result. Even when data scientists
keep logs, it is onerous to make sense of the resulting large number of history records
full of overlapping variants of code, output, plots, etc. We developed algorithmic
and visualization techniques for notebook code environments to help data scientists
forage for information in their history. To test these interventions, we conducted
a think-aloud evaluation with 15 data scientists, where participants were asked to
find specific information from the history of another person's data science project.
The participants succeed on a median of 80% of the tasks they performed. The quantitative
results suggest promising aspects of our design, while qualitative results motivated
a number of design improvements. The resulting system, called Verdant, is released
as an open-source extension for JupyterLab.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300323,
author = {Vaziripour, Elham and Howard, Devon and Tyler, Jake and O'Neill, Mark and Wu, Justin and Seamons, Kent and Zappala, Daniel},
title = {I Don't Even Have to Bother Them! Using Social Media to Automate the Authentication Ceremony in Secure Messaging},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300323},
abstract = {The privacy guaranteed by secure messaging applications relies on users completing
an authentication ceremony to verify they are using the proper encryption keys. We
examine the feasibility of social authentication, which partially automates the ceremony
using social media accounts. We implemented social authentication in Signal and conducted
a within-subject user study with 42 participants to compare this with existing methods.
To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents.
Our results show that users found social authentication to be convenient and fast.
They particularly liked verifying keys asynchronously, and viewing social media profiles
naturally coincided with how participants thought of verification. However, some participants
reacted negatively to integrating social media with Signal, primarily because they
distrust social media services. Overall, automating the authentication ceremony and
distributing trust with additional service providers is promising, but this infrastructure
needs to be more trusted than social media companies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300324,
author = {Jain, Dhruv and Lin, Angela and Guttman, Rose and Amalachandran, Marcus and Zeng, Aileen and Findlater, Leah and Froehlich, Jon},
title = {Exploring Sound Awareness in the Home for People Who Are Deaf or Hard of Hearing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300324},
abstract = {The home is filled with a rich diversity of sounds from mundane beeps and whirs to
dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing
(DHH) people think about and relate to sounds in the home, solicit feedback and reactions
to initial domestic sound awareness systems, and explore potential concerns. We present
findings from two qualitative studies: in Study 1, 12 DHH participants discussed their
perceptions of and experiences with sound in the home and provided feedback on initial
sound awareness mockups. Informed by Study 1, we designed three tablet-based sound
awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz
approach. Together, our findings suggest a general interest in smarthome-based sound
awareness systems particularly for displaying contextually aware, personalized and
glanceable visualizations but key concerns arose related to privacy, activity tracking,
cognitive overload, and trust.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300325,
author = {Liang, Claire and Proft, Julia and Andersen, Erik and Knepper, Ross A.},
title = {Implicit Communication of Actionable Information in Human-AI Teams},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300325},
abstract = {Humans expect their collaborators to look beyond the explicit interpretation of their
words. Implicature is a common form of implicit communication that arises in natural
language discourse when an utterance leverages context to imply information beyond
what the words literally convey. Whereas computational methods have been proposed
for interpreting and using different forms of implicature, its role in human and artificial
agent collaboration has not yet been explored in a concrete domain. The results of
this paper provide insights to how artificial agents should be structured to facilitate
natural and efficient communication of actionable information with humans. We investigated
implicature by implementing two strategies for playing Hanabi, a cooperative card
game that relies heavily on communication of actionable implicit information to achieve
a shared goal. In a user study with 904 completed games and 246 completed surveys,
human players randomly paired with an implicature AI are 71% more likely to think
their partner is human than players paired with a non-implicature AI. These teams
demonstrated game performance similar to other state of the art approaches.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300326,
author = {Pearson, Jennifer and Robinson, Simon and Reitmaier, Thomas and Jones, Matt and Ahire, Shashank and Joshi, Anirudha and Sahoo, Deepak and Maravi, Nimish and Bhikne, Bhakti},
title = {StreetWise: Smart Speakers vs Human Help in Public Slum Settings},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300326},
abstract = {This paper explores the use of conversational speech question and answer systems in
the challenging context of public spaces in slums. A major part of this work is a
comparison of the source and speed of the given responses; that is, either machine-powered
and instant or human-powered and delayed. We examine these dimensions via a two-stage,
multi-sited deployment. We report on a pilot deployment that helped refine the system,
and a second deployment involving the installation of nine of each type of system
within a large Mumbai slum for a 40-day period, resulting in over 12,000 queries.
We present the findings from a detailed analysis and comparison of the two question-answer
corpora; discuss how these insights might help improve machine-powered smart speakers;
and, highlight the potential benefits of multi-sited public speech installations within
slum environments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300327,
author = {Howard, Dorothy and Irani, Lilly},
title = {Ways of Knowing When Research Subjects Care},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300327},
abstract = {This paper investigates a hidden dimension of research with real world stakes: research
subjects who care -- sometimes deeply -- about the topic of the research in which
they participate. They manifest this care, we show, by managing how they are represented
in the research process, by exercising politics in shaping knowledge production, and
sometimes in experiencing trauma in the process. We draw first-hand reflections on
participation in diversity research on Wikipedia, transforming participants from objects
of study to active negotiators of research process. We depict how care, vulnerability,
harm, and emotions shape ethnographic and qualitative data. We argue that, especially
in reflexive cultures, research subjects are active agents with agendas, accountabilities,
and political projects of their own. We propose ethics of care and collaboration to
open up new possibilities for knowledge production and socio-technical intervention
in HCI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300328,
author = {Peng, Zhenhui and Kwon, Yunhwan and Lu, Jiaan and Wu, Ziming and Ma, Xiaojuan},
title = {Design and Evaluation of Service Robot's Proactivity in Decision-Making Support Process},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300328},
abstract = {As service robots are envisioned to provide decision-making support (DMS) in public
places, it is becoming essential to design the robot's manner of offering assistance.
For example, robot shop assistants that proactively or reactively give product recommendations
may impact customers' shopping experience. In this paper, we propose an anticipation-autonomy
policy framework that models three levels of proactivity (high, medium and low) of
service robots in DMS contexts. We conduct a within-subject experiment with 36 participants
to evaluate the effects of DMS robot's proactivity on user perceptions and interaction
behaviors. Results show that a highly proactive robot is deemed inappropriate though
people can get rich information from it. A robot with medium proactivity helps reduce
the decision space while maintaining users' sense of engagement. The least proactive
robot grants users more control but may not realize its full capability. We conclude
the paper with design considerations for service robot's manner.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300329,
author = {Ismail, Azra and Kumar, Neha},
title = {Empowerment on the Margins: The Online Experiences of Community Health Workers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300329},
abstract = {Research in Human-Computer Interaction for Development (HCI4D) routinely relies on
and engages with the increasing penetration of smartphones and the internet. We examine
the mobile, internet, and social media practices of women community health workers,
for whom internet access has newly become possible. These workers are uniquely positioned
at the intersections of various communities of practice---their familial units, workplaces,
networks of health workers, larger communities, and the online world. However, they
remain at the margins of each, on account of difference in gender, class, literacies,
professional expertise, and more. Our findings unpack the legitimate peripheral participation
of these workers; examining how they appropriate smartphones and the internet to move
away from the peripheries to fully participate in these communities. We discuss how
their activities are motivated by moves towards empowerment, digitization, and improved
healthcare provision. We consider how future work might support, leverage, and extend
their efforts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300330,
author = {Koesten, Laura and Kacprzak, Emilia and Tennison, Jeni and Simperl, Elena},
title = {Collaborative Practices with Structured Data: Do Tools Support What Users Need?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300330},
abstract = {Collaborative work with data is increasingly common and spans a broad range of activities
- from creating or analysing data in a team, to sharing it with others, to reusing
someone else's data in a new context. In this paper, we explore collaboration practices
around structured data and how they are supported by current technology. We present
the results of an interview study with twenty data practitioners, from which we derive
four high-level user needs for tool support. We compare them against the capabilities
of twenty systems that are commonly associated with data activities, including data
publishing software, wikis, web-based collaboration tools, and online community platforms.
Our findings suggest that data-centric collaborative work would benefit from: structured
documentation of data and its lifecycle; advanced affordances for conversations among
collaborators; better change control; and custom data access. The findings help us
formalise practices around data teamwork, and build a better understanding how people's
motivations and barriers when working with structured data.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300331,
author = {Baloup, Marc and Pietrzak, Thomas and Casiez, G\'{e}ry},
title = {RayCursor: A 3D Pointing Facilitation Technique Based on Raycasting},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300331},
abstract = {Raycasting is the most common target pointing technique in virtual reality environments.
However, performance on small and distant targets is impacted by the accuracy of the
pointing device and the user's motor skills. Current pointing facilitation techniques
are currently only applied in the context of the virtual hand, i.e. for targets within
reach. We propose enhancements to Raycasting: filtering the ray, and adding a controllable
cursor on the ray to select the nearest target. We describe a series of studies for
the design of the visual feedforward, filtering technique, as well as a comparative
study between different 3D pointing techniques. Our results show that highlighting
the nearest target is one of the most efficient visual feedforward technique. We also
show that filtering the ray reduces error rate in a drastic way. Finally we show the
benefits of RayCursor compared to Raycasting and another technique from the literature.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300332,
author = {Simon, Florine and Roudaut, Anne and Irani, Pourang and Serrano, Marcos},
title = {Finding Information on Non-Rectangular Interfaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300332},
abstract = {With upcoming breakthroughs in free-form display technologies, new user interface
design challenges have emerged. Here, we investigate a question, which has been widely
explored on traditional GUIs but unexplored on non-rectangular interfaces: what are
the user strategies in terms of visual search when information is not presented in
a traditional rectangular layout? To achieve this, we present two complementary studies
investigating eye movements in different visual search tasks. Our results unveil which
areas are seen first according to different visual structures. By doing so we address
the question of where to place relevant content for the UI designers of non-rectangular
displays.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8}
}

@inbook{10.1145/3290605.3300333,
author = {Kljun, Matja\v{z} and Pucihar, Klen \v{C}opi\v{c} and Alexander, Jason and Weerasinghe, Maheshya and Campos, Cuauhtli and Ducasse, Julie and Kopacin, Barbara and Grubert, Jens and Coulton, Paul and \v{C}elar, Miha},
title = {Augmentation Not Duplication: Considerations for the Design of Digitally-Augmented Comic Books},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300333},
abstract = {Digital-augmentation of print-media can provide contextually relevant audio, visual,
or haptic content to supplement the static text and images. The design of such augmentation--its
medium, quantity, frequency, content, and access technique--can have a significant
impact on the reading experience. In the worst case, such as where children are learning
to read, the print medium can become a proxy for accessing digital content only, and
the textual content is avoided. In this work, we examine how augmented content can
change the reader's behaviour with a comic book. We first report on the usage of a
commercially available augmented comic for children, providing evidence that a third
of all readers converted to simply viewing the digital media when printed content
is duplicated. Second, we explore the design space for digital content augmentation
in print media. Third, we report a user study with 136 children that examined the
impact of both content length and presentation in a digitally-augmented comic book.
From this, we report a series of design guidelines to assist designers and editors
in the development of digitally-augmented print media.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300334,
author = {Huang, Forrest and Canny, John F. and Nichols, Jeffrey},
title = {Swire: Sketch-Based User Interface Retrieval},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300334},
abstract = {Sketches and real-world user interface examples are frequently used in multiple stages
of the user interface design process. Unfortunately, finding relevant user interface
examples, especially in large-scale datasets, is a highly challenging task because
user interfaces have aesthetic and functional properties that are only indirectly
reflected by their corresponding pixel data and meta-data. This paper introduces Swire,
a sketch-based neural-network-driven technique for retrieving user interfaces. We
collect the first large-scale user interface sketch dataset from the development of
Swire that researchers can use to develop new sketch-based data-driven design interfaces
and applications. Swire achieves high performance for querying user interfaces: for
a known validation task it retrieves the most relevant example as within the top-10
results for over 60% of queries. With this technique, for the first time designers
can accurately retrieve relevant user interface examples with free-form sketches natural
to their design workflows. We demonstrate several novel applications driven by Swire
that could greatly augment the user interface design process.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300335,
author = {Kim, Nam Wook and Henry Riche, Nathalie and Bach, Benjamin and Xu, Guanpeng and Brehmer, Matthew and Hinckley, Ken and Pahud, Michel and Xia, Haijun and McGuffin, Michael J. and Pfister, Hanspeter},
title = {DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300335},
abstract = {Comics are an entertaining and familiar medium for presenting compelling stories about
data. However, existing visualization authoring tools do not leverage this expressive
medium. In this paper, we seek to incorporate elements of comics into the construction
of data-driven stories about dynamic networks. We contribute DataToon, a flexible
data comic storyboarding tool that blends analysis and presentation with pen and touch
interactions. A storyteller can use DataToon rapidly generate visualization panels,
annotate them, and position them within a canvas to produce a visually compelling
narrative. In a user study, participants quickly learned to use DataToon for producing
data comics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300336,
author = {Zhao, Jun and Wang, Ge and Dally, Carys and Slovak, Petr and Edbrooke-Childs, Julian and Van Kleek, Max and Shadbolt, Nigel},
title = {`I Make up a Silly Name': Understanding Children's Perception of Privacy Risks Online},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300336},
abstract = {Children under 11 are often regarded as too young to comprehend the implications of
online privacy. Perhaps as a result, little research has focused on younger kids'
risk recognition and coping. Such knowledge is, however, critical for designing efficient
safeguarding mechanisms for this age group. Through 12 focus group studies with 29
children aged 6-10 from UK schools, we examined how children described privacy risks
related to their use of tablet computers and what information was used by them to
identify threats. We found that children could identify and articulate certain privacy
risks well, such as information oversharing or revealing real identities online; however,
they had less awareness with respect to other risks, such as online tracking or game
promotions. Our findings offer promising directions for supporting children's awareness
of cyber risks and the ability to protect themselves online.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3290605.3300337,
author = {Mishra, Sonali R. and Klasnja, Predrag and MacDuffie Woodburn, John and Hekler, Eric B. and Omberg, Larsson and Kellen, Michael and Mangravite, Lara},
title = {Supporting Coping with Parkinson's Disease Through Self Tracking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300337},
doi = {10.1145/3290605.3300337},
abstract = {Self-tracking can help people understand their medical condition and the factors that
influence their symptoms. However, it is unclear how tracking technologies should
be tailored to help people cope with the progression of a degenerative disease. To
understand how smartphone apps and other tracking technologies can support people
in coping with an incurable illness, we interviewed both people with Parkinson's Disease
(n=17) and care partners (n=6) who help people with Parkinson's manage their lives.
We describe how symptom trackers can help people identify and solve problems to improve
their quality of life, the role symptom trackers can play in helping people combat
their own tendencies towards avoidance and denial, and the complex role of care partners
in defining and tracking ambiguous symptoms. Our findings yield insights that can
guide the design of tracking technologies to help people with Parkinson's Disease
accept and plan for their condition.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {coping with chronic disease, personal informatics, quality of life, health informatics, parkinson's disease, symptom tracking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inbook{10.1145/3290605.3300338,
author = {Wen, Zikai Alex and Lin, Zhiqiu and Chen, Rowena and Andersen, Erik},
title = {What.Hack: Engaging Anti-Phishing Training Through a Role-Playing Phishing Simulation Game},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300338},
abstract = {Phishing attacks are a major problem, as evidenced by the DNC hackings during the
2016 US presidential election, in which staff were tricked into sharing passwords
by fake Google security emails, granting access to confidential information. Vulnerabilities
such as these are due in part to insufficient and tiresome user training in cybersecurity.
Ideally, we would have more engaging training methods that teach cybersecurity in
an active and entertaining way. To address this need, we introduce the game What.Hack,
which not only teaches phishing concepts but also simulates actual phishing attacks
in a role-playing game to encourage the player to practice defending themselves. Our
user study shows that our game design is more engaging and effective in improving
performance than a standard form of training and a competing training game design
(which does not simulate phishing attempts through role-playing).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300339,
author = {Mu\~{n}oz, Diego and Ploderer, Bernd and Brereton, Margot},
title = {Position Exchange Workshops: A Method to Design for Each Other in Families},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300339},
abstract = {Existing methods for researching and designing to support relationships between parents
and their adult children tend to lead to designs that respect the differences between
them. We conducted 14 Position Exchange Workshops with parents and their adult children,
where the child has left home in recent years, aiming to explicate and confront their
positions in creative and supportive ways. We designed three co-design methods (Card
Sort for Me &amp; You, Would I Lie to You? and A Magic Machine for You) to support participants
to explore, understand, empathize, and design for each other. The findings show that
the methods facilitated understanding, renegotiating, and reimagining their current
positions. We discuss how positions can help consider both perspectives in the design
process. This paper seeks to contribute (1) how the notion of positions enables generating
understandings of the relationship, and (2) a set of methods influenced by position
exchange, empathy, and playful engagement that help explore human relationships.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300340,
author = {Pfeuffer, Ken and Geiger, Matthias J. and Prange, Sarah and Mecke, Lukas and Buschek, Daniel and Alt, Florian},
title = {Behavioural Biometrics in VR: Identifying People from Body Motion and Relations in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300340},
abstract = {Every person is unique, with individual behavioural characteristics: how one moves,
coordinates, and uses their body. In this paper we investigate body motion as behavioural
biometrics for virtual reality. In particular, we look into which behaviour is suitable
to identify a user. This is valuable in situations where multiple people use a virtual
reality environment in parallel, for example in the context of authentication or to
adapt the VR environment to users' preferences. We present a user study (N=22) where
people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring
their head, hand, and eye motion data over two sessions. These body segments can be
arbitrarily combined into body relations, and we found that these movements and their
combination lead to characteristic behavioural patterns. We present an extensive analysis
of which motion/relation is useful to identify users in which tasks using classification
methods. Our findings are beneficial for researchers and practitioners alike who aim
to build novel adaptive and secure user interfaces in virtual reality.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300341,
author = {Zhao, Yuhang and Cutrell, Edward and Holz, Christian and Morris, Meredith Ringel and Ofek, Eyal and Wilson, Andrew D.},
title = {SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300341},
abstract = {Current virtual reality applications do not support people who have low vision, i.e.,
vision loss that falls short of complete blindness but is not correctable by glasses.
We present SeeingVR, a set of 14 tools that enhance a VR application for people with
low vision by providing visual and audio augmentations. A user can select, adjust,
and combine different tools based on their preferences. Nine of our tools modify an
existing VR application post hoc via a plugin without developer effort. The rest require
simple inputs from developers using a Unity toolkit we created that allows integrating
all 14 of our low vision support tools during development. Our evaluation with 11
participants with low vision showed that SeeingVR enabled users to better enjoy VR
and complete tasks more quickly and accurately. Developers also found our Unity toolkit
easy and convenient to use.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300342,
author = {Andersen, Kristina and Wakkary, Ron},
title = {The Magic Machine Workshops: Making Personal Design Knowledge},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300342},
abstract = {New technologies emerge into an increasingly complex everyday life. How can we engage
users further into material practices that explore ideas and notions of these new
things? This paper proposes a set of qualities for short, intense, workshop-like experiences,
created to generate strong individual commitments, and expose underlying personal
desires as drivers for ideas. By making use of open-ended making to engage participants
in the imagination of new things, we aim to allow a broad range of knowledge to materialise,
focused on the making of work that is about technology, rather than of technology.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300343,
author = {Mauriello, Matthew Louis and McNally, Brenna and Froehlich, Jon E.},
title = {Thermporal: An Easy-To-Deploy Temporal Thermographic Sensor System to Support Residential Energy Audits},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300343},
abstract = {Underperforming, degraded, and missing insulation in US residential buildings is common.
Detecting these issues, however, can be difficult. Using thermal cameras during energy
audits can aid in locating potential insulation issues, but prior work indicates it
is challenging to determine their severity using thermal imagery alone. In this work,
we present an easy-to-deploy, temporal thermographic sensor system designed to support
residential energy audits through quantitative analysis of building envelope performance.
We then offer an evaluation of the system through two studies: (i) a one-week, in-home
field study in five homes and (ii) a semi-structured interview study with five professional
energy auditors. Our results show our system helps raise awareness, improves homeowners'
ability to gauge the severity of issues, and provides opportunities for new interactions
between homeowners, building data, and professional auditors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300344,
author = {Rogers, Jon and Clarke, Loraine and Skelly, Martin and Taylor, Nick and Thomas, Pete and Thorne, Michelle and Larsen, Solana and Odrozek, Katarzyna and Kloiber, Julia and Bihr, Peter and Jain, Anab and Arden, Jon and von Grafenstein, Max},
title = {Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300344},
abstract = {Emerging technologies---such as the voice enabled internet---present many opportunities
and challenges for HCI research and society as a whole. Advocating for better, healthier
implementations of these technologies will require us to communicate abstract values,
such as trust, to an audience that ranges from the general public to technologists
and even policymakers. In this paper, we show how a combination of film-making and
product design can help to illustrate these abstract values. Working as part of a
wider international advocacy campaign, Our Friends Electric focuses on the voice enabled
internet, translating abstract notions of Internet Health into comprehensible digital
futures for the relationship between our voice and the internet. We conclude with
a call for designers of physical things to be more involved with the development of
trust, privacy and security in this powerful emerging technological landscape.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300345,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Lazar, Amanda and Su, Norman Makoto},
title = {(Re-)Framing Menopause Experiences for HCI and Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300345},
abstract = {Informed by considerations from medicine and wellness research, experience design,
investigations of new and emerging technologies, and sociopolitical critique, HCI
researchers have demonstrated that women's health is a complex and rich topic. Turning
these research outputs into productive interventions, however, is difficult. We argue
that design is well positioned to address such a challenge thanks to its methodological
traditions of problem setting and framing situated in synthetic (rather than analytic)
knowledge production. In this paper, we focus on designing for experiences of menopause.
Building on our prior empirical work on menopause and our commitment to pursue design
informed by women's lived experience, we iteratively generated dozens of design frames
and accompanying design crits. We document the unfolding of our design reasoning,
showing how good-seeming insights nonetheless often lead to bad designs, while working
progressively towards stronger insights and design constructs. The latter we offer
as a contribution to researchers and practitioners who work at the intersections of
women's health and design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300346,
author = {Andrade, Ronny and Rogerson, Melissa J. and Waycott, Jenny and Baker, Steven and Vetere, Frank},
title = {Playing Blind: Revealing the World of Gamers with Visual Impairment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300346},
abstract = {Previous research on games for people with visual impairment (PVI) has focused on
co-designing or evaluating specific games - mostly under controlled conditions. In
this research, we follow a game-agnostic, "in-the-wild" approach, investigating the
habits, opinions and concerns of PVI regarding digital games. To explore these issues,
we conducted an online survey and follow-up interviews with gamers with VI (GVI).
Dominant themes from our analysis include the particular appeal of digital games to
GVI, the importance of social trajectories and histories of gameplay, the need to
balance complexity and accessibility in both games targeted to PVI and mainstream
games, opinions about the state of the gaming industry, and accessibility concerns
around new and emerging technologies such as VR and AR. Our study gives voice to an
underrepresented group in the gaming community. Understanding the practices, experiences
and motivations of GVI provides a valuable foundation for informing development of
more inclusive games.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300347,
author = {Hirskyj-Douglas, Ilyena and Lucero, Andr\'{e}s},
title = {On the Internet, Nobody Knows You're a Dog... Unless You're Another Dog},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300347},
abstract = {How humans use computers has evolved from human-machine interfaces to human-human
computer mediated communication. Whilst the field of animal-computer interaction has
roots in HCI, technology developed in this area currently only supports animal-computer
communication. This design fiction paper presents animal-animal connected interfaces,
using dogs as an instance. Through a co-design workshop, we created six proposals.
The designs focused on what a dog internet could look like and how interactions might
be presented. Analysis of the narratives and conceived designs indicated that participants'
concerns focused around asymmetries within the interaction. This resulted in the use
of objects seen as familiar to dogs. This was conjoined with interest in how to initiate
and end interactions, which was often achieved through notification systems. This
paper builds upon HCI methods for unconventional users, and applies a design fiction
approach to uncover key questions towards the creation of animal-to-animal interfaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300348,
author = {Meissner, Janis Lena and Jarusriboonchai, Pradthana and McLaughlin, Janice and Wright, Peter},
title = {More than the Sum of Makers: The Complex Dynamics of Diverse Practices at Maker Faire},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300348},
abstract = {Human Computer Interaction has developed great interest in the Maker Movement. Previous
work has explored it from various perspectives, focusing either on its potentials
or issues. As these are however only fragmented portrayals, this paper aims to take
a broader perspective and interconnect some of the fragments. We conducted a qualitative
study in the context of two Maker Faires to gain a better understanding of the complex
dynamics that makers operate in. We captured the voices of different stakeholders
and explored how their respective agendas relate to each other. The findings illustrate
how the event is co-created at the nexus of different technological, social and economic
interests while leaving space for diverse practices. The paper contributes a first
focused analysis of Maker Faire, probes it as a site for research and discusses how
holistic perspectives on the Maker Movement could create new research opportunities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300349,
author = {Raj, Shriti and Toporski, Kelsey and Garrity, Ashley and Lee, Joyce M. and Newman, Mark W.},
title = {"My Blood Sugar is Higher on the Weekends": Finding a Role for Context and Context-Awareness in the Design of Health Self-Management Technology},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300349},
abstract = {Tools for self-care of chronic conditions often do not fit the contexts in which self-care
happens because the influence of context on self-care practices is unclear. We conducted
a diary study with 15 adolescents with Type 1 Diabetes and their caregivers to understand
how context affects self-care. We observed different contextual settings, which we
call contextual frames, in which diabetes self-management varied depending on certain
factors - physical activity, food, emotional state, insulin, people, and attitudes.
The relative prevalence of these factors across contextual frames impacts self-care
necessitating different types of support. We show that contextual frames, as phenomenological
abstractions of context, can help designers of context-aware systems systematically
explore and model the relation of context with behavior and with technology supporting
behavior. Lastly, considering contextual frames as sensitizing concepts, we provide
design direction for using context in technology design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300350,
author = {Yamanaka, Shota and Stuerzlinger, Wolfgang},
title = {Modeling Fully and Partially Constrained Lasso Movements in a Grid of Icons},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300350},
abstract = {Lassoing objects is a basic function in illustration software and presentation tools.
Yet, for many common object arrangements lassoing is sometimes time-consuming to perform
and requires precise pen operation. In this work, we studied lassoing movements in
a grid of objects similar to icons. We propose a quantitative model to predict the
time to lasso such objects depending on the margins between icons, their sizes, and
layout, which all affect the number of stopping and crossing movements. Results of
two experiments showed that our models predict fully and partially constrained movements
with high accuracy. We also analyzed the speed profiles and pen stroke trajectories
and identified deeper insights into user behaviors, such as that an unconstrained
area can induce higher movement speeds even in preceding path segments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300351,
author = {Frier, William and Pittera, Dario and Ablart, Damien and Obrist, Marianna and Subramanian, Sriram},
title = {Sampling Strategy for Ultrasonic Mid-Air Haptics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300351},
abstract = {Mid-air tactile stimulation using ultrasonics has been used in a variety of human
computer interfaces in the form of prototypes as well as products. When generating
these tactile patterns with mid-air tactile ultrasonic displays, the common approach
has been to sample the patterns using the hardware update rate capabilities to their
full extent. In the current study we show that the hardware update rate can impact
perception, but unexpectedly we find that higher update rates do not improve pattern
perception. In a first user study, we highlight the effect of update rate on the perceived
strength of a pattern, especially for patterns rendered at slow rate of less than
10 Hz. In a second user study, we identify the evolution of the optimal update rate
according to variations in pattern size. Our main results show that update rate should
be designated as additional parameter for tactile patterns. We also discuss how the
relationships we defined in the current study can be implemented into designer tools
so that designers remain oblivious to this additional complexity.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300352,
author = {Bellini, Rosanna and Strohmayer, Angelika and Olivier, Patrick and Crivellaro, Clara},
title = {Mapping the Margins: Navigating the Ecologies of Domestic Violence Service Provision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300352},
abstract = {Work addressing the negative impacts of domestic violence on victim-survivors and
service providers has slowly been contributing to the HCI discourse. However, work
discussing the necessary, pre-emptive steps for researchers to enter these spaces
sensitively and considerately, largely remains opaque. Heavily-politicised specialisms
that are imbued with conflicting values and practices, such as domestic violence service
delivery can be especially difficult to navigate. In this paper, we report on a mixed
methods study consisting of interviews, a design dialogue and an ideation workshop
with domestic violence service providers to explore the potential of an online service
directory to support their work. Through this three-stage research process, we were
able to characterise this unique service delivery landscape and identify tensions
in services' access, understandings of technologies and working practices. Drawing
from our findings, we discuss opportunities for researchers to work with and sustain
complex information ecologies in sensitive settings.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300353,
author = {Alahmadi, Alaa and Davies, Alan and Royle, Jennifer and Vigo, Markel and Jay, Caroline},
title = {Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-Induced ECG Changes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300353},
abstract = {The electrocardiogram (ECG), a graphical representation of the heart's electrical
activity, is used for detecting cardiac pathologies. Certain medications can produce
a complication known as 'long QT syndrome', shown on the ECG as an increased gap between
two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome
can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate
whether using pseudo-colour to highlight wave length and changing the coordinate system
can support lay people in identifying increases in the QT interval. The results show
that introducing colour significantly improves accuracy, and that whilst it is easier
to detect a difference without colour with Cartesian coordinates, the greatest accuracy
is achieved when Polar coordinates are combined with colour. The results show that
applying simple visualisation techniques has the potential to improve ECG interpretation
accuracy, and support people in monitoring their own ECG.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300354,
author = {Chancellor, Stevie and Nitzburg, George and Hu, Andrea and Zampieri, Francisco and De Choudhury, Munmun},
title = {Discovering Alternative Treatments for Opioid Use Recovery Using Social Media},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300354},
abstract = {Opioid use disorder (OUD) poses substantial risks to personal well-being and public
health. In online communities, users support those seeking recovery, in part by promoting
clinically grounded treatments. However, some communities also promote clinically
unverified OUD treatments, such as unregulated and untested drugs. Little research
exists on which alternative treatments people use, whether these treatments are effective
for recovery, or if they cause negative side effects. We provide the first large-scale
social media study of clinically unverified, alternative treatments in OUD recovery
on Reddit, partnering with an addiction research scientist. We adopt transfer learning
across 63 subreddits to precisely identify posts related to opioid recovery. Then,
we quantitatively discover potential alternative treatments and contextualize their
effectiveness. Our work benefits health research and practice by identifying undiscovered
recovery strategies. We also discuss the impacts to online communities dealing with
stigmatized behavior and research ethics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300355,
author = {Franinovi\'{c}, Karmen and Franzke, Luke},
title = {Shape Changing Surfaces and Structures: Design Tools and Methods for Electroactive Polymers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300355},
abstract = {Electroactive polymers (EAP) are a promising material for shape changing interfaces,
soft robotics and other novel design explorations. However, the uptake of EAP prototyping
in design, art and architecture has been slow due to limited commercial availability,
challenging high voltage electronics and lack of simple fabrication techniques. This
paper introduces DIY tools for building and activating EAP prototypes, together with
design methods for making novel shape-changing surfaces and structures, outside of
material science labs. We present iterations of our methods and tools, their use and
evaluation in participatory workshops and public installations and how they affect
the design outcomes. We discuss unique aesthetic and interactive experiences enabled
by the organic and subtle movement of semi-transparent EAP membranes. Finally, we
summarise the potential of design tools and methods to facilitate increased exploration
of interactive EAP prototypes and outline future steps.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300356,
author = {Muller, Michael and Lange, Ingrid and Wang, Dakuo and Piorkowski, David and Tsay, Jason and Liao, Q. Vera and Dugan, Casey and Erickson, Thomas},
title = {How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300356},
abstract = {With the rise of big data, there has been an increasing need for practitioners in
this space and an increasing opportunity for researchers to understand their workflows
and design new tools to improve it. Data science is often described as data-driven,
comprising unambiguous data and proceeding through regularized steps of analysis.
However, this view focuses more on abstract processes, pipelines, and workflows, and
less on how data science workers engage with the data. In this paper, we build on
the work of other CSCW and HCI researchers in describing the ways that scientists,
scholars, engineers, and others work with their data, through analyses of interviews
with 21 data science professionals. We set five approaches to data along a dimension
of interventions: Data as given; as captured; as curated; as designed; and as created.
Data science workers develop an intuitive sense of their data and processes, and actively
shape their data. We propose new ways to apply these interventions analytically, to
make sense of the complex activities around data practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300357,
author = {G\"{u}ldenpfennig, Florian and Mayer, Peter and Panek, Paul and Fitzpatrick, Geraldine},
title = {An Autonomy-Perspective on the Design of Assistive Technology Experiences of People with Multiple Sclerosis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300357},
abstract = {In HCI and Assistive Technology design, autonomy is regularly equated with independence.
This is a shortcut and leaves out design opportunities by omitting a more nuanced
idea of autonomy. To improve our understanding of how people with severe physical
disabilities experience autonomy, particularly in the context of Assistive Technologies,
we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used
to assistive devices. We constructed a grounded theory from a series of interviews,
focus groups and observations, pointing to strategies in which participants sought
autonomy either in the short-term (managing their daily energy reserve) or in the
long-term (making future plans). The theory shows how factors like enabling technologies,
capital (human, social, psychological resources), and compatibility with daily practices
facilitated a sense of being in control for our participants. Moreover, we show how
over-ambitious or bad design (e.g., paternalism) can lead to opposite results and
restrict autonomy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300358,
author = {Hu, Kevin and Bakker, Michiel A. and Li, Stephen and Kraska, Tim and Hidalgo, C\'{e}sar},
title = {VizML: A Machine Learning Approach to Visualization Recommendation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300358},
abstract = {Visualization recommender systems aim to lower the barrier to exploring basic visualizations
by automatically generating results for analysts to search and select, rather than
manually specify. Here, we demonstrate a novel machine learning-based approach to
visualization recommendation that learns visualization design choices from a large
corpus of datasets and associated visualizations. First, we identify five key design
choices made by analysts while creating visualizations, such as selecting a visualization
type and choosing to encode a column along the X- or Y-axis. We train models to predict
these design choices using one million dataset-visualization pairs collected from
a popular online visualization platform. Neural networks predict these design choices
with high accuracy compared to baseline models. We report and interpret feature importances
from one of these baseline models. To evaluate the generalizability and uncertainty
of our approach, we benchmark with a crowdsourced test set, and show that the performance
of our model is comparable to human performance when predicting consensus visualization
type, and exceeds that of other visualization recommender systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300359,
author = {Young, Alyson L. and Miller, Andrew D.},
title = {"This Girl is on Fire": Sensemaking in an Online Health Community for Vulvodynia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300359},
abstract = {Online health communities (OHCs) allow people living with a shared diagnosis or medical
condition to connect with peers for social support and advice. OHCs have been well
studied in conditions like diabetes and cancer, but less is known about their role
in enigmatic diseases with unknown or complex causal mechanisms. In this paper, we
study one such condition: Vulvodynia, a chronic pain syndrome of the vulvar region.
Through observations of and interviews with members of a vulvodynia Facebook group,
we found that while the interaction types are broadly similar to those found in other
OHCs, the women spent more time seeking basic information and building individualized
management plans. They also encounter significant emotional and interpersonal challenges,
which they discuss with each other. We use this study to extend the field's understanding
of OHCs, and to propose implications for the design of self-tracking tools to support
sensemaking in enigmatic conditions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300360,
author = {Lee, Alexandra and Archambault, Daniel and Nacenta, Miguel},
title = {Dynamic Network Plaid: A Tool for the Analysis of Dynamic Networks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300360},
abstract = {Network data that changes over time can be very useful for studying a wide range of
important phenomena, from how social network connections change to epidemiology. However,
it is challenging to analyze, especially if it has many actors, connections or if
the covered timespan is large with rapidly changing links (e.g., months of changes
with changes at second resolution). In these analyses one would often like to compare
many periods of time to others, without having to look at the full timeline. To support
this kind of analysis we designed and implemented a technique and system to visualize
this dynamic data. The Dynamic Network Plaid (DNP) is designed for large displays
and based on user-generated interactive timeslicing on the dynamic graph attributes
and on linked provenance-preserving representations. We present the technique, interface
and the design/evaluation with a group of public health researchers investigating
non-suicidal self-harm picture sharing in Instagram.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300361,
author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Binns, Reuben and Slack, Adam and Inzlicht, Michael and Van Kleek, Max and Shadbolt, Nigel},
title = {Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300361},
abstract = {Many people struggle to control their use of digital devices. However, our understanding
of the design mechanisms that support user self-control remains limited. In this paper,
we make two contributions to HCI research in this space: first, we analyse 367 apps
and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify
common core design features and intervention strategies afforded by current tools
for digital self-control. Second, we adapt and apply an integrative dual systems model
of self-regulation as a framework for organising and evaluating the design features
found. Our analysis aims to help the design of better tools in two ways: (i) by identifying
how, through a well-established model of self-regulation, current tools overlap and
differ in how they support self-control; and (ii) by using the model to reveal underexplored
cognitive mechanisms that could aid the design of new tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–18},
numpages = {18}
}

@inbook{10.1145/3290605.3300362,
author = {Pittera, Dario and Gatti, Elia and Obrist, Marianna},
title = {<i>I'm Sensing in the Rain</i>: Spatial Incongruity in Visual-Tactile Mid-Air Stimulation Can Elicit Ownership in VR Users},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300362},
abstract = {Major virtual reality (VR) companies are trying to enhance the sense of immersion
in virtual environments by implementing haptic feedback in their systems (e.g., Oculus
Touch). It is known that tactile stimulation adds realism to a virtual environment.
In addition, when users are not limited by wearing any attachments (e.g., gloves),
it is even possible to create more immersive experiences. Mid-air haptic technology
provides contactless haptic feedback and offers the potential for creating such immersive
VR experiences. However, one of the limitations of mid-air haptics resides in the
need for freehand tracking systems (e.g., Leap Motion) to deliver tactile feedback
to the user's hand. These tracking systems are not accurate, limiting designers capability
of delivering spatially precise tactile stimulation. Here, we investigated an alternative
way to convey incongruent visual-tactile stimulation that can be used to create the
illusion of a congruent visual-tactile experience, while participants experience the
phenomenon of the rubber hand illusion in VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300363,
author = {Snyder, Jaime and Murnane, Elizabeth and Lustig, Caitie and Voida, Stephen},
title = {Visually Encoding the Lived Experience of Bipolar Disorder},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300363},
abstract = {Issues of social identity, attitudes towards self-disclosure, and potentially biased
approaches to what is considered "typical" or "normal" are critical factors when designing
visualizations for personal informatics systems. This is particularly true when working
with vulnerable populations like those who self-track to manage serious mental illnesses
like bipolar disorder (BD). We worked with individuals diagnosed with BD to 1) better
understand sense-making challenges related to the representation and interpretation
of personal data and 2) probe the benefits, risks, and limitations of participatory
approaches to designing personal data visualizations that better reflect their lived
experiences. We describe our co-design process, present a series of emergent visual
encoding schemas resulting from these activities, and report on the assessment of
these speculative designs by participants. We conclude by summarizing important considerations
and implications for designing personal data visualizations for (and with) people
who self-track to manage serious mental illness.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300364,
author = {Ernala, Sindhu Kiranmai and Birnbaum, Michael L. and Candan, Kristin A. and Rizvi, Asra F. and Sterling, William A. and Kane, John M. and De Choudhury, Munmun},
title = {Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300364},
abstract = {A growing body of research is combining social media data with machine learning to
predict mental health states of individuals. An implication of this research lies
in informing evidence-based diagnosis and treatment. However, obtaining clinically
valid diagnostic information from sensitive patient populations is challenging. Consequently,
researchers have operationalized characteristic online behaviors as "proxy diagnostic
signals" for building these models. This paper posits a challenge in using these diagnostic
signals, purported to support clinical decision-making. Focusing on three commonly
used proxy diagnostic signals derived from social media, we find that predictive models
built on these data, although offer strong internal validity, suffer from poor external
validity when tested on mental health patients. A deeper dive reveals issues of population
and sampling bias, as well as of uncertainty in construct validity inherent in these
proxies. We discuss the methodological and clinical implications of these gaps and
provide remedial guidelines for future research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300365,
author = {Kip, Hanneke and Kelders, Saskia M. and Van Gemert-Pijnen, Lisette J.E.W.C},
title = {Putting the Value in VR: How to Systematically and Iteratively Develop a Value-Based VR Application with a Complex Target Group},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300365},
abstract = {In development, implementation and evaluation of eHealth it is essential to account
for stakeholders' perspectives, opinions and values, which are statements that specify
what stakeholders want to achieve or improve via a technology. The use of values enables
developers to systematically include stakeholders' perspectives and the context of
use in an eHealth development process. However, there are relatively few papers that
explain how to use values in technology development. Consequently, in this paper we
show how we formulated values during the multi-method, interdisciplinary and iterative
development process of a VR application for a complex setting: forensic mental healthcare.
We report the main foundations for these values: the outcomes of an online questionnaire
with patients, therapists and other stakeholders (n=146) and interviews with patients
and therapists (n=18). We show how a multidisciplinary project team used these qualitative
results to formulate and adapt values and create lo-fi prototypes of a VR application.
We discuss the importance of a systematic development process with multiple formative
evaluations for eHealth and reflect on the role of values within this.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300366,
author = {Chen, Anita and Yuan, Chien-Wen and Ma, Ning F. and Hsu, Chi-Yang and Hanrahan, Benjamin V.},
title = {Navigating Ride-Sharing Regulations: How Regulations Changed the 'Gig' of Ride-Sharing for Drivers in Taiwan},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300366},
abstract = {Ride-sharing platforms have rapidly spread and disrupted ride hailing markets, resulting
in conflicts between ride-sharing and taxi drivers. Taxi drivers claim that their
counterparts have unfair advantages in terms of lower prices and a more stable customer
base, making it difficult to earn a living. Local government entities have dealt with
this disruption and conflict in different ways, often looking towards some form of
regulation. While there have been discussions about what the regulation should be,
there has been less work looking at what impacts regulations have on ride-sharing
drivers and their usage of the platforms. In this paper we present our interview study
of ride-sharing drivers in Taiwan, who have gone through three distinct phases of
regulation. Drivers felt that regulations legitimized their work, while having to
navigate consequences related to regulated access to platforms and fundamental changes
to the "gig'' of ride-sharing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300367,
author = {Andalibi, Nazanin},
title = {What Happens After Disclosing Stigmatized Experiences on Identified Social Media: Individual, Dyadic, and Social/Network Outcomes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300367},
abstract = {Disclosing stigmatized experiences or identity facets on identified social media (e.g.,
Facebook) can be risky, inhibited, yet beneficial for the discloser. I investigate
such disclosures' outcomes when they do happen on identified social media as perceived
by the individuals who perform them. I draw on interviews with women who have experienced
pregnancy loss and are social media users in the U.S. I document outcomes at the social/network,
individual, and dyad levels. I highlight the powerful role of connecting with others
with a similar experience within networks of known ties, how disclosures lead to relationship
changes, how disclosers take on new social roles as mentors and support sources, and
how helpful connections following disclosures originate from various kinds of ties
via diverse communication channels. I emphasize reciprocal disclosures as an outcome
contributing to further outcomes (e.g., destigmatizing pregnancy loss). I provide
design implications related to facilitating being a support source and mentor, helpful
reciprocal disclosures, and finding similar others within networks of known ties.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300368,
author = {Cook, Amy and Hammer, Jessica and Elsayed-Ali, Salma and Dow, Steven},
title = {How Guiding Questions Facilitate Feedback Exchange in Project-Based Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300368},
abstract = {Peer feedback is essential for learning in project-based disciplines. However, students
often need guidance when acting as either a feedback provider or a feedback receiver,
both to gain from peer feedback and to criticize their peers' work. This paper explores
how to more effectively scaffold this exchange such that peers more deeply engage
in the feedback process. Within a game design course, we introduced different processes
for feedback receivers to write questions to guide peer feedback. Feedback receivers
wrote four main types of guiding questions: improve, share, brainstorm, critique.
We found that "improve'' questions tended to lead to better feedback (more specific,
critical, and actionable) than other question types, but feedback receivers wrote
improve questions least often. We offer insights on how best to scaffold the question-writing
process to facilitate peer feedback exchange.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300369,
author = {Rankin, Yolanda A. and Han, Na-eun},
title = {Exploring the Plurality of Black Women's Gameplay Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300369},
abstract = {Few gender-focused studies of video games explore the gameplay experiences of women
of color, and those that do tend to only emphasize negative phenomena (i.e., racial
or gender discrimination). In this paper, we conduct an exploratory case study attending
to the motivations and gaming practices of Black college women. Questionnaire responses
and focus group discussion illuminate the plurality of gameplay experiences for this
specific population of Black college women. Sixty-five percent of this population
enjoy the ubiquity of mobile games with casual and puzzle games being the most popular
genres. However, academic responsibilities and competing recreational interests inhibit
frequent gameplay. Consequently, this population of Black college women represent
two types of casual gamers who report positive gameplay experiences, providing insights
into creating a more inclusive gaming subculture.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300370,
author = {Naiakshina, Alena and Danilova, Anastasia and Gerlitz, Eva and von Zezschwitz, Emanuel and Smith, Matthew},
title = {"If You Want, I Can Store the Encrypted Password": A Password-Storage Field Study with Freelance Developers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300370},
abstract = {In 2017 and 2018, Naiakshina et al. (CCS'17, SOUPS'18) studied in a lab setting whether
computer science students need to be told to write code that stores passwords securely.
The authors' results showed that, without explicit prompting, none of the students
implemented secure password storage. When asked about this oversight, a common answer
was that they would have implemented secure storage - if they were creating code for
a company. To shed light on this possible confusion, we conducted a mixed-methods
field study with developers. We hired freelance developers online and gave them a
similar password storage task followed by a questionnaire to gain additional insights
into their work. From our research, we offer two contributions. First of all, we reveal
that, similar to the students, freelancers do not store passwords securely unless
prompted, they have misconceptions about secure password storage, and they use outdated
methods. Secondly, we discuss the methodological implications of using freelancers
and students in developer studies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300371,
author = {Wedoff, Ryan and Ball, Lindsay and Wang, Amelia and Khoo, Yi Xuan and Lieberman, Lauren and Rector, Kyle},
title = {Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300371},
abstract = {Virtual Reality (VR) is a growing source of entertainment, but people who are visually
impaired have not been effectively included. Audio cues are motivated as a complement
to visuals, making experiences more immersive, but are not a primary cue. To address
this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown
on an accessible real-world game called Showdown, where people use their hearing to
locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration
Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability
of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth
who are visually impaired. Thirty-three participants wanted to play Virtual Showdown
again, and we learned that participants scored higher with the Verbal Scaffold or
if they had prior Showdown experience. Our empirical findings inform the design of
future accessible VR experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300372,
author = {Dosono, Bryan and Semaan, Bryan},
title = {Moderation Practices as Emotional Labor in Sustaining Online Communities: The Case of AAPI Identity Work on Reddit},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300372},
abstract = {We examine how and why Asian American and Pacific Islander (AAPI) moderators on Reddit
shape the norms of their online communities through the analytic lens of emotional
labor. We conduct interviews with 21 moderators who facilitate identity work discourse
in AAPI subreddits and present a thematic analysis of their moderation practices.
We report on their challenges to sustaining moderation, which include burning out
from volunteer work, navigating hierarchical structures, and balancing unfulfilled
expectations. We then describe strategies that moderators employ to manage emotional
labor, which involve distancing away from drama, building solidarity from shared struggles,
and integrating an ecology of tools for self-organized moderation. We provide recommendations
for improving moderation in online communities centered around identity work and discuss
implications of emotional labor in the design of Reddit and similar platforms.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300373,
author = {Kruijff, Ernst and Biswas, Saugata and Trepkowski, Christina and Maiero, Jens and Ghinea, George and Stuerzlinger, Wolfgang},
title = {Multilayer Haptic Feedback for Pen-Based Tablet Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300373},
abstract = {We present a novel, multilayer interaction approach that enables state transitions
between spatially above-screen and 2D on-screen feedback layers. This approach supports
the exploration of haptic features that are hard to simulate using rigid 2D screens.
We accomplish this by adding a haptic layer above the screen that can be actuated
and interacted with (pressed on) while the user interacts with on-screen content using
pen input. The haptic layer provides variable firmness and contour feedback, while
its membrane functionality affords additional tactile cues like texture feedback.
Through two user studies, we look at how users can use the layer in haptic exploration
tasks, showing that users can discriminate well between different firmness levels,
and can perceive object contour characteristics. Demonstrated also through an art
application, the results show the potential of multilayer feedback to extend on-screen
feedback with additional widget, tool and surface properties, and for user guidance.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300374,
author = {Frison, Anna-Katharina and Wintersberger, Philipp and Riener, Andreas and Schartm\"{u}ller, Clemens and Boyle, Linda Ng and Miller, Erika and Weigl, Klemens},
title = {In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300374},
abstract = {In the evolution of technical systems, freedom from error and early adoption plays
a major role for market success and to maintain competitiveness. In the case of automated
driving, we see that faulty systems are put into operation and users trust these systems,
often without any restrictions. Trust and use are often associated with users' experience
of the driver-vehicle interfaces and interior design. In this work, we present the
results of our investigations on factors that influence the perception of automated
driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle
with either perfect or faulty driving function. As a secondary activity, participants
had to solve tasks on an infotainment system with varying aesthetics and usability
(2x2). Results reveal that the interaction of conditions significantly influences
trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle
design cumulate to system and trust perception.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300375,
author = {Fedosov, Anton and Kitazaki, Masako and Odom, William and Langheinrich, Marc},
title = {Sharing Economy Design Cards},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300375},
abstract = {Sharing economy services have become increasingly popular. In addition to various
well-known for-profit activities in this space (e.g., ride and apartment sharing),
many community groups and non-profit organizations offer collections of shared things
(e.g., books, tools) that explicitly aim to benefit local communities. We expect that
both non-profit and for-profit approaches will see an increased use in the future.
To support designers in devising new sharing economy services, we developed the Sharing
Economy Design Cards, a design toolkit in the form of a card deck. We present two
deployments of the cards: (1) in individual interviews with 16 designers and sharing
economy domain experts; and (2) in two workshops with 5 participants each. Our findings
show that the use of the cards not only facilitates the creation of future sharing
platforms and services in a collaborative setting, but also helps to evaluate existing
sharing economy services as an individual activity.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300376,
author = {Kimura, Naoki and Kono, Michinari and Rekimoto, Jun},
title = {SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300376},
abstract = {The availability of digital devices operated by voice is expanding rapidly. However,
the applications of voice interfaces are still restricted. For example, speaking in
public places becomes an annoyance to the surrounding people, and secret information
should not be uttered. Environmental noise may reduce the accuracy of speech recognition.
To address these limitations, a system to detect a user's unvoiced utterance is proposed.
From internal information observed by an ultrasonic imaging sensor attached to the
underside of the jaw, our proposed system recognizes the utterance contents without
the user's uttering voice. Our proposed deep neural network model is used to obtain
acoustic features from a sequence of ultrasound images. We confirmed that audio signals
generated by our system can control the existing smart speakers. We also observed
that a user can adjust their oral movement to learn and improve the accuracy of their
voice recognition.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300377,
author = {Funk, Markus and M\"{u}ller, Florian and Fendrich, Marco and Shene, Megan and Kolvenbach, Moritz and Dobbertin, Niclas and G\"{u}nther, Sebastian and M\"{u}hlh\"{a}user, Max},
title = {Assessing the Accuracy of Point &amp; Teleport Locomotion with Orientation Indication for Virtual Reality Using Curved Trajectories},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300377},
abstract = {Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked
environments are set up in limited physical spaces. As most Virtual Environments (VEs)
are larger than the tracked physical space, locomotion techniques are used to navigate
in VEs. Currently, in recent VR games, point &amp; teleport is the most popular locomotion
technique. However, it only allows users to select the position of the teleportation
and not the orientation that the user is facing after the teleport. This results in
users having to manually correct their orientation after teleporting and possibly
getting entangled by the cable of the headset. In this paper, we introduce and evaluate
three different point &amp; teleport techniques that enable users to specify the target
orientation while teleporting. The results show that, although the three teleportation
techniques with orientation indication increase the average teleportation time, they
lead to a decreased need for correcting the orientation after teleportation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300378,
author = {Ramchurn, Richard and Martindale, Sarah and Wilson, Max L. and Benford, Steve},
title = {From Director's Cut to User's Cut: To Watch a Brain-Controlled Film is to Edit It},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300378},
abstract = {Introducing interactivity to films has proven a longstanding and difficult challenge
due to their narrative-driven, linear and theatre-based nature. Previous research
has suggested that Brain-Computer Interfaces (BCI) may be a promising approach but
also revealed a tension between being immersed in the film and thinking about control.
We report a performance-led and in-the-wild study of a BCI film called The MOMENT
covering its design rationale and how it was experienced by the public as controllers,
non-controllers and repeat viewers. Our findings suggest that BCI movies should be
designed to be credibly controllable, generate personal versions, be watchable as
linear films, encourage repeat viewing and fit the medium of cinema. They also reveal
how viewers appreciated the sense of editing their own personal cuts, suggesting a
new stance on introducing interactivity into lean-back media in which filmmakers release
editorial control to users to make their own versions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300379,
author = {Perusqu\'{\i}a-Hern\'{a}ndez, Monica and Ayabe-Kanamura, Saho and Suzuki, Kenji and Kumano, Shiro},
title = {The Invisible Potential of Facial Electromyography: A Comparison of EMG and Computer Vision When Distinguishing Posed from Spontaneous Smiles},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300379},
abstract = {Positive experiences are a success metric in product and service design. Quantifying
smiles is a method of assessing them continuously. Smiles are usually a cue of positive
affect, but they can also be fabricated voluntarily. Automatic detection is a promising
complement to human perception in terms of identifying the differences between smile
types. Computer vision (CV) and facial distal electromyography (EMG) have been proven
successful in this task. This is the first study to use a wearable EMG that does not
obstruct the face to compare the performance of CV and EMG measurements in the task
of distinguishing between posed and spontaneous smiles. The results showed that EMG
has the advantage of being able to identify covert behavior not available through
vision. Moreover, CV appears to be able to identify visible dynamic features that
human judges cannot account for. This sheds light on the role of non-observable behavior
in distinguishing affect-related smiles from polite positive affect displays.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300380,
author = {Lessel, Pascal and Altmeyer, Maximilian and Schmeer, Lea Verena and Kr\"{u}ger, Antonio},
title = {"Enable or Disable Gamification?": Analyzing the Impact of Choice in a Gamified Image Tagging Task},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300380},
abstract = {This paper investigates a simple form of customization: giving users the choice to
enable or disable gamification. We present a study (N=77) in the context of image
tagging, in which a gamification approach was shown to be effective in previous work.
In our case, some participants could enable or disable gamification after they had
experienced the task with and without it. Other participants had no choice and did
the task with or without game elements. The results indicate that those who are not
attracted by the elements can be motivated to tag more through this choice. In contrast,
those that like the elements are not affected by it. This suggests that systems should
provide the option to disable gamification in the absence of more sophisticated tailoring.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300381,
author = {Wolf, Flynn and Kuber, Ravi and Aviv, Adam J.},
title = {"Pretty Close to a Must-Have": Balancing Usability Desire and Security Concern in Biometric Adoption},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300381},
abstract = {We report on a qualitative inquiry among security-expert and non-expert mobile device
users about the adoption of biometric authentication using semi-structured interviews(n=38,
19/19 expert/non-expert). Security experts more readily adopted biometrics than non-experts
but also harbored greater distrust towards its use for sensitive transactions,feared
biometric signature compromise, and in some cases distrusted newer facial recognition
methods. Both groups harbored misconceptions, such as misunderstanding of the functional
role of biometrics in authentication, and were about equally likely to have stopped
using biometrics due to usability. Implications include the need for tailored training
for security-informed advocates, better design for device sharing and co-registration,
and consideration for usability needs in work environments. Refinement of these features
would remove perceived obstacles to ubiquitous computing among the growing population
of mobile technology users sensitized to security risk.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300383,
author = {Jones, Ridley and Colusso, Lucas and Reinecke, Katharina and Hsieh, Gary},
title = {R/Science: Challenges and Opportunities in Online Science Communication},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300383},
abstract = {Online discussion websites, such as Reddit's r/science forum, have the potential to
foster science communication between researchers and the general public. However,
little is known about who participates, what is discussed, and whether such websites
are successful in achieving meaningful science discussions. To find out, we conducted
a mixed-methods study analyzing 11,859 r/science posts and conducting interviews with
18 community members. Our results show that r/science facilitates rich information
exchange and that the comments section provides a unique science communication document
that guides engagement with scientific research. However, this community-sourced science
communication comes largely from a knowledgeable public. We conclude with design suggestions
for a number of critical problems that we uncovered: addressing the problem of topic
newsworthiness and balancing broader participation and rigor.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300384,
author = {Pauchet, Sylvain and Vinot, Jean-Luc and Letondal, Catherine and Lemort, Alexandre and Lavenir, Claire and Lecomte, Timoth\'{e}e and Rey, St\'{e}phanie and Becquet, Valentin and Crouzet, Guillaume},
title = {Multi-Pli\'{e}: A Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300384},
abstract = {We present the design concept of an accordion-fold interactive display to address
the limits of touch-based interaction in airliner cockpits. Based on an analysis of
pilot activity, tangible design principles for this design concept are identified.
Two resulting functional prototypes are explored during participatory workshops with
pilots, using activity scenarios. This exploration validated the design concept by
revealing its ability to match pilot responsibilities in terms of safety, efficiency
and collaboration. It provides an efficient visual perception of the system for real-time
collaborative operations and tangible interaction to strengthen the perception of
action and to manage safety through anticipation and awareness. The design work and
insights enabled to specify further our needs regarding flexible screens. They also
helped to better characterize the design concept as based on continuity of a developed
surface, predictability of aligned folds and pleat face roles, embodied interactive
properties, and flexibility through affordable reconfigurations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300385,
author = {Thinyane, Hannah and Bhat, Karthik S.},
title = {Apprise: Supporting the Critical-Agency of Victims of Human Trafficking in Thailand},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300385},
abstract = {Human trafficking and forced labor are global issues affecting millions of people
around the world. This paper describes an initiative that we are currently undertaking
to understand the role technology can play to support the critical-agency of migrant
workers in these situations of severe exploitation. Building on five consultations
with more than 170 direct and indirect stakeholders in Thailand, the paper presents
the co-design, development, and evaluation of Apprise, a mobile app to support the
identification of victims of human trafficking using a Value Sensitive Design approach.
It also provides a critical reflection on the use of digital technology in the initial
screening of potential victims of human trafficking, to understand in what ways Apprise
can support the critical agency of migrant workers in vulnerable situations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300386,
author = {Leen, Danny and Veuskens, Tom and Luyten, Kris and Ramakers, Raf},
title = {JigFab: Computational Fabrication of Constraints to Facilitate Woodworking with Power Tools},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300386},
abstract = {We present JigFab, an integrated end-to-end system that supports casual makers in
designing and fabricating constructions with power tools. Starting from a digital
version of the construction, JigFab achieves this by generating various types of constraints
that configure and physically aid the movement of a power tool. Constraints are generated
for every operation and are custom to the work piece. Constraints are laser cut and
assembled together with predefined parts to reduce waste. JigFab's constraints are
used according to an interactive step-by-step manual. JigFab internalizes all the
required domain knowledge for designing and building intricate structures, consisting
of various types of finger joints, tenon &amp; mortise joints, grooves, and dowels. Building
such structures is normally reserved for artisans or automated with advanced CNC machinery.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300387,
author = {B\"{o}rjesson, Peter and Barendregt, Wolmet and Eriksson, Eva and Torgersson, Olof and Bekker, Tilde},
title = {Teachers' Expected and Perceived Gains of Participation in Classroom Based Design Activities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300387},
abstract = {This paper explores teachers' expected and perceived gains from classroom participation
in design projects. The results indicate that teachers hope the experience will be
fun for the children, and that it will increase both children's and their own knowledge
about technology. Although they consider learning goals important, these do not necessarily
have to be communicated to the children, since the teachers experience that the children
are learning several skills anyway. However, early involvement in the definition of
learning goals could make participation more beneficial. The teachers also see several
gains from partication for themselves, especially related to using a design approach
in the classroom. We discuss the implications of these finding and suggest a way to
increase the user gains for both children and teachers by considering the opportunity
to use classroom participation as a way to support teachers' competence development,
thereby fulfilling the promise of mutual learning as advocated in Participatory Design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300388,
author = {Ioannou, Christos and Archard, Patrick and O'Neill, Eamonn and Lutteroth, Christof},
title = {Virtual Performance Augmentation in an Immersive Jump &amp; Run Exergame},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300388},
abstract = {Human performance augmentation through technology has been a recurring theme in science
and culture, aiming to increase human capabilities and accessibility. We investigate
a related concept: virtual performance augmentation (VPA), using VR to give users
the illusion of greater capabilities than they actually have. We propose a method
for VPA of running and jumping, based on in place movements, and studied its effects
in a VR exergame. We found that in place running and jumping in VR can be used to
create a somewhat natural experience and can elicit medium to high physical exertion
in an immersive and intrinsically motivating manner. We also found that virtually
augmenting running and jumping can increase intrinsic motivation, perceived competence
and flow, and may also increase motivation for physical activity in general. We discuss
implications of VPA for safety and accessibility, with initial evidence suggesting
that VPA may help users with physical impairments enjoy the benefits of exergaming.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300389,
author = {Lambton-Howard, Daniel and Anderson, Robert and Montague, Kyle and Garbett, Andrew and Hazeldine, Shaun and Alvarez, Carlos and Sweeney, John A. and Olivier, Patrick and Kharrufa, Ahmed and Nappey, Tom},
title = {WhatFutures: Designing Large-Scale Engagements on WhatsApp},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300389},
abstract = {WhatsApp, as the world's most popular messaging application, offers significant opportunities
for improving the reach and effectiveness of engagement projects. In collaboration
with the International Federation of Red Cross and Red Crescent Societies (IFRC) we
designed WhatFutures, a collaborative future forecasting engagement for global youth
using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries
(Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within
the IFRC. Based on our analysis of the activity - including 16,100 messages, 95 multimedia
artifacts, and a post-engagement survey - we present a reflection upon the design
decisions underpinning WhatFutures and identify how decisions made around group structures,
processes and externalization of outputs influenced engagement and data quality. We
conclude with the wider implications of our findings for the design of engagements
that best utilize the affordances of existing messaging applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300390,
author = {Wohn, Donghee Yvette},
title = {Volunteer Moderators in Twitch Micro Communities: How They Get Involved, the Roles They Play, and the Emotional Labor They Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300390},
abstract = {The ability to engage in real-time text conversations is an important feature on live
streaming platforms. The moderation of this text content relies heavily on the work
of unpaid volunteers. This study reports on interviews with 20 people who moderate
for Twitch micro communities, defined as channels that are built around a single or
group of streamers, rather than the broadcast of an event. The study identifies how
people become moderators, their different styles of moderating, and the difficulties
that come with the job. In addition to the hardships of dealing with negative content,
moderators also have complex interpersonal relationships with the streamers and viewers,
where the boundaries between emotional labor, physical labor, and fun are intertwined.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300391,
author = {Schneider, Hanna and Wayrauther, Julia and Hassib, Mariam and Butz, Andreas},
title = {Communicating Uncertainty in Fertility Prognosis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300391},
abstract = {Communicating uncertainty has been shown to provide positive effects on user understanding
and decision-making. Surprisingly however, most personal health tracking applications
fail to disclose the accuracy of their measurements and predictions. In the case of
fertility tracking applications (FTAs), inaccurate predictions have already led to
numerous unwanted pregnancies and law suits. However, integrating uncertainty into
FTAs is challenging: Prediction accuracy is hard to understand and communicate, and
its effect on users' trust and behavior is not well understood. We created a prototype
for uncertainty visualizations for FTAs and evaluated it in a four-week field study
with real users and their own data (N=9). Our results uncover far-reaching effects
of communicating uncertainty: For example, users interpreted prediction accuracy as
a proxy for their cycle health and as a security indicator for contraception. Displaying
predicted and detected fertile phases next to each other helped users to understand
uncertainty without negative emotional effects.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300392,
author = {Kobayashi, Jumpei and Kawashima, Toshio},
title = {Paragraph-Based Faded Text Facilitates Reading Comprehension},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300392},
abstract = {We propose a new text layout that facilitates reading comprehension. By sequentially
fading out characters sentence-by-sentence from the beginning of each paragraph, we
highlight the paragraph structure of the entire text and the relative positions of
the sentences. To evaluate the effectiveness of the paragraph-based faded text in
a reading comprehension, we measure the comprehension, eye movements, and recognition
for both the proposed method and a conventional standard method. In the proposed method,
rates of correct answers to text comprehension questions are improved. Moreover, the
proposed method leads to slower reading speeds and better recognition rates for the
first sentences of paragraphs, which are displayed in a relatively thicker mode. With
the paragraph-based faded text, the reader is naturally facilitated to pay attention
to the first sentence of each paragraph, suggesting that this reading style could
result in a more accurate text comprehension.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300393,
author = {Qiu, Lina and De Luca, Alexander and Muslukhov, Ildar and Beznosov, Konstantin},
title = {Towards Understanding the Link Between Age and Smartphone Authentication},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300393},
abstract = {While previous work on smartphone (un)locking has revealed real world usage patterns,
several aspects still need to be explored. In this paper, we fill one of these knowledge
gaps: the interplay between age and smartphone authentication behavior. To do this,
we performed a two-month long field study (N = 134). Our results indicate that there
are indeed significant differences across age. For instance, younger participants
were more likely to use biometric unlocking mechanisms and older participants relied
more on auto locks.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300394,
author = {Ofer, Netta and David, Idan and Erel, Hadas and Zuckerman, Oren},
title = {Coding for Outdoor Play: A Coding Platform for Children to Invent and Enhance Outdoor Play Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300394},
abstract = {Outdoor play is in decline, including its benefits to children's development. Coding,
a typically indoor, screen-based activity, can potentially enrich outdoor play, serving
as a rule-making medium. We present a coding platform that controls a programmable
hardware device, enabling children to technologically-enhance their outdoor play experiences
by inventing game ideas, coding them, and playing their games together with their
friends. In the evaluation study, 24 children used the system to invent and play outdoor
games. Results show children are able to bridge between the different domains of coding
and outdoor play. They used the system to modify traditional games and invent new
ones, enriching their outdoor experience. Children merged computational concepts with
physical game elements, integrated physical outdoor properties as variables in their
code, and were excited to see their code come to life. We conclude children can use
coding to express their ideas by creating technologically-enhanced outdoor play experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300395,
author = {Cui, Wenzhe and Zheng, Jingjie and Lewis, Blaine and Vogel, Daniel and Bi, Xiaojun},
title = {HotStrokes: Word-Gesture Shortcuts on a Trackpad},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300395},
abstract = {Expert interaction techniques like hotkeys are efficient, but poorly adopted because
they are hard to learn. HotStrokes removes the need for learning arbitrary mappings
of commands to hotkeys. A user enters a HotStroke by holding a modifier key, then
gesture typing a command name on a laptop trackpad as if on an imaginary virtual keyboard.
The gestures are recognized using an adaptation of the SHARK2 algorithm with a new
spatial model and a refined method for dynamic suggestions. A controlled experiment
shows HotStrokes effectively augments the existing "menu and hotkey" command activation
paradigm. Results show the method is efficient by reducing command activation time
by 43% compared to linear menus. The method is also easy to learn with a high adoption
rate, replacing 91% of linear menu usage. Finally, combining linear menus, hotkeys,
and HotStrokes leads to 24% faster command activation overall.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300397,
author = {Leung, Weiwen},
title = {How Do One's Peers on a Leaderboard Affect Oneself?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300397},
abstract = {Leaderboards are a workhorse of the gamification literature. While the effect of a
leaderboard has been well studied, there is much less evidence how one's peer group
affects the treatment effect of a leaderboard. Through a pre-registered field experiment
involving more than 1000 users on an online movie recommender website, we expose users
to leaderboards, but different sets of users are exposed to different peer groups.
Contrary to what a standard behavioral model would predict, we find that a user's
contribution increases when their peer's scores are more dispersed. We also find that
decreasing average peer contributions motivates a user to contribute more. Moreover,
these effects are themselves mediated by group size. This sheds new light on existing
theories of motivation and demotivation with regards to leaderboards, and also illustrates
the potential of using personalized leaderboards to increase contributions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300398,
author = {Gordon, Mitchell L. and Gatys, Leon and Guestrin, Carlos and Bigham, Jeffrey P. and Trister, Andrew and Patel, Kayur},
title = {App Usage Predicts Cognitive Ability in Older Adults},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300398},
abstract = {We have limited understanding of how older adults use smartphones, how their usage
differs from younger users, and the causes for those differences. As a result, researchers
and developers may miss promising opportunities to support older adults or offer solutions
to unimportant problems. To characterize smartphone usage among older adults, we collected
iPhone usage data from 84 healthy older adults over three months. We find that older
adults use fewer apps, take longer to complete tasks, and send fewer messages. We
use cognitive test results from these same older adults to then show that up to 79%
of these differences can be explained by cognitive decline, and that we can predict
cognitive test performance from smartphone usage with 83% ROCAUC. While older adults
differ from younger adults in app usage behavior, the "cognitively young" older adults
use smartphones much like their younger counterparts. Our study suggests that to better
support all older adults, researchers and developers should consider the full spectrum
of cognitive function.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300399,
author = {Vashistha, Aditya and Garg, Abhinav and Anderson, Richard},
title = {ReCall: Crowdsourcing on Basic Phones to Financially Sustain Voice Forums},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300399},
abstract = {Although voice forums are widely used to enable marginalized communities to produce,
consume, and share information, their financial sustainability is a key concern among
HCI4D researchers and practitioners. We present ReCall, a crowdsourcing marketplace
accessible via phone calls where low-income rural residents vocally transcribe audio
files to gain free airtime to participate in voice forums as well as to earn money.
We conducted a series of experimental and usability evaluations with 28 low-income
people in rural India to examine the effect of phone types, channel types, and review
modes on speech transcription performance. We then deployed ReCall for two weeks to
24 low-income rural residents who placed 5,879 phone calls, completed 29,000 micro
tasks to yield transcriptions with 85% accuracy, and earned INR 20,500. Our mixed-methods
analysis indicates that each minute of crowd work on ReCall gives users eight minutes
of free airtime on another voice forum, and thus illustrates a way to address the
financial sustainability of voice forums.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300400,
author = {Peiris, Roshan Lalitha and Feng, Yuan-Ling and Chan, Liwei and Minamizawa, Kouta},
title = {ThermalBracelet: Exploring Thermal Haptic Feedback Around the Wrist},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300400},
abstract = {Smartwatches enable the wrist to be used as an ideal location to provide always-available
haptic notifications as they are constantly worn with direct contact with the skin.
With the wrist straps, the haptic feedback can be extended to the full space around
the wrist to provide more spatial and enriched feedback. With ThermalBracelet, we
investigate thermal feedback as a haptic feedback modality around the wrist. We present
three studies that lead to the development of a smartwatch-integratable thermal bracelet
that stimulates six locations around the wrist. Our initial evaluation reports on
the selection of the thermal module configurations. Secondly, with the selected six-module
configuration, we explore its usability in a real-world scenarios such as walking
and reading. Thirdly, we investigate its capability of providing spatio temporal feedback
while engaged in distracting tasks. Finally we present application scenarios that
demonstrates its usability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300401,
author = {Chen, Daniel K.Y. and Chossat, Jean-Baptiste and Shull, Peter B.},
title = {HaptiVec: Presenting Haptic Feedback Vectors in Handheld Controllers Using Embedded Tactile Pin Arrays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300401},
abstract = {HaptiVec is a new haptic feedback paradigm for handheld controllers which allows users
to feel directional haptic pressure vectors on their fingers and hands while interacting
with virtual environments. We embed a 3 by 5 tactile pin array (with an average pin
spacing of 25 mm) into the handles of two custom VR type controllers. By presenting
directional pressure vectors in eight cardinal directions (N, NE, E, SE, S, SW, W,
NW) to users without prior training, they were able to distinguish the correct direction
with an accuracy of at least 79%. We illustrate two applications where our device
enhances virtual experiences over traditional vibrotactile feedback. In the first
application, through the classic first-person shooter Doom, we demonstrate that users
can receive directional pressure feedback corresponding to the direction of incident
enemy projectiles. In the second application, we demonstrate how our controller can
create a more immersive experience by allowing the user to feel their virtual climate
by randomizing the directional vectors and presenting the user with "haptic rain"
which adapts with the intensity of the rainfall.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300402,
author = {Chilton, Lydia B. and Petridis, Savvas and Agrawala, Maneesh},
title = {VisiBlends: A Flexible Workflow for Visual Blends},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300402},
abstract = {Visual blends are an advanced graphic design technique to draw attention to a message.
They combine two objects in a way that is novel and useful in conveying a message
symbolically. This paper presents VisiBlends, a flexible workflow for creating visual
blends that follows the iterative design process. We introduce a design pattern for
blending symbols based on principles of human visual object recognition. Our workflow
decomposes the process into both computational techniques and human microtasks. It
allows users to collaboratively generate visual blends with steps involving brainstorming,
synthesis, and iteration. An evaluation of the workflow shows that decentralized groups
can generate blends in independent microtasks, co-located groups can collaboratively
make visual blends for their own messages, and VisiBlends improves novices' ability
to make visual blends.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300403,
author = {Kim, Seungwon and Lee, Gun and Huang, Weidong and Kim, Hayun and Woo, Woontack and Billinghurst, Mark},
title = {Evaluating the Combination of Visual Communication Cues for HMD-Based Mixed Reality Remote Collaboration},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300403},
abstract = {Many researchers have studied various visual communication cues (e.g. pointer, sketching,
and hand gesture) in Mixed Reality remote collaboration systems for real-world tasks.
However, the effect of combining them has not been so well explored. We studied the
effect of these cues in four combinations: hand only, hand + pointer, hand + sketch,
and hand + pointer + sketch, with three problem tasks: Lego, Tangram, and Origami.
The study results showed that the participants completed the task significantly faster
and felt a significantly higher level of usability when the sketch cue is added to
the hand gesture cue, but not with adding the pointer cue. Participants also preferred
the combinations including hand and sketch cues over the other combinations. However,
using additional cues (pointer or sketch) increased the perceived mental effort and
did not improve the feeling of co-presence. We discuss the implications of these results
and future research directions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300404,
author = {Elvitigala, Don Samitha and Matthies, Denys J.C. and David, L\"{o}ic and Weerasinghe, Chamod and Nanayakkara, Suranga},
title = {GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300404},
abstract = {The correct execution of exercises, such as squats and dead-lifts, is essential to
prevent various bodily injuries. Existing solutions either rely on expensive motion
tracking or multiple Inertial Measurement Units (IMU) systems require an extensive
set-up and individual calibration. This paper introduces a proof of concept, GymSoles,
an insole prototype that provides feedback on the Centre of Pressure (CoP) at the
feet to assist users with maintaining the correct body posture, while performing squats
and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback,
2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing
feedback on the current CoP, results in a significantly improved body posture.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300405,
author = {Oberd\"{o}rfer, Sebastian and Heidrich, David and Latoschik, Marc Erich},
title = {Usability of Gamified Knowledge Learning in VR and Desktop-3D},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300405},
abstract = {Affine Transformations (ATs) often escape an intuitive approach due to their high
complexity. Therefore, we developed GEtiT that directly encodes ATs in its game mechanics
and scales the knowledge's level of abstraction. This results in an intuitive application
as well as audiovisual presentation of ATs and hence in a knowledge learning. We also
developed a specific Virtual Reality (VR) version to explore the effects of immersive
VR on the learning outcomes. This paper presents our approach of directly encoding
abstract knowledge in game mechanics, the conceptual design of GEtiT and its technical
implementation. Both versions are compared in regard to their usability in a user
study. The results show that both GEtiT versions induce a high degree of flow and
elicit a good intuitive use. They validate the effectiveness of the design and the
resulting knowledge application requirements. Participants favored GEtiT VR thus showing
a potentially higher learning quality when using VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300406,
author = {Kwan, Kin Chung and Fu, Hongbo},
title = {Mobi3DSketch: 3D Sketching in Mobile AR},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300406},
abstract = {Mid-air 3D sketching has been mainly explored in Virtual Reality (VR) and typically
requires special hardware for motion capture and immersive, stereoscopic displays.
The recently developed motion tracking algorithms allow real-time tracking of mobile
devices, and have enabled a few mobile applications for 3D sketching in Augmented
Reality (AR). However, they are more suitable for making simple drawings only, since
they do not consider special challenges with mobile AR 3D sketching, including the
lack of stereo display, narrow field of view, and the coupling of 2D input, 3D input
and display. To address these issues, we present Mobi3DSketch, which integrates multiple
sources of inputs with tools, mainly different versions of 3D snapping and planar/curves
surface proxies. Our multimodal interface supports both absolute and relative drawing,
allowing easy creation of 3D concept designs in situ. The effectiveness and expressiveness
of Mobi3DSketch are demonstrated via a pilot study.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300407,
author = {Kim, Yoonji and Choi, Youngkyung and Lee, Hyein and Lee, Geehyuk and Bianchi, Andrea},
title = {VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300407},
abstract = {Prototyping electronic circuits is an increasingly popular activity, supported by
researchers, who develop toolkits to improve the design, debugging, and fabrication
of electronics. Although past work mainly dealt with circuit topology, in this paper
we propose a system for determining or tuning the values of the circuit components.
Based on the results of a formative study with seventeen makers, we designed VirtualComponent,
a mixed-reality tool that allows users to digitally place electronic components on
a real breadboard, tune their values in software, and see these changes applied to
the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play
modules containing banks of components, and a custom breadboard managing the connections
and components' values. Through demonstrations and the results of an informal study
with twelve makers, we show that VirtualComponent is easy to use and allows users
to test components' value configurations with little effort.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300408,
author = {Gray, Colin M. and Chivukula, Shruthi Sai},
title = {Ethical Mediation in UX Practice},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300408},
abstract = {HCI scholars have become increasingly interested in describing the complex nature
of UX practice. In parallel, HCI and STS scholars have sought to describe the ethical
and value-laden relationship between designers and design outcomes. However, little
research describes the ethical engagement of UX practitioners as a form of design
complexity, including the multiple mediating factors that impact ethical awareness
and decision-making. In this paper, we use a practice-led approach to describe ethical
complexity, presenting three varied cases of UX practitioners based onin situ observations
and interviews. In each case, we describe salient factors relating to ethical mediation,
including organizational practices, self-driven ethical principles, and unique characteristics
of specific projects the practitioner is engaged in. Using the concept of mediation
from activity theory, we provide a rich account of practitioners' ethical decision
making. We propose future work on ethical awareness and design education based on
the concept of ethical mediation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300409,
author = {Law, Po-Ming and Das, Subhajit and Basole, Rahul C.},
title = {Comparing Apples and Oranges: Taxonomy and Design of Pairwise Comparisons within Tabular Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300409},
abstract = {Asking pairwise comparison questions is common. Yet, we often find ourselves comparing
apples and oranges --- the two entities of interest are not readily comparable. To
understand how technologies can extend our capabilities to conduct pairwise comparisons
during data analysis, we analyzed pairwise comparison questions collected from crowd
workers and propose a taxonomy of pairwise comparisons. We demonstrate how the taxonomy
can be adopted by incorporating pairwise comparison capabilities into Duo, a spreadsheet
application that supports comparing two groups of records in a data table. Duo decomposes
a pairwise comparison question into rules and showcases sloppy rules, a query technique
for specifying pairwise comparisons. We conducted a user study comparing sloppy rules
and natural language. The findings suggest that for easier pairwise comparison tasks,
the two techniques are comparable in efficiency and preference and that for more difficult
pairwise comparison tasks, sloppy rules allow faster specification and are more preferable.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300410,
author = {Ahmed, Syed Ishtiaque and Haque, Md. Romael and Haider, Irtaza and Chen, Jay and Dell, Nicola},
title = {"Everyone Has Some Personal Stuff": Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300410},
abstract = {People in South Asia frequently share a single device among multiple individuals,
resulting in digital privacy challenges. This paper explores a design concept that
aims to mitigate some of these challenges through a 'tiered' privacy model. Using
this model, a person creates a 'shared' account that contains data they are willing
to share and that is assigned a password that will be shared. Simultaneously, they
create a separate 'secret' account that contains data they prefer to keep secret and
that uses a password they do not share with anyone. When a friend or family member
asks to check their device, the user can tell them the password for their shared account,
with their private data secure in the secret account that the other person is unaware
of. We explore the benefits and trade-offs of our design through a three-week deployment
with 21 participants in Bangladesh, presenting findings that show how our work aids
digital privacy while also exposing the challenges that remain.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300411,
author = {Coles-Kemp, Lizzie and Jensen, Rikke Bjerg},
title = {Accessing a New Land: Designing for a Social Conceptualisation of Access},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300411},
abstract = {This paper presents a study of mobile phone use by people settling in a new land to
access state provided digital services. It shows that digital literacy and access
to technology are not the only resources and capabilities needed to successfully access
digital services and do not guarantee a straightforward resettlement process. Using
creative engagement methods, the research involved 132 "newcomers" seeking to settle
in Sweden. Ribot and Peluso's theory of access (2003) was employed to examine the
complex web of access experienced by our participants. We uncover that when communities
are dealing with high levels of precarity, their primary concerns are related to accessing
the benefits of a service, rather than controlling access. Broadening the HCI framework,
the paper concludes that a sociotechnical model of access needs to connect access
control and access benefit to facilitate the design of an effective digital service.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300412,
author = {Altmeyer, Maximilian and Dernbecher, Kathrin and Hnatovskiy, Vladislav and Schubhan, Marc and Lessel, Pascal and Kr\"{u}ger, Antonio},
title = {Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300412},
abstract = {While the use of ad blockers prevents negative impacts of advertising on user experience,
it poses a serious threat to the business model of commercial web services and freely
available content on the web. As an alternative, we investigate the user enjoyment
and the advertising effectiveness of playfully deactivating online ads. We created
eight game concepts, performed a pre-study assessing the users' perception of them
(N=50) and implemented three well-perceived ones. In a lab study (N=72), we found
that these game concepts are more enjoyable than deactivating ads without game elements.
Additionally, one game concept was even preferred over using an ad blocker. Notably,
playfully deactivating ads was shown to have a positive impact on users' brand and
product memory, enhancing the advertising effectiveness. Thus, our results indicate
that playfully deactivating ads is a promising way of bridging the gap between user
enjoyment and effective advertising.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300413,
author = {Schulz, Peter and Alexandrovsky, Dmitry and Putze, Felix and Malaka, Rainer and Sch\"{o}ning, Johannes},
title = {The Role of Physical Props in VR Climbing Environments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300413},
abstract = {Dealing with fear of falling is a challenge in sport climbing. Virtual reality (VR)
research suggests that using physical and reality-based interaction increases the
presence in VR. In this paper, we present a study that investigates the influence
of physical props on presence, stress and anxiety in a VR climbing environment involving
whole body movement. To help climbers overcoming fear of falling, we compared three
different conditions: Climbing in reality at 10 m height, physical climbing in VR
(with props attached to the climbing wall) and virtual climbing in VR using game controllers.
From subjective reports and biosignals, our results show that climbing with props
in VR increases the anxiety and sense of realism in VR for sport climbing. This suggests
that VR in combination with physical props are an effective simulation setup to induce
the sense of height.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300414,
author = {Albaugh, Lea and Hudson, Scott and Yao, Lining},
title = {Digital Fabrication of Soft Actuated Objects by Machine Knitting},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300414},
abstract = {With recent interest in shape-changing interfaces, material-driven design, wearable
technologies, and soft robotics, digital fabrication of soft actuatable material is
increasingly in demand. Much of this research focuses on elastomers or non-stretchy
air bladders. Computationally-controlled machine knitting offers an alternative fabrication
technology which can rapidly produce soft textile objects that have a very different
character: breathable, lightweight, and pleasant to the touch. These machines are
well established and optimized for the mass production of garments, but compared to
other digital fabrication techniques such as CNC machining or 3D printing, they have
received much less attention as general purpose fabrication devices. In this work,
we explore new ways to employ machine knitting for the creation of actuated soft objects.
We describe the basic operation of this type of machine, then show new techniques
for knitting tendon-based actuation into objects. We explore a series of design strategies
for integrating tendons with shaping and anisotropic texture design. Finally, we investigate
different knit material properties, including considerations for motor control and
sensing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300415,
author = {Yang, Qian and Cranshaw, Justin and Amershi, Saleema and Iqbal, Shamsi T. and Teevan, Jaime},
title = {Sketching NLP: A Case Study of Exploring the Right Things To Design with Language Intelligence},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300415},
abstract = {This paper investigates how to sketch NLP-powered user experiences. Sketching is a
cornerstone of design innovation. When sketching, designers rapidly experiment with
a number of abstract ideas using simple, tangible instruments such as drawings and
paper prototypes. Sketching NLP-powered experiences, however, presents challenges,
i.e. How to visualize abstract language interaction? How to ideate a broad range of
technically feasible intelligent functionalities? As a first step towards understanding
these challenges, we present a first-person account of our sketching process when
designing intelligent writing assistance. We detail the challenges we encountered
and emergent solutions, such as a new format of wireframe for sketching language interactions
and a new wizard-of-oz-based NLP rapid prototyping method. Drawing on these findings,
we discuss the importance of abstraction in sketching and other implications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300416,
author = {Doherty, Kevin and Marcano-Belisario, Jos\'{e} and Cohn, Martin and Mastellos, Nikolaos and Morrison, Cecily and Car, Josip and Doherty, Gavin},
title = {Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300416},
abstract = {Perinatal depression (PND) affects up to 15% of women within the United Kingdom and
has a lasting impact on a woman's quality of life, birth outcomes and her child's
development. Suicide is the leading cause of maternal mortality. However, it is estimated
that at least 50% of PND cases go undiagnosed. This paper presents the results of
the first feasibility study to examine the potential of mobile devices to engage women
in antenatal mental health screening. Using a mobile application, 254 women attending
14 National Health Service midwifery clinics provided 2,280 momentary and retrospective
reports of their wellbeing over a 9-month period. Women spoke positively of the experience,
installing and engaging with this technology regardless of age, education, wellbeing,
number of children, marital or employment status, or past diagnosis of depression.
39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were
not identified by screening in-clinic.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300417,
author = {Jung, Joshua D.A. and Iyer, Rahul N. and Vogel, Daniel},
title = {Automating the Intentional Encoding of Human-Designable Markers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300417},
abstract = {Recent work established that it is possible for human artists to encode information
into hand-drawn markers, but it is difficult to do when simultaneously maintaining
aesthetic quality. We present two methods for relieving the mental burden associated
with encoding, while allowing an artist to draw as freely as possible. A 'Helper Overlay'
guides the artist with real-time feedback indicating where visual features should
be added or removed, and an 'Autocomplete Tool' directly adds necessary features to
the drawing for the artist to touch up. Both methods are enabled by a two-part algorithm
that uses a tree-search for finding 'major' changes and a dynamic programming method
for finding the minimum number of 'minor' changes. A 24-person study demonstrates
that a majority of participants prefer both tools over previous methods of manual
encoding, with the Helper Overlay being the more popular of the two.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300418,
author = {Correll, Michael},
title = {Ethical Dimensions of Visualization Research},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300418},
abstract = {Visualizations have a potentially enormous influence on how data are used to make
decisions across all areas of human endeavor. However, it is not clear how this power
connects to ethical duties: what obligations do we have when it comes to visualizations
and visual analytics systems, beyond our duties as scientists and engineers? Drawing
on historical and contemporary examples, I address the moral components of the design
and use of visualizations, identify some ongoing areas of visualization research with
ethical dilemmas, and propose a set of additional moral obligations that we have as
designers, builders, and researchers of visualizations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300419,
author = {Colley, Ashley and Mayer, Sven and Henze, Niels},
title = {Investigating the Effect of Orientation and Visual Style on Touchscreen Slider Performance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300419},
abstract = {Sliders are one of the most fundamental components used in touchscreen user interfaces
(UIs). When entering data using a slider, errors occur due e.g. to visual perception,
resulting in inputs not matching what is intended by the user. However, it is unclear
if the errors occur uniformly across the full range of the slider or if there are
systematic offsets. We conducted a study to assess the errors occurring when entering
values with horizontal and vertical sliders as well as two common visual styles. Our
results reveal significant effects of slider orientation and style on the precision
of the entered values. Furthermore, we identify systematic offsets that depend on
the visual style and the target value. As the errors are partially systematic, they
can be compensated to improve users' precision. Our findings provide UI designers
with data to optimize user experiences in the wide variety of application areas where
slider based touchscreen input is used.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300420,
author = {Fortin, Pascal E. and Sulmont, Elisabeth and Cooperstock, Jeremy},
title = {Detecting Perception of Smartphone Notifications Using Skin Conductance Responses},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300420},
abstract = {Today's smartphone notification systems are incapable of determining whether a notification
has been successfully perceived without explicit interaction from the user. If the
system incorrectly assumes that a notification has not been perceived, it may repeat
it redundantly, disrupting the user and others (e.g., phone ringing). Or, if it incorrectly
assumes that a notification was perceived, and therefore fails to repeat it, the notification
will be missed altogether (e.g., text message). Results from a laboratory study confirm,
for the first time, that both vibrotactile and auditory smartphone notifications induce
skin conductance responses (SCR), that the induced responses differ from that of arbitrary
stimuli, and that they could be employed to predict perception of smartphone notifications
after their presentation using wearable sensors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300421,
author = {Bartlett, Rachel and Khoo, Yi Xuan and Hourcade, Juan Pablo and Rector, Kyle K.},
title = {Exploring the Opportunities for Technologies to Enhance Quality of Life with People Who Have Experienced Vision Loss},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300421},
abstract = {Research predicts that 196 million people will be diagnosed with Age-Related Macular
Degeneration (AMD) by 2020. People who experience AMD and other vision loss face barriers
that affect their Quality of Life (QoL). People experience only modest improvement
from technologies (e.g., screen readers, CCTV), tools (e.g., magnifying glasses, tactile
buttons), and human help (e.g., friends, blindness organizations). Further, there
are issues to accessing these resources based on one's place of residence. To explore
these challenges and determine design implications to support people who have experienced
vision loss (PVL), we conducted a qualitative semi-structured interview study exploring
QoL with 10 PVL. We uncovered themes of supporting creative work, recognizing the
impact of one's living in a non-urban setting on QoL, and increasing efficiency at
accomplishing tasks. We motivate the inclusion of PVL in the design process because
they learned skills while sighted and are now low vision or blind.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8}
}

@inbook{10.1145/3290605.3300422,
author = {Mylavarapu, Pranathi and Yalcin, Adil and Gregg, Xan and Elmqvist, Niklas},
title = {Ranked-List Visualization: A Graphical Perception Study},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300422},
abstract = {Visualization of ranked lists is a common occurrence, but many in-the-wild solutions
fly in the face of vision science and visualization wisdom. For example, treemaps
and bubble charts are commonly used for this purpose, despite the fact that the data
is not hierarchical and that length is easier to perceive than area. Furthermore,
several new visual representations have recently been suggested in this area, including
wrapped bars, packed bars, piled bars, and Zvinca plots. To quantify the differences
and trade-offs for these ranked-list visualizations, we here report on a crowdsourced
graphical perception study involving six such visual representations, including the
ubiquitous scrolled barchart, in three tasks: ranking (assessing a single item), comparison
(two items), and average (assessing global distribution). Results show that wrapped
bars may be the best choice for visualizing ranked lists, and that treemaps are surprisingly
accurate despite the use of area rather than length to represent value.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300423,
author = {Ritchie, Jacob and Wigdor, Daniel and Chevalier, Fanny},
title = {A Lie Reveals the Truth: Quasimodes for Task-Aligned Data Presentation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300423},
abstract = {Designers are often discouraged from creating data visualizations that omit or distort
information, because they can easily be misleading. However, the same representations
that could be used to deceive can provide benefits when chosen to appropriately align
with user tasks. We present an interaction technique, Perceptual Glimpses, which allows
for the transparent presentation of so-called 'deceptive' views of information that
are made temporary using quasimodes. When presented using Perceptual Glimpses, message-level
exaggeration caused by a truncated axis on a bar chart was reduced under some conditions,
but users require guidance to avoid errors, and view presentation order may affect
trust. When Perceptual Glimpses was extended to display a range of views that might
otherwise be deceptive or difficult to understand if shown out of context, users were
able to understand and leverage these transformations to perform a range of low-level
tasks. Design recommendations and examples suggest extensions of the technique.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300424,
author = {Zou, Yixin and Danino, Shawn and Sun, Kaiwen and Schaub, Florian},
title = {You `Might' Be Affected: An Empirical Analysis of Readability and Usability Issues in Data Breach Notifications},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300424},
abstract = {Data breaches place affected individuals at significant risk of identity theft. Yet,
prior studies have shown that many consumers do not take protective actions after
receiving a data breach notification from a company. We analyzed 161 data breach notifications
sent to consumers with respect to their readability, structure, risk communication,
and presentation of potential actions. We find that notifications are long and require
advanced reading skills. Many companies downplay or obscure the likelihood of the
receiver being affected by the breach and associated risks. Moreover, potential actions
and offered compensations are frequently described in lengthy paragraphs instead of
clearly listed. Little information is provided regarding an action's urgency and effectiveness;
little guidance is provided on which actions to prioritize. Based on our findings,
we provide recommendations for designing more usable and informative data breach notifications
that could help consumers better mitigate the consequences of being affected by a
data breach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300425,
author = {Brewer, Robin N. and Kameswaran, Vaishnav},
title = {Understanding Trust, Transportation, and Accessibility through Ridesharing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300425},
abstract = {Relatively few studies of accessibility and transportation for people with vision
impairments have investigated forms of transportation besides public transportation
and walking. To develop a more nuanced understanding of this context, we turn to ridesharing,
an increasingly used mode of transportation. We interviewed 16 visually-impaired individuals
about their active use of ridesharing services like Uber and Lyft. Our findings show
that, while people with vision impairments value independence, ridesharing involves
building trust across a complex network of stakeholders and technologies. This data
is used to start a discussion on how other systems can facilitate trust for people
with vision impairments by considering the role of conversation, affordances of system
incentives, and increased agency.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300426,
author = {Surale, Hemant Bhaskar and Matulic, Fabrice and Vogel, Daniel},
title = {Experimental Analysis of Barehand Mid-Air Mode-Switching Techniques in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300426},
abstract = {We present an empirical comparison of eleven bare hand, mid-air mode-switching techniques
suitable for virtual reality in two experiments. The first evaluates seven techniques
spanning dominant and non-dominant hand actions. Techniques represent common classes
of actions selected by a methodical examination of 56 examples of prior art. The standard
"subtraction method" protocol is adapted for 3D interfaces, with two baseline selection
methods, bare hand pinch and device controller button. A second experiment with four
techniques explores more subtle dominant-hand techniques and the effect of using a
dominant hand device for selection. Results provide guidance to practitioners when
choosing bare hand, mid-air mode-switching techniques, and for researchers when designing
new mode-switching methods in VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300427,
author = {Shi, Lei and Lawson, Holly and Zhang, Zhuohao and Azenkot, Shiri},
title = {Designing Interactive 3D Printed Models with Teachers of the Visually Impaired},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300427},
abstract = {Students with visual impairments struggle to learn various concepts in the academic
curriculum because diagrams, images, and other visual are not accessible to them.
To address this, researchers have design interactive 3D printed models (I3Ms) that
provide audio descriptions when a user touches components of a model. In prior work,
I3Ms were designed on an ad hoc basis, and it is currently unknown what general guidelines
produce effective I3M designs. To address this gap, we conducted two studies with
Teachers of the Visually Impaired (TVIs). First, we led two design workshops with
35 TVIs, who modified sample models and added interactive elements to them. Second,
we worked with three TVIs to design three I3Ms in an iterative instructional design
process. At the end of this process, the TVIs used the I3Ms we designed to teach their
students. We conclude that I3Ms should (1) have effective tactile features (e.g.,
distinctive patterns between components), (2) contain both auditory and visual content
(e.g., explanatory animations), and (3) consider pedagogical methods (e.g., overview
before details).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300428,
author = {Yao, Yaxing and Basdeo, Justin Reed and Kaushik, Smirity and Wang, Yang},
title = {Defending My Castle: A Co-Design Study of Privacy Mechanisms for Smart Homes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300428},
abstract = {Home is a person's castle, a private and protected space. Internet-connected devices
such as locks, cameras, and speakers might make a home "smarter" but also raise privacy
issues because these devices may constantly and inconspicuously collect, infer or
even share information about people in the home. To explore user-centered privacy
designs for smart homes, we conducted a co-design study in which we worked closely
with diverse groups of participants in creating new designs. This study helps fill
the gap in the literature between studying users' privacy concerns and designing privacy
tools only by experts. Our participants' privacy designs often relied on simple strategies,
such as data localization, disconnection from the Internet, and a private mode. From
these designs, we identified six key design factors: data transparency and control,
security, safety, usability and user experience, system intelligence, and system modality.
We discuss how these factors can guide design for smart home privacy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300429,
author = {Cheng, Justin and Burke, Moira and Davis, Elena Goetz},
title = {Understanding Perceptions of Problematic Facebook Use: When People Experience Negative Life Impact and a Lack of Control},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300429},
abstract = {While many people use social network sites to connect with friends and family, some
feel that their use is problematic, seriously affecting their sleep, work, or life.
Pairing a survey of 20,000 Facebook users measuring perceptions of problematic use
with behavioral and demographic data, we examined Facebook activities associated with
problematic use as well as the kinds of people most likely to experience it. People
who feel their use is problematic are more likely to be younger, male, and going through
a major life event such as a breakup. They spend more time on the platform, particularly
at night, and spend proportionally more time looking at profiles and less time browsing
their News Feeds. They also message their friends more frequently. While they are
more likely to respond to notifications, they are also more likely to deactivate their
accounts, perhaps in an effort to better manage their time. Further, they are more
likely to have seen content about social media or phone addiction. Notably, people
reporting problematic use rate the site as more valuable to them, highlighting the
complex relationship between technology use and well-being. A better understanding
of problematic Facebook use can inform the design of context-appropriate and supportive
tools to help people become more in control.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300430,
author = {Lu, Yiqin and Yu, Chun and Fan, Shuyi and Bi, Xiaojun and Shi, Yuanchun},
title = {Typing on Split Keyboards with Peripheral Vision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300430},
abstract = {Split keyboards are widely used on hand-held touchscreen devices (e.g., tablets).
However, typing on a split keyboard often requires eye movement and attention switching
between two halves of the keyboard, which slows users down and increases fatigue.
We explore peripheral typing, a superior typing mode in which a user focuses her visual
attention on the output text and keeps the split keyboard in peripheral vision. Our
investigation showed that peripheral typing reduced attention switching, enhanced
user experience and increased overall performance (27 WPM, 28% faster) over the typical
eyes-on typing mode. This typing mode can be well supported by accounting the typing
behavior in statistical decoding. Based on our study results, we have designed GlanceType,
a text entry system that supported both peripheral and eyes-on typing modes for real
typing scenario. Our evaluation showed that peripheral typing not only well co-existed
with the existing eyes-on typing, but also substantially improved the text entry performance.
Overall, peripheral typing is a promising typing mode and supporting it would significantly
improve the text entry performance on a split keyboard.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300431,
author = {Teo, Theophilus and Lawrence, Louise and Lee, Gun A. and Billinghurst, Mark and Adcock, Matt},
title = {Mixed Reality Remote Collaboration Combining 360 Video and 3D Reconstruction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300431},
abstract = {Remote Collaboration using Virtual Reality (VR) and Augmented Reality (AR) has recently
become a popular way for people from different places to work together. Local workers
can collaborate with remote helpers by sharing 360-degree live video or 3D virtual
reconstruction of their surroundings. However, each of these techniques has benefits
and drawbacks. In this paper we explore mixing 360 video and 3D reconstruction together
for remote collaboration, by preserving benefits of both systems while reducing drawbacks
of each. We developed a hybrid prototype and conducted user study to compare benefits
and problems of using 360 or 3D alone to clarify the needs for mixing the two, and
also to evaluate the prototype system. We found participants performed significantly
better on collaborative search tasks in 360 and felt higher social presence, yet 3D
also showed potential to complement. Participant feedback collected after trying our
hybrid system provided directions for improvement.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300432,
author = {Kale, Alex and Kay, Matthew and Hullman, Jessica},
title = {Decision-Making Under Uncertainty in Research Synthesis: Designing for the Garden of Forking Paths},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300432},
abstract = {To make evidence-based recommendations to decision-makers, researchers conducting
systematic reviews and meta-analyses must navigate a garden of forking paths: a series
of analytical decision-points, each of which has the potential to influence findings.
To identify challenges and opportunities related to designing systems to help researchers
manage uncertainty around which of multiple analyses is best, we interviewed 11 professional
researchers who conduct research synthesis to inform decision-making within three
organizations. We conducted a qualitative analysis identifying 480 analytical decisions
made by researchers throughout the scientific process. We present descriptions of
current practices in applied research synthesis and corresponding design challenges:
making it more feasible for researchers to try and compare analyses, shifting researchers'
attention from rationales for decisions to impacts on results, and supporting communication
techniques that acknowledge decision-makers' aversions to uncertainty. We identify
opportunities to design systems which help researchers explore, reason about, and
communicate uncertainty in decision-making about possible analyses in research synthesis.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300433,
author = {Sindhwani, Shyamli and Lutteroth, Christof and Weber, Gerald},
title = {ReType: Quick Text Editing with Keyboard and Gaze},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300433},
abstract = {When a user needs to reposition the cursor during text editing, this is often done
using the mouse. For experienced typists especially, the switch between keyboard and
mouse can slow down the keyboard editing workflow considerably. To address this we
propose ReType, a new gaze-assisted positioning technique combining keyboard with
gaze input based on a new 'patching' metaphor. ReType allows users to perform some
common editing operations while keeping their hands on the keyboard. We present the
result of two studies. A free-use study indicated that ReType enhances the user experience
of text editing. ReType was liked by many participants, regardless of their typing
skills. A comparative user study showed that ReType is able to match or even beat
the speed of mouse-based interaction for small text edits. We conclude that the gaze-augmented
user interface can make common interactions more fluent, especially for professional
keyboard users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300434,
author = {Rivera, Michael L. and Hudson, Scott E.},
title = {Desktop Electrospinning: A Single Extruder 3D Printer for Producing Rigid Plastic and Electrospun Textiles},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300434},
abstract = {We present a new type of 3D printer that combines rigid plastic printing with melt
electrospinning? a technique that uses electrostatic forces to create thin fibers
from a molten polymer. Our printer enables custom-shaped textile sheets (similar in
feel to wool felt) to be produced alongside rigid plastic using a single material
(i.e., PLA) in a single process. We contribute open-source firmware, hardware specifications,
and printing parameters to achieve melt electrospinning. Our approach offers new opportunities
for fabricating interactive objects and sensors that blend the flexibility, absorbency
and softness of produced electrospun textiles with the structure and rigidity of hard
plastic for actuation, sensing, and tactile experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300435,
author = {Ding, Xianghua and Jiang, Yanqi and Qin, Xiankang and Chen, Yunan and Zhang, Wenqiang and Qi, Lizhe},
title = {Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300435},
abstract = {With the recent advancement in computer vision, Artificial Intelligence (AI), and
mobile technologies, it has become technically feasible for computerized Face Reading
Technologies (FRTs) to learn about one's health in everyday settings. However, how
to design FRT-based applications for everyday health practices remains unexplored.
This paper presents a design study with a technology probe called Faced, a mobile
health checkup application based on the facial diagnosis method from Traditional Chinese
Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage
modes and highlights a number of critical design issues in the use of FRTs for everyday
health, including adaptability, practicality, sensitivity, and trustworthiness. We
end by discussing design implications to address the unique challenges of fully integrating
FRTs into everyday health practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300436,
author = {Li, Jingyi and Kim, Son and Miele, Joshua A. and Agrawala, Maneesh and Follmer, Sean},
title = {Editing Spatial Layouts through Tactile Templates for People with Visual Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300436},
abstract = {Spatial layout is a key component in graphic design. While people who are blind or
visually impaired (BVI) can use screen readers or magnifiers to access digital content,
these tools fail to fully communicate the content's graphic design information. Through
semi-structured interviews and contextual inquiries, we identify the lack of this
information and feedback as major challenges in understanding and editing layouts.
Guided by these insights and a co-design process with a blind hobbyist web developer,
we developed an interactive, multimodal authoring tool that lets blind people understand
spatial relationships between elements and modify layout templates. Our tool automatically
generates tactile print-outs of a web page's layout, which users overlay on top of
a tablet that runs our self-voicing digital design tool. We conclude with design considerations
grounded in user feedback for improving the accessibility of spatially encoded information
and developing tools for BVI authors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300437,
author = {Barrera Machuca, Mayra Donaji and Stuerzlinger, Wolfgang},
title = {The Effect of Stereo Display Deficiencies on Virtual Hand Pointing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300437},
abstract = {The limitations of stereo display systems affect depth perception, e.g., due to the
vergence-accommodation conflict or diplopia. We performed three studies to understand
how stereo display deficiencies impact 3D pointing for targets in front of a screen
and close to the user, i.e., in peripersonal space. Our first two experiments compare
movements with and without a change in visual depth for virtual respectively physical
targets. Results indicate that selecting targets along the depth axis is slower and
has less throughput for virtual targets, while physical pointing demonstrates the
opposite result. We then propose a new 3D extension for Fitts' law that models the
effect of stereo display deficiencies. Next, our third experiment verifies the model
and measures more broadly how the change in visual depth between targets affects pointing
performance in peripersonal space and confirms significant effects on time and throughput.
Finally, we discuss implications for 3D user interface design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300438,
author = {Long, Michael and Gutwin, Carl},
title = {Effects of Local Latency on Game Pointing Devices and Game Pointing Tasks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300438},
abstract = {Studies have shown certain game tasks such as targeting to be negatively and significantly
affected by latencies as low as 41ms. Therefore it is important to understand the
relationship between local latency - delays between an input action and resulting
change in the display - and common gaming tasks such as targeting and tracking. In
addition, games now use a variety of input devices, including touchscreens, mice,
tablets and controllers. These devices provide very different combinations of direct/indirect
input, absolute/relative movement, and position/rate control, and are likely to be
affected by latency in different ways. We performed a study evaluating and comparing
the effects of latency across four devices (touchscreen, mouse, controller and drawing
tablet) on targeting and interception tasks. We analyze both throughput and path characteristics,
identify differences between devices, and provide design considerations for game designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300439,
author = {Grudin, Jonathan and Jacques, Richard},
title = {Chatbots, Humbots, and the Quest for Artificial General Intelligence},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300439},
abstract = {What began as a quest for artificial general intelligence branched into several pursuits,
including intelligent assistants developed by tech companies and task-oriented chatbots
that deliver more information or services in specific domains. Progress quickened
with the spread of low-latency networking, then accelerated dramatically a few years
ago. In 2016, task-focused chatbots became a centerpiece of machine intelligence,
promising interfaces that are more engaging than robotic answering systems and that
can accommodate our increasingly phone-based information needs. Hundreds of thousands
were built. Creating successful non-trivial chatbots proved more difficult than anticipated.
Some developers now design for human-chatbot (humbot) teams, with people handling
difficult queries. This paper describes the conversational agent space, difficulties
in meeting user expectations, potential new design approaches, uses of human-bot hybrids,
and implications for the ultimate goal of creating software with general intelligence.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300440,
author = {Di Campli San Vito, Patrizia and Shakeri, G\"{o}zel and Brewster, Stephen and Pollick, Frank and Brown, Edward and Skrypchuk, Lee and Mouzakitis, Alexandros},
title = {Haptic Navigation Cues on the Steering Wheel},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300440},
abstract = {Haptic feedback is used in cars to reduce visual inattention. While tactile feedback
like vibration can be influenced by the car's movement, thermal and cutaneous push
feedback should be independent of such interference. This paper presents two driving
simulator studies investigating novel tactile feedback on the steering wheel for navigation.
First, devices on one side of the steering wheel were warmed, indicating the turning
direction, while those on the other side were cooled. This thermal feedback was compared
to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m
before the turn and to 91.7% correct turns. Speech had perfect recognition for both.
In the second experiment, only the destination side was indicated thermally, and this
design was compared to cutaneous push feedback. The simplified thermal feedback design
did not increase recognition, but cutaneous push feedback had high recognition rates
(100% for 200 m warnings, 98% for turns).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300441,
author = {Zenner, Andr\'{e} and Kr\"{u}ger, Antonio},
title = {Drag:On: A Virtual Reality Controller Providing Haptic Feedback Based on Drag and Weight Shift},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300441},
abstract = {Standard controllers for virtual reality (VR) lack sophisticated means to convey a
realistic, kinesthetic impression of size, resistance or inertia. We present the concept
and implementation of Drag:on, an ungrounded shape-changing VR controller that provides
dynamic passive haptic feedback based on drag, i.e. air resistance, and weight shift.
Drag:on leverages the airflow occurring at the controller during interaction. By dynamically
adjusting its surface area, the controller changes the drag and rotational inertia
felt by the user. In a user study, we found that Drag:on can provide distinguishable
levels of haptic feedback. Our prototype increases the haptic realism in VR compared
to standard controllers and when rotated or swung improves the perception of virtual
resistance. By this, Drag:on provides haptic feedback suitable for rendering different
virtual mechanical resistances, virtual gas streams, and virtual objects differing
in scale, material and fill state.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300442,
author = {Corsten, Christian and Lahaye, Marcel and Borchers, Jan and Voelker, Simon},
title = {ForceRay: Extending Thumb Reach via Force Input Stabilizes Device Grip for Mobile Touch Input},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300442},
abstract = {Smartphones are used predominantly one-handed, using the thumb for input. Many smartphones,
however, have grown beyond 5". Users cannot tap everywhere on these screens without
destabilizing their grip. ForceRay (FR) lets users aim at an out-of-reach target by
applying a force touch at a comfortable thumb location, casting a virtual ray towards
the target. Varying pressure moves a cursor along the ray. When reaching the target,
quickly lifting the thumb selects it. In a first study, FR was 195 ms slower and had
a 3% higher selection error than the best existing technique, BezelCursor (BC), but
FR caused significantly less device movement than all other techniques, letting users
maintain a steady grip and removing their concerns about device drops. A second study
showed that an hour of training speeds up both BC and FR, and that both are equally
fast for targets at the screen border.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300443,
author = {Wu, Ziming and Kim, Taewook and Li, Quan and Ma, Xiaojuan},
title = {Understanding and Modeling User-Perceived Brand Personality from Mobile Application UIs},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300443},
abstract = {Designers strive to make their mobile apps stand out in a competitive market by creating
a distinctive brand personality. However, it is unclear whether users can form a consistent
impression of brand personality by looking at a few user interface (UI) screenshots
in the app store, and if this process can be modeled computationally. To bridge this
gap, we first collect crowd assessment on brand personalities depicted by the UIs
of 318 applications, and statistically confirm that users can reach substantial agreement.
To further model how users process mobile UI visually, we compute UI descriptors including
Color, Organization, and Texture at both element and page levels. We feed these descriptors
to a computational model, achieving a high accuracy of predicting perceived brand
personality (MSE = 0.035 and R^2 = 0.78). This work could benefit designers by highlighting
contributing visual factors to brand personality creation and providing quick, low-cost
design feedback.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300444,
author = {Komkaite, Aida and Lavrinovica, Liga and Vraka, Maria and Skov, Mikael B.},
title = {Underneath the Skin: An Analysis of YouTube Videos to Understand Insertable Device Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300444},
abstract = {During the last decade, people have started to experiment with insertable technology
like RFID or NFC chips and use them for e.g. identification. However, little is known
about how people in fact interact with and adapt insertables. We conducted a video
analysis of 122 YouTube videos to gain insight into the interaction with the insertables.
Second, we implemented an online survey to complement our data from the video analysis.
Our findings show that there are many opportunities for interaction with insertables
both for task-oriented and creative purposes. However, there are also multiple challenges
and obstacles as well as side effects and health concerns. Our findings conclude that
the current infrastructure is not ready to support the use of insertables yet, and
we discuss implications of this.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300445,
author = {Vatavu, Radu-Daniel and Ungurean, Ovidiu-Ciprian},
title = {Stroke-Gesture Input for People with Motor Impairments: Empirical Results &amp; Research Roadmap},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300445},
abstract = {We examine the articulation characteristics of stroke-gestures produced by people
with upper body motor impairments on touchscreens as well as the accuracy rates of
popular classification techniques, such as the $-family, to recognize those gestures.
Our results on a dataset of 9,681 gestures collected from 70 participants reveal that
stroke-gestures produced by people with motor impairments are recognized less accurately
than the same gesture types produced by people without impairments, yet still accurately
enough (93.0%) for practical purposes; are similar in terms of geometrical criteria
to the gestures produced by people without impairments; but take considerably more
time to produce (3.4s vs. 1.7s) and exhibit lower consistency (-49.7%). We outline
a research roadmap for accessible gesture input on touchscreens for users with upper
body motor impairments, and we make our large gesture dataset publicly available in
the community.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300446,
author = {Crabb, Michael and Heron, Michael and Jones, Rhianne and Armstrong, Mike and Reid, Hayley and Wilson, Amy},
title = {Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300446},
abstract = {When creating digital artefacts, it is important to ensure that the product being
made is accessible to as much of the population as is possible. Many guidelines and
supporting tools exist to assist reaching this goal. However, little is known about
developers' understanding of accessible practice and the methods that are used to
implement this. We present findings from an accessibility design workshop that was
carried out with a mixture of 197 developers and digital technology students. We discuss
perceptions of accessibility, techniques that are used when designing accessible products,
and what areas of accessibility development participants believed were important.
We show that there are gaps in the knowledge needed to develop accessible products
despite the effort to promote accessible design. Our participants are themselves aware
of where these gaps are and have suggested a number of areas where tools, techniques
and guidance would improve their practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300447,
author = {Eiselmayer, Alexander and Wacharamanotham, Chat and Beaudouin-Lafon, Michel and Mackay, Wendy E.},
title = {<i>Touchstone2</i>: An Interactive Environment for Exploring Trade-Offs in HCI Experiment Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300447},
abstract = {Touchstone2 offers a direct-manipulation interface for generating and examining trade-offs
in experiment designs. Based on interviews with experienced researchers, we developed
an interactive environment for manipulating experiment design parameters, revealing
patterns in trial tables, and estimating and comparing statistical power. We also
developed TSL, a declarative language that precisely represents experiment designs.
In two studies, experienced HCI researchers successfully used Touchstone2 to evaluate
design trade-offs and calculate how many participants are required for particular
effect sizes. We discuss Touchstone2's benefits and limitations, as well as directions
for future research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}


@inproceedings{10.1145/3251786,
author = {M\"{u}ller, J\"{o}rg},
title = {Session Details: Non-Rigid Interaction Surfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251786},
doi = {10.1145/3251786},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702611,
author = {Yao, Lining and Ou, Jifei and Cheng, Chin-Yi and Steiner, Helene and Wang, Wen and Wang, Guanyun and Ishii, Hiroshi},
title = {BioLogic: Natto Cells as Nanoactuators for Shape Changing Interfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702611},
doi = {10.1145/2702123.2702611},
abstract = {Nature has engineered its own actuators, as well as the efficient material composition,
geometry and structure to utilize its actuators and achieve functional transformation.
Based on the natural phenomenon of cells' hygromorphic transformation, we introduce
the living Bacillus Subtilis natto cell as a humidity sensitive nanoactuator. In this
paper, we unfold the process of exploring and comparing cell types that are proper
for HCI use, the development of the composite biofilm, the development of the responsive
structures, the control setup for actuating biofilms, and a simulation and fabrication
platform. Finally, we provide a variety of application designs, with and without computer
control to demonstrate the potential of our bio actuators. Through this paper, we
intend to enable the use of natto cells and our platform technologies for HCI researchers,
designers and bio-hackers. More generally, we try to encourage the research and use
of biological responsive materials and interdisciplinary research in HCI.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {hygromorph, smart material, biological material, programmable material, shape changing interfaces, biology, bio-printing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702363,
author = {Sahoo, Deepak Ranjan and Martinez Plasencia, Diego and Subramanian, Sriram},
title = {Control of Non-Solid Diffusers by Electrostatic Charging},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702363},
doi = {10.1145/2702123.2702363},
abstract = {The form factors of displays using fog or water surface are limited by our ability
to control the non-solid substances used as the diffuser. We propose a charging technique
for polar aerosols (e.g., mist or fog) that allows control of the shape and trajectory
of such non-solid diffusers using electric fields. We report experiments that allowed
us to design a charging mechanism that produces charged fog aerosols with homogeneous
electrical mobility. We illustrate our idea by demonstrating how electric fields can
be used to control the shape of a fog display and the trajectory of a bubble display.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {11–14},
numpages = {4},
keywords = {control, aerosol, non-solid diffusers, electrostatic field, polar molecules, shape changing, diffusion charging},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702290,
author = {Abdelrahman, Yomna and Sahami Shirazi, Alireza and Henze, Niels and Schmidt, Albrecht},
title = {Investigation of Material Properties for Thermal Imaging-Based Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702290},
doi = {10.1145/2702123.2702290},
abstract = {Recent work demonstrated the exciting opportunities that thermal imaging offers for
the development of interactive systems. It was shown that a thermal camera can sense
when a user touches a surface, performs gestures in the camera's direct field of view
and, in addition, performs gestures outside the camera's direct field of view through
thermal reflection. In this paper, we investigate the material properties that should
be considered for detecting interaction using thermal imaging considering both in-
and outdoor settings. We conducted a study to analyze the recognition performance
for different gestures and different surfaces. Using the results, we derive guidelines
on material properties of surfaces for detecting on-surface as well as mid-air interaction
using a thermal camera. We discuss the constrains that should be taken into account
using thermal imaging as the sensing technology. Finally, we present a material space
based on our findings. The space depicts surfaces and the required properties that
enable the different interaction techniques.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {15–18},
numpages = {4},
keywords = {interaction, thermal imaging, conductivity, roughness},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702599,
author = {Hardy, John and Weichel, Christian and Taher, Faisal and Vidler, John and Alexander, Jason},
title = {ShapeClip: Towards Rapid Prototyping with Shape-Changing Displays for Designers},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702599},
doi = {10.1145/2702123.2702599},
abstract = {This paper presents ShapeClip: a modular tool capable of transforming any computer
screen into a z-actuating shape-changing display. This enables designers to produce
dynamic physical forms by "clipping" actuators onto screens. ShapeClip displays are
portable, scalable, fault-tolerant, and support runtime re-arrangement. Users are
not required to have knowledge of electronics or programming, and can develop motion
designs with presentation software, image editors, or web-technologies. To evaluate
ShapeClip we carried out a full-day workshop with expert designers. Participants were
asked to generate shape-changing designs and then construct them using ShapeClip.
ShapeClip enabled participants to rapidly and successfully transform their ideas into
functional systems.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {19–28},
numpages = {10},
keywords = {shapeclip, shape-changing displays, reconfigurable, shape displays, actuated displays, tool},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702516,
author = {Ogata, Masa and Fukumoto, Masaaki},
title = {FluxPaper: Reinventing Paper with Dynamic Actuation Powered by Magnetic Flux},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702516},
doi = {10.1145/2702123.2702516},
abstract = {FluxPaper is a new paper-based medium that enables physical movement and dynamic interaction
between a high-power magnetized paper and a programmable magnetic field. FluxPaper
has a very thin patterned magnetic layer (0.1 mm) pasted behind the paper. A thin
but strong neodymium-based magnet realizes fast, powerful, and precise physical actions
while retaining the original characteristics of the paper that is widely used in our
daily lives. Owing to an effective magnetic pattern and a computer-controlled magnetic
field, FluxPaper can add new interaction modality to ordinary paper. We describe the
functions of magnetized paper; challenges through realization; and the interaction
scenarios in several applications, such as self-alignment, self-construction, floating
on the board, and quickly picking out a target card from a stack.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {29–38},
numpages = {10},
keywords = {magnetic flux, shape-changing, paper interaction, active paper},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251787,
author = {Oakley, Ian},
title = {Session Details: What Do I Hear? Communicating with Sound},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251787},
doi = {10.1145/3251787},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702373,
author = {Guerreiro, Jo\~{a}o and Rodrigues, Andr\'{e} and Montague, Kyle and Guerreiro, Tiago and Nicolau, Hugo and Gon\c{c}alves, Daniel},
title = {TabLETS Get Physical: Non-Visual Text Entry on Tablet Devices},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702373},
doi = {10.1145/2702123.2702373},
abstract = {Tablet devices can display full-size QWERTY keyboards similar to the physical ones.
Yet, the lack of tactile feedback and the inability to rest the fingers on the home
keys result in a highly demanding and slow exploration task for blind users. We present
SpatialTouch, an input system that leverages previous experience with physical QWERTY
keyboards, by supporting two-handed interaction through multitouch exploration and
spatial, simultaneous audio feedback. We conducted a user study, with 30 novice touchscreen
participants entering text under one of two conditions: (1) SpatialTouch or (2) mainstream
accessibility method Explore by Touch. We show that SpatialTouch enables blind users
to leverage previous experience as they do a better use of home keys and perform more
efficient exploration paths. Results suggest that although SpatialTouch did not result
in faster input rates overall, it was indeed able to leverage previous QWERTY experience
in contrast to Explore by Touch.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {39–42},
numpages = {4},
keywords = {bi-manual interaction, touchscreen, non-visual interaction, blind, tablet, spatial audio, text-entry},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702387,
author = {Cartwright, Mark and Pardo, Bryan},
title = {VocalSketch: Vocally Imitating Audio Concepts},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702387},
doi = {10.1145/2702123.2702387},
abstract = {A natural way of communicating an audio concept is to imitate it with one's voice.
This creates an approximation of the imagined sound (e.g. a particular owl's hoot),
much like how a visual sketch approximates a visual concept (e.g a drawing of the
owl). If a machine could understand vocal imitations, users could communicate with
software in this natural way, enabling new interactions (e.g. programming a music
synthesizer by imitating the desired sound with one's voice). In this work, we collect
thousands of crowd-sourced vocal imitations of a large set of diverse sounds, along
with data on the crowd's ability to correctly label these vocal imitations. The resulting
data set will help the research community understand which audio concepts can be effectively
communicated with this approach. We have released the data set so the community can
study the related issues and build systems that leverage vocal imitation as an interaction
modality.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {43–46},
numpages = {4},
keywords = {data set, vocal imitation, audio software, user interaction},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702499,
author = {Tubb, Robert and Dixon, Simon},
title = {An Evaluation of Multidimensional Controllers for Sound Design Tasks},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702499},
doi = {10.1145/2702123.2702499},
abstract = {This paper presents an investigation into musicians' ability to control sound synthesiser
parameters using various inter- faces. The principal aim was to compare separate,
1D parameter controls (touchscreen sliders) to multidimensional con- trollers (an
XY touchpad for 2D, the Leap Motion for 3D). Subjects had to match a target sound
as quickly and accurately as possible. Results show that after about two hours of
practice, the XY pad is 9% faster than two sliders for no accuracy loss, and the Leap
is 17% faster than 3 sliders with 9% accuracy loss. The multidimensional controllers
improved most with practice. A new perspective on Fitts' index of difficulty is presented:
"Index of Search Space Reduction" (ISSR). ISSR and retrospective accuracy thresholds
on the search trajectory are used to obtain straight line plots and throughput values.
These plots reveal that the Leap's speed improvement was mainly due to reaction time,
but the XY pad traversed the space faster.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {47–56},
numpages = {10},
keywords = {leap motion, fitts' law, synthesiser, parameter exploration, audio, 3d interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702358,
author = {Suzuki, Ryohei and Sakamoto, Daisuke and Igarashi, Takeo},
title = {AnnoTone: Record-Time Audio Watermarking for Context-Aware Video Editing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702358},
doi = {10.1145/2702123.2702358},
abstract = {We present a video annotation system called ``AnnoTone', which can embed various contextual
information describing a scene, such as geographical location. Then the system allows
the user to edit the video using this contextual information, enabling one to, for
example, overlay with map or graphical annotations. AnnoTone converts annotation data
into high-frequency audio signals (which are inaudible to the human ear), and then
transmits them from a smartphone speaker placed near a video camera. This scheme makes
it possible to add annotations using standard video cameras with no requirements for
specific equipment other than a smartphone. We designed the audio watermarking protocol
using dual-tone multi-frequency signaling, and developed a general-purpose annotation
framework including an annotation generator and extractor. We conducted a series of
performance tests to understand the reliability and the quality of the watermarking
method. We then created several examples of video-editing applications using annotations
to demonstrate the usefulness of Annotone, including an After Effects plug-in.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {57–66},
numpages = {10},
keywords = {video annotation, context awareness, video editing interface, audio watermarking, metadata},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702497,
author = {Smith, Thomas and Bowen, Simon J. and Nissen, Bettina and Hook, Jonathan and Verhoeven, Arno and Bowers, John and Wright, Peter and Olivier, Patrick},
title = {Exploring Gesture Sonification to Support Reflective Craft Practice},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702497},
doi = {10.1145/2702123.2702497},
abstract = {Much of the knowing employed in skilled craft practice is difficult to communicate
solely through written or verbal description. Consequently, the reflection and development
of a craft practice in this manner may miss important nuances of practitioners' skills
and experiences. We created digital technologies to sonify (using audio to perceptualize
data) a group of craft practitioners' gestures to explore how we can aid their reflection
in and on their craft, and consequently develop it. Over a number of workshops, the
design of these sonifications were iterated based on how the practitioners responded
to them. We found that direct sonification of gesture (sounds generated directly from
motion sensor data) helped practitioners understand and reflect upon their own and
each other's practice, encouraged discussion and enabled modification of craft technique.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {67–76},
numpages = {10},
keywords = {sonification, reflective practice, craft skills},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251788,
author = {Mackay, Wendy},
title = {Session Details: Rethinking Evaluation for Today's HCI},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251788},
doi = {10.1145/3251788},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702423,
author = {Chen, Kevin and Zhang, Haoqi},
title = {Remote Paper Prototype Testing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702423},
doi = {10.1145/2702123.2702423},
abstract = {To test paper prototypes of mobile applications, we have been experimenting with remote
paper prototype testing as an approach and tool for enabling a designer to wizard
a paper prototype from afar while a user tests the prototype out of the lab. This
paper presents a system for remote paper prototype testing that consists of (1) a
video camera placed over a paper prototype, which streams a live audio-visual feed
via Google Hangouts to a tester, and (2) Google Glass on the tester, which streams
a live audio-visual-data feed to the facilitator and wizard. Results from a pilot
study found that remote paper prototype testing helped designers gain valuable insights
through use in realistic scenarios.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {77–80},
numpages = {4},
keywords = {paper prototyping, design, lo-fi prototyping, mobile apps},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702353,
author = {Claes, Sandy and Wouters, Niels and Slegers, Karin and Vande Moere, Andrew},
title = {Controlling In-the-Wild Evaluation Studies of Public Displays},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702353},
doi = {10.1145/2702123.2702353},
abstract = {In this paper, we investigate the potential of controlled in-the-wild studies as an
evaluation methodology that merges the benefits of lab-based and in-the-wild studies.
Our exploratory investigation builds upon a comparative, between subject experiment
benchmarking different interaction features of a custom public installation that visualized
a series of urban datasets. In order to evaluate the usefulness of the in-the-wild
versus the controlled in-the-wild methodologies, we compared the resulting findings
in terms of participant engagement, insight generation, and social interaction. We
propose that a controlled in-the-wild study offers a viable alternative when evaluating
more complex interaction methods in public space, hereby potentially reducing the
practical efforts of in-the-wild studies to involve participants.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {81–84},
numpages = {4},
keywords = {controlled study, data visualization, in-the-wild study, evaluation, urban visualization, public display, methods},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702466,
author = {Luusua, Anna and Ylipulli, Johanna and Jurmu, Marko and Pihlajaniemi, Henrika and Markkanen, Piia and Ojala, Timo},
title = {Evaluation Probes},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702466},
doi = {10.1145/2702123.2702466},
abstract = {We introduce evaluation probes for conducting emic, experiential evaluation of urban
technologies "in the wild" without direct researcher presence. We commence with a
thorough discussion and analysis of the original cultural probes, used by Gaver, Dunne
and Pacenti to gain design inspiration, and their subsequent variations. We develop
the concept of evaluation probes through careful re-conceptualization and application
of the cultural probes in three successive studies conducted in the wild. We recount
and reflect on our use of evaluation probes and discuss their merits and limitations
in experiential emic evaluation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {85–94},
numpages = {10},
keywords = {evaluation, methodology, in the wild, probes, experience},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702561,
author = {Harboe, Gunnar and Huang, Elaine M.},
title = {Real-World Affinity Diagramming Practices: Bridging the Paper-Digital Gap},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702561},
doi = {10.1145/2702123.2702561},
abstract = {Despite the availability of computer-based alternatives both for desktop and touch
screen systems, a number of cooperative work processes still commonly rely on simple
paper sticky notes. In this paper, we present the first in-depth investigation of
the real-world practices of people who use paper-based affinity diagrams and similar
clustering processes in their work, in order to identify challenges and requirements
for technology support. Findings from retrospective and artifact-based interviews
with 13 participants suggest ways in which the rich interactions and material affordances
offered by paper are key to the process. Instead of seeking to replicate interactions
with paper on a screen, simpler transfer of information between the physical and digital
worlds has the potential to address many of the most pressing problems experienced
in practice. We describe different types of technology integration and augmentation,
with preliminary recommendations for different situations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {95–104},
numpages = {10},
keywords = {affinity diagrams, augmented paper, cooperative data analysis, interview study, paper clustering, sticky notes},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702481,
author = {Munteanu, Cosmin and Molyneaux, Heather and Moncur, Wendy and Romero, Mario and O'Donnell, Susan and Vines, John},
title = {Situational Ethics: Re-Thinking Approaches to Formal Ethics Requirements for Human-Computer Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702481},
doi = {10.1145/2702123.2702481},
abstract = {Most Human-Computer Interaction (HCI) researchers are accustomed to the process of
formal ethics review for their evaluation or field trial protocol. Although this process
varies by country, the underlying principles are universal. While this process is
often a formality, for field research or lab-based studies with vulnerable users,
formal ethics requirements can be challenging to navigate -- a common occurrence in
the social sciences; yet, in many cases, foreign to HCI researchers. Nevertheless,
with the increase in new areas of research such as mobile technologies for marginalized
populations or assistive technologies, this is a current reality. In this paper we
present our experiences and challenges in conducting several studies that evaluate
interactive systems in difficult settings, from the perspective of the ethics process.
Based on these, we draft recommendations for mitigating the effect of such challenges
to the ethical conduct of research. We then issue a call for interaction researchers,
together with policy makers, to refine existing ethics guidelines and protocols in
order to more accurately capture the particularities of such field-based evaluations,
qualitative studies, challenging lab-based evaluations, and ethnographic observations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {105–114},
numpages = {10},
keywords = {ethics, vulnerable populations, situational ethics, research protocol, field studies},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251789,
author = {Nacke, Lennart},
title = {Session Details: Improving Game Experiences},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251789},
doi = {10.1145/3251789},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702163,
author = {Vidal, Melodie and Bismuth, Remi and Bulling, Andreas and Gellersen, Hans},
title = {The Royal Corgi: Exploring Social Gaze Interaction for Immersive Gameplay},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702163},
doi = {10.1145/2702123.2702163},
abstract = {The eyes are a rich channel for non-verbal communication in our daily interactions.
We propose social gaze interaction as a game mechanic to enhance user interactions
with virtual characters. We develop a game from the ground-up in which characters
are designed to be reactive to the player's gaze in social ways, such as getting annoyed
when the player seems distracted or changing their dialogue depending on the player's
apparent focus of attention. Results from a qualitative user study provide insights
about how social gaze interaction is intuitive for users, elicits deep feelings of
immersion, and highlight the players' self-consciousness of their own eye movements
through their strong reactions to the characters.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {115–124},
numpages = {10},
keywords = {games, eye tracking, immersion, virtual agents},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702138,
author = {Kulshreshth, Arun and LaViola, Joseph J.},
title = {Exploring 3D User Interface Technologies for Improving the Gaming Experience},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702138},
doi = {10.1145/2702123.2702138},
abstract = {We present the results of a comprehensive video game study which explores how the
gaming experience is effected when several 3D user interface technologies are used
simultaneously. We custom designed an air-combat game integrating several 3DUI technologies
(stereoscopic 3D, head tracking, and finger-count gestures) and studied the combined
effect of these technologies on the gaming experience. Our game design was based on
existing design principles for optimizing the usage of these technologies in isolation.
Additionally, to enhance depth perception and minimize visual discomfort, the game
dynamically optimizes stereoscopic 3D parameters (convergence and separation) based
on the user's look direction. We conducted a within subjects experiment where we examined
performance data and self-reported data on users perception of the game. Our results
indicate that participants performed significantly better when all the 3DUI technologies
(stereoscopic 3D, head-tracking and finger-count gestures) were available simultaneously
with head tracking as a dominant factor. We explore the individual contribution of
each of these technologies to the overall gaming experience and discuss the reasons
behind our findings.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {125–134},
numpages = {10},
keywords = {user study, user experience., finger-count, stereoscopic 3d, game-play metrics, video games, player behavior, air-combat game, game design, head tracking},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702432,
author = {Ivkovic, Zenja and Stavness, Ian and Gutwin, Carl and Sutcliffe, Steven},
title = {Quantifying and Mitigating the Negative Effects of Local Latencies on Aiming in 3D Shooter Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702432},
doi = {10.1145/2702123.2702432},
abstract = {Real-time games such as first-person shooters (FPS) are sensitive to even small amounts
of lag. The effects of net-work latency have been studied, but less is known about
local latency, the lag caused by input devices and displays. While local latency is
important to gamers, we do not know how it affects aiming performance and whether
we can reduce its negative effects. To explore these issues, we tested local latency
in a variety of real-world gaming scenarios and carried out a controlled study focusing
on targeting and tracking activities in an FPS game with varying degrees of local
latency. In addition, we tested the ability of a lag compensation technique (based
on aim assistance) to mitigate the negative effects. Our study found local latencies
in the real-world range from 23 to 243 ms which cause significant and substantial
degradation in performance (even for latencies as low as 41 ms). The study also showed
that our compensation technique worked extremely well, reducing the problems caused
by lag in the case of targeting, and removing the problem altogether in the case of
tracking. Our work shows that local latency is a real and substantial problem -- but
games can mitigate the problem with appropriate compensation methods.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {135–144},
numpages = {10},
keywords = {fps games, local latency, lag, aiming, targeting},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702256,
author = {Denisova, Alena and Cairns, Paul},
title = {First Person vs. Third Person Perspective in Digital Games: Do Player Preferences Affect Immersion?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702256},
doi = {10.1145/2702123.2702256},
abstract = {Contemporary digital game developers offer a variety of games for the diverse tastes
of their customers. Although the gaming experience often depends on one's preferences,
the same may not apply to the level of their immersion. It has been argued whether
the player perspective can influence the level of player's involvement with the game.
The aim of this study was to research whether interacting with a game in first person
perspective is more immersive than playing in the third person point of view (POV).
The set up to test the theory involved participants playing a role-playing game in
either mode, naming their preferred perspective, and subjectively evaluating their
immersive experience. The results showed that people were more immersed in the game
play when viewing the game world through the eyes of the character, regardless of
their preferred perspectives.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {145–148},
numpages = {4},
keywords = {player perspective, immersion, camera point of view, player experience, digital games},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702264,
author = {Lee, Jin Ha and Hong, Sungsoo (Ray) and Cho, Hyerim and Kim, Yea-Seul},
title = {VIZMO Game Browser: Accessing Video Games by Visual Style and Mood},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702264},
doi = {10.1145/2702123.2702264},
abstract = {Despite the growing interests in video games as consumer products as well as objects
of research, current methods for accessing video games are limited. We present Vizmo
as a new way of browsing video games based on their visual style and mood. In order
to test the usability and usefulness of Vizmo, we asked 19 video game experts to evaluate
their interaction with the tool. The results show that experts perceived Vizmo as
a novel and aesthetically pleasing game discovery tool which would be most useful
for game research on historical and aesthetic aspects. We discuss five key points
for improving the design of Vizmo as well as our future plan for the next iteration
of this prototype game browser.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {149–152},
numpages = {4},
keywords = {mood, video games, visual style, visualization, metadata},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251790,
author = {Shamma, David},
title = {Session Details: Facebook Newsfeeds &amp; Friendships},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251790},
doi = {10.1145/3251790},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702556,
author = {Eslami, Motahhare and Rickman, Aimee and Vaccaro, Kristen and Aleyasen, Amirhossein and Vuong, Andy and Karahalios, Karrie and Hamilton, Kevin and Sandvig, Christian},
title = {"I Always Assumed That I Wasn't Really That Close to [Her]": Reasoning about Invisible Algorithms in News Feeds},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702556},
doi = {10.1145/2702123.2702556},
abstract = {Our daily digital life is full of algorithmically selected content such as social
media feeds, recommendations and personalized search results. These algorithms have
great power to shape users' experiences, yet users are often unaware of their presence.
Whether it is useful to give users insight into these algorithms' existence or functionality
and how such insight might affect their experience are open questions. To address
them, we conducted a user study with 40 Facebook users to examine their perceptions
of the Facebook News Feed curation algorithm. Surprisingly, more than half of the
participants (62.5%) were not aware of the News Feed curation algorithm's existence
at all. Initial reactions for these previously unaware participants were surprise
and anger. We developed a system, FeedVis, to reveal the difference between the algorithmically
curated and an unadulterated News Feed to users, and used it to study how users perceive
this difference. Participants were most upset when close friends and family were not
shown in their feeds. We also found participants often attributed missing stories
to their friends' decisions to exclude them rather than to Facebook News Feed algorithm.
By the end of the study, however, participants were mostly satisfied with the content
on their feeds. Following up with participants two to six months after the study,
we found that for most, satisfaction levels remained similar before and after becoming
aware of the algorithm's presence, however, algorithmic awareness led to more active
engagement with Facebook and bolstered overall feelings of control on the site.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {153–162},
numpages = {10},
keywords = {news feeds, algorithms, hidden processes, algorithm awareness},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702554,
author = {Lapides, Paul and Chokshi, Apoorve and Carpendale, Sheelagh and Greenberg, Saul},
title = {News Feed: What's in It for Me?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702554},
doi = {10.1145/2702123.2702554},
abstract = {Over a billion people use social networking sites like Facebook to maintain awareness
of their friends. Facebook's News Feed is the primary mechanism by which people are
shown updates about their friends' daily activities on the site in the form of an
algorithmically curated list of stories. This paper examines how people browse the
News Feed, their perceptions and satisfaction while using it, and the interactions
they make with their personal social network. We conducted a qualitative study involving
think-aloud semi-structured interviews as the participants casually browsed their
own feeds. We observed a wide variation in the use of the News Feed ranging from careful
consideration of social conventions, judgment of people, and annoyance and frustration
towards certain friends. Our findings suggest that people do not deliberately curate
their own News Feed either due to lack of awareness or perceived social repercussions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {163–172},
numpages = {10},
keywords = {news feed, social networks, facebook},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702174,
author = {Rader, Emilee and Gray, Rebecca},
title = {Understanding User Beliefs About Algorithmic Curation in the Facebook News Feed},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702174},
doi = {10.1145/2702123.2702174},
abstract = {People are becoming increasingly reliant on online socio-technical systems that employ
algorithmic curation to organize, select and present information. We wanted to understand
how individuals make sense of the influence of algorithms, and how awareness of algorithmic
curation may impact their interaction with these systems. We investigated user understanding
of algorithmic curation in Facebook's News Feed, by analyzing open-ended responses
to a survey question about whether respondents believe their News Feeds show them
every post their Facebook Friends create. Responses included a wide range of beliefs
and causal inferences, with different potential consequences for user behavior in
the system. Because user behavior is both input for algorithms and constrained by
them, these patterns of belief may have tangible consequences for the system as a
whole.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {173–182},
numpages = {10},
keywords = {intuitive theories, facebook news feed., feedback loop, algorithms},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251791,
author = {Hsieh, Gary},
title = {Session Details: Activism in Wikipedia &amp; Beyond},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251791},
doi = {10.1145/3251791},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702346,
author = {Hale, Scott A.},
title = {Cross-Language Wikipedia Editing of Okinawa, Japan},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702346},
doi = {10.1145/2702123.2702346},
abstract = {This article analyzes users who edit Wikipedia articles about Okinawa, Japan, in English
and Japanese. It finds these users are among the most active and dedicated users in
their primary languages, where they make many large, high-quality edits. However,
when these users edit in their non-primary languages, they tend to make edits of a
different type that are overall smaller in size and more often restricted to the narrow
set of articles that exist in both languages. Design changes to motivate wider contributions
from users in their non-primary languages and to encourage multilingual users to transfer
more information across language divides are presented.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {183–192},
numpages = {10},
keywords = {information discovery, social media, wikipedia, information diffusion, multilingual, cross-language, social network analysis},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702436,
author = {Borra, Erik and Weltevrede, Esther and Ciuccarelli, Paolo and Kaltenbrunner, Andreas and Laniado, David and Magni, Giovanni and Mauri, Michele and Rogers, Richard and Venturini, Tommaso},
title = {Societal Controversies in Wikipedia Articles},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702436},
doi = {10.1145/2702123.2702436},
abstract = {Collaborative content creation inevitably reaches situations where different points
of view lead to conflict. We focus on Wikipedia, the free encyclopedia anyone may
edit, where disputes about content in controversial articles often reflect larger
societal debates. While Wikipedia has a public edit history and discussion section
for every article, the substance of these sections is difficult to phantom for Wikipedia
users interested in the development of an article and in locating which topics were
most controversial. In this paper we present Contropedia, a tool that augments Wikipedia
articles and gives insight into the development of controversial topics. Contropedia
uses an efficient language agnostic measure based on the edit history that focuses
on wiki links to easily identify which topics within a Wikipedia article have been
most controversial and when.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {193–196},
numpages = {4},
keywords = {controversy mapping, wikipedia, data visualization, social science},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702170,
author = {Sen, Shilad W. and Ford, Heather and Musicant, David R. and Graham, Mark and Keyes, Os and Hecht, Brent},
title = {Barriers to the Localness of Volunteered Geographic Information},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702170},
doi = {10.1145/2702123.2702170},
abstract = {Localness is an oft-cited benefit of volunteered geographic information (VGI). This
study examines whether localness is a constant, universally shared benefit of VGI,
or one that varies depending on the context in which it is produced. Focusing on articles
about geographic entities (e.g. cities, points of interest) in 79 language editions
of Wikipedia, we examine the localness of both the editors working on articles and
the sources of the information they cite. We find extensive geographic inequalities
in localness, with the degree of localness varying with the socioeconomic status of
the local population and the health of the local media. We also point out the key
role of language, showing that information in languages not native to a place tends
to be produced and sourced by non-locals. We discuss the implications of this work
for our understanding of the nature of VGI and highlight a generalizable technical
contribution: an algorithm that determines the home country of the original publisher
of online content.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {197–206},
numpages = {10},
keywords = {wikipedia, localness, volunteered geographic information},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702514,
author = {Menking, Amanda and Erickson, Ingrid},
title = {The Heart Work of Wikipedia: Gendered, Emotional Labor in the World's Largest Online Encyclopedia},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702514},
doi = {10.1145/2702123.2702514},
abstract = {This note explores the issue of women's participation in Wikipedia through the lens
of emotional labor. Using a grounded theory approach, we detail the kinds of tasks
women Wikipedians choose to do and explore why they choose the work they do. We also
explore the emotional costs of their labor and their strategies for coping. Our analysis
of 20 interviews leads us to posit that the gendered and emotional labor required
of many women to participate in Wikipedia's production renders it, problematically,
a space of conflicting public and private spheres, motivated by antithetical open
and closed values. In addition to other contributions, we believe this insight sheds
light on some of the complex dynamics behind Wikipedia's observed gender gap.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {207–210},
numpages = {4},
keywords = {wikipedia, gender gap, emotional labor, women},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702559,
author = {Huang, Shih-Wen and Suh, Minhyang (Mia) and Hill, Benjamin Mako and Hsieh, Gary},
title = {How Activists Are Both Born and Made: An Analysis of Users on Change.Org},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702559},
doi = {10.1145/2702123.2702559},
abstract = {E-petitioning has become one of the most important and popular forms of online activism.
Although e-petition success is driven by user behavior, users have received relatively
little study by HCI and social computing researchers. Drawing from theoretical and
empirical work in analogous social computing systems, we identify two potentially
competing theories about the trajectories of users in e-petition platforms: (1) "power"
users in social computing systems are born, not made; and (2) users mature into "power"
users. In a quantitative analysis of data from Change.org, one of the largest online
e-petition platforms, we test and find support for both theories. A follow-up qualitative
analysis shows that not only do users learn from their experience, systems also "learn"
from users to make better recommendations. In this sense, we find that although power
users are "born," they are also "made" through both processes of personal growth and
improved support from the system.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {211–220},
numpages = {10},
keywords = {contribution, civic engagement, motivation, online activism, e-petition, power user},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251792,
author = {Kane, Shaun},
title = {Session Details: HMDs &amp; Wearables to Overcome Disabilities},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251792},
doi = {10.1145/3251792},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702188,
author = {Malu, Meethu and Findlater, Leah},
title = {Personalized, Wearable Control of a Head-Mounted Display for Users with Upper Body Motor Impairments},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702188},
doi = {10.1145/2702123.2702188},
abstract = {Head-mounted displays provide relatively hands-free interaction that could improve
mobile computing access for users with motor impairments. To investigate this largely
unexplored area, we present two user studies. The first, smaller study evaluated the
accessibility of Google Glass, a head-mounted display, with 6 participants. Findings
revealed potential benefits of a head-mounted display yet demonstrated the need for
alternative means of controlling Glass-3 of the 6 participants could not use it at
all. We then conducted a second study with 12 participants to evaluate a potential
alternative input mechanism that could allow for accessible control of a head-mounted
display: switch-based wearable touchpads that can be affixed to the body or wheelchair.
The study assessed input performance with three sizes of touchpad, investigated personalization
patterns when participants were asked to place the touchpads on their body or wheelchair,
and elicited subjective responses. All 12 participants were able to use the touchpads
to control the display, and patterns of touchpad placement point to the value of personalization
in providing support for each user's motor abilities.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {221–230},
numpages = {10},
keywords = {motor impairments, wearables, mobile accessibility},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702484,
author = {Williams, Kristin and Moffatt, Karyn and McCall, Denise and Findlater, Leah},
title = {Designing Conversation Cues on a Head-Worn Display to Support Persons with Aphasia},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702484},
doi = {10.1145/2702123.2702484},
abstract = {Symbol-based dictionaries of text, images and sound can help individuals with aphasia
find the words they need, but are often seen as a last resort because they tend to
replace rather than augment the user's natural speech. Through two design investigations,
we explore head-worn displays as a means of providing unobtrusive, always-available,
and glanceable vocabulary support. The first study used narrative storyboards as a
design probe to explore the potential benefits and challenges of a head-worn approach
over traditional augmented alternative communication (AAC) tools. The second study
then evaluated a proof-of-concept prototype in both a lab setting with the researcher
and in situ with unfamiliar conversation partners at a local market. Findings suggest
that a head-worn approach could better allow wearers to maintain focus on the conversation,
reduce reliance on the availability of external tools (e.g., paper and pen) or people,
and minimize visibility of the support by others. These studies should motivate further
investigation of head-worn conversational support.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {231–240},
numpages = {10},
keywords = {conversational support, accessibility, head-worn display, wearable computing, aphasia},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702393,
author = {Jain, Dhruv and Findlater, Leah and Gilkeson, Jamie and Holland, Benjamin and Duraiswami, Ramani and Zotkin, Dmitry and Vogler, Christian and Froehlich, Jon E.},
title = {Head-Mounted Display Visualizations to Support Sound Awareness for the Deaf and Hard of Hearing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702393},
doi = {10.1145/2702123.2702393},
abstract = {Persons with hearing loss use visual signals such as gestures and lip movement to
interpret speech. While hearing aids and cochlear implants can improve sound recognition,
they generally do not help the wearer localize sound necessary to leverage these visual
cues. In this paper, we design and evaluate visualizations for spatially locating
sound on a head-mounted display (HMD). To investigate this design space, we developed
eight high-level visual sound feedback dimensions. For each dimension, we created
3-12 example visualizations and evaluated these as a design probe with 24 deaf and
hard of hearing participants (Study 1). We then implemented a real-time proof-of-concept
HMD prototype and solicited feedback from 4 new participants (Study 2). Study 1 findings
reaffirm past work on challenges faced by persons with hearing loss in group conversations,
provide support for the general idea of sound awareness visualizations on HMDs, and
reveal preferences for specific design options. Although preliminary, Study 2 further
contextualizes the design probe and uncovers directions for future work.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {241–250},
numpages = {10},
keywords = {head-mounted display, accessibility, deaf, sound visualization, conversation support, hard of hearing, wearable},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702474,
author = {Katan, Simon and Grierson, Mick and Fiebrink, Rebecca},
title = {Using Interactive Machine Learning to Support Interface Development Through Workshops with Disabled People},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702474},
doi = {10.1145/2702123.2702474},
abstract = {We have applied interactive machine learning (IML) to the creation and customisation
of gesturally controlled musical interfaces in six workshops with people with learning
and physical disabilities. Our observations and discussions with participants demonstrate
the utility of IML as a tool for participatory design of accessible interfaces. This
work has also led to a better understanding of challenges in end-user training of
learning models, of how people develop personalised interaction strategies with different
types of pre-trained interfaces, and of how properties of control spaces and input
devices influence people's customisation strategies and engagement with instruments.
This work has also uncovered similarities between the musical goals and practices
of disabled people and those of expert musicians.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {251–254},
numpages = {4},
keywords = {accessible interfaces, interactive machine learning, music.},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702591,
author = {Goel, Mayank and Zhao, Chen and Vinisha, Ruth and Patel, Shwetak N.},
title = {Tongue-in-Cheek: Using Wireless Signals to Enable Non-Intrusive and Flexible Facial Gestures Detection},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702591},
doi = {10.1145/2702123.2702591},
abstract = {Serious brain injuries, spinal injuries, and motor neuron diseases often lead to severe
paralysis. Individuals with such disabilities can benefit from interaction techniques
that enable them to interact with the devices and thereby the world around them. While
a number of systems have proposed tongue-based gesture detection systems, most of
these systems require intrusive instrumentation of the user's body (e.g., tongue piercing,
dental retainers, multiple electrodes on chin). In this paper, we propose a wireless,
non-intrusive and non-contact facial gesture detection system using X-band Doppler.
The system can accurately differentiate between 8 different facial gestures through
non-contact sensing, with an average accuracy of 94.3%.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {255–258},
numpages = {4},
keywords = {tongue gestures, wireless signals, tongue-computer interface, accessibility},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251793,
author = {Hurter, Christophe},
title = {Session Details: Visualizing Data},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251793},
doi = {10.1145/3251793},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702419,
author = {Zhao, Jian and Liu, Zhicheng and Dontcheva, Mira and Hertzmann, Aaron and Wilson, Alan},
title = {MatrixWave: Visual Comparison of Event Sequence Data},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702419},
doi = {10.1145/2702123.2702419},
abstract = {Event sequence data analysis is common in many domains, including web and software
development, transportation, and medical care. Few have investigated visualization
techniques for comparative analysis of multiple event sequence datasets. Grounded
in the real-world characteristics of web clickstream data, we explore visualization
techniques for comparison of two clickstream datasets collected on different days
or from users with different demographics. Through iterative design with web analysts,
we designed MatrixWave, a matrix-based representation that allows analysts to get
an overview of differences in traffic patterns and interactively explore paths through
the website. We use color to encode differences and size to offer context over traffic
volume. User feedback on MatrixWave is positive. Our study participants made fewer
errors with MatrixWave and preferred it over the more familiar Sankey diagram.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {259–268},
numpages = {10},
keywords = {information visualization, matrix representation, sankey diagram, visual comparison, event sequences},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702217,
author = {Liu, Xiaotong and Shen, Han-Wei},
title = {The Effects of Representation and Juxtaposition on Graphical Perception of Matrix Visualization},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702217},
doi = {10.1145/2702123.2702217},
abstract = {Analyzing multiple networks at once is a common yet difficult task in many domains.
Using adjacency matrices for this purpose, however, can be effective because of its
superior ability to accommodate dense networks in a small area. We evaluate various
representations and juxtaposition designs for visualizing adjacency matrices through
a series of controlled experiments. We investigate the effect of using square matrices
and triangular matrices on the speed and accuracy of performing graphical-perception
tasks. Based on human symmetric perception, we propose two alternative juxtaposition
designs to the conventional side-by-side juxtaposition, and study how users perform
visual search and comparison tasks regarding different juxtaposition types. Our results
show that the matrix representations have similar performance, and the matrix juxtaposition
types perform differently. With the design guidelines derived from our studies, we
present a compact visualization termed TileMatrix for juxtaposing a large number of
matrices, and demonstrate its effectiveness in analyzing multi-faceted, time-varying
networks using real-world data.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {269–278},
numpages = {10},
keywords = {information visualization, adjacency matrices, networks},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702446,
author = {Cao, Nan and Lin, Yu-Ru and Li, Liangyue and Tong, Hanghang},
title = {G-Miner: Interactive Visual Group Mining on Multivariate Graphs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702446},
doi = {10.1145/2702123.2702446},
abstract = {With the rapid growth of rich network data available through various sources such
as social media and digital archives,there is a growing interest in more powerful
network visual analysis tools and methods. The rich information about the network
nodes and links can be represented as multivariate graphs, in which the nodes are
accompanied with attributes to represent the properties of individual nodes. An important
task often encountered in multivariate network analysis is to uncover link structure
with groups, e.g., to understand why a person fits a specific job or certain role
in a social group well.The task usually involves complex considerations including
specific requirement of node attributes and link structure, and hence a fully automatic
solution is typically not satisfactory.In this work, we identify the design challenges
for min-ing groups with complex criteria and present an interactive system, "g-Miner,"
that enables visual mining of groups on multivariate graph data. We demonstrate the
effectiveness of our system through case study and in-depth expert inter-views. This
work contributes to understanding the design of systems for leveraging users' knowledge
progressively with algorithmic capacity for tackling massive heterogeneous information.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {279–288},
numpages = {10},
keywords = {group mining, visual analysis, information visualization},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702476,
author = {Du, Fan and Cao, Nan and Zhao, Jian and Lin, Yu-Ru},
title = {Trajectory Bundling for Animated Transitions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702476},
doi = {10.1145/2702123.2702476},
abstract = {Animated transition has been a popular design choice for smoothly switching between
different visualization views or layouts, in which movement trajectories are created
as cues for tracking objects during location shifting. Tracking moving objects, however,
becomes difficult when their movement paths overlap or the number of tracking targets
increases. We propose a novel design to facilitate tracking moving objects in animated
transitions. Instead of simply animating an object along a straight line, we create
"bundled" movement trajectories for a group of objects that have spatial proximity
and share similar moving directions. To study the effect of bundled trajectories,
we untangle variations due to different aspects of tracking complexity in a comprehensive
controlled user study. The results indicate that using bundled trajectories is particularly
effective when tracking more targets (six vs. three targets) or when the object movement
involves a high degree of occlusion or deformation. Based on the study, we discuss
the advantages and limitations of the new technique, as well as provide design implications.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {289–298},
numpages = {10},
keywords = {animated transitions, movement trajectory bundling, information visualization, multiple object tracking},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251794,
author = {Zhu, Kening},
title = {Session Details: Interaction in 3D Space},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251794},
doi = {10.1145/3251794},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702126,
author = {Perrault, Simon T. and Lecolinet, Eric and Bourse, Yoann Pascal and Zhao, Shengdong and Guiard, Yves},
title = {Physical Loci: Leveraging Spatial, Object and Semantic Memory for Command Selection},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702126},
doi = {10.1145/2702123.2702126},
abstract = {Physical Loci, a technique based on an ancient memory technique, allows users to quickly
learn a large command set by leveraging spatial, object and verbal/semantic memory
to create a cognitive link between individual commands and nearby physical objects
in a room (called loci). We first report on an experiment that showed that for learning
25 items Physical Loci outperformed a mid-air Marking Menu baseline. A long-term retention
experiment with 48 items then showed that recall was nearly perfect one week later
and, surprisingly, independent of whether the command/locus mapping was one's own
choice or somebody else's. A final study suggested that recall performance is robust
to alterations of the learned mapping, whether systematic or random.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {299–308},
numpages = {10},
keywords = {memorization, command selection, mnemonic device, association, method of loci, input, spatial memory},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702333,
author = {Omirou, Themis and Marzo, Asier and Seah, Sue Ann and Subramanian, Sriram},
title = {LeviPath: Modular Acoustic Levitation for 3D Path Visualisations},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702333},
doi = {10.1145/2702123.2702333},
abstract = {LeviPath is a modular system to levitate objects across 3D paths. It consists of two
opposed arrays of transducers that create a standing wave capable of suspending objects
in mid-air. To control the standing wave, the system employs a novel algorithm based
on combining basic patterns of movement. Our approach allows the control of multiple
beads simultaneously along different 3D paths. Due to the patterns and the use of
only two opposed arrays, the system is modular and can scale its interaction space
by joining several LeviPaths. In this paper, we describe the hardware architecture,
the basic patterns of movement and how to combine them to produce 3D path visualisations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {309–312},
numpages = {4},
keywords = {modular system, acoustic levitation, physical visualisations, 3d paths},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702201,
author = {Shovman, Mark and Bown, James and Szymkowiak, Andrea and Scott-Brown, Kenneth C.},
title = {Twist and Learn: Interface Learning in 3DOF Exploration of 3D Scatterplots},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702201},
doi = {10.1145/2702123.2702201},
abstract = {The increasing availability of 3D interfaces brings promise of improved user experience
in diverse areas. Our study focuses on visual analytics, testing whether 3D interactivity
improves performance in a visual data exploration task. Specifically, we compared
scene rotation around vertical axis to a full 3D rotation using a InterSense IS-900
3D controller, in a task involving trivariate trend detection in a 3D scatterplot.
We found that, while 3D rotation leads to slower performance, previous exposure to
single-axis rotation removes that difference. This shows that an interactive 3D scatterplot
can be an effective visual exploration technique for detecting trivariate patterns
in the data, and highlights the role of interface learning in design and assessment
of novel interfaces.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {313–316},
numpages = {4},
keywords = {interface learning, 3d controller, visual analytics, scatterplot},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702158,
author = {Achibet, Merwan and Casiez, G\'{e}ry and L\'{e}cuyer, Anatole and Marchal, Maud},
title = {THING: Introducing a Tablet-Based Interaction Technique for Controlling 3D Hand Models},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702158},
doi = {10.1145/2702123.2702158},
abstract = {The hands of virtual characters are highly complex 3D models that can be tedious and
time-consuming to animate with current methods. This paper introduces THING, a novel
tablet-based approach that leverages multi-touch interaction for a quick and precise
control of a 3D hand's pose. The flexion/extension and abduction/adduction of the
virtual fingers can be controlled for each finger individually or for several fingers
in parallel through sliding motions on the tablet's surface. We designed two variants
of THING: (1) MobileTHING, which maps the spatial location and orientation of the
tablet to that of the virtual hand, and (2) DesktopTHING, which combines multi-touch
controls of fingers with traditional mouse controls for the hand's global position
and orientation. We compared the usability of THING against mouse-only controls and
a data glove in two controlled experiments. Results show that DesktopTHING was significantly
preferred by users while providing performance similar to data gloves. Together, these
results could pave the way to the introduction of novel hybrid user interfaces based
on tablets and mice in future animation pipelines.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {317–326},
numpages = {10},
keywords = {computer animation., virtual hand, multi-touch input},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702244,
author = {Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel},
title = {The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702244},
doi = {10.1145/2702123.2702244},
abstract = {We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input
device that combines the advantages of the mouse (position displacement) and of 3D
devices (roll and rotation) to unify 2D and 3D interaction. Our first study explores
RPM gesture amplitude and stability for different upper shapes (Hemispherical, Convex)
and hand postures. 8 roll directions can be performed precisely and their amplitude
is larger on Hemispherical RPM. As minor rolls affect translation, we propose a roll
correction algorithm to support stable 2D pointing with RPM. We propose the use of
compound gestures for 3D pointing and docking, and evaluate them against a commercial
3D device, the SpaceMouse. Our studies reveal that RPM performs 31% faster than the
SpaceMouse for 3D pointing and equivalently for 3D rotation. Finally, we present a
proof-of-concept integrated RPM prototype along with discussion on the various technical
challenges to overcome to build a final integrated version of RPM.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {327–336},
numpages = {10},
keywords = {2d pointing, 3d interaction, input device},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251795,
author = {Davis, Richard},
title = {Session Details: Understanding &amp; Evaluating Performance},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251795},
doi = {10.1145/3251795},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702509,
author = {Amershi, Saleema and Chickering, Max and Drucker, Steven M. and Lee, Bongshin and Simard, Patrice and Suh, Jina},
title = {ModelTracker: Redesigning Performance Analysis Tools for Machine Learning},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702509},
doi = {10.1145/2702123.2702509},
abstract = {Model building in machine learning is an iterative process. The performance analysis
and debugging step typically involves a disruptive cognitive switch from model building
to error analysis, discouraging an informed approach to model building. We present
ModelTracker, an interactive visualization that subsumes information contained in
numerous traditional summary statistics and graphs while displaying example-level
performance and enabling direct error examination and debugging. Usage analysis from
machine learning practitioners building real models with ModelTracker over six months
shows ModelTracker is used often and throughout model building. A controlled experiment
focusing on ModelTracker's debugging capabilities shows participants prefer ModelTracker
over traditional tools without a loss in model performance.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {337–346},
numpages = {10},
keywords = {debugging, interactive visualization, machine learning, performance analysis},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702603,
author = {Kay, Matthew and Patel, Shwetak N. and Kientz, Julie A.},
title = {How Good is 85%? A Survey Tool to Connect Classifier Evaluation to Acceptability of Accuracy},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702603},
doi = {10.1145/2702123.2702603},
abstract = {Many HCI and ubiquitous computing systems are characterized by two important properties:
their output is uncertain-it has an associated accuracy that researchers attempt to
optimize-and this uncertainty is user-facing-it directly affects the quality of the
user experience. Novel classifiers are typically evaluated using measures like the
F1 score-but given an F-score of (e.g.) 0.85, how do we know whether this performance
is good enough? Is this level of uncertainty actually tolerable to users of the intended
application-and do people weight precision and recall equally? We set out to develop
a survey instrument that can systematically answer such questions. We introduce a
new measure, acceptability of accuracy, and show how to predict it based on measures
of classifier accuracy. Out tool allows us to systematically select an objective function
to optimize during classifier evaluation, but can also offer new insights into how
to design feedback for user-facing classification systems (e.g., by combining a seemingly-low-performing
classifier with appropriate feedback to make a highly usable system). It also reveals
potential issues with the ubiquitous F1-measure as applied to user-facing systems.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {347–356},
numpages = {10},
keywords = {sensors, accuracy acceptability, classifiers, inference, accuracy, machine learning},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702139,
author = {Cockburn, Andy and Quinn, Philip and Gutwin, Carl},
title = {Examining the Peak-End Effects of Subjective Experience},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702139},
doi = {10.1145/2702123.2702139},
abstract = {Psychological research has shown that 'peak-end' effects influence people's retrospective
evaluation of hedonic and affective experience. Rather than objectively reviewing
the total amount of pleasure or pain during an experience, people's evaluation is
shaped by the most intense moment (the peak) and the final moment (end). We describe
an experiment demonstrating that peak-end effects can influence a user's preference
for interaction sequences that are objectively identical in their overall requirements.
Participants were asked to choose which of two interactive sequences of five pages
they preferred. Both sequences required setting a total of 25 sliders to target values,
and differed only in the distribution of the sliders across the five pages -- with
one sequence intended to induce positive peak-end effects, the other negative. The
study found that manipulating only the peak or the end of the series did not significantly
change preference, but that a combined manipulation of both peak and end did lead
to significant differences in preference, even though all series had the same overall
effort.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {357–366},
numpages = {10},
keywords = {hedonic experience, peak-end rule, subjective preferences},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702428,
author = {Asthana, Siddhartha and Singh, Pushpendra and Gupta, Parul},
title = {Survival Analysis: Objective Assessment of Wait Time in HCI},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702428},
doi = {10.1145/2702123.2702428},
abstract = {Waiting for the completion of a system process is an everyday experience. While waiting,
system provides feedback to the user about ongoing process through temporal metaphors
(Progress bar, Busy icons, etc.). One of the key performance requirement for temporal
metaphors is to retain the user till the process completes. Researchers have evaluated
these metaphors through subjective means, and objective assessment has not been well
explored. In this paper, we present survival analysis as objective assessment method
to evaluate temporal metaphors. Through a field experiment, we demonstrate the application
of survival analysis and empirically establish that auditory progress bar (temporal
metaphor for audio interfaces) works for callers of a distress helpline. To the best
of our knowledge, it is the first study on distress callers. The paper further discusses
the applicability of survival analysis for evaluating temporal metaphors and wait
time experiments for other applications, tasks, and settings.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {367–376},
numpages = {10},
keywords = {wait-time, time-perception, objective assessment, temporal metaphors},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251796,
author = {Hook, Jonathan},
title = {Session Details: Music &amp; Art},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251796},
doi = {10.1145/3251796},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702492,
author = {Troiano, Giovanni Maria and Pedersen, Esben Warming and Hornb\ae{}k, Kasper},
title = {Deformable Interfaces for Performing Music},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702492},
doi = {10.1145/2702123.2702492},
abstract = {Deformable interfaces offer new possibilities for gestures, some of which have been
shown effective in controlled laboratory studies. Little work, however, has attempted
to match deformable interfaces to a demanding domain and evaluate them out of the
lab. We investigate how musicians use deformable interfaces to perform electronic
music. We invited musicians to three workshops, where they explored 10 deformable
objects and generated ideas on how to use these objects to perform music. Based on
the results from the workshops, we implemented sensors in the five preferred objects
and programmed them for controlling sounds. Next, we ran a performance study where
six musicians performed music with these objects at their studios. Our results show
that (1) musicians systematically map deformations to certain musical parameters,
(2) musicians use deformable interfaces especially to filter and modulate sounds,
and (3) musicians think that deformable interfaces embody the parameters that they
control. We discuss what these results mean to research in deformable interfaces.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {377–386},
numpages = {10},
keywords = {usefulness, deformable interfaces, user study, music, controller, user interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702236,
author = {Hazzard, Adrian and Benford, Steve and Burnett, Gary},
title = {Sculpting a Mobile Musical Soundtrack},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702236},
doi = {10.1145/2702123.2702236},
abstract = {We present an in-the-wild project to design and study a mobile musical soundtrack
that enhances the experience of visiting a sculpture park. As with soundtracks for
films and games, the goal was to enhance the emotional and narrative aspects of the
experience while remaining in the background. We describe a compositional approach
in which we first established a broad musical landscape before treating specific exhibits
with detailed musical trajectories. Our study reveals how our soundtrack dramatically
shaped visitors' experiences while they remained largely unaware of its operation.
We distil seven experiential factors to be addressed by mobile soundtracks alongside
ten compositional guidelines.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {387–396},
numpages = {10},
keywords = {mobile, soundtracks, trajectories, experiences, composition},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702467,
author = {Rosner, Daniela K. and Saegusa, Hidekazu and Friedland, Jeremy and Chambliss, Allison},
title = {Walking by Drawing},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702467},
doi = {10.1145/2702123.2702467},
abstract = {This paper describes a study of algorithmic living with Trace, a mobile mapping application
that generates walking routes based on digital sketches people create and annotate
without a map. In addition to creating walking paths, Trace enables people to send
the paths to others. We designed Trace to explore the possibility of emphasizing guided
wandering over precise, destination-oriented navigation. Studies of sixteen people's
use of Trace over roughly one week reveal how walkers find Trace both delightful and
disorienting, highlighting moments of surprise, frustration, and identification with
GIS routing algorithms. We conclude by discussing how design interventions offers
possibilities for understanding the work of mapping and how it might be done differently
in HCI.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {397–406},
numpages = {10},
keywords = {geo-spatial navigation, algorithmic living, design, walking},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702281,
author = {Coughlan, Tim and Carletti, Laura and Giannachi, Gabriella and Benford, Steve and McAuley, Derek and Price, Dominic and Locatelli, Cristina and Sinker, Rebecca and Stack, John},
title = {ArtMaps: Interpreting the Spatial Footprints of Artworks},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702281},
doi = {10.1145/2702123.2702281},
abstract = {Creating and utilizing simple links between items and locations in map-based systems
has become a mainstream component of modern computing. In this paper, we explore support
for "art mapping", an activity that requires consideration of more complex interpretations
of spatial relationships as users engage with identifying locations of relevance to
artworks. Through a user study of the ArtMaps platform, and an exploratory study with
professional artists, we identify diverse interpretations of spatial meaning in relation
to art. We find that art mapping highlights potential for more active engagement with
art through technology, but challenges existing systems for spatial representation.
Through connecting our findings with work on designing for interpretation, and on
space and place in HCI, we contribute new understanding of creating engagement through
the spatial interpretation of art, and define potential characteristics and uses of
holistic "footprints" for artworks.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {407–416},
numpages = {10},
keywords = {museum, art, interpretation, maps, geotagging, location},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251797,
author = {Joshi, Anirudha},
title = {Session Details: Supporting Change in Developing Countries},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251797},
doi = {10.1145/3251797},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702191,
author = {Vashistha, Aditya and Cutrell, Edward and Borriello, Gaetano and Thies, William},
title = {Sangeet Swara: A Community-Moderated Voice Forum in Rural India},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702191},
doi = {10.1145/2702123.2702191},
abstract = {Interactive voice forums have emerged as a promising platform for people in developing
regions to record and share audio messages using low-end mobile phones. However, one
of the barriers to the scalability of voice forums is the process of screening and
categorizing content, often done by a dedicated team of moderators. We present Sangeet
Swara, a voice forum for songs and cultural content that relies on the community of
callers to curate high-quality posts that are prioritized for playback to others.
An 11-week deployment of Sangeet Swara found broad and impassioned usage, especially
among visually impaired users. We also conducted a follow-up experiment, called Talent
Hunt, that sought to reduce reliance on toll-free telephone lines. Together, our deployments
span about 53,000 calls from 13,000 callers, who submitted 6,000 posts and 150,000
judgments of other content. Using a mixed-methods analysis of call logs, audio content,
comparison with outside judges, and 204 automated phone surveys, we evaluate the user
experience, the strengths and weaknesses of community moderation, financial sustainability,
and the implications for future systems.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {417–426},
numpages = {10},
keywords = {hci4d, ivr, interactive voice response, ict4d, india},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702258,
author = {Kumar, Neha and Anderson, Richard J.},
title = {Mobile Phones for Maternal Health in Rural India},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702258},
doi = {10.1145/2702123.2702258},
abstract = {We present our findings from a mixed methods study of mobile phone practices of rural
Indian women. We situate our study in the context of Projecting Health, a public health
initiative we deployed in Uttar Pradesh (India) to target the dissemination of health
information for mothers and newborns. Adopting the lens of feminist reflexivity, we
reconsider our design of Projecting Health by factoring in the mobile media consumption
and sharing practices of our target audience. We stress the importance of taking a
community-oriented approach and show that although there are strict social conventions
and patriarchal norms that constrain various practices of these women, they are able
to exercise agency and mobilize help within their communities when needed.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {427–436},
numpages = {10},
keywords = {health, feminist hci, ictd, hci4d, information},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702573,
author = {Ahmed, Syed Ishtiaque and Mim, Nusrat Jahan and Jackson, Steven J.},
title = {Residual Mobilities: Infrastructural Displacement and Post-Colonial Computing in Bangladesh},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702573},
doi = {10.1145/2702123.2702573},
abstract = {This paper explores discrepancies between the founding assumptions of mobile and ubiquitous
computing in the western world, and the starkly different experiences of mobility
and infrastructure to be found in many post-colonial environments. Based on a field
study of forced mobility and technology use among populations displaced by the Hatirjheel
waterfront development project in Dhaka, Bangladesh, we make two basic arguments.
First, we point to the partial nature of assumptions around mobility that frame the
imagination of mainstream HCI research, and argue that different and heretofore residual
experiences of mobility must also be accounted for in post-colonial and other marginal
computing environments. Second, we document four forms of infrastructural experience
-- dispossession, reconstitution, collaboration, and repair -- that characterize real-world
engagements with infrastructure in such settings. We conclude with implications for
HCI research and design, and reflections on how HCI researchers might better account
for such experiences in their work.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {437–446},
numpages = {10},
keywords = {post-colonial computing, development, ictd, ethnography, infrastructure, mobility, bangladesh},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702595,
author = {Therias, Emeline and Bird, Jon and Marshall, Paul},
title = {M\'{a}s Tecnologia, M\'{a}s Cambio? Investigating an Educational Technology Project in Rural Peru},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702595},
doi = {10.1145/2702123.2702595},
abstract = {Providing access to and training in ICTs is seen as key to bridging the digital divide
between technology-rich communities and those with poor IT infrastructures. Several
projects have focused on providing ICTs for education in developing countries, of
which the best known is One Laptop Per Child (OLPC). Although, there has been significant
criticism of some of these projects, in particular OLPC, due to its use of a top-down
implementation strategy and the limited evidence for its educational benefits, there
has been comparatively little analysis of what underlies successful approaches. We
aimed to address this deficit by conducting an ethnographic study of community-based
projects organised by Blue Sparrow, a small charity that donates refurbished desktop
computers to schools in rural Peru, as this organisation has experienced both successes
and failures when implementing its educational technology projects. The relative success
of Blue Sparrow highlights the benefits of: understanding local contexts; using a
bottom up approach; involving stakeholders in setting programme objectives; and empowering
communities. We argue that the educational impact of such projects can be improved
by: providing teacher training; integrating computers into the wider curriculum; and
providing teaching materials and clear objectives for volunteers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {447–456},
numpages = {10},
keywords = {one laptop per child, educational icts, hci4d, peru},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251798,
author = {Rader, Emilee},
title = {Session Details: Privacy, Security &amp; Interruptions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251798},
doi = {10.1145/3251798},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702142,
author = {Luger, Ewa and Urquhart, Lachlan and Rodden, Tom and Golembewski, Michael},
title = {Playing the Legal Card: Using Ideation Cards to Raise Data Protection Issues within the Design Process},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702142},
doi = {10.1145/2702123.2702142},
abstract = {The regulatory climate is in a process of change. Design, having been implicated for
some time, is now explicitly linked to law. This paper recognises the heightened role
of designers in the regulation of ambient interactive technologies. Taking account
of incumbent legal requirements is difficult. Legal rules are convoluted, uncertain,
and not geared towards operationalisable heuristics or development guidelines for
system designers. Privacy and data protection are a particular moral, social and legal
concern for technologies. This paper seeks to understand how to make emerging European
data protection regulation more accessible to our community. Our approach develops
and tests a series of data protection ideation cards with teams of designers. We find
that, whilst wishing to protect users, regulation is viewed as a compliance issue.
Subsequently we argue for the use of instruments, such as our cards, as a means to
engage designers in leading a human-centered approach to regulation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {457–466},
numpages = {10},
keywords = {regulation, design, data protection, ideation cards},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702370,
author = {Ismail, Qatrunnada and Ahmed, Tousif and Kapadia, Apu and Reiter, Michael K.},
title = {Crowdsourced Exploration of Security Configurations},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702370},
doi = {10.1145/2702123.2702370},
abstract = {Smartphone apps today request permission to access a multitude of sensitive resources,
which users must accept completely during installation (e.g., on Android) or selectively
configure after installation (e.g., on iOS, but also planned for Android). Everyday
users, however, do not have the ability to make informed decisions about which permissions
are essential for their usage. For enhanced privacy, we seek to leverage crowdsourcing
to find minimal sets of permissions that will preserve the usability of the app for
diverse users. We advocate an efficient 'lattice-based' crowd-management strategy
to explore the space of permissions sets. We conducted a user study (N = 26) in which
participants explored different permission sets for the popular Instagram app. This
study validates our efficient crowd management strategy and shows that usability scores
for diverse users can be predicted accurately, enabling suitable recommendations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {467–476},
numpages = {10},
keywords = {crowdsourcing, privacy, android apps, permissions},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702295,
author = {Gilbert, Eric},
title = {Open Book: A Socially-Inspired Cloaking Technique That Uses Lexical Abstraction to Transform Messages},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702295},
doi = {10.1145/2702123.2702295},
abstract = {Both governments and corporations routinely surveil computer-mediated communication
(CMC). Technologists often suggest widespread encryption as a defense mechanism, but
CMC encryption schemes have historically faced significant usability and adoption
problems. Here, we introduce a novel technique called Open Book designed to address
these two problems. Inspired by how people deal with eavesdroppers offline, Open Book
uses data mining and natural language processing to transform CMC messages into ones
that are vaguer than the original. Specifically, we present: 1) a greedy Open Book
algorithm that cloaks messages by transforming them to resemble the average Internet
message; 2) an open-source, browser-based instantiation of it called Read Me, designed
for Gmail; and, 3) a set of experiments showing that intended recipients can decode
Open Book messages, but that unintended human- and machine-recipients cannot. Finally,
we reflect on some open questions raised by this approach, such as recognizability
and future side-channel attacks.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {477–486},
numpages = {10},
keywords = {cmc, social media, encryption, usable security},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702409,
author = {Kim, SeungJun and Chun, Jaemin and Dey, Anind K.},
title = {Sensors Know When to Interrupt You in the Car: Detecting Driver Interruptibility Through Monitoring of Peripheral Interactions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702409},
doi = {10.1145/2702123.2702409},
abstract = {Interruptions while driving can be quite dangerous, whether these are self-interruptions
or external interruptions. They increase driver workload and reduce performance on
the primary driving task. Being able to identify when a driver is interruptible is
critical for building systems that can mediate these interruptions. In this paper,
we collect sensor and human-annotated data from 15 drivers, including vehicle motion,
traffic states, physiological responses and driver motion. We demonstrate that this
data can be used to build a machine learning classifier that can determine interruptibility
every second with a 94% accuracy. We present both population and individual models
and discuss the features that contribute to the high performance of this system. Such
a classifier can be used to build systems that mediate when drivers use technology
to self-interrupt and when drivers are interrupted by technology.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {487–496},
numpages = {10},
keywords = {naturalistic driving, interruptions, sensor data mining},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251799,
author = {Nanayakkara, Suranga},
title = {Session Details: Making &amp; Sharing Assistive Technologies},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251799},
doi = {10.1145/3251799},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702292,
author = {McNaney, Roisin and Poliakov, Ivan and Vines, John and Balaam, Madeline and Zhang, Pengfei and Olivier, Patrick},
title = {LApp: A Speech Loudness Application for People with Parkinson's on Google Glass},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702292},
doi = {10.1145/2702123.2702292},
abstract = {Reduced vocal volume in Parkinson's is extremely common and can have significant social
and emotional impact. We describe the development and evaluation of LApp--an application
for Google Glass to help people with Parkinson's (PwP) monitor their speech volume
and cue themselves to speak louder when necessary. Our findings highlight enthusiasm
for using the application both at home as a volume training tool and in public social
settings as a situated cueing device. We contribute insights to the literature on
how eyewear technologies can provide assistance to people with health conditions and
offer insights for the design of future self-monitoring and management applications
on Google Glass.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {497–500},
numpages = {4},
keywords = {parkinson's disease, wearable technology, google glass, augmented reality, self- monitoring},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702310,
author = {McNaney, Roisin and Balaam, Madeline and Holden, Amey and Schofield, Guy and Jackson, Daniel and Webster, Mary and Galna, Brook and Barry, Gillian and Rochester, Lynn and Olivier, Patrick},
title = {Designing for and with People with Parkinson's: A Focus on Exergaming},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702310},
doi = {10.1145/2702123.2702310},
abstract = {Parkinson's is a complex and multifaceted condition with a myriad of symptoms, thus,
designing for and with this user group requires careful consideration. We reflect
upon two studies, employing different design methodologies, relating to the design
of rehabilitative exergames in Parkinson's. The first explored the concept of designing 'for' People with Parkinson's (PwP) and focused on specifications outlined by clinical
stakeholders. The second used a designing 'with' approach and modified a pre-established
participatory design method for use with PwP. We call attention to the importance
of carrying out design work with PwP and contribute; an empathic understanding of
living with Parkinson's, a set of recommendations for how to design with PwP and a
set of wider considerations for developing rehabilitative exergames for PwP.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {501–510},
numpages = {10},
keywords = {parkinson's disease, exergames, design, rehabilitation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702342,
author = {Mentis, Helena M. and Shewbridge, Rita and Powell, Sharon and Fishman, Paul and Shulman, Lisa},
title = {Being Seen: Co-Interpreting Parkinson's Patient's Movement Ability in Deep Brain Stimulation Programming},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702342},
doi = {10.1145/2702123.2702342},
abstract = {The purpose of this study is to address the use of movement assessment sensors for
clinical diagnosis and treatment. Eleven patients with Parkinson's disease who had
under-gone deep brain stimulation (DBS) surgery were observed during follow-up appointments
for adjustments to the stimulation settings. We examine the ways in which the patients
and clinicians assess movement ability together in the clinic and how these assessments
relate to the treatment of functional disability through DBS. We have found that effective
assessment of movement and treatment efficacy is a collaborative and interpretive
process (co-interpretation) that relies on input from patients, clinicians, and caregivers.
From these findings we describe the design directions for movement sensors to support
co-interpretation of movement in a clinical context as opposed to simply movement
definition.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {511–520},
numpages = {10},
keywords = {health, wearable sensors, movement, communication, co-interpretation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702344,
author = {Gromala, Diane and Tong, Xin and Choo, Amber and Karamnejad, Mehdi and Shaw, Chris D.},
title = {The Virtual Meditative Walk: Virtual Reality Therapy for Chronic Pain Management},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702344},
doi = {10.1145/2702123.2702344},
abstract = {Because the nature of chronic pain is complex, pharmacological analgesics are often
not enough to achieve an ideal treatment plan. Virtual Reality (VR) technologies have
emerged within medical research in recent years for treating acute pain, and proved
to be an effective strategy based on pain distraction. This paper describes a VR system
designed for chronic pain patients. The system incorporates biofeedback sensors, an
immersive virtual environment, and stereoscopic sound titled the "Virtual Meditative
Walk" (VMW). It was designed to enable chronic pain patients to learn Mindfulness-based
stress reduction (MBSR), a form of meditation. By providing real-time visual and sonic
feedback, VMW enables patients to learn how to manage their pain. A proof-of-concept
user study was conducted to investigate the effectiveness of the VR system with chronic
pain patients in clinical settings. Results show that the VMW was more effective in
reducing perceived pain compared to the non-VR control condition.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {521–524},
numpages = {4},
keywords = {chronic pain, biofeedback, mindfulness meditation., virtual reality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702525,
author = {Buehler, Erin and Branham, Stacy and Ali, Abdullah and Chang, Jeremy J. and Hofmann, Megan Kelly and Hurst, Amy and Kane, Shaun K.},
title = {Sharing is Caring: Assistive Technology Designs on Thingiverse},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702525},
doi = {10.1145/2702123.2702525},
abstract = {An increasing number of online communities support the open-source sharing of designs
that can be built using rapid prototyping to construct physical objects. In this paper,
we examine the designs and motivations for assistive technology found on Thingiverse.com,
the largest of these communities at the time of this writing. We present results from
a survey of all assistive technology that has been posted to Thingiverse since 2008
and a questionnaire distributed to the designers exploring their relationship with
assistive technology and the motivation for creating these designs. The majority of
these designs are intended to be manufactured on a 3D printer and include assistive
devices and modifications for individuals with disabilities, older adults, and medication
management. Many of these designs are created by the end-users themselves or on behalf
of friends and loved ones. These designers frequently have no formal training or expertise
in the creation of assistive technology. This paper discusses trends within this community
as well as future opportunities and challenges.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {525–534},
numpages = {10},
keywords = {prototyping, personal-scale fabrication, open-source, disability, design, assistive technology, 3d printing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251800,
author = {Kaye, Jofish},
title = {Session Details: Matching &amp; Facilitating Social Interactions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251800},
doi = {10.1145/3251800},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702417,
author = {Masden, Christina and Edwards, W. Keith},
title = {Understanding the Role of Community in Online Dating},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702417},
doi = {10.1145/2702123.2702417},
abstract = {Online dating sites have become a common means of finding a romantic partner. And
yet, these sites differ greatly from many other socially oriented websites: perhaps
most notably, the pairwise style of interaction afforded by these sites prevents a
robust online community from forming. Users, however, have taken matters into their
own hands by creating thriving external forums for discussion of specific dating sites.
We report on a multiple methods study of two online dating services, via observation
and interviews with users of the forums associated with these sites. Our findings
suggest that these forums play an essential role in creating an "outsourced community"
for the dating sites, and also reveal practices around how some users "game the system"
in online dating, the prevalence of harassment in online dating, and users' frustrations
with current dating sites. We conclude with a number of recommendations for system
design.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {535–544},
numpages = {10},
keywords = {online communities, legitimate peripheral participation, online dating, social computing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702343,
author = {Mayer, Julia M. and Hiltz, Starr Roxanne and Jones, Quentin},
title = {Making Social Matching Context-Aware: Design Concepts and Open Challenges},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702343},
doi = {10.1145/2702123.2702343},
abstract = {Social matching systems recommend people to people. In an ideal world, such systems
could be context-aware, in that they would introduce users to each other in situations
where they are mutually interested, available and open to meeting (i.e., facilitate
a valuable encounter). Unfortunately, today's systems primarily match individuals
based on simple similarity and proximity metrics. This paper explores how contextual
information available on today's mobile phones could be used to identify opportunities
for people to make valuable new connections. Three types of context that are relevant
for this work are: relational, social and personal. We present insights gained from
several iterations of semi-structured interviewing (N=58) exploring these three types
of contexts and propose novel context-aware social matching concepts such as: sociability
of others as an indicator of opportune social context; activity involvement as an
indicator of opportune personal context; and contextual rarity as an indicator of
opportune relational context.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {545–554},
numpages = {10},
keywords = {context-aware social matching, social recommender systems, chance encounters, introduction systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702411,
author = {Nguyen, Tien T. and Nguyen, Duyen T. and Iqbal, Shamsi T. and Ofek, Eyal},
title = {The Known Stranger: Supporting Conversations between Strangers with Personalized Topic Suggestions},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702411},
doi = {10.1145/2702123.2702411},
abstract = {Striking up a good conversation with new acquaintances is often a difficult problem.
In this paper we report on the perceptions of wearable device users who were given
real-time personalized topic suggestions during a conversation with a person they
just met. Suggestions were generated using a ranking recommendation algorithm, and
were delivered via Google Glasses. We conducted a study with 38 pairs of strangers,
who received such suggestions while conversing for the first time. Participants found
the suggestions to be helpful, but only at the right moments, and for certain types
of speakers. Our results contribute to the understanding of how communication interventions
influence people's experience and behaviors, and enhance interpersonal interactions.
Our study also presents design implications for applications on wearable devices to
facilitate conversations between strangers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {555–564},
numpages = {10},
keywords = {conversations, personalization, strangers, topic suggestion},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702314,
author = {Damian, Ionut and Tan, Chiew Seng (Sean) and Baur, Tobias and Sch\"{o}ning, Johannes and Luyten, Kris and Andr\'{e}, Elisabeth},
title = {Augmenting Social Interactions: Realtime Behavioural Feedback Using Social Signal Processing Techniques},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702314},
doi = {10.1145/2702123.2702314},
abstract = {Nonverbal and unconscious behaviour is an important component of daily human-human
interaction. This is especially true in situations such as public speaking, job interviews
or information sensitive conversations, where researchers have shown that an increased
awareness of one's behaviour can improve the outcome of the interaction. With wearable
technology, such as Google Glass, we now have the opportunity to augment social interactions
and provide realtime feedback on one's behaviour in an unobtrusive way. In this paper
we present Logue, a system that provides realtime feedback on the presenters' openness,
body energy and speech rate during public speaking. The system analyses the user's
nonverbal behaviour using social signal processing techniques and gives visual feedback
on a head-mounted display. We conducted two user studies with a staged and a real
presentation scenario which yielded that Logue's feedback was perceived helpful and
had a positive impact on the speaker's performance.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {565–574},
numpages = {10},
keywords = {peripheral feedback, social signal processing, behaviour analysis, computer-enhanced interaction},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251801,
author = {Wakkary, Ron},
title = {Session Details: Reflecting Upon Design Reflection},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251801},
doi = {10.1145/3251801},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702221,
author = {Odom, William},
title = {Understanding Long-Term Interactions with a Slow Technology: An Investigation of Experiences with FutureMe},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702221},
doi = {10.1145/2702123.2702221},
abstract = {Emerging over a decade ago, slow technology is a design philosophy aimed at supporting
experiences of reflection through and on technology in everyday life. Recent research
has suggested that slow technologies can open up new forms of interaction with digital
content that support self-reflection and re-visitation of the past. However, little
work has investigated people's long-term interactions with systems that embody this
design strategy. To investigate, a qualitative study with 31 participants was conducted
to understand their long-term experiences with FutureMe-a slow technology that has
been in use for over twelve years by more than one million people. Findings reveal
that, despite its simplicity, FutureMe produced a range of outcomes-from profound
reminiscence to unsettling encounters. Findings are interpreted to present opportunities
and implications for future research and practice initiatives.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {575–584},
numpages = {10},
keywords = {temporality, slow technology, reflection, memories},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702234,
author = {Baumer, Eric P.S.},
title = {Reflective Informatics: Conceptual Dimensions for Designing Technologies of Reflection},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702234},
doi = {10.1145/2702123.2702234},
abstract = {Despite demonstrated interest in designing for reflection, relatively little work
provides a detailed explication of what exactly is meant by reflection or how to design
around it. This paper fills that gap by reviewing and engaging with conceptual and
theoretical models of reflection, organized by the disciplinary and epistemological
perspectives each embodies. Synthesizing across this theoretical background, the paper
identifies three dimensions of reflection: breakdown, inquiry, and transformation.
Together, these dimensions serve as the foundation for reflective informatics, a conceptual
approach that helps bring clarity and guidance to the discussion of designing for
reflection. The paper distinguishes reflective informatics by demonstrating how it
both differs from and complements existing related work. Finally, the paper provides
a critically reflexive consideration of its own latent assumptions, especially about
the value of reflection, and how they might impact work on designing for reflection.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {585–594},
numpages = {10},
keywords = {reflection, reflective informatics, reflective hci, design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702323,
author = {Tanahashi, Yuzuru and Ma, Kwan-Liu},
title = {Stock Lamp: An Engagement-Versatile Visualization Design},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702323},
doi = {10.1145/2702123.2702323},
abstract = {Design methodologies for information visualizations are typically based on the assumption
that the users will be fully engaged in the visual exploration of the displayed information.
However, recent research suggests that there is an increasing diversity in how users
engage with modern visualizations, and that the traditional design theories do not
always satisfy the varied users needs. In this paper, we present a new design concept,
engagement-versatile design, for visualizations that target users with a variety of
engagement styles. Without losing generality, we demonstrate the feasibility of this
concept through the designing of a system called Stock Lamp, an engagement-versatile
visualization that helps users keep track of the stock market in real-time. This design
process includes identifying different modes of engagement, deriving design implications
from each engagement-mode, and applying them to the visualization's design. Our user
study shows that Stock Lamp is able to consistently relay market information even
when the users are multi-tasking. We believe this study establishes a new concept
that promotes a systematic design approach that leverages both theoretical and empirical
design methodologies for future visualization development.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {595–604},
numpages = {10},
keywords = {design concept, visualization usability, user engagement},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702485,
author = {Matthews, Mark and Snyder, Jaime and Reynolds, Lindsay and Chien, Jacqueline T. and Shih, Adam and Lee, Jonathan W. and Gay, Geri},
title = {Real-Time Representation Versus Response Elicitation in Biosensor Data},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702485},
doi = {10.1145/2702123.2702485},
abstract = {Recognized stress management techniques include cultivating mindfulness, breathing
exercises, and meditation. While these approaches have been shown to mitigate the
negative effects of stress, they can be difficult to learn or consistently apply.
To support these techniques, we developed MoodLight, a playful system that uses ambient
colored light to provide feedback regarding an individual's current arousal levels.
Like many affective computing systems, MoodLight was designed to help users observe
their internal state and learn to relax. However, our findings indicate that prompting
or leading feedback can be more effective than real time feedback in helping users
relax. This work contributes to affective computing by suggesting alternative approaches
to designing biofeedback systems for stress management.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {605–608},
numpages = {4},
keywords = {affective computing, stress management, biosensors},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251802,
author = {Do, Ellen Yi-Luen},
title = {Session Details: Makers &amp; Hackers},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251802},
doi = {10.1145/3251802},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702550,
author = {Wakkary, Ron and Schilling, Markus Lorenz and Dalton, Matthew A. and Hauser, Sabrina and Desjardins, Audrey and Zhang, Xiao and Lin, Henry W.J.},
title = {Tutorial Authorship and Hybrid Designers: The Joy (and Frustration) of DIY Tutorials},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702550},
doi = {10.1145/2702123.2702550},
abstract = {Tutorials are critical to the success and vitality of DIY practices. In this paper,
we elevate the importance of tutorial authorship as one way to maintain and improve
the quality of tutorials in DIY. We discuss the role interaction designers can play
as hybrid designers, mediating between author and audience to contribute to the improvement
of practices of tutorial authorship in DIY. We examine the quality of tutorials through
the building and analysis of ten DIY projects and tutorials. We analyze key issues
across three categories: 1) competences, components and tools, 2) sequencing, 3) and
communication. We offer findings that are both practical guidelines for detailed improvements
of tutorials and structural themes for improving tutorial authorship including the
themes of accurate information, competences and tools, and tutorial format. In conclusion,
we discuss the potential for interaction designers to simultaneously mediate and shape
tutorials and tools in a form of hybrid design.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {609–618},
numpages = {10},
keywords = {diy, tutorials, hybrid designer, interaction design, authorship, making culture},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702362,
author = {Jacobs, Jennifer and Zoran, Amit},
title = {Hybrid Practice in the Kalahari: Design Collaboration through Digital Tools and Hunter-Gatherer Craft},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702362},
doi = {10.1145/2702123.2702362},
abstract = {People have been making things for a long time, yet digital making has developed mostly
within an industrial context. We question how non-digital craft cultures can inform
the design of digital tools. Furthermore, what methods can help us understand these
cultures in ways that are relevant to digital practice? As makers ourselves, we see
potential for collaborative making to mitigate barriers in communication and provide
insight into non-digital practices and values. To evaluate this approach, we visited
a hunter-gatherer community that preserves an ancient craft, bringing with us digital
design and fabrication tools. Working together, we merged digital tools with ostrich
eggshell jewelry craft. We use this experience to draw conclusions about making as
a form of communication, the importance of supporting appropriation and immediacy
in collaborations, the challenge of combining abstract design tools with concrete
approaches, and the value of incorporating design and making into communal life.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {619–628},
numpages = {10},
keywords = {computer-aided design (cad), digital fabrication, hybrid, design, hunter-gatherers, collaboration, craft},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702522,
author = {Toombs, Austin L. and Bardzell, Shaowen and Bardzell, Jeffrey},
title = {The Proper Care and Feeding of Hackerspaces: Care Ethics and Cultures of Making},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702522},
doi = {10.1145/2702123.2702522},
abstract = {Communities of making have been at the center of attention in popular, business, political,
and academic research circles in recent years. In HCI, they seem to carry the promise
of new forms of computer use, education, innovation, and even ways of life. In the
West in particular, the maker manifestos of these communities have shown strong elements
of a neoliberal ethos, one that prizes self-determination, tech-savvy, independence,
freedom from government, suspicion of authority, and so forth. Yet such communities,
to function as communities, also require values of collaboration, cooperation, interpersonal
support-in a word, care. In this ethnographic study, we studied and participated as
members of a hackerspace for 19 months, focusing in particular not on their technical
achievements, innovations, or for glimmers of a more sustainable future, but rather
to make visible and to analyze the community maintenance labor that helps the hackerspace
support the practices that its members, society, and HCI research are so interested
in. We found that the maker ethic entails a complex negotiation of both a neoliberal
libertarian ethos and a care ethos.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {629–638},
numpages = {10},
keywords = {hci, hackerspace, ethnography, care, care ethics},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702175,
author = {Oehlberg, Lora and Willett, Wesley and Mackay, Wendy E.},
title = {Patterns of Physical Design Remixing in Online Maker Communities},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702175},
doi = {10.1145/2702123.2702175},
abstract = {Makers participate in remixing culture by drawing inspiration from, combining, and
adapting designs for physical objects. To examine how makers remix each others' designs
on a community scale, we analyzed metadata from over 175,000 digital designs from
Thingiverse, the largest online design community for digital fabrication. Remixed
designs on Thingiverse are predominantly generated designs from Customizer a built-in
web app for adjusting parametric designs. However, we find that these designs do not
elicit subsequent user activity and the authors who generate them tend not to contribute
additional content to Thingiverse. Outside of Customizer, influential sources of remixing
include complex assemblies and design primitives, as well as non-physical resources
posing as physical designs. Building on our findings, we discuss ways in which online
maker communities could become more than just design repositories and better support
collaborative remixing.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {639–648},
numpages = {10},
keywords = {hacking, remixing, customization, maker communities, user innovation, collaboration},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251803,
author = {Rohs, Michael},
title = {Session Details: How Fast Can You Type on Your Phone?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251803},
doi = {10.1145/3251803},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702503,
author = {Fowler, Andrew and Partridge, Kurt and Chelba, Ciprian and Bi, Xiaojun and Ouyang, Tom and Zhai, Shumin},
title = {Effects of Language Modeling and Its Personalization on Touchscreen Typing Performance},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702503},
doi = {10.1145/2702123.2702503},
abstract = {Modern smartphones correct typing errors and learn user-specific words (such as proper
names). Both techniques are useful, yet little has been published about their technical
specifics and concrete benefits. One reason is that typing accuracy is difficult to
measure empirically on a large scale. We describe a closed-loop, smart touch keyboard
(STK) evaluation system that we have implemented to solve this problem. It includes
a principled typing simulator for generating human-like noisy touch input, a simple-yet-effective
decoder for reconstructing typed words from such spatial data, a large web-scale background
language model (LM), and a method for incorporating LM personalization. Using the
Enron email corpus as a personalization test set, we show for the first time at this
scale that a combined spatial-language model reduces word error rate from a pre-model
baseline of 38.4% down to 5.7%, and that LM personalization can improve this further
to 4.6%.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {649–658},
numpages = {10},
keywords = {mobile text entry, language modeling, keyboard error correction},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702135,
author = {Vertanen, Keith and Memmi, Haythem and Emge, Justin and Reyal, Shyam and Kristensson, Per Ola},
title = {VelociTap: Investigating Fast Mobile Text Entry Using Sentence-Based Decoding of Touchscreen Keyboard Input},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702135},
doi = {10.1145/2702123.2702135},
abstract = {We present VelociTap: a state-of-the-art touchscreen keyboard decoder that supports
a sentence-based text entry approach. VelociTap enables users to seamlessly choose
from three word-delimiter actions: pushing a space key, swiping to the right, or simply
omitting the space key and letting the decoder infer spaces automatically. We demonstrate
that VelociTap has a significantly lower error rate than Google's keyboard while retaining
the same entry rate. We show that intermediate visual feedback does not significantly
affect entry or error rates and we find that using the space key results in the most
accurate results. We also demonstrate that enabling flexible word-delimiter options
does not incur an error rate penalty. Finally, we investigate how small we can make
the keyboard when using VelociTap. We show that novice users can reach a mean entry
rate of 41 wpm on a 40 mm wide smartwatch-sized keyboard at a 3% character error rate.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {659–668},
numpages = {10},
keywords = {sentence decoding, touchscreen keyboard, mobile text entry},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702388,
author = {Leiva, Luis A. and Sahami, Alireza and Catala, Alejandro and Henze, Niels and Schmidt, Albrecht},
title = {Text Entry on Tiny QWERTY Soft Keyboards},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702388},
doi = {10.1145/2702123.2702388},
abstract = {The advent of wearables (e.g., smartwatches, smartglasses, and digital jewelry) anticipates
the need for text entry methods on very small devices. We conduct fundamental research
on this topic using 3 qwerty-based soft keyboards for 3 different screen sizes, motivated
by the extensive training that users have with qwerty keyboards. In addition to ZoomBoard
(a soft keyboard for diminutive screens), we propose a callout-based soft keyboard
and ZShift, a novel extension of the Shift pointing technique. We conducted a comprehensive
user study followed by extensive analyses on performance, usability, and short-term
learning. Our results show that different small screen sizes demand different types
of assistance. In general, manufacturers can benefit from these findings by selecting
an appropriate qwerty soft keyboard for their devices. Ultimately, this work provides
designers, researchers, and practitioners with new understanding of qwerty soft keyboard
design space and its scalability for tiny touchscreens.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {669–678},
numpages = {10},
keywords = {text entry, small screens, small devices, qwerty},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702597,
author = {Reyal, Shyam and Zhai, Shumin and Kristensson, Per Ola},
title = {Performance and User Experience of Touchscreen and Gesture Keyboards in a Lab Setting and in the Wild},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702597},
doi = {10.1145/2702123.2702597},
abstract = {We study the performance and user experience of two popular mainstream mobile text
entry methods: the Smart Touch Keyboard (STK) and the Smart Gesture Keyboard (SGK).
Our first study is a lab-based ten-session text entry experiment. In our second study
we use a new text entry evaluation methodology based on the experience sampling method
(ESM). In the ESM study, participants installed an Android app on their own mobile
phones that periodically sampled their text entry performance and user experience
amid their everyday activities for four weeks. The studies show that text can be entered
at an average speed of 28 to 39 WPM, depending on the method and the user's experience,
with 1.0% to 3.6% character error rates remaining. Error rates of touchscreen input,
particularly with SGK, are a major challenge; and reducing out-of-vocabulary errors
is particularly important. Both SGK and STK have strengths, weaknesses, and different
individual awareness and preferences. Two-thumb touch typing in a focused setting
is particularly effective on STK, whereas one-handed SGK typing with the thumb is
particularly effective in more mobile situations. When exposed to both, users tend
to migrate from STK to SGK. We also conclude that studies in the lab and in the wild
can both be informative to reveal different aspects of keyboard experience, but used
in conjunction is more reliable in comprehensively assessing input technologies of
current and future generations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {679–688},
numpages = {10},
keywords = {experience sampling, gesture keyboard, mobile text entry},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251804,
author = {Quintana, Chris},
title = {Session Details: Understand &amp; Enhancing Learning},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251804},
doi = {10.1145/3251804},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702349,
author = {Lee, Yi-Chieh and Lin, Wen-Chieh and Cherng, Fu-Yin and Wang, Hao-Chuan and Sung, Ching-Ying and King, Jung-Tai},
title = {Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702349},
doi = {10.1145/2702123.2702349},
abstract = {Online learning is increasingly prevalent as an option for self-learning and as a
resource for instructional design. Prerecorded video is currently the main medium
of online education content delivery and instruction; this affords asynchronicity
and flexibility, and enables the dissemination of lecture content in a distributed
and scalable manner. However, the same properties may impede learners' engagement
due to the lack of social interaction and peer support. In this paper, we propose
a time-anchored commenting interface to allow online learners who watch the same video
clips to exchange comments on them. Comments left by previous learners at specific
time points of a video are displayed to new learners when they watch the same video
and reach those time points. We investigated how the display of time-anchored comments
(dynamic or static) and type of comments (content-related or social-oriented) influenced
users' perceived engagement, perceived social interactivity, and learning outcomes.
Our results show that dynamically displaying time-anchored comments can indeed enhance
learners' perceived social interactivity. Moreover, the content of comments would
further affect learners' intention of commenting. Based on our findings, we make various
recommendations for the improvement of social interaction and learning experience
in online education.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {689–698},
numpages = {10},
keywords = {asynchronous communication., online educational interface, e-learning, synchronous communication},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702303,
author = {Bianchi, Andrea and Ban, So-Ryang and Oakley, Ian},
title = {Designing a Physical Aid to Support Active Reading on Tablets},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702303},
doi = {10.1145/2702123.2702303},
abstract = {Tablet computers and portable eReaders are gradually becoming the preferred platform
for the consumption of textual materials. However, although these technologies are
powerful, it is widely acknowledged that print documents better support the advanced
active reading tasks necessary to gain a deep understanding of a text. While prior
work to address this issue has aimed improve digital eReaders by either leveraging
familiar physical affordances or by extending paper's capabilities with digital tools,
in this paper we propose a juncture of these two approaches. We first present a formative
study that captures the needs and requirements of users during active reading tasks
with tablets. We instantiate the findings in the design of a simple physical aid to
support active reading: a smart bookmark. We then define an interaction space for
this device, describe a set of interfaces designed to facilitate active reading and
close with a user study that assesses the potential of the bookmark device and interaction
techniques.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {699–708},
numpages = {10},
keywords = {etab, tablet, tangible, active reading, bookmark, ereader},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251805,
author = {Lindley, Si\^{a}n},
title = {Session Details: Family Communication},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251805},
doi = {10.1145/3251805},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702356,
author = {Cramer, Henriette and Jacobs, Maia L.},
title = {Couples' Communication Channels: What, When &amp; Why?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702356},
doi = {10.1145/2702123.2702356},
abstract = {An overwhelming variety of communication channels are available to consumers. Here,
we present an overview of the aspects that need to be accounted for when intimate
partners select a communication channel. We present interviews with 10 cohabiting
couples (20 participants) and an 8-day diary study of communication and coordination.
Using reported instances of within-couple communication, triggered by relationship-oriented
or practical household needs, we identify why particular channels are chosen or sequenced.
Extending media richness critiques, we identify additional factors that influence
communication choice such as intimate knowledge of the others' habits, possibilities
to add emotional meaning, and couples' shared needs as an identifiable unit. We also
extend the notion of network effects on channel choice, and discuss the ecology of
channel, networks, devices and device settings involved between partners. Finally,
channel choice is not an all-or-nothing game; multiple channels can, and must, co-exist.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {709–712},
numpages = {4},
keywords = {communicational channel choice, couples},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702462,
author = {Brereton, Margot and Soro, Alessandro and Vaisutis, Kate and Roe, Paul},
title = {The Messaging Kettle: Prototyping Connection over a Distance between Adult Children and Older Parents},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702462},
doi = {10.1145/2702123.2702462},
abstract = {A prototype "messaging kettle" is described. The connected kettle aims to foster communication
and engagement with an older friend or relative who lives remotely, during the routine
of boiling the kettle. We describe preliminary encounters and findings from demonstrating
a working prototype in morning tea gatherings of people in their 50s-late 70s and
from introducing it into the homes of two people in their 80s who live on another
continent. Key findings are that: The concept of keeping in touch around a "habituated
object" such as a kettle was well received; Simple and varied interaction modalities
that allow asymmetric forms of communication are needed; Designing for use across
different time zones requires attention; And, that even when augmenting a habituated
object, the process of introduction, appropriation and habituation still needs significant
attention and investigation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {713–716},
numpages = {4},
keywords = {elderly, internet of things, habituation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702301,
author = {Melvin, Roberta M. and Bunt, Andrea and Oduor, Erick and Neustaedter, Carman},
title = {The Effect of Signal Expense and Dependability on Family Communication in Rural and Northern Canada},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702301},
doi = {10.1145/2702123.2702301},
abstract = {Family communication and technology designed to support it is a widely studied topic.
However, most research that focuses on family communication in North America tends
to assume high degrees of connectivity and Internet access. We present a study of
family communication practices in rural and northern areas of Manitoba, Canada where
Internet connectivity is intermittent or severely limited in some communities. Our
results show the ways in which individuals stay connected with outside relatives can
be hampered by communication infrastructure challenges. In particular, these challenges
can dictate how, where and how often conversations with loved ones take place. Our
results also indicate that these experiences, many of which are negative, can create
lasting impressions that may be difficult to alter as infrastructure improves. This
suggests opportunities for designing family communication technologies for outdoor
locations with better connectivity, scheduling communication during times with better
connectivity, and combating social isolation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {717–726},
numpages = {10},
keywords = {ict4d, mobile devices, rural environment, awareness, family communication},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702199,
author = {Hiniker, Alexis and Sobel, Kiley and Suh, Hyewon and Sung, Yi-Chen and Lee, Charlotte P. and Kientz, Julie A.},
title = {Texting While Parenting: How Adults Use Mobile Phones While Caring for Children at the Playground},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702199},
doi = {10.1145/2702123.2702199},
abstract = {Child development research suggests that using phones while caring for children can
be problematic, but limited prior work in this space makes defining appropriate use
challenging. We conducted the first exploration of whether adults feel pressure to
limit phone use in this context and whether they choose to do so. Through mixed methods,
we collected data from 466 adult caregivers at playgrounds. We found that phone use
was a small part of playground time, yet a notable source of guilt. Adults engaged
in systematic and specific phone-use and phone-non-use behaviors in order to prioritize
their children above themselves. Our results indicate that caregiver values and self-control
together predict behavior and can be used to model phone use in this context. Users'
mixed success with engaging in intentional periods of non-use suggests that a design
agenda which prioritizes cycles of engagement, disengagement, and re-engagement may
be of value to this group.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {727–736},
numpages = {10},
keywords = {children, mobile phones, mindfulness, parents, families, non-use},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702427,
author = {Fourney, Adam and White, Ryen W. and Horvitz, Eric},
title = {Exploring Time-Dependent Concerns about Pregnancy and Childbirth from Search Logs},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702427},
doi = {10.1145/2702123.2702427},
abstract = {We study time-dependent patterns of information seeking about pregnancy, birth, and
the first several weeks of caring for newborns via analyses of queries drawn from
anonymized search engine logs. We show how we can detect and align web search behavior
for a population of searchers with the natural clock of gestational physiology via
proxies for ground truth based on searchers' self-report queries (e.g., [I am 30 weeks
pregnant and my baby is moving a lot]). Then, we present a methodology for performing
additional alignments, that are valuable for learning about the concerns, curiosities,
and needs that arise over time with pregnancy and early parenting. Our findings have
implications for learning about the temporal dynamics of pregnancy-related interests
and concerns, and also for the design of systems that tailor their responses to point
estimates of each searcher's current stage in pregnancy.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {737–746},
numpages = {10},
keywords = {childbirth, search, health, temporal processes, pregnancy},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251806,
author = {Lawson, Shaun},
title = {Session Details: Crowdsourcing Fans &amp; Friends},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251806},
doi = {10.1145/3251806},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702463,
author = {Flintham, Martin D. and Velt, Raphael and Wilson, Max L. and Anstead, Edward J. and Benford, Steve and Brown, Anthony and Pearce, Timothy and Price, Dominic and Sprinks, James},
title = {Run Spot Run: Capturing and Tagging Footage of a Race by Crowds of Spectators},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702463},
doi = {10.1145/2702123.2702463},
abstract = {There has been a massive growth in the number of people who film and upload amateur
footage of events to services such as Facebook and Youtube, or even stream live to
services such as LiveStream. We present an exploratory study that investigates the
potential of these spectators in creating footage en masse; in this case, during a
live trial at a local marathon. We deployed a prototype app, RunSpotRun, as a technology
probe to see what kinds of footage spectators would produce. We present an analysis
of this footage in terms of its coverage, quality, and contents, and also discuss
the implications for a) spectators enjoying the race, and b) extracting the stories
of individual runners throughout the race. We conclude with a discussion of the challenges
that remain for deploying such technology at a larger scale.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {747–756},
numpages = {10},
keywords = {story telling, public settings, video, marathon, tagging, crowd sourcing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702338,
author = {Curmi, Franco and Ferrario, Maria Angela and Whittle, Jon and Mueller, Florian 'Floyd'},
title = {Crowdsourcing Synchronous Spectator Support: (Go on, Go on, You're the Best)<sup>n-1</sup>},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702338},
doi = {10.1145/2702123.2702338},
abstract = {Many studies have shown that crowd-support, such as cheering during sport events,
can have a positive impact on athletes' performance. However, up until recently this
support was only possible if the supporters and the athletes were geographically co-located.
Can cheering be done remotely and would this be effective? In this paper we investigate
the effect and possibilities of live remote cheering on co-located athletes and online
supporting crowds that have a weak social tie and no social tie with the athlete.
We recruit 140 online spectators and 5 athletes for an ad-hoc 5km road race. Results
indicate that crowds socially closer to the athletes are significantly more engaged
in the support. The athletes were excited by live remote cheering from friendsourced
spectators and cheering from unknown crowdsourced participants indicating that remote
friends and outsourced spectators could be an important source of support.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {757–766},
numpages = {10},
keywords = {friendsourcing, crowdsourcing, sports, spectators, spectator support, social networks, cheering, broadcast, human behavior},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702229,
author = {Schofield, Guy and Bartindale, Tom and Wright, Peter},
title = {Bootlegger: Turning Fans into Film Crew},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702229},
doi = {10.1145/2702123.2702229},
abstract = {Bootlegger is a system for creating multi-camera films of live music events using
mobile devices. Using readily available technology and a synthesis of film-making
conventions, the system coordinates music fans at live shows into an improvised film
crew, suggesting shots, collating footage and generating rich metadata in real time.
Bootlegger is part of a research project exploring adapting professional media workflows
to amateur contexts in order to lower the bar to entry for media production. By enabling
concert-goers to contribute to high-quality concert films, the system leverages mobile
phone 'bootlegging' practices to support emerging musicians.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {767–776},
numpages = {10},
keywords = {user-generated content, diy, amateur video, digital video, bootlegging, mobile},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702402,
author = {Hong, Hwajung and Gilbert, Eric and Abowd, Gregory D. and Arriaga, Rosa I.},
title = {In-Group Questions and Out-Group Answers: Crowdsourcing Daily Living Advice for Individuals with Autism},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702402},
doi = {10.1145/2702123.2702402},
abstract = {Difficulty in navigating daily life can lead to frustration and decrease independence
for people with autism. While they turn to online autism communities for information
and advice for coping with everyday challenges, these communities may present only
a limited perspective because of their in-group nature. Obtaining support from out-group
sources beyond the in-group community may prove valuable in dealing with challenging
situations such as public anxiety and workplace conflicts. In this paper, we explore
the value of supplementary out-group support from crowdsourced responders added to
in-group support from a community of members. We find that out-group sources provide
relatively rapid, concise responses with direct and structured information, socially
appropriate coping strategies without compromising emotional value. Using an autism
community as a motivating example, we conclude by providing design implications for
combining in-group and out-group resources that may enhance the question-and-answer
experience.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {777–786},
numpages = {10},
keywords = {online community, out-group, q&amp;a, autism, crowdsourcing, social support, in-group},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251807,
author = {Patil, Sameer},
title = {Session Details: Managing Personal Privacy},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251807},
doi = {10.1145/3251807},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702210,
author = {Almuhimedi, Hazim and Schaub, Florian and Sadeh, Norman and Adjerid, Idris and Acquisti, Alessandro and Gluck, Joshua and Cranor, Lorrie Faith and Agarwal, Yuvraj},
title = {Your Location Has Been Shared 5,398 Times! A Field Study on Mobile App Privacy Nudging},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702210},
doi = {10.1145/2702123.2702210},
abstract = {Smartphone users are often unaware of the data collected by apps running on their
devices. We report on a study that evaluates the benefits of giving users an app permission
manager and sending them nudges intended to raise their awareness of the data collected
by their apps. Our study provides both qualitative and quantitative evidence that
these approaches are complementary and can each play a significant role in empowering
users to more effectively control their privacy. For instance, even after a week with
access to the permission manager, participants benefited from nudges showing them
how often some of their sensitive data was being accessed by apps, with 95% of participants
reassessing their permissions, and 58% of them further restricting some of their permissions.
We discuss how participants interacted both with the permission manager and the privacy
nudges, analyze the effectiveness of both solutions, and derive some recommendations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {787–796},
numpages = {10},
keywords = {privacy nudges, mobile, privacy decision making, privacy},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702274,
author = {Warshaw, Jeffrey and Matthews, Tara and Whittaker, Steve and Kau, Chris and Bengualid, Mateo and Smith, Barton A.},
title = {Can an Algorithm Know the "Real You"? Understanding People's Reactions to Hyper-Personal Analytics Systems},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702274},
doi = {10.1145/2702123.2702274},
abstract = {Recent research has developed analytics that threaten online self-presentation and
privacy by automatically generating profiles of individuals' most personal traits-their
personality, values, motivations, and so on. But we know little about people's reactions
to personal traits profiles of themselves, or what influences their decisions to share
such profiles. We present an early qualitative study of people's reactions to a working
hyper-personal analytics system. The system lets them see their personality and values
profile derived from their own social media text. Our results reveal a paradox. Participants
found their personal traits profiles creepily accurate and did not like sharing them
in many situations. However, they felt pressured by the social risks of not sharing
and showed signs of learned helplessness, leading them to share despite their misgivings.
Further, they felt unqualified to significantly modify their profile contents due
to a surprising trust in the "expert" algorithm. We explore design implications for
hyper-personal analytics systems that consider the needs and preferences of the people
being profiled, suggesting ways to enhance the control they feel and the benefits
they reap.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {797–806},
numpages = {10},
keywords = {privacy, hyper-personal analytics, user study, self-presentation, social media, personality, values},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702404,
author = {Shih, Fuming and Liccardi, Ilaria and Weitzner, Daniel},
title = {Privacy Tipping Points in Smartphones Privacy Preferences},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702404},
doi = {10.1145/2702123.2702404},
abstract = {The aim of this research was to understand what affects people's privacy preferences
in smartphone apps. We ran a four-week study in the wild with 34 participants. Participants
were asked to answer questions, which were used to gather their personal context and
to measure their privacy preferences by varying app name and purpose of data collection.
Our results show that participants shared the most when no information about data
access or purpose was given, and shared the least when both of these details were
specified. When just one of either purpose or the requesting app was shown, participants
shared less when just the purpose was specified than when just the app name was given.
We found that the purpose for data access was the predominant factor affecting users'
choices. In our study the purpose condition vary from being not specified, to vague
to be very specific. Participants were more willing to disclose data when no purpose
was specified. When a vague purpose was shown, participants became more privacy-aware
and were less willing to disclose their information. When specific purposes were shown
participants were more willing to disclose when the purpose for requesting the information
appeared to be beneficial to them, and shared the least when the purpose for data
access was solely beneficial to developers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {807–816},
numpages = {10},
keywords = {experience sampling, privacy preferences, android},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702293,
author = {Wang, Yang and Gou, Liang and Xu, Anbang and Zhou, Michelle X. and Yang, Huahai and Badenes, Hernan},
title = {VeilMe: An Interactive Visualization Tool for Privacy Configuration of Using Personality Traits},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702293},
doi = {10.1145/2702123.2702293},
abstract = {With the recent advances in using data analytics to automatically infer one's personality
traits from their social media data, users are facing a growing tension between the
use of the technology to aid self development in workplace and the privacy concerns
of such use. Given the richness of personality data that can be derived today and
the varied sensitivity of revealing such data, it is a non-trivial task for users
to configure their privacy settings for sharing and protecting their derived personality
data. Here we present the design, development, and evaluation of an interactive visualization
tool, VeilMe, which helps users configure the privacy settings for the use of their
personality portraits derived from social media. Unlike other privacy configuration
tools, our tool offers two distinct advantages. First, it presents a novel and intuitive
visual interface that aids users in understanding and exploring their own personality
traits derived from their social media data, and configuring their privacy preferences.
Second, our tool helps users to jump start their privacy settings by suggesting initial
sharing strategies based on a set of factors, including the users' personality and
target audience. We have evaluated the use of our tool with 124 participants in an
enterprise context. Our results show that VeilMe effectively supports various user
privacy configuration tasks, and also suggest several design implications, including
the approaches to personalized privacy configurations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {817–826},
numpages = {10},
keywords = {sharing settings, social media, personality traits, visual interface, privacy},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251808,
author = {Mandryk, Regan},
title = {Session Details: Health Sensors &amp; Monitoring},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251808},
doi = {10.1145/3251808},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702192,
author = {Skov, Mikael B. and Johansen, Pauline G. and Skov, Charlotte S. and Lauberg, Astrid},
title = {No News is Good News: Remote Monitoring of Implantable Cardioverter-Defibrillator Patients},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702192},
doi = {10.1145/2702123.2702192},
abstract = {Implantable cardioverter-defibrillator (ICD) patients have increased safety when connected
to remote monitoring as ICD problems and issues are instantly discovered compared
to patients without a monitor. While remote monitoring is intrusive in the domestic
environment, little HCI research has investigated how people live and interact with
such monitoring technologies. We conducted a study with 19 ICD patients and their
spouses using diaries and interviews. Our findings illustrate that our participants
were satisfied with the monitoring despite the fact that they had almost no knowledge
of the data collected and they lacked feedback from the monitor on transmission and
operation. Based on our findings, we describe a safety paradox for remote monitoring
as participants experienced less safety while being safer, and identify privacy and
surveillance concerns in the unequal monitoring of ICD patients.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {827–836},
numpages = {10},
keywords = {icd, anxiety, implantable cardioverter defibrillator, privacy, surveillance, remote monitoring},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702200,
author = {Adib, Fadel and Mao, Hongzi and Kabelac, Zachary and Katabi, Dina and Miller, Robert C.},
title = {Smart Homes That Monitor Breathing and Heart Rate},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702200},
doi = {10.1145/2702123.2702200},
abstract = {The evolution of ubiquitous sensing technologies has led to intelligent environments
that can monitor and react to our daily activities, such as adapting our heating and
cooling systems, responding to our gestures, and monitoring our elderly. In this paper,
we ask whether it is possible for smart environments to monitor our vital signs remotely,
without instrumenting our bodies. We introduce Vital-Radio, a wireless sensing technology
that monitors breathing and heart rate without body contact. Vital-Radio exploits
the fact that wireless signals are affected by motion in the environment, including
chest movements due to inhaling and exhaling and skin vibrations due to heartbeats.
We describe the operation of Vital-Radio and demonstrate through a user study that
it can track users' breathing and heart rates with a median accuracy of 99%, even
when users are 8~meters away from the device, or in a different room. Furthermore,
it can monitor the vital signs of multiple people simultaneously. We envision that
Vital-Radio can enable smart homes that monitor people's vital signs without body
instrumentation, and actively contribute to their inhabitants' well-being.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {837–846},
numpages = {10},
keywords = {wireless, well-being, vital signs, breathing, smart homes, seeing through walls},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702502,
author = {Han, Teng and Xiao, Xiang and Shi, Lanfei and Canny, John and Wang, Jingtao},
title = {Balancing Accuracy and Fun: Designing Camera Based Mobile Games for Implicit Heart Rate Monitoring},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702502},
doi = {10.1145/2702123.2702502},
abstract = {Heart rate monitoring is widely used in clinical care, fitness training, and stress
management. However, tracking individuals' heart rates faces two major challenges,
namely equipment availability and user motivation. In this paper, we present a novel
technique, LivePulse Games (LPG), to measure users' heart rates in real time by having
them play games on unmodified mobile phones. With LPG, the heart rate is calculated
by detecting changes in transparency of users' fingertips via the built-in camera
of a mobile device. More importantly, LPG integrate users' camera lens covering actions
as an essential control mechanism in game play, and detect heart rates implicitly
from intermittent lens covering actions. We explore the design space and trade-offs
of LPG through three rounds of iterative design. In a 12-subject user study, we found
that LPG are fun to play and can measure heart rates accurately. We also report the
insights for balancing measurement speed, accuracy, and entertainment value in LPG.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {847–856},
numpages = {10},
keywords = {ecg, mobile phone, game design, multi-modal interface, quantified self, heart rate, serious game},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702399,
author = {Lyu, Yongqiang and Luo, Xiaomin and Zhou, Jun and Yu, Chun and Miao, Congcong and Wang, Tong and Shi, Yuanchun and Kameyama, Ken-ichi},
title = {Measuring Photoplethysmogram-Based Stress-Induced Vascular Response Index to Assess Cognitive Load and Stress},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702399},
doi = {10.1145/2702123.2702399},
abstract = {Quantitative assessment for cognitive load and mental stress is very important in
optimizing human-computer system designs to improve performance and efficiency. Traditional
physiological measures, such as heart rate variation (HRV), blood pressure and electrodermal
activity (EDA), are widely used but still have limitations in sensitivity, reliability
and usability. In this study, we propose a novel photoplethysmogram-based stress induced
vascular index (sVRI) to measure cognitive load and stress. We also provide the basic
methodology and detailed algorithm framework. We employed a classic experiment with
three levels of task difficulty and three stages of testing period to verify the new
measure. Compared with the blood pressure, heart rate and HRV components recorded
simultaneously, the sVRI reached the same level of significance on the effect of task
difficulty/period as the most significant other measure. Our findings showed sVRI's
potential as a sensitive, reliable and usable parameter.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {857–866},
numpages = {10},
keywords = {stress-induced vascular response index (svri), stress, photoplethysmogram, mental effort, cognitive load},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251809,
author = {Reiterer, Harald},
title = {Session Details: Collaborative Tables, Walls &amp; Rooms},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251809},
doi = {10.1145/3251809},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702231,
author = {Block, Florian and Hammerman, James and Horn, Michael and Spiegel, Amy and Christiansen, Jonathan and Phillips, Brenda and Diamond, Judy and Evans, E. Margaret and Shen, Chia},
title = {Fluid Grouping: Quantifying Group Engagement around Interactive Tabletop Exhibits in the Wild},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702231},
doi = {10.1145/2702123.2702231},
abstract = {Interactive surfaces are increasingly common in museums and other informal learning
environments where they are seen as a medium for promoting social engagement. However,
despite their increasing prevalence, we know very little about factors that contribute
to collaboration and learning around interactive surfaces. In this paper we present
analyses of visitor engagement around several multi-touch tabletop science exhibits.
Observations of 629 visitors were collected through two widely used techniques: video
study and shadowing. We make four contributions: 1) we present an algorithm for identifying
groups within a dynamic flow of visitors through an exhibit hall; 2) we present measures
of group-level engagement along with methods for statistically analyzing these measures;
3) we assess the effect of observational techniques on visitors' engagement, demonstrating
that consented video studies do not necessarily reflect visitor behavior in more naturalistic
circumstances; and 4) we present an analysis showing that groups of two, groups with
both children and adults, and groups that take turns spend longer at the exhibits
and engage more with scientific concepts.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {867–876},
numpages = {10},
keywords = {multi-touch tabletops, learning, museums, quantitative methods},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702286,
author = {Luff, Paul K. and Yamashita, Naomi and Kuzuoka, Hideaki and Heath, Christian},
title = {Flexible Ecologies And Incongruent Locations},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702286},
doi = {10.1145/2702123.2702286},
abstract = {In this paper we report on some experiments with a high fidelity media space, t-Room,
an immersive system that presents full scale, real-time images of co-participants.
The system has been enhanced to provide more flexibility in the ways participants
could organise themselves and the materials they are working on. Drawing on some quasi-naturalistic
experiments, where the participants were required to undertake a range of complex
tasks, we consider the formations they adopt and the issues and problems that arise
when they attempt to establish and preserve a common focus and alignment. We conclude
by briefly discussing the consequences for developing advanced spaces to support collaborative
work and understanding complex video-mediated interaction.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {877–886},
numpages = {10},
keywords = {interaction analysis, media spaces, cscw, embodied interaction},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702506,
author = {Reilly, Derek and Echenique, Andy and Wu, Andy and Tang, Anthony and Edwards, W. Keith},
title = {Mapping out Work in a Mixed Reality Project Room},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702506},
doi = {10.1145/2702123.2702506},
abstract = {We present results from a study examining how the physical layout of a project room
and task affect the cognitive maps acquired of a connected virtual environment during
mixed-presence collaboration. Results indicate that a combination of physical layout
and task impacts cognitive maps of the virtual space. Participants did not form a
strong model of how different physical work regions were situated relative to each
other in the virtual world when the tasks performed in each region differed. Egocentric
perspectives of multiple displays enforced by different furniture arrangements encouraged
cognitive maps of the virtual world that reflected these perspectives, when the displays
were used for the same task. These influences competed or coincided with document-based,
audiovisual and interface cues, influencing collaboration. We consider the implications
of our findings on WYSIWIS mappings between real and virtual for mixed-presence collaboration.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {887–896},
numpages = {10},
keywords = {display ecology, mixed reality, cognitive map, mixed presence, spatial cognition, cross reality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251810,
author = {Blythe, Mark},
title = {Session Details: The Value of Things},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251810},
doi = {10.1145/3251810},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702394,
author = {Bowser, Anne E. and Haimson, Oliver L. and Melcer, Edward F. and Churchill, Elizabeth F.},
title = {On Vintage Values: The Experience of Secondhand Fashion Reacquisition},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702394},
doi = {10.1145/2702123.2702394},
abstract = {Secondhand fashion is a rapidly growing, lucrative market with both off- and online
outlets. Studies of secondhand consumption have focused primarily on people's motivations
for secondhand shopping, highlighting sustainability and/or thrift. We extend this
work by looking at the motivations and practices of secondhand shoppers who are driven
instead by style, playfulness and treasure-hunting. We present findings from ethnographic
observation and interviews with 13 secondhand shoppers. Three secondhand shopping
orientations emerged. Perfection Seeking involves seeking items that fit with an individual
look or personal brand. These items are seen as unique, and demonstrate an alternative
to mainstream fashion and consumption. Casual curiosity is less focused, more engaged
in browsing, and driven by both secondhand objects and the secondhand experience itself.
Digging involves the focused pursuit of hidden "gems" or treasures, following the
belief that unusual items are waiting to be found. We offer ideas for designing secondhand
shopping experiences to support the needs for storytelling, experiential pleasure,
and negotiation around durable value.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {897–906},
numpages = {10},
keywords = {value-centered design, ecommerce consumption, recycling, fashion, field study, sustainable hci, recirculation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702137,
author = {Pritchard, Gary and Vines, John and Olivier, Patrick},
title = {Your Money's No Good Here: The Elimination of Cash Payment on London Buses},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702137},
doi = {10.1145/2702123.2702137},
abstract = {As digital payments become increasingly important features of economic exchange, traditional
forms of payment such as cash are becoming phased out in certain settings. We study
one such context-the elimination of cash payment on London buses in July 2014. We
conducted ethnographic fieldwork, interviews with drivers and collected online and
social media comments before, during and shortly after the introduction of cashless
fares. We explore how drivers and passengers were fearful of the change due in part
to a lack of information and communication, the anticipation of negative effects on
vulnerable passengers and a compromise in freedom, flexibility and surveillance. We
highlight the ways cashless payments can alter the social function of money, create
new forms of work for drivers and passengers, and if not carefully introduced can
cause emotional stress and fears of state surveillance and control.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {907–916},
numpages = {10},
keywords = {electronic payments, cashless, public transport, contactless},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702408,
author = {Gunaratne, Junius and Nov, Oded},
title = {Informing and Improving Retirement Saving Performance Using Behavioral Economics Theory-Driven User Interfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702408},
doi = {10.1145/2702123.2702408},
abstract = {Can human-computer interaction help people make informed and effective decisions about
their retirement savings? We applied the behavioral economic theories of endowment
effect and loss aversion to the design of novel retirement saving user interfaces.
To examine effectiveness, we conducted an experiment in which 487 participants were
exposed to one of three experimental user interface designs of a retirement saving
simulator, representing endowment effect, loss aversion and control. Users made 34
yearly asset allocation decisions. We found that designs informed by the endowment
effect and loss aversion theories and which communicated to savers the long-term implications
of their asset allocation choices, led users to adjust their behavior, make larger
and more frequent asset allocation changes, and achieve their saving goals more effectively.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {917–920},
numpages = {4},
keywords = {behavioral economics, persuasive technology, retirement saving, financial literacy., personal finance, behavior change},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251696,
author = {Harrison, Chris},
title = {Session Details: Muscle-Computer Interfaces},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251696},
doi = {10.1145/3251696},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702501,
author = {Amma, Christoph and Krings, Thomas and B\"{o}er, Jonas and Schultz, Tanja},
title = {Advancing Muscle-Computer Interfaces with High-Density Electromyography},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702501},
doi = {10.1145/2702123.2702501},
abstract = {In this paper we present our results on using electromyographic (EMG) sensor arrays
for finger gesture recognition. Sensing muscle activity allows to capture finger motion
without placing sensors directly at the hand or fingers and thus may be used to build
unobtrusive body-worn interfaces. We use an electrode array with 192 electrodes to
record a high-density EMG of the upper forearm muscles. We present in detail a baseline
system for gesture recognition on our dataset, using a naive Bayes classifier to discriminate
the 27 gestures. We recorded 25 sessions from 5 subjects. We report an average accuracy
of 90% for the within-session scenario, showing the feasibility of the EMG approach
to discriminate a large number of subtle gestures. We analyze the effect of the number
of used electrodes on the recognition performance and show the benefit of using high
numbers of electrodes. Cross-session recognition typically suffers from electrode
position changes from session to session. We present two methods to estimate the electrode
shift between sessions based on a small amount of calibration data and compare it
to a baseline system with no shift compensation. The presented methods raise the accuracy
from 59% baseline accuracy to 75% accuracy after shift compensation. The dataset is
publicly available.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {929–938},
numpages = {10},
keywords = {emg, gesture recognition, muscle-computer-interfaces, electrode arrays},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702461,
author = {Lopes, Pedro and Ion, Alexandra and Mueller, Willi and Hoffmann, Daniel and Jonell, Patrik and Baudisch, Patrick},
title = {Proprioceptive Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702461},
doi = {10.1145/2702123.2702461},
abstract = {We propose a new way of eyes-free interaction for wearables. It is based on the user's
proprioceptive sense, i.e., rather than seeing, hearing, or feeling an outside stimulus,
users feel the pose of their own body. We have implemented a wearable device called
Pose-IO that offers input and output based on proprioception. Users communicate with
Pose-IO through the pose of their wrists. Users enter information by performing an
input gesture by flexing their wrist, which the device senses using a 3-axis accelerometer.
Users receive output from Pose-IO by find-ing their wrist posed in an output gesture,
which Pose-IO actuates using electrical muscle stimulation. This mechanism allows
users to interact with Pose-IO without visual or auditory senses, but through the
proprioceptive sense alone. We developed three simple applications that demonstrate
symmetric proprioceptive interaction, where input and output occur through the same
limb, as well as asymmetric interaction, where input and output occur through different
limbs. In a first user study, participants using a symmetric proprioceptive interface
re-entered poses received from Pose-IO with an average accuracy of 5.8° despite the
minimal bandwidth offered by the device. In a second, exploratory study, we investigated
participants' emotional response to asymmetric proprioceptive interaction and the
concept of the user's body serving as interface. Participants reported to enjoy the
experience (4.6 out of 5).},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {939–948},
numpages = {10},
keywords = {muscle actuation, io, proprioception},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251697,
author = {Yamashita, Naomi},
title = {Session Details: Phones for More than Just Talking &amp; Text},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251697},
doi = {10.1145/3251697},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702159,
author = {Heller, Florian and Borchers, Jan},
title = {AudioScope: Smartphones as Directional Microphones in Mobile Audio Augmented Reality Systems},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702159},
doi = {10.1145/2702123.2702159},
abstract = {Mobile audio augmented reality systems (MAARS) provide a new and engaging modality
to present information or to create playful experiences. Using special filters, spatial
audio rendering creates the impression that the sound of a virtual source emanates
from a certain position in the physical space. So far, most of the implementations
of such systems rely on head tracking to create a realistic effect, which requires
additional hardware. Recent results indicate that the built-in sensors of a smartphone
can be used as source for orientation measurement, reducing deployment to a simple
app download. AudioScope presents an alternative interaction technique to create such
an experience, using the metaphor of pointing a directional microphone at the environment.
In an experiment with 20 users, we compared the time to locate a proximate audio source
and the perceived presence in the virtual environment. Results show that there is
no significant difference between head-orientation measurement and AudioScope regarding
accuracy and perceived presence. This means that MAARS, such as audio guides for museums,
do not require special hardware but can run on the visitor's smartphones with standard
headphones.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {949–952},
numpages = {4},
keywords = {mobile devices, audio augmented reality, navigation., virtual audio spaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702440,
author = {Oh, Jeungmin and Choi, Woohyeok and Kim, Joohyun and Lee, Uichin},
title = {ScanShot: Detecting Document Capture Moments and Correcting Device Orientation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702440},
doi = {10.1145/2702123.2702440},
abstract = {Document capturing with smartphone cameras is performed increasingly often in our
daily lives. However, our user study results (n=10) showed that more than 80% of landscape
tasks had incorrect orientations. To solve this problem, we systematically analyzed
user behavior of document capturing and proposed a novel solution called ScanShot
that detects document capturing moments to help users correct the orientation errors.
ScanShot tracks the gravity direction to capture document capturing moments, analyzes
logged gyroscope data to automatically update orientation changes, and provides visual
feedback of the inferred orientation for manual correction. Our user study results
(n=20) confirmed that capturing moments can be recognized with accuracy of 97.5%,
our update mechanism can reduce the orientation errors by 59 percentage points.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {953–956},
numpages = {4},
keywords = {device orientation, document capturing, smartphone camera, automatic rotation},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702345,
author = {Jones, Brennan and Witcraft, Anna and Bateman, Scott and Neustaedter, Carman and Tang, Anthony},
title = {Mechanics of Camera Work in Mobile Video Collaboration},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702345},
doi = {10.1145/2702123.2702345},
abstract = {Mobile video conferencing, where one or more participants are moving about in the
real world, enables entirely new interaction scenarios (e.g., asking for help to construct
or repair an object, or showing a physical location). While we have a good understanding
of the challenges of video conferencing in office or home environments, we do not
fully understand the mechanics of camera work-how people use mobile devices to communicate
with one another-during mobile video calls. To provide an understanding of what people
do in mobile video collaboration, we conducted an observational study where pairs
of participants completed tasks using a mobile video conferencing system. Our analysis
suggests that people use the camera view deliberately to support their interactions-for
example, to convey a message or to ask questions-but the limited field of view, and
the lack of camera control can make it a frustrating experience.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {957–966},
numpages = {10},
keywords = {handheld devices, cscw, collaboration, video communication, mobile computing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702208,
author = {Bentley, Frank R. and Chen, Ying-Yu and Holz, Christian},
title = {Reducing the Stress of Coordination: Sharing Travel Time Information Between Contacts on Mobile Phones},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702208},
doi = {10.1145/2702123.2702208},
abstract = {We explore the everyday use of a new abstraction for mo-bile location-sharing. By
sharing the travel time between contacts calculated for walking, transit, and driving,
we have enabled users to more easily coordinate meeting up and planning family obligations.
Specifically, our participants reported that the information helped to lower the stress
of these activities and provided reassurance of the arrival times of their close friends
and family. In this paper, we describe our system, motivate its design, and explore
results from a 20-user, 21-day field trial showing the use-fulness of the abstraction
as well as attitudes towards privacy when sharing travel times with close friends
or family.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {967–970},
numpages = {4},
keywords = {navigation, mobile, presence, location sharing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702269,
author = {Samsonov, Pavel Andreevich and Tang, Xun and Sch\"{o}ning, Johannes and Kuhn, Werner and Hecht, Brent},
title = {You Can't Smoke Here: Towards Support for Space Usage Rules in Location-Aware Technologies},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702269},
doi = {10.1145/2702123.2702269},
abstract = {Recent work has identified the lack of space usage rule (SUR) data -- e.g. "no smoking",
"no campfires" -- as an important limitation of online/mobile maps that presents risks
to user safety and the environment. In order to address this limitation, a large-scale
means of mapping SURs must be developed. In this paper, we introduce and motivate
the problem of mapping space usage rules and take the first steps towards identifying
solutions. We show how computer vision can be employed to identify SUR indicators
in the environment (e.g. "No Smoking" signs) with reasonable accuracy and describe
techniques that can assign each rule to the appropriate geographic feature.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {971–974},
numpages = {4},
keywords = {space usage rules, no smoking, geohci, mobile maps, computer vision},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251698,
author = {Dumais, Susan},
title = {Session Details: Search &amp; Recommendations},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251698},
doi = {10.1145/3251698},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702496,
author = {Loepp, Benedikt and Herrmanny, Katja and Ziegler, J\"{u}rgen},
title = {Blended Recommending: Integrating Interactive Information Filtering and Algorithmic Recommender Techniques},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702496},
doi = {10.1145/2702123.2702496},
abstract = {We present a novel approach that integrates algorithmic recommender techniques with
interactive faceted filtering methods. We refer to this approach as blended recommending.
It allows users to interact with a set of filter facets representing criteria that
can serve as input for different recommendation methods including both collaborative
and content-based filtering. Users can select filter criteria from these facets and
weight them to express their preferences and to exert control over the hybrid recommendation
process. In contrast to hard Boolean filtering, the method aggregates the weighted
criteria and calculates a ranked list of recommendations that is visualized and immediately
updated when users change the filter settings. Based on this approach, we implemented
an interactive movie recommender, MyMovieMixer. In a user study, we compared the system
with a conventional faceted filtering system that served as a baseline to obtain insights
into user interaction behavior and to assess recommendation quality for our system.
The results indicate, among other findings, a higher level of perceived user control,
more detailed preference settings, and better suitability when the search goal is
vague.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {975–984},
numpages = {10},
keywords = {user interfaces, recommender systems, information filtering, interactive recommending},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702527,
author = {Park, Jaimie Y. and O'Hare, Neil and Schifanella, Rossano and Jaimes, Alejandro and Chung, Chin-Wan},
title = {A Large-Scale Study of User Image Search Behavior on the Web},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702527},
doi = {10.1145/2702123.2702527},
abstract = {In this study, we analyze user image search behavior from a large-scale Yahoo! Image
Search query log, based on the hypothesis that behavior is dependent on query type.
We categorize queries using two orthogonal taxonomies (subject-based and facet-based)
and identify important query types at the intersection of these taxonomies. We study
user search behavior on a large-scale set of search sessions for each query type,
examining characteristics of sessions, query reformulation patterns, click patterns,
and page view patterns. We identify important behavioral differences across query
types, in particular showing that some query types are more exploratory, while others
correspond to focused search. We also supplement our study with a survey to link the
behavioral differences to users' intent. Our findings shed light on the importance
of considering query categories to better understand user behavior on image search
platforms.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {985–994},
numpages = {10},
keywords = {query analysis, user search behavior, search strategy, image search, click analysis, search intent},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702224,
author = {Kleiman, Yanir and Lanir, Joel and Danon, Dov and Felberbaum, Yasmin and Cohen-Or, Daniel},
title = {DynamicMaps: Similarity-Based Browsing through a Massive Set of Images},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702224},
doi = {10.1145/2702123.2702224},
abstract = {We present a novel system for browsing through a very large set of images according
to similarity. The images are dynamically placed on a 2D canvas next to their nearest
neighbors in a high-dimensional feature space. The layout and choice of images is
generated on-the-fly during user interaction, reflecting the user's navigation tendencies
and interests. This intuitive solution for image browsing provides a continuous experience
of navigating through an infinite 2D grid arranged by similarity. In contrast to common
multidimensional embedding methods, our solution does not entail an upfront creation
of a full global map. Image map generation is dynamic, fast and scalable, independent
of the number of images in the dataset, and seamlessly supports online updates to
the dataset. Thus, the technique is a viable solution for massive and constantly varying
datasets consisting of millions of images. Evaluation of our approach shows that when
using DynamicMaps, users viewed many more images per minute compared to a standard
relevance feedback interface, suggesting that it supports more fluid and natural interaction
that enables easier and faster movement in the image space. Most users preferred DynamicMaps,
indicating it is more exploratory, better supports serendipitous browsing and more
fun to use},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {995–1004},
numpages = {10},
keywords = {similarity browsing, image browsing, image search, relevance feedback},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702568,
author = {Speicher, Maximilian and Both, Andreas and Gaedke, Martin},
title = {S.O.S.: Does Your Search Engine Results Page (SERP) Need Help?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702568},
doi = {10.1145/2702123.2702568},
abstract = {Over the past 20 years, search engines have become emph{the} entry point of the WWW.
Due to evolving needs for different and new kinds of information, the interfaces of
search engine results pages (SERPs) change over time. Thus, their usability must be
continuously evaluated to ensure user satisfaction and competitive edge. As no complete
solution exists, we present emph{S.O.S.:} the emph{SERP Optimization Suite}. Our approach
comprises (a) emph{WaPPU}, which is a near real-time tool for evaluating web interfaces
based on usability scores, and (b) a emph{catalog of best practices} that maps bad
scores to potential causes and corresponding adjustments for optimization. During
a case study in which we assessed and optimized a real-world SERP, S.O.S. has proven
its feasibility and effectiveness by significantly improving the SERP's usability.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1005–1014},
numpages = {10},
keywords = {search engine results pages, evaluation, metrics, best practices, scores, optimization, usability},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251699,
author = {Gilutz, Shuli},
title = {Session Details: Kids Haptic, Wearable, Tangible Learning},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251699},
doi = {10.1145/3251699},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702396,
author = {Yannier, Nesra and Israr, Ali and Lehman, Jill Fain and Klatzky, Roberta L.},
title = {<i>FeelSleeve</i>: Haptic Feedback to Enhance Early Reading},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702396},
doi = {10.1145/2702123.2702396},
abstract = {Engaging children with traditional approaches in education, especially reading, grows
ever more difficult in the face of their attachment to tablets and computer games.
We explore the possibility of making the story reading experience more interesting
and memorable for children using haptic augmentation. In this paper, we present FeelSleeve,
an interface that allows children to feel story events in their hands while they are
reading on a mobile device. FeelSleeve uses transducers and audio output from the
tablet within a gloved attachment to create vibratory effects that are meaningfully
related to story content. We describe a study investigating whether embedding such
haptic feedback into stories enhances reading for six to nine year olds. Our results
indicate that story events accompanied by haptic feedback are better comprehended
and appear to be more salient in memory. These results provide evidence that haptic
effects have the potential to improve children's reading experience and make it more
memorable.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1015–1024},
numpages = {10},
keywords = {story listening technology, haptic vocabulary, story reading technology, vibrotactile feedback, handheld technology},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702299,
author = {Norooz, Leyla and Mauriello, Matthew Louis and Jorgensen, Anita and McNally, Brenna and Froehlich, Jon E.},
title = {BodyVis: A New Approach to Body Learning Through Wearable Sensing and Visualization},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702299},
doi = {10.1145/2702123.2702299},
abstract = {Internal organs are hidden and untouchable, making it difficult for children to learn
their size, position, and function. Traditionally, human anatomy (body form) and physiology
(body function) are taught using techniques ranging from worksheets to three-dimensional
models. We present a new approach called BodyVis, an e-textile shirt that combines
biometric sensing and wearable visualizations to reveal otherwise invisible body parts
and functions. We describe our 15-month iterative design process including lessons
learned through the development of three prototypes using participatory design and
two evaluations of the final prototype: a design probe interview with seven elementary
school teachers and three single-session deployments in after-school programs. Our
findings have implications for the growing area of wearables and tangibles for learning.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1025–1034},
numpages = {10},
keywords = {physiological sensing, interactive body learning, wearables},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702250,
author = {Bai, Zhen and Blackwell, Alan F. and Coulouris, George},
title = {Exploring Expressive Augmented Reality: The FingAR Puppet System for Social Pretend Play},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702250},
doi = {10.1145/2702123.2702250},
abstract = {We present "FingAR Puppet", an Augmented Reality (AR) system enhancing social pretend
play by young children. Unlike goal-oriented AR systems that augment reality with
informative instructions, FingAR Puppet helps children associate expressive interpretations
with immediate reality. Empirical results show that FingAR Puppet promotes reasoning
about emotional states, communication and divergent thinking during social pretend
play for children 4-6 years old. We suggest that this study opens an interesting space
for future AR systems to support complex cognitive and social development in early
childhood. We also identify broader implications from using theories of cognitive
development to guide the design of tangible and augmented interactions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1035–1044},
numpages = {10},
keywords = {pretend play, tangible user interface, children, augmented reality},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702397,
author = {Yannier, Nesra and Koedinger, Kenneth R. and Hudson, Scott E.},
title = {Learning from Mixed-Reality Games: Is Shaking a Tablet as Effective as Physical Observation?},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702397},
doi = {10.1145/2702123.2702397},
abstract = {The possibility of leveraging technology to support children's learning in the real
world is both appealing and technically challenging. We have been exploring factors
in tangible games that may contribute to both learning and enjoyment with an eye toward
technological feasibility and scalability. Previous research found that young children
learned early physics principles better when interactively predicting and observing
experimental comparisons on a physical earthquake table than when seeing a video of
the same. Immersing children in the real world with computer vision-based feedback
appears to evoke embodied cognition that enhances learning. In the current experiment,
we replicated this intriguing result of the mere difference between observing the
real world versus a flat-screen. Further, we explored whether a simple and scalable
addition of physical control (such as shaking a tablet) would yield an increase in
learning and enjoyment. Our 2x2 experiment found no evidence that adding simple forms
of hands-on control enhances learning, while demonstrating a large impact of physical
observation. A general implication for educational game design is that affording physical
observation in the real world accompanied by interactive feedback may be more important
than affording simple hands-on control on a tablet.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1045–1054},
numpages = {10},
keywords = {learning technologies, mixed-reality games, tangible interfaces, educational games},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/3251700,
author = {Morris, Meredith},
title = {Session Details: Motivation &amp; Participation},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251700},
doi = {10.1145/3251700},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702329,
author = {Brady, Erin and Morris, Meredith Ringel and Bigham, Jeffrey P.},
title = {Gauging Receptiveness to Social Microvolunteering},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702329},
doi = {10.1145/2702123.2702329},
abstract = {Crowd-powered systems that help people are difficult to scale and sustain because
human labor is expensive and worker pools are difficult to grow. To address this problem
we introduce the idea of social microvolunteering, a type of intermediated friendsourcing
in which a person can provide access to their friends as potential workers for microtasks
supporting causes that they care about. We explore this idea by creating Visual Answers,
an exemplar social microvolunteering application for Facebook that posts visual questions
from people who are blind. We present results of a survey of 350 participants on the
concept of social microvolunteering, and a deployment of the Visual Answers application
with 91 participants, which collected 618 high-quality answers to questions asked
over 12 days, illustrating the feasibility of the approach.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1055–1064},
numpages = {10},
keywords = {sns, volunteering, crowdsourcing, friendsourcing},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702296,
author = {Dergousoff, Kristen and Mandryk, Regan L.},
title = {Mobile Gamification for Crowdsourcing Data Collection: Leveraging the Freemium Model},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702296},
doi = {10.1145/2702123.2702296},
abstract = {Classic ways of gathering data on human behaviour are time-consuming, costly and are
subject to limited participant pools. Crowdsourcing offers a reduction in operating
costs and access to a diverse and large participant pool; however issues arise concerning
low worker pay and questions about data quality. Gamification provides a motivation
to participate, but also requires the development of specialized, research-question
specific games that can be costly to produce. Our solution combines gamification and
crowdsourcing in a smartphone-based system that emulates the popular Freemium model
of play to motivate voluntary participation through in-game rewards, using a robust
framework to study multiple unrelated research questions within the same system. We
deployed our game on the Android store and compared it to a gamified laboratory version
and a non-gamified laboratory version, and found that players who used the in-game
rewards were motivated to do experimental tasks. There was no difference between the
systems for performance on a motor task; however, performance on the cognitive task
was worse for the crowdsourced game. We discuss options for improving performance
on tasks requiring attention.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1065–1074},
numpages = {10},
keywords = {psychophysics, crowdsourcing, freemium, gamification},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702560,
author = {Shih, Patrick C. and Bellotti, Victoria and Han, Kyungsik and Carroll, John M.},
title = {Unequal Time for Unequal Value: Implications of Differing Motivations for Participation in Timebanking},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702560},
doi = {10.1145/2702123.2702560},
abstract = {Timebanking is a service-based community currency, built on the principle that everyone's
time is valued equally. It has potential for community building and reenergizing neighborhoods,
but it faces several adoption challenges. We report on the largest investigation of
timebanking practices to date by analyzing a combination of service exchange records
from the three largest hOurworld timebanks with over 3,500 members with 33,000 completed
service exchanges, and a survey of 446 members of over 120 hOurworld timebanks. Our
findings suggest that the ideal of 'equal time, equal value' that is at the foundation
of timebanking is a source of tension between members with instrumental versus idealistic
and altruistic motivations. We suggest that future peer-to-peer systems must incorporate
different rewards and incentives in order to accommodate users with different motivations.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1075–1084},
numpages = {10},
keywords = {peer-to-peer service exchange, use and adoption challenges., timebanking, community currency},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702123.2702272,
author = {Bellotti, Victoria and Ambard, Alexander and Turner, Daniel and Gossmann, Christina and Demkova, Kamila and Carroll, John M.},
title = {A Muddle of Models of Motivation for Using Peer-to-Peer Economy Systems},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702272},
doi = {10.1145/2702123.2702272},
abstract = {This paper reports on a study of motivations for the use of peer-to-peer or sharing
economy services. We interviewed both users and providers of these systems to obtain
different perspectives and to determine if providers are matching their system designs
to the most important drivers of use. We found that the motivational models implicit
in providers' explanations of their systems' designs do not match well with what really
seems to motivate users. Providers place great emphasis on idealistic motivations
such as creating a better community and increasing sustainability. Users, on the other
hand are looking for services that provide what they need whilst increasing value
and convenience. We discuss the divergent models of providers and users and offer
design implications for peer system providers.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {1085–1094},
numpages = {10},
keywords = {field study, user experience design, peer-to-peer economy},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}


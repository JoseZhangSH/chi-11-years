@inproceedings{10.1145/3250980,
author = {Guerreiro, Tiago},
title = {Session Details: Lost and Found in Translation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250980},
doi = {10.1145/3250980},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557215,
author = {Hautasaari, Ari MJ and Yamashita, Naomi and Gao, Ge},
title = {"Maybe It Was a Joke": Emotion Detection in Text-Only Communication by Non-Native English Speakers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557215},
doi = {10.1145/2556288.2557215},
abstract = {Previous studies have shown that people can effectively detect emotions in text-only
messages written in their native languages. But is this the same for non-native speakers'
In this paper, we conduct an experiment where native English speakers (NS) and Japanese
non-native English speakers (NNS) rate the emotional valence in text-only messages
written by native English-speaking authors. They also annotate all emotional cues
(words, symbols and emoticons) that affected their rating. Accuracy of NS and NNS
ratings and annotations are calculated by comparing their average correlations with
author ratings and annotations used as a gold standard. Our results conclude that
NNS are significantly less accurate at detecting the emotional valence of messages,
especially when the messages include highly negative words. Although NNS are as accurate
as NS at detecting emotional cues, they are not able to make use of symbols (exclamation
marks) and emoticons to detect the emotional valence of text-only messages.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3715–3724},
numpages = {10},
keywords = {computer-mediated communication, non-native speaker, emotion, text-only communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556985,
author = {Savva, Manolis and Chang, Angel X. and Manning, Christopher D. and Hanrahan, Pat},
title = {TransPhoner: Automated Mnemonic Keyword Generation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556985},
doi = {10.1145/2556288.2556985},
abstract = {We present TransPhoner: a system that generates keywords for a variety of scenarios
including vocabulary learning, phonetic transliteration, and creative word plays.
We select effective keywords by considering phonetic, orthographic and semantic word
similarity, and word concept imageability. We show that keywords provided by TransPhoner
improve learner performance in an online vocabulary learning study, with the improvement
being more pronounced for harder words. Participants rated TransPhoner keywords as
more helpful than a random keyword baseline, and almost as helpful as manually selected
keywords. Comments also indicated higher engagement in the learning task, and more
desire to continue learning. We demonstrate additional applications to tasks such
as pure phonetic transliteration, generation of mnemonics for complex vocabulary,
and topic-based transformation of song lyrics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3725–3734},
numpages = {10},
keywords = {mnemonic keywords},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556993,
author = {Robinson, Simon and Pearson, Jennifer S. and Jones, Matt},
title = {AudioCanvas: Internet-Free Interactive Audio Photos},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556993},
doi = {10.1145/2556288.2556993},
abstract = {In this paper we present a novel interaction technique that helps to make textual
information more accessible to those with low or no textual literacy skills. AudioCanvas
allows cameraphone users to interact directly with their own photos of printed media
to receive audio feedback or narration. The use of a remote telephone-based service
also allows our design to be used over a standard phone line, removing the need for
data connections, which can be problematic in developing regions. We show the value
of the technique via user evaluations in both a rural Indian village and a South African
township.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3735–3738},
numpages = {4},
keywords = {qr codes, audio, developing regions, camera phones},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556982,
author = {Leiva, Luis A. and Alabau, Vicent},
title = {The Impact of Visual Contextualization on UI Localization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556982},
doi = {10.1145/2556288.2556982},
abstract = {Translating the text in an interface is a challenging task. Besides the jargon and
technical terms, many of the strings are often very short, such as those shown in
buttons and pull-down menus. Then, as a result of the lack of visual context in the
traditional localization process, an important ambiguity problem arises. We study
three approaches to solve this problem: using plain gettext (baseline condition),
using gettext plus being able to operate the UI, and translating the UI in-place.
We found that translators are substantially faster with plain gettext but commit a
significantly higher number of errors in comparison to the other approaches. Unexpectedly,
the mixed condition was slower and more error-prone than in-place translation. The
latter was found to be comparable to plain gettext in terms of time, although some
strings passed unnoticed as the UI was operated. Based on our results, we arrive at
a set of recommendations to augment localization tools to improve translator's productivity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3739–3742},
numpages = {4},
keywords = {internationalization, translation, i18n, l10n, localization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557171,
author = {Xu, Bin and Gao, Ge and Fussell, Susan R. and Cosley, Dan},
title = {Improving Machine Translation by Showing Two Outputs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557171},
doi = {10.1145/2556288.2557171},
abstract = {We propose to improve real-time communication between people who do not share a common
language by foregrounding potential problems in machine translation. We developed
a prototype chat tool that displays two parallel translations of each chat turn, with
the thought that comparing the translations might both highlight problems and provide
resources for resolving them. We conducted a user study to investigate how people
use and like such an interface compared to a standard one-translation interface. On
balance, users preferred two translations to one, using them to both notice differences
and infer meaning from uncertain translations, with no increase in workload. This
suggests that this interface may help improve cross-lingual communication in practical
applications and lays the groundwork for a larger design space around systems that
highlight possible errors to support communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3743–3746},
numpages = {4},
keywords = {multiple translations, machine translation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250981,
author = {Guha, Mona Leigh},
title = {Session Details: Participatory Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250981},
doi = {10.1145/3250981},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557244,
author = {Benton, Laura and Vasalou, Asimina and Khaled, Rilla and Johnson, Hilary and Gooch, Daniel},
title = {Diversity for Design: A Framework for Involving Neurodiverse Children in the Technology Design Process},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557244},
doi = {10.1145/2556288.2557244},
abstract = {The neurodiversity movement seeks to positively reframe certain neurological conditions,
such as autism spectrum disorders (ASD) and dyslexia, by concentrating on their strengths.
In recent years, neurodiverse children have increasingly been involved in the technology
design process, but the design approaches adopted have focused mostly on overcoming
difficulties of working with these children, leaving their strengths untapped. We
present a new participatory design (PD) framework, Diversity for Design (D4D), which
provides guidance for technology designers working with neurodiverse children in establishing
PD methods that capitalize on children's strengths and also support potential difficulties.
We present two case studies of use of the D4D framework, involving children with ASD
and dyslexia, showing how it informed the development and refinement of PD methods
tailored to these populations. In addition, we show how to apply the D4D framework
to other neurodiverse populations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3747–3756},
numpages = {10},
keywords = {children, neurodiversity, dyslexia, autism, participatory design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557396,
author = {Robinson, Charlotte L. and Mancini, Clara and van der Linden, Janet and Guest, Claire and Harris, Robert},
title = {Canine-Centered Interface Design: Supporting the Work of Diabetes Alert Dogs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557396},
doi = {10.1145/2556288.2557396},
abstract = {Many people with Diabetes live with the continuous threat of hypoglycemic attacks
and the danger of going into coma. Diabetes Alert Dogs are trained to detect the onset
of an attack before the condition of the human handler they are paired with deteriorates,
giving them time to take action. We investigated requirements for designing an alarm
system allowing dogs to remotely call for help when their human falls unconscious
before being able to react to an alert. Through a multispecies ethnographic approach
we focus on the requirements for a physical canine user interface, involving dogs,
their handlers and specialist dog trainers in the design process. We discuss tensions
between the requirements for canine and the human users, argue the need for increased
sensitivity towards the needs of individual dogs that goes beyond breed specific physical
characteristics, and reflect on how we can move from designing for dogs to designing
with dogs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3757–3766},
numpages = {10},
keywords = {diabetes alert dog, user-centered design, multispecies ethnography, animal-computer interaction, human-animal interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557115,
author = {W\"{a}rnest\r{a}l, Pontus and Svedberg, Petra and Nygren, Jens},
title = {Co-Constructing Child Personas for Health-Promoting Services with Vulnerable Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557115},
doi = {10.1145/2556288.2557115},
abstract = {The availability of health-promoting resources for young children diagnosed with cancer
who are transitioning from intensive care to everyday life is limited. In the context
of designing digital peer support services for children who are considered vulnerable
due to clinical and age-related aspects, there are several challenges that put critical
requirements on a user-centered design process. This paper reports on a new method
for co-constructing child-personas that are tailored for developing health-promoting
services where empirical data is restricted due to practical and ethical reasons.
In particular, we are proposing to focus children design workshop sessions on salutogenesis,
and complement this with a pathogenic perspective by interviewing healthcare professionals
and parents. We also introduce the use of proxy personas, and redemption scenarios
in the form of comicboards, both collaboratively constructed by children and designers
through storytelling. By applying four progressive steps of data collection and analysis
we arrive at authentic child-personas that can be used to design and develop health-promoting
services for children in vulnerable life stages.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3767–3776},
numpages = {10},
keywords = {vulnerable children, participatory design, digital peer support, user experience, methodology, personas, social interaction, interaction design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557301,
author = {Kusunoki, Diana S. and Sarcevic, Aleksandra and Weibel, Nadir and Marsic, Ivan and Zhang, Zhan and Tuveson, Genevieve and Burd, Randall S.},
title = {Balancing Design Tensions: Iterative Display Design to Support Ad Hoc and Multidisciplinary Medical Teamwork},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557301},
doi = {10.1145/2556288.2557301},
abstract = {In this paper, we describe how we developed an information display prototype for trauma
resuscitation teams based on design ideas and feedback from clinicians. Our approach
is grounded in participatory design, emphasizing the importance of gaining long-term
commitment from clinicians in system development. Through a series of participatory
design workshops, heuristic evaluation, and simulated resuscitation sessions, we identified
the main information features to include on our display. Our results focus on how
we balanced the design tensions that emerged when addressing the ad hoc, hierarchical,
and multidisciplinary nature of trauma teamwork. We discuss the implications of balancing
role-based differences for each information feature, as well as two major design tensions:
process-based vs. state-based designs and role-based vs. team-based displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3777–3786},
numpages = {10},
keywords = {participatory design, healthcare, teamwork, information displays, trauma resuscitation, design tensions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250982,
author = {Baillie, Lynne},
title = {Session Details: Brain Computer Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250982},
doi = {10.1145/3250982},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557015,
author = {Vi, Chi Thanh and Jamil, Izdihar and Coyle, David and Subramanian, Sriram},
title = {Error Related Negativity in Observing Interactive Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557015},
doi = {10.1145/2556288.2557015},
abstract = {Error Related Negativity is triggered when a user either makes a mistake or the application
behaves differently from their expectation. It can also appear while observing another
user making a mistake. This paper investigates ERN in collaborative settings where
observing another user (the executer) perform a task is typical and then explores
its applicability to HCI. We first show that ERN can be detected on signals captured
by commodity EEG headsets like an Emotiv headset when observing another person perform
a typical multiple-choice reaction time task. We then investigate the anticipation
effects by detecting ERN in the time interval when an executer is reaching towards
an answer. We show that we can detect this signal with both a clinical EEG device
and with an Emotiv headset. Our results show that online single trial detection is
possible using both headsets during tasks that are typical of collaborative interactive
applications. However there is a trade-off between the detection speed and the quality/prices
of the headsets. Based on the results, we discuss and present several HCI scenarios
for use of ERN in observing tasks and collaborative settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3787–3796},
numpages = {10},
keywords = {brain computer interface, error related negativity, tabletop, eeg, electroencephalography},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557230,
author = {Afergan, Daniel and Peck, Evan M. and Solovey, Erin T. and Jenkins, Andrew and Hincks, Samuel W. and Brown, Eli T. and Chang, Remco and Jacob, Robert J.K.},
title = {Dynamic Difficulty Using Brain Metrics of Workload},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557230},
doi = {10.1145/2556288.2557230},
abstract = {Dynamic difficulty adjustments can be used in human-computer systems in order to improve
user engagement and performance. In this paper, we use functional near-infrared spectroscopy
(fNIRS) to obtain passive brain sensing data and detect extended periods of boredom
or overload. From these physiological signals, we can adapt a simulation in order
to optimize workload in real-time, which allows the system to better fit the task
to the user from moment to moment. To demonstrate this idea, we ran a laboratory study
in which participants performed path planning for multiple unmanned aerial vehicles
(UAVs) in a simulation. Based on their state, we varied the difficulty of the task
by adding or removing UAVs and found that we were able to decrease error by 35% over
a baseline condition. Our results show that we can use fNIRS brain sensing to detect
task difficulty in real-time and construct an interface that improves user performance
through dynamic difficulty adjustment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3797–3806},
numpages = {10},
keywords = {fnirs, uav, workload, near-infrared spectroscopy, passive brain-computer interface, bci, dynamic difficulty},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556974,
author = {Pike, Matthew F. and Maior, Horia A. and Porcheron, Martin and Sharples, Sarah C. and Wilson, Max L.},
title = {Measuring the Effect of Think Aloud Protocols on Workload Using FNIRS},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556974},
doi = {10.1145/2556288.2556974},
abstract = {The Think Aloud Protocol (TAP) is a verbalisation technique widely employed in HCI
user studies to give insight into user experience, yet little work has explored the
impact that TAPs have on participants during user studies. This paper utilises a brain
sensing technique, fNIRS, to observe the effect that TAPs have on participants. Functional
Near-Infrared Spectroscopy (fNIRS) is a brain sensing technology that offers the potential
to provide continuous, detailed insight into brain activity, enabling an objective
view of cognitive processes during complex tasks. Participants were asked to perform
a mathematical task under 4 conditions: nonsense verbalisations, passive concurrent
think aloud protocol, invasive concurrent think aloud protocol, and a baseline of
silence. Subjective ratings and performance measures were collected during the study.
Our results provide a novel view into the effect that different forms of verbalisation
have on workload during tasks. Further, the results provide a means for estimating
the effect of spoken artefacts when measuring workload, which is another step towards
our goal of proactively involving fNIRS analysis in ecologically valid user studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3807–3816},
numpages = {10},
keywords = {human cognition, fnirs, functional near-infrared spectroscopy, think aloud protocol, hci, bci},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557076,
author = {Lee, Yi-Chieh and Lin, Wen-Chieh and King, Jung-Tai and Ko, Li-Wei and Huang, Yu-Ting and Cherng, Fu-Yin},
title = {An EEG-Based Approach for Evaluating Audio Notifications under Ambient Sounds},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557076},
doi = {10.1145/2556288.2557076},
abstract = {Audio notifications are an important means of prompting users of electronic products.
Although useful in most environments, audio notifications are ineffective in certain
situations, especially against particular auditory backgrounds or when the user is
distracted. Several studies have used behavioral performance to evaluate audio notifications,
but these studies failed to achieve consistent results due to factors including user
subjectivity and environmental differences; thus, a new method and more objective
indicators are necessary. In this study, we propose an approach based on electroencephalography
(EEG) to evaluate audio notifications by measuring users' auditory perceptual responses
(mismatch negativity) and attention shifting (P3a). We demonstrate our approach by
applying it to the usability testing of audio notifications in realistic scenarios,
such as users performing a major task amid ambient noises. Our results open a new
perspective for evaluating the design of the audio notifications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3817–3826},
numpages = {10},
keywords = {usability testing, mismatch negativity, human cognition, electroencephalography (eeg), audio notifications},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250983,
author = {Olwal, Alex},
title = {Session Details: 3D Printing and Fabrication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250983},
doi = {10.1145/3250983},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557005,
author = {Mueller, Stefanie and Mohr, Tobias and Guenther, Kerstin and Frohnhofen, Johannes and Baudisch, Patrick},
title = {FaBrickation: Fast 3D Printing of Functional Objects by Integrating Construction Kit Building Blocks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557005},
doi = {10.1145/2556288.2557005},
abstract = {We present a new approach to rapid prototyping of functional objects, such as the
body of a head-mounted display. The key idea is to save 3D printing time by automatically
substituting sub-volumes with standard building blocks'in our case Lego bricks. When
making the body for a head-mounted display, for example, getting the optical path
right is paramount. Users thus mark the lens mounts as "high-resolution" to indicate
that these should later be 3D printed. faBrickator then 3D prints these parts. It
also generates instructions that show users how to create everything else from Lego
bricks. If users iterate on the design later, faBrickator offers even greater benefit
as it allows re-printing only the elements that changed. We validated our system at
the example of three 3D models of functional objects. On average, our system fabricates
objects 2.44 times faster than traditional 3D printing while requiring only 14 minutes
of manual assembly.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3827–3834},
numpages = {8},
keywords = {design iteration, physical prototyping, 3d printing, rapid prototyping, building blocks},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557144,
author = {Khot, Rohit Ashok and Hjorth, Larissa and Mueller, Florian 'Floyd'},
title = {Understanding Physical Activity through 3D Printed Material Artifacts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557144},
doi = {10.1145/2556288.2557144},
abstract = {In this paper, we advocate a novel approach of representing physical activity in the
form of material artifacts. By designing such material representations, we aim to
understand what these artifacts might offer in terms of reflecting upon physical activity.
For example, what types of affect do material artifacts, representing ones' physical
activity create for the user' In order to advance this understanding, we designed
a system called SweatAtoms that transforms the physical activity data based on heart
rate into 3D printed material artifacts. We conducted an 'in the wild study' by deploying
our system in six households where participants were experiencing five different material
representations of their physical activity for a period of two weeks each. We found
that the material artifacts made participants more conscious about their involvement
in physical activity and illustrated different levels of engagement with the artifacts.
Along with reporting the gained insights from the deployments, we offer reflections
on designing material representations for physical activity. We hope that our work
will inspire designers to consider new possibilities afforded by digital fabrication
to support user's experience with physical activity by utilizing interactive technologies
at our disposal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3835–3844},
numpages = {10},
keywords = {entertainment, personal informatics, physical exercise, 3d printing, quantifiable self, digital fabrication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557310,
author = {Swaminathan, Saiganesh and Shi, Conglei and Jansen, Yvonne and Dragicevic, Pierre and Oehlberg, Lora A. and Fekete, Jean-Daniel},
title = {Supporting the Design and Fabrication of Physical Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557310},
doi = {10.1145/2556288.2557310},
abstract = {Physical visualizations come in increasingly diverse forms, and are used in domains
including art and entertainment, business analytics, and scientific research. However,
creating physical visualizations requires laborious craftsmanship and demands expertise
in both data visualization and digital fabrication. We present three case studies
that illustrate limitations of current visualization fabrication workflows. We then
present MakerVis, a prototype tool that integrates the entire process of creating
physical visualizations, from data filtering to physical fabrication. Design sessions
with three end users demonstrate how tools such as MakerVis can dramatically lower
the barriers to producing physical visualizations. Observations and interviews from
these sessions highlighted future research areas, including customization support,
using material properties to represent data variables, and allowing the reuse of physical
data objects in new visualizations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3845–3854},
numpages = {10},
keywords = {physical visualization, digital fabrication, infovis},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557090,
author = {Weichel, Christian and Lau, Manfred and Kim, David and Villar, Nicolas and Gellersen, Hans W.},
title = {MixFab: A Mixed-Reality Environment for Personal Fabrication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557090},
doi = {10.1145/2556288.2557090},
abstract = {Personal fabrication machines, such as 3D printers and laser cutters, are becoming
increasingly ubiquitous. However, designing objects for fabrication still requires
3D modeling skills, thereby rendering such technologies inaccessible to a wide user-group.
In this paper, we introduce MixFab, a mixed-reality environment for personal fabrication
that lowers the barrier for users to engage in personal fabrication. Users design
objects in an immersive augmented reality environment, interact with virtual objects
in a direct gestural manner and can introduce existing physical objects effortlessly
into their designs. We describe the design and implementation of MixFab, a user-defined
gesture study that informed this design, show artifacts designed with the system and
describe a user study evaluating the system's prototype.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3855–3864},
numpages = {10},
keywords = {3d printing, direct manipulation, 3d modeling, personal fabrication, mixed-reality},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250984,
author = {Elmqvist, Niklas},
title = {Session Details: Modeling Users and Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250984},
doi = {10.1145/3250984},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557093,
author = {Bailly, Gilles and Oulasvirta, Antti and Brumby, Duncan P. and Howes, Andrew},
title = {Model of Visual Search and Selection Time in Linear Menus},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557093},
doi = {10.1145/2556288.2557093},
abstract = {This paper presents a novel mathematical model for visual search and selection time
in linear menus. Assuming two visual search strategies, serial and directed, and a
pointing sub-task, it captures the change of performance with five fac- tors: 1) menu
length, 2) menu organization, 3) target position, 4) absence/presence of target, and
5) practice. The novel aspect is that the model is expressed as probability density
distribution of gaze, which allows for deriving total selection time. We present novel
data that replicates and extends the Nielsen menu selection paradigm and uses eye-tracking
and mouse tracking to confirm model predictions. The same parametrization yielded
a high fit to both menu selection time and gaze distributions. The model has the potential
to improve menu designs by helping designers identify more effective solutions without
conducting empirical studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3865–3874},
numpages = {10},
keywords = {mathematical predictive models, visual search, linear menus, eye-tracking, user performance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557324,
author = {Kieras, David E. and Hornof, Anthony J.},
title = {Towards Accurate and Practical Predictive Models of Active-Vision-Based Visual Search},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557324},
doi = {10.1145/2556288.2557324},
abstract = {Being able to predict the performance of interface designs using models of human cognition
and performance is a long-standing goal of HCI research. This paper presents recent
advances in cognitive modeling which permit increasingly realistic and accurate predictions
for visual human-computer interaction tasks such as icon search by incorporating an
"active vision" approach which emphasizes eye movements to visual features based on
the availability of features in relationship to the point of gaze. A high fidelity
model of a classic visual search task demonstrates the value of incorporating visual
acuity functions into models of visual performance. The features captured by the high-fidelity
model are then used to formulate a model simple enough for practical use, which is
then implemented in an easy-to-use GLEAN modeling tool. Easy-to-use predictive models
for complex visual search are thus feasible and should be further developed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3875–3884},
numpages = {10},
keywords = {visual acuity, cognitive architecture, human performance modeling, visual search, goms},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557351,
author = {Zhang, Yunfeng and Hornof, Anthony J.},
title = {Understanding Multitasking through Parallelized Strategy Exploration and Individualized Cognitive Modeling},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557351},
doi = {10.1145/2556288.2557351},
abstract = {Human multitasking often involves complex task interactions and subtle tradeoffs which
might be best understood through detailed computational cognitive modeling, yet traditional
cognitive modeling approaches may not explore a sufficient range of task strategies
to reveal the true complexity of multitasking behavior. This study proposes a systematic
approach for exploring a large number of strategies using a computer-cluster-based
parallelized modeling system. The paper demonstrates the efficacy of the approach
for investigating and revealing the effects of different microstrategies on human
performance, both within and across individuals, for a time-pressured multimodal dual
task. The modeling results suggest that multitasking performance is not simply a matter
of interleaving cognitive and sensorimotor processing but is instead heavily influenced
by the selection of subtask microstrategies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3885–3894},
numpages = {10},
keywords = {model comparison, cognitive modeling, multimodal, high performance computing, multitasking, task strategies.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557064,
author = {Brumby, Duncan P. and Cox, Anna L. and Chung, Jacqueline and Fernandes, Byron},
title = {How Does Knowing What You Are Looking for Change Visual Search Behavior?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557064},
doi = {10.1145/2556288.2557064},
abstract = {When searching a display, users sometimes know what the target is but sometimes do
not. It has generally been assumed that for this latter case people must engage in
a deeper semantic evaluation of items during the search process. This idea is central
to Information Foraging theory. But do people actually spend longer assessing items
when engaged in a semantically demanding search task' We investigate this by having
participants locate target items in 16-item menus. Participants were either told exactly
what to look for (known-item search) or they were told the category that the target
belonged to (semantic search). Participants were faster and more accurate at known-item
searches. Eye-movement data show that this was because participants were more likely
to skip over items when performing known-item searches. Contrary to expectation, we
found limited empirical evidence to support the idea that deeper semantic evaluations
of items lead to longer gaze durations (this occurred only when items were arranged
very close together). This finding is important because it reveals how people adopt
different eye gaze strategies depending on the kind of search activity they are engaged
in.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3895–3898},
numpages = {4},
keywords = {eye-tracking, information foraging, menus, visual search},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556999,
author = {Oulasvirta, Antti},
title = {Automated Nonlinear Regression Modeling for HCI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556999},
doi = {10.1145/2556288.2556999},
abstract = {Predictive models in HCI, such as models of user performance, are often expressed
as multivariate nonlinear regressions. This approach has been preferred, because it
is compact and allows scrutiny. However, existing modeling tools in HCI, along with
the common statistical packages, are limited to predefined nonlinear models or support
linear models only. To assist researchers in the task of identifying novel nonlinear
models, we propose a stochastic local search method that constructs equations iteratively.
Instead of predefining a model equation, the researcher defines constraints that guide
the search process. Comparison of outputs to published baselines in HCI shows improvements
in model fit in seven out of 11 cases. We present a few ways in which the method can
help HCI researchers explore modeling problems. We conclude that the approach is particularly
suitable for complex datasets that have many predictor variables.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3899–3902},
numpages = {4},
keywords = {multivariate nonlinear regression models, predictive modeling in human--computer interaction, model selection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250985,
author = {McGrenere, Joanna},
title = {Session Details: Engaging Older Adults through Technology},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250985},
doi = {10.1145/3250985},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557133,
author = {Hope, Alexis and Schwaba, Ted and Piper, Anne Marie},
title = {Understanding Digital and Material Social Communications for Older Adults},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557133},
doi = {10.1145/2556288.2557133},
abstract = {Online technologies are promising for helping older adults maintain social connectedness,
particularly with younger people, yet many older adults resist or participate minimally
in the mainstream technologies used by younger members of their social network. We
present results from an interview study involving 22 older adults (age 71-92) to understand
communication preferences and values related to social media. Seniors articulate many
concerns with online social media, including the time required for legitimate participation,
the loss of deeper communication, content irrelevance, and privacy. Additionally,
older adults engage in social practices that could be supported by online social technologies,
but they rarely use such tools. The theme of material social communications emerges
from our data, and we examine this in context of online social media. We conclude
with design considerations for the development of social media for older adults, and
as part of this we describe the notion of bridging technologies as a framework for
intergenerational communication design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3903–3912},
numpages = {10},
keywords = {social network sites, materiality., older adults, social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557184,
author = {Rogers, Yvonne and Paay, Jeni and Brereton, Margot and Vaisutis, Kate L. and Marsden, Gary and Vetere, Frank},
title = {Never Too Old: Engaging Retired People Inventing the Future with MaKey MaKey},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557184},
doi = {10.1145/2556288.2557184},
abstract = {Within HCI, aging is often viewed in terms of designing assistive technologies to
improve the lives of older people, such as those who are suffering from frailty or
memory loss. Our research adopts a very different approach, reframing the relationship
in terms of wisdom, creativity and invention. We ran a series of workshops where groups
of retirees, aged between early 60s and late 80s, used the MaKey MaKey inventor's
toolkit. We asked them to think about inventing the future and suggest ideas for new
technologies. Our findings showed that they not only rose to the challenge but also
mastered the technology, collaborated intensely together while using it and freely
and at length discussed their own, their family's and others' relationship with technology.
We discuss the value of empowering people in this way and consider what else could
be invented to enable more people to be involved in the design and use of creative
technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3913–3922},
numpages = {10},
keywords = {creativity, toolkits, invention, future technology, retired people, makey makey, aging},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556992,
author = {Norval, Chris and Arnott, John L. and Hanson, Vicki L.},
title = {What's on Your Mind? Investigating Recommendations for Inclusive Social Networking and Older Adults},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556992},
doi = {10.1145/2556288.2556992},
abstract = {Social networking sites (SNSs) are becoming increasingly popular as a method for social
interaction. While research has reported benefits associated with components of SNS
usage, a digital divide has emerged between younger and older users. SNSs can be useful
for communicating with family members and helping one feel digitally included; however,
there are a wide range of reasons why many older adults choose not to use this kind
of technology. We present a series of user studies investigating the barriers and
challenges that SNSs can present to older users. These user studies led to the derivation
of user recommendations to mitigate these barriers. The recommendations were then
evaluated within a comparative evaluation which involved 25 older adults completing
tasks on two interface versions of a simulation SNS. We present the recommendations
and the methods of their creation and evaluation. Implications for developers of SNSs
are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3923–3932},
numpages = {10},
keywords = {inclusive design, older adults, comparative evaluation, recommendations, social networking sites},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557248,
author = {Sun, Yuling and Ding, Xianghua and Lindtner, Silvia and Lu, Tun and Gu, Ning},
title = {Being Senior and ICT: A Study of Seniors Using ICT in China},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557248},
doi = {10.1145/2556288.2557248},
abstract = {System design for seniors often focuses on the decline of their biological capabilities
and social connectedness. This approach has been challenged as too simplistic to capture
what it really means to be senior. This paper presents a qualitative study of 17 seniors
in urban China (age ranging from 50s to 70s), who have adopted and incorporated ICT
into their daily lives. Findings from this study show that the ways in which seniors
attend to ICT are not simply shaped by changes in health or other wellbeing, but also
by their life attitudes, value systems, relationships to younger generations as well
as historical specifics during their coming of age. This paper contributes by showing
that 1) what it means to be senior is shaped from within a whole social ecology of
past and current experiences, values and interactions; 2) senior identities are not
fixed, but continuously negotiated, articulated and enacted through ICT; 3) social
interaction and access of technologies are highly intertwined.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3933–3942},
numpages = {10},
keywords = {companionship, qualitative study, cross-generational communication, elders, seniors, ict, values},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250986,
author = {Thomas, John},
title = {Session Details: Computer Mediated Intimacy and Romance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250986},
doi = {10.1145/3250986},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557127,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Zhang, Guo and Pace, Tyler},
title = {The Lonely Raccoon at the Ball: Designing for Intimacy, Sociability, and Selfhood},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557127},
doi = {10.1145/2556288.2557127},
abstract = {Designing for sociable systems requires, among other abilities, a sensitivity to the
meanings, structures, and nuances of technology-mediated experiences that are simultaneously
felt by users to be intimate and also social. Such a sensitivity is not easily acquired,
and design researchers have recommended the use of social theories to guide designers'
readings of technology-mediated social experiences. We use philosopher Michel Foucault's
theory of identity (and social power, discourse, sexuality, creativity, and style)
known as "the care of the self," as a scaffold with which to produce a sensitive interpretation
of the intimacy (and expert social creative) practices of adult users of the virtual
world Second Life (SL). This reading sheds light on several skilled and creative intimacy
practices in SL. It also offers a philosophically grounded hermeneutic strategy for
designers interested in analyzing intimate experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3943–3952},
numpages = {10},
keywords = {intimacy, sociability, user experience, amateurs, sexuality, creativity, design, hci, maker culture, identity, making},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557177,
author = {Scissors, Lauren E. and Roloff, Michael E and Gergle, Darren},
title = {Room for Interpretation: The Role of Self-Esteem and CMC in Romantic Couple Conflict},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557177},
doi = {10.1145/2556288.2557177},
abstract = {This work explores the role of communication technologies during romantic couple conflict,
and the impact that self-esteem has on behavior, preferences for communication channels,
and attitudes about mediated communication during conflict. Results revealed that
lower levels of self-esteem and communicating via text messaging (vs. face-to-face)
were associated with increased distancing and perceived partner distancing behaviors.
Lower levels of self-esteem and using mediated communication were also associated
with a greater likelihood of thinking that a conflict had a negative impact on the
relationship. Yet, there was no evidence to suggest that individuals with lower levels
of self-esteem exhibited more negative behaviors and perceptions in text-based communication
than in FtF communication. In addition, lower levels of self-esteem were associated
with increased use of and preferences for text-based mediated communication over FtF
communication during conflict. Overall, this study suggests that both self-esteem
and communication channel impact the nature of romantic couple conflict.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3953–3962},
numpages = {10},
keywords = {self-esteem, conflict, relationships, romantic couples, computer-mediated communication (cmc), cscw},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557343,
author = {Mullenbach, Joe and Shultz, Craig and Colgate, J. Edward and Piper, Anne Marie},
title = {Exploring Affective Communication through Variable-Friction Surface Haptics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557343},
doi = {10.1145/2556288.2557343},
abstract = {This paper explores the use of variable friction surface haptics enabled by the TPad
Tablet to support affective communication between pairs of users. We introduce three
haptic applications for the TPad Tablet (text messaging, image sharing, and virtual
touch) and evaluate the applications with 24 users, including intimate couples and
strangers. Participants used haptics to communicate literal texture, denote action
within a scene, convey emotional information, highlight content, express and engage
in physical playfulness, and to provide one's partner with an experience or sensation.
We conclude that users readily associate haptics with emotional expression and that
the intimacy of touch in the contexts we study is best suited for communications with
close social partners.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3963–3972},
numpages = {10},
keywords = {tablet, touchscreen, variable friction, communication, surface haptics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557166,
author = {Park, Joohee and Park, Young-Woo and Nam, Tek-Jin},
title = {Wrigglo: Shape-Changing Peripheral for Interpersonal Mobile Communication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557166},
doi = {10.1145/2556288.2557166},
abstract = {We introduce Wrigglo, a shape-changing smart phone peripheral that allows pairs of
users to share wriggling movements with one another. Attached to a smart phone, Wrigglo
captures the sender's motions and activates the receiver's Wrigglo which repeats the
motion simultaneously. The result of our in-lab use observation with twelve couples
showed that Wrigglo supported emotional and functional roles of body gestures and
postures, creating vocabularies related to the motion of specific body parts and,
to some extent, reflected the connected user's presence through the device's movement.
Through its peripheral anthropomorphization, Wrigglo can deliver new forms of telepresence
by embodied posturing and gesturing in mobile communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3973–3976},
numpages = {4},
keywords = {remote communication, shape-changing, mobile peripheral},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250987,
author = {Olivier, Patrick},
title = {Session Details: Network of Care},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250987},
doi = {10.1145/3250987},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557035,
author = {Siriaraya, Panote and Ang, Chee Siang},
title = {Recreating Living Experiences from Past Memories through Virtual Worlds for People with Dementia},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557035},
doi = {10.1145/2556288.2557035},
abstract = {This paper describes a study aimed to understand the use of 3D virtual world (VW)
technology to support life engagement for people with dementia in long-term care.
Three versions of VW prototypes (reminiscence room, virtual tour and gardening) utilising
gestured-base interaction were developed iteratively. These prototypes were tested
with older residents (80+) with dementia in care homes and their caregivers. Data
collection was based on observations of how the residents and care staff interacted
collaboratively with the VW. We discussed in depth the use of VWs in stimulating past
memories and how this technology could help enhance their sense of self through various
means. We also highlighted key approaches in designing VWs to sustain attention, create
ludic experiences and facilitate interaction for older people with dementia.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3977–3986},
numpages = {10},
keywords = {older people, dementia, 3d virtual worlds, gesture-based interaction, care home},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557307,
author = {Wan, Lin and M\"{u}ller, Claudia and Wulf, Volker and Randall, David William},
title = {Addressing the Subtleties in Dementia Care: Pre-Study &amp; Evaluation of a GPS Monitoring System},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557307},
doi = {10.1145/2556288.2557307},
abstract = {In this work we present a user-centered development process for a GPS-based monitoring
system to be used in dementia care. Our research covers a full design process including
a qualitative-empirical pre-study, the prototyping process and the investigation of
long-term appropriation processes of the stable prototypes in three different practice
environments. Specifically, we deal with the problem of 'wandering' by persons suffering
from late-phase dementia. Although GPS tracking is not a novel technological objective,
the usage of those systems in dementia care remains very low. The paper therefore
takes a socio-technical stance on development and appropriation of GPS technology
in dementia care and assesses the practical and ideological issues surrounding care
to understand why. We additionally provide design research in two different settings,
familial and institutional care, and report on the design of a GPS-based tracking
system reflecting these considerations. What comes to the fore is the need for ICT
to reflect complex organizational, ideological and practical issues that form part
of a moral universe where sensitivity is crucial.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3987–3996},
numpages = {10},
keywords = {evaluation, gps monitoring system, autonomy, privacy, dementia},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557344,
author = {Zhou, Xiaomu and Sun, Si and Yang, Jiang},
title = {Sweet Home: Understanding Diabetes Management via a Chinese Online Community},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557344},
doi = {10.1145/2556288.2557344},
abstract = {China has overtaken India and the U.S. as host to the largest diabetic population
in the world. Many problems exist in the Chinese healthcare system and very small
number of diabetes patients receives treatment. Our paper reports on a case study
through the lens of an online diabetes patient community, Sweet Home. We conducted
participant observations, text analysis, and interviews, to understand the health
management of patients at Sweet Home. Our findings reveal that patients' understanding
of diabetes, their choice of treatments, their routine management, and their interactions
with others (in the physical world) and among themselves (in the online world) are
influenced by many factors: belief in traditional Chinese versus western medicine,
cultural and social norms regarding social eating and drinking, conflicts over self-images,
and responses to comments and pressures of coworkers. That is, social context may
significantly affect patients' behaviors and each individual patient's actions may
also help reshape the social context. We draw out implications for how our society
as a whole may respond to these issues, from the perspective of public health, education,
and information technology design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3997–4006},
numpages = {10},
keywords = {chronic disease management, chinese table culture, online community, diabetes, social eating, chinese medicine},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250989,
author = {Kirk, David},
title = {Session Details: Driving Interfaces and Evaluations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250989},
doi = {10.1145/3250989},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557321,
author = {Hong, Jin-Hyuk and Margines, Ben and Dey, Anind K.},
title = {A Smartphone-Based Sensing Platform to Model Aggressive Driving Behaviors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557321},
doi = {10.1145/2556288.2557321},
abstract = {Driving aggressively increases the risk of accidents. Assessing a person's driving
style is a useful way to guide aggressive drivers toward having safer driving behaviors.
A number of studies have investigated driving style, but they often rely on the use
of self-reports or simulators, which are not suitable for the real-time, continuous,
automated assessment and feedback on the road. In order to understand and model aggressive
driving style, we construct an in-vehicle sensing platform that uses a smartphone
instead of using heavyweight, expensive systems. Utilizing additional cheap sensors,
our sensing platform can collect useful information about vehicle movement, maneuvering
and steering wheel movement. We use this data and apply machine learning to build
a driver model that evaluates drivers' driving styles based on a number of driving-related
features. From a naturalistic data collection from 22 drivers for 3 weeks, we analyzed
the characteristics of drivers who have an aggressive driving style. Our model classified
those drivers with an accuracy of 90.5% (violation-class) and 81% (questionnaire-class).
We describe how, in future work, our model can be used to provide real-time feedback
to drivers using only their current smartphone.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4047–4056},
numpages = {10},
keywords = {smartphone, in-vehicle sensing platform, driving assessment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557068,
author = {Solovey, Erin T. and Zec, Marin and Garcia Perez, Enrique Abdon and Reimer, Bryan and Mehler, Bruce},
title = {Classifying Driver Workload Using Physiological and Driving Performance Data: Two Field Studies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557068},
doi = {10.1145/2556288.2557068},
abstract = {Understanding the driver's cognitive load is important for evaluating in-vehicle user
interfaces. This paper describes experiments to assess machine learning classification
algorithms on their ability to automatically identify elevated cognitive workload
levels in drivers, leading towards the development of robust tools for automobile
user interface evaluation. We look at using both driver performance as well as physiological
data. These measures can be collected in real-time and do not interfere with the primary
task of driving the vehicle. We report classification accuracies of up to 90% for
detecting elevated levels of cognitive load, and show that the inclusion of physiological
data leads to higher classification accuracy than vehicle sensor data evaluated alone.
Finally, we show results suggesting that models can be built to classify cognitive
load across individuals, instead of building individual models for each per-son. By
collecting data from drivers in two large field studies on the highway (20 drivers
and 99 drivers), this work extends prior work and demonstrates feasibility and potential
of such measures for HCI research in vehicles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4057–4066},
numpages = {10},
keywords = {physiological computing, machine learning, driving, heart rate, cognitive workload, skin conductance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556988,
author = {Politis, Ioannis and Brewster, Stephen A. and Pollick, Frank},
title = {Evaluating Multimodal Driver Displays under Varying Situational Urgency},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556988},
doi = {10.1145/2556288.2556988},
abstract = {Previous studies have investigated audio, visual and tactile driver warnings, indicating
the importance of communicating the appropriate level of urgency to the drivers. However,
these modalities have never been combined exhaustively and tested under conditions
of varying situational urgency to assess their effectiveness both in the presence
and absence of critical driving events. This paper describes an experiment evaluating
all multimodal combinations of such warnings under two contexts of situational urgency:
a lead car braking and not braking. The results showed that participants responded
quicker to more urgent warnings, especially in the presence of a car braking. They
also responded faster to the multimodal as opposed to unimodal signals. Driving behaviour
improved in the presence of the warnings and the absence of a car braking. These results
highlight the influence of urgency and number of modalities in warning design and
indicate the utility of non-visual warnings in driving.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4067–4076},
numpages = {10},
keywords = {response time, lateral deviation, simulator, situational urgency, multimodal interaction, steering angle, visual, tactile, warnings, audio},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250990,
author = {M\"{u}ller, J\"{o}rg},
title = {Session Details: Gesture-Based Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250990},
doi = {10.1145/3250990},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557113,
author = {Rovelo Ruiz, Gustavo Alberto and Vanacken, Davy and Luyten, Kris and Abad, Francisco and Camahort, Emilio},
title = {Multi-Viewer Gesture-Based Interaction for Omni-Directional Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557113},
doi = {10.1145/2556288.2557113},
abstract = {Omni-directional video (ODV) is a novel medium that offers viewers a 360º panoramic
recording. This type of content will become more common within our living rooms in
the near future, seeing that immersive displaying technologies such as 3D television
are on the rise. However, little attention has been given to how to interact with
ODV content. We present a gesture elicitation study in which we asked users to perform
mid-air gestures that they consider to be appropriate for ODV interaction, both for
individual as well as collocated settings. We are interested in the gesture variations
and adaptations that come forth from individual and collocated usage. To this end,
we gathered quantitative and qualitative data by means of observations, motion capture,
questionnaires and interviews. This data resulted in a user-defined gesture set for
ODV, alongside an in-depth analysis of the variation in gestures we observed during
the study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4077–4086},
numpages = {10},
keywords = {multi-user interaction, omni-directional video, user-defined gestures, gesture elicitation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557219,
author = {Reetz, Adrian and Gutwin, Carl},
title = {Making Big Gestures: Effects of Gesture Size on Observability and Identification for Co-Located Group Awareness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557219},
doi = {10.1145/2556288.2557219},
abstract = {Co-located work environments allow people to maintain awareness by observing others'
actions (called consequen-tial communication), but the computerization of many tasks
has dramatically reduced the observability of work actions. The recent interest in
gestural interaction techniques offers the possibility of recreating some of the noticeability
of previous work actions, but little is known about the observability and identifiability
of command gestures. To investigate these basic issues, we carried out a study that
asked people to observe and identify different sizes and morphologies of gestures
from different locations, while carrying out an attention-demanding primary task.
We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures.
Our study showed that although size did have significant effects, as expected, even
small gestures were highly noticeable (rates above 75%) and identifiable (rates above
69%). Our results provide empirical guidance about the ways that gesture size, morphology,
and location affect observation, and show that gestural interaction has potential
for improving group awareness in co-located environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4087–4096},
numpages = {10},
keywords = {group awareness, consequential communication, gestures},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557051,
author = {Probst, Kathrin and Lindlbauer, David and Haller, Michael and Schwartz, Bernhard and Schrempf, Andreas},
title = {A Chair as Ubiquitous Input Device: Exploring Semaphoric Chair Gestures for Focused and Peripheral Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557051},
doi = {10.1145/2556288.2557051},
abstract = {During everyday office work we are used to controlling our computers with keyboard
and mouse, while the majority of our body remains unchallenged and the physical workspace
around us stays largely unattended. Addressing this untapped potential, we explore
the concept of turning a flexible office chair into a ubiquitous input device. To
facilitate daily desktop work, we propose the utilization of semaphoric chair gestures
that can be assigned to specific application functionalities. The exploration of two
usage scenarios in the context of focused and peripheral interaction demonstrates
high potential of chair gestures as additional input modality for opportunistic, hands-free
interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4097–4106},
numpages = {10},
keywords = {gestural interaction, interactive chair, input technologies},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557373,
author = {Valdes, Consuelo and Eastman, Diana and Grote, Casey and Thatte, Shantanu and Shaer, Orit and Mazalek, Ali and Ullmer, Brygg and Konkel, Miriam K.},
title = {Exploring the Design Space of Gestural Interaction with Active Tokens through User-Defined Gestures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557373},
doi = {10.1145/2556288.2557373},
abstract = {Multi-touch and tangible interfaces provide unique opportunities for enhancing learning
and discovery with big data. However, existing interaction techniques have limitations
when manipulating large data sets. Our goal is to define novel interaction techniques
for multi-touch and tangible interfaces, which support the construction of complex
queries for big data. In this paper, we present results from a study which investigates
the use of gestural interaction with active tokens for manipulating large data sets.
In particular, we studied user expectations of a hybrid tangible and gestural language
engaging this space. Our main results include a vocabulary of user-defined gestures
for interaction with active tokens, which extends beyond familiar multi-touch gestures;
characterization of the design space of gestural interaction with active tokens; and
insight into participants' mental models, including common metaphors. We also present
implications for the design of multi-touch and tangible interfaces with active tokens.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4107–4116},
numpages = {10},
keywords = {multi-display environments, gestures, queries, physical tokens., cross-device interaction, tabletop},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250991,
author = {Quigley, Aaron},
title = {Session Details: Interactive Surfaces and Pervasive Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250991},
doi = {10.1145/3250991},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557365,
author = {Winkler, Christian and Seifert, Julian and Dobbelstein, David and Rukzio, Enrico},
title = {Pervasive Information through Constant Personal Projection: The Ambient Mobile Pervasive Display (AMP-D)},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557365},
doi = {10.1145/2556288.2557365},
abstract = {The vision of pervasive ambient information displays which show relevant information
has not yet come true. One of the main reasons is the limited number of available
displays in the environment which is a fundamental requirement of the original vision.
We introduce the concept of an Ambient Mobile Pervasive Display AMP-D which is a wearable
projector system that constantly projects an ambient information display in front
of the user. The floor display provides serendipitous access to public and personal
information. The display is combined with a projected display on the user's hand,
forming a continuous interaction space that is controlled by hand gestures. The paper
introduces this novel device concept, discusses its interaction design, and explores
its advantages through various implemented application examples. Furthermore, we present
the AMP-D prototype which illustrates the involved challenges concerning hardware,
sensing, and visualization.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4117–4126},
numpages = {10},
keywords = {augmented reality, pervasive displays, personal projection, ambient displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557071,
author = {R\"{a}dle, Roman and Jetter, Hans-Christian and M\"{u}ller, Jens and Reiterer, Harald},
title = {Bigger is Not Always Better: Display Size, Performance, and Task Load during Peephole Map Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557071},
doi = {10.1145/2556288.2557071},
abstract = {Dynamic peephole navigation is an increasingly popular technique for navigating large
information spaces such as maps. Users can view the map through handheld, spatially
aware displays that serve as peepholes and navigate the map by moving these displays
in physical space. We conducted a controlled experiment of peephole map navigation
with 16 participants to better understand the effect of a peephole's size on users'
map navigation behavior, navigation performance, and task load. Simulating different
peephole sizes from 4' (smartphone) up to 120' (control condition), we confirmed that
larger peepholes significantly improve learning speed, navigation speed, and reduce
task load; however, this added benefit diminishes with growing sizes. Our data shows
that a relatively small, tablet-sized peephole can serve as a 'sweet spot' between
peephole size and both user navigation performance and user task load.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4127–4136},
numpages = {10},
keywords = {peephole navigation, experimentation, navigation performance, display size, user study, map navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557172,
author = {Grau, Alex M. and Hendee, Charles and Rizzo, John-Ross and Perlin, Ken},
title = {Mechanical Force Redistribution: Enabling Seamless, Large-Format, High-Accuracy Surface Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557172},
doi = {10.1145/2556288.2557172},
abstract = {We present Mechanical Force Redistribution (MFR): a method of sensing which creates
an anti-aliased image of forces applied to a surface. This technique mechanically
focuses the force from a surface onto adjacent discrete forcels (force sensing cells)
by way of protrusions (small bumps or pegs), allowing for high-accuracy interpolation
between adjacent discrete forcels. MFR works with any force transducing technique
or material, including force variable resistive inks, piezoelectric materials and
capacitive force plates. MFR sensors can be tiled such that the signal is continuous
across contiguous tiles. By minimizing active materials and computational complexity,
MFR makes large-format interactive walls, collaborative tabletops and high-resolution
floor tiles possible and economically feasible.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4137–4146},
numpages = {10},
keywords = {tabletop, sensor, input device, walls, large format, floors, mechanical force redistribution, force, pressure},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557020,
author = {Liu, Can and Chapuis, Olivier and Beaudouin-Lafon, Michel and Lecolinet, Eric and Mackay, Wendy E.},
title = {Effects of Display Size and Navigation Type on a Classification Task},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557020},
doi = {10.1145/2556288.2557020},
abstract = {The advent of ultra-high resolution wall-size displays and their use for complex tasks
require a more systematic analysis and deeper understanding of their advantages and
drawbacks compared with desktop monitors. While previous work has mostly addressed
search, visualization and sense-making tasks, we have designed an abstract classification
task that involves explicit data manipulation. Based on our observations of real uses
of a wall display, this task represents a large category of applications. We report
on a controlled experiment that uses this task to compare physical navigation in front
of a wall-size display with virtual navigation using pan-and-zoom on the desktop.
Our main finding is a robust interaction effect between display type and task difficulty:
while the desktop can be faster than the wall for simple tasks, the wall gains a sizable
advantage as the task becomes more difficult. A follow-up study shows that other desktop
techniques (overview+detail, lens) do not perform better than pan-and-zoom and are
therefore slower than the wall for difficult tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4147–4156},
numpages = {10},
keywords = {pan-and-zoom, physical navigation, wall-size display, lenses, overview+detail, classification task},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250992,
author = {Odom, William},
title = {Session Details: Social Media for Relationships},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250992},
doi = {10.1145/3250992},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557059,
author = {Brubaker, Jed R. and Dombrowski, Lynn S. and Gilbert, Anita M. and Kusumakaulika, Nafiri and Hayes, Gillian R.},
title = {Stewarding a Legacy: Responsibilities and Relationships in the Management of Post-Mortem Data},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557059},
doi = {10.1145/2556288.2557059},
abstract = {This paper extends research on the giving and inheriting of digital artifacts by examining
social network site accounts post-mortem. Given the important role that social network
sites play in online bereavement practices, we conducted a series of in-depth qualitative
interviews to explore issues around inheritance and post-mortem data management of
Facebook accounts. We found that participants focused less on ownership of the data,
and instead on the duties and potential conflicts associated with maintaining an account
post-mortem. Subsequently, we argue for 'stewardship' as an alternative to inheritance
for framing post-mortem data management practices. Analysis of post-mortem data management
activities highlights how stewards are accountable and responsible to the deceased
and various survivors. However, weighing competing responsibilities is complicated
by varied relationships with disparate survivors, as well as the inability to consult
with the deceased. Based on our findings, we claim that post-mortem solutions need
to account for the needs of stewards in addition to those of the deceased and survivors.
We suggest that a model of stewardship better accounts for the interpersonal responsibilities
that accompany online data than inheritance alone.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4157–4166},
numpages = {10},
keywords = {inheritance, social network sites, digital legacy, stewardship, qualitative study, death, facebook},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557059_R50298,
author = {Strnadl, Christoph F.},
title = {Review ID:R50298 for DOI: 10.1145/2556288.2557059},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557059_R50298}
}

@inproceedings{10.1145/2556288.2557290,
author = {Waycott, Jenny and Davis, Hilary and Vetere, Frank and Morgans, Amee and Gruner, Alan and Ozanne, Elizabeth and Kulik, Lars},
title = {Captioned Photographs in Psychosocial Aged Care: Relationship Building and Boundary Work},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557290},
doi = {10.1145/2556288.2557290},
abstract = {In this paper we examine the use of a novel social technology to support the provision
of formal aged care services to clients who live in their own homes. Social technologies
offer enormous potential for enhancing aged care, but research on their use in aged
care has largely focused on institutional or informal care settings, rather than formal
care in the home. Meanwhile, technologies for aging in place typically focus on monitoring
and security, rather than psychosocial support. We conducted a field study in which
aged care managers used a photo and message-sharing tool to communicate with clients
living in their own homes. Our findings demonstrate that visual and social forms of
communication are valuable for supporting psychosocial care-giving, but there are
barriers to effectively adopting new communication tools in this setting. Time constraints
inhibited care managers' use of the technology, which was also influenced by their
efforts to carefully maintain boundaries between their personal and professional lives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4167–4176},
numpages = {10},
keywords = {ipad, aged care, social technologies, photo-sharing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557255,
author = {Forghani, Azadeh and Neustaedter, Carman},
title = {The Routines and Needs of Grandparents and Parents for Grandparent-Grandchild Conversations over Distance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557255},
doi = {10.1145/2556288.2557255},
abstract = {A variety of systems have been designed to support communication between distance-separated
grandparents and grandchildren. Yet there are few studies of the actual conversational
routines of these groups as well as the social challenges that might arise as a result
of technology usage. To address this gap, we conducted an interview and diary study
that explores the conversational practices of distance-separated grandparents and
young grandchildren (aged 3-10) from the perspective of the grandparents and parents
of the children. Our results describe the focus of grandparent-grandchild conversations
and show that grandparent-grandchild communication is not without its challenges:
grandparents sometimes feel self-conscious, perceive that parents or children will
be annoyed if they ask too many questions, and do not want to interfere too much in
their grandchildren's lives. The implication is that designs should attempt to support
the conversation routines and needs of grandparents and grandchildren while attempting
to mitigate the social challenges.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4177–4186},
numpages = {10},
keywords = {family communication, grandparent and grandchild communication, design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557094,
author = {Burke, Moira and Kraut, Robert E.},
title = {Growing Closer on Facebook: Changes in Tie Strength through Social Network Site Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557094},
doi = {10.1145/2556288.2557094},
abstract = {Scientists debate whether people grow closer to their friends through social networking
sites like Facebook, whether those sites displace more meaningful interaction, or
whether they simply reflect existing ties. Combining server log analysis and longitudinal
surveys of 3,649 Facebook users reporting on relationships with 26,134 friends, we
find that communication on the site is associated with changes in reported relationship
closeness, over and above effects attributable to their face-to-face, phone, and email
contact. Tie strength increases with both one-on-one communication, such as posts,
comments, and messages, and through reading friends' broadcasted content, such as
status updates and photos. The effect is greater for composed pieces, such as comments,
posts, and messages than for 'one-click' actions such as 'likes.' Facebook has a greater
impact on non-family relationships and ties who do not frequently communicate via
other channels.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4187–4196},
numpages = {10},
keywords = {facebook, social relationships, friendship, social network sites, families, tie strength, relational closeness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557094_R51179,
author = {Peoples, Cathryn},
title = {Review ID:R51179 for DOI: 10.1145/2556288.2557094},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557094_R51179}
}

@dataset{10.1145/review-2556288.2557094_R51216,
author = {Jane, Sandhya},
title = {Review ID:R51216 for DOI: 10.1145/2556288.2557094},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557094_R51216}
}


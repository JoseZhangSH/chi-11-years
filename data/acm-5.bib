@inproceedings{10.1145/3025453.3026042,
author = {Correia, Nuno N. and Tanaka, Atau},
title = {AVUI: Designing a Toolkit for Audiovisual Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026042},
doi = {10.1145/3025453.3026042},
abstract = {The combined use of sound and image has a rich history, from audiovisual artworks
to research exploring the potential of data visualization and sonification. However,
we lack standard tools or guidelines for audiovisual (AV) interaction design, particularly
for live performance. We propose the AVUI (AudioVisual User Interface), where sound
and image are used together in a cohesive way in the interface; and an enabling technology,
the ofxAVUI toolkit. AVUI guidelines and ofxAVUI were developed in a three-stage process,
together with AV producers: 1) participatory design activities; 2) prototype development;
3) encapsulation of prototype as a plug-in, evaluation, and roll out. Best practices
identified include: reconfigurable interfaces and mappings; object-oriented packaging
of AV and UI; diverse sound visualization; flexible media manipulation and management.
The toolkit and a mobile app developed using it have been released as open-source.
Guidelines and toolkit demonstrate the potential of AVUI and offer designers a convenient
framework for AV interaction design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1093–1104},
numpages = {12},
keywords = {audiovisual, participatory design, hackathons, interface builder, toolkit, crossmodal interaction, prototyping, interaction design, user interface},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025827,
author = {Ichinco, Michelle and Hnin, Wint Yee and Kelleher, Caitlin L.},
title = {Suggesting API Usage to Novice Programmers with the Example Guru},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025827},
abstract = {Programmers, especially novices, often have difficulty learning new APIs (Application
Programming Interfaces). Existing research has not fully addressed novice programmers'
unawareness of all available API methods. To help novices discover new and appropriate
uses for API methods, we designed a system called the Example Guru. The Example Guru
suggests context-relevant API methods based on each programmer's code. The suggestions
provide contrasting examples to demonstrate how to use the API methods. To evaluate
the effectiveness of the Example Guru, we ran a study comparing novice programmers'
use of the Example Guru and documentation-inspired API information. We found that
twice as many participants accessed the Example Guru suggestions compared to documentation
and that participants used more than twice as many new API methods after accessing
suggestions than documentation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1105–1117},
numpages = {13}
}

@inproceedings{10.1145/3025453.3025599,
author = {Feit, Anna Maria and Williams, Shane and Toledo, Arturo and Paradiso, Ann and Kulkarni, Harish and Kane, Shaun and Morris, Meredith Ringel},
title = {Toward Everyday Gaze Input: Accuracy and Precision of Eye Tracking and Implications for Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025599},
doi = {10.1145/3025453.3025599},
abstract = {For eye tracking to become a ubiquitous part of our everyday interaction with computers,
we first need to understand its limitations outside rigorously controlled labs, and
develop robust applications that can be used by a broad range of users and in various
environments. Toward this end, we collected eye tracking data from 80 people in a
calibration-style task, using two different trackers in two lighting conditions. We
found that accuracy and precision can vary between users and targets more than six-fold,
and report on differences between lighting, trackers, and screen regions. We show
how such data can be used to determine appropriate target sizes and to optimize the
parameters of commonly used filters. We conclude with design recommendations and examples
how our findings and methodology can inform the design of error-aware adaptive applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1118–1130},
numpages = {13},
keywords = {adaptive interfaces, gaze filters, eye tracking, sensor noise},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025965,
author = {Tewell, Jordan and Bird, Jon and Buchanan, George R.},
title = {Heat-Nav: Using Temperature Changes as Navigation Cues},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025965},
doi = {10.1145/3025453.3025965},
abstract = {HCI is increasingly exploring how temperature can be used as an interaction modality.
One challenge is that temperature changes are perceived over the course of seconds.
This can be attributed to both the slow response time of skin thermoreceptors and
the latency of the technology used to heat and cool the skin. For this reason, thermal
cues are typically used to communicate single states, such as an emotion, and then
there is a pause of tens of seconds to allow the skin to re-adapt to a neutral temperature
before sending another signal. In contrast, this paper presents the first experimental
demonstration that continuous temperature changes can guide behaviour: significantly
improving performance in a 2D maze navigation task, without having to return to a
neutral state before a new signal is sent. We discuss how continuous thermal feedback
may be used for real world navigational tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1131–1135},
numpages = {5},
keywords = {thermal feedback, navigation, thermal haptics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025876,
author = {Warner, Jeremy and Guo, Philip J.},
title = {CodePilot: Scaffolding End-to-End Collaborative Software Development for Novice Programmers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025876},
doi = {10.1145/3025453.3025876},
abstract = {Novice programmers often have trouble installing, configuring, and managing disparate
tools (e.g., version control systems, testing infrastructure, bug trackers) that are
required to become productive in a modern collaborative software development environment.
To lower the barriers to entry into software development, we created a prototype IDE
for novices called CodePilot, which is, to our knowledge, the first attempt to integrate
coding, testing, bug reporting, and version control management into a real-time collaborative
system. CodePilot enables multiple users to connect to a web-based programming session
and work together on several major phases of software development. An eight-subject
exploratory user study found that first-time users of CodePilot spontaneously used
it to assume roles such as developer/tester and developer/assistant when creating
a web application together in pairs. Users felt that CodePilot could aid in scaffolding
for novices, situational awareness, and lowering barriers to impromptu collaboration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1136–1141},
numpages = {6},
keywords = {pair programming, collaborative ide, novice programmers},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025917,
author = {Ikeda, Kazushi and Hoashi, Keiichiro},
title = {Crowdsourcing GO: Effect of Worker Situation on Mobile Crowdsourcing Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025917},
doi = {10.1145/3025453.3025917},
abstract = {The increasing popularity of mobile crowdsourcing platforms has enabled crowd workers
to accept jobs wherever/whenever they are, and also provides opportunity for task
requesters to order time/location specific tasks to workers. Since workers on mobile
platforms are working on the go, the situation of the workers is expected to influence
their performance. However, the effects of mobile worker situations to task performance
is an uninvestigated area. In this paper, our research question is, "do worker situations
affect task completion, price and quality on mobile crowdsourcing platforms?" We draw
on economics and psychology research to examine whether worker situations such as
busyness, fatigue and presence of companions affect their performance. Our three-week
between-subjects field experiment revealed that worker busyness caused 30.1% relative
decrease of task completion rate. Mean accepted task price increased by 7.6% when
workers are with companions. Worker fatigue caused 37.4% relative decrease of task
quality.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1142–1153},
numpages = {12},
keywords = {worker performance, mobile crowdsourcing, situational effect, crowdsourcing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025737,
author = {Lin, Allen Yilun and Kuehl, Kate and Sch\"{o}ning, Johannes and Hecht, Brent},
title = {Understanding "Death by GPS": A Systematic Study of Catastrophic Incidents Associated with Personal Navigation Technologies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025737},
doi = {10.1145/3025453.3025737},
abstract = {Catastrophic incidents associated with GPS devices and other personal navigation technologies
are sufficiently common that these incidents have been given a colloquial nickname:
"Death by GPS". While there is a significant body of work on the use of personal navigation
technologies in everyday scenarios, no research has examined these technologies' roles
in catastrophic incidents. In this paper, we seek to address this gap in the literature.
Borrowing techniques from public health research and communication studies, we construct
a corpus of 158 detailed news reports of unique catastrophic incidents associated
with personal navigation technologies. We then identify key themes in these incidents
and the roles that navigation technologies played in them, e.g. missing road characteristics
data contributed to over 25% of these incidents. With the goal of reducing casualties
associated with personal navigation technologies, we outline implications for design
and research that emerge from our results, e.g. advancing "space usage rule" mapping,
incorporating weather information in routing, and improving visual and audio instructions
in complex situations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1154–1166},
numpages = {13},
keywords = {map apps, gps, satnav, personal navigation technologies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3026015,
author = {Johnson, Isaac and McMahon, Connor and Sch\"{o}ning, Johannes and Hecht, Brent},
title = {The Effect of Population and "Structural" Biases on Social Media-Based Algorithms: A Case Study in Geolocation Inference Across the Urban-Rural Spectrum},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026015},
abstract = {Much research has shown that social media platforms have substantial population biases.
However, very little is known about how these population biases affect the many algorithms
that rely on social media data. Focusing on the case study of geolocation inference
algorithms and their performance across the urban-rural spectrum, we establish that
these algorithms exhibit significantly worse performance for underrepresented populations
(i.e. rural users). We further establish that this finding is robust across both text-
and network-based algorithm designs. However, we also show that some of this bias
can be attributed to the design of algorithms themselves rather than population biases
in the underlying data sources. For instance, in some cases, algorithms perform badly
for rural users even when we substantially overcorrect for population biases by training
exclusively on rural data. We discuss the implications of our findings for the design
and study of social media-based algorithms.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1167–1178},
numpages = {12}
}

@inproceedings{10.1145/3025453.3025495,
author = {Colley, Ashley and Thebault-Spieker, Jacob and Lin, Allen Yilun and Degraen, Donald and Fischman, Benjamin and H\"{a}kkil\"{a}, Jonna and Kuehl, Kate and Nisi, Valentina and Nunes, Nuno Jardim and Wenig, Nina and Wenig, Dirk and Hecht, Brent and Sch\"{o}ning, Johannes},
title = {The Geography of Pok\'{e}Mon GO: Beneficial and Problematic Effects on Places and Movement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025495},
doi = {10.1145/3025453.3025495},
abstract = {The widespread popularity of Pok\'{e}mon GO presents the first opportunity to observe
the geographic effects of location-based gaming at scale. This paper reports the results
of a mixed methods study of the geography of Pok\'{e}mon GO that includes a five-country
field survey of 375 Pok\'{e}mon GO players and a large scale geostatistical analysis of
game elements. Focusing on the key geographic themes of places and movement, we find
that the design of Pok\'{e}mon GO reinforces existing geographically-linked biases (e.g.
the game advantages urban areas and neighborhoods with smaller minority populations),
that Pok\'{e}mon GO may have instigated a relatively rare large-scale shift in global
human mobility patterns, and that Pok\'{e}mon GO has geographically-linked safety risks,
but not those typically emphasized by the media. Our results point to geographic design
implications for future systems in this space such as a means through which the geographic
biases present in Pok\'{e}mon GO may be counteracted.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1179–1192},
numpages = {14},
keywords = {geography, geoHCI, pok'mon GO, location-based games, algorithmic bias, augmented reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025882,
author = {Dasgupta, Aritra and Burrows, Susannah and Han, Kyungsik and Rasch, Philip J.},
title = {Empirical Analysis of the Subjective Impressions and Objective Measures of Domain Scientists' Visual Analytic Judgments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025882},
abstract = {Scientists often use specific data analysis and presentation methods familiar within
their domain. But does high familiarity drive better analytical judgment? This question
is especially relevant when familiar methods themselves can have shortcomings: many
visualizations used conventionally for scientific data analysis and presentation do
not follow established best practices. This necessitates new methods that might be
unfamiliar yet prove to be more effective. But there is little empirical understanding
of the relationships between scientists' subjective impressions about familiar and
unfamiliar visualizations and objective measures of their visual analytic judgments.
To address this gap and to study these factors, we focus on visualizations used for
comparison of climate model performance. We report on a comprehensive survey-based
user study with 47 climate scientists and present an analysis of: i) relationships
among scientists' familiarity, their perceived levels of comfort, confidence, accuracy,
and objective measures of accuracy, and ii) relationships among domain experience,
visualization familiarity, and post-study preference.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1193–1204},
numpages = {12}
}

@inproceedings{10.1145/3025453.3025596,
author = {Chen, Xiuli and Starke, Sandra Dorothee and Baber, Chris and Howes, Andrew},
title = {A Cognitive Model of How People Make Decisions Through Interaction with Visual Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025596},
doi = {10.1145/3025453.3025596},
abstract = {In this paper we report a cognitive model of how people make decisions through interaction.
The model is based on the assumption that interaction for decision making is an example
of a Partially Observable Markov Decision Process (POMDP) in which observations are
made by limited perceptual systems that model human foveated vision and decisions
are made by strategies that are adapted to the task. We illustrate the model by applying
it to the task of determining whether to block a credit card given a number of variables
including the location of a transaction, its amount, and the customer history. Each
of these variables have a different validity and users may weight them accordingly.
The model solves the POMDP by learning patterns of eye movements (strategies) adapted
to different presentations of the data. We compare the model behavior to human performance
on the credit card transaction task.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1205–1216},
numpages = {12},
keywords = {cognitive modeling, eye movements, decision making., visual search, markov decision process, reinforcement learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025850,
author = {Hull, Carmen and Willett, Wesley},
title = {Building with Data: Architectural Models as Inspiration for Data Physicalization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025850},
abstract = {In this paper we analyze the role of physical scale models in the architectural design
process and apply insights from architecture for the creation and use of data physicalizations.
Based on a survey of the architecture literature on model making and ten interviews
with practicing architects, we describe the role of physical models as a tool for
exploration and communication. From these observations, we identify trends in the
use of physical models in architecture, which have the potential to inform the design
of data physicalizations. We identify four functions of architectural modeling that
can be directly adapted for use in the process of building rich data models. Finally,
we discuss how the visualization community can apply observations from architecture
to the design of new data physicalizations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1217–1264},
numpages = {48}
}

@inproceedings{10.1145/3025453.3025626,
author = {Kery, Mary Beth and Horvath, Amber and Myers, Brad},
title = {Variolite: Supporting Exploratory Programming by Data Scientists},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025626},
doi = {10.1145/3025453.3025626},
abstract = {How do people ideate through code? Using semi-structured interviews and a survey,
we studied data scientists who program, often with small scripts, to experiment with
data. These studies show that data scientists frequently code new analysis ideas by
building off of their code from a previous idea. They often rely on informal versioning
interactions like copying code, keeping unused code, and commenting out code to repurpose
older analysis code while attempting to keep those older analyses intact. Unlike conventional
version control, these informal practices allow for fast versioning of any size code
snippet, and quick comparisons by interchanging which versions are run. However, data
scientists must maintain a strong mental map of their code in order to distinguish
versions, leading to errors and confusion. We explore the needs for improving version
control tools for exploratory tasks, and demonstrate a tool for lightweight local
versioning, called Variolite, which programmers found usable and desirable in a preliminary
usability study.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1265–1276},
numpages = {12},
keywords = {version control systems (vcs), variants, variations, end-user programming, exploratory data analysis},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025838,
author = {Koesten, Laura M. and Kacprzak, Emilia and Tennison, Jenifer F. A. and Simperl, Elena},
title = {The Trials and Tribulations of Working with Structured Data: -A Study on Information Seeking Behaviour},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025838},
doi = {10.1145/3025453.3025838},
abstract = {Structured data such as databases, spreadsheets and web tables is becoming critical
in every domain and professional role. Yet we still do not know much about how people
interact with it. Our research focuses on the information seeking behaviour of people
looking for new sources of structured data online, including the task context in which
the data will be used, data search, and the identification of relevant datasets from
a set of possible candidates. We present a mixed-methods study covering in-depth interviews
with 20 participants with various professional backgrounds, supported by the analysis
of search logs of a large data portal. Based on this study, we propose a framework
for human structured-data interaction and discuss challenges people encounter when
trying to find and assess data that helps their daily work. We provide design recommendations
for data publishers and developers of online data platforms such as data catalogs
and marketplaces. These recommendations highlight important questions for HCI research
to improve how people engage and make use of this incredibly useful online resource.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1277–1289},
numpages = {13},
keywords = {data portal, human data interaction, data search},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025912,
author = {Matejka, Justin and Fitzmaurice, George},
title = {Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025912},
doi = {10.1145/3025453.3025912},
abstract = {Datasets which are identical over a number of statistical properties, yet produce
dissimilar graphs, are frequently used to illustrate the importance of graphical representations
when exploring data. This paper presents a novel method for generating such datasets,
along with several examples. Our technique varies from previous approaches in that
new datasets are iteratively generated from a seed dataset through random perturbations
of individual data points, and can be directed towards a desired outcome through a
simulated annealing optimization strategy. Our method has the benefit of being agnostic
to the particular statistical properties that are to remain constant between the datasets,
and allows for control over the graphical appearance of resulting output.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1290–1294},
numpages = {5},
keywords = {anscombe, scatter plots, visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025576,
author = {Kangasr\"{a}\"{a}si\"{o}, Antti and Athukorala, Kumaripaba and Howes, Andrew and Corander, Jukka and Kaski, Samuel and Oulasvirta, Antti},
title = {Inferring Cognitive Models from Data Using Approximate Bayesian Computation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025576},
doi = {10.1145/3025453.3025576},
abstract = {An important problem for HCI researchers is to estimate the parameter values of a
cognitive model from behavioral data. This is a difficult problem, because of the
substantial complexity and variety in human behavioral strategies. We report an investigation
into a new approach using approximate Bayesian computation (ABC) to condition model
parameters to data and prior knowledge. As the case study we examine menu interaction,
where we have click time data only to infer a cognitive model that implements a search
behaviour with parameters such as fixation duration and recall probability. Our results
demonstrate that ABC (i) improves estimates of model parameter values, (ii) enables
meaningful comparisons between model variants, and (iii) supports fitting models to
individual users. ABC provides ample opportunities for theoretical HCI research by
allowing principled inference of model parameter values and their uncertainty.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1295–1306},
numpages = {12},
keywords = {cognitive models in hci, computational rationality, approximate bayesian computation, inverse modeling},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025707,
author = {Liu, Wanyu and Bailly, Gilles and Howes, Andrew},
title = {Effects of Frequency Distribution on Linear Menu Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025707},
doi = {10.1145/3025453.3025707},
abstract = {While it is well known that menu usage follows a Zipfian distribution, there has been
little interest in the impact of menu item frequency distribution on user's behavior.
In this note, we explore the effects of frequency distribution on average menu performance
as well as individual item performance. We compare three frequency distributions of
menu item usage: Uniform; Zipfian with s=1 and Zipfian with s=2. The results show
that (1) user's behavior is sensitive to different frequency distributions at both
menu and item level; (2) individual item selection time depends on, not only its frequency,
but also the frequency of other items in the menu. Finally, we discuss how these findings
might have impacts on menu design, empirical studies and menu modeling.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1307–1312},
numpages = {6},
keywords = {frequency distribution, user performance, menus},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025558,
author = {McNaney, Roisin and Vines, John and Mercer, Jamie and Mexter, Leon and Welsh, Daniel and Young, Tony},
title = {DemYouth: Co-Designing and Enacting Tools to Support Young People's Engagement with People with Dementia},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025558},
doi = {10.1145/3025453.3025558},
abstract = {There is a growing body of research examining the role of technology in supporting
the care of--and relationships surrounding--people with dementia, yet little attention
has been given to how this relates to younger family members. We conducted a qualitative
study based on a series of 6 co-design workshops conducted with 14 young people who
had personal experience with dementia. Initially, our workshops focused on understanding
the difficulties that young people face when engaging, interacting and being with
people with dementia. Initial analysis of workshop data informed the design of three
digital tool concepts that were used as the basis for user enactment workshops. Our
findings highlight the young people's desire to be more involved in their family discussions
around dementia and a need for them to find new ways to connect with their loved ones
with dementia. We offer a set of design considerations for future systems that support
these needs and reflect on some of the complexities we faced around engaging young
people in this difficult topic of discussion.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1313–1325},
numpages = {13},
keywords = {dementia, young people, mobile applications, co-design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025527,
author = {Morrissey, Kellie and McCarthy, John and Pantidi, Nadia},
title = {The Value of Experience-Centred Design Approaches in Dementia Research Contexts},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025527},
doi = {10.1145/3025453.3025527},
abstract = {Experience-Centred Design (ECD) has been applied in numerous HCI projects to call
attention to the particular and dialogical nature of people's experiences with technology.
In this paper, we report on ECD within the context of publicly-funded, long-stay residential
dementia care, where the approach helped to highlight aspects of participants' felt
experience, and informed sensitive and meaningful design responses. This study contributes
an extended understanding of the quality of experience and the means of making sense
in dementia, as well as unpicking the potential of ECD to support enriched experience
and contextual meaning-making for people with dementia. Finally, we delineate what
it is about Experience-Centred Design that differentiates the approach from other
often-used approaches in designing in dementia contexts: 1) explorative thinking,
2) working within 'cuttings-out of time and space', 3) careful yet expressive methodology
and documentation, and 4) working together to imagine futures. We end with considerations
of how the contributions of this research may extend to other experience-centred projects
in challenging settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1326–1338},
numpages = {13},
keywords = {dementia, experience, embodiment, design methods, design approaches, experience-centred design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025715,
author = {Long, Kiel and Bakewell, Lyndsey L. and McNaney, Roisin C. and Vasileiou, Konstantina and Atkinson, Mark and Barreto, Manuela and Barnett, Julie and Wilson, Michael and Lawson, Shaun and Vines, John},
title = {Connecting Those That Care: Designing for Transitioning, Talking, Belonging and Escaping},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025715},
doi = {10.1145/3025453.3025715},
abstract = {Care provision in many nations increasingly relies on the work of informal, or non-professional,
carers. Often these carers experience substantial disruptions and reductions to their
own sociality, weakened social support networks and, ultimately, a heightened risk
of social isolation. We describe a qualitative study, comprised of interviews, design
workshops and probes, that investigated the social and community support practices
of carers. Our findings highlight issues related to becoming and recognising being
a carer, and feelings of being ignored by, and isolated from, others. We also note
the benefits that sharing between carers can bring, and routes to coping and relaxing
from the burdens of care. We conclude with design considerations for facilitating
new forms of digitally mediated support that connect those that care, emphasising
design qualities related to transitioning, talking, belonging and escaping.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1339–1351},
numpages = {13},
keywords = {co-design, qualitative study, carers, informal care},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025676,
author = {Tabor, Aaron and Bateman, Scott and Scheme, Erik and Flatla, David R. and Gerling, Kathrin},
title = {Designing Game-Based Myoelectric Prosthesis Training},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025676},
abstract = {A myoelectric prosthesis (myo) is a dexterous artificial limb controlled by muscle
contractions. Learning to use a myo can be challenging, so extensive training is often
required to use a myo prosthesis effectively. Signal visualizations and simple muscle-controlled
games are currently used to help patients train their muscles, but are boring and
frustrating. Furthermore, current training systems require expensive medical equipment
and clinician oversight, restricting training to infrequent clinical visits. To address
these limitations, we developed a new game that promotes fun and success, and shows
the viability of a low-cost myoelectric input device. We adapted a user-centered design
(UCD) process to receive feedback from patients, clinicians, and family members as
we iteratively addressed challenges to improve our game. Through this work, we introduce
a free and open myo training game, provide new information about the design of myo
training games, and reflect on an adapted UCD process for the practical iterative
development of therapeutic games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1352–1363},
numpages = {12}
}

@inproceedings{10.1145/3025453.3026041,
author = {Bartram, Lyn and Patra, Abhisekh and Stone, Maureen},
title = {Affective Color in Visualization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026041},
doi = {10.1145/3025453.3026041},
abstract = {Communicating the right affect, a feeling, experience or emotion, is critical in creating
engaging visual communication. We carried out three studies examining how different
color properties (lightness, chroma and hue) and different palette properties (combinations
and distribution of colors) contribute to different affective interpretations in information
visualization where the numbers of colors is typically smaller than the rich palettes
used in design. Our results show how color and palette properties can be manipulated
to achieve affective expressiveness even in the small sets of colors used for data
encoding in information visualization.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1364–1374},
numpages = {11},
keywords = {affective visualization, color perception, design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025592,
author = {Kim, Yea-Seul and Reinecke, Katharina and Hullman, Jessica},
title = {Explaining the Gap: Visualizing One's Predictions Improves Recall and Comprehension of Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025592},
doi = {10.1145/3025453.3025592},
abstract = {Information visualizations use interactivity to enable user-driven querying of visualized
data. However, users' interactions with their internal representations, including
their expectations about data, are also critical for a visualization to support learning.
We present multiple graphically-based techniques for eliciting and incorporating a
user's prior knowledge about data into visualization interaction. We use controlled
experiments to evaluate how graphically eliciting forms of prior knowledge and presenting
feedback on the gap between prior knowledge and the observed data impacts a user's
ability to recall and understand the data. We find that participants who are prompted
to reflect on their prior knowledge by predicting and self-explaining data outperform
a control group in recall and comprehension. These effects persist when participants
have moderate or little prior knowledge on the datasets. We discuss how the effects
differ based on text versus visual presentations of data. We characterize the design
space of graphical prediction and feedback techniques and describe design recommendations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1375–1386},
numpages = {12},
keywords = {information visualization, self-explanation, prediction, mental models, internal representations of data},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025922,
author = {Correll, Michael and Heer, Jeffrey},
title = {Regression by Eye: Estimating Trends in Bivariate Visualizations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025922},
doi = {10.1145/3025453.3025922},
abstract = {Observing trends and predicting future values are common tasks for viewers of bivariate
data visualizations. As many charts do not explicitly include trend lines or related
statistical summaries, viewers often visually estimate trends directly from a plot.
How reliable are the inferences viewers draw when performing such regression by eye?
Do particular visualization designs or data features bias trend perception? We present
a series of crowdsourced experiments that assess the accuracy of trends estimated
using regression by eye across a variety of bivariate visualizations, and examine
potential sources of bias in these estimations. We find that viewers accurately estimate
trends in many standard visualizations of bivariate data, but that both visual features
(e.g., "within-the-bar" bias) and data features (e.g., the presence of outliers) can
result in visual estimates that systematically diverge from standard least-squares
regression models.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1387–1396},
numpages = {10},
keywords = {graphical perception, regression, information visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026024,
author = {Chang, Chunlei and Bach, Benjamin and Dwyer, Tim and Marriott, Kim},
title = {Evaluating Perceptually Complementary Views for Network Exploration Tasks},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026024},
doi = {10.1145/3025453.3026024},
abstract = {We explore the relative merits of matrix, node-link and combined side-by-side views
for the visualisation of weighted networks with three controlled studies: (1) finding
the most effective visual encoding for weighted edges in matrix representations; (2)
comparing matrix, node-link and combined views for static weighted networks; and (3)
comparing MatrixWave, Sankey and combined views of both for event-sequence data. Our
studies underline that node-link and matrix views are suited to different analysis
tasks. For the combined view, our studies show that there is a perceptually complementary
effect in terms of improved accuracy for some tasks, but that there is a cost in terms
of longer completion time than the faster of the two techniques alone. Eye-movement
data shows that for many tasks participants strongly favour one of the two views,
after trying both in the training phase.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1397–1407},
numpages = {11},
keywords = {matrices, network visualization, node-link diagrams, sankey diagrams, event sequence data, eye tracking},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025541,
author = {van Kollenburg, Janne and Bogers, Sander and Deckers, Eva and Frens, Joep and Hummels, Caroline},
title = {How Design-Inclusive UXR Influenced the Integration of Project Activities: Three Design Cases from Industry},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025541},
abstract = {In this paper, we discuss how the implementation of design-inclusive User Experience
Research (UXR) has influenced the composition of UXR and design activities in the
industrial setting of Philips Design. We present three design case studies that were
executed in a time span of three years: a baby sleep project; a pregnancy project;
and a baby bottle-feeding project. Through a retrospective analysis we conclude that
the approach adopted in these cases progressed from complete separation of UXR and
design activities to design-inclusive UXR in which design forms an integral part of
research. This is reflected by a rearrangement of project activities to identify,
envision, enable and evaluate user experiences. Previously the UXR (identify and evaluate)
and design (envision and enable) activities were executed sequentially. Now, these
four project activities merge in studying design interventions in context over a prolonged
time, to iteratively explore and advance UX design qualities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1408–1418},
numpages = {11}
}

@inproceedings{10.1145/3025453.3025860,
author = {Hoang, Thuong and Reinoso, Martin and Joukhadar, Zaher and Vetere, Frank and Kelly, David},
title = {Augmented Studio: Projection Mapping on Moving Body for Physiotherapy Education},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025860},
doi = {10.1145/3025453.3025860},
abstract = {Physiotherapy students often struggle to translate anatomical knowledge from textbooks
into a dynamic understanding of the mechanics of body movements in real life patients.
We present the Augmented Studio, an augmented reality system that uses body tracking
to project anatomical structures and annotations over moving bodies for physiotherapy
education. Through a user and learner centered design approach, we established an
understanding that through augmentation and annotation, augmented reality technology
can enhance physiotherapy education. Augmented Studio enables augmentation through
projection mapping to display anatomical information such as muscles and skeleton
in real time on the body as it moves. We created a technique for annotation to create
projected hand-drawing on the moving body, to enable explicit communication of the
teacher's clinical reasoning strategies to the students. Findings from our pilot usability
study demonstrate a more engaging learning and teaching experience and increased communication
between teacher and students when using Augmented Studio.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1419–1430},
numpages = {12},
keywords = {spatial augmented reality, annotation, physiotherapy education, projection mapping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025805,
author = {Culbertson, Gabriel and Shen, Solace and Jung, Malte and Andersen, Erik},
title = {Facilitating Development of Pragmatic Competence through a Voice-Driven Video Learning Interface},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025805},
doi = {10.1145/3025453.3025805},
abstract = {Authentic foreign language videos are effective for developing pragmatic competence,
or sensitivity to meanings expressed by tone and word choice, and the ability to effectively
express these meanings. However, established methods for learning from foreign language
videos are primarily text-based (e.g.captioning). Using text, learners do not practice
aspects of oral performance (e.g. intonation, pausing, and pitch) that are important
to pragmatic competence. In this paper we present a voice-driven system where learners
practice and learn a foreign language by repeating phrases out loud from any video.
Utterances are transcribed and translated and, if captions are available, the system
indicates the correctness of the utterance. In an evaluation with 27 participants,
we show that participants more frequently used the voice-driven system than a comparison
text-based system. Furthermore, ina field study of 130 independent learners, we show
potential for community-driven resource collection.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1431–1440},
numpages = {10},
keywords = {pragmatic competence, speech-recognition, language learning, video learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025726,
author = {Vorvoreanu, Mihaela and Gray, Colin M. and Parsons, Paul and Rasche, Nancy},
title = {Advancing UX Education: A Model for Integrated Studio Pedagogy},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025726},
doi = {10.1145/3025453.3025726},
abstract = {The rapid growth of the UX profession has led to an increased need for qualified practitioners
and a proliferation of UX educational programs offered in both academia and industry.
In this note, we present the design and initial evaluation of a new studio-based undergraduate
program in UX--the first of its kind at a large, research-intensive US university.
The program includes several curricular innovations, such as an integrated studio
pedagogy in which six topical strands are interwoven across two types of studios.
These studios are interconnected and span five semesters of the undergraduate experience.
We present the curriculum model and the foundational principles that informed its
design. We describe the two types of studios and their interconnection, and present
early evaluation data showing that students are building valuable skills. The program
described in this note provides a trailblazing model for UX pedagogy at the undergraduate
level.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1441–1446},
numpages = {6},
keywords = {studio education, ux competence, hci pedagogy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025463,
author = {Shorey, Paden and Girouard, Audrey},
title = {Bendtroller: An Exploration of In-Game Action Mappings with a Deformable Game Controller},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025463},
abstract = {We explore controller input mappings for games using a deformable prototype that combines
deformation gestures with standard button input. In study one, we tested discrete
gestures using three simple games. We categorized the control schemes as binary (button
only), action, and navigation, the latter two named based on the game mechanics mapped
to the gestures. We found that the binary scheme performed the best, but gesture-based
control schemes are stimulating and appealing. Results also suggest that the deformation
gestures are best mapped to simple and natural tasks. In study two, we tested continuous
gestures in a 3D racing game using the same control scheme categorization. Results
were mostly consistent with study one but showed an improvement in performance and
preference for the action control scheme.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1447–1458},
numpages = {12}
}

@inproceedings{10.1145/3025453.3025743,
author = {Roo, Joan Sol and Gervais, Renaud and Frey, Jeremy and Hachet, Martin},
title = {Inner Garden: Connecting Inner States to a Mixed Reality Sandbox for Mindfulness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025743},
doi = {10.1145/3025453.3025743},
abstract = {Digital technology has been completely integrated into our daily lives, yet the potential
of technology to improve its users' life satisfaction is still largely untapped. Mindfulness,
the act of paying a deliberate and non-judgmental attention to the present moment,
has been shown to have a positive impact on a person's health and subjective well-being--commonly
called "happiness". Based on an iterative process with meditation teachers and practitioners,
we designed a new tool to support mindfulness practices. This tool takes the shape
of an augmented sandbox, designed to inspire the user's self-motivation and curiosity.
By shaping the sand, the user creates a living miniature world that is projected back
onto the sand. The natural elements of the garden are connected to real-time physiological
measurements, such as breathing, helping the user to stay focused on the body. Moreover,
using a Virtual Reality headset, they can travel inside their garden for a dedicated
meditation session. Preliminary results seem to indicate that the system is well suited
for mindfulness and induces a calm and mindful state on the user. The meditation teachers
envisioned the use of Inner Garden in their practice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1459–1470},
numpages = {12},
keywords = {virtual reality, mixed reality, mindfulness, spatial augmented reality, tangible interaction, calm technologies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025600,
author = {Lopes, Pedro and You, Sijing and Cheng, Lung-Pan and Marwecki, Sebastian and Baudisch, Patrick},
title = {Providing Haptics to Walls &amp; Heavy Objects in Virtual Reality by Means of Electrical Muscle Stimulation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025600},
doi = {10.1145/3025453.3025600},
abstract = {We explore how to add haptics to walls and other heavy objects in virtual reality.
When a user tries to push such an object, our system actuates the user's shoulder,
arm, and wrist muscles by means of electrical muscle stimulation, creating a counter
force that pulls the user's arm backwards. Our device accomplishes this in a wearable
form factor.In our first user study, participants wearing a head-mounted display interacted
with objects provided with different types of EMS effects. The repulsion design (visualized
as an electrical field) and the soft design (visualized as a magnetic field) received
high scores on "prevented me from passing through" as well as "realistic".In a second
study, we demonstrate the effectiveness of our approach by letting participants explore
a virtual world in which all objects provide haptic EMS effects, including walls,
gates, sliders, boxes, and projectiles.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1471–1482},
numpages = {12},
keywords = {force feedback, virtual reality, proprioception, real-walking, muscle interfaces, ems, haptics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025761,
author = {Sobel, Kiley and Bhattacharya, Arpita and Hiniker, Alexis and Lee, Jin Ha and Kientz, Julie A. and Yip, Jason C.},
title = {It Wasn't Really about the Pok\'{e}Mon: Parents' Perspectives on a Location-Based Mobile Game},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025761},
doi = {10.1145/3025453.3025761},
abstract = {Though prior work shows parents worry about screen media experiences displacing physical
activity and time outdoors, this research does not account for location-based mobile
games like Pok\'{e}mon GO, which specifically facilitate outdoor activity. To fill this
gap in the research, we surveyed and interviewed parents to understand (1) their values
and perceptions of this type of gameplay and (2) how they co-play Pok\'{e}mon GO with
their children. Our findings provide empirical evidence that, in addition to appreciating
the increased exercise and time outdoors, parents valued how play led to family bonding
experiences. Furthermore, some traditional concerns about screen time persisted in
this context, and new concerns about safety in real-world environments emerged. Parents
mitigated these concerns with rules and gameplay choices, such as maintaining control
of the mobile device, to ensure children were safe. This work contributes an empirical
understanding of families as co-users of technology and offers a generative lens to
study and design for joint media engagement among family members where gameplay differs
from normative notions of screen time.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1483–1496},
numpages = {14},
keywords = {augmented reality games, children, pokemon go, parental mediation, families, joint media engagement, location-based mobile games},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3026030,
author = {Bergstrom-Lehtovirta, Joanna and Boring, Sebastian and Hornb\ae{}k, Kasper},
title = {Placing and Recalling Virtual Items on the Skin},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026030},
abstract = {The human skin provides an ample, always-on surface for input to smart watches, mobile
phones, and remote displays. Using touch on bare skin to issue commands, however,
requires users to recall the location of items without direct visual feedback. We
present an in-depth study in which participants placed 30 items on the hand and forearm
and attempted to recall their locations. We found that participants used a variety
of landmarks, personal associations, and semantic groupings in placing the items on
the skin. Although participants most frequently used anatomical landmarks (e.g., fingers,
joints, and nails), recall rates were higher for items placed on personal landmarks,
including scars and tattoos. We further found that personal associations between items
improved recall, and that participants often grouped important items in similar areas,
such as family members on the nails. We conclude by discussing the implications of
our findings for design of skin-based interfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1497–1507},
numpages = {11}
}

@inbook{10.1145/3025453.3025981,
author = {Yoshino, Koichi and Obata, Koichi and Tokuhisa, Satoru},
title = {FLIPPIN': Exploring a Paper-Based Book UI Design in a Public Space},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025981},
abstract = {Digital information systems are increasingly being used in public spaces such as museums.
Such systems should be easily accessible, arouse interest and offer useful information,
and be easy to use. We present FLIPPIN' user interface (UI) system, which mimics the
look, feel, and usability of traditional books. We explored how the paper-based book
UI is designed to improve the usability problems in a public space while creating
the prototypes with the aim of introducing Japanese cultural assets and conducting
a field evaluation to compare the proposed system to a touch panel UI. The results
of evaluation indicated the positive effects of the system, especially in terms of
the usability and user's active appreciation derived from a physical book interaction.
In addition, we present design guidelines derived from our findings. The suggested
design guidelines are expected to facilitate the future development of effective interactive
digital information systems in public spaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1508–1517},
numpages = {10}
}

@inproceedings{10.1145/3025453.3025531,
author = {Sahibzada, Hasibullah and Hornecker, Eva and Echtler, Florian and Fischer, Patrick Tobias},
title = {Designing Interactive Advertisements for Public Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025531},
doi = {10.1145/3025453.3025531},
abstract = {Although public displays are increasingly being deployed in everyday situations, they
are still mostly used as auto-active information sources. Adding interactivity can
help to attract and engage users. We report on the design and in-the-wild evaluation
of an interactive advert for a public display in a tourist information center. We
evaluate and compare 3 different variants - non-interactive, interaction using body
tracking, and interaction using personal mobile devices - with respect to attracting
the attention and interaction from passersby. We further compare these variants with
an iterated version of the body tracking system with an extended tracking area. Our
findings include an unexpected reluctance of passersby to use their mobile device
in public, and the increased interactive area for body interaction resulting in increased
engagement and spontaneous multi-user interaction, while removing the so-called 'landing
effect'. Based on our findings, we suggest guidelines for interactive adverts on public
displays.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1518–1529},
numpages = {12},
keywords = {advertisements, full-body interaction, mobile devices, public display, in-the-wild study, kinect},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025563,
author = {Bowey, Jason T. and Depping, Ansgar E. and Mandryk, Regan L.},
title = {Don't Talk Dirty to Me: How Sexist Beliefs Affect Experience in Sexist Games},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025563},
abstract = {Research on sexism in digital games has suggested that women self-select out of playing
sexist games; however, assuming a homogenous gender-based response does not account
for the diversity of identities within a gender group. Gender-incongruent responses
to recent events like #gamergate implies that the gender of the participant is not
paramount to experience, but that their beliefs about gender roles are. To explore
the role of sexist beliefs on experience in sexist games, we created three versions
of a game that were identical except for the presence of sexist imagery and/or dialogue.
We show that enjoyment of sexist games is not predicted by player gender, but by the
player's pre-existing beliefs about gender. Furthermore, avatar identification is
the pathway through which enjoyment is facilitated. Finally, sexist dialogue does
not improve the play experience for anyone rather it harms experience for players
of all genders who do not hold sexist beliefs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1530–1543},
numpages = {14}
}

@inproceedings{10.1145/3025453.3025623,
author = {Shaer, Orit and Westendorf, Lauren and Knouf, Nicholas A. and Pederson, Claudia},
title = {Understanding Gaming Perceptions and Experiences in a Women's College Community},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025623},
doi = {10.1145/3025453.3025623},
abstract = {Recent trends in gaming diversification have shown that women are both an increasingly
significant pool of consumers and game producers, and regular victims of misogynistic
harassment. Such observations stress the importance of investigating the complex relationships
of women and gaming. In this paper, we draw upon perspectives from Feminist HCI to
extend the current knowledge of issues in gaming that are specific to women. We present
results from a mixed-methods study with 327 participants who are students and alumnae
of a women's college. Our findings shed light on the complex relationships of women
with games, with other gamers, and with gaming culture and industry. The results also
indicate that in some cases gender-related negative experiences of gaming have lasting
impact on the participation and self-confidence of young women. We conclude by discussing
the implications of our findings for the design of games, game development education,
and for the study of gaming.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1544–1557},
numpages = {14},
keywords = {video games, feminism, gender},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025813,
author = {Tekin, Burak S. and Reeves, Stuart},
title = {Ways of Spectating: Unravelling Spectator Participation in Kinect Play},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025813},
abstract = {We explore spectating on video game play as an interactional and participatory activity.
Drawing on a corpus of video recordings capturing 'naturally occurring' Kinect gaming
within home settings, we detail how the analytic 'work' of spectating is interactionally
accomplished as a matter of collaborative action with players and engagement in the
game. We examine: spectators supporting players with continuous 'scaffolding'; spectators
critiquing player technique during and between moments of play; spectators recognising
and complimenting competent player conduct; and spectators reflecting on prior play
to build instructions for the player. From this we draw out a number of points that
shift the conversation in HCI about 'the spectator' towards understanding and designing
for spectating as an interactional activity; that is, sequentially ordered and temporally
coordinated. We also discuss bodily conduct and the particular ways of 'seeing' involved
in spectating, and conclude with remarks on conceptual and design implications for
HCI.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1558–1570},
numpages = {13}
}

@inproceedings{10.1145/3025453.3025708,
author = {Lessel, Pascal and Vielhauer, Alexander and Kr\"{u}ger, Antonio},
title = {Expanding Video Game Live-Streams with Enhanced Communication Channels: A Case Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025708},
doi = {10.1145/3025453.3025708},
abstract = {Live-streaming of video games is a recent phenomenon. One driving factor is the direct
communication between the streamer and the audience. Currently, besides the platform-integrated
options such as text chats, streamers often use external sources to let their community
better articulate their opinions. In this paper we present a case study with our tool
Helpstone, a live-streaming tool for the card game Hearthstone. Helpstone provides
several new communication channels that allow for a better viewer-streamer interaction.
We evaluated the tool within a live-streaming session with 23 viewers using Helpstone,
and interviewed the streamer. The results indicate that not every implemented interactivity
option is relevant. However, in general, new communication channels appear to be valuable
and novel influence options are appreciated.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1571–1576},
numpages = {6},
keywords = {audience influence, hearthstone, twitch, streaming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025602,
author = {Schwind, Valentin and Knierim, Pascal and Tasci, Cagri and Franczak, Patrick and Haas, Nico and Henze, Niels},
title = {"These Are Not My Hands!": Effect of Gender on the Perception of Avatar Hands in Virtual Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025602},
abstract = {Rendering the user's body in virtual reality increases immersion and presence the
illusion of "being there". Recent technology enables determining the pose and position
of the hands to render them accordingly while interacting within the virtual environment.
Virtual reality applications often use realistic male or female hands, mimic robotic
hands, or cartoon hands. However, it is unclear how users perceive different hand
styles. We conducted a study with 14 male and 14 female participants in virtual reality
to investigate the effect of gender on the perception of six different hands. Quantitative
and qualitative results show that women perceive lower levels of presence while using
male avatar hands and male perceive lower levels of presence using non-human avatar
hands. While women dislike male hands, men accept and feel presence with avatar hands
of both genders. Our results highlight the importance of considering the users' diversity
when designing virtual reality experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1577–1582},
numpages = {6}
}

@inproceedings{10.1145/3025453.3025479,
author = {Beheshti, Elham and Kim, David and Ecanow, Gabrielle and Horn, Michael S.},
title = {Looking Inside the Wires: Understanding Museum Visitor Learning with an Augmented Circuit Exhibit},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025479},
doi = {10.1145/3025453.3025479},
abstract = {Understanding electrical circuits can be difficult for novices of all ages. In this
paper, we describe a science museum exhibit that enables visitors to make circuits
on an interactive tabletop and observe a simulation of electrons flowing through the
circuit. Our goal is to use multiple representations to help convey basic concepts
of current and resistance. To study visitor interaction and learning, we tested the
design at a popular science museum with 60 parent-child dyads in three conditions:
a control condition with no electron simulation; a condition with the simulation displayed
alongside the circuit on the same screen; and an augmented reality condition, with
the simulation displayed on a tablet that acts as a lens to see into the circuit.
Our findings show that children did significantly better on a post-test in both experimental
conditions, with children performing best in the AR condition. However, analysis of
session videos shows unexpected parent-child collaboration in the AR condition.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1583–1594},
numpages = {12},
keywords = {multiple representations, interactive surfaces, museum learning., augmented reality, design, agent-based modeling, electrical circuits},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025578,
author = {Snow, Stephen and Auffenberg, Frederik and schraefel, m. c.},
title = {Log It While It's Hot: Designing Human Interaction with Smart Thermostats for Shared Work Environments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025578},
doi = {10.1145/3025453.3025578},
abstract = {Smart thermostats offer impressive scope for adapting to users' thermal comfort preferences
and saving energy in shared work environments. Yet human interactions with smart thermostats
thus far amount to an assumption from designers that users are willing and able to
provide unbiased data at regular intervals; which may be unrealistic. In this paper
we highlight the variety of social factors which complicate users' relationships with
smart thermostats in shared work environments. These include social dynamics, expectations,
and contextually specific factors that influence motivations for interaction with
the system. In response we outline our framework towards a Smarter Thermostat: one
which better accounts for these messy social inevitabilities, is equipped for a decline
in user feedback over time and one which augments rather than attempts to replaces
human intelligence- thereby ensuring a smarter thermostat does not create dumber humans.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1595–1606},
numpages = {12},
keywords = {reciprocity, participatory sensing, office, smart thermostat, shared work environments, thermal comfort},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025853,
author = {Hsu, Yen-Chia and Dille, Paul and Cross, Jennifer and Dias, Beatrice and Sargent, Randy and Nourbakhsh, Illah},
title = {Community-Empowered Air Quality Monitoring System},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025853},
abstract = {Developing information technology to democratize scientific knowledge and support
citizen empowerment is a challenging task. In our case, a local community suffered
from air pollution caused by industrial activity. The residents lacked the technological
fluency to gather and curate diverse scientific data to advocate for regulatory change.
We collaborated with the community in developing an air quality monitoring system
which integrated heterogeneous data over a large spatial and temporal scale. The system
afforded strong scientific evidence by using animated smoke images, air quality data,
crowdsourced smell reports, and wind data. In our evaluation, we report patterns of
sharing smoke images among stakeholders. Our survey study shows that the scientific
knowledge provided by the system encourages agonistic discussions with regulators,
empowers the community to support policy making, and rebalances the power relationship
between stakeholders.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1607–1619},
numpages = {13}
}

@inproceedings{10.1145/3025453.3025799,
author = {Jakobi, Timo and Ogonowski, Corinna and Castelli, Nico and Stevens, Gunnar and Wulf, Volker},
title = {The Catch(Es) with Smart Home: Experiences of a Living Lab Field Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025799},
doi = {10.1145/3025453.3025799},
abstract = {Smart home systems are becoming an integral feature of the emerging home IT market.
Under this general term, products mainly address issues of security, energy savings
and comfort. Comprehensive systems that cover several use cases are typically operated
and managed via a unified dashboard. Unfortunately, research targeting user experience
(UX) design for smart home interaction that spans several use cases or covering the
entire system is scarce. Furthermore, existing comprehensive and user-centered longterm
studies on challenges and needs throughout phases of information collection, installation
and operation of smart home systems are technologically outdated. Our 18-month Living
Lab study covering 14 households equipped with smart home technology provides insights
on how to design for improving smart home appropriation. This includes a stronger
sensibility for household practices during setup and configuration, flexible visualizations
for evolving demands and an extension of smart home beyond the location.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1620–1633},
numpages = {14},
keywords = {design, user experience, smart home, qualitative study, living lab},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025909,
author = {Bagroy, Shrey and Kumaraguru, Ponnurangam and De Choudhury, Munmun},
title = {A Social Media Based Index of Mental Well-Being in College Campuses},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025909},
abstract = {Psychological distress in the form of depression, anxiety and other mental health
challenges among college students is a growing health concern. Dearth of accurate,
continuous, and multi-campus data on mental well-being presents significant challenges
to intervention and mitigation efforts in college campuses. We examine the potential
of social media as a new "barometer" for quantifying the mental well-being of college
populations. Utilizing student-contributed data in Reddit communities of over 100
universities, we first build and evaluate a transfer learning based classification
approach that can detect mental health expressions with 97% accuracy. Thereafter,
we propose a robust campus-specific Mental Well-being Index: MWI. We find that MWI
is able to reveal meaningful temporal patterns of mental well-being in campuses, and
to assess how their expressions relate to university attributes like size, academic
prestige, and student demographics. We discuss the implications of our work for improving
counselor efforts, and in the design of tools that can enable better assessment of
the mental health climate of college campuses.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1634–1646},
numpages = {13}
}

@inproceedings{10.1145/3025453.3025654,
author = {Gui, Xinning and Chen, Yu and Caldeira, Clara and Xiao, Dan and Chen, Yunan},
title = {When Fitness Meets Social Networks: Investigating Fitness Tracking and Social Practices on WeRun},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025654},
doi = {10.1145/3025453.3025654},
abstract = {The last two decades have seen growing interest in promoting physical activities by
using self-tracking technologies. Previous work has identified social interactions
in self-tracking as a crucial factor in motivating users to exercise. However, it
is unclear how integrating fitness features into complex pre-existing social network
affects users' fitness tracking practices and social interactions. In this research,
we address this gap through a qualitative study of 32 users of WeRun--a fitness plugin
of the widely adopted Chinese mobile social networking service WeChat. Our findings
indicate that sharing fitness data with pre-existing social networks motivates users
to continue self-tracking and enhances their existing social relationships. Nevertheless,
users' concerns about their online personal images lead to challenges around privacy.
We discuss how our study could advance understanding of the effects of fitness applications
built on top of pre-existing social networks. We present implications for future social
fitness applications design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1647–1659},
numpages = {13},
keywords = {social influence, sharing, personal informatics, social network, werun, self-tracking, behavior change, wearable, motivation, social interaction, wechat, physical activity, privacy, fitness},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025796,
author = {MacLeod, Haley and Bastin, Grace and Liu, Leslie S. and Siek, Katie and Connelly, Kay},
title = {"Be Grateful You Don't Have a Real Disease": Understanding Rare Disease Relationships},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025796},
doi = {10.1145/3025453.3025796},
abstract = {We characterize how people with rare diseases consider their support needs as being
met or neglected by different sources. After a 22-week study with 11 participants,
we found that people with rare diseases identify strongly with their conditions but
demonstrate a range of outlooks on their condition (positive, negative, and accepting).
We found that participants think of themselves as being in a separate "Rare World"
from the "normal" people in their lives and that relationships with friends and family
members are strained. On the other hand, online communities were described as valuable
sources of many forms of support, but do not adequately compensate for the lack of
tangible support in offline relationships. We propose an approach to facilitating
tangible support that leverages existing research on social matching, towards facilitating
support among people with different rare diseases to overcome geographic and symptomatic
challenges of coordinating support between people with the same rare disease.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1660–1673},
numpages = {14},
keywords = {chronic illness, social matching, social support, online health communities, timebanking, rare disease},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025747,
author = {Chung, Chia-Fang and Agapie, Elena and Schroeder, Jessica and Mishra, Sonali and Fogarty, James and Munson, Sean A.},
title = {When Personal Tracking Becomes Social: Examining the Use of Instagram for Healthy Eating},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025747},
abstract = {Many people appropriate social media and online communities in their pursuit of personal
health goals, such as healthy eating or increased physical activity. However, people
struggle with impression management, and with reaching the right audiences when they
share health information on these platforms. Instagram, a popular photo-based social
media platform, has attracted many people who post and share their food photos. We
aim to inform the design of tools to support healthy behaviors by understanding how
people appropriate Instagram to track and share food data, the benefits they obtain
from doing so, and the challenges they encounter. We interviewed 16 women who consistently
record and share what they eat on Instagram. Participants tracked to support themselves
and others in their pursuit of healthy eating goals. They sought social support for
their own tracking and healthy behaviors and strove to provide that support for others.
People adapted their personal tracking practices to better receive and give this support.
Applying these results to the design of health tracking tools has the potential to
help people better access social support.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1674–1687},
numpages = {14}
}

@inbook{10.1145/3025453.3025745,
author = {Manuel, Jennifer and Vigar, Geoff and Bartindale, Tom and Comber, Rob},
title = {Participatory Media: Creating Spaces for Storytelling in Neighbourhood Planning},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025745},
abstract = {Neighbourhood planning devolves power to communities to create their own planning
policy but traditional forms of participation are still relied upon. And despite the
ubiquitous nature of technology in society, digital participation methods are rarely
used. In this paper, we outline fieldwork with two neighbourhood planning groups who
used participatory media technology to improve engagement though the art of storytelling.
We focus on the configuration of participatory media as a way to widen participation
and enable story creation and sharing amongst citizens. We highlight that storytelling
using media technology can provide a model of and a model for the way we "do" neighbourhood
planning whilst emphasising the challenges of ensuring processes are linked to tangible
actions and encouraging the multiplicity of stories.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1688–1701},
numpages = {14}
}

@inbook{10.1145/3025453.3026035,
author = {Zhou, Huiyuan and Edrah, Aisha and MacKay, Bonnie and Reilly, Derek},
title = {Block Party: Synchronized Planning and Navigation Views for Neighbourhood Expeditions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026035},
abstract = {Mobile wayfinding and guide apps have become indispensable tools for navigating unfamiliar
urban spaces. Such applications address targeted, "just-in-time" queries, but are
not optimally designed for multi-point expeditions that can quickly build route and
survey-level familiarity with a neighbourhood. We first conducted an experimental
simulation involving a homebuying scenario to assess the usefulness of a popular mobile
wayfinding and search application (Google Maps) for exploring a neighbourhood. We
then designed a prototype application called Block Party that addresses a number of
limitations of Google Maps for this purpose, and evaluated it in a second replica
study. The results suggested that application designs that facilitate switching among
distinct but synchronized navigation views such as Block Party might support more
efficient usage and the selection of task-appropriate views, leading to better overall
spatial awareness.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1702–1713},
numpages = {12}
}

@inproceedings{10.1145/3025453.3025948,
author = {Smith, Nancy and Bardzell, Shaowen and Bardzell, Jeffrey},
title = {Designing for Cohabitation: Naturecultures, Hybrids, and Decentering the Human in Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025948},
doi = {10.1145/3025453.3025948},
abstract = {Recent research in urban informatics has presented the city as both a complex technological
center and a diverse cultural, social, and political entity. However, there has been
little research into the changing role that nature plays in urban space, particularly
when it comes to understanding how animals have adapted to life in technological and
networked cities. In the wake of urbanization, new kinds of cohabitation, including
increased interactions between humans and animals, has resulted in new challenges
for those working in urban informatics. We leverage key concepts in the Anthropocene-naturecultures,
hybrids, and decentering the human in design-to unpack the entanglements of animal-human-computer
interaction in two design cases: The Big Cat Behavioral Tracking Initiative and The
Phenology Clock. We contribute to urban informatics and HCI research by reflecting
on ways in which design can promote new forms of cohabitation and support a broader
conception of the city that sees animals as an essential part of the urban landscape.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1714–1725},
numpages = {12},
keywords = {animal-computer interaction, anthropocene, posthumanism, urban informatics, cohabitation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025705,
author = {Johnson, Isaac and Sosik, Victoria Schwanda and Ballard, Kacey},
title = {Stranger Searching in a Strange Land: The Impact of Familiarity on Local Search},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025705},
doi = {10.1145/3025453.3025705},
abstract = {Local search entails looking for places, such as restaurants or hotels, in a geographically-constrained
region. Within local search, it has been observed that an individual's familiarity
with their environment (i.e. how well they know the area in a query of the form "{places}
in {area}") impacts which places they are most interested in visiting. Less well-understood
though is how people's information preferences differ during 1) different phases of
the search process and 2) based on their level of familiarity. Through a series of
surveys in the domain of dining, we explore how familiarity moderates what level of
information is useful to an individual about restaurant location when choosing a place
to visit. We further examine how these preferences vary between regions and phases
of local search (deciding on a restaurant or determining how to go). We contribute
an understanding of people's information preferences during search, building on prior
research of how offline context impacts online needs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1726–1730},
numpages = {5},
keywords = {localization, local search, familiarity, dining},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025723,
author = {Ranasinghe, Nimesha and Jain, Pravar and Karwita, Shienny and Tolley, David and Do, Ellen Yi-Luen},
title = {Ambiotherm: Enhancing Sense of Presence in Virtual Reality by Simulating Real-World Environmental Conditions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025723},
abstract = {In this paper, we present and evaluate Ambiotherm, a wearable accessory for Head Mounted
Displays (HMD) that provides thermal and wind stimuli to simulate real-world environmental
conditions, such as ambient temperatures and wind conditions, to enhance the sense
of presence in Virtual Reality (VR). Ambiotherm consists of a Ambient Temperature
Module that is attached to the user's neck, a Wind Simulation Module focused towards
the user's face, and a Control Module utilizing Bluetooth communication. We demonstrate
Ambiotherm with two VR environments, a hot desert, and a snowy mountain, to showcase
the different types of simulated environmental conditions. We conduct several studies
to 1) address design factors of the system and 2) evaluate Ambiotherm's effect on
factors related to a user's sense of presence. Our findings show that the addition
of wind and thermal stimuli significantly improves sensory and realism factors, contributing
towards an enhanced sense of presence when compared to traditional VR experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1731–1742},
numpages = {12}
}

@inproceedings{10.1145/3025453.3025614,
author = {Wilson, Graham and Brewster, Stephen A.},
title = {Multi-Moji: Combining Thermal, Vibrotactile &amp; Visual Stimuli to Expand the Affective Range of Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025614},
doi = {10.1145/3025453.3025614},
abstract = {This paper explores the combination of multiple concurrent modalities for conveying
emotional information in HCI: temperature, vibration and abstract visual displays.
Each modality has been studied individually, but can only convey a limited range of
emotions within two-dimensional valence-arousal space. This paper is the first to
systematically combine multiple modalities to expand the available affective range.
Three studies were conducted: Study 1 measured the emotionality of vibrotactile feedback
by itself; Study 2 measured the perceived emotional content of three bimodal combinations:
vibrotactile + thermal, vibrotactile + visual and visual + thermal. Study 3 then combined
all three modalities. Results show that combining modalities increases the available
range of emotional states, particularly in the problematic top-right and bottom-left
quadrants of the dimensional model. We also provide a novel lookup resource for designers
to identify stimuli to convey a range of emotions},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1743–1755},
numpages = {13},
keywords = {emotion, visual feedback, vibration, thermal feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025844,
author = {Tewell, Jordan and Bird, Jon and Buchanan, George R.},
title = {The Heat is On: A Temperature Display for Conveying Affective Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025844},
doi = {10.1145/3025453.3025844},
abstract = {Previous research has investigated whether temperature can augment a range of media
including music, images and video. We describe the first experiment to investigate
whether temperature can augment emotion conveyed by text messages. A challenge in
prior work has been ensuring users can discern different thermal signals. We present
an improved technique for thermal feedback that uses an array of three thermal stimulators.
We demonstrate that the Thermal Array Display (TAD) increases users' ability to identify
temperatures within a narrower range, compared to using a single thermal stimulator.
While text messages dominate valence in the absence of context for temperature, the
TAD consistently conveys arousal, and can enhance arousal of text messages, especially
those that are emotionally neutral. We discuss potential applications of augmenting
text with temperature.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1756–1767},
numpages = {12},
keywords = {thermal haptics, affective computing, thermal feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025471,
author = {Mauriello, Matthew Louis and Saha, Manaswi and Brown, Erica Brown and Froehlich, Jon E.},
title = {Exploring Novice Approaches to Smartphone-Based Thermographic Energy Auditing: A Field Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025471},
abstract = {The recent integration of thermal cameras with commodity smartphones presents an opportunity
to engage the public in evaluating energy-efficiency issues in the built environment.
However, it is unclear how novice users without professional experience or training
approach thermographic energy auditing activities. In this paper, we recruited 10
participants for a four-week field study of end-user behavior exploring novice approaches
to semi-structured thermographic energy auditing tasks. We analyze thermographic imagery
captured by participants as well as weekly surveys and post-study debrief interviews.
Our findings suggest that while novice users perceived thermal cameras as useful in
identifying energy-efficiency issues in buildings, they struggled with interpretation
and confidence. We characterize how novices perform thermographic-based energy auditing,
synthesize key challenges, and discuss implications for design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1768–1780},
numpages = {13}
}

@inproceedings{10.1145/3025453.3025956,
author = {Ma, Xiao and Andalibi, Nazanin and Barkhuus, Louise and Naaman, Mor},
title = {"People Are Either Too Fake or Too Real": Opportunities and Challenges in Tie-Based Anonymity},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025956},
doi = {10.1145/3025453.3025956},
abstract = {In recent years, several mobile applications allowed individuals to anonymously share
information with friends and contacts, without any persistent identity marker. The
functions of these "tie-based" anonymity services may be notably different than other
social media services. We use semi-structured interviews to qualitatively examine
motivations, practices and perceptions in two tie-based anonymity apps: Secret (now
defunct, in the US) and Mimi (in China). Among the findings, we show that: (1) while
users are more comfortable in self-disclosure, they still have specific practices
and strategies to avoid or allow identification; (2) attempts for deidentification
of others are prevalent and often elaborate; and (3) participants come to expect both
negativity and support in response to posts. Our findings highlight unique opportunities
and potential benefits for tie-based anonymity apps, including serving disclosure
needs and social probing. Still, challenges for making such applications successful,
for example the prevalence of negativity and bullying, are substantial.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1781–1793},
numpages = {13},
keywords = {anonymity, cmc, social media, wumii, self-disclosure, mimi, secret},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025465,
author = {Whiting, Emily and Ouf, Nada and Makatura, Liane and Mousas, Christos and Shu, Zhenyu and Kavan, Ladislav},
title = {Environment-Scale Fabrication: Replicating Outdoor Climbing Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025465},
doi = {10.1145/3025453.3025465},
abstract = {Despite rapid advances in 3D printing, fabricating large, durable and robust artifacts
is impractical with current technology. We focus on a particularly challenging environment-scale
artifact: rock climbing routes. We propose a prototype fabrication method to replicate
part of an outdoor climbing route and enable the same sensorimotor experience in an
indoor gym. We start with 3D reconstruction of the rock wall using multi-view stereo
and use reference videos of a climber in action to identify localized rock features
that are necessary for ascent. We create 3D models akin to traditional indoor climbing
holds, fabricated using rapid prototyping, molding and casting techniques. This results
in robust holds accurately replicating the features and configuration of the original
rock route. Validation was performed on two rock climbing sites in New Hampshire and
Utah. We verified our results by comparing climbers' moves on the indoor replicas
and original outdoor routes.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1794–1804},
numpages = {11},
keywords = {rapid prototyping, 3d reconstruction, rock climbing, sports technologies, fabrication, terrain modeling},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3026048,
author = {Fan, Min and Antle, Alissa N. and Hoskyn, Maureen and Neustaedter, Carman and Cramer, Emily S.},
title = {Why Tangibility Matters: A Design Case Study of At-Risk Children Learning to Read and Spell},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026048},
abstract = {Tangibles may be effective for reading applications. Letters can be represented as
3D physical objects. Words are spatially organized collections of letters. We explore
how tangibility impacts reading and spelling acquisition for young Anglophone children
who have dyslexia. We describe our theory-based design rationale and present a mixed-methods
case study of eight children using our PhonoBlocks system. All children made significant
gains in reading and spelling on trained and untrained (new) words, and could apply
all spelling rules a month later. We discuss the design features of our system that
contributed to effective learning processes, resulting in successful learning outcomes:
dynamic colour cues embedded in 3D letters, which can draw attention to how letter(s)
position changes their sounds; and the form of 3D tangible letters, which can enforce
correct letter orientation and enable epistemic strategies in letter organization
that simplify spelling tasks. We conclude with design guidelines for tangible reading
systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1805–1816},
numpages = {12}
}

@inproceedings{10.1145/3025453.3026036,
author = {Fraser, C. Ailie and Grossman, Tovi and Fitzmaurice, George},
title = {WeBuild: Automatically Distributing Assembly Tasks Among Collocated Workers to Improve Coordination},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026036},
doi = {10.1145/3025453.3026036},
abstract = {Physical construction and assembly tasks are often carried out by groups of collocated
workers, and they can be difficult to coordinate. Group members must spend time deciding
how to split up the task, how to assign subtasks to each other, and in what order
subtasks should be completed. Informed by an observational study examining group coordination
challenges, we built a task distribution system called WeBuild. Our custom algorithm
dynamically assigns subtasks to workers in a group, taking into account factors such
as the dependencies between subtasks and the skills of each group member. Each worker
views personalized step-by-step instructions on a mobile phone, while a dashboard
visualizes the entire process. An initial study found that WeBuild reduced the start-up
time needed to coordinate and begin a task, and provides direction for future research
to build on toward improving group efficiency and coordination for complex tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1817–1830},
numpages = {14},
keywords = {task distribution, assembly instructions, coordination, collaboration},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025890,
author = {Besan\c{c}on, Lonni and Ammi, Mehdi and Isenberg, Tobias},
title = {Pressure-Based Gain Factor Control for Mobile 3D Interaction Using Locally-Coupled Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025890},
abstract = {We present the design and evaluation of pressure-based interactive control of 3D navigation
precision. Specifically, we examine the control of gain factors in tangible 3D interactions
using locally-coupled mobile devices. By focusing on pressure as a separate input
channel we can adjust gain factors independently from other input modalities used
in 3D navigation, in particular for the exploration of 3D visualisations. We present
two experiments. First, we determined that people strongly preferred higher pressures
to be mapped to higher gain factors. Using this mapping, we compared pressure with
rate control, velocity control, and slider-based control in a second study. Our results
show that pressure-based gain control allows people to be more precise in the same
amount of time compared to established input modalities. Pressure-based control was
also clearly preferred by our participants. In summary, we demonstrate that pressure
facilitates effective and efficient precision control for mobile 3D navigation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1831–1842},
numpages = {12}
}

@inbook{10.1145/3025453.3025464,
author = {Girotto, Victor and Walker, Erin and Burleson, Winslow},
title = {The Effect of Peripheral Micro-Tasks on Crowd Ideation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025464},
abstract = {Research has explored different ways of improving crowd ideation, such as presenting
examples or employing facilitators. While such support is usually generated through
peripheral tasks delegated to crowd workers who are not part of the ideation, it is
possible that the ideators themselves could benefit from the extra thought involved
in doing them. Therefore, we iterate over an ideation system in which ideators can
perform one of three peripheral tasks (rating originality and usefulness, similarity,
or idea combination) on demand. In controlled experiments with workers on Mechanical
Turk, we compare the effects of these secondary tasks to simple idea exposure or no
support at all, examining usage of the inspirations, fluency, breadth, and depth of
ideas generated. We find tasks to be as good or better than exposure, although this
depends on the period of ideation and the fluency level. We also discuss implications
of inspiration size, homogeneity, and frequency.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1843–1854},
numpages = {12}
}

@inproceedings{10.1145/3025453.3025640,
author = {Vashistha, Aditya and Sethi, Pooja and Anderson, Richard},
title = {Respeak: A Voice-Based, Crowd-Powered Speech Transcription System},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025640},
doi = {10.1145/3025453.3025640},
abstract = {Speech transcription is an expensive service with high turnaround time for audio files
containing languages spoken in developing countries and regional accents of well-represented
languages. We present Respeak - a voice-based, crowd-powered system that capitalizes
on the strengths of crowdsourcing and automatic speech recognition (instead of typing)
to transcribe such audio files. We created Respeak and optimized its design through
a series of cognitive experiments. We deployed it with 25 university students in India
who completed 5464 micro-transcription tasks, transcribing 55 minutes of widely-varied
audio content, and collectively earning USD 46 as mobile airtime. The Respeak engine
aligned the transcript generated by five randomly selected users to transcribe Hindi
and Indian English audio files with a word error rate (WER) of 8.6% and 15.2%, respectively.
The cost of speech transcription was USD 0.83 per minute with a turnaround time of
39.8 hours, substantially less than industry standards. Using a mixed-methods analysis
of cognitive experiments, system performance and qualitative interviews, we evaluate
Respeak's design, user experience, strengths, and weaknesses. Our findings suggest
that Respeak improves the quality of speech transcription while enhancing the earning
potential of low-income populations in resource-constrained settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1855–1866},
numpages = {12},
keywords = {HCI4D, crowdsourcing, India, speech, transcription},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025687,
author = {Morris, Meredith Ringel and Bigham, Jeffrey P. and Brewer, Robin and Bragg, Jonathan and Kulkarni, Anand and Li, Jessie and Savage, Saiph},
title = {Subcontracting Microwork},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025687},
doi = {10.1145/3025453.3025687},
abstract = {Mainstream crowdwork platforms treat microtasks as indivisible units; however, in
this article, we propose that there is value in re-examining this assumption. We argue
that crowdwork platforms can improve their value proposition for all stakeholders
by supporting subcontracting within microtasks. After describing the value proposition
of subcontracting, we then define three models for microtask subcontracting: real-time
assistance, task management, and task improvement, and reflect on potential use cases
and implementation considerations associated with each. Finally, we describe the outcome
of two tasks on Mechanical Turk meant to simulate aspects of subcontracting. We reflect
on the implications of these findings for the design of future crowd work platforms
that effectively harness the potential of subcontracting workflows.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1867–1876},
numpages = {10},
keywords = {subcontracting, microwork, task selection, crowdsourcing, task design, human computation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025930,
author = {Gebru, Timnit and Krause, Jonathan and Deng, Jia and Fei-Fei, Li},
title = {Scalable Annotation of Fine-Grained Categories Without Experts},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025930},
doi = {10.1145/3025453.3025930},
abstract = {We present a crowdsourcing workflow to collect image annotations for visually similar
synthetic categories without requiring experts. In animals, there is a direct link
between taxonomy and visual similarity: e.g. a collie (type of dog) looks more similar
to other collies (e.g. smooth collie) than a greyhound (another type of dog). However,
in synthetic categories such as cars, objects with similar taxonomy can have very
different appearance: e.g. a 2011 Ford F-150 Supercrew-HD looks the same as a 2011
Ford F-150 Supercrew-LL but very different from a 2011 Ford F-150 Supercrew-SVT. We
introduce a graph based crowdsourcing algorithm to automatically group visually indistinguishable
objects together. Using our workflow, we label 712,430 images by ~1,000 Amazon Mechanical
Turk workers; resulting in the largest fine-grained visual dataset reported to date
with 2,657 categories of cars annotated at 1/20th the cost of hiring experts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1877–1881},
numpages = {5},
keywords = {fine-grained dataset, human computation, crowdsourcing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025553,
author = {Huber, Bernd and Reinecke, Katharina and Gajos, Krzysztof Z.},
title = {The Effect of Performance Feedback on Social Media Sharing at Volunteer-Based Online Experiment Platforms},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025553},
abstract = {As an alternative to online labor markets, several platforms recruit unpaid online
volunteers to participate in behavioral experiments that provide personalized feedback.
These platforms rely on word-of-mouth sharing by previous participants for recruitment
of new participants. We analyzed the impact of performance feedback provided at the
end of an experiment on 81,131 participants' sharing behavior. We show that higher
performing participants share significantly more. We also show that self-verification
has a moderating effect: people who expected to do poorly are not affected by a high
score, but people who expected to do as well as others or better, are. In a second
experiment, we evaluate three distinct social comparison designs for the presentation
of the results. As expected, the design that most emphasized participants' relative
success led to most sharing. Contrary to our expectations, people who expected to
do poorly benefited from the most optimistic social comparison more than participants
who expected to do better than others.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1882–1886},
numpages = {5}
}

@inproceedings{10.1145/3025453.3025508,
author = {Krupka, Eyal and Karmon, Kfir and Bloom, Noam and Freedman, Daniel and Gurvich, Ilya and Hurvitz, Aviv and Leichter, Ido and Smolin, Yoni and Tzairi, Yuval and Vinnikov, Alon and Bar-Hillel, Aharon},
title = {Toward Realistic Hands Gesture Interface: Keeping It Simple for Developers and Machines},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025508},
doi = {10.1145/3025453.3025508},
abstract = {Development of a rich hand-gesture-based interface is currently a tedious process,
requiring expertise in computer vision and/or machine learning. We address this problem
by introducing a simple language for pose and gesture description, a set of development
tools for using it, and an algorithmic pipeline that recognizes it with high accuracy.
The language is based on a small set of basic propositions, obtained by applying four
predicate types to the fingers and to palm center: direction, relative location, finger
touching and finger folding state. This enables easy development of a gesture-based
interface, using coding constructs, gesture definition files or an editing GUI. The
language is recognized from 3D camera input with an algorithmic pipeline composed
of multiple classification/regression stages, trained on a large annotated dataset.
Our experimental results indicate that the pipeline enables successful gesture recognition
with a very low computational load, thus enabling a gesture-based interface on low-end
processors.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1887–1898},
numpages = {12},
keywords = {hand gesture nui development, hand gesture recognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026001,
author = {Zagermann, Johannes and Pfeil, Ulrike and Fink, Daniel and von Bauer, Philipp and Reiterer, Harald},
title = {Memory in Motion: The Influence of Gesture- and Touch-Based Input Modalities on Spatial Memory},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026001},
doi = {10.1145/3025453.3026001},
abstract = {People's ability to remember and recall spatial information can be harnessed to improve
navigation and search performances in interactive systems. In this paper, we investigate
how display size and input modality influence spatial memory, especially in relation
to efficiency and user satisfaction. Based on an experiment with 28 participants,
we analyze the effect of three input modalities (trackpad, direct touch, and gesture-based
motion controller) and two display sizes (10.6" and 55") on people's ability to navigate
to spatially spread items and recall their positions. Our findings show that the impact
of input modality and display size on spatial memory is not straightforward, but characterized
by trade-offs between spatial memory, efficiency, and user satisfaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1899–1910},
numpages = {12},
keywords = {output device, spatial memory, input modality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025692,
author = {Matthies, Denys J. C. and Strecker, Bernhard A. and Urban, Bodo},
title = {<i>EarFieldSensing</i>: A Novel In-Ear Electric Field Sensing to Enrich Wearable Gesture Input through Facial Expressions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025692},
doi = {10.1145/3025453.3025692},
abstract = {EarFieldSensing (EarFS) is a novel input method for mobile and wearable computing
using facial expressions. Facial muscle movements induce both electric field changes
and physical deformations, which are detectable with electrodes placed inside the
ear canal. The chosen ear-plug form factor is rather unobtrusive and allows for facial
gesture recognition while utilizing the close proximity to the face. We collected
25 facial-related gestures and used them to compare the performance levels of several
electric sensing technologies (EMG, CS, EFS, EarFS) with varying electrode setups.
Our developed wearable fine-tuned electric field sensing employs differential amplification
to effectively cancel out environmental noise while still being sensitive towards
small facial-movement-related electric field changes and artifacts from ear canal
deformations. By comparing a mobile with a stationary scenario, we found that EarFS
continues to perform better in a mobile scenario. Quantitative results show EarFS
to be capable of detecting a set of 5 facial gestures with a precision of 90% while
sitting and 85.2% while walking. We provide detailed instructions to enable replication
of our low-cost sensing device. Applying it to different positions of our body will
also allow to sense a variety of other gestures and activities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1911–1922},
numpages = {12},
keywords = {wearable computing, hands-/eyes-free, facial expression control, electric field sensing, body potential sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025807,
author = {McIntosh, Jess and Marzo, Asier and Fraser, Mike and Phillips, Carol},
title = {EchoFlex: Hand Gesture Recognition Using Ultrasound Imaging},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025807},
doi = {10.1145/3025453.3025807},
abstract = {Recent improvements in ultrasound imaging enable new opportunities for hand pose detection
using wearable devices. Ultrasound imaging has remained under-explored in the HCI
community despite being non-invasive, harmless and capable of imaging internal body
parts, with applications including smart-watch interaction, prosthesis control and
instrument tuition. In this paper, we compare the performance of different forearm
mounting positions for a wearable ultrasonographic device. Location plays a fundamental
role in ergonomics and performance since the anatomical features differ among positions.
We also investigate the performance decrease due to cross-session position shifts
and develop a technique to compensate for this misalignment. Our gesture recognition
algorithm combines image processing and neural networks to classify the flexion and
extension of 10 discrete hand gestures with an accuracy above 98%. Furthermore, this
approach can continuously track individual digit flexion with less than 5% NRMSE,
and also differentiate between digit flexion at different joints.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1923–1934},
numpages = {12},
keywords = {machine learning, computer vision, interactive ultrasound imaging, gesture recognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3026053,
author = {Ford, Colin M.},
title = {Virtuosos on the Screen: Playing Virtual Characters Like Instruments in Competitive Super Smash Bros. Melee},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026053},
abstract = {Previous research on virtual sociality in games suggests that players use custom avatars
to reflect, alter, and perform new identities in digital spaces. However, this study
explores an alternative theory of social performance by analyzing a competitive game,
Super Smash Bros. Melee, where players face off in timed matches and interact through
pre-designed characters. This study shows how Melee players treat virtual characters
as performative instruments, similar to the violin or the piano. In forum posts and
player-created media, Melee players emphasize the need to train one's hands, eyes,
and mind in order to master a character's complexity and express style and skills
in live matches. Instrumental embodiment in a competitive game like Melee thus positions
players as virtuosos who perform for perceptive audiences. This research points to
a range of ways that players may relate to virtual bodies, connected to distinct kinds
of social activities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1935–1948},
numpages = {14}
}

@inproceedings{10.1145/3025453.3025826,
author = {Jia, Yuan and Liu, Yikun and Yu, Xing and Voida, Stephen},
title = {Designing Leaderboards for Gamification: Perceived Differences Based on User Ranking, Application Domain, and Personality Traits},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025826},
doi = {10.1145/3025453.3025826},
abstract = {Leaderboards, a common gamification technique, are used to enhance engagement through
social comparisons. Prior research has demonstrated the overall utility of leaderboards
but has not examined their effectiveness when individuals are ranked at particular
levels or when the technique is applied in different application domains, such as
social networking, fitness, or productivity. In this paper, we present a survey study
investigating how preferences for leaderboards change based on individual differences
(personality traits), ranking, social scoping, and application domains. Our results
show that a respondent's position on the leaderboard had important effects on their
perception of the leaderboard and the surrounding app, and that participants rated
leaderboards most favorably in fitness apps and least favorably in social networking
contexts. More extraverted people reported more positive experiences with leaderboards
despite their ranking or the application domain. We present design implications for
creating leaderboards targeted at different domains and for different audiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1949–1960},
numpages = {12},
keywords = {user interface design, personality, gamification, leaderboards, motivational affordances},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025678,
author = {Qian, Kun and Wu, Chenshu and Zhou, Zimu and Zheng, Yue and Yang, Zheng and Liu, Yunhao},
title = {Inferring Motion Direction Using Commodity Wi-Fi for Interactive Exergames},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025678},
doi = {10.1145/3025453.3025678},
abstract = {In-air interaction acts as a key enabler for ambient intelligence and augmented reality.
As an increasing popular example, exergames, and the alike gesture recognition applications,
have attracted extensive research in designing accurate, pervasive and low-cost user
interfaces. Recent advances in wireless sensing show promise for a ubiquitous gesture-based
interaction interface with Wi-Fi. In this work, we extract complete information of
motion-induced Doppler shifts with only commodity Wi-Fi. The key insight is to harness
antenna diversity to carefully eliminate random phase shifts while retaining relevant
Doppler shifts. We further correlate Doppler shifts with motion directions, and propose
a light-weight pipeline to detect, segment, and recognize motions without training.
On this basis, we present WiDance, a Wi-Fi-based user interface, which we utilize
to design and prototype a contactless dance-pad exergame. Experimental results in
typical indoor environment demonstrate a superior performance with an accuracy of
92%, remarkably outperforming prior approaches.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1961–1972},
numpages = {12},
keywords = {wireless sensing, motion direction recognition, off-the-shelf wi-fi, exergame},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025934,
author = {Kasunic, Anna and Kaufman, Geoff},
title = {Be Me or Be Mii? A Study of Self-Presentation and Interaction in the Miitomo Mobile Application},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025934},
abstract = {In this study, we consider what Nintendo's widely downloaded Miitomo mobile application,
which simultaneously promotes non-idealized self-fictionalization and authentic self-presentation,
can suggest to us about self-presentation and technology design. Ten groups of four
friends each (N=40), all novice users, engaged with Miitomo for one week, and completed
supplementary pre- and post-use surveys. The data were analyzed to assess the extent
to which participants' engagement in Miitomo reflected their "real life" selves and
correlated with in-app and "real life" features, respectively. Although most participants
believed that their behaviors within the app accurately reflected their "true selves,"
we found that in-app traits generally correlated more strongly with Miitomo engagement
patterns than did users' "real life" traits and qualities. We discuss implications
for social network and online community design, and propose future plans to study
authenticity and self-distancing in online self-presentation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1973–1977},
numpages = {5}
}

@inproceedings{10.1145/3025453.3025967,
author = {Wuertz, Jason and Bateman, Scott and Tang, Anthony},
title = {Why Players Use Pings and Annotations in Dota 2},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025967},
doi = {10.1145/3025453.3025967},
abstract = {Groupware research has long focused on representing gestures as a means to facilitate
collaboration. However, this work has not led to wide support of gesturing in commercial
groupware systems. In contrast, Dota 2, a popular MOBA game, provides two frequently-used
gesturing tools: annotations - freely drawn lines on top of the gamespace - and pings
- a combination of animation and sound indicating a point of interest. While gesturing
tools are important for quickly coordinating with teammates in Dota 2, there is little
information about how and why people use them. To gather this information, we performed
two complementary studies: an interaction analysis of eight game replays, and a survey
of 167 experienced players. Our findings include: six distinct motivations for the
use of gesturing tools; when and how frequently gesture motivations occur during games;
and, that players find pings an essential tool for winning, but not annotations. Our
findings provide new directions for the design of gesturing tools in groupware and
online games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1978–2018},
numpages = {41},
keywords = {motivation, dota 2, pings, annotations, online games, gestures, mobas, communication tools, groupware},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025862,
author = {Windlin, Charles and Laaksolahti, Jarmo},
title = {Unpacking Visible Light Communication as a Material for Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025862},
abstract = {Communication through visible light (VLC) is gaining ground as an alternative to traditional
radio communication in many settings. Effectively using VLC in creative design processes
may however be difficult as the material properties of VLC can be hard to grasp and
therefore to use. This paper presents a design exploration where a set of artifacts
was created to enable designers to play around with VLC and better understand its
properties and their potential use for design. Each artifact was designed to illustrate
a particular property of light communication ranging from inner workings of transmission
protocols to properties of light in itself. The set was used in two small scale workshops
where users played around with the artifacts and afterward were interviewed about
their experiences. Interviews and observations from the workshops suggest that users
gained insights into the material properties of light communication and were also
inspired to think of creative uses for VLC based on those insights},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2019–2023},
numpages = {5}
}

@inproceedings{10.1145/3025453.3025504,
author = {Harnett, C. K.},
title = {Tobiko: A Contact Array for Self-Configuring, Surface-Powered Sensors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025504},
doi = {10.1145/3025453.3025504},
abstract = {This paper describes a contact array that outputs the maximum and minimum voltages
at its contacts. The goal is to extract power for a detachable touch sensor, display,
or other human-computer interaction (HCI) device that is attached to a surface by
a user, and that does not have its own power source. Experimental results are shown
for an array that has positive and negative outputs and a pass-through at each contact
position. It solves the startup problem for a randomly-placed batteryless sensor patch
or sticker, which can scan its ports to discover neighboring devices only after it
obtains power. Applications include user-configurable electronic textile circuits,
and new methods for prototyping and repairing large-area flexible circuits. This note
describes construction of a 7x7 array, provides design rules, and examines the signal
quality on two kinds of electronic surfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2024–2028},
numpages = {5},
keywords = {e-textiles, self-configuring, contact array, wearables},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025987,
author = {Clegg, Tamara and Norooz, Leyla and Kang, Seokbin and Byrne, Virginia and Katzen, Monica and Velez, Rafael and Plane, Angelisa and Oguamanam, Vanessa and Outing, Thomas and Yip, Jason and Bonsignore, Elizabeth and Froehlich, Jon},
title = {Live Physiological Sensing and Visualization Ecosystems: An Activity Theory Analysis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025987},
abstract = {Wearable sensing poses new opportunities to enhance personal connections to learning
and authentic scientific inquiry experiences. In our work, we leverage the body and
physical action as an engaging platform for learning through live physiological sensing
and visualization (LPSV). Prior research suggests the potential of this approach,
but was limited to single-session evaluations in informal environments. In this paper,
we examine LPSV tools in a classroom environment during a four-day deployment. To
highlight the complex interconnections between space, teachers, curriculum, and tool
use, we analyze our data through the lens of Activity Theory. Our findings show the
importance of integrating model-based representations for supporting exploration and
analytic representations for scaffolding scientific inquiry. Activity Theory highlights
leveraging life-relevant connections available within a physical space and considering
policies and norms related to learners' physical bodies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2029–2041},
numpages = {13}
}

@inproceedings{10.1145/3025453.3025983,
author = {Soden, Robert and Sprain, Leah and Palen, Leysia},
title = {Thin Grey Lines: Confrontations With Risk on Colorado's Front Range},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025983},
doi = {10.1145/3025453.3025983},
abstract = {This paper reports on two years of ethnographic observation of the science and politics
of flood risk in Colorado, as well as design research that examines citizen interaction
with expert knowledge about flooding in the region. We argue that the 100-year floodplain
standard that inform maps produced by the USA Federal Emergency Management Agency
(FEMA)'s National Floodplain Insurance Program (NFIP) represent a problematic form
of discursive closure of scientific understanding of flood hazard. We show that in
order to meet the requirements of the NFIP, this standard acts as a closure that conveys
a certainty that the underlying science does not warrant and foreshortens dialogue
on disaster risk and public understanding of flood hazard. Engaging with literature
in science and technology studies and human-centered computing, we investigate design
opportunities for resisting closure and supporting public formation through encounters
with the uncertainty and complexities of risk information.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2042–2053},
numpages = {12},
keywords = {design, human-centered computing, public engagement, flood risk, science and technology studies.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025893,
author = {Musabirov, Ilya and Bulygin, Denis and Okopny, Paul and Sirotkin, Alexander},
title = {Deconstructing Cosmetic Virtual Goods Experiences in Dota 2},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025893},
doi = {10.1145/3025453.3025893},
abstract = {Cosmetic items do not provide functional advantages in games, but, nevertheless, they
play an important role in the overall player experience. Possessing predominantly
socially-constructed dimensions of value, cosmetic items are chosen, discussed, assessed,
and valuated in an ongoing iterative collaborative process by communities of players.
In our study, we explore the case of Dota 2 and apply Topic Modeling to community-discussions
data gathered from Reddit.com. We describe social experiences related to the valuation
of cosmetic items in interaction and collision of various logics, including artificial
scarcity, decomposition of visual effects, and connectedness to the game lore. Our
findings connect the collective experience of players in the game and on online community
platforms, suggesting that non-utility-based social value construction becomes an
important part of game experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2054–2058},
numpages = {5},
keywords = {cosmetic items, games/play, virtual goods, decorative items, social media/online communities},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025944,
author = {Ghosh, Sanjay and Joshi, Anirudha and Joshi, Manjiri and Emmadi, Nagraj and Dalvi, Girish and Ahire, Shashank and Rangale, Swati},
title = {Shift+Tap or Tap+LongPress? The Upper Bound of Typing Speed on InScript},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025944},
doi = {10.1145/3025453.3025944},
abstract = {This paper presents the results of a within-subject longitudinal evaluation on Inscript
keyboard, which is the national standard layout for Indian scripts. We studied the
practical upper bound speed and accuracy as well as the effect of practice. Through
longitudinal transcription task of 400 repeated attempts, we observed typing speeds
for highly experienced users consistently peak close to 120 cpm i.e. 2.5 times that
of fastest speeds reported in literature. Our analysis compared the lower bound times
for Tap, Tap+LongPress and Shift+Tap, the three text input mechanisms in this keyboard.
Among the two alternative methods, our findings established Tap+LongPress method to
be faster than Shift+Tap method and almost equally accurate. Also, we derived a model
which explains the influence of corrected errors and number of practice attempts on
the typing speed.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2059–2063},
numpages = {5},
keywords = {performance modelling, error analysis, virtual keyboards, text input in indian language},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025658,
author = {Salovaara, Antti and Oulasvirta, Antti and Jacucci, Giulio},
title = {Evaluation of Prototypes and the Problem of Possible Futures},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025658},
doi = {10.1145/3025453.3025658},
abstract = {There is a blind spot in HCI's evaluation methodology: we rarely consider the implications
of the fact that a prototype can never be fully evaluated in a study. A prototype
under study exists firmly in the present world, in the circumstances created in the
study, but its real context of use is a partially unknown future state of affairs.
This present-future gap is implicit in any evaluation of prototypes, be they usability
tests, controlled experiments, or field trials. A carelessly designed evaluation may
inadvertently evaluate the wrong futures, contexts, or user groups, thereby leading
to false conclusions and expensive design failures. The essay analyses evaluation
methodology from this perspective, illuminating how to mitigate the present-future
gap.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2064–2077},
numpages = {14},
keywords = {field trials, future, evaluation methodology, experiments, usability studies, prototypes},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025696,
author = {Chen, Ko-Le and Clarke, Rachel and Almeida, Teresa and Wood, Matthew and Kirk, David S.},
title = {Situated Dissemination through an HCI Workplace},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025696},
abstract = {Researchers working in domains such as Research through Design and Feminist HCI have
been questioning "dissemination practices" and their impact on our capacity to produce
reflexive accounts of research in publications. This paper examines academic dissemination
practices within HCI research communities from an institutional to individual level.
We unpack the practice via a meta-review of recent literature published in CHI and
other venues on 'What is HCI?'. We review the core text on this debate and other similar
discussions on HCI methodologies and reflexive accounts of research in domains such
as 'Research through Design' and 'Feminist HCI'. We highlight the importance of practicing
reflexivity through dissemination and introduce 'Research Fictions' in the form of
video essays and live performances, produced by the first author with her colleagues,
based on their HCI submissions. Through experimenting with alternative dissemination
formats, we argue that our exploratory processes engender a practice of reflexivity
within a research lab.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2078–2090},
numpages = {13}
}

@inproceedings{10.1145/3025453.3026022,
author = {Velt, Raphael and Benford, Steve and Reeves, Stuart},
title = {A Survey of the Trajectories Conceptual Framework: Investigating Theory Use in HCI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026022},
doi = {10.1145/3025453.3026022},
abstract = {We present a case study of how Human-Computer Interaction (HCI) theory is reused within
the field. We analyze the HCI literature in order to reveal the impact of one particular
theory, the trajectories framework that has been cited as an example of both contemporary
HCI theory and a strong concept that sits between theory and design practice. Our
analysis of 60 papers that seriously engaged with trajectories reveals the purposes
that the framework served and which parts of it they used. We compare our findings
to the originally stated goals of trajectories and to subsequent claims of its status
as both theory and strong concept. The results shed new light on what we mean by theory
in HCI, including its relationship to practice and to other disciplines.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2091–2105},
numpages = {15},
keywords = {hci, theory, trajectories, strong concepts},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025498,
author = {Yamaoka, Junichi and Kakehi, Yasuaki},
title = {ProtoMold: An Interactive Vacuum Forming System for Rapid Prototyping},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025498},
doi = {10.1145/3025453.3025498},
abstract = {In this paper, we propose a novel fabrication machine called ProtoMold, which uses
interactive vacuum forming system for rapid prototyping. ProtoMold combines a dynamical
shape-changing surface that consists of 12 \texttimes{} 8 linear actuators and a vacuum forming
system. According to the shape of the surface, this system can mold various 2.5 dimensional
objects quickly. Another characteristic of this system is that users can reuse molded
objects and change their design; by applying tension and heat to a molded object,
the object becomes flat and can be molded again. We also designed user several interaction
methods for manipulating ProtoMold. In addition to loading predesigned data, the user
can control the shape of the pin display directly using gesture input or physical
objects.We propose several use scenarios for ProtoMold: changing the design of a plate
based on objects placed on it, fabricating a facemask with a printed texture, and
fabricating electrical devices with printed electronic circuits. By using this system,
we conducted a user test and discuss the known limitations and potential applications
of our system.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2106–2115},
numpages = {10},
keywords = {design methods, prototyping, interactive fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025937,
author = {Hsu, Chen-Yu and Liu, Yuchen and Kabelac, Zachary and Hristov, Rumen and Katabi, Dina and Liu, Christine},
title = {Extracting Gait Velocity and Stride Length from Surrounding Radio Signals},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025937},
doi = {10.1145/3025453.3025937},
abstract = {Gait velocity and stride length are critical health indicators for older adults. A
decade of medical research shows that they provide a predictor of future falls, hospitalization,
and functional decline among seniors. However, currently these metrics are measured
only occasionally during medical visits. Such infrequent measurements hamper the opportunity
to detect changes and intervene early in the impairment process.In this paper, we
develop a sensor that uses radio signals to continuously measure gait velocity and
stride length at home. Our sensor hangs on a wall like a picture frame. It does not
require the monitored person to wear or carry a device on her body. Our approach builds
on recent advances in wireless systems which have shown that one can locate people
based on how their bodies impact the surrounding radio signals. We demonstrate the
accuracy of our method by comparing it to the gold standard in clinical tests, and
the VICON motion tracking system. Our experience from deploying the sensor in 14 homes
indicates comfort with the technology and a high acceptance rate.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2116–2126},
numpages = {11},
keywords = {continuous monitoring, device-free sensing, stride length, gait velocity, wireless sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026003,
author = {Jansen, Arne and Van Mechelen, Maarten and Slegers, Karin},
title = {Personas and Behavioral Theories: A Case Study Using Self-Determination Theory to Construct Overweight Personas},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026003},
doi = {10.1145/3025453.3026003},
abstract = {Personas are a widely used tool to keep real users in mind, while avoiding stereotypical
thinking in the design process. Yet, creating personas can be challenging. Starting
from Cooper's approach for constructing personas, this paper details how behavioral
theory can contribute substantially to the development of personas. We describe a
case study in which Self-Determination Theory (SDT) is used to develop five distinctive
personas for the design of a digital coach for sustainable weight loss. We show how
behavioral theories such as SDT can help to understand what genuinely drives and motivates
users to sustainably change their behavior. In our study, we used SDT to prepare and
analyze interviews with envisioned users of the coach and to create complex, yet engaging
and highly realistic personas that make users' basic psychological needs explicit.
The paper ends with a critical reflection on the use of behavioral theories to create
personas, discussing both challenges and strengths.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2127–2136},
numpages = {10},
keywords = {design methods, obesity, personas, self-determination theory, behavioral theories},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025904,
author = {Hornof, Anthony and Whitman, Haley and Sutherland, Marah and Gerendasy, Samuel and McGrenere, Joanna},
title = {Designing for the "Universe of One": Personalized Interactive Media Systems for People with the Severe Cognitive Impairment Associated with Rett Syndrome},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025904},
doi = {10.1145/3025453.3025904},
abstract = {The needs and capabilities of a person with severe disabilities are often so specific
that designing for the person is like designing for a "universe of one." This project
addresses this problem for women with Rett syndrome, a disorder accompanied by severe
cognitive, communication, and motor impairment. The research team adapted participatory
design techniques to work with five such women, and their families, to design and
evaluate new assistive technology for these women. The process suggests a class of
media-playing devices that would be generally useful to women with Rett syndrome:
systems that can load multiple audio or video segments; be activated by many different
switches; and respond instantly to switch-hits. As well, the systems should permit
a caregiver to set the start and end time of each segment, and how the system advances
through a sequence of segments. The paper also discusses patterns that were observed
when collaborating with the families. For example, parents shared longstanding but
untried ideas for new assistive technology; and expressed a strong interest in any
device that would help their daughters do things for themselves.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2137–2148},
numpages = {12},
keywords = {severe cognitive impairment, participatory design, user-centered design, user training, intellectual disability, rett syndrome, assistive technology, user observation studies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025586,
author = {Lazar, Amanda and Edasis, Caroline and Piper, Anne Marie},
title = {Supporting People with Dementia in Digital Social Sharing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025586},
doi = {10.1145/3025453.3025586},
abstract = {Sharing online is an important way in which people across the lifespan express themselves,
maintain relationships, and connect with others. Yet, people with dementia are often
not supported in engaging to the full extent of their abilities, particularly in their
interaction with online technology. This paper presents a design case study that examines
what it means to design for agency in online sharing involving individuals with dementia.
Our work is situated in the context of art therapy for adults with dementia. We present
the design and exploration of Moments, a system that allows individuals to share through
artwork by manipulating their physical environment. We discuss how designing for agency
calls attention to the ways in which the material workspace, including the tools we
introduce, and the surrounding social context participate in the creation of agency.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2149–2162},
numpages = {14},
keywords = {agency, dementia, art therapy, sharing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025732,
author = {Morrissey, Kellie and Garbett, Andrew and Wright, Peter and Olivier, Patrick and Jenkins, Edward Ian and Brittain, Katie},
title = {Care and Connect: Exploring Dementia-Friendliness Through an Online Community Commissioning Platform},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025732},
doi = {10.1145/3025453.3025732},
abstract = {In this paper, we present "Care and Connect", a mobile application created through
the App Movement platform that aims to identify and rate public places (e.g., parks,
shops, cafes) on their 'dementia-friendliness' - their suitability for people with
dementia and their carers. Care and Connect saw significant support in its early stages
on the online platform, yet failed to engage participants in its design phase and
deployment. To unpick this, we contribute an account of its initial use in the community,
and then describe findings from research engagements with carers and people with dementia.
These workshops used Care and Connect to structure discussions of participants' own
experiences of dementia-friendliness, and uncovered themes of 1) trust, 2) exclusion
versus inclusion, 3) duration and quality of time, and 4) empathy becoming action.
Using this evidence, we advance an account of online community commissioning as a
process which needs to understand not only the general issues ongoing in communities
facing significant life challenges, but also the particularity of community members'
experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2163–2174},
numpages = {12},
keywords = {mobile applications, dementia, dementia care, community commissioning, community information systems},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025522,
author = {Lazar, Amanda and Edasis, Caroline and Piper, Anne Marie},
title = {A Critical Lens on Dementia and Design in HCI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025522},
doi = {10.1145/3025453.3025522},
abstract = {Designing new technologies with and for individuals with dementia is a growing topic
of interest within HCI. Yet, predominant societal views contribute to the positioning
of individuals with dementia as deficient and declining, and treat technology as filling
a gap left by impairment. We present the perspective of critical dementia as a way
of reflecting on these views in the context of recent epistemological shifts in HCI.
In addition to articulating how HCI can leverage the perspective of critical dementia,
we present a case analysis of technology design in art therapy involving people with
dementia aimed at challenging conventional narratives. This paper calls attention
to and helps solidify an agenda for how the CHI community approaches dementia, design,
and technology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2175–2188},
numpages = {14},
keywords = {disability, theory, design, dementia, paradigm},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025875,
author = {Matthews, Tara and O'Leary, Kathleen and Turner, Anna and Sleeper, Manya and Woelfer, Jill Palzkill and Shelton, Martin and Manthorne, Cori and Churchill, Elizabeth F. and Consolvo, Sunny},
title = {Stories from Survivors: Privacy &amp; Security Practices When Coping with Intimate Partner Abuse},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025875},
doi = {10.1145/3025453.3025875},
abstract = {We present a qualitative study of the digital privacy and security motivations, practices,
and challenges of survivors of intimate partner abuse (IPA). This paper provides a
framework for organizing survivors' technology practices and challenges into three
phases: physical control, escape, and life apart. This three-phase framework combines
technology practices with three phases of abuse to provide an empirically sound method
for technology creators to consider how survivors of IPA can leverage new and existing
technologies. Overall, our results suggest that the usability of and control over
privacy and security functions should be or continue to be high priorities for technology
creators seeking ways to better support survivors of IPA.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2189–2201},
numpages = {13},
keywords = {domestic violence, security, intimate partner abuse, privacy, user study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025926,
author = {Sawaya, Yukiko and Sharif, Mahmood and Christin, Nicolas and Kubota, Ayumu and Nakarai, Akihiro and Yamada, Akira},
title = {Self-Confidence Trumps Knowledge: A Cross-Cultural Study of Security Behavior},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025926},
doi = {10.1145/3025453.3025926},
abstract = {Computer security tools usually provide universal solutions without taking user characteristics
(origin, income level, ...) into account. In this paper, we test the validity of using
such universal security defenses, with a particular focus on culture. We apply the
previously proposed Security Behavior Intentions Scale (SeBIS) to 3,500 participants
from seven countries. We first translate the scale into seven languages while preserving
its reliability and structure validity. We then build a regression model to study
which factors affect participants' security behavior. We find that participants from
different countries exhibit different behavior. For instance, participants from Asian
countries, and especially Japan, tend to exhibit less secure behavior. Surprisingly
to us, we also find that actual knowledge influences user behavior much less than
user self-confidence in their computer security knowledge. Stated differently, what
people think they know affects their security behavior more than what they do know.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2202–2214},
numpages = {13},
keywords = {computer security, cross-cultural study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025896,
author = {Vance, Anthony and Kirwan, Brock and Bjornn, Daniel and Jenkins, Jeffrey and Anderson, Bonnie Brinton},
title = {What Do We Really Know about How Habituation to Warnings Occurs Over Time? A Longitudinal FMRI Study of Habituation and Polymorphic Warnings},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025896},
doi = {10.1145/3025453.3025896},
abstract = {A major inhibitor of the effectiveness of security warnings is habituation: decreased
response to a repeated warning. Although habituation develops over time, previous
studies have examined habituation and possible solutions to its effects only within
a single experimental session, providing an incomplete view of the problem. To address
this gap, we conducted a longitudinal experiment that examines how habituation develops
over the course of a five-day workweek and how polymorphic warnings decrease habituation.
We measured habituation using two complementary methods simultaneously: functional
magnetic resonance imaging (fMRI) and eye tracking.Our results show a dramatic drop
in attention throughout the workweek despite partial recovery between workdays. We
also found that the polymorphic warning design was substantially more resistant to
habituation compared to conventional warnings, and it sustained this advantage throughout
the five-day experiment. Our findings add credibility to prior studies by showing
that the pattern of habituation holds across a workweek, and indicate that cross-sectional
habituation studies are valid proxies for longitudinal studies. Our findings also
show that eye tracking is a valid measure of the mental process of habituation to
warnings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2215–2227},
numpages = {13},
keywords = {longitudinal experiment, polymorphic warnings, security warnings, functional magnetic resonance imaging (fmri), habituation, eye tracking},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025911,
author = {Wash, Rick and Rader, Emilee and Fennell, Chris},
title = {Can People Self-Report Security Accurately? Agreement Between Self-Report and Behavioral Measures},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025911},
doi = {10.1145/3025453.3025911},
abstract = {It is common for researchers to use self-report measures (e.g. surveys) to measure
people's security behaviors. In the computer security community, we don't know what
behaviors people understand well enough to self-report accurately, or how well those
self-reports correlate with what people actually do. In a six week field study, we
collected both behavior data and survey responses from 122 subjects. We found that
a relatively small number of behaviors -- mostly related to tasks that require users
to take a specific, regular action -- have non-zero correlations. Since security is
almost never a user's primary task for everyday computer users, several important
security behaviors that we directly measured were not self-reported accurately. These
results suggest that security research based on self-report is only reliable for certain
behaviors. Additionally, a number of important security behaviors are not sufficiently
salient to users that they can self-report accurately.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2228–2232},
numpages = {5},
keywords = {security, intentions, self-report},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025856,
author = {Singh, Vivek K. and Jain, Arushi},
title = {Toward Harmonizing Self-Reported and Logged Social Data for Understanding Human Behavior},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025856},
doi = {10.1145/3025453.3025856},
abstract = {While self-reporting remains the most common method to understand human behavior,
recent advances in social networks, mobile technologies, and other computer-mediated
communication technologies are allowing researchers to obtain detailed logs of human
behavior with ease. While the logged data is very useful (and accurate) at capturing
the structure of the user's social network, the self-reported data provides an insight
into the user's cognitive map of her social network. Based on a field study involving
47 users for a period of ten weeks we report that combining the two sets of data (self-reported
and logged) gives higher predictive power than using either one of them individually.
Further, the difference between the two types of values captures the level of dissonance
between a user's actual and perceived social behavior and is found to be an important
predictor of the person's social outcomes including social capital, social support
and trust.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2233–2238},
numpages = {6},
keywords = {dissonance coefficient, social ties, call-log data, self-reported, socio-mobile behavior, bias},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025758,
author = {Hassib, Mariam and Buschek, Daniel and Wozniak, Pawe\l{} W. and Alt, Florian},
title = {HeartChat: Heart Rate Augmented Mobile Chat to Support Empathy and Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025758},
doi = {10.1145/3025453.3025758},
abstract = {Textual communication via mobile phones suffers from a lack of context and emotional
awareness. We present a mobile chat application, HeartChat, which integrates heart
rate as a cue to increase awareness and empathy. Through a literature review and a
focus group, we identified design dimensions important for heart rate augmented chats.
We created three concepts showing heart rate per message, in real-time, or sending
it explicitly. We tested our system in a two week in-the-wild study with 14 participants
(7 pairs). Interviews and questionnaires showed that HeartChat supports empathy between
people, in particular close friends and partners. Sharing heart rate helped them to
implicitly understand each other's context (e.g. location, physical activity) and
emotional state, and sparked curiosity on special occasions. We discuss opportunities,
challenges, and design implications for enriching mobile chats with physiological
sensing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2239–2251},
numpages = {13},
keywords = {physiological sensing, affective computing, heart rate, instant messagingg},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025833,
author = {Feltwell, Tom and Wood, Gavin and Long, Kiel and Brooker, Phillip and Schofield, Tom and Petridis, Ioannis and Barnett, Julie and Vines, John and Lawson, Shaun},
title = {"I've Been Manipulated!": Designing Second Screen Experiences for Critical Viewing of Reality TV},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025833},
doi = {10.1145/3025453.3025833},
abstract = {The recent proliferation of a reality TV genre that focusses on welfare recipients
has led to concerns that prime-time media experiences are exacerbating misconceptions,
and stifling critical debate, around major societal issues such as welfare reform
and poverty. Motivated by arguments that 'second screening' practices offer opportunities
to engage viewers with issues of political concern, we describe the design and evaluation
of two smartphone apps that facilitate and promote more critical live-viewing of reality
TV. Our apps, Spotting Guide and Moral Compass, encourage users to identify, categorise,
tag and filter patterns and tropes within reality TV, as well as reinterpret social
media posts associated with their broadcast. We show that such interactions encourage
critical thinking around typical editing and production techniques and foster co-discussion
and reflection amongst viewers. We discuss, more broadly, how these interactions encourage
users to identify the wider consequences and framings of reality TV, and offer implications
and considerations for design that provokes criticality and reflection in second screening
contexts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2252–2263},
numpages = {12},
keywords = {tv, welfare, second screening, social media, politics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025459,
author = {Dowell, John and Anstead, Edward},
title = {Interaction with a TV Companion App as Synopsis and Supplement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025459},
doi = {10.1145/3025453.3025459},
abstract = {Television companion apps on tablets and smartphones provide interactive content synchronized
with TV shows. A key design question raised by this novel, multi-display, multimedia
interface is whether the app's role is to be a synopsis of the show or a supplement.
In other words, should the app help viewers better follow what they are watching on
TV, or offer additional enriching content to respond to interest created by the show?
We developed a companion app for a documentary with both synoptic and supplementary
content. A laboratory study with 28 participants examined the effect of these different
types of content on the experience of using the companion and the effect on engagement
with the show in terms of participants' recall. Engagement with the show was not affected
by supplementary content in the app but coordinated viewing of both screens was more
difficult. Design guidelines evident from these results are discussed.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2264–2268},
numpages = {5},
keywords = {mobile devices, television, engagement, companion apps, second screen},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025611,
author = {Gorkovenko, Katerina and Taylor, Nick and Rogers, Jon},
title = {Social Printers: A Physical Social Network for Political Debates},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025611},
doi = {10.1145/3025453.3025611},
abstract = {Social Printers are physical devices that create a pseudonymous social network between
households during televised political debates. Through studies conducted around the
Scottish Parliamentary Election and EU Referendum in 2016, we aimed to understand
how physical devices could be used to engage viewers with televised political debates.
By displacing the interaction from conventional social media and second screens we
observed that the printers were successful in encouraging the participants to share
their thoughts and create a personal social experience. Based on the results we discuss
potential implications for conventional social media and second screens in the context
of political television programs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2269–2281},
numpages = {13},
keywords = {politics, political discourse, research products, second screens, television, social media.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025915,
author = {Balestrini, Mara and Rogers, Yvonne and Hassan, Carolyn and Creus, Javi and King, Martha and Marshall, Paul},
title = {A City in Common: A Framework to Orchestrate Large-Scale Citizen Engagement around Urban Issues},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025915},
doi = {10.1145/3025453.3025915},
abstract = {Citizen sensing is an approach that develops and uses lightweight technologies with
local communities to collect, share and act upon data. In doing so it enables them
to become more aware of how they can tackle local issues. We report here on the development
and uptake of the 'City- Commons Framework for Citizen Sensing', a conceptual model
that builds on Participatory Action Research with the aim of playing an integrating
role: outlining the processes and mechanisms for ensuring sensing technologies are
co-designed by citizens to address their concerns. At the heart of the framework is
the idea of a city commons: a pool of community-managed resources. We discuss how
the framework was used by communities in Bristol to measure and monitor the problem
of damp housing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2282–2294},
numpages = {13},
keywords = {citizen sensing, commons, framework, smart cities, methods, open data, publics, citizen engagement},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025963,
author = {Asad, Mariam and Le Dantec, Christopher A. and Nielsen, Becky and Diedrick, Kate},
title = {Creating a Sociotechnical API: Designing City-Scale Community Engagement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025963},
doi = {10.1145/3025453.3025963},
abstract = {Community engagement is to cities what user experience is to computing: it signifies
a large category that simultaneously speaks to general qualities of interaction and
to specific ways of doing that interaction. Recently, digital civics has emerged as
a research area with a comprehensive approach to designing for civic encounters where
community engagement is a primary concern for designing systems and processes that
support broad civic interaction. In short, over the past year, we worked with municipal
officials, service providers, and city residents to design a community engagement
playbook detailing best practices for city-scale engagement. The playbook, as well
as the collaborative process that produced it, provides a roadmap for thinking through
the kinds of systems that might populate the design space of city-scale digital civics.
This paper details our design-led research process and builds on emerging literature
on designing for digital civic interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2295–2306},
numpages = {12},
keywords = {participatory design, community engagement, publics, digital civics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025996,
author = {Erete, Sheena and Burrell, Jennifer O.},
title = {Empowered Participation: How Citizens Use Technology in Local Governance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025996},
doi = {10.1145/3025453.3025996},
abstract = {The partnership between local residents and city officials to inform policy and decision-making
about government resources, or participatory governance, has been extensively studied.
In addition to numerous ethnographic studies about how citizens engage in-person,
there has been increased focus in HCI to understand the impact of technology on citizen
participation in local governance. Building upon those studies, this paper provides
unique insight from a 3-year longitudinal study on the use of online tools that were
organically adapted by citizens to engage in local governance in three diverse Chicago
neighborhoods. Though the responsiveness of government officials varied across communities,
our results suggest that citizens use technology to heighten the visibility of their
concerns, to support mechanisms of government accountability, and to provide various
options for resident participation in local governance. We argue that while communities
may be effective in their use of ICTs, technology may not increase their political
power.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2307–2319},
numpages = {13},
keywords = {low income, participatory governance, civic engagement},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025559,
author = {Johnson, Ian G. and MacDonald, Alistair and Briggs, Jo and Manuel, Jennifer and Salt, Karen and Flynn, Emma and Vines, John},
title = {Community Conversational: Supporting and Capturing Deliberative Talk in Local Consultation Processes},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025559},
doi = {10.1145/3025453.3025559},
abstract = {The development of platforms for community decision-making has been of growing interest
to the HCI community, yet the ways technology might be woven into traditional consultation
processes has been under-studied. We conducted fieldwork at consultation events where
residents were invited to discuss and map assets related to their neighbourhoods to
inform community decision-making. The fieldwork highlighted problems with equality,
turn taking, the evidencing and elaborating on opinions by residents, and challenges
related to capturing and documenting the events. We developed Community Conversational-a
hybrid table-top game and digital capture and review platform-in response to these
issues. Community Conversational was designed to provide a flexible structure to consultation
events related to 'place', and support the production, capture and review of deliberative 'talk' to support decision-making. We study how the platform was used in two consultation
events, and discuss the implications of capturing and evidencing local people's opinions
for the accountability of decision-makers and community organisations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2320–2333},
numpages = {14},
keywords = {civic technology, consultation, deliberation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026044,
author = {Chang, Joseph Chee and Amershi, Saleema and Kamar, Ece},
title = {Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026044},
doi = {10.1145/3025453.3026044},
abstract = {Crowdsourcing provides a scalable and efficient way to construct labeled datasets
for training machine learning systems. However, creating comprehensive label guidelines
for crowdworkers is often prohibitive even for seemingly simple concepts. Incomplete
or ambiguous label guidelines can then result in differing interpretations of concepts
and inconsistent labels. Existing approaches for improving label quality, such as
worker screening or detection of poor work, are ineffective for this problem and can
lead to rejection of honest work and a missed opportunity to capture rich interpretations
about data. We introduce Revolt, a collaborative approach that brings ideas from expert
annotation workflows to crowd-based labeling. Revolt eliminates the burden of creating
detailed label guidelines by harnessing crowd disagreements to identify ambiguous
concepts and create rich structures (groups of semantically related items) for post-hoc
label decisions. Experiments comparing Revolt to traditional crowdsourced labeling
show that Revolt produces high quality labels without requiring label guidelines in
turn for an increase in monetary cost. This up front cost, however, is mitigated by
Revolt's ability to produce reusable structures that can accommodate a variety of
label boundaries without requiring new data to be collected. Further comparisons of
Revolt's collaborative and non-collaborative variants show that collaboration reaches
higher label accuracy with lower monetary cost.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2334–2346},
numpages = {13},
keywords = {crowdsourcing, real-time, machine learning, collaboration},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026025,
author = {Barowy, Daniel W. and Berger, Emery D. and Goldstein, Daniel G. and Suri, Siddharth},
title = {VoxPL: Programming with the Wisdom of the Crowd},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026025},
doi = {10.1145/3025453.3026025},
abstract = {Having a crowd estimate a numeric value is the original inspiration for the notion
of "the wisdom of the crowd." Quality control for such estimated values is challenging
because prior, consensus-based approaches for quality control in labeling tasks are
not applicable in estimation tasks. We present VoxPL, a high-level programming framework
that automatically obtains high-quality crowdsourced estimates of values. The VoxPL
domain-specific language lets programmers concisely specify complex estimation tasks
with a desired level of confidence and budget. VoxPL's runtime system implements a
novel quality control algorithm that automatically computes sample sizes and obtains
high quality estimates from the crowd at low cost. To evaluate VoxPL, we implement
four estimation applications, ranging from facial feature recognition to calorie counting.
The resulting programs are concise---under 200 lines of code---and obtain high quality
estimates from the crowd quickly and inexpensively.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2347–2358},
numpages = {12},
keywords = {crowdsourcing, quality control, domain-specific languages, scalability, wisdom of the crowd, crowdprogramming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025551,
author = {Curmi, Franco and Ferrario, Maria Angela and Whittle, Jon},
title = {Embedding a Crowd inside a Relay Baton: A Case Study in a Non-Competitive Sporting Activity},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025551},
doi = {10.1145/3025453.3025551},
abstract = {This paper presents a digital relay baton that connects long-distance runners with
distributed online spectators. The baton broadcasts athletes? live locative data to
a social network and communicates back remote-crowd support through haptic and audible
cheers. Our work takes an exploratory design approach to bring new insights into the
design of real-time techno-mediated social support. The prototype was deployed during
a 170-mile charity relay race across the UK with 13 participants, 261 on-line supporters,
and gathered a total of 3,153 'cheers'. We report on the insights collected during
the design and deployment process and identify three fundamental design considerations:
the degree of spectator expression that the design affords, the context applicability,
and the data flow within the social network.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2359–2370},
numpages = {12},
keywords = {cheering, relay baton, social networks, spectators, sports, relay race, broadcast, social support},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025647,
author = {Gonzales, Amy and Fritz, Nicole},
title = {Prioritizing Flexibility and Intangibles: Medical Crowdfunding for Stigmatized Individuals},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025647},
doi = {10.1145/3025453.3025647},
abstract = {HCI research on crowdfunding has primarily focused on creative or organizational endeavors.
Yet a majority of crowdfunding campaigns are conducted by individuals in need, often
for healthcare. To better understand and improve this common crowdfunding experience,
especially for those that inhabit a vulnerable social status, we conducted 20 interviews
with transmen crowdfunding for top-surgery. Design choices that optimize site flexibility
(e.g. control of personal information; enable cross-site communication) and foreground
intangibles, such as political values and emotional support, are priorities for individuals
from a stigmatized community. Findings differed from previous crowdfunding research
and contribute to limited research on transgender identities in HCI. Overall they
provide unique insights into how design choices can facilitate marginalized identity
management in highly public online spaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2371–2375},
numpages = {5},
keywords = {crowdfunding, identity, transmen, healthcare, privacy, vulnerable populations},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025763,
author = {Dey, Sanorita and Karahalios, Karrie and Fu, Wai-Tat},
title = {Understanding the Effects of Endorsements in Scientific Crowdfunding},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025763},
doi = {10.1145/3025453.3025763},
abstract = {Understanding the factors that persuade backers to donate to research projects has
become increasingly important with the rising popularity of scientific crowdfunding.
Although there are many similarities between enterprise and scientific crowdfunding,
some factors differentiate these two forms of crowdfunding. One such factor is the
use of endorsements. The endorsement helps backers gain trust based on expert opinions
about the competency of the researchers and the usefulness of the projects. We analyzed
810 endorsements from scientific campaigns posted on Experiment.com and derived a
taxonomy of topics discussed in the endorsements. A regression analysis revealed that
when endorsers explained the skills of the campaign owners, the probability of success
of the campaign improved; on the contrary, when endorsers reiterated the goal of the
project, the campaign was less likely to succeed. We conclude with design implications
formulated from our findings to better support scientific crowdfunding.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2376–2381},
numpages = {6},
keywords = {endorsement, scientific crowdfunding, crowdfunding},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025780,
author = {Cranshaw, Justin and Elwany, Emad and Newman, Todd and Kocielnik, Rafal and Yu, Bowen and Soni, Sandeep and Teevan, Jaime and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {Calendar.Help: Designing a Workflow-Based Scheduling Agent with Humans in the Loop},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025780},
doi = {10.1145/3025453.3025780},
abstract = {Although we may complain about meetings, they are an essential part of an information
worker's work life. Consequently, busy people spend a significant amount of time scheduling
meetings. We present Calendar.help, a system that provides fast, efficient scheduling
through structured workflows. Users interact with the system via email, delegating
their scheduling needs to the system as if it were a human personal assistant. Common
scheduling scenarios are broken down using well-defined workflows and completed as
a series of microtasks that are automated when possible and executed by a human otherwise.
Unusual scenarios fall back to a trained human assistant executing an unstructured
macrotask. We describe the iterative approach we used to develop Calendar.help, and
share the lessons learned from scheduling thousands of meetings during a year of real-world
deployments. Our findings provide insight into how complex information tasks can be
broken down into repeatable components that can be executed efficiently to improve
productivity.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2382–2393},
numpages = {12},
keywords = {assistant, macrotask, microtask, scheduling, crowdsourcing, conversational agent},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025621,
author = {Miller, Matthew K. and Tang, John C. and Venolia, Gina and Wilkinson, Gerard and Inkpen, Kori},
title = {Conversational Chat Circles: Being All Here Without Having to Hear It All},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025621},
doi = {10.1145/3025453.3025621},
abstract = {Live streaming services are a growing form of social media. Most live streaming platforms
allow viewers to communicate with each other and the broadcaster via a text chat.
However, interaction in a text chat does not work well with too many users. Existing
techniques to make text chat work with a larger number of participants often limit
who can participate or how much users can participate. In this paper, we describe
a new design for a text chat system that allows more people to participate without
overwhelming users with too many messages. Our design strategically limits the number
of messages a user sees based on the concept of neighborhoods, and emphasizes important
messages through upvoting. We present a study comparing our system to a chat system
similar to those found in commercial streaming services. Results of the study indicate
that the Conversational Circle system is easier to understand and interact with, while
supporting community among viewers and highlighting important content for the streamer.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2394–2404},
numpages = {11},
keywords = {live streaming, text chat},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025700,
author = {Fong, Allan and Hettinger, A. Zachary and Ratwani, Raj M.},
title = {A Predictive Model of Emergency Physician Task Resumption Following Interruptions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025700},
doi = {10.1145/3025453.3025700},
abstract = {Interruptions in the emergency department (ED) can have serious patient safety consequences,
and few solutions exist to mitigate the disruptiveness of interruptions. We developed
a theoretically motivated model to predict the likelihood of emergency physicians
returning to an interrupted task. Eighteen emergency physicians were observed individually
for two-hour blocks of time, resulting in a total of 2160 minutes of observation and
231 interruptions. We used a mixed effects logistic regression model to predict the
likelihood of primary task resumption after interruptions. The likelihood of primary
task resumption was predicted by memory decay, measured by the duration of the interruption,
workload, measured by the patient volume during the shift, and whether shift was day
or night. With a better understanding of these interruptions, we can help design interventions
to manage interruptions, minimize medical errors, and improve patient safety.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2405–2410},
numpages = {6},
keywords = {logistic mixed-effects model, predictive modeling, task resumption, emergency department, interruption, patient safety},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025552,
author = {Xiao, Xiang and Wang, Jingtao},
title = {Undertanding and Detecting Divided Attention in Mobile MOOC Learning},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025552},
doi = {10.1145/3025453.3025552},
abstract = {The emergence of mobile apps for Massive Open Online Courses (MOOCs) allows learners
to access quality learning materials at low cost and "to control where, what, how
and with whom they learn". Unfortunately, when compared with traditional classroom
education, learners face more distractions and are more likely to multitask when they
study alone in an informal learning environment. In this paper, we investigate the
impact of divided attention (DA) on both the learning process and learning outcomes
in the context of mobile MOOC learning. We propose OneMind, a system and algorithm
for detecting divided attention on unmodified mobile phones via implicit, camera-based
heart rate tracking. In an 18-participant study, we found that internal divided attention
has a significant negative impact on learning outcomes; and that the photoplethysmography
(PPG) waveforms implicitly captured by OneMind can be used to detect the presence,
type, and intensity of divided attention in mobile MOOC learning.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2411–2415},
numpages = {5},
keywords = {divided attention, mooc, mobile interfaces, ppg},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025971,
author = {Jung, Jingun and Youn, Eunhye and Lee, Geehyuk},
title = {PinPad: Touchpad Interaction with Fast and High-Resolution Tactile Output},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025971},
doi = {10.1145/3025453.3025971},
abstract = {We explored new interaction scenarios that can be realized when a touchpad outputs
fast and high-resolution spatio-temporal tactile patterns to the touch-sensitive skin
on the fingertips of a user. We first constructed a special tactile multi-touch touchpad
called PinPad, which was capable of outputting fast and high-resolution tactile patterns
using a 40 x 25 array of actuated pins. We then developed various interaction scenarios
that could be realized using the prototype: 1) Tactile Target, 2) Guide and Constraint,
3) Multi-finger Output, and 4) Dynamic Partition. To evaluate the PinPad scenarios,
we implemented demo applications, and conducted interviews with users to collect feedback
about their experiences with PinPad and the PinPad scenarios. The participants confirmed
the effectiveness of spatio-temporal outputs of PinPad in the scenarios. In particular,
they provided diverse feedback regarding the unique tactile experiences of the fast
and high-resolution outputs of PinPad.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2416–2425},
numpages = {10},
keywords = {pinpad, tactile touchpad interaction, fast and high-resolution tactile output},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025457,
author = {Cornelio Martinez, Patricia Ivette and De Pirro, Silvana and Vi, Chi Thanh and Subramanian, Sriram},
title = {Agency in Mid-Air Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025457},
doi = {10.1145/3025453.3025457},
abstract = {Touchless interfaces allow users to view, control and manipulate digital content without
physically touching an interface. They are being explored in a wide range of application
scenarios from medical surgery to car dashboard controllers. One aspect of touchless
interaction that has not been explored to date is the Sense of Agency (SoA). The SoA
refers to the subjective experience of voluntary control over actions in the external
world. In this paper, we investigated the SoA in touchless systems using the intentional
binding paradigm. We first compare touchless systems with physical interactions and
then augmented different types of haptic feedback to explore how different outcome
modalities influence intentional binding. From our experiments, we demonstrated that
an intentional binding effect is observed in both physical and touchless interactions
with no statistical difference. Additionally, we found that haptic and auditory feedback
help to increase SoA compared with visual feedback in touchless interfaces. We discuss
these findings and identify design opportunities that take agency into consideration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2426–2439},
numpages = {14},
keywords = {gestures, intentional binding, haptics, the sense of agency, touchless interfaces},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025655,
author = {Al Maimani, Ahmed and Roudaut, Anne},
title = {Frozen Suit: Designing a Changeable Stiffness Suit and Its Application to Haptic Games},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025655},
doi = {10.1145/3025453.3025655},
abstract = {We present the concept of Frozen Suit, a type of clothing that restricts users' movements
at joint positions (e.g. elbow, knee) via a changeable stiffness jamming material.
The suit can "freeze" users' body parts, for example during a game in order to provide
the physical sensation of being frozen by an enemy. In this paper we first present
the Frozen Suit concept and its potential applications. We then systematically investigate
how to design jamming patches in order to sufficiently restrict an arm or a leg. In
particular we used low-fidelity prototypes to explore the restricting power of different
material and particles. In order to push this analysis further we conducted a controlled
experiment in order to compare the perceived stiffness of different patches sizes
attached to the elbow. We performed a paired comparison experience and used a Bradley-Terry-Luce
model to analyze the subjective feedback from participants. We found that 20cm long
x 7cm large is the most restrictive patch and that an increase in patch area correlates
with an increase in perceived stiffness (quadratic). We finish by presenting a use
case application with a game that we implemented where enemies can freeze the player.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2440–2448},
numpages = {9},
keywords = {changeable stiffness, wearable, haptic feedback, clothing, jamming, paired comparison experiment},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025994,
author = {\"{O}zg\"{u}r, Ayberk and Johal, Wafa and Mondada, Francesco and Dillenbourg, Pierre},
title = {Haptic-Enabled Handheld Mobile Robots: Design and Analysis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025994},
doi = {10.1145/3025453.3025994},
abstract = {The Cellulo robots are small tangible robots that are designed to represent virtual
interactive point-like objects that reside on a plane within carefully designed learning
activities. In the context of these activities, our robots not only display autonomous
motion and act as tangible interfaces, but are also usable as haptic devices in order
to exploit, for instance, kinesthetic learning. In this article, we present the design
and analysis of the haptic interaction module of the Cellulo robots. We first detail
our hardware and controller design that is low-cost and versatile. Then, we describe
the task-based experimental procedure to evaluate the robot's haptic abilities. We
show that our robot is usable in most of the tested tasks and extract perceptive and
manipulative guidelines for the design of haptic elements to be integrated in future
learning activities. We conclude with limitations of the system and future work.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2449–2461},
numpages = {13},
keywords = {mobile robots, handheld robots, haptic interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025816,
author = {van Delden, Robby and Moreno, Alejandro and Poppe, Ronald and Reidsma, Dennis and Heylen, Dirk},
title = {A Thing of Beauty: Steering Behavior in an Interactive Playground},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025816},
doi = {10.1145/3025453.3025816},
abstract = {Interactive playgrounds are spaces where players engage in collocated, playful activities,
in which added digital technology can be designed to promote cognitive, social, and
motor skills development. To promote such development, different strategies can be
used to implement game mechanics that change player's in-game behavior. One of such
strategies is enticing players to take action through incentives akin to game achievements.
We explored if this strategy could be used to influence players' proxemic behavior
in the Interactive Tag Playground, an installation that enhances the traditional game
of tag. We placed the ITP in an art gallery, observed hundreds of play sessions, and
refined the mechanics, which consisted in projecting collectible particles around
the tagger that upon collection by runners resulted only in the embellishment of their
circles. We implemented the refined mechanics in a study with 48 children. The playground
automatically collected the players' positions, and analyses show that runners got
closer to and moved more towards taggers when using our enticing strategy. This suggests
an enticing strategy can be used to influence physical in-game behavior.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2462–2472},
numpages = {11},
keywords = {augmented reality, social, interactive playgrounds, steering behavior, persuasion, play, entice, proxemics, interactive floor},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025746,
author = {Mueller, Florian 'Floyd' and Young, Damon},
title = {Five Lenses for Designing Exertion Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025746},
doi = {10.1145/3025453.3025746},
abstract = {The field of HCI has increasingly looked at ways to support the physically active
human being, however, new work suggests that the field has only begun to understand
the many virtues of exertion. To further the field, we present a set of five design
lenses extended primarily from sports philosophy literature to help approach exertion
not just as a means of deferring death, but also as an opportunity for personal growth.
The lenses facilitate learning how to appreciate a void (Reverie), welcome pleasure
(Pleasure), become humble (Humility), as well as be fearful and excited simultaneously
(Sublime), whilst being more carefully aware of one's own body (Oneness). Using these
lenses, we articulate associated technology opportunities through related work as
well as our own craft knowledge. With our work, we aim to support designers who want
to facilitate the many virtues of exertion so that ultimately more people profit from
the many benefits of being physically active.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2473–2487},
numpages = {15},
keywords = {movement-based interaction, exertion interface, whole-body interaction, exergame, sport, exertion games},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025476,
author = {Park, Hyung Kun and Yi, HyeonBeom and Lee, Woohun},
title = {Recording and Sharing Non-Visible Information on Body Movement While Skateboarding},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025476},
doi = {10.1145/3025453.3025476},
abstract = {Knowing your own body movement is an essential element of sports. Recently, the popularization
of smartphones has enabled people to easily record their performance in most situations.
However, these observations have limited applicability in assisting with a clear understanding
of body movement. In this paper, we propose the Motion Log Skateboard, which records
and shares non-visible information about body movement that is difficult to obtain
through current observation methods in skateboarding. A pressure-sensor matrix on
a skateboard deck is used to record the pressure distribution data, which are then
played using the video function of a smartphone camera. With this logged data, a user
can access the feet positions, pressure intensity, and timing of the foot movements.
To verify the proposed concept and determine the specific context of its use, an experimental
session and interviews were conducted with skateboarders of various skill levels.
Based on the results of this research, the shared experiences of non-visible information,
which is perceived differently depending on the individual, are expected to become
a standard for exploring and training body movement.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2488–2492},
numpages = {5},
keywords = {representation, body perception, body movement, skateboarding, sports learning, sports interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025871,
author = {Paavilainen, Janne and Korhonen, Hannu and Alha, Kati and Stenros, Jaakko and Koskinen, Elina and Mayra, Frans},
title = {The Pok\'{e}Mon GO Experience: A Location-Based Augmented Reality Mobile Game Goes Mainstream},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025871},
doi = {10.1145/3025453.3025871},
abstract = {Pok\'{e}mon GO is a location-based augmented reality mobile game based on the Pok\'{e}mon
franchise. After the game was launched globally in July 2016, it quickly became the
most successful mobile game in both popularity and revenue generation at the time,
and the first location-based augmented reality game to reach a mainstream status.
We explore the game experiences through a qualitative survey (n=1000) in Finland focusing
on the positive and the negative aspects of Pok\'{e}mon GO as told by the players. The
positive experiences are related to movement, sociability, game mechanics, and brand
while the negative experiences emerge from technical problems, unequal gaming opportunities,
bad behavior of other players and non-players, and unpolished game design. Interestingly,
the augmented reality features, safety issues or the free-to-play revenue model did
not receive considerable feedback. The findings are useful for academics and industry
practitioners for studying and designing location-based augmented reality game experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2493–2498},
numpages = {6},
keywords = {game experience, Pokemon GO, augmented reality, location-based, mobile game, pervasive game, qualitative study, game design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025629,
author = {Britton, Lauren M. and Semaan, Bryan},
title = {Manifesting the Cyborg through Techno-Body Modification: From Human-Computer Interaction to Integration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025629},
doi = {10.1145/3025453.3025629},
abstract = {A community of DIY cyborgs has emerged, known as 'grinders', who practice techno-body
modification-the embedding of computing technology into the body. This paper reports
on an ethnographic study following GrinderTech, an organization working to design,
build and sell these technological artifacts, as it shifts from hacker collective
to biotech startup. As technologies are embedded in the body, the boundary between
human and machine starts to blur. We find that GrinderTech members, through the design
and making of technologies for embedding, do so as a means to move beyond social and
gendered binary constructions-or, societal norms that are practiced and performed,
and re-enforced through language, as a way of creating power differentials in society,
e.g. citizen/scientist and man/woman. Moreover, their motivations for designing and
making these devices reflects their desire to re-imagine society. Finally, we re-conceptualize
Human-Computer Interaction to include Integration-when technology is embedded in the
human body-and discuss the theoretical and design implications of human-computer integration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2499–2510},
numpages = {12},
keywords = {cyborg, human computer integration, fsts},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025968,
author = {Hou, Youyang and Lampe, Cliff and Bulinski, Maximilian and Prescott, J.J.},
title = {Factors in Fairness and Emotion in Online Case Resolution Systems},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025968},
doi = {10.1145/3025453.3025968},
abstract = {Courts are increasingly adopting online information and communication technology,
creating a need to consider the potential consequences of these tools for the justice
system. Using survey responses from 209 litigants who had recently used an online
case resolution system, we investigate factors that influenced litigants' experiences
of fairness and emotional feelings toward court officials. Our results show that ease
of using the online case resolution system, the outcome of the case, and a litigant's
perceptions of procedural justice are positively associated both with whether the
litigant views the process as fair and whether the litigant ultimately feels positive
emotions toward court officials. We also analyze the online explanations litigants
offer in their arguments to courts and litigant answers to an open-ended question
about their court experiences, and highlight design and practical implications for
online systems seeking to improve access to justice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2511–2522},
numpages = {12},
keywords = {judicial systems, fairness, e-government, courts, cscw, procedural justice, justice},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025539,
author = {Oh, Changhoon and Lee, Taeyoung and Kim, Yoojung and Park, SoHyun and Kwon, Saebom and Suh, Bongwon},
title = {Us vs. Them: Understanding Artificial Intelligence Technophobia over the Google DeepMind Challenge Match},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025539},
doi = {10.1145/3025453.3025539},
abstract = {Various forms of artificial intelligence (AI), such as Apple's Siri and Google Now,
have permeated our everyday lives. However, the advent of such "human-like" technology
has stirred both awe and a great deal of fear. Many consider it a woe to have an unimaginable
future where human intelligence is exceeded by AI. This paper investigates how people
perceive and understand AI with a case study of the Google DeepMind Challenge Match,
a Go match between Lee Sedol and AlphaGo, in March 2016. This study explores the underlying
and changing perspectives toward AI as users experienced this historic event. Interviews
with 22 participants show that users tacitly refer to AlphaGo as an "other" as if
it were comparable to a human, while dreading that it would come back to them as a
potential existential threat. Our work illustrates a confrontational relationship
between users and AI, and suggests the need to prepare for a new kind of user experience
in this nascent socio- technological change. It calls for a collaborative research
effort from the HCI community to study and accommodate users for a future where they
interact with algorithms, not just interfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2523–2534},
numpages = {12},
keywords = {artificial intelligence, alienation, technophobia, algorithm, anthropomorphism, algorithmic experience},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025757,
author = {Lin, Yen-Chen and Chang, Yung-Ju and Hu, Hou-Ning and Cheng, Hsien-Tzu and Huang, Chi-Wen and Sun, Min},
title = {Tell Me Where to Look: Investigating Ways for Assisting Focus in 360° Video},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025757},
doi = {10.1145/3025453.3025757},
abstract = {360° videos give viewers a spherical view and immersive experience of surroundings.
However, one challenge of watching 360° videos is continuously focusing and re-focusing
intended targets. To address this challenge, we developed two Focus Assistance techniques:
Auto Pilot (directly bringing viewers to the target), and Visual Guidance (indicating
the direction of the target). We conducted an experiment to measure viewers' video-watching
experience and discomfort using these techniques and obtained their qualitative feedback.
We showed that: 1) Focus Assistance improved ease of focus. 2) Focus Assistance techniques
have specificity to video content. 3) Participants' preference of and experience with
Focus Assistance depended not only on individual difference but also on their goal
of watching the video. 4) Factors such as view-moving-distance, salience of the intended
target and guidance, and language comprehension affected participants' video-watching
experience. Based on these findings, we provide design implications for better 360°
video focus assistance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2535–2545},
numpages = {11},
keywords = {video experience, visual guidance, focus assistance, 360-degree videos, auto pilot},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025794,
author = {Huang, Michael Xuelin and Li, Jiajia and Ngai, Grace and Leong, Hong Va},
title = {ScreenGlint: Practical, In-Situ Gaze Estimation on Smartphones},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025794},
doi = {10.1145/3025453.3025794},
abstract = {Gaze estimation has widespread applications. However, little work has explored gaze
estimation on smartphones, even though they are fast becoming ubiquitous. This paper
presents ScreenGlint, a novel approach which exploits the glint (reflection) of the
screen on the user's cornea for gaze estimation, using only the image captured by
the front-facing camera. We first conduct a user study on common postures during smartphone
use. We then design an experiment to evaluate the accuracy of ScreenGlint under varying
face-to-screen distances. An in-depth evaluation involving multiple users is conducted
and the impact of head pose variations is investigated. ScreenGlint achieves an overall
angular error of 2.44º without head pose variations, and 2.94º with head pose variations.
Our technique compares favorably to state-of-the-art research works, indicating that
the glint of the screen is an effective and practical cue to gaze estimation on the
smartphone platform. We believe that this work can open up new possibilities for practical
and ubiquitous gaze-aware applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2546–2557},
numpages = {12},
keywords = {mobile eye tracker, glint, screen reflection, gaze estimation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025517,
author = {Mott, Martez E. and Williams, Shane and Wobbrock, Jacob O. and Morris, Meredith Ringel},
title = {Improving Dwell-Based Gaze Typing with Dynamic, Cascading Dwell Times},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025517},
doi = {10.1145/3025453.3025517},
abstract = {We present cascading dwell gaze typing, a novel approach to dwell-based eye typing
that dynamically adjusts the dwell time of keys in an on-screen keyboard based on
the likelihood that a key will be selected next, and the location of the key on the
keyboard. Our approach makes unlikely keys more difficult to select and likely keys
easier to select by increasing and decreasing their required dwell times, respectively.
To maintain a smooth typing rhythm for the user, we cascade the dwell time of likely
keys, slowly decreasing the minimum allowable dwell time as a user enters text. Cascading
the dwell time affords users the benefits of faster dwell times while causing little
disruption to users' typing cadence. Results from a longitudinal study with 17 non-disabled
participants show that our dynamic cascading dwell technique was significantly faster
than a static dwell approach. Participants were able to achieve typing speeds of 12.39
WPM on average with our cascading technique, whereas participants were able to achieve
typing speeds of 10.62 WPM on average with a static dwell time approach. In a small
evaluation conducted with five people with ALS, participants achieved average typing
speeds of 9.51 WPM with our cascading dwell approach. These results show that our
dynamic cascading dwell technique has the potential to improve gaze typing for users
with and without disabilities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2558–2570},
numpages = {13},
keywords = {gaze typing, text entry, eye typing, accessibility},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026033,
author = {Andrist, Sean and Gleicher, Michael and Mutlu, Bilge},
title = {Looking Coordinated: Bidirectional Gaze Mechanisms for Collaborative Interaction with Virtual Characters},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026033},
doi = {10.1145/3025453.3026033},
abstract = {Successful collaboration relies on the coordination and alignment of communicative
cues. In this paper, we present mechanisms of bidirectional gaze - the coordinated
production and detection of gaze cues - by which a virtual character can coordinate
its gaze cues with those of its human user. We implement these mechanisms in a hybrid
stochastic/heuristic model synthesized from data collected in human-human interactions.
In three lab studies wherein a virtual character instructs participants in a sandwich-making
task, we demonstrate how bidirectional gaze can lead to positive outcomes in error
rate, completion time, and the agent's ability to produce quick, effective nonverbal
references. The first study involved an on-screen agent and the participant wearing
eye-tracking glasses. The second study demonstrates that these positive outcomes can
be achieved using head-pose estimation in place of full eye tracking. The third study
demonstrates that these effects also transfer into virtual-reality interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2571–2582},
numpages = {12},
keywords = {joint attention, bidirectional gaze, dyadic gaze, embodied agents, gaze coordination, verbal referencing, interactive gaze},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025652,
author = {Ledo, David and Anderson, Fraser and Schmidt, Ryan and Oehlberg, Lora and Greenberg, Saul and Grossman, Tovi},
title = {Pineal: Bringing Passive Objects to Life with Embedded Mobile Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025652},
doi = {10.1145/3025453.3025652},
abstract = {Interactive, smart objects-customized to individuals and uses-are central to many
movements, such as tangibles, the internet of things (IoT), and ubiquitous computing.
Yet, rapid prototyping both the form and function of these custom objects can be problematic,
particularly for those with limited electronics or programming experience. Designers
often need to embed custom circuitry; program its workings; and create a form factor
that not only reflects the desired user experience but can also house the required
circuitry and electronics. To mitigate this, we created Pineal, a design tool that
lets end-users: (1) modify 3D models to include a smart watch or phone as its heart;
(2) specify high-level interactive behaviours through visual programming; and (3)
have the phone or watch act out such behaviours as the objects' "smarts". Furthermore,
a series of prototypes show how Pineal exploits mobile sensing and output, and automatically
generates 3D printed form-factors for rich, interactive, objects.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2583–2593},
numpages = {11},
keywords = {smart objects, fabrication, rapid prototyping, 3d printing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025950,
author = {Santini, Thiago and Fuhl, Wolfgang and Kasneci, Enkelejda},
title = {CalibMe: Fast and Unsupervised Eye Tracker Calibration for Gaze-Based Pervasive Human-Computer Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025950},
doi = {10.1145/3025453.3025950},
abstract = {As devices around us become smart, our gaze is poised to become the next frontier
of human-computer interaction (HCI). State-of-the-art mobile eye tracker systems typically
rely on eye-model-based gaze estimation approaches, which do not require a calibration.
However, such approaches require specialized hardware (e.g., multiple cameras and
glint points), can be significantly affected by glasses, and, thus, are not fit for
ubiquitous gaze-based HCI. In contrast, regression-based gaze estimations are straightforward
approaches requiring solely one eye and one scene camera but necessitate a calibration.
Therefore, a fast and accurate calibration is a key development to enable ubiquitous
gaze-based HCI. In this paper, we introduce CalibMe, a novel method that exploits
collection markers (automatically detected fiducial markers) to allow eye tracker
users to gather a large array of calibration points, remove outliers, and automatically
reserve evaluation points in a fast and unsupervised manner. The proposed approach
is evaluated against a nine-point calibration method, which is typically used due
to its relatively short calibration time and adequate accuracy. CalibMe reached a
mean angular error of 0.59 (0=0.23) in contrast to 0.82 (0=0.15) for a nine-point
calibration, attesting for the efficacy of the method. Moreover, users are able to
calibrate the eye tracker anywhere and independently in - 10 s using a cellphone to
display the collection marker.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2594–2605},
numpages = {12},
keywords = {usability, eye tracking, calibration, fiducial markers, gaze-based interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026016,
author = {Kovacs, Robert and Seufert, Anna and Wall, Ludwig and Chen, Hsiang-Ting and Meinel, Florian and M\"{u}ller, Willi and You, Sijing and Brehm, Maximilian and Striebel, Jonathan and Kommana, Yannis and Popiak, Alexander and Bl\"{a}sius, Thomas and Baudisch, Patrick},
title = {TrussFab: Fabricating Sturdy Large-Scale Structures on Desktop 3D Printers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026016},
doi = {10.1145/3025453.3026016},
abstract = {We present TrussFab, an integrated end-to-end system that allows users to fabricate
large scale structures that are sturdy enough to carry human weight. TrussFab achieves
the large scale by complementing 3D print with plastic bottles. It does not use these
bottles as "bricks" though, but as beams that form structurally sound node-link structures,
also known as trusses, allowing it to handle the forces resulting from scale and load.
TrussFab embodies the required engineering knowledge, allowing non-engineers to design
such structures and to validate their design using integrated structural analysis.
We have used TrussFab to design and fabricate tables and chairs, a 2.5 m long bridge
strong enough to carry a human, a functional boat that seats two, and a 5 m diameter
dome.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2606–2616},
numpages = {11},
keywords = {3d printing, truss structure, fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025938,
author = {Vogl, Anita and Parzer, Patrick and Babic, Teo and Leong, Joanne and Olwal, Alex and Haller, Michael},
title = {StretchEBand: Enabling Fabric-Based Interactions through Rapid Fabrication of Textile Stretch Sensors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025938},
doi = {10.1145/3025453.3025938},
abstract = {The increased interest in interactive soft materials, such as smart clothing and responsive
furniture, means that there is a need for flexible and deformable electronics. In
this paper, we focus on stitch-based elastic sensors, which have the benefit of being
manufacturable with textile craft tools that have been used in homes for centuries.
We contribute to the understanding of stitch-based stretch sensors through four experiments
and one user study that investigate conductive yarns from textile and technical perspectives,
and analyze the impact of different stitch types and parameters. The insights informed
our design of new stretch-based interaction techniques that emphasize eyes-free or
causal interactions. We demonstrate with StretchEBand how soft, continuous sensors
can be rapidly fabricated with different parameters and capabilities to support interaction
with a wide range of performance requirements across wearables, mobile devices, clothing,
furniture, and toys.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2617–2627},
numpages = {11},
keywords = {stretching sensor, interactive textiles, DIY, smart car seat, deformation, smart textiles, fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025866,
author = {Kim, Younghoon and Wongsuphasawat, Kanit and Hullman, Jessica and Heer, Jeffrey},
title = {GraphScape: A Model for Automated Reasoning about Visualization Similarity and Sequencing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025866},
doi = {10.1145/3025453.3025866},
abstract = {We present GraphScape, a directed graph model of the vi- sualization design space
that supports automated reasoning about visualization similarity and sequencing. Graph
nodes represent grammar-based chart specifications and edges rep- resent edits that
transform one chart to another. We weight edges with an estimated cost of the difficulty
of interpreting a target visualization given a source visualization. We con- tribute
(1) a method for deriving transition costs via a partial ordering of edit operations
and the solution of a resulting lin- ear program, and (2) a global weighting term
that rewards consistency across transition subsequences. In a controlled experiment,
subjects rated visualization sequences covering a taxonomy of common transition types.
In all but one case, GraphScape's highest-ranked suggestion aligns with subjects'
top-rated sequences. Finally, we demonstrate applications of GraphScape to automatically
sequence visualization presen- tations, elaborate transition paths between visualizations,
and recommend design alternatives (e.g., to improve scalability while minimizing design
changes).},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2628–2638},
numpages = {11},
keywords = {transition, model, automated design, sequence, visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026006,
author = {von Zadow, Ulrich and Dachselt, Raimund},
title = {GIAnT: Visualizing Group Interaction at Large Wall Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026006},
doi = {10.1145/3025453.3026006},
abstract = {Large interactive displays are increasingly important and a relevant research topic,
and several studies have focused on wall interaction. However, in many cases, thorough
user studies currently require time-consuming video analysis and coding. We present
the Group Interaction Analysis Toolkit GIAnT, which provides a rich set of visualizations
supporting investigation of multi-user interaction at large display walls. GIAnT focuses
on visualizing time periods, making it possible to gain overview-level insights quickly.
The toolkit is designed to be extensible and features several carefully crafted visualizations:
A novel timeline visualization shows movement in front of the wall over time, a wall
visualization shows interactions on the wall and gaze data, and a floor visualization
displays user positions. In addition, GIAnT shows the captured video stream along
with basic statistics. We validate our tool by analyzing how it supports investigating
major research topics and by practical use in evaluating a cooperative game.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2639–2647},
numpages = {9},
keywords = {awareness, coupling, visualization, physical navigation, visual analysis, collaborative work, multitouch, territoriality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025768,
author = {Wongsuphasawat, Kanit and Qu, Zening and Moritz, Dominik and Chang, Riley and Ouk, Felix and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
title = {Voyager 2: Augmenting Visual Analysis with Partial View Specifications},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025768},
doi = {10.1145/3025453.3025768},
abstract = {Visual data analysis involves both open-ended and focused exploration. Manual chart
specification tools support question answering, but are often tedious for early-stage
exploration where systematic data coverage is needed. Visualization recommenders can
encourage broad coverage, but irrelevant suggestions may distract users once they
commit to specific questions. We present Voyager 2, a mixed-initiative system that
blends manual and automated chart specification to help analysts engage in both open-ended
exploration and targeted question answering. We contribute two partial specification
interfaces: wildcards let users specify multiple charts in parallel, while related
views suggest visualizations relevant to the currently specified chart. We present
our interface design and applications of the CompassQL visualization query language
to enable these interfaces. In a controlled study we find that Voyager 2 leads to
increased data field coverage compared to a traditional specification tool, while
still allowing analysts to flexibly drill-down and answer specific questions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2648–2659},
numpages = {12},
keywords = {exploratory analysis, partial specification, visualization recommendation, mixed-initiative interfaces, data visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025752,
author = {Jo, Jaemin and L'Yi, Sehi and Lee, Bongshin and Seo, Jinwook},
title = {TouchPivot: Blending WIMP &amp; Post-WIMP Interfaces for Data Exploration on Tablet Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025752},
doi = {10.1145/3025453.3025752},
abstract = {Recent advancements in tablet technology pose a great opportunity for information
visualization to expand its horizons beyond desktops. In this paper, we present TouchPivot,
a novel interface that assists visual data exploration on tablet devices. With novices
in mind, TouchPivot supports data transformations, such as pivoting and filtering,
with simple pen and touch interactions, and facilitates understanding of the transformations
through tight coupling between a data table and visualization. We bring in WIMP interfaces
to TouchPivot, leveraging their familiarity and accessibility to novices. We report
on a user study conducted to compare TouchPivot with two commercial interfaces, Tableau
and Microsoft Excel's PivotTable. Our results show that novices not only answered
data-driven questions faster, but also created a larger number of meaningful charts
during freeform exploration with TouchPivot than others. Finally, we discuss the main
hurdles novices encountered during our study and possible remedies for them.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2660–2671},
numpages = {12},
keywords = {table devices, pen and touch interaction, data exploration, novices, natural interaction, pivot, information visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025914,
author = {Salehzadeh Niksirat, Kavous and Silpasuwanchai, Chaklam and Mohamed Hussien Ahmed, Mahmoud and Cheng, Peng and Ren, Xiangshi},
title = {A Framework for Interactive Mindfulness Meditation Using Attention-Regulation Process},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025914},
doi = {10.1145/3025453.3025914},
abstract = {We are often overwhelmed by everyday stressors. Mindfulness meditation can help slow
things down and bring one's attention into the present moment. Given the prevalence
of smartphones, mindfulness-based mobile applications (MBMAs) have received much attention.
Current MBMAs mainly use the guided meditation method which may not be always effective,
e.g., users may not be able to follow the pace of instructions and they need a private
environment. This paper presents a framework for interactive MBMAs which allows users
to self-regulate their attention according to their abilities and conditions. The
framework is described by an Attention-Regulation Process and has two components:
(1) Relaxation Response and (2) Attention Restoration Theory. The framework is validated
by our experiment. It also informs future development for interactive meditation and
has broad implications for designing mindfulness and well-being.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2672–2684},
numpages = {13},
keywords = {mindfulness, framework, attention restoration theory, meditation, relaxation response, attention-regulation process, mobile applications, interactivity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025590,
author = {Zhu, Bin and Hedman, Anders and Li, Haibo},
title = {Designing Digital Mindfulness: Presence-In and Presence-With versus Presence-Through},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025590},
doi = {10.1145/3025453.3025590},
abstract = {The digital health and wellbeing movement has led to development of digital mindfulness
applications that aim to help people to become mindful. In this paper we suggest a
broad scheme for classifying and ordering apps intended to support mindfulness. This
scheme consists of four levels of what we here term digital mindfulness. One crucial
aspect of the fourth level is that artifacts at this level allow for what we term
as presence-with and presence-in as opposed to presence-through, which occurs at the
first three levels. We articulate our four levels along with specific design qualities
through concrete examples of existing mindfulness apps and through research through
design (RtD) work conducted with design fiction examples. We then use a working design
case prototype to further illustrate the possibilities of presence-with and presence-in.
We hope our four levels of digital mindfulness framework will be found useful by other
researchers in discussing and planning the design of their own mindfulness apps and
digital artifacts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2685–2695},
numpages = {11},
keywords = {awareness, aesthetics, digital mindfulness, presence, wellbeing, design, being, interaction, research through design, attention},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025516,
author = {Slov\'{a}k, Petr and Frauenberger, Christopher and Fitzpatrick, Geraldine},
title = {Reflective Practicum: A Framework of Sensitising Concepts to Design for Transformative Reflection},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025516},
doi = {10.1145/3025453.3025516},
abstract = {Designing for reflection is becoming an increasingly important part of many HCI systems
in a wide range of application domains. However, there is a gap in our understanding
of how the process of reflection can be supported through technology. In fact, an
implicit assumption in the majority of existing work is that, just by providing access
to well-selected data, in-depth reflection can and will occur. To counter this view,
we draw on Sch\"{o}n's notion of reflective practicum and apply it as a sensitising concept
to identify the complex interplay of factors that support transformative reflection
in the context of two social-emotional learning (SEL) studies. The results highlight
the need to carefully scaffold the process of reflection, rather than simply assume
that the capability to reflect is a broadly available trait to be 'triggered' through
data. Building on this analysis, we develop a conceptual framework that extends the
concept of the reflective practicum towards identifying appropriate roles of technology
to support transformative reflection. While our case is within the context of SEL,
we argue that a deeper understanding of these opportunities can also benefit designing
for reflection in other areas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2696–2707},
numpages = {12},
keywords = {social-emotional skills, reflection, sel, personal informatics, reflective informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025918,
author = {Barry, Marguerite and Doherty, Kevin and Marcano Belisario, Jose and Car, Josip and Morrison, Cecily and Doherty, Gavin},
title = {MHealth for Maternal Mental Health: Everyday Wisdom in Ethical Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025918},
doi = {10.1145/3025453.3025918},
abstract = {Health and wellbeing applications increasingly raise ethical issues for design. User-centred
and participatory design approaches, while grounded in everyday wisdom, cannot be
expected to address ethical reflection consistently, as multiple value systems come
into play. We explore the potential of phronesis, a concept from Aristotelian virtue
ethics, for mHealth design. Phronesis describes wisdom and judgment garnered from
practical experience of specific situations in context. Applied phronesis contributes
everyday wisdom to challenging issues for vulnerable target users. Drawing on research
into mHealth technologies for psychological wellbeing, we explore how phronesis can
inform ethical design. Using a case study on an app for self-reporting symptoms of
depression during pregnancy, we present a framework for incorporating a phronetic
approach into design, involving: (a) a wide feedback net to capture phronetic input
early in design; (b) observing the order of feedback, which directly affects value
priorities in design; (c) ethical pluralism recognising different coexisting value
systems; (d) acknowledging subjectivity in the disclosure and recognition of individual
researcher and participant values. We offer insights into how a phronetic approach
can contribute everyday wisdom to designing mHealth technologies to help designers
foster the values that promote human flourishing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2708–2756},
numpages = {49},
keywords = {virtue ethics, maternal mental health, ethical design, mHealth, phronesis, human flourishing, psychological wellbeing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025470,
author = {Dillahunt, Tawanna R. and Kameswaran, Vaishnav and Li, Linfeng and Rosenblat, Tanya},
title = {Uncovering the Values and Constraints of Real-Time Ridesharing for Low-Resource Populations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025470},
doi = {10.1145/3025453.3025470},
abstract = {Real-time ridesharing services (e.g., Uber and Lyft) are often touted as sharing-economy
leaders and dramatically lower the cost of transportation. However, how to make these
services work better among low-income and transportation-scarce households, how these
individuals experience these services, and whether they encounter barriers in enlisting
these services is unknown. To address these questions, we onboarded 13 low-income
individuals living in transportation-scarce environments to Uber as passengers. Our
participants found these services to be reliable and benefited from rich social interactions
with drivers; however, barriers such as cost, limited payment methods, and low digital
literacy can make such services infeasible. We contribute platform designs that could
lead to increased digital literacy and application transparency. To be more inclusive
and to reach critical mass, we suggest that these companies foster belief in commons
and community trust by coordinating with local businesses in low-resource areas with
lower digital literacy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2757–2769},
numpages = {13},
keywords = {low-income populations, sharing economy, real-time ridesharing services, uber, transportation scarcity, mobility},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025514,
author = {DeRenzi, Brian and Dell, Nicola and Wacksman, Jeremy and Lee, Scott and Lesh, Neal},
title = {Supporting Community Health Workers in India through Voice- and Web-Based Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025514},
doi = {10.1145/3025453.3025514},
abstract = {Our research aims to support community health workers (CHWs) in low-resource settings
by providing them with personalized information regarding their work. This information
is delivered through a combination of voice- and web-based feedback that is derived
from data already collected by CHWs. We describe the in situ participatory design
approach used to create usable and appropriate feedback for low-literate CHWs and
present usage data from a 12-month study with 71 CHWs in India. We show how the system
supported and motivated CHWs, and how they used both the web- and voice-based systems,
and each of the visualizations, for different reasons. We also show that the comparative
feedback provided by the system introduced elements of competition that discouraged
some CHWs while motivating others. Taken together, our findings suggest that providing
personalized voice- and web-based feedback could be an effective way to support and
motivate CHWs in low-resource settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2770–2781},
numpages = {12},
keywords = {community health, ictd, chw, asha, hci4d, mhealth},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025593,
author = {Lazem, Shaimaa and Jad, Hussein Aly},
title = {We Play We Learn: Exploring the Value of Digital Educational Games in Rural Egypt},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025593},
doi = {10.1145/3025453.3025593},
abstract = {The Egyptian education system faces urgent challenges. Proposed governmental reforms
tend to focus on increasing access to physical and digital resources. There is insufficient
understanding as to how the provided resources are currently used in rural areas.
We explored the extent to which digital technology could motivate primary students
to collaboratively learn a challenging topic in the National Mathematics Curriculum.
We designed and researched a digital game to support memorizing multiplication facts.
We used an incentive structure that encouraged individual learning with rewarding
teamwork. The game was tested with mixed ability and gender groups of students using
the Teams-Game-Tournament collaboration technique. A key outcome was that the students
with educationally disadvantaged backgrounds benefited from using the game format.
They devised their own play and study strategies. We discuss implications on future
designs of the game, and considerations for its integration in Egyptian schools.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2782–2791},
numpages = {10},
keywords = {play, games, collaborative learning, HCI4D, game-based learning, Egypt, edutainment, ICTD, ICT4D},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025958,
author = {Sorcar, Piya and Strauber, Benjamin and Loyalka, Prashant and Kumar, Neha and Goldman, Shelley},
title = {Sidestepping the Elephant in the Classroom: Using Culturally Localized Technology To Teach Around Taboos},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025958},
doi = {10.1145/3025453.3025958},
abstract = {Cultural taboos can restrict student learning on topics of critical importance. In
India, such taboos have led multiple states to ban materials intended to educate youth
about HIV, putting millions at risk. We present the design of TeachAIDS, a software
application that leverages cultural insights, learning science, and affordances of
technology to provide comprehensive HIV education while circumventing taboos. Using
a mixed-methods evaluation, we demonstrate that this software leaves students with
significantly increased knowledge about HIV and reduced stigma toward individuals
infected with the virus. Validating the effectiveness of TeachAIDS in circumventing
taboos, students report comfort in learning from the software, and it has since been
deployed in tens of thousands of schools throughout India. The methodology presented
here has broader implications for the design and implementation of interactive technologies
for providing education on sensitive topics in health and other areas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2792–2804},
numpages = {13},
keywords = {aids, taboo topics, hci4d, india, education, hiv},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025929,
author = {Fridman, Lex and Toyoda, Heishiro and Seaman, Sean and Seppelt, Bobbie and Angell, Linda and Lee, Joonbum and Mehler, Bruce and Reimer, Bryan},
title = {What Can Be Predicted from Six Seconds of Driver Glances?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025929},
doi = {10.1145/3025453.3025929},
abstract = {We consider a large dataset of real-world, on-road driving from a 100-car naturalistic
study to explore the predictive power of driver glances and, specifically, to answer
the following question: what can be predicted about the state of the driver and the
state of the driving environment from a 6-second sequence of macro-glances? The context-based
nature of such glances allows for application of supervised learning to the problem
of vision-based gaze estimation, making it robust, accurate, and reliable in messy,
real-world conditions. So, it's valuable to ask whether such macro-glances can be
used to infer behavioral, environmental, and demographic variables? We analyze 27
binary classification problems based on these variables. The takeaway is that glance
can be used as part of a multi-sensor real-time system to predict radio-tuning, fatigue
state, failure to signal, talking, and several environment variables.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2805–2813},
numpages = {9},
keywords = {gaze patterns, hidden markov models, naturalistic on-road study, driver state prediction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025634,
author = {Wang, MinJuan and Lyckvi, Sus Lundgren and Chen, Chenhui and Dahlstedt, Palle and Chen, Fang},
title = {Using Advisory 3D Sound Cues to Improve Drivers' Performance and Situation Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025634},
doi = {10.1145/3025453.3025634},
abstract = {Within vehicle Human Machine Interface design, visual displays are predominant, taking
up more and more of the visual channel for each new system added to the car, e.g.
navigation systems, blind spot information and forward collision warnings. Sounds
however, are mainly used to alert or warn drivers together with visual information.
In this study we investigated the design of auditory displays for advisory information,
by designing a 3D auditory advisory traffic information system (3DAATIS) which was
evaluated in a drive simulator study with 30 participants. Our findings indicate that
overall, drivers' performance and situation awareness improved when using this system.
But, more importantly, the results also point towards the advantages and limitations
of the use of advisory 3D-sounds in cars, e.g. attention capture vs. limited auditory
resolution. These findings are discussed and expressed as design implications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2814–2825},
numpages = {12},
keywords = {drive behavior, auditory display, 3d auditory advisory traffic information system, in-vehicle design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025511,
author = {Steinberger, Fabius and Schroeter, Ronald and Foth, Marcus and Johnson, Daniel},
title = {Designing Gamified Applications That Make Safe Driving More Engaging},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025511},
doi = {10.1145/3025453.3025511},
abstract = {Low levels of engagement while driving can pose road safety risks, e.g., inattention
during low traffic or routine trips. Interactive technologies that increase task engagement
could therefore offer safety benefits, e.g., through performance feedback, increased
challenge, and incentives. As a means to build upon these notions, we chose to explore
gamification of the driving task. The research aim was to study how to design gamified
applications that make safe driving more engaging. We present six design lenses which
bring into focus considerations most relevant to creating engaging car applications.
A user study enhanced our understanding of design requirements and revealed user personas
to support the development of such applications. These lenses and personas informed
two prototypes, which we evaluated in driving simulator studies. Our results indicate
that the gamified conditions increased driver engagement and reduced driving speeds.
As such, our work contributes towards the design of engaging applications that are
both appropriate to the safety-critical driving context and compelling to users.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2826–2839},
numpages = {14},
keywords = {road safety, gamification, task engagement},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025713,
author = {Mok, Brian and Johns, Mishel and Miller, David and Ju, Wendy},
title = {Tunneled In: Drivers with Active Secondary Tasks Need More Time to Transition from Automation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025713},
doi = {10.1145/3025453.3025713},
abstract = {In partially automated driving, rapid transitions of control present a severe hazard.
How long does it take a driver to take back control of the vehicle when engaged with
other non-driving tasks? In this driving simulator study, we examined the performance
of participants (N=30) after an abrupt loss of automated vehicle control. We tested
three transition time conditions, with an unstructured transition of control occurring
2s, 5s, or 8s before entering a curve. As participants were occupied with an active
secondary task (playing a game on a tablet) while the automated driving mode was enabled,
they needed to disengage from the task and regain control of the car when the transition
occurred. Few drivers in the 2 second condition were able to safely negotiate the
road hazard situation, while the majority of drivers in the 5 or 8 second conditions
were able to navigate the hazard situation safely.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2840–2844},
numpages = {5},
keywords = {car simulator, autonomous vehicles, controlled study, human machine interaction, transition of control},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025736,
author = {Ng, Alexander and Brewster, Stephen A. and Beruscha, Frank and Krautter, Wolfgang},
title = {An Evaluation of Input Controls for In-Car Interactions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025736},
doi = {10.1145/3025453.3025736},
abstract = {The way drivers operate in-car systems is rapidly changing as traditional physical
controls, such as buttons and dials, are being replaced by touchscreens and touch-sensing
surfaces. This has the potential to increase driver distraction and error as controls
may be harder to find and use. This paper presents an in-car, on the road driving
study which examined three key types of input controls to investigate their effects:
a physical dial, pressure-based input on a touch surface and touch input on a touchscreen.
The physical dial and pressure-based input were also evaluated with and without haptic
feedback. The study was conducted with users performing a list-based targeting task
using the different controls while driving on public roads. Eye-gaze was recorded
to measure distraction from the primary task of driving. The results showed that target
accuracy was high across all input methods (greater than 94%). Pressure-based targeting
was the slowest while directly tapping on the targets was the faster selection method.
Pressure-based input also caused the largest number of glances towards to the touchscreen
but the duration of each glance was shorter than directly touching the screen. Our
study will enable designers to make more appropriate design choices for future in-car
interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2845–2852},
numpages = {8},
keywords = {touch input, pressure-based input, haptic feedback, in-car interactions, touchscreens},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025785,
author = {Spiel, Katta and Frauenberger, Christopher and Hornecker, Eva and Fitzpatrick, Geraldine},
title = {When Empathy Is Not Enough: Assessing the Experiences of Autistic Children with Technologies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025785},
doi = {10.1145/3025453.3025785},
abstract = {Capturing and describing the multi-faceted experiences autistic children have with
technologies provides a unique research challenge. Approaches based on pragmatist
notions of experience, which mostly rely on empathy, are particularly limited if used
alone. To address this we have developed an approach that combines Actor-Network Theory
and Critical Discourse Analysis. Drawing on this approach, we discuss the experiences
autistic children had with technologies resulting from the collaborative design process
in the OutsideTheBox project. We construct a holistic picture of the experience by
drawing on diverse data sources ranging from interviews to log-data, and most importantly,
the first-hand perspective of autistic children. In four case studies, we demonstrate
how this approach allowed us to develop unique individual and structural insights
into the experiences of autistic children with technology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2853–2864},
numpages = {12},
keywords = {experience, autism, children, co-design evaluation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026014,
author = {Boyd, LouAnne E. and Jiang, Xinlong and Hayes, Gillian R.},
title = {ProCom: Designing and Evaluating a Mobile and Wearable System to Support Proximity Awareness for People with Autism},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026014},
doi = {10.1145/3025453.3026014},
abstract = {People with autism are at risk for social isolation due to differences in their perception
and engagement with the social world. In this work, we aim to address one specific
concern related to socialization the understanding, awareness, and use of interpersonal
space. Over the course of a year, we iteratively designed and tested a series of concepts
for supporting children with autism in perceiving, understanding, and responding to
physical proximity with other people. During this process, we developed ProCom, a
prototype system for measuring proximity without requiring instrumentation of the
environment or another person. We used a variety of low and high fidelity prototypes,
culminating in ProCom, to assess the feasibility, utility, and challenges of this
approach. The results of these iterative design engagements indicate that wearable
assistive technologies can support people in developing awareness of physical proximity
in social settings. However, challenges related to both personal and collective use
remain},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2865–2877},
numpages = {13},
keywords = {proximity, self-monitoring, social skills, wearable computing, autism, children, parallel design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025790,
author = {Zhang, Xiaoyi and Kulkarni, Harish and Morris, Meredith Ringel},
title = {Smartphone-Based Gaze Gesture Communication for People with Motor Disabilities},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025790},
doi = {10.1145/3025453.3025790},
abstract = {Current eye-tracking input systems for people with ALS or other motor impairments
are expensive, not robust under sunlight, and require frequent re-calibration and
substantial, relatively immobile setups. Eye-gaze transfer (e-tran) boards, a low-tech
alternative, are challenging to master and offer slow communication rates. To mitigate
the drawbacks of these two status quo approaches, we created GazeSpeak, an eye gesture
communication system that runs on a smartphone, and is designed to be low-cost, robust,
portable, and easy-to-learn, with a higher communication bandwidth than an e-tran
board. GazeSpeak can interpret eye gestures in real time, decode these gestures into
predicted utterances, and facilitate communication, with different user interfaces
for speakers and interpreters. Our evaluations demonstrate that GazeSpeak is robust,
has good user satisfaction, and provides a speed improvement with respect to an e-tran
board; we also identify avenues for further improvement to low-cost, low-effort gaze-based
communication technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2878–2889},
numpages = {12},
keywords = {eye gesture, augmentative and alternative communication (AAC), amyotrophic lateral sclerosis (ALS), accessibility},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025610,
author = {Sobel, Kiley and Fiannaca, Alexander and Campbell, Jon and Kulkarni, Harish and Paradiso, Ann and Cutrell, Ed and Morris, Meredith Ringel},
title = {Exploring the Design Space of AAC Awareness Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025610},
doi = {10.1145/3025453.3025610},
abstract = {Augmentative and alternative communication (AAC) devices are a critical technology
for people with disabilities that affect their speech. One challenge with AAC systems
is their inability to portray aspects of nonverbal communication that typically accent,
complement, regulate, or substitute for verbal speech. In this paper, we explore the
design space of awareness displays that can supplement AAC devices, considering their
output features and their effects on the perceptions of interlocutors. Through designing
prototypes and getting feedback on our designs from people with ALS, their primary
caregivers, and other communication partners, we consider (1) the consistent tensions
that arose between abstractness and clarity in meaning for these designs and (2) the
ways in which these designs can further mark users as "other." Overall, we contribute
a generative understanding of designing AAC awareness displays to augment and contextualize
communication.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2890–2903},
numpages = {14},
keywords = {nonverbal communication, emotion expression, accessibility, aac, disability., conversational flow, conversational awareness, awareness displays, als},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025456,
author = {Moritz, Dominik and Fisher, Danyel and Ding, Bolin and Wang, Chi},
title = {Trust, but Verify: Optimistic Visualizations of Approximate Queries for Exploring Big Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025456},
doi = {10.1145/3025453.3025456},
abstract = {Analysts need interactive speed for exploratory analysis, but big data systems are
often slow. With sampling, data systems can produce approximate answers fast enough
for exploratory visualization, at the cost of accuracy and trust. We propose optimistic
visualization, which approaches these issues from a user experience perspective. This
method lets analysts explore approximate results interactively, and provides a way
to detect and recover from errors later. Pangloss implements these ideas. We discuss
design issues raised by optimistic visualization systems. We test this concept with
five expert visualizers in a laboratory study and three case studies at Microsoft.
Analysts reported that they felt more confident in their results, and used optimistic
visualization to check that their preliminary results were correct.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2904–2915},
numpages = {12},
keywords = {uncertainty, approximation, data visualization, optimistic visualization, exploratory analysis},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025628,
author = {Du, Fan and Cao, Nan and Lin, Yu-Ru and Xu, Panpan and Tong, Hanghang},
title = {ISphere: Focus+Context Sphere Visualization for Interactive Large Graph Exploration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025628},
doi = {10.1145/3025453.3025628},
abstract = {Interactive exploration plays a critical role in large graph visualization. Existing
techniques, such as zoom-and-pan on a 2D plane and hyperbolic browser facilitate large
graph exploration by showing both the details of a focal area and its surrounding
context that guides the exploration process. However, existing techniques for large
graph exploration are limited in either providing too little context or presenting
graphs with too much distortion. In this paper, we propose a novel focus+context technique,
iSphere, to address the limitation. iSphere maps a large graph onto a Riemann Sphere
that better preserves graph structures and shows greater context information. We conduct
extensive experiment studies on different graph exploration tasks under various conditions.
The results show that iSphere performs the best in task completion time compared to
the baseline techniques in link and path exploration tasks. This research also contributes
to understanding large graph exploration on small screens.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2916–2927},
numpages = {12},
keywords = {graph visualization, focus+context, graph exploration},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025868,
author = {Kralj, Christoph and Kamalzadeh, Mohsen and M\"{o}ller, Torsten},
title = {TagRefinery: A Visual Tool for Tag Wrangling},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025868},
doi = {10.1145/3025453.3025868},
abstract = {We present TagRefinery, an interactive visual application aiding the cleaning and
processing of open tag spaces, such as those in Last.fm or YouTube. Our pre-design
analysis showed a need to support a spectrum of user expertise from novice to advanced,
which resulted in two distinct interface modes. Summative evaluations of TagRefinery
showed that it could effectively guide the novice users through the workflow by giving
them brief but helpful explanations on why each step was required, and providing visual
and statistical aids to help them in making important decisions. This is while our
more expert users greatly appreciated the amount of control and granularity over the
workflow that our more advanced interface mode offered. Both the underlying tag cleaning
workflow and the interface were designed iteratively in a participatory design process
in collaboration with research on a music recommendation interface based on Last.fm
tags.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2928–2939},
numpages = {12},
keywords = {social tags, visual data analysis, data wrangling, graphical interface, user centred design, data cleaning, folksonomy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025801,
author = {Zhang, Jiawei and Malik, Abish and Ahlbrand, Benjamin and Elmqvist, Niklas and Maciejewski, Ross and Ebert, David S.},
title = {TopoGroups: Context-Preserving Visual Illustration of Multi-Scale Spatial Aggregates},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025801},
doi = {10.1145/3025453.3025801},
abstract = {Spatial datasets, such as tweets in a geographic area, often exhibit different distribution
patterns at multiple levels of scale, such as live updates about events occurring
in very specific locations on the map. Navigating in such multi-scale data-rich spaces
is often inefficient, requires users to choose between overview or detail information,
and does not support identifying spatial patterns at varying scales. In this paper,
we propose TopoGroups, a novel context-preserving technique that aggregates spatial
data into hierarchical clusters to improve exploration and navigation at multiple
spatial scales. The technique uses a boundary distortion algorithm to minimize the
visual clutter caused by overlapping aggregates. Our user study explores multiple
visual encoding strategies for TopoGroups including color, transparency, shading,
and shapes in order to convey the hierarchical and statistical information of the
geographical aggregates at different scales.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2940–2951},
numpages = {12},
keywords = {geospatial visualization, context preservation, multi-scale analysis, social media},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025837,
author = {Feinberg, Melanie},
title = {A Design Perspective on Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025837},
doi = {10.1145/3025453.3025837},
abstract = {Empirical studies invariably show that data generation is situationally contingent
and interpretively flexible, even when data is collected automatically. This essay
situates data generation within a design perspective, demonstrating how data creation
can be understood as a multilayered set of interlocking design activities. By showing
how data is infused with design, this paper argues that any "use" of data represents
a continuation of its design. We are always designers of data, never its mere appropriators.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2952–2963},
numpages = {12},
keywords = {materiality, infrastructure, data, design, metadata},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025878,
author = {Pschetz, Larissa and Tallyn, Ella and Gianni, Rory and Speed, Chris},
title = {Bitbarista: Exploring Perceptions of Data Transactions in the Internet of Things},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025878},
doi = {10.1145/3025453.3025878},
abstract = {We are surrounded by a proliferation of connected devices performing increasingly
complex data transactions. Traditional design methods tend to simplify or conceal
this complexity to improve ease of use. However, the hidden nature of data is causing
increasing discomfort. This paper presents BitBarista, a coffee machine designed to
explore perceptions of data processes in the Internet of Things. BitBarista reveals
social, environmental, qualitative and economic aspects of coffee supply chains. It
allows people to choose a source of future coffee beans, situating their choices within
the pool of decisions previously made. In doing so, it attempts to engage them in
the transactions that are required to produce coffee. Initial studies of BitBarista
with 42 participants reveal challenges of designing for connected systems, particularly
in terms of perceptions of data gathering and sharing, as well as assumptions generated
by current models of consumption. A discussion is followed by a series of suggestions
for increasing positive attitudes towards data use in interactive systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2964–2975},
numpages = {12},
keywords = {data transactions, design, internet of things, privacy, supply chains},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026012,
author = {Krafft, Peter and Zhou, Kaitlyn and Edwards, Isabelle and Starbird, Kate and Spiro, Emma S.},
title = {Centralized, Parallel, and Distributed Information Processing during Collective Sensemaking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026012},
doi = {10.1145/3025453.3026012},
abstract = {Widespread rumoring can hinder attempts to make sense of what is going on during disaster
scenarios. Understanding how and why rumors spread in these contexts could assist
in the design of systems that facilitate timely and accurate sensemaking. We address
a basic question in this line: To what extent does rumor evolution occur (1) through
reliance on a centralized information source, (2) in parallel information silos, or
(3) through a web of complex informational interactions? We develop a conceptual model
and associated analysis algorithms that allow us to distinguish between these possibilities.
We analyze a case of rumoring on Twitter during the Boston Marathon Bombing. We find
that rumor spreading was predominantly a parallel process in this case, which is consistent
with a hypothesis that information silos may underlie the persistence of false rumors.
Special attention towards detecting and resolving parallel information threads during
collective sensemaking may hence be warranted.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2976–2987},
numpages = {12},
keywords = {computational modeling, rumor spreading, twitter, rumoring, social media, sociotechnical systems, computational social science, rumor evolution, collective sensemaking, collective intelligence},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025670,
author = {Lee, Kyung-Ryong and Goh, Geon-il and Park, Young-Woo},
title = {Quietto: An Interactive Timepiece Molded in Concrete and Milled Wood},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025670},
doi = {10.1145/3025453.3025670},
abstract = {We introduce Quietto: an interactive timepiece made of molded concrete and milled
wood. It shows upcoming daily schedules and the time through the quiet, ambient motions
of a clock hand and light through the concrete touch interface. The results of an
in-field user observation of 10 participants over 3 days showed the possibilities
of using concrete as a unique and attractive material for designing a tangible interface
due to its unexpected haptic feeling. We also found that Quietto provides an intuitive
and effective representation of its users' daily schedules and can be used as a private,
personal device. Through its distinctive design, Quietto can provide a new way of
understanding scheduling through its concrete texture and amusing interaction qualities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2988–2992},
numpages = {5},
keywords = {schedule, ambient, interactive timepiece, concrete},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025617,
author = {Yarosh, Svetlana and Zave, Pamela},
title = {Locked or Not? Mental Models of IoT Feature Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025617},
doi = {10.1145/3025453.3025617},
abstract = {Internet of Things (IoT) frequently involves conflicting interactions between devices
and features that must be resolved to a single system state. The problem of feature
interaction (FI) resolution has been investigated in Software Engineering through
approaches that focus on verifiability but usually do not include the user in the
evaluation. This paper bridges the gap between IoT approaches in HCI and Software
Engineering by applying qualitative methods to understanding users' mental models
of one representative FI resolution mechanism. Our contributions are in identifying
common mental model errors and biases and how these may inform future IoT systems
and research.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2993–2997},
numpages = {5},
keywords = {feature interaction, iot, home automation, mental models},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025601,
author = {Karolus, Jakob and Wozniak, Pawe\l{} W. and Chuang, Lewis L. and Schmidt, Albrecht},
title = {Robust Gaze Features for Enabling Language Proficiency Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025601},
doi = {10.1145/3025453.3025601},
abstract = {We are often confronted with information interfaces designed in an unfamiliar language,
especially in an increasingly globalized world, where the language barrier inhibits
interaction with the system. In our work, we explore the design space for building
interfaces that can detect the user's language proficiency. Specifically, we look
at how a user's gaze properties can be used to detect whether the interface is presented
in a language they understand. We report a study (N=21) where participants were presented
with questions in multiple languages, whilst being recorded for gaze behavior. We
identified fixation and blink durations to be effective indicators of the participants'
language proficiencies. Based on these findings, we propose a classification scheme
and technical guidelines for enabling language proficiency awareness on information
displays using gaze data.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2998–3010},
numpages = {13},
keywords = {adaptive interfaces, machine learning, language-aware interfaces, eye-tracking},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025644,
author = {Ding, Yu and Zhang, Yuting and Xiao, Meihua and Deng, Zhigang},
title = {A Multifaceted Study on Eye Contact Based Speaker Identification in Three-Party Conversations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025644},
doi = {10.1145/3025453.3025644},
abstract = {To precisely understand human gaze behaviors in three-party conversations, this work
is dedicated to look into whether the speaker can be reliably identified from the
interlocutors in a three-party conversation on the basis of the interactive behaviors
of eye contact, where speech signals are not provided. Derived from a pre-recorded,
multimodal, and three-party conversational behavior dataset, a statistical framework
is pro- posed to determine who is the speaker from the interactive behaviors of eye
contact. Additionally, with the aid of virtual human technologies, a user study is
conducted to study whether subjects are capable of distinguishing the speaker from
the listeners according to the gaze behaviors of the interlocutors alone. Our results
show that eye contact provides a reliable cue for the identification of the speaker
in three-party conversations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3011–3021},
numpages = {11},
keywords = {multiparty conversation, eye gaze, eye contact, nonverbal behaviors, eye-head coordination, perception of gaze, face-to-face communication, head gestures, human-human interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025920,
author = {Istance, Howell and Hyrskykari, Aulikki I.},
title = {Supporting Making Fixations and the Effect on Gaze Gesture Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025920},
doi = {10.1145/3025453.3025920},
abstract = {Gaze gestures are deliberate patterns of eye movements that can be used to invoke
commands. These are less reliant on accurate measurement and calibration than other
gaze-based interaction techniques. These may be used with wearable displays fitted
with eye tracking capability, or as part of an assistive technology. The visual stimuli
in the information on the display that can act as fixation targets may or may not
be sparse and will vary over time. The paper describes an experiment to investigate
how the amount of information provided on a display to assist making fixations affects
gaze gesture performance. The impact of providing visualization guides and small fixation
targets on the time to complete gestures and error rates is presented. The number
and durations of fixations made during gesture completion is used to explain differences
in performance as a result of practice and direction of eye movement.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3022–3033},
numpages = {12},
keywords = {gaze gestures, gaze gesture performance, fixation duration, fixation targets},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025455,
author = {Schenk, Simon and Dreiser, Marc and Rigoll, Gerhard and Dorr, Michael},
title = {GazeEverywhere: Enabling Gaze-Only User Interaction on an Unmodified Desktop PC in Everyday Scenarios},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025455},
doi = {10.1145/3025453.3025455},
abstract = {Eye tracking is becoming more and more affordable, and thus gaze has the potential
to become a viable input modality for human-computer interaction. We present the GazeEverywhere
solution that can replace the mouse with gaze control by adding a transparent layer
on top of the system GUI. It comprises three parts: i) the SPOCK interaction method
that is based on smooth pursuit eye movements and does not suffer from the Midas touch
problem; ii) an online recalibration algorithm that continuously improves gaze-tracking
accuracy using the SPOCK target projections as reference points; and iii) an optional
hardware setup utilizing head-up display technology to project superimposed dynamic
stimuli onto the PC screen where a software modification of the system is not feasible.
In validation experiments, we show that GazeEverywhere's throughput according to ISO
9241-9 was improved over dwell time based interaction methods and nearly reached trackpad
level. Online recalibration reduced interaction target ('button') size by about 25%.
Finally, a case study showed that users were able to browse the internet and successfully
run Wikirace using gaze only, without any plug-ins or other modifications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3034–3044},
numpages = {11},
keywords = {smooth pursuit, eye tracking, mouse replacement, gaze-based interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026054,
author = {Smith, Wally and Ploderer, Bernd and Wadley, Greg and Webber, Sarah and Borland, Ron},
title = {Trajectories of Engagement and Disengagement with a Story-Based Smoking Cessation App},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026054},
doi = {10.1145/3025453.3026054},
abstract = {Strong user engagement with digital technologies for behaviour change is often taken
as a precursor to their longer-term efficacy. We critically examine this assumption
through a qualitative study of a smoking cessation app, called NewLeaf, which allows
quitters to swap personal stories. The study examined what influenced people to engage
or disengage with NewLeaf, and how the app was deployed in quit attempts during a
four week trial. Several properties of swapped stories were reported to promote engagement,
including: authenticity, currency, contextualization of advice, and evoking a sense
of community. But while the resulting engagement was sometimes productive in supporting
quitting, other trajectories of use were observed involving counterproductive engagement,
and a surprising pattern of productive disengagement especially among stronger quitters.
We discuss how this analysis of different trajectories problematizes any simple interpretation
of user engagement as an early indicator of success for behaviour change technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3045–3056},
numpages = {12},
keywords = {qualitative research, engagement, health behavior change, smoking cessation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025725,
author = {Bhattacharya, Arpita and Vilardaga, Roger and Kientz, Julie A. and Munson, Sean A.},
title = {Lessons from Practice: Designing Tools to Facilitate Individualized Support for Quitting Smoking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025725},
doi = {10.1145/3025453.3025725},
abstract = {Many health care providers, with a variety of trainings, counsel clients on quitting
smoking on a day-to-day basis. In their clinical practice, they draw from and adapt
guidelines and research-based strategies to fit individual client situations and challenges.
Designers of technologies to support quitting smoking can learn from these real world
practices to create tools that better adapt to individual differences. We present
findings from interviews with 28 providers with diverse experiences in smoking cessation
counselling. Through analysis of their individualization strategies, challenges, and
perceptions of technology, we find that providers: (1) individualize context appropriate
coping strategies by involving clients in brainstorming, (2) emphasize the need to
support nicotine withdrawal in clients, (3) mitigate social triggers and mediate social
support for clients, and (4) need to navigate dependencies with other providers for
managing medications and comorbid health conditions of clients. With this empirical
understanding, we extend the discussion on the design of technology to support quitting
smoking, highlight current barriers to individualization, and suggest future opportunities
to address these barriers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3057–3070},
numpages = {14},
keywords = {personalization, smoking cessation, behavior change, health, smoking, counseling practice, individualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026013,
author = {Klasnja, Predrag and Hekler, Eric B. and Korinek, Elizabeth V. and Harlow, John and Mishra, Sonali R.},
title = {Toward Usable Evidence: Optimizing Knowledge Accumulation in HCI Research on Health Behavior Change},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026013},
doi = {10.1145/3025453.3026013},
abstract = {Over the last ten years, HCI researchers have introduced a range of novel ways to
support health behavior change, from glanceable displays to sophisticated game dynamics.
Yet, this research has not had as much impact as its originality warrants. A key reason
for this is that common forms of evaluation used in HCI make it difficult to effectively
accumulate-and use-knowledge across research projects. This paper proposes a strategy
for HCI research on behavior change that retains the field's focus on novel technical
contributions while enabling accumulation of evidence that can increase impact of
individual research projects both in HCI and the broader behavior-change science.
The core of this strategy is an emphasis on the discovery of causal effects of individual
components of behavior-change technologies and the precise ways in which those effects
vary with individual differences, design choices, and contexts in which those technologies
are used.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3071–3082},
numpages = {12},
keywords = {evaluation methods, behavior change, user studies, health informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025501,
author = {Sato, Yuka and Ueoka, Ryoko},
title = {Investigating Haptic Perception of and Physiological Responses to Air Vortex Rings on a User's Cheek},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025501},
doi = {10.1145/3025453.3025501},
abstract = {Haptic perception is one of the primary means of interaction with the world. Recent
research on affective haptics suggests that it can affect emotional and behavioral
responses. In this study, we evaluate user perceptions of haptic stimuli generated
by air vortex rings on the cheek and investigate the effects on their physiological
responses. To develop a cheek haptic display, we investigated and found that the cheek
had enough resolution to perceive the differences in haptic stimuli in a two-point
discrimination threshold test of the face. Additionally, the intensities of the haptic
stimuli for experiments were determined by investigating the subjective impressions
of different stimuli pairs. Finally, we conducted experiments to evaluate quantitatively
the effects of four different combinations of haptic stimuli on the physiological
responses in terms of stress modification, brainwave activities, task performance,
and subjective assessment. The results suggest that different stimuli affect physiological
responses and task performance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3083–3094},
numpages = {12},
keywords = {physiological responses, haptic perception, cheek haptic interface, air vortex rings, subjective impression},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025704,
author = {Weigel, Martin and Nittala, Aditya Shekhar and Olwal, Alex and Steimle, J\"{u}rgen},
title = {SkinMarks: Enabling Interactions on Body Landmarks Using Conformal Skin Electronics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025704},
doi = {10.1145/3025453.3025704},
abstract = {The body provides many recognizable landmarks due to the underlying skeletal structure
and variations in skin texture, elasticity, and color. The visual and spatial cues
of such body landmarks can help in localizing on-body interfaces, guide input on the
body, and allow for easy recall of mappings. Our main contribution are SkinMarks,
novel skin-worn I/O devices for precisely localized input and output on fine body
landmarks. SkinMarks comprise skin electronics on temporary rub-on tattoos. They conform
to fine wrinkles and are compatible with strongly curved and elastic body locations.
We identify five types of body landmarks and demonstrate novel interaction techniques
that leverage SkinMarks' unique touch, squeeze and bend sensing with integrated visual
output. Finally, we detail on the conformality and evaluate sub-millimeter electrodes
for touch sensing. Taken together, SkinMarks expands the on-body interaction space
to more detailed, highly curved and challenging areas on the body.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3095–3105},
numpages = {11},
keywords = {flexible display., on-skin sensing, fabrication, on-skin display, epidermal electronics, on-body interaction, electronic tattoos},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025703,
author = {Je, Seungwoo and Rooney, Brendan and Chan, Liwei and Bianchi, Andrea},
title = {TactoRing: A Skin-Drag Discrete Display},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025703},
doi = {10.1145/3025453.3025703},
abstract = {Smart rings are an emerging wearable technology particularly suitable for discrete
notifications based on haptic cues. Previous work mostly focused on tactile actuators
that stimulate only specific skin receptors on the finger, resulting in limited information
expressiveness. We propose tactoRing, a novel tactile display that, by dragging a
small tactor on the skin around the finger, excites multiple skin areas resulting
in more accurate cue recognition. In this paper, we present the hardware and a perception
study to understand the ability of users to recognize eight distinct points around
the finger. Moreover, we show two different techniques to encode information through
skin-dragging motion with accuracy up to 94%. We finally showcase a set of applications
that, by combining sequences of tactile stimuli, achieve higher expressiveness than
prior methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3106–3114},
numpages = {9},
keywords = {ring, wearable, eyes-free, haptics, skin-drag},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025744,
author = {Schorr, Samuel B. and Okamura, Allison M.},
title = {Fingertip Tactile Devices for Virtual Object Manipulation and Exploration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025744},
doi = {10.1145/3025453.3025744},
abstract = {One of the main barriers to immersivity during object manipulation in virtual reality
is the lack of realistic haptic feedback. Our goal is to convey compelling interactions
with virtual objects, such as grasping, squeezing, pressing, lifting, and stroking,
without requiring a bulky, world-grounded kinesthetic feedback device (traditional
haptics) or the use of predetermined passive objects (haptic retargeting). To achieve
this, we use a pair of finger-mounted haptic feedback devices that deform the skin
on the fingertips to convey cutaneous force information from object manipulation.
We show that users can perceive differences in virtual object weight and that they
apply increasing grasp forces when lifting virtual objects as rendered mass is increased.
Moreover, we show how naive users perceive changes of a virtual object's physical
properties when we use skin deformation to render objects with varying mass, friction,
and stiffness. These studies demonstrate that fingertip skin deformation devices can
provide a compelling haptic experience appropriate for virtual reality scenarios involving
object manipulation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3115–3119},
numpages = {5},
keywords = {mass perception, haptics, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025759,
author = {Strasnick, Evan and Cauchard, Jessica R. and Landay, James A.},
title = {BrushTouch: Exploring an Alternative Tactile Method for Wearable Haptics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025759},
doi = {10.1145/3025453.3025759},
abstract = {Haptic interfaces are ideal in situations where visual/auditory attention is impossible,
unsafe, or socially unacceptable. However, conventional (vibrotactile) wearable interfaces
often possess a limited bandwidth for expressing information. We explore a novel form
of tactile stimulation through brushing, and demonstrate BrushTouch, a wearable prototype
for brushing haptics. We also present schemes for conveying information such as time
and direction through multi-tactor wrist-worn haptic interfaces. To evaluate BrushTouch,
two user studies were run, comparing it to a conventional vibrotactile wristband across
a number of tasks in both lab and mobile conditions. We show that for certain cues
brushing can be more accurately recognized than vibration, enabling more effective
spatial schemes for presenting information through haptic means. We then show that
BrushTouch is capable of greater information transfer using such cues. We believe
that brushing, as with other non-vibrotactile haptic techniques, merits further investigation
as potential vehicles for richer haptic feedback.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3120–3125},
numpages = {6},
keywords = {wearables, wayfinding, vibrotactile, tactile, haptics, brushtouch, brush},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025490,
author = {Vlachokyriakos, Vasillis and Crivellaro, Clara and Wright, Pete and Karamagioli, Evika and Staiou, Eleni-Revekka and Gouscos, Dimitris and Thorpe, Rowan and Kr\"{u}ger, Antonio and Sch\"{o}ning, Johannes and Jones, Matt and Lawson, Shaun and Olivier, Patrick},
title = {HCI, Solidarity Movements and the Solidarity Economy},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025490},
doi = {10.1145/3025453.3025490},
abstract = {The financial crisis and austerity politics in Europe has had a devastating impact
on public services, social security and vulnerable populations. Greek civil society
responded quickly by establishing solidarity structures aimed at helping vulnerable
citizens to meet their basic needs and empower them to co-create an anti-austerity
movement. While digital technology and social media played an important role in the
initiation of the movement, it has a negligible role in the movement's on-going practices.
Through embedded work with several solidarity structures in Greece, we have begun
to understand the "solidarity economy" (SE) as an experiment in direct democracy and
self-organization. Working with a range of solidarity structures we are developing
a vision for a "Solidarity HCI" committed to designing to support personal, social
and institutional transformation through processes of agonistic pluralism and contestation,
where the aims and objectives of the SE are continuously re-formulated and put into
practice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3126–3137},
numpages = {12},
keywords = {digital civics, solidarity economy, social movements},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025667,
author = {Aoki, Paul and Woodruff, Allison and Yellapragada, Baladitya and Willett, Wesley},
title = {Environmental Protection and Agency: Motivations, Capacity, and Goals in Participatory Sensing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025667},
doi = {10.1145/3025453.3025667},
abstract = {In this paper we consider various genres of citizen science from the perspective of
citizen participants. As a mode of scientific inquiry, citizen science has the potential
to "scale up" scientific data collection efforts and increase lay engagement with
science. However, current technological directions risk losing sight of the ways in
which citizen science is actually practiced. As citizen science is increasingly used
to describe a wide range of activities, we begin by presenting a framework of citizen
science genres. We then present findings from four interlocking qualitative studies
and technological interventions of community air quality monitoring efforts, examining
the motivations and capacities of citizen participants and characterizing their alignment
with different types of citizen science. Based on these studies, we suggest that data
acquisition involves complex multi-dimensional tradeoffs, and the commonly held view
that citizen science systems are a win-win for citizens and science may be overstated.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3138–3150},
numpages = {13},
keywords = {environmental sensing, citizen science},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025627,
author = {Chauhan, Apoorva and Hughes, Amanda L.},
title = {Providing Online Crisis Information: An Analysis of Official Sources during the 2014 Carlton Complex Wildfire},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025627},
doi = {10.1145/3025453.3025627},
abstract = {Using the 2014 Carlton Complex Wildfire as a case study, we examine who contributes
official information online during a crisis event, and the timeliness and relevance
of the information provided. We identify and describe the communication behaviors
of four types of official information sources (Event Based Resources, Local Responders,
Local News Media, and Cooperating Agencies), and collect message data from each source's
website, public Facebook page, and/or Twitter account. The data show that the Local
News Media provided the highest quantity of relevant information and the timeliest
information. Event Based Resources shared the highest percentage of relevant information,
however, it was often unclear who managed these resources and the credibility of the
information. Based on these findings, we offer suggestions for how providers of official
crisis information might better manage their online communications and ways that the
public can find more timely and relevant online crisis information from official sources.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3151–3162},
numpages = {12},
keywords = {wildfire, social media, social computing, risk communication, crisis informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025659,
author = {DeVito, Michael A. and Gergle, Darren and Birnholtz, Jeremy},
title = {"Algorithms Ruin Everything": #RIPTwitter, Folk Theories, and Resistance to Algorithmic Change in Social Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025659},
doi = {10.1145/3025453.3025659},
abstract = {As algorithmically-driven content curation has become an increasingly common feature
of social media platforms, user resistance to algorithmic change has become more frequent
and visible. These incidents of user backlash point to larger issues such as inaccurate
understandings of how algorithmic systems work as well as mismatches between designer
and user intent. Using a content analysis of 102,827 tweets from #RIPTwitter, a recent
hashtag-based backlash to rumors about introducing algorithmic curation to Twitter's
timeline, this study addresses the nature of user resistance in the form of the complaints
being expressed, folk theories of the algorithmic system espoused by users, and how
these folk theories potentially frame user reactions. We find that resistance to algorithmic
change largely revolves around expectation violation, with folk theories acting as
frames for reactions such that more detailed folk theories are expressed through more
specific reactions to algorithmic change.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3163–3174},
numpages = {12},
keywords = {expectation violation, user resistance, social media, folk theories, machine classification, algorithm awareness, technology continuance, algorithmic curation, algorithms},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026018,
author = {Chandrasekharan, Eshwar and Samory, Mattia and Srinivasan, Anirudh and Gilbert, Eric},
title = {The Bag of Communities: Identifying Abusive Behavior Online with Preexisting Internet Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026018},
doi = {10.1145/3025453.3026018},
abstract = {Since its earliest days, harassment and abuse have plagued the Internet. Recent research
has focused on in-domain methods to detect abusive content and faces several challenges,
most notably the need to obtain large training corpora. In this paper, we introduce
a novel computational approach to address this problem called Bag of Communities (BoC)---a
technique that leverages large-scale, preexisting data from other Internet communities.
We then apply BoC toward identifying abusive behavior within a major Internet community.
Specifically, we compute a post's similarity to 9 other communities from 4chan, Reddit,
Voat and MetaFilter. We show that a BoC model can be used on communities "off the
shelf" with roughly 75% accuracy---no training examples are needed from the target
community. A dynamic BoC model achieves 91.18% accuracy after seeing 100,000 human-moderated
posts, and uniformly outperforms in-domain methods. Using this conceptual and empirical
work, we argue that the BoC approach may allow communities to deal with a range of
common problems, like abusive behavior, faster and with fewer engineering resources.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3175–3187},
numpages = {13},
keywords = {abusive behavior, machine learning, moderation, online communities, social computing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025631,
author = {Adar, Eytan and Gearig, Carolyn and Balasubramanian, Ayshwarya and Hullman, Jessica},
title = {PersaLog: Personalization of News Article Content},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025631},
doi = {10.1145/3025453.3025631},
abstract = {Content personalization automatically modifying text and multimedia features within
articles based on the reader's individual features'is evolving as a new form of journalism.
Informed by constraints articulated through a survey of journalists, we have implemented
PersaLog, a novel system for creating personalized content (e.g., text and interactive
visualizations). Because crafting, and validating, personalized content can be challenging
to scale across articles (unlike feed personalization), we offer a simple Domain Specific
Language (DSL), and editing environment, to support this task. PersaLog is particularly
designed to support the personalization of existing text and visualizations. Our work
provides guidelines for personalization as well as a system that allows for both subtle
and dramatic personalization-driven content changes. We validate PersaLog using case
and lab studies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3188–3200},
numpages = {13},
keywords = {personalized content, news personalization, guidelines},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026011,
author = {Jahanbakhsh, Farnaz and Fu, Wai-Tat and Karahalios, Karrie and Marinov, Darko and Bailey, Brian},
title = {You Want Me to Work with <i>Who</i>? Stakeholder Perceptions of Automated Team Formation in Project-Based Courses},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026011},
doi = {10.1145/3025453.3026011},
abstract = {Instructors are increasingly using algorithmic tools for team formation, yet little
is known about how these tools are applied or how students and instructors perceive
their use. We studied a representative team formation tool (CATME) in eight project-based
courses. An instructor uses the tool to form teams by surveying students' working
styles, skills, and demographics; then configuring these criteria as input into an
algorithm that assigns teams. We surveyed students (N=277) in the courses to gauge
their perceptions of the strengths and weaknesses of the tool and ideas for improving
it. We also interviewed instructors (N=13) different from those who taught the eight
courses to learn about their criteria selections and perceptions of the tool. Students
valued the rational basis for forming teams but desired a stronger voice in criteria
selection and explanations as to why they were assigned to a particular team. Instructors
appreciated the efficiency of team formation but wanted to view exemplars of criteria
used in similar courses. This work contributes recommendations for deploying team
formation tools in educational settings and for better satisfying the goals of all
stakeholders.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3201–3212},
numpages = {12},
keywords = {catme, education, algorithms, team formation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025985,
author = {Chancellor, Stevie and Kalantidis, Yannis and Pater, Jessica A. and De Choudhury, Munmun and Shamma, David A.},
title = {Multimodal Classification of Moderated Online Pro-Eating Disorder Content},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025985},
doi = {10.1145/3025453.3025985},
abstract = {Social media sites are challenged by both the scale and variety of deviant behavior
online. While algorithms can detect spam and obscenity, behaviors that break community
guidelines on some sites are difficult because they have multimodal subtleties (images
and/or text). Identifying these posts is often regulated to a few moderators. In this
paper, we develop a deep learning classifier that jointly models textual and visual
characteristics of pro-eating disorder content that violates community guidelines.
Using a million Tumblr photo posts, our classifier discovers deviant content efficiently
while also maintaining high recall (85%). Our approach uses human sensitivity throughout
to guide the creation, curation, and understanding of this approach to challenging,
deviant content. We discuss how automation might impact community moderation, and
the ethical and social obligations of this area.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3213–3226},
numpages = {14},
keywords = {computer vision, content moderation, tumblr, pro-eating disorder, deep learning, social media, deviant behavior},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025664,
author = {Xia, Haijun and Hinckley, Ken and Pahud, Michel and Tu, Xiao and Buxton, Bill},
title = {<i>WritLarge</i>: Ink Unleashed by Unified Scope, Action, &amp; Zoom},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025664},
doi = {10.1145/3025453.3025664},
abstract = {WritLarge is a freeform canvas for early-stage design on electronic whiteboards with
pen+touch input. The system aims to support a higher-level flow of interaction by 'chunking' the traditionally disjoint steps of selection and action into unified selection-action
phrases. This holistic goal led us to address two complementary aspects: SELECTION,
for which we devise a new technique known as the Zoom-Catcher that integrates pinch-to-zoom
and selection in a single gesture for fluidly selecting and acting on content; plus:
ACTION, where we demonstrate how this addresses the combined issues of navigating,
selecting, and manipulating content. In particular, the designer can transform select
ink strokes in flexible and easily-reversible representations via semantic, structural,
and temporal axes of movement that are defined as conceptual 'moves' relative to the
specified content.This approach dovetails zooming with lightweight specification of
scope as well as the evocation of context-appropriate commands, at-hand, in a location-independent
manner. This establishes powerful new primitives that can help to scaffold higher-level
tasks, thereby unleashing the expressive power of ink in a compelling manner.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3227–3240},
numpages = {14},
keywords = {pen+touch, electronic whiteboard, bimanual input, toolglass},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025716,
author = {Riche, Yann and Henry Riche, Nathalie and Hinckley, Ken and Panabaker, Sheri and Fuelling, Sarah and Williams, Sarah},
title = {As We May Ink? Learning from Everyday Analog Pen Use to Improve Digital Ink Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025716},
doi = {10.1145/3025453.3025716},
abstract = {This paper sheds light on gaps and discrepancies between the experiences afforded
by analog pens and their digital counterparts. Despite the long history (and recent
renaissance) of digital pens, the literature still lacks a comprehensive survey of
what types of marks people make and what motivates them to use ink-both analog and
digital in daily life. To capture the diversity of inking behaviors and tease out
the unique affordances of pen-and ink, we conducted a diary study with 26 participants
from diverse backgrounds. From analysis of 493 diary entries we identified 8 analog
pen-and-ink activities, and 9 affordances of pens. We contextualized and contrasted
these findings using a survey with 1,633 respondents and a follow-up diary study with
30 participants, observing digital pens. Our analysis reveals gaps and research opportunities
based on pen affordances not yet fully explored in the literature.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3241–3253},
numpages = {13},
keywords = {pen interaction, diary studies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025567,
author = {Pfeuffer, Ken and Hinckley, Ken and Pahud, Michel and Buxton, Bill},
title = {Thumb + Pen Interaction on Tablets},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025567},
doi = {10.1145/3025453.3025567},
abstract = {Modern tablets support simultaneous pen and touch input, but it remains unclear how
to best leverage this capability for bimanual input when the nonpreferred hand holds
the tablet. We explore Thumb + Pen interactions that support simultaneous pen and
touch interaction, with both hands, in such situations. Our approach engages the thumb
of the device-holding hand, such that the thumb interacts with the touch screen in
an indirect manner, thereby complementing the direct input provided by the preferred
hand. For instance, the thumb can determine how pen actions (articulated with the
opposite hand) are interpreted. Alternatively, the pen can point at an object, while
the thumb manipulates one or more of its parameters through indirect touch. Our techniques
integrate concepts in a novel way that derive from marking menus, spring-loaded modes,
indirect input, and multi-touch conventions. Our overall approach takes the form of
a set of probes, each representing a meaningfully distinct class of application. They
serve as an initial exploration of the design space at a level which will help determine
the feasibility of supporting bimanual interaction in such contexts, and the viability
of the Thumb + Pen techniques in so doing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3254–3266},
numpages = {13},
keywords = {pen+touch, bimanual input, postures of use, tablet, thumb},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025865,
author = {Surale, Hemant Bhaskar and Matulic, Fabrice and Vogel, Daniel},
title = {Experimental Analysis of Mode Switching Techniques in Touch-Based User Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025865},
doi = {10.1145/3025453.3025865},
abstract = {This paper presents the results of a 36 participant empirical comparison of touch
mode-switching. Six techniques are evaluated, spanning current and future techniques:
long press, non-dominant hand, two-fingers, hard press, knuckle, and thumb-on-finger.
Two poses are controlled for, seated with the tablet on a desk and standing with the
tablet held on the forearm. Findings indicate pose has no effect on mode switching
time and little effect on error rate; using two-fingers is fastest while long press
is much slower; non-preferred hand and thumb-on-finger also rate highly in subjective
scores. The experiment protocol is based on Li et al.'s pen mode-switching study,
enabling a comparison of touch and pen mode switching. Among the common techniques,
the non-dominant hand is faster than pressure with touch, whereas no significant difference
had been found for pen. Our work addresses the lack of empirical evidence comparing
touch mode-switching techniques and provides guidance to practitioners when choosing
techniques and to researchers when designing new mode-switching methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3267–3280},
numpages = {14},
keywords = {mode switching, multi-touch, touch input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025605,
author = {Antoine, Axel and Malacria, Sylvain and Casiez, G\'{e}ry},
title = {ForceEdge: Controlling Autoscroll on Both Desktop and Mobile Computers Using the Force},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025605},
doi = {10.1145/3025453.3025605},
abstract = {Operating systems support autoscroll to allow users to scroll a view while in dragging
mode: the user moves the pointer near the window's edge to trigger an "automatic"
scrolling whose rate is typically proportional to the distance between the pointer
and the window's edge. This approach suffers from several problems, especially when
the window is maximized, resulting in a very limited space around it. Another problem
is that for some operations, such as object drag-and-drop, the source and destination
might be located in different windows, making it complicated for the computer to understand
user's intention. In this paper, we present ForceEdge, a novel autoscroll technique
relying on touch surfaces with force-sensing capabilities to alleviate the problems
related to autoscroll. We report on the results of three controlled experiments showing
that it improves over macOS and iOS systems baselines for top-to-bottom select and
move tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3281–3292},
numpages = {12},
keywords = {autoscroll, touchscreen, force control, trackpad, scrolling},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025808,
author = {Grosse-Puppendahl, Tobias and Holz, Christian and Cohn, Gabe and Wimmer, Raphael and Bechtold, Oskar and Hodges, Steve and Reynolds, Matthew S. and Smith, Joshua R.},
title = {Finding Common Ground: A Survey of Capacitive Sensing in Human-Computer Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025808},
doi = {10.1145/3025453.3025808},
abstract = {For more than two decades, capacitive sensing has played a prominent role in human-computer
interaction research. Capacitive sensing has become ubiquitous on mobile, wearable,
and stationary devices - enabling fundamentally new interaction techniques on, above,
and around them. The research community has also enabled human position estimation
and whole-body gestural interaction in instrumented environments. However, the broad
field of capacitive sensing research has become fragmented by different approaches
and terminology used across the various domains. This paper strives to unify the field
by advocating consistent terminology and proposing a new taxonomy to classify capacitive
sensing approaches. Our extensive survey provides an analysis and review of past research
and identifies challenges for future work. We aim to create a common understanding
within the field of human-computer interaction, for researchers and practitioners
alike, and to stimulate and facilitate future research in capacitive sensing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3293–3315},
numpages = {23},
keywords = {electric field sensing, capacitive sensing, survey},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025829,
author = {Nishida, Jun and Suzuki, Kenji},
title = {BioSync: A Paired Wearable Device for Blending Kinesthetic Experience},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025829},
doi = {10.1145/3025453.3025829},
abstract = {We present a novel, paired, wearable system for combining the kinesthetic experiences
of two persons. These devices allow users to sense and combine muscle contraction
and joint rigidity bi-directionally. This is achieved through kinesthetic channels
based on electromyogram (EMG) measurement and electrical muscle stimulation (EMS).
We developed a pair of wearable kinesthetic input-output (I/O) devices called bioSync
that uses specially designed electrodes to perform biosignal measurement and stimulation
simultaneously on the same electrodes.In a user study, participants successfully evaluated
the strength of their partners' muscle contractions while exerting their own muscles.
We confirmed that the pair of devices could help participants synchronize their hand
movements through tapping, without visual and auditory feedback. The proposed interpersonal
kinesthetic communication system can be used to enhance interactions such as clinical
gait rehabilitation and sports training, and facilitate sharing of physical experiences
with Parkinson's patients, thereby enhancing understanding of the physical challenges
they face in daily life.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3316–3327},
numpages = {12},
keywords = {electromyogram signals, rehabilitation, blending kinesthetic experience, electrical muscle stimulation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025523,
author = {Jang, Sujin and Stuerzlinger, Wolfgang and Ambike, Satyajit and Ramani, Karthik},
title = {Modeling Cumulative Arm Fatigue in Mid-Air Interaction Based on Perceived Exertion and Kinetics of Arm Motion},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025523},
doi = {10.1145/3025453.3025523},
abstract = {Quantifying cumulative arm muscle fatigue is a critical factor in understanding, evaluating,
and optimizing user experience during prolonged mid-air interaction. A reasonably
accurate estimation of fatigue requires an estimate of an individual's strength. However,
there is no easy-to-access method to measure individual strength to accommodate inter-individual
differences. Furthermore, fatigue is influenced by both psychological and physiological
factors, but no current HCI model provides good estimates of cumulative subjective
fatigue. We present a new, simple method to estimate the maximum shoulder torque through
a mid-air pointing task, which agrees with direct strength measurements. We then introduce
a cumulative fatigue model informed by subjective and biomechanical measures. We evaluate
the performance of the model in estimating cumulative subjective fatigue in mid-air
interaction by performing multiple cross-validations and a comparison with an existing
fatigue metric. Finally, we discuss the potential of our approach for real-time evaluation
of subjective fatigue as well as future challenges.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3328–3339},
numpages = {12},
keywords = {perceived exertion, cumulative fatigue model, biomechanical arm model, mid-air interaction, maximum arm strength},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025532,
author = {Karusala, Naveena and Kumar, Neha},
title = {Women's Safety in Public Spaces: Examining the Efficacy of Panic Buttons in New Delhi},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025532},
doi = {10.1145/3025453.3025532},
abstract = {We present a qualitative inquiry through the lens of feminist Human-Computer Interaction
(HCI) into women's perceptions of personal safety in New Delhi, India. Since a brutal
gang-rape incident took place in Delhi in December 2012 and received global attention,
women's safety has been the focus of much attention India-wide. In April 2016, the
Indian government issued a mandate that all mobile phones sold in India 2017 onwards
must include a panic button for women's safety. We draw on interview and survey data
to examine women's responses to the mandate, also investigating what factors influence
their perceptions of safety, positively and negatively. Our findings indicate that
women's sense of safety may be deconstructed into a multitude of factors--personal,
public, social, technological--that must align for this sense of safety to be preserved.
We then discuss the implications these factors have for the success and (re-)design
of the panic button and similar interventions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3340–3351},
numpages = {12},
keywords = {hci4d, india, gender, feminist hci, safety},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025615,
author = {Strohmayer, Angelika and Laing, Mary and Comber, Rob},
title = {Technologies and Social Justice Outcomes in Sex Work Charities: Fighting Stigma, Saving Lives},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025615},
doi = {10.1145/3025453.3025615},
abstract = {Sex workers' rights are human rights, and as such are an issue inherently based in
social, criminal, and political justice debates. As HCI continues to move towards
feminist and social justice oriented research and design approaches, we argue that
we need to take into consideration the difficulties faced by sex workers; and explore
how technology can and does mediate social justice outcomes for them. We contribute
directly to this challenge by providing an empirical account of a charity whose work
is built on the underlying move towards social and criminal justice for sex workers
in the UK. Through ethnographic fieldwork, meetings, interviews, surveys, and creative
workshops we describe the different points of view associated with the charity from
a variety of stakeholders. We discuss their service provision and the ways in which
HCI is uniquely positioned to be able respond to the needs of and to support sex work
support services.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3352–3364},
numpages = {13},
keywords = {social justice, feminist hci, activism, ethnography, sex work, charities},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025884,
author = {Lee, Min Kyung and Kim, Ji Tae and Lizarondo, Leah},
title = {A Human-Centered Approach to Algorithmic Services: Considerations for Fair and Motivating Smart Community Service Management That Allocates Donations to Non-Profit Organizations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025884},
doi = {10.1145/3025453.3025884},
abstract = {Algorithms are increasingly being incorporated into diverse services that orchestrate
multiple stakeholders' needs and interests. How can we design these algorithmic services
to make decisions that are not only efficient, but also fair and motivating? We take
a human-centered approach to identify and address challenges in building human-centered
algorithmic services. We are in the process of building an allocation algorithm for
412 Food Rescue, an organization that matches food donations with non-profit organizations.
As part of this ongoing project, we conducted interviews with multiple stakeholders
in the service-organization staff, donors, volunteers, recipient non-profits and their
clients, and everyday citizens-in order to understand how the allocation algorithm,
interfaces, and surrounding work practices should be designed. The findings suggest
that we need to understand and account for varying fairness notions held by stakeholders;
consider people, contexts, and interfaces for algorithms to work fairly in the real
world; and preserve meaningfulness and social interaction in automation in order to
build fair and motivating algorithmic services.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3365–3376},
numpages = {12},
keywords = {allocation, automation, community service, donation, motivation, fairness, algorithmic services, service design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025921,
author = {Rho, Eugenia Ha Rim and Haimson, Oliver L. and Andalibi, Nazanin and Mazmanian, Melissa and Hayes, Gillian R.},
title = {Class Confessions: Restorative Properties in Online Experiences of Socioeconomic Stigma},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025921},
doi = {10.1145/3025453.3025921},
abstract = {In this paper, we examine stigma related to class identity online through an empirical
examination of Elite University Class Confessions (EUCC). EUCC is an online space
that includes a Facebook page and a surrounding sociotechnical ecosystem. It is a
community of, for, and about low-income and first generation students at an elite
university. By bringing in a community that learns and engages with users' socioeconomic
struggles, EUCC engenders unique restorative properties for students experiencing
class stigma. EUCC's restorative properties foster new ways of understanding one's
stigmatized identity through meaning- making interactions in a networked sociotechnical
system. We discuss how EUCC's design shapes the nature of user interactions around
class stigma, and explore in depth how people experience stigma differently through
the restorative properties of EUCC.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3377–3389},
numpages = {13},
keywords = {restorative properties, stigma, low-ses, social networking sites, low-income, networked publics, identity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@dataset{10.1145/review-3025453.3025921_R53502,
author = {Ruzic, Fjodor J.},
title = {Review ID:R53502 for DOI: 10.1145/3025453.3025921},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-3025453.3025921_R53502}
}

@inproceedings{10.1145/3025453.3025990,
author = {Waern, Annika and Back, Jon},
title = {Activity as the Ultimate Particular of Interaction Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025990},
doi = {10.1145/3025453.3025990},
abstract = {In the turn towards practice-oriented research in interaction design, one of the most
important proposals has been the emphasis on the 'ultimate particulars' produced by
design, as embodiments of design knowledge. In current HCI research, those particulars
are almost always taken to be 'things' artefacts or singular systems. We argue that
this emphasis may have come at a cost that can be described as a loss of identity;
interaction design research was never primarily concerned with the design of artefacts,
but with how humans act and interact with each other with and through artefacts. We
propose a complementary perspective by looking at design projects and traditions where
the 'ultimate particulars' can be considered to be activities rather than things.
The article is concerned with how knowledge needs to be articulated in the scholarly
engagement with such design practices. We argue that engagement with activity-centric
design gets design research one step closer towards understanding salient contemporary
design practices and what Buchanan calls 'environmental design'.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3390–3402},
numpages = {13},
keywords = {ultimate particular, research through design, environmental design, activity-centric design, third wave hci, second order design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025534,
author = {Faste, Haakon},
title = {Intuition in Design: Reflections on the Iterative Aesthetics of Form},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025534},
doi = {10.1145/3025453.3025534},
abstract = {Curious to reflect on the factors contributing to the internal decision-making processes
of intuitive design, a reflective study was established to systematically examine
and document the practice of intuition while performing an iterative aesthetic task.
Autoethnographic techniques were used to document the reflective practices that occurred
over numerous iterations spanning several weeks of activity. Our analysis concludes
with a summary of reflections on how intuition informs judgment in design cognition.
We examine four dimensions of intuition in design - efficiency, inspiration, curiosity,
and insight - and the reflective and sensory inputs that drive intuitive speculation
and impulse.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3403–3413},
numpages = {11},
keywords = {self-reflection, design, decision-making, intuition, iteration},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025598,
author = {Williamson, Julie R. and Williamson, John},
title = {Understanding Public Evaluation: Quantifying Experimenter Intervention},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025598},
doi = {10.1145/3025453.3025598},
abstract = {Public evaluations are popular because some research questions can only be answered
by turning "to the wild." Different approaches place experimenters in different roles
during deployment, which has implications for the kinds of data that can be collected
and the potential bias introduced by the experimenter. This paper expands our understanding
of how experimenter roles impact public evaluations and provides an empirical basis
to consider different evaluation approaches. We completed an evaluation of a playful
gesture-controlled display not to understand interaction at the display but to compare
different evaluation approaches. The conditions placed the experimenter in three roles,
steward observer, overt observer, and covert observer, to measure the effect of experimenter
presence and analyse the strengths and weaknesses of each approach.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3414–3425},
numpages = {12},
keywords = {public displays, public evaluation, in the wild methods},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025798,
author = {M\"{a}kel\"{a}, Ville and Sharma, Sumita and Hakulinen, Jaakko and Heimonen, Tomi and Turunen, Markku},
title = {Challenges in Public Display Deployments: A Taxonomy of External Factors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025798},
doi = {10.1145/3025453.3025798},
abstract = {Public display deployments are often subjected to various surprising and unwanted
effects. These effects are frequently due to external factors properties and phenomena
that are unrelated to the deployment. Therefore, we conducted a literature review
within the public display domain to investigate the causes behind the reported issues.
This work presents a taxonomy of external factors affecting deployments, consisting
of six categories: weather, events, surroundings, space, inhabitants, and vandalism.
Apart from a few positive examples, we predominantly found negative effects arising
from these factors. We then identified four ways of addressing the effects: ignoring,
adapting, solving, and embracing. Of these, ignoring and adapting are substantially
more frequent responses than solving and embracing emphasizing the need for researchers
to adapt. We present real-world examples and insights on how researchers and practitioners
can address the effects to better manage their deployments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3426–3475},
numpages = {50},
keywords = {pervasive displays, literature review, public displays, deployments, external factors, taxonomy, challenges},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025919,
author = {Candello, Heloisa and Pinhanez, Claudio and Figueiredo, Flavio},
title = {Typefaces and the Perception of Humanness in Natural Language Chatbots},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025919},
doi = {10.1145/3025453.3025919},
abstract = {How much do visual aspects influence the perception of users about whether they are
conversing with a human being or a machine in a mobile-chat environment? This paper
describes a study on the influence of typefaces using a blind Turing test-inspired
approach. The study consisted of two user experiments. First, three different typefaces
(OCR, Georgia, Helvetica) and three neutral dialogues between a human and a financial
adviser were shown to participants. The second experiment applied the same study design
but OCR font was substituted by Bradley font. For each of our two independent experiments,
participants were shown three dialogue transcriptions and three typefaces counterbalanced.
For each dialogue typeface pair, participants had to classify adviser conversations
as human or chatbot-like. The results showed that machine-like typefaces biased users
towards perceiving the adviser as machines but, unexpectedly, handwritten-like typefaces
had not the opposite effect. Those effects were, however, influenced by the familiarity
of the user to artificial intelligence and other participants' characteristics.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3476–3487},
numpages = {12},
keywords = {user experience, typography, dialogue systems, chatbots},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025830,
author = {Long, Kiel and Vines, John and Sutton, Selina and Brooker, Phillip and Feltwell, Tom and Kirman, Ben and Barnett, Julie and Lawson, Shaun},
title = {"Could You Define That in Bot Terms"? Requesting, Creating and Using Bots on Reddit},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025830},
doi = {10.1145/3025453.3025830},
abstract = {Bots are estimated to account for well over half of all web traffic, yet they remain
an understudied topic in HCI. In this paper we present the findings of an analysis
of 2284 submissions across three discussion groups dedicated to the request, creation
and discussion of bots on Reddit. We set out to examine the qualities and functionalities
of bots and the practical and social challenges surrounding their creation and use.
Our findings highlight the prevalence of misunderstandings around the capabilities
of bots, misalignments in discourse between novices who request and more expert members
who create them, and the prevalence of requests that are deemed to be inappropriate
for the Reddit community. In discussing our findings, we suggest future directions
for the design and development of tools that support more carefully guided and reflective
approaches to bot development for novices, and tools to support exploring the consequences
of contextually-inappropriate bot ideas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3488–3500},
numpages = {13},
keywords = {online communities, co-creation, bots, Reddit},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025649,
author = {Komatsu, Takanori and Kobayashi, Kazuki and Yamada, Seiji and Funakoshi, Kotaro and Nakano, Mikio},
title = {Response Times When Interpreting Artificial Subtle Expressions Are Shorter than with Human-like Speech Sounds},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025649},
doi = {10.1145/3025453.3025649},
abstract = {Artificial subtle expressions (ASEs) are machine-like expressions used to convey a
system's confidence level to users intuitively. In this paper, we focus on the cognitive
loads of users in interpreting ASEs in this study. Specifically, we assume that a
shorter response time indicates less cognitive load, and we hypothesize that users
will show a shorter response time when interpreting ASEs compared with speech sounds.
We succeeded in verifying our hypothesis in a web-based investigation done to comprehend
participants' cognitive loads by measuring their response times in interpreting ASEs
and speeches.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3501–3505},
numpages = {5},
keywords = {response time, speech, cognitive loads, artificial subtle expressions (ases)},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025496,
author = {Xu, Anbang and Liu, Zhe and Guo, Yufan and Sinha, Vibha and Akkiraju, Rama},
title = {A New Chatbot for Customer Service on Social Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025496},
doi = {10.1145/3025453.3025496},
abstract = {Users are rapidly turning to social media to request and receive customer service;
however, a majority of these requests were not addressed timely or even not addressed
at all. To overcome the problem, we create a new conversational system to automatically
generate responses for users requests on social media. Our system is integrated with
state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations
between users and agents from over 60 brands. The evaluation reveals that over 40%
of the requests are emotional, and the system is about as good as human agents in
showing empathy to help users cope with emotional situations. Results also show our
system outperforms information retrieval system based on both human judgments and
an automatic evaluation metric.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3506–3510},
numpages = {5},
keywords = {customer service, deep learning, social media, chatbot},
location = {Denver, Colorado, USA},
series = {CHI '17}
}


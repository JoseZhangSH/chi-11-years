@inbook{10.1145/3290605.3300675,
author = {Leonardi, Nicola and Manca, Marco and Patern\`{o}, Fabio and Santoro, Carmen},
title = {Trigger-Action Programming for Personalising Humanoid Robot Behaviour},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300675},
abstract = {In the coming years humanoid robots will be increasingly used in a variety of contexts,
thereby presenting many opportunities to exploit their capabilities in terms of what
they can sense and do. One main challenge is to design technologies that enable those
who are not programming experts to personalize robot behaviour. We propose an end
user development solution based on trigger-action personalization rules. We describe
how it supports editing such rules and its underlying software architecture, and report
on a user test that involved end user developers. The test results show that users
were able to perform the robot personalization tasks with limited effort, and found
the trigger-action environment usable and suitable for the proposed tasks. Overall,
we show the potential for using trigger-action programming to make robot behaviour
personalization possible even to people who are not professional software developers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300676,
author = {Lilija, Klemen and Pohl, Henning and Boring, Sebastian and Hornb\ae{}k, Kasper},
title = {Augmented Reality Views for Occluded Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300676},
abstract = {We rely on our sight when manipulating objects. When objects are occluded, manipulation
becomes difficult. Such occluded objects can be shown via augmented reality to re-enable
visual guidance. However, it is unclear how to do so to best support object manipulation.
We compare four views of occluded objects and their effect on performance and satisfaction
across a set of everyday manipulation tasks of varying complexity. The best performing
views were a see-through view and a displaced 3D view. The former enabled participants
to observe the manipulated object through the occluder, while the latter showed the
3D view of the manipulated object offset from the object's real location. The worst
performing view showed remote imagery from a simulated hand-mounted camera. Our results
suggest that alignment of virtual objects with their real-world location is less important
than an appropriate point-of-view and view stability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300677,
author = {Williams, Randi and Park, Hae Won and Breazeal, Cynthia},
title = {A is for Artificial Intelligence: The Impact of Artificial Intelligence Activities on Young Children's Perceptions of Robots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300677},
abstract = {We developed a novel early childhood artificial intelligence (AI) platform, PopBots,
where preschool children train and interact with social robots to learn three AI concepts:
knowledge-based systems, supervised machine learning, and generative AI. We evaluated
how much children learned by using AI assessments we developed for each activity.
The median score on the cumulative assessment was 70% and children understood knowledge-based
systems the best. Then, we analyzed the impact of the activities on children's perceptions
of robots. Younger children came to see robots as toys that were smarter than them,
but their older counterparts saw them more as people that were not as smart as them.
Children who performed worse on the AI assessments believed that robots were like
toys that were not as smart as them, however children who did better on the assessments
saw robots as people who were smarter than them. We believe early AI education can
empower children to understand the AI devices that are increasingly in their lives.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300678,
author = {Zhu, Suwen and Zheng, Jingjie and Zhai, Shumin and Bi, Xiaojun},
title = {I'sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300678},
abstract = {Entering text without having to pay attention to the keyboard is compelling but challenging
due to the lack of visual guidance. We propose i'sFree to enable eyes-free gesture
typing on a distant display from a touch-enabled remote control. i'sFree does not
display the keyboard or gesture trace but decodes gestures drawn on the remote control
into text according to an invisible and shifting Qwerty layout. i'sFree decodes gestures
similar to a general gesture typing decoder, but learns from the instantaneous and
historical input gestures to dynamically adjust the keyboard location. We designed
it based on the understanding of how users perform eyes-free gesture typing. Our evaluation
shows eyes-free gesture typing is feasible: reducing visual guidance on the distant
display hardly affects the typing speed. Results also show that the i'sFree gesture
decoding algorithm is effective, enabling an input speed of 23 WPM, 46% faster than
the baseline eyes-free condition built on a general gesture decoder. Finally, i'sFree
is easy to learn: participants reached 22 WPM in the first ten minutes, even though
40% of them were first-time gesture typing users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300679,
author = {Yuan, Ye and Yarosh, Svetlana},
title = {Beyond Tutoring: Opportunities for Intergenerational Mentorship at a Community Level},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300679},
abstract = {Community intergenerational mentorship offers an opportunity to address older adults'
social isolation while providing valuable one-on-one or small group learning experiences
for elementary school students. Current organizations that support this kind of engagement
focus on in-person visits that place the burden of logistics and transportation on
the older adult. However, as older adults become less independent while aging, coming
to schools in person becomes more challenging. We present a qualitative analysis of
current intergenerational mentorship practices to understand opportunities for technology
to expand access to this experience. We highlight elements critical for building successful
mentorship: the importance of relationship building between older adults and children
during mentoring activities, the skills mentors acquired to carry out mentoring activities,
and support needed from teachers and schools. We contribute a rich description of
current intergenerational mentorship practices and provide insights for opportunities
for novel HCI technologies in this context.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300680,
author = {Seering, Joseph and Luria, Michal and Kaufman, Geoff and Hammer, Jessica},
title = {Beyond Dyadic Interactions: Considering Chatbots as Community Members},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300680},
abstract = {Chatbots have grown as a space for research and development in recent years due both
to the realization of their commercial potential and to advancements in language processing
that have facilitated more natural conversations. However, nearly all chatbots to
date have been designed for dyadic, one-on-one communication with users. In this paper
we present a comprehensive review of research on chatbots supplemented by a review
of commercial and independent chatbots. We argue that chatbots' social roles and conversational
capabilities beyond dyadic interactions have been underexplored, and that expansion
into this design space could support richer social interactions in online communities
and help address the longstanding challenges of maintaining, moderating, and growing
these communities. In order to identify opportunities beyond dyadic interactions,
we used research-through-design methods to generate more than 400 concepts for new
social chatbots, and we present seven categories that emerged from analysis of these
ideas.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300681,
author = {Dole, Lorin and Ju, Wendy},
title = {Face and Ecological Validity in Simulations: Lessons from Search-and-Rescue HRI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300681},
abstract = {In fields where in situ performance cannot be measured, ecological validity is difficult
to estimate. Drawing on theory from social psychology and virtual reality, we argue
that face validity can be a useful proxy for ecological validity. We provide illustrative
examples of this relationship from work in search-and-rescue HRI, and conclude with
some practical guidelines for the construction of immersive simulations in general.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8}
}

@inbook{10.1145/3290605.3300682,
author = {Sun, Yuqian and Yoshida, Shigeo and Narumi, Takuji and Hirose, Michitaka},
title = {PaCaPa: A Handheld VR Device for Rendering Size, Shape, and Stiffness of Virtual Objects in Tool-Based Interactions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300682},
abstract = {We present PaCaPa, a handheld device that renders haptics on a user's palm when the
user interacts with virtual objects using virtual tools such as a stick. PaCaPa is
a cuboid device with two wings that open and close. As the user's stick makes contact
with a virtual object, the wings open by a specific degree to dynamically change the
pressure on the palm and fingers. The open angle of the wings is calculated from the
angle between the virtual stick and hand direction. As the stick bites into the target
object, a large force is generated. Our device enables three kinds of renderings:
size, shape, and stiffness. We conducted user studies to evaluate the performance
of our device. We also evaluated our device in two application scenarios. User feedback
and qualitative ratings indicated that our device can make indirect interaction with
handheld tools more realistic.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300683,
author = {Trielli, Daniel and Diakopoulos, Nicholas},
title = {Search as News Curator: The Role of Google in Shaping Attention to News Information},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300683},
abstract = {This paper presents an algorithm audit of the Google Top Stories box, a prominent
component of search engine results and powerful driver of traffic to news publishers.
As such, it is important in shaping user attention towards news outlets and topics.
By analyzing the number of appearances of news article links we contribute a series
of novel analyses that provide an in-depth characterization of news source diversity
and its implications for attention via Google search. We present results indicating
a considerable degree of source concentration (with variation among search terms),
a slight exaggeration in the ideological skew of news in comparison to a baseline,
and a quantification of how the presentation of items translates into traffic and
attention for publishers. We contribute insights that underscore the power that Google
wields in exposing users to diverse news information, and raise important questions
and opportunities for future work on algorithmic news curation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300684,
author = {Schmitz, Martin and Stitz, Martin and M\"{u}ller, Florian and Funk, Markus and M\"{u}hlh\"{a}user, Max},
title = {../Trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300684},
abstract = {Hover, touch, and force are promising input modalities that get increasingly integrated
into screens and everyday objects. However, these interactions are often limited to
flat surfaces and the integration of suitable sensors is time-consuming and costly.
To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline
to 3D print custom objects that detect the 3D position of a finger hovering, touching,
or forcing them by combining multiple capacitance measurements via capacitive trilateration.
Trilaterate places and routes actively-shielded sensors inside the object and operates
on consumer-level 3D printers. We present technical evaluations and example applications
that validate and demonstrate the wide applicability of Trilaterate.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300685,
author = {Feger, Sebastian S. and Dallmeier-Tiessen, S\"{u}nje and Schmidt, Albrecht and Wo\'{z}niak, Pawe\l{} W.},
title = {Designing for Reproducibility: A Qualitative Study of Challenges and Opportunities in High Energy Physics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300685},
abstract = {Reproducibility should be a cornerstone of scientific research and is a growing concern
among the scientific community and the public. Understanding how to design services
and tools that support documentation, preservation and sharing is required to maximize
the positive impact of scientific research. We conducted a study of user attitudes
towards systems that support data preservation in High Energy Physics, one of science's
most data-intensive branches. We report on our interview study with 12 experimental
physicists, studying requirements and opportunities in designing for research preservation
and reproducibility. Our findings suggest that we need to design for motivation and
benefits in order to stimulate contributions and to address the observed scalability
challenge. Therefore, researchers' attitudes towards communication, uncertainty, collaboration
and automation need to be reflected in design. Based on our findings, we present a
systematic view of user needs and constraints that define the design space of systems
supporting reproducible practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300686,
author = {Shugrina, Maria and Zhang, Wenjia and Chevalier, Fanny and Fidler, Sanja and Singh, Karan},
title = {Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300686},
abstract = {Color themes or palettes are popular for sharing color combinations across many visual
domains. We present a novel interface for creating color themes through direct manipulation
of color swatches. Users can create and rearrange swatches, and combine them into
smooth and step-based gradients and three-color blends -- all using a seamless touch
or mouse input. Analysis of existing solutions reveals a fragmented color design workflow,
where separate software is used for swatches, smooth and discrete gradients and for
in-context color visualization. Our design unifies these tasks, while encouraging
playful creative exploration. Adjusting a color using standard color pickers can break
this interaction flow with mechanical slider manipulation. To keep interaction seamless,
we additionally design an in situ color tweaking interface for freeform exploration
of an entire color neighborhood. We evaluate our interface with a group of professional
designers and students majoring in this field.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300687,
author = {Terzimehi\'{c}, Naundefineda and H\"{a}uslschmid, Renate and Hussmann, Heinrich and schraefel, m.c.},
title = {A Review &amp; Analysis of Mindfulness Research in HCI: Framing Current Lines of Research and Future Opportunities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300687},
abstract = {Mindfulness is a term seen with increasing frequency in HCI literature, and yet the
term itself is used almost as variously as the number of papers in which it appears.
This diversity makes comparing or evaluating HCI approaches around mindfulness or
understanding the design space itself a challenging task. We conducted a structured
ACM literature search based on the term mindfulness. Our selection process yielded
38 relevant papers, which we analyzed for their definition, motivation, practice,
evaluation and technology use around mindfulness. We identify similarities, divergences
and areas of interest for each aspect, resulting in a framework composed of four perspectives
and seven lines of research. We highlight challenges and opportunities for future
HCI research and design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300688,
author = {Gui, Xinning and Chen, Yunan},
title = {Making Healthcare Infrastructure Work: Unpacking the Infrastructuring Work of Individuals},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300688},
abstract = {The U.S. healthcare infrastructure is fragmented with various breakdowns. Patients
or caregivers have to rely on their own to overcome barriers and fix breakdowns in
order to obtain necessary service, that is, infrastructuring work to make the healthcare
infrastructure work for them. So far little attention has been paid to such infrastructuring
work in healthcare. We present an interview study of 32 U.S. parents of young children
to discuss the work of infrastructuring our participants carry out to deal with breakdowns
within the healthcare infrastructure. We report how they repaired unexpected failures
happening at the individual level, aligned components at organizational and cross-organizational
level, and circumvented infrastructural constraints (e.g., policy and financial ones)
that were perceived as ambiguous and demanding. We discuss infrastructuring work in
light of the literature on patients' and caregivers' work, reflect upon the notion
of patient engagement, and explore nuances along several dimensions of infrastructuring
work.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300689,
author = {Metatla, Oussama and Maggioni, Emanuela and Cullen, Clare and Obrist, Marianna},
title = {"Like Popcorn": Crossmodal Correspondences Between Scents, 3D Shapes and Emotions in Children},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300689},
abstract = {There is increasing interest in multisensory experiences in HCI. However, little research
considers how sensory modalities interact with each other and how this may impact
interactive experiences. We investigate how children associate emotions with scents
and 3D shapes. 14 participants (10-17yrs) completed crossmodal association tasks to
attribute emotional characteristics to variants of the "Bouba/Kiki" stimuli, presented
as 3D tangible models, in conjunction with lemon and vanilla scents. Our findings
support pre-existing mappings between shapes and scents, and confirm the associations
between the combination of angular shapes ("Kiki") and lemon scent with arousing emotion,
and of round shapes ("Bouba") and vanilla scent with calming emotion. This extends
prior work on crossmodal correspondences in terms of stimuli (3D as opposed to 2D
shapes), sample (children), and conveyed content (emotions). We outline how these
findings can contribute to designing more inclusive interactive multisensory technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300690,
author = {Feger, Sebastian S. and Dallmeier-Tiessen, S\"{u}nje and Wo\'{z}niak, Pawe\l{} W. and Schmidt, Albrecht},
title = {Gamification in Science: A Study of Requirements in the Context of Reproducible Research},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300690},
abstract = {The need for data preservation and reproducible research is widely recognized in the
scientific community. Yet, researchers often struggle to find the motivation to contribute
to data repositories and to use tools that foster reproducibility. In this paper,
we explore possible uses of gamification to support reproducible practices in High
Energy Physics. To understand how gamification can be effective in research tools,
we participated in a workshop and performed interviews with data analysts. We then
designed two interactive prototypes of a research preservation service that use contrasting
gamification strategies. The evaluation of the prototypes showed that gamification
needs to address core scientific challenges, in particular the fair reflection of
quality and individual contribution. Through thematic analysis, we identified four
themes which describe perceptions and requirements of gamification in research: Contribution,
Metrics, Applications and Scientific practice. Based on these, we discuss design implications
for gamification in science.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300691,
author = {Bi, Tao and Bianchi-Berthouze, Nadia and Singh, Aneesha and Costanza, Enrico},
title = {Understanding the Shared Experience of Runners and Spectators in Long-Distance Running Events},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300691},
abstract = {Increasingly popular, long-distance running events (LDRE) attract not just runners
but an exponentially increasing number of spectators. Due to the long duration and
broad geographic spread of such events, interactions between them are limited to brief
moments when runners (R) pass by their supporting spectators (S). Current technology
is limited in its potential for supporting interactions and mainly measures and displays
basic running information to spectators who passively consume it. In this paper, we
conducted qualitative studies for an in-depth understanding of the R&amp;S' shared experience
during LDRE and how technology can enrich this experience. We propose a two-layer
DyPECS framework, highlighting the rich dynamics of the R&amp;S multi-faceted running
journey and of their micro-encounters. DyPECS is enriched by the findings from our
in depth qualitative studies. We finally present design implications for the multi-facet
co-experience of R&amp;S during LDRE.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300692,
author = {Abbott, Jacob and MacLeod, Haley and Nurain, Novia and Ekobe, Gustave and Patil, Sameer},
title = {Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300692},
abstract = {When studying technologies pertaining to health, wellness, accessibility, and aging,
researchers are often required to perform a balancing act between controlling and
sharing sensitive data of the people in their studies and protecting the privacy of
these participants. If the data can be anonymized and shared, it can boost the impact
of the research by facilitating replication and extension. Despite anonymization,
data reporting and sharing may lead to re-identification of participants, which can
be particularly problematic when the research deals with sensitive topics, such as
health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility,
and aging to examine data reporting and sharing practices. Our analysis revealed notable
patterns and trends regarding the reporting of age, gender, participant types, sample
sizes, methodology, ethical considerations, anonymization techniques, and data sharing.
Based on our findings, we propose several suggestions for community standards and
practices that could facilitate data reporting and sharing while limiting the privacy
risks for study participants.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300693,
author = {Constant, Thomas and Levieux, Guillaume},
title = {Dynamic Difficulty Adjustment Impact on Players' Confidence},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300693},
abstract = {Difficulty is one of the major motivational pull of video games, and thus many games
use Dynamic Difficulty Adjustment (DDA) systems to improve the game experience. This
paper describes our research investigating the influence of DDA systems on player's
confidence, evaluated using an in-game bet system. Our hypothesis is that DDA systems
may lead players to overconfidence, revealed by an overestimation of their success
chances when betting. This boost of confidence may be a part of the positive impact
of DDA systems on the quality of game experience. We explain our method to evaluate
player's confidence and implement it into three games related to logical, motor and
sensory difficulties. We describe two experimental conditions where difficulty is
either randomly chosen or adapted using a DDA algorithm. Results show how DDA systems
can lead players to high level of overconfidence.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300694,
author = {Tag, Benjamin and Vargo, Andrew W. and Gupta, Aman and Chernyshov, George and Kunze, Kai and Dingler, Tilman},
title = {Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300694},
abstract = {As the day progresses, cognitive functions are subject to fluctuations. While the
circadian process results in diurnal peaks and drops, the homeostatic process manifests
itself in a steady decline of alertness across the day. Awareness of these changes
allows the design of proactive recommender and warning systems, which encourage demanding
tasks during periods of high alertness and flag accident-prone activities in low alertness
states. In contrast to conventional alertness assessments, which are often limited
to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach
on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography
sensors integrated into regular glasses' frames, we recorded the eye movements of
16 participants over the course of two weeks in-the-wild and built a robust model
of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous
monitoring of alertness levels throughout the day.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300695,
author = {Madaio, Michael A. and Tanoh, Fabrice and Seri, Axel Blahoua and Jasinska, Kaja and Ogan, Amy},
title = {"Everyone Brings Their Grain of Salt": Designing for Low-Literate Parental Engagement with a Mobile Literacy Technology in C\^{o}Te d'Ivoire},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300695},
abstract = {Significant research has demonstrated the crucial role that parents play in supporting
the development of children's literacy, but in contexts where adults may lack sufficient
literacy in the target language, it is not clear how to most effectively scaffold
parental support for children's literacy. Prior work has designed technologies to
teach children literacy directly, but this work has not focused on designing for low-literate
parents, particularly for multilingual and developing contexts. In this paper, we
describe findings from a qualitative study conducted in several regions of rural C\^{o}te
d'Ivoire to understand Ivorian parents' beliefs, desires, and preferences for French
literacy. We discuss themes that emerged from these interviews, surrounding ideas
of trust, collaboration, and culturally-responsive design, and we highlight implications
for the design of technology to scaffold low-literate parental support for children's
literacy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300696,
author = {Widdicks, Kelly and Hazas, Mike and Bates, Oliver and Friday, Adrian},
title = {Streaming, Multi-Screens and YouTube: The New (Unsustainable) Ways of Watching in the Home},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300696},
abstract = {Internet use and online services underpin everyday life, and the resultant energy
demand is almost entirely hidden, yet significant and growing: it is anticipated to
reach 21% of global electricity demand by 2030 and to eclipse half the greenhouse
gas emissions of transportation by 2040. Driving this growth, real-time video streaming
('watching') is estimated at around 50% of all peak data traffic. Using a mixed-methods
analysis of the use of 66 devices (e.g. smart TVs, tablets) across 20 participants
in 9 households, we reveal the online activity of domestic watching and provide a
detailed exploration of video-on-demand activities. We identify new ways in which
watching is transitioning in more rather than less data demanding directions; and
explore the role HCI may play in reducing this growing data demand. We further highlight
implications for key HCI and societal stakeholders (policy makers, service providers,
network engineers) to tackle this important issue.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300697,
author = {Tseng, Vincent W.-S. and Lee, Matthew L. and Denoue, Laurent and Avrahami, Daniel},
title = {Overcoming Distractions during Transitions from Break to Work Using a Conversational Website-Blocking System},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300697},
abstract = {Work breaks--both physical and digital--play an important role in productivity and
workplace wellbeing. Yet, the growing availability of digital distractions from online
content can turn breaks into prolonged "cyberloafing". In this paper, we present UpTime,
a system that aims to support workers' transitions from breaks back to work--moments
susceptible to digital distractions. Combining a browser extension and chatbot, users
interact with UpTime through proactive and reactive chat prompts. By sensing transitions
from inactivity, UpTime helps workers avoid distractions by automatically blocking
distracting websites temporarily, while still giving them control to take necessary
digital breaks. We report findings from a 3-week comparative field study with 15 workers.
Our results show that automatic, temporary blocking at transition points can significantly
reduce digital distractions and stress without sacrificing workers' sense of control.
Our findings, however, also emphasize that overloading users' existing communication
channels for chatbot interaction should be done thoughtfully.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300698,
author = {Noman, Abu Saleh Md and Das, Sanchari and Patil, Sameer},
title = {Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300698},
abstract = {Researchers have recognized the need to pay attention to negative aspects and non-use
of social media services to uncover usage barriers and surface shortcomings of these
systems. We contribute to these efforts by analyzing comments on posts related to
Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on
Security. Our analysis indicates that technically savvy individuals exhibit notably
large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments
we coded expressing such views. Qualitative coding revealed Privacy and Security,
User Experience, and Personal Disposition as key factors underlying the negative views.
Our findings suggest that negative sentiment is an explicit higher level factor driving
non-use practices. Further, we confirm several non-use practices reported in the literature
and identify additional aspects connected to recent technological and societal developments.
Our results demonstrate that analysis of user generated content can be useful for
surfacing usage practices on a large scale.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300699,
author = {Carucci, Kayla and Toyama, Kentaro},
title = {Making Well-Being: Exploring the Role of Makerspaces in Long Term Care Facilities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300699},
abstract = {Fourth-age residents in long-term care facilities (LTCF) are known to suffer declines
in well-being due to their advanced age and resulting loss of independence. Using
an action research approach, we set up a makerspace in a New Jersey LTCF for eight
weeks to see whether it could improve well-being for residents. Based on engaged observation
over 280 hours and semi-structured interviews with participants, we find that people
aged 80-99 years will spend (sometimes significant) time in a makerspace for the purposes
of making and companionship; that makerspaces can contribute to both autonomy and
well-being for older residents; and participants produced not only decorative art,
but novel artifacts that solved real challenges in their daily lives. We situate these
findings in the literature on art and activity therapy for fourth-age people, and
make recommendations for makerspaces in long-term care facilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300700,
author = {Berry, Andrew B. L. and Lim, Catherine Y. and Hirsch, Tad and Hartzler, Andrea L. and Kiel, Linda M. and Bermet, Zo\"{e} A. and Ralston, James D.},
title = {Supporting Communication About Values Between People with Multiple Chronic Conditions and Their Providers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300700},
abstract = {People with multiple chronic conditions (MCC) often disagree with healthcare providers
on priorities for care, leading to worse health outcomes. To align priorities, there
is a need to support patient-provider communication about what patients consider important
for their well-being and health (i.e., their personal values). To address barriers
to communication about values, we conducted a two-part study with key stakeholders
in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities
generated seven dimensions that characterize stakeholders' diverse ideas for supporting
communication about values: explicitness, effort, disclosure, guidance, intimacy,
scale, and synchrony. In Part II, we used the dimensions to generate three design
concepts and presented them in focus groups to further scrutinize findings from Part
I. Based on these findings we outline directions for research and design to improve
patient-provider communication about patients' personal values.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300701,
author = {Ma, Shuai and Wei, Zijun and Tian, Feng and Fan, Xiangmin and Zhang, Jianming and Shen, Xiaohui and Lin, Zhe and Huang, Jin and M\v{e}ch, Radom\'{\i}r and Samaras, Dimitris and Wang, Hongan},
title = {SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300701},
abstract = {Instant photo taking and sharing has become one of the most popular forms of social
networking. However, taking high-quality photos is difficult as it requires knowledge
and skill in photography that most non-expert users lack. In this paper we present
SmartEye, a novel mobile system to help users take photos with good compositions in-situ.
The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning
based model that outputs composition suggestions in real time, and a novel, interactively
updated module (P-Module) that adjusts the VPN outputs to account for personalized
composition preferences. We also design a novel interface with functions at the front-end
to enable real-time and informative interactions for photo taking. We conduct two
user studies to investigate SmartEye qualitatively and quantitatively. Results show
that SmartEye effectively models and predicts personalized composition preferences,
provides instant high-quality compositions in-situ, and outperforms the non-personalized
systems significantly.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300702,
author = {Menking, Amanda and Erickson, Ingrid and Pratt, Wanda},
title = {People Who Can Take It: How Women Wikipedians Negotiate and Navigate Safety},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300702},
abstract = {Wikipedia is one of the most successful online communities in history, yet it struggles
to attract and retain women editors-a phenomenon known as the gender gap. We investigate
this gap by focusing on the voices of experienced women Wikipedians. In this interview-based
study (N=25), we identify a core theme among these voices: safety. We reveal how our
participants perceive safety within their community, how they manage their safety
both conceptually and physically, and how they act on this understanding to create
safe spaces on and off Wikipedia. Our analysis shows Wikipedia functions as both a
multidimensional and porous space encompassing a spectrum of safety. Navigating this
space requires these women to employ sophisticated tactics related to identity management,
boundary management, and emotion work. We conclude with a set of provocations to spur
the design of future online environments that encourage equity, inclusivity, and safety
for historically marginalized users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300703,
author = {Ramirez Gomez, Argenis and Gellersen, Hans},
title = {SuperVision: Playing with Gaze Aversion and Peripheral Vision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300703},
abstract = {In this work, we challenge the Gaze interaction paradigm "What you see is what you
get" to introduce "playing with peripheral vision". We developed the conceptual framework
to introduce this novel gaze-aware game dynamic. We illustrated the concept with SuperVision,
a collection of three games that play with peripheral vision. We propose perceptual
and interaction challenges that require players not to look and rely on their periphery.
To validate the game dynamic and experience, we conducted a user study with twenty-four
participants. Results show how the game concept created an engaging and playful experience
playing with peripheral vision. Participants showed proficiency in overcoming the
game challenges, developing clear strategies to succeed. Moreover, we found evidence
that playing the game can affect our visual skills, with greater peripheral awareness.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300704,
author = {Kizilcec, Ren\'{e} F. and Saltarelli, Andrew J.},
title = {Psychologically Inclusive Design: Cues Impact Women's Participation in STEM Education},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300704},
abstract = {Visual and verbal cues can reinforce barriers to access for women in science, technology,
engineering, and math (STEM) disciplines. Psychologically inclusive design is an evidence-based
approach to reduce psychological barriers by strategically placing content and design
cues in the environment. Two large field experiments provide estimates of the behavioral
impact of psychologically inclusive cues on women's and men's enrollment behaviors
in an online learning environment. First, a gender-inclusive photo and statement in
an online advertisement for a STEM course increased the click-through rate among women
but not men by 26% (N=209,000). Second, an inclusivity statement with a gender-inclusive
course image to the enrollment page raised the proportion of women enrolling in a
STEM course by up to 18% (N=63,000). These findings contribute evidence of the behavioral
impact of psychologically inclusive design to the literature and yield practical implications
for the presentation of STEM opportunities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300705,
author = {Clark, Leigh and Pantidi, Nadia and Cooney, Orla and Doyle, Philip and Garaialde, Diego and Edwards, Justin and Spillane, Brendan and Gilmartin, Emer and Murad, Christine and Munteanu, Cosmin and Wade, Vincent and Cowan, Benjamin R.},
title = {What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300705},
abstract = {Conversational agents promise conversational interaction but fail to deliver. Efforts
often emulate functional rules from human speech, without considering key characteristics
that conversation must encapsulate. Given its potential in supporting long-term human-agent
relationships, it is paramount that HCI focuses efforts on delivering this promise.
We aim to understand what people value in conversation and how this should manifest
in agents. Findings from a series of semi-structured interviews show people make a
clear dichotomy between social and functional roles of conversation, emphasising the
long-term dynamics of bond and trust along with the importance of context and relationship
stage in the types of conversations they have. People fundamentally questioned the
need for bond and common ground in agent communication, shifting to more utilitarian
definitions of conversational qualities. Drawing on these findings we discuss key
challenges for conversational agent design, most notably the need to redefine the
design parameters for conversational agent interaction.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300706,
author = {Avila, Juan Pablo Martinez and Greenhalgh, Chris and Hazzard, Adrian and Benford, Steve and Chamberlain, Alan},
title = {Encumbered Interaction: A Study of Musicians Preparing to Perform},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300706},
abstract = {Guitars are physical instruments that require skillful two-handed use. Their use is
also supported by diverse digital and physical resources, such as videos and chord
charts. To understand the challenges of interacting with supporting resources at the
same time as playing we conducted an ethnographic study of the preparation activities
of working musicians. We observe successive stages of individual and collaborative
preparation, in which working musicians engage with a diverse range of digital and
physical resources to support their preparation. Interaction with this complex ecology
of digital and physical resources is finely interwoven into their embodied musical
practices, which are usually encumbered by having their instrument in hand, and often
by playing. We identify challenges for augmenting guitars within the rehearsal process
by supporting interaction that is encumbered, contextual and connected, and suggest
a range of possible responses.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300707,
author = {M\"{u}ller, Florian and McManus, Joshua and G\"{u}nther, Sebastian and Schmitz, Martin and M\"{u}hlh\"{a}user, Max and Funk, Markus},
title = {Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300707},
abstract = {From voice commands and air taps to touch gestures on frames: Various techniques for
interacting with head-mounted displays (HMDs) have been proposed. While these techniques
have both benefits and drawbacks dependent on the current situation of the user, research
on interacting with HMDs has not concluded yet. In this paper, we add to the body
of research on interacting with HMDs by exploring foot-tapping as an input modality.
Through two controlled experiments with a total of 36 participants, we first explore
direct interaction with interfaces that are displayed on the floor and require the
user to look down to interact. Secondly, we investigate indirect interaction with
interfaces that, although operated by the user's feet, are always visible as they
are floating in front of the user. Based on the results of the two experiments, we
provide design recommendations for direct and indirect foot-based user interfaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300708,
author = {Reinhardt, Daniel and Hurtienne, J\"{o}rn},
title = {Only One Item Left? Heuristic Information Trumps Calorie Count When Supporting Healthy Snacking Under Low Self-Control},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300708},
abstract = {Pursuing the goal of a healthy diet may be challenging, especially when self-control
resources are low. Yet many persuasive user interfaces fostering healthy choices are
designed for situations with ample self-control, e.g. showing nutritional information
to support reflective decision making. In this paper we propose that under low self-control,
persuasive user interfaces need to rely on simple heuristic decision making to be
successful. We report an experiment that tested this assumption in a 2 (low vs. high
self-control) x 2 (calorie vs. heuristic information) design. The results reveal a
significant interaction effect. Participants with low self-control resources chose
the healthy snack more often when snacks were labelled with heuristic information
than when they were labelled with calorie information. Both strategies were about
equally successful for participants with high self-control. Exploiting situations
of low self-control with heuristic information is a new and promising approach to
designing persuasive technology for healthy eating.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300709,
author = {Phelan, Chanda and Hullman, Jessica and Kay, Matthew and Resnick, Paul},
title = {Some Prior(s) Experience Necessary: Templates for Getting Started With Bayesian Analysis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300709},
abstract = {Bayesian statistical analysis has gained attention in recent years, including in HCI.
The Bayesian approach has several advantages over traditional statistics, including
producing results with more intuitive interpretations. Despite growing interest, few
papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require
significant time investment, making it difficult to casually explore Bayesian methods.
Here, we present a tool that lowers the barrier to exploration: a set of R code templates
that guide Bayesian novices through their first analysis. The templates are tailored
to CHI, supporting analyses found to be most common in recent CHI papers. In a user
study, we found that the templates were easy to understand and use. However, we found
that participants without a statistical background were not confident in their use.
Together our contributions provide a concise analysis tool and empirical results for
understanding and addressing barriers to using Bayesian analysis in HCI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300710,
author = {Lazar, Amanda and Su, Norman Makoto and Bardzell, Jeffrey and Bardzell, Shaowen},
title = {Parting the Red Sea: Sociotechnical Systems and Lived Experiences of Menopause},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300710},
abstract = {Menopause is a major life change affecting roughly half of the population, resulting
in physiological, emotional, and social changes. To understand experiences with menopause
holistically, we conducted a study of a subreddit forum. The project was informed
by feminist social science methodologies, which center knowledge production on women's
lived experiences. Our central finding is that the lived experience of menopause is
social: menopause is less about bodily experiences by themselves and more about how
experiences with the body become meaningful over time in the social context. We find
that gendered marginalization shapes diverse social relationships, leading to widespread
feelings of alienation and negative transformation - often expressed in semantically
dense figurative language. Research and design can accordingly address menopause not
only as a women's health concern, but also as a matter of facilitating social support
and a social justice issue.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300711,
author = {Kou, Yubo and Gui, Xinning and Chen, Yunan and Nardi, Bonnie},
title = {Turn to the Self in Human-Computer Interaction: Care of the Self in Negotiating the Human-Technology Relationship},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300711},
abstract = {Everyday life is increasingly mediated by technology. Technology is rapidly growing
capacity and complexity, especially evident in developments in artificial intelligence
and big data analytics. As human-computer interaction (HCI) endeavors to examine and
theorize how people act and interact with the ever-evolving technology, an important,
emerging concern is how the self-the totality of internal qualities such as consciousness
and agency-plays out in relation to the technology-mediated external world. To analyze
this question, we draw from Michel Foucault's ethics of "care of the self," which
examines how the self is constituted through conscious and reflective work on self-transformation.
We present three case studies to illustrate how individuals carry out practices of
the self to reflect upon and negotiate their relationship with technology. We discuss
the importance of examining the self and foreground the notion of care of the self
in HCI research and design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300712,
author = {Poon, Anthony and Giroux, Sarah and Eloundou-Enyegue, Parfait and Guimbretiere, Fran\c{c}ois and Dell, Nicola},
title = {Engaging High School Students in Cameroon with Exam Practice Quizzes via SMS and WhatsApp},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300712},
abstract = {We created a quiz-based intervention to help secondary school students in Cameroon
with exam practice. We sent regularly-spaced, multiple-choice questions to students'
own mobile devices and examined factors which influenced quiz participation. These
quizzes were delivered via either SMS or WhatsApp per each student's preference. We
conducted a 3-week deployment with 546 students at 3 schools during their month of
independent study prior to their graduating exam. We found that participation rates
were heavily impacted by trust in the intervening organization and perceptions of
personal security in the socio-technical environment. Parents also played a key gate-keeping
role on students' digital activities. We describe how this role - along with different
perceptions of smartphones versus basic phones - may manifest in lower participation
rates among WhatsApp-based users as compared to SMS. Finally, we discuss design implications
for future educational interventions that target students' personal cellphones outside
of the classroom.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300713,
author = {Memoli, Gianluca and Chisari, Letizia and Eccles, Jonathan P. and Caleap, Mihai and Drinkwater, Bruce W. and Subramanian, Sriram},
title = {VARI-SOUND: A Varifocal Lens for Sound},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300713},
abstract = {Centuries of development in optics have given us passive devices (i.e. lenses, mirrors
and filters) to enrich audience immersivity with light effects, but there is nothing
similar for sound. Beam-forming in concert halls and outdoor gigs still requires a
large number of speakers, while headphones are still the state-of-the-art for personalized
audio immersivity in VR. In this work, we show how 3D printed acoustic meta-surfaces,
assembled into the equivalent of optical systems, may offer a different solution.
We demonstrate how to build them and how to use simple design tools, like the thin-lens
equation, also for sound. We present some key acoustic devices, like a "collimator",
to transform a standard computer speaker into an acoustic "spotlight"; and a "magnifying
glass", to create sound sources coming from distinct locations than the speaker itself.
Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent
to auto-focus cameras and VR headsets and the limitations of the technology.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300714,
author = {Kim, Da-jung and Lim, Youn-kyung},
title = {Co-Performing Agent: Design for Building User-Agent Partnership in Learning and Adaptive Services},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300714},
abstract = {Intelligent agents have become prevalent in everyday IT products and services. To
improve an agent's knowledge of a user and the quality of personalized service experience,
it is important for the agent to cooperate with the user (e.g., asking users to provide
their information and feedback). However, few works inform how to support such user-agent
co-performance from a human-centered perspective. To fill this gap, we devised Co-Performing
Agent, a Wizard-of-Oz-based research probe of an agent that cooperates with a user
to learn by helping users to have a partnership mindset. By incorporating the probe,
we conducted a two-month exploratory study, aiming to understand how users experience
co-performing with their agent over time. Based on the findings, this paper presents
the factors that affected users' co-performing behaviors and discusses design implications
for supporting constructive co-performance and building a resilient user-agent partnership
over time.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300715,
author = {Henderson, Jay and Avery, Jeff and Grisoni, Laurent and Lank, Edward},
title = {Leveraging Distal Vibrotactile Feedback for Target Acquisition},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300715},
abstract = {Many touch based interactions provide limited opportunities for direct tactile feedback;
examples include multi-user touch displays, augmented reality based projections on
passive surfaces, and mid-air input. In this paper, we consider distal feedback, through
vibrotactile stimulation on a smart-watch placed on the user's non-dominant wrist,
as an alternative feedback mechanism to interaction location vibrotactile feedback,
under the user's finger. We compare the effectiveness of interaction location feedback
vs. distal feedback through a Fitts's Law task completed on a smartphone. Results
show that distal and interaction location feedback both reduce errors in target acquisition
and exhibit statistically comparable performance, suggesting that distal vibrotactile
feedback is a suitable alternative when interaction location feedback is not readily
available.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300716,
author = {Zhang, Min and Sas, Corina and Lambert, Zoe and Ahmad, Masitah},
title = {Designing for the Infrastructure of the Supply Chain of Malay Handwoven Songket in Terengganu},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300716},
abstract = {The growing HCI interest in developing contexts and cultural craft practices is ripe
to focus on their under-explored homegrown sociotechnical infrastructures. This paper
explores the creative infrastructural actions embedded within the practices of songket's
supply chain in Terengganu, Malaysia. We report on contextual interviews with 92 participants
including preparation workers, weavers, designers, merchants, and customers. Findings
indicate that increased creative infrastructural actions are reflected in these actors'
resourcefulness for mobilizing information, materials, and equipment, and for making
creative artifacts through new technologies weaved within traditional practices. We
propose two novel approaches to design in this craft-based infrastructure. First,
we explore designing for the social layer of infrastructure and its mutually advantageous
exploitative relationships rooted in culture and traditions. Second, we suggest designing
for roaming value-creation artifacts, which blend physical and digital materializations
of songket textile design. Developed through a collaborative and asynchronous process,
we argue that these artifacts represent less-explored vehicles for value co-creation,
and that sociotechnical infrastructures as emerging sites of innovation could benefit
from HCI research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300717,
author = {Kunkel, Johannes and Donkers, Tim and Michael, Lisa and Barbu, Catalin-Mihai and Ziegler, J\"{u}rgen},
title = {Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300717},
abstract = {Trust in a Recommender System (RS) is crucial for its overall success. However, it
remains underexplored whether users trust personal recommendation sources (i.e. other
humans) more than impersonal sources (i.e. conventional RS), and, if they do, whether
the perceived quality of explanation provided account for the difference. We conducted
an empirical study in which we compared these two sources of recommendations and explanations.
Human advisors were asked to explain movies they recommended in short texts while
the RS created explanations based on item similarity. Our experiment comprised two
rounds of recommending. Over both rounds the quality of explanations provided by users
was assessed higher than the quality of the system's explanations. Moreover, explanation
quality significantly influenced perceived recommendation quality as well as trust
in the recommendation source. Consequently, we suggest that RS should provide richer
explanations in order to increase their perceived recommendation quality and trustworthiness.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300718,
author = {Hamdan, Nur Al-huda and Wagner, Adrian and Voelker, Simon and Steimle, J\"{u}rgen and Borchers, Jan},
title = {Springlets: Expressive, Flexible and Silent On-Skin Tactile Interfaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300718},
abstract = {We introduce Springlets, expressive, non-vibrating mechanotactile interfaces on the
skin. Embedded with shape memory alloy springs, we implement Springlets as thin and
flexible stickers to be worn on various body locations, thanks to their silent operation
even on the neck and head. We present a technically simple and rapid technique for
fabricating a wide range of Springlet interfaces and computer-generated tactile patterns.
We developed Springlets for six tactile primitives: pinching, directional stretching,
pressing, pulling, dragging, and expanding. A study placing Springlets on the arm
and near the head demonstrates Springlets' effectiveness and wearability in both stationary
and mobile situations. We explore new interactive experiences in tactile social communication,
physical guidance, health interfaces, navigation, and virtual reality gaming, enabled
by Springlets' unique and scalable form factor.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300719,
author = {Yarmand, Matin and Yoon, Dongwook and Dodson, Samuel and Roll, Ido and Fels, Sidney S.},
title = {"Can You Believe [1:21]?!": Content and Time-Based Reference Patterns in Video Comments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300719},
abstract = {As videos become increasingly ubiquitous, so is video-based commenting. To contextualize
comments, people often reference specific audio/visual content within video. However,
the literature falls short of explaining the types of video content people refer to,
how they establish references and identify referents, how video characteristics (e.g.,
genre) impact referencing behaviors, and how references impact social engagement.
We present a taxonomy for classifying video references by referent type and temporal
specificity. Using our taxonomy, we analyzed 2.5K references with quotations and timestamps
collected from public YouTube comments. We found: 1) people reference intervals of
video more frequently than time-points, 2) visual entities are referenced more often
than sounds, and 3) comments with quotes are more likely to receive replies but not
more "likes". We discuss the need for in-situ dereferencing user interfaces, illustrate
design concepts for typed referencing features, and provide a dataset for future studies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300720,
author = {Himmelsbach, Julia and Schwarz, Stephanie and Gerdenitsch, Cornelia and Wais-Zechmann, Beatrix and Bobeth, Jan and Tscheligi, Manfred},
title = {Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300720},
abstract = {In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity
of users is increasing. In this work, we analyze whether the articulated need for
more diversity-sensitive research led indeed to a higher consideration of diversity
in HCI research. Based on a comprehensive collection of diversity dimensions, we present
results of a quantitative content analysis of articles accepted in the Proceedings
of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results
demonstrate how many and how intensively diversity dimensions were considered, and
moreover highlight those dimensions that have so far received less attention. Uncovering
continuous and discontinuous trends across time and differences between subfields
of research, we identify research gaps and aim at contributing to a comprehensive
understanding of diversity supporting diversity-sensitive research in HCI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300721,
author = {Kwok, Tiffany C.K. and Kiefer, Peter and Schinazi, Victor R. and Adams, Benjamin and Raubal, Martin},
title = {Gaze-Guided Narratives: Adapting Audio Guide Content to Gaze in Virtual and Real Environments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300721},
abstract = {Exploring a city panorama from a vantage point is a popular tourist activity. Typical
audio guides that support this activity are limited by their lack of responsiveness
to user behavior and by the difficulty of matching audio descriptions to the panorama.
These limitations can inhibit the acquisition of information and negatively affect
user experience. This paper proposes Gaze-Guided Narratives as a novel interaction
concept that helps tourists find specific features in the panorama (gaze guidance)
while adapting the audio content to what has been previously looked at (content adaptation).
Results from a controlled study in a virtual environment (n=60) revealed that a system
featuring both gaze guidance and content adaptation obtained better user experience,
lower cognitive load, and led to better performance in a mapping task compared to
a classic audio guide. A second study with tourists situated at a vantage point (n=16)
further demonstrated the feasibility of this approach in the real world.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300722,
author = {Koushik, Varsha and Guinness, Darren and Kane, Shaun K.},
title = {StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300722},
abstract = {Block-based programming languages can support novice programmers through features
such as simplified code syntax and user-friendly libraries. However, most block-based
programming languages are highly visual, which makes them inaccessible to blind and
visually impaired students. To address the inaccessibility of block-based languages,
we introduce StoryBlocks, a tangible block-based game that enables blind programmers
to learn basic programming concepts by creating audio stories. In this paper, we document
the design of StoryBlocks and report on a series of design activities with groups
of teachers, Braille experts, and students. Participants in our design sessions worked
together to create accessible stories, and their feedback offers insights for the
future development of accessible, tangible programming tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300723,
author = {Fox, Sarah E. and Sobel, Kiley and Rosner, Daniela K.},
title = {Managerial Visions: Stories of Upgrading and Maintaining the Public Restroom with IoT},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300723},
abstract = {This paper examines the entangled development of governance strategies and networked
technologies in the pervasive but under-examined domain of public restrooms. Drawing
on a mix of archival materials, participant observation, and interviews within and
beyond the city of Seattle, Washington, we look at the motivations of public restroom
facilities managers as they introduce (or consider introducing) networked technology
in the spaces they administer. Over the course of the research, we found internet
of things technologies-or, connected devices imbued with computational capacity-became
increasingly tied up with cost-reducing efficiencies and exploitative regulatory techniques.
Drawing from this case study, we develop the concept of managerial visions: ways of
seeing that structure labor, enforce compliance, and define access to resources. We
argue that these ways of seeing prove increasingly critical to HCI research as it
attends to computer-mediated collaboration beyond white-collar settings.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300724,
author = {Eslami, Motahhare and Vaccaro, Kristen and Lee, Min Kyung and Elazari Bar On, Amit and Gilbert, Eric and Karahalios, Karrie},
title = {User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300724},
abstract = {Algorithms exert great power in curating online information, yet are often opaque
in their operation, and even existence. Since opaque algorithms sometimes make biased
or deceptive decisions, many have called for increased transparency. However, little
is known about how users perceive and interact with potentially biased and deceptive
opaque algorithms. What factors are associated with these perceptions, and how does
adding transparency into algorithmic systems change user attitudes? To address these
questions, we conducted two studies: 1) an analysis of 242 users' online discussions
about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users
disclosing the algorithm's existence via a tool. We found that users question or defend
this algorithm and its opacity depending on their engagement with and personal gain
from the algorithm. We also found adding transparency into the algorithm changed users'
attitudes towards the algorithm: users reported their intention to either write for
the algorithm in future reviews or leave the platform.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300725,
author = {Kimura-Thollander, Philippe and Kumar, Neha},
title = {Examining the "Global" Language of Emojis: Designing for Cultural Representation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300725},
abstract = {Emojis are becoming an increasingly popular mode of communication between individuals
worldwide, with researchers claiming them to be a type of "ubiquitous language'' that
can span different languages due to its pictorial nature. Our study uses a combination
of methods to examine how emojis are adopted and perceived by individuals from diverse
cultural backgrounds and 45 countries. Our survey and interview findings point to
the existence of a cultural gap between user perceptions and the current emoji standard.
Using participatory design, we sought to address this gap by designing 40 emojis and
conducted another survey to evaluate their acceptability compared to existing Japanese
emojis. We also draw on participant observation from a Unicode Consortium meeting
on emoji addition. Our analysis leads us to discuss how emojis might be made more
inclusive, diverse, and representative of the populations that use them.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300726,
author = {Hutt, Stephen and Grafsgaard, Joseph F. and D'Mello, Sidney K.},
title = {Time to Scale: Generalizable Affect Detection for Tens of Thousands of Students across An Entire School Year},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300726},
abstract = {We developed generalizable affect detectors using 133,966 instances of 18 affective
states collected from 69,174 students who interacted with an online math learning
platform called Algebra Nation over the entire school year. To enable scalability
and generalizability, we used generic interaction features (e.g., viewing a video,
taking a quiz), which do not require specialized sensors and are domain- and (to a
certain extent) system-independent. We experimented with standard classifiers, recurrent
neural networks, and genetically evolved neural networks for affect modeling. Prediction
accuracies, quantified with Spearman's rho, were modest and ranged from .08 (for surprise)
to .34 (for happiness) with a mean of .25. Our model trained on Algebra students generalized
to a different set of Geometry students (n = 28,458) on the same platform. We discuss
implications for scaling up affect detection for affect-sensitive online learning
environments which aim to improve engagement and learning by detecting and responding
to student affect.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300727,
author = {K\"{u}tt, Grete Helena and Lee, Kevin and Hardacre, Ethan and Papoutsaki, Alexandra},
title = {Eye-Write: Gaze Sharing for Collaborative Writing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300727},
abstract = {Online collaborative writing is an increasingly common practice. Despite its positive
effect on productivity and quality of work, it poses challenges to co-authors in remote
settings because of limitations in conversational grounding and activity awareness.
This paper presents Eye-Write, a novel system which allows two co-authors to see at
will the location of their partner's gaze within a text editor. To investigate the
effect of shared gaze on collaboration, we conducted a study on synchronous remote
collaborative writing in academic settings with 20 dyads. Gaze sharing improved five
aspects of perceived collaboration quality: mutual understanding, level of joint attention,
flow of communication, level of negotiation, and awareness of the co-author's activity.
Furthermore, dyads whose participants deactivated the gaze visualization showed a
smaller degree of collaboration. Our findings offer insights for future text editors
by outlining the benefits of at-will gaze sharing in collaborative writing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300728,
author = {Karchemsky, Mitchell and Zamfirescu-Pereira, J.D. and Wu, Kuan-Ju and Guimbreti\`{e}re, Fran\c{c}ois and Hartmann, Bjoern},
title = {Heimdall: A Remotely Controlled Inspection Workbench For Debugging Microcontroller Projects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300728},
abstract = {Students and hobbyists build embedded systems that combine sensing, actuation and
microcontrollers on solderless breadboards. To help students debug such circuits,
experienced teachers apply visual inspection, targeted measurements, and circuit modifications
to diagnose and localize the problem(s). However, experienced helpers may not always
be available to review student projects in person. To enable remote debugging of circuit
problems, we introduce Heimdall, a remote electronics workbench that allows experts
to visually inspect a student's circuit; perform measurements; and to re-wire and
inject test signals. These interactions are enabled by an actuated inspection camera;
an augmented breadboard that enables flexible configuration of row connectivity and
measurement/injection lines; and a web-based UI that teachers can use to perform measurements
through interaction with the captured images. We demonstrate that common issues arising
in embedded electronics classes can be successfully diagnosed remotely and report
on preliminary user feedback from teaching assistants who frequently debug circuits.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300729,
author = {Venn-Wycherley, Megan and Kharrufa, Ahmed},
title = {HOPE for Computing Education: Towards the Infrastructuring of Support for University-School Partnerships},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300729},
abstract = {The state of computing education in the UK is described as "patchy and fragile" with
universities tasked to provide further support to schools. However, little guidance
exists towards the provision of this support. To explore the development of university-school
partnerships, we present findings of an extended educational engagement coordinated
by Newcastle University, as part of the national "Create, Learn and Inspire with the
micro:bit and the BBC" initiative. Following an action research approach, we explore
the experiences of undergraduate students, schoolteachers and an educational broker
through the process, including recruitment, content development, and delivery of over
30 computing lessons by nine undergraduates. We identify a number of design considerations
towards the development of High Opportunity Progression Ecosystems for the improvement
of computing education, such as student identity, workload model,and process visibility.
We then discuss the potential role of technology in infrastructuring support for university-school
partnerships},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300730,
author = {Moore, Dylan and Dahl, Tobias and Varela, Paula and Ju, Wendy and N\ae{}s, Tormod and Berget, Ingunn},
title = {Unintended Consonances: Methods to Understand Robot Motor Sound Perception},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300730},
abstract = {Recent research suggests that a robot's motors make sounds that can influence users'
perception of the robot's characteristics. To more deeply understand users' associations
with specific sonic characteristics, we adapted methods from sensory science including
Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease
out small differences in motor sounds in an online survey. These methods are straightforward
for untrained people to do in an online setting, mathematically rigorous, and can
explore a variety of subtle auditory and perceptual stimuli. We describe how to use
these methods, interpret the results with several intuitive visual representations,
and show that the results align with a previous study of the same dataset. We close
by discussing benefits and limitations of applying these methods to study subtle phenomena
in the HCI community.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300731,
author = {Han, Teng and Liu, Jie and Hasan, Khalad and Fan, Mingming and Kim, Junhyeok and Li, Jiannan and Fan, Xiangmin and Tian, Feng and Lank, Edward and Irani, Pourang},
title = {PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300731},
abstract = {Intensive exploration and navigation of hierarchical lists on smartphones can be tedious
and time-consuming as it often requires users to frequently switch between multiple
views. To overcome this limitation, we present PinchList, a novel interaction design
that leverages pinch gestures to support seamless exploration of multi-level list
items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out
gesture whereas a pinch-in gesture navigates back to the previous level. Additionally,
pinch and flick gestures are used to navigate lists consisting of more than two levels.
We conduct a user study to refine the design parameters of PinchList such as a suitable
item size, and quantitatively evaluate the target acquisition performance using pinch-in/out
gestures in both scrolling and non-scrolling conditions. In a second study, we compare
the performance of PinchList in a hierarchal navigation task with two commonly used
touch interfaces for list browsing: pagination and expand-and-collapse interfaces.
The results reveal that PinchList is significantly faster than other two interfaces
in accessing items located in hierarchical list views. Finally, we demonstrate that
PinchList enables a host of novel applications in list-based interaction?},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300732,
author = {Salmela, Tarja and Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
title = {Together in Bed? Couples' Mobile Technology Use in Bed},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300732},
abstract = {In this paper, we investigate the use of mobile technology in an underexplored context,
the bed that couples share. Despite large amounts of research on the impact of pre-bedtime
technology use on our sleep and mental state, scant research in the HCI field focuses
on the physical bed as a negotiated site of technology use by couples. This paper
explores (a) the meaning of the bed accessed by mobile technology and (b) the strategies
of both individual and shared technology use in bed, in the context of couple's relationships.
We investigate the effects of mobile technology to couples' bed-sharing practices
through in-depth interviews (n = 12) and an online survey (n = 117). We report on
creative and negotiated bodily practices of mobile technology use by couples in bed,
and the perceived effects on couples' verbal and physical interaction and the intimacy
of the bed.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300733,
author = {Caraban, Ana and Karapanos, Evangelos and Gon\c{c}alves, Daniel and Campos, Pedro},
title = {23 Ways to Nudge: A Review of Technology-Mediated Nudging in Human-Computer Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300733},
abstract = {Ten years ago, Thaler and Sunstein introduced the notion of nudging to talk about
how subtle changes in the 'choice architecture' can alter people's behaviors in predictable
ways. This idea was eagerly adopted in HCI and applied in multiple contexts, including
health, sustainability and privacy. Despite this, we still lack an understanding of
how to design effective technology-mediated nudges. In this paper we present a systematic
review of the use of nudging in HCI research with the goal of laying out the design
space of technology-mediated nudging - the why (i.e., which cognitive biases do nudges
combat) and the how (i.e., what exact mechanisms do nudges employ to incur behavior
change). All in all, we found 23 distinct mechanisms of nudging, grouped in 6 categories,
and leveraging 15 different cognitive biases. We present these as a framework for
technology-mediated nudging, and discuss the factors shaping nudges' effectiveness
and their ethical implications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300734,
author = {Manzoor, Ahtsham and Arooj, Safa and Zulfiqar, Shaban and Parvez, Murayyiam and Shahid, Suleman and Karim, Asim},
title = {ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300734},
abstract = {Assistive technologies such as screen readers and text editors have been used in past
to improve the accessibility and authoring of scientific and mathematical documents.
However, most screens readers fail to narrate complex mathematical notations and expressions
as they skip symbols and necessary information required for the accurate narration
of mathematical content. This study aims at evaluating a new Accessible LaTeX Based
Mathematical Document Authoring and Presentation (ALAP) tool, which assist people
with visual impairments in reading and writing mathematical documents. ALAP includes
features like, assistive debugging, Math Mode for reading and writing mathematical
notations, and automatic generation of an accessible PDF document. These features
aim to improve the LaTeX debugging experience and make it simple for blind users to
author mathematical content by narrating it in natural language through the use of
integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with
18 visually impaired LaTeX users. The results showed that users preferred ALAP over
another comparable LaTeX based authoring tool and were relatively more comfortable
in completing the tasks while using ALAP.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300735,
author = {Galindo Esparza, Rosella P. and Healey, Patrick G. T. and Weaver, Lois and Delbridge, Matthew},
title = {Embodied Imagination: An Approach to Stroke Recovery Combining Participatory Performance and Interactive Technology},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300735},
abstract = {Participatory performance provides methods for exploring social identities and situations
in ways that can help people to imagine new ways of being. Digital technologies provide
tools that can help people envision these possibilities. We explore this combination
through a performance workshop process designed to help stroke survivors imagine new
physical and social possibilities by enacting fantasies of "things they always wanted
to do". This process uses performance methods combined with specially designed real-time
movement visualisations to progressively build fantasy narratives that are enacted
with and for other workshop participants. Qualitative evaluations suggest this process
successfully stimulates participant's embodied imagination and generates a diverse
range of fantasies. The interactive and communal aspects of the workshop process appear
to be especially important in achieving these effects. This work highlights how the
combination of performance methods and interactive tools can bring a rich, prospective
and political understanding of people's lived experience to design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300736,
author = {Bevan, Chris and Green, David Philip and Farmer, Harry and Rose, Mandy and Cater, Kirsten and Stanton Fraser, Dana\"{e} and Brown, Helen},
title = {Behind the Curtain of the "Ultimate Empathy Machine": On the Composition of Virtual Reality Nonfiction Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300736},
abstract = {Virtual Reality nonfiction (VRNF) is an emerging form of immersive media experience
created for consumption using panoramic "Virtual Reality" headsets. VRNF promises
nonfiction content producers the potential to create new ways for audiences to experience
"the real"; allowing viewers to transition from passive spectators to active participants.
Our current project is exploring VRNF through a series of ethnographic and experimental
studies. In order to document the content available, we embarked on an analysis of
VR documentaries produced to date. In this paper, we present an analysis of a representative
sample of 150 VRNF titles released between 2012-2018. We identify and quantify 64
characteristics of the medium over this period, discuss how producers are exploiting
the affordances of VR, and shed light on new audience roles. Our findings provide
insight into the current state of the art in VRNF and provide a digital resource for
other researchers in this area.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300737,
author = {Voit, Alexandra and Mayer, Sven and Schwind, Valentin and Henze, Niels},
title = {Online, VR, AR, Lab, and In-Situ: Comparison of Research Methods to Evaluate Smart Artifacts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300737},
abstract = {Empirical studies are a cornerstone of HCI research. Technical progress constantly
enables new study methods. Online surveys, for example, make it possible to collect
feedback from remote users. Progress in augmented and virtual reality enables to collect
feedback with early designs. In-situ studies enable researchers to gather feedback
in natural environments. While these methods have unique advantages and disadvantages,
it is unclear if and how using a specific method affects the results. Therefore, we
conducted a study with 60 participants comparing five different methods (online, virtual
reality, augmented reality, lab setup, and in-situ) to evaluate early prototypes of
smart artifacts. We asked participants to assess four different smart artifacts using
standardized questionnaires. We show that the method significantly affects the study
result and discuss implications for HCI research. Finally, we highlight further directions
to overcome the effect of the used methods.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300738,
author = {Miniukovich, Aliaksei and Scaltritti, Michele and Sulpizio, Simone and De Angeli, Antonella},
title = {Guideline-Based Evaluation of Web Readability},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300738},
abstract = {Effortless reading remains an issue for many Web users, despite a large number of
readability guidelines available to designers. This paper presents a study of manual
and automatic use of 39 readability guidelines in webpage evaluation. The study collected
the ground-truth readability for a set of 50 webpages using eye-tracking with average
and dyslexic readers (n = 79). It then matched the ground truth against human-based
(n = 35) and automatic evaluations. The results validated 22 guidelines as being connected
to readability. The comparison between human-based and automatic results also revealed
a complex framework: algorithms were better or as good as human experts at evaluating
webpages on specific guidelines - particularly those about low-level features of webpage
legibility and text formatting. However, multiple guidelines still required a human
judgment related to understanding and interpreting webpage content. These results
contribute a guideline categorization laying the ground for future design evaluation
methods.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300739,
author = {Mirnig, Alexander G. and Meschtscherjakov, Alexander},
title = {Trolled by the Trolley Problem: On What Matters for Ethical Decision Making in Automated Vehicles},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300739},
abstract = {Automated vehicles have to make decisions, such as driving maneuvers or rerouting,
based on environment data and decision algorithms. There is a question whether ethical
aspects should be considered in these algorithms. When all available decisions within
a situation have fatal consequences, this leads to a dilemma. Contemporary discourse
surrounding this issue is dominated by the trolley problem, a specific version of
such a dilemma. Based on an outline of its origins, we discuss the trolley problem
and its viability to help solve the questions regarding ethical decision making in
automated vehicles. We show that the trolley problem serves several important functions
but is an ill-suited benchmark for the success or failure of an automated algorithm.
We argue that research and design should focus on avoiding trolley-like problems at
all rather than trying to solve an unsolvable dilemma and discuss alternative approaches
on how to feasibly address ethical issues in automated agents.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300740,
author = {Qu, Chengcheng and Sas, Corina and Doherty, Gavin},
title = {Exploring and Designing for Memory Impairments in Depression},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300740},
abstract = {Depression is an affective disorder with distinctive autobiographical memory impairments,
including negative bias, overgeneralization and reduced positivity. Several clinical
therapies address these impairments, and there is an opportunity to develop new supports
for treatment by considering depression-associated memory impairments within design.
We report on interviews with ten experts in treating depression, with expertise in
both neuropsychology and cognitive behavioral therapies. The interviews explore approaches
for addressing each of these memory impairments. We found consistent use of positive
memories for treating all memory impairments, the challenge of direct retrieval, and
the need to support the experience of positive memories. We aim to sensitize HCI researchers
to the limitations of memory technologies, broaden their awareness of memory impairments
beyond episodic memory recall, and inspire them to engage with this less explored
design space. Our findings open up new design opportunities for memory technologies
for depression, including positive memory banks for active encoding and selective
retrieval, novel cues for supporting generative retrieval, and novel interfaces to
strengthen the reliving of positive memories.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300741,
author = {Hsueh, Stacy and Alaoui, Sarah Fdili and Mackay, Wendy E.},
title = {Understanding Kinaesthetic Creativity in Dance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300741},
abstract = {Kinaesthetic creativity refers to the body's ability to generate alternate futures
in activities such as role-playing in participatory design workshops. This has relevance
not only to the design of methods for inspiring creativity but also to the design
of systems that promote engaging experiences via bodily interaction. This paper probes
this creative process by studying how dancers interact with technology to generate
ideas. We developed a series of parameterized interactive visuals and asked dance
practitioners to use them in generating movement materials. From our study, we define
a taxonomy that comprises different relationships and movement responses dancers form
with the visuals. Against this taxonomy, we describe six types of interaction patterns
and demonstrate how dance creativity is driven by the ability to shift between these
patterns. We then propose a set of interaction design qualities to support kinaesthetic
creativity.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300742,
author = {Kuhlman, Caitlin and Doherty, Diana and Nurbekova, Malika and Deva, Goutham and Phyo, Zarni and Schoenhagen, Paul-Henry and VanValkenburg, MaryAnn and Rundensteiner, Elke and Harrison, Lane},
title = {Evaluating Preference Collection Methods for Interactive Ranking Analytics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300742},
abstract = {Rankings distill a large number of factors into simple comparative models to facilitate
complex decision making. Yet key questions remain in the design of mixed-initiative
systems for ranking, in particular how best to collect users' preferences to produce
high-quality rankings that users trust and employ in the real world. To address this
challenge we evaluate the relative merits of three preference collection methods for
ranking in a crowdsourced study. We find that with a categorical binning technique,
users interact with a large amount of data quickly, organizing information using broad
strokes. Alternative interaction modes using pairwise comparisons or sub-lists result
in smaller, targeted input from users. We consider how well each interaction mode
addresses design goals for interactive ranking systems. Our study indicates that the
categorical approach provides the best value-added benefit to users, requiring minimal
effort to create sufficient training data for the underlying ranking algorithm.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300743,
author = {Lee, Yi-Chen and Cherng, Fu-Yin and King, Jung-Tai and Lin, Wen-Chieh},
title = {To Repeat or Not to Repeat? Redesigning Repeating Auditory Alarms Based on EEG Analysis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300743},
abstract = {Auditory alarms that repeatedly interrupt users until they react are common, especially
in the context of alarms. However, when an alarm repeats, our brains habituate to
it and perceive it less and less, with reductions in both perception and attention-shifting:
a phenomenon known as the repetition-suppression effect (RS). To retain users' perception
and attention, this paper proposes and tests the use of pitch- and intensity-modulated
alarms. Its experimental findings suggest that the proposed modulated alarms can reduce
RS, albeit in different patterns, depending on whether pitch or intensity is the focus
of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more
when the number of repetitions was small, while intensity-modulated alarms reduced
it more as the number of repetitions increased. Based on these results, we make several
recommendations for the design of improved repeating alarms, based on which modulation
approach should be adopted in various situations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300744,
author = {Koushik, Varsha and Kane, Shaun K.},
title = {"It Broadens My Mind": Empowering People with Cognitive Disabilities through Computing Education},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300744},
abstract = {Computer science education is widely viewed as a path to empowerment for young people,
potentially leading to higher education, careers, and development of computational
thinking skills. However, few resources exist for people with cognitive disabilities
to learn computer science. In this paper, we document our observations of a successful
program in which young adults with cognitive disabilities are trained in computing
concepts. Through field observations and interviews, we identify instructional strategies
used by this group, accessibility challenges encountered by this group, and how instructors
and students leverage peer learning to support technical education. Our findings lead
to guidelines for developing tools and curricula to support young adults with cognitive
disabilities in learning computer science.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300745,
author = {Nissen, Bettina and Neumann, Victoria and Mikusz, Mateusz and Gianni, Rory and Clinch, Sarah and Speed, Chris and Davies, Nigel},
title = {Should I Agree? Delegating Consent Decisions Beyond the Individual},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300745},
abstract = {Obtaining meaningful user consent is increasingly problematic in a world of numerous,
heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions)
are rooted in the idea of individual control despite growing evidence that users do
not (or cannot) exercise such control in informed ways. We consider an alternative
approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties
including friends, experts, groups and AI entities. We present the results of a study
that used a technology probe at a large festival to explore initial public responses
to this reframing -- focusing on when and to whom users would delegate such decisions.
The results reveal substantial public interest in delegating consent and identify
differing preferences depending on the privacy context, highlighting the need for
alternative decision mechanisms beyond the current focus on individual choice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300746,
author = {Wu, Shaomei and Reynolds, Lindsay and Li, Xian and Guzm\'{a}n, Francisco},
title = {Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300746},
abstract = {People with dyslexia face challenges expressing themselves in writing on social networking
sites (SNSs). Such challenges come from not only the technicality of writing, but
also the self-representation aspect of sharing and communicating publicly on social
networking sites such as Facebook. To empower people with dyslexia-style writing to
express them-selves more confidently on SNSs, we designed and implemented Additional
Writing Help(AWH) - a writing assistance tool to proofread text produced by users
with dyslexia before they post on Facebook. AWH was powered by a neural machine translation
(NMT) model that translates dyslexia style to non-dyslexia style writing. We evaluated
the performance and the design of AWH through a week-long field study with 19 people
with dyslexia and received highly positive feedback. Our field study demonstrated
the value of providing better and more extensive writing support on SNSs, and the
potential of AI for building a more inclusive Internet.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300747,
author = {Shi, Weinan and Yu, Chun and Fan, Shuyi and Wang, Feng and Wang, Tong and Yi, Xin and Bi, Xiaojun and Shi, Yuanchun},
title = {VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300747},
abstract = {Modern touchscreen keyboards are all powered by the word-level auto-correction ability
to handle input errors. Unfortunately, visually impaired users are deprived of such
benefit because a screen-reader keyboard offers only character-level input and provides
no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually
impaired people, which aims at improving the underlying keyboard algorithm without
altering the current input interaction. Upon each tap, VIPBoard predicts the probability
of each key considering both touch location and language model, and reads the most
likely key, which saves the calibration time when the touchdown point misses the target
key. Meanwhile, the keyboard layout automatically scales according to users' touch
point location, which enables them to select other keys easily. A user study shows
that compared with the current keyboard technique, VIPBoard can reduce touch error
rate by 63.0% and increase text entry speed by 12.6%.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300748,
author = {Petelka, Justin and Zou, Yixin and Schaub, Florian},
title = {Put Your Warning Where Your Link Is: Improving and Evaluating Email Phishing Warnings},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300748},
abstract = {Phishing emails often disguise a link's actual URL. Thus, common anti-phishing advice
is to check a link's URL before clicking, but email clients do not support this well.
Automated phishing detection enables email clients to warn users that an email is
suspicious, but current warnings are often not specific. We evaluated the effects
on phishing susceptibility of (1) moving phishing warnings close to the suspicious
link in the email, (2) displaying the warning on hover interactions with the link,
and (3) forcing attention to the warning by deactivating the original link, forcing
users to click the URL in the warning. We assessed the effectiveness of such link-focused
phishing warning designs in a between-subjects online experiment (n=701). We found
that link-focused phishing warnings reduced phishing click-through rates compared
to email banner warnings; forced attention warnings were most effective. We discuss
the implications of our findings for phishing warning design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300749,
author = {Nachtigall, Troy and Tomico, Oscar and Wakkary, Ron and van Dongen, Pauline},
title = {Encoding Materials and Data for Iterative Personalization},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300749},
abstract = {Data is changing how we design consumer products. Shoe production is a prime example
of this; foot size, footstep pressure and personal preferences can be used to design
personalized shoes. Research done around metamaterials, programming materials and
computational composites illustrate the possibilities of creating complex data &amp; material
relationships. These new relationships allow us to look at future products almost
like software apps, becoming a kind of product service systems, where the focus is
on its iterative personalization improvement over time. Can we create systems of such
data driven objects that in turn allow us to design new objects that are informed
by the data trail? In this paper we report on four RtD project iterations that explore
this challenge and provide a set of insights on how to close this new iterative loop.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300750,
author = {Roy, Quentin and Zhang, Futian and Vogel, Daniel},
title = {Automation Accuracy Is Good, but High Controllability May Be Better},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300750},
abstract = {When automating tasks using some form of artificial intelligence, some inaccuracy
in the result is virtually unavoidable. In many cases, the user must decide whether
to try the automated method again, or fix it themselves using the available user interface.
We argue this decision is influenced by both perceived automation accuracy and degree
of task "controllability" (how easily and to what extent an automated result can be
manually modified). This relationship between accuracy and controllability is investigated
in a 750-participant crowdsourced experiment using a controlled, gamified task. With
high controllability, self-reported satisfaction remained constant even under very
low accuracy conditions, and overall, a strong preference was observed for using manual
control rather than automation, despite much slower performance and regardless of
very poor controllability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8}
}

@inbook{10.1145/3290605.3300751,
author = {Arora, Jatin and Mathur, Kartik and Saini, Aryan and Parnami, Aman},
title = {Gehna: Exploring the Design Space of Jewelry as an Input Modality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300751},
abstract = {Jewelry weaves into our everyday lives as no other wearable does. It comes in many
wearable forms, is fashionable, and can adorn any part of the body. In this paper,
through an exploratory, Research through Design (RtD) process, we tap into this vast
potential space of input interaction that jewelry can enable. We do so by first identifying
a small set of fundamental structural elements --- called Jewelements --- that any
jewelry is composed of, and then defining their properties that enable the interaction.
We leverage this synthesis along with observational data and literature to formulate
a design space of jewelry-enabled input techniques. This work encapsulates both the
extensions of common existing input methods (e.g., touch) as well as new ones inspired
by jewelry. Furthermore, we discuss our prototypical sensor-based implementations.
Through this work, we invite the community to engage in the conversation on how jewelry
as a material can help shape wearable-based input.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300752,
author = {Abtahi, Parastoo and Gonzalez-Franco, Mar and Ofek, Eyal and Steed, Anthony},
title = {I'm a Giant: Walking in Large Virtual Environments at High Speed Gains},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300752},
abstract = {Advances in tracking technology and wireless headsets enable walking as a means of
locomotion in Virtual Reality. When exploring virtual environments larger than room-scale,
it is often desirable to increase users' perceived walking speed, for which we investigate
three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them
to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature,
while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements
along their walking path. We conduct a study comparing these methods and find that
users feel most embodied using Ground-Level Scaling and consequently increase their
stride length. Using Seven-League Boots, unlike the other two methods, diminishes
positional accuracy at high gains, and users modify their walking behavior to compensate
for the lack of control. We conclude with a discussion on each technique's strength
and weaknesses and the types of situation they might be appropriate for.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300753,
author = {Schneegass, Stefan and Poguntke, Romina and Machulla, Tonja},
title = {Understanding the Impact of Information Representation on Willingness to Share Information},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300753},
abstract = {Since the release of the first activity tracker, there has been a steady increase
in the number of sensors embedded in wearable devices and with it in the amount and
diversity of information that can be derived from these sensors. This development
leads to novel privacy threats for users. In a web survey with 248 participants, we
explored whether users' willingness to share private data is dependent on how the
data is requested by an application. Specifically, requests can be formulated as access
to sensor data or as access to information derived from the sensor data (e.g., accelerometer
vs. sleep quality). We show that non-expert users lack an understanding of how the
two representation levels relate to each other. The results suggest that the willingness
to share sensor data over derived information is governed by whether the derived information
has positive or negative connotations (e.g., training intensity vs. life expectancy).
Using the results of the survey, we derive implications for supporting users in protecting
their private data collected via wearable sensors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6}
}

@inbook{10.1145/3290605.3300754,
author = {Li, Qisheng and Morris, Meredith Ringel and Fourney, Adam and Larson, Kevin and Reinecke, Katharina},
title = {The Impact of Web Browser Reader Views on Reading Speed and User Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300754},
abstract = {As reading increasingly shifts from paper to online media, many web browsers now provide
a "Reader View,'' which modifies web page layout and design for better readability.
However, research has yet to establish whether Reader Views are effective in improving
readability and how they might change the user experience. We characterize how Mozilla
Firefox's Reader View significantly reduces the visual complexity of websites by excluding
menus, images, and content. We then conducted an online study with 391 participants
(including 42 who self-reported having been diagnosed with dyslexia), showing that
compared to standard websites the Reader View increased reading speed by 5% for readers
on average, and significantly improved perceived readability and visual appeal. We
suggest guidelines for the design of websites and browsers that better support people
with varying reading skills.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300755,
author = {Vaidya, Tavish and Votipka, Daniel and Mazurek, Michelle L. and Sherr, Micah},
title = {Does Being Verified Make You More Credible? Account Verification's Effect on Tweet Credibility},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300755},
abstract = {Many popular social networking and microblogging sites support verified accounts---user
accounts that are deemed of public interest and whose owners have been authenticated
by the site. Importantly, the content of messages contributed by verified account
owners is not verified. Such messages may be factually correct, or not. This paper
investigates whether users confuse authenticity with credibility by posing the question:
Are users more likely to believe content from verified accounts than from non-verified
accounts? We conduct two online studies, a year apart, with 748 and 2041 participants
respectively, to assess how the presence or absence of verified account indicators
influences users' perceptions of tweets. Surprisingly, across both studies, we find
that---in the context of unfamiliar accounts---most users can effectively distinguish
between authenticity and credibility. The presence or absence of an authenticity indicator
has no significant effect on willingness to share a tweet or take action based on
its contents.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300756,
author = {Lee, Hao-Ping and Chen, Kuan-Yin and Lin, Chih-Heng and Chen, Chia-Yu and Chung, Yu-Lin and Chang, Yung-Ju and Sun, Chien-Ru},
title = {Does <i>Who</i> Matter? Studying the Impact of Relationship Characteristics on Receptivity to Mobile IM Messages},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300756},
abstract = {This study examines the characteristics of mobile instant-messaging users' relationships
with their social contacts and the effects of both relationship and interruption context
on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility,
and Opportuneness. Overall, interruption context overshadows relationship characteristics
as predictors of all four of these facets of receptivity; this overshadowing was most
acute for Interruptibility and Opportuneness, but existed for all factors. In addition,
while Mobile Maintenance Expectation and Activity Engagement were negatively correlated
with all receptivity measures, each such measure had its own set of predictors, highlighting
the conceptual differences among the measures. Finally, delving more deeply into potential
relationship effects, we found that a single, simple closeness question was as effective
at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300757,
author = {Auxier, Brooke E. and Buntain, Cody L. and Jaeger, Paul and Golbeck, Jennifer and Kacorri, Hernisa},
title = {#HandsOffMyADA: A Twitter Response to the ADA Education and Reform Act},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300757},
abstract = {Twitter continues to be used increasingly for communication related advocacy, activism,
and social change. This is also the case for the disability community. In light of
the recently proposed ADA Education and Reform in the United States, we investigate
factors for effectiveness of sharing or retweeting messages about topics affecting
the rights of people with disabilities. We perform a multifaceted study of the #HandsOffMyADA
campaign against the proposed H.R.620 bill to: (1) explore how communication via Twitter
compares to previous disability rights movements; (2) characterize the campaign in
terms of hashtags, user groups, and content such as accessible multimedia that contribute
to dissemination of campaign messages; (3) identify major themes in tweets and responses,
and their variation among user groups; and (4) understand how the disability community
mobilized for this campaign compared to previous Twitter initiatives.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300758,
author = {Tanner, Kesler and Johnson, Naomi and Landay, James A.},
title = {Poirot: A Web Inspector for Designers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300758},
abstract = {To better understand the issues designers face as they interact with developers and
use developer tools to create websites, we conducted a formative investigation consisting
of interviews, a survey, and an analysis of professional design documents. Based on
insights gained from these efforts, we developed Poirot, a web inspection tool for
designers that enables them to make style edits to websites using a familiar graphical
interface. We compared Poirot to Chrome DevTools in a lab study with 16 design professionals.
We observed common problems designers experience when using Chrome DevTools and found
that when using Poirot, designers were more successful in accomplishing typical design
tasks (97% to 63%). In addition, we found that Poirot had a significantly lower perceived
cognitive load and was overwhelmingly preferred by the designers in our study.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300759,
author = {Lee, Sooyeon and Hubert-Wallander, Bjorn and Stevens, Molly and Carroll, John M.},
title = {Understanding and Designing for Deaf or Hard of Hearing Drivers on Uber},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300759},
abstract = {We used content analysis of in-app driver survey responses, customer support tickets,
and tweets, and face-to-face interviews of DHH Uber drivers to better understand the
DHH driver experience. Here we describe challenges DHH drivers experience and how
they address those difficulties via Uber's accessibility features and their own workarounds.
We also identify and discuss design and product opportunities to improve the DHH driver
experience on Uber.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300760,
author = {Alkhatib, Ali and Bernstein, Michael},
title = {Street-Level Algorithms: A Theory at the Gaps Between Policy and Decisions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300760},
abstract = {Errors and biases are earning algorithms increasingly malignant reputations in society.
A central challenge is that algorithms must bridge the gap between high-level policy
and on-the-ground decisions, making inferences in novel situations where the policy
or training data do not readily apply. In this paper, we draw on the theory of street-level
bureaucracies, how human bureaucrats such as police and judges interpret policy to
make on-the-ground decisions. We present by analogy a theory of street-level algorithms,
the algorithms that bridge the gaps between policy and decisions about people in a
socio-technical system. We argue that unlike street-level bureaucrats, who reflexively
refine their decision criteria as they reason through a novel situation, street-level
algorithms at best refine their criteria only after the decision is made. This loop-and-a-half
delay results in illogical decisions when handling new or extenuating circumstances.
This theory suggests designs for street-level algorithms that draw on historical design
patterns for street-level bureaucracies, including mechanisms for self-policing and
recourse in the case of error.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300761,
author = {Chen, Quanze and Bragg, Jonathan and Chilton, Lydia B. and Weld, Dan S.},
title = {Cicero: Multi-Turn, Contextual Argumentation for Accurate Crowdsourcing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300761},
abstract = {Traditional approaches for ensuring high quality crowdwork have failed to achieve
high-accuracy on difficult problems. Aggregating redundant answers often fails on
the hardest problems when the majority is confused. Argumentation has been shown to
be effective in mitigating these drawbacks. However, existing argumentation systems
only support limited interactions and show workers general justifications, not context-specific
arguments targeted to their reasoning. This paper presents Cicero, a new workflow
that improves crowd accuracy on difficult tasks by engaging workers in multi-turn,
contextual discussions through real-time, synchronous argumentation. Our experiments
show that compared to previous argumentation systems which only improve the average
individual worker accuracy by 6.8 percentage points on the Relation Extraction domain,
our workflow achieves 16.7 percentage point improvement. Furthermore, previous argumentation
approaches don't apply to tasks with many possible answers; in contrast, Cicero works
well in these cases, raising accuracy from 66.7% to 98.8% on the Codenames domain.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300762,
author = {Vinayagamoorthy, Vinoba and Glancy, Maxine and Ziegler, Christoph and Sch\"{a}ffer, Richard},
title = {Personalising the TV Experience Using Augmented Reality: An Exploratory Study on Delivering Synchronised Sign Language Interpretation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300762},
abstract = {Augmented Reality (AR) technology has the potential to extend the screen area beyond
the rigid frames of televisions. The additional display area can be used to augment
televisions (TVs) with extra information tailored to individuals, for instance, the
provision of access services like sign language interpretations. We invited 23 (11
in the UK, 12 in Germany) users of signed content to evaluate three methods of watching
a sign language interpreted programme - one traditional in-vision method with signed
programme content on TV and two AR-enabled methods in which an AR sign language interpreter
(a 'half-body' version and a 'full-body' version) is projected just outside the frame
of the TV presenting the programme. In the UK, participants were split 3-ways in their
preferences while in Germany, half the participants preferred the traditional method
followed closely by the 'half-body' version. We discuss our participants reasoning
behind their preferences and implications for future research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300763,
author = {Fafard, Dylan and Stavness, Ian and Dechant, Martin and Mandryk, Regan and Zhou, Qian and Fels, Sidney},
title = {FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300763},
abstract = {Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual "crystal
ball" experience using head-tracked rendering. Almost all of these systems have omitted
stereo cues, making them easy to build, but it is not clear how much this omission
degrades the 3D experience. In this study, we evaluate performance and subjective
effects of stereo on 3D perception and interaction tasks with a spherical FTVR display.
To control for calibration error and tracking latency, we perform the evaluation on
a simulated spherical display in VR. The results of our study provide a clear recommendation
for the design and use of spherical FTVR displays: while omitting stereo may not be
readily apparent for users, their performance will be significantly degraded (20%
- 91% increase in median task time). Therefore, including stereo viewing in spherical
displays is critical for use in FTVR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300764,
author = {Emami-Naeini, Pardis and Dixon, Henry and Agarwal, Yuvraj and Cranor, Lorrie Faith},
title = {Exploring How Privacy and Security Factor into IoT Device Purchase Behavior},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300764},
abstract = {Despite growing concerns about security and privacy of Internet of Things (IoT) devices,
consumers generally do not have access to security and privacy information when purchasing
these devices. We interviewed 24 participants about IoT devices they purchased. While
most had not considered privacy and security prior to purchase, they reported becoming
concerned later due to media reports, opinions shared by friends, or observing unexpected
device behavior. Those who sought privacy and security information before purchase,
reported that it was difficult or impossible to find. We asked interviewees to rank
factors they would consider when purchasing IoT devices; after features and price,
privacy and security were ranked among the most important. Finally, we showed interviewees
our prototype privacy and security label. Almost all found it to be accessible and
useful, encouraging them to incorporate privacy and security in their IoT purchase
decisions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300765,
author = {Schuetz, Immo and Murdison, T. Scott and MacKenzie, Kevin J. and Zannoli, Marina},
title = {An Explanation of Fitts' Law-like Performance in Gaze-Based Selection Tasks Using a Psychophysics Approach},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300765},
abstract = {Eye gaze as an input method has been studied since the 1990s, to varied results: some
studies found gaze to be more efficient than traditional input methods like a mouse,
others far behind. Comparisons are often backed up by Fitts' Law without explicitly
acknowledging the ballistic nature of saccadic eye movements. Using a vision science-inspired
model, we here show that a Fitts'-like distribution of movement times can arise due
to the execution of secondary saccades, especially when targets are small. Study participants
selected circular targets using gaze. Seven different target sizes and two saccade
distances were used. We then determined performance across target sizes for different
sampling windows ("dwell times") and predicted an optimal dwell time range. Best performance
was achieved for large targets reachable by a single saccade. Our findings highlight
that Fitts' Law, while a suitable approximation in some cases, is an incomplete description
of gaze interaction dynamics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300766,
author = {Tan, Sheng and Zhang, Linghan and Wang, Zi and Yang, Jie},
title = {MultiTrack: Multi-User Tracking and Activity Recognition Using Commodity WiFi},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300766},
abstract = {This paper presents MultiTrack, a commodity WiFi based human sensing system that can
track multiple users and recognize activities of multiple users performing them simultaneously.
Such a system can enable easy and large-scale deployment for multi-user tracking and
sensing without the need for additional sensors through the use of existing WiFi devices
(e.g., desktops, laptops and smart appliances). The basic idea is to identify and
extract the signal reflection corresponding to each individual user with the help
of multiple WiFi links and all the available WiFi channels at 5GHz. Given the extracted
signal reflection of each user, MultiTrack examines the path of the reflected signals
at multiple links to simultaneously track multiple users. It further reconstructs
the signal profile of each user as if only a single user has performed activity in
the environment to facilitate multi-user activity recognition. We evaluate MultiTrack
in different multipath environments with up to 4 users for multi-user tracking and
up to 3 users for activity recognition. Experimental results show that our system
can achieve decimeter localization accuracy and over 92% activity recognition accuracy
under multi-user scenarios.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300767,
author = {Speicher, Maximilian and Hall, Brian D. and Nebeling, Michael},
title = {What is Mixed Reality?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300767},
abstract = {What is Mixed Reality (MR)? To revisit this question given the many recent developments,
we conducted interviews with ten AR/VR experts from academia and industry, as well
as a literature survey of 68 papers. We find that, while there are prominent examples,
there is no universally agreed on, one-size-fits-all definition of MR. Rather, we
identified six partially competing notions from the literature and experts' responses.
We then started to isolate the different aspects of reality relevant for MR experiences,
going beyond the primarily visual notions and extending to audio, motion, haptics,
taste, and smell. We distill our findings into a conceptual framework with seven dimensions
to characterize MR applications in terms of the number of environments, number of
users, level of immersion, level of virtuality, degree of interaction, input, and
output. Our goal with this paper is to support classification and discussion of MR
applications' design and provide a better means to researchers to contextualize their
work within the increasingly fragmented MR landscape.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300768,
author = {Sundar, S. Shyam and Kim, Jinyoung},
title = {Machine Heuristic: When We Trust Computers More than Humans with Our Personal Information},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300768},
abstract = {In this day and age of identity theft, are we likely to trust machines more than humans
for handling our personal information? We answer this question by invoking the concept
of "machine heuristic," which is a rule of thumb that machines are more secure and
trustworthy than humans. In an experiment (N = 160) that involved making airline reservations,
users were more likely to reveal their credit card information to a machine agent
than a human agent. We demonstrate that cues on the interface trigger the machine
heuristic by showing that those with higher cognitive accessibility of the heuristic
(i.e., stronger prior belief in the rule of thumb) were more likely than those with
lower accessibility to disclose to a machine, but they did not differ in their disclosure
to a human. These findings have implications for design of interface cues conveying
machine vs. human sources of our online interactions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300769,
author = {Bharadwaj, Aditya and Siangliulue, Pao and Marcus, Adam and Luther, Kurt},
title = {Critter: Augmenting Creative Work with Dynamic Checklists, Automated Quality Assurance, and Contextual Reviewer Feedback},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300769},
abstract = {Checklists and guidelines have played an increasingly important role in complex tasks
ranging from the cockpit to the operating theater. Their role in creative tasks like
design is less explored. In a needfinding study with expert web designers, we identified
designers' challenges in adhering to a checklist of design guidelines. We built Critter,
which addressed these challenges with three components: Dynamic Checklists that progressively
disclose guideline complexity with a self-pruning hierarchical view, AutoQA to automate
common quality assurance checks, and guideline-specific feedback provided by a reviewer
to highlight mistakes as they appear. In an observational study, we found that the
more engaged a designer was with Critter, the fewer mistakes they made in following
design guidelines. Designers rated the AutoQA and contextual feedback experience highly,
and provided feedback on the tradeoffs of the hierarchical Dynamic Checklists. We
additionally found that a majority of designers rated the AutoQA experience as excellent
and felt that it increased the quality of their work. Finally, we discuss broader
implications for supporting complex creative tasks.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300770,
author = {Taneja, Harsh and Yaeger, Katie},
title = {Do People Consume the News They Trust?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300770},
abstract = {It is reasonable to expect trusted news organizations to have more engaged users.
However, given the lowest levels of trust in media and the several intermediaries
involved in digital news consumption, recent studies posit that trust and usage may
not be related. We argue that while trust may not relate to overall news usage, given
that much of it is incidental, but it could still explain intentional usage. We correlated
passively metered usage from digital trace data on 35 national news outlets in the
US with their trustworthiness from a nationally representative survey, for three discrete
months. We find no association between trust and overall user engagement, but a positive
relationship between trustworthiness and direct visits, the latter a measure of intentional
usage. These relationships held for outlets despite their partisan leanings, multi-platform
presence and their mainstream nature.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300771,
author = {Veras, Rafael and Collins, Christopher},
title = {Saliency Deficit and Motion Outlier Detection in Animated Scatterplots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300771},
abstract = {We report the results of a crowdsourced experiment that measured the accuracy of motion
outlier detection in multivariate, animated scatterplots. The targets were outliers
either in speed or direction of motion, and were presented with varying levels of
saliency in dimensions that are irrelevant to the task of motion outlier detection
(e.g., color, size, position). We found that participants had trouble finding the
outlier when it lacked irrelevant salient features and that visual channels contribute
unevenly to the odds of an outlier being correctly detected. Direction of motion contributes
the most to accurate detection of speed outliers, and position contributes the most
to accurate detection of direction outliers. We introduce the concept of saliency
deficit in which item importance in the data space is not reflected in the visualization
due to a lack of saliency. We conclude that motion outlier detection is not well supported
in multivariate animated scatterplots.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300772,
author = {Yang, Xi and Aurisicchio, Marco and Baxter, Weston},
title = {Understanding Affective Experiences with Conversational Agents},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300772},
abstract = {While previous studies of Conversational Agents (e.g. Siri, Google Assistant, Alexa
and Cortana) have focused on evaluating usability and exploring capabilities of these
systems, little work has examined users' affective experiences. In this paper we present
a survey study with 171 participants to examine CA users' affective experiences. Specifically,
we present four major usage scenarios, users' affective responses in these scenarios,
and the factors which influenced the affective responses. We found that users' overall
experience was positive with interest being the most salient positive emotion. Affective
responses differed depending on the scenarios. Both pragmatic and hedonic qualities
influenced affect. The factors underlying pragmatic quality are: helpfulness, proactivity,
fluidity, seamlessness and responsiveness. The factors underlying hedonic quality
are: comfort in human-machine conversation, pride of using cutting-edge technology,
fun during use, perception of having a human-like assistant, concern about privacy
and fear of causing distraction.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300773,
author = {Barbosa, Nat\~{a} M. and Chen, Monchu},
title = {Rehumanized Crowdsourcing: A Labeling Framework Addressing Bias and Ethics in Machine Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300773},
abstract = {The increased use of machine learning in recent years led to large volumes of data
being manually labeled via crowdsourcing microtasks completed by humans. This brought
about dehumanization effects, namely, when task requesters overlook the humans behind
the task, leading to issues of ethics (e.g., unfair payment) and amplification of
human biases, which are transferred into training data and affect machine learning
in the real world. We propose a framework that allocates microtasks considering human
factors of workers such as demographics and compensation. We deployed our framework
to a popular crowdsourcing platform and conducted experiments with 1,919 workers collecting
160,345 human judgments. By routing microtasks to workers based on demographics and
appropriate pay, our framework mitigates biases in the contributor sample and increases
the hourly pay given to contributors. We discuss potential extensions and how it can
promote transparency in crowdsourcing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300774,
author = {Radu, Iulian and Schneider, Bertrand},
title = {What Can We Learn from Augmented Reality (AR)? Benefits and Drawbacks of AR for Inquiry-Based Learning of Physics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300774},
abstract = {Emerging technologies such as Augmented Reality (AR), have the potential to radically
transform education by making challenging concepts visible and accessible to novices.
In this project, we have designed a Hololens-based system in which collaborators are
exposed to an unstructured learning activity in which they learned about the invisible
physics involved in audio speakers. They learned topics ranging from spatial knowledge,
such as shape of magnetic fields, to abstract conceptual knowledge, such as relationships
between electricity and magnetism. We compared participants' learning, attitudes and
collaboration with a tangible interface through multiple experimental conditions containing
varying layers of AR information. We found that educational AR representations were
beneficial for learning specific knowledge and increasing participants' self-efficacy
(i.e., their ability to learn concepts in physics). However, we also found that participants
in conditions that did not contain AR educational content, learned some concepts better
than other groups and became more curious about physics. We discuss learning and collaboration
differences, as well as benefits and detriments of implementing augmented reality
for unstructured learning activities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300775,
author = {Shahmiri, Fereshteh and Chen, Chaoyu and Waghmare, Anandghan and Zhang, Dingtian and Mittal, Shivan and Zhang, Steven L. and Wang, Yi-Cheng and Wang, Zhong Lin and Starner, Thad E. and Abowd, Gregory D.},
title = {Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300775},
abstract = {We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord
capable of sensing a variety of human input. The material properties and structural
design of Serpentine allow it to be flexible, twistable, stretchable and squeezable,
enabling a broad variety of expressive input modalities. The sensor operates using
the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical
deformation without an external power source. The affordances of the cord include
six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates
the ability to simultaneously recognize these inputs through a single physical interface.
A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition
model using a realtime system and 92.17% for user-independent offline detection. We
conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing
applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300776,
author = {Hoppe, Matthias and Karolus, Jakob and Dietz, Felix and Wo\'{z}niak, Pawe\l{} W. and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300776},
abstract = {While Virtual Reality continues to increase in fidelity, it remains an open question
how to effectively reflect the user's movements and provide congruent feedback in
virtual environments. We present VRsneaky, a system for producing auditory movement
feedback, which helps participants orient themselves in a virtual environment by providing
footstep sounds. The system reacts to the user's specific gait features and adjusts
the audio accordingly. In a user study with 28 participants, we found that VRsneaky
increases users' sense of presence as well as awareness of their own posture and gait.
Additionally, we find that increasing auditory realism significantly influences certain
characteristics of participants' gait. Our work shows that gait-aware audio feedback
is a means to increase presence in virtual environments. We discuss opportunities
and design requirements for future scenarios where users walk through immersive virtual
worlds.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300777,
author = {Kulp, Leah and Sarcevic, Aleksandra and Cheng, Megan and Zheng, Yinan and Burd, Randall S.},
title = {Comparing the Effects of Paper and Digital Checklists on Team Performance in Time-Critical Work},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300777},
abstract = {This mixed-methods study examines the effects of a tablet-based checklist system on
team performance during a dynamic and safety-critical process of trauma resuscitation.
We compared team performance from 47 resuscitations that used a paper checklist to
that from 47 cases with a digital checklist to determine if digitizing a checklist
led to improvements in task completion rates and in how fast the tasks were initiated
for 18 most critical assessment and treatment tasks. We also compared if the checklist
compliance increased with the digital design. We found that using the digital checklist
led to more frequent completions of the initial airway assessment task but fewer completions
of ear and lower extremities exams. We did not observe any significant differences
in time to task performance, but found increased compliance with the checklist. Although
improvements in team performance with the digital checklist were minor, our findings
are important because they showed no adverse effects as a result of the digital checklist
introduction. We conclude by discussing the takeaways and implications of these results
for effective digitization of medical work.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300778,
author = {Hsu, Chen-Yu and Hristov, Rumen and Lee, Guang-He and Zhao, Mingmin and Katabi, Dina},
title = {Enabling Identification and Behavioral Sensing in Homes Using Radio Reflections},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300778},
abstract = {Understanding users' behavior at home is central to behavioral research. For example,
social researchers are interested in studying domestic abuse, and healthcare professionals
are interested in caregiver-patient interaction. Today, such studies rely on diaries
and questionnaires, which are subjective, erroneous, and hard to sustain in longitudinal
studies. We introduce Marko, a system that automatically collects behavior-related
data, without asking people to write diaries or wear sensors. Marko transmits a low
power wireless signal and analyses its reflections from the environment. It maps those
reflections to how users interact with the environment (e.g., access to medication
cabinet) and with each other (e.g., watch TV together). It provides novel algorithms
for identifying who-does-what, and bootstrapping the system in new homes without asking
users for new annotations. We evaluate Marko with a one-month deployment in six homes,
and demonstrate its value for studying couple relationships and caregiver-patient
interaction.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300779,
author = {Mayer, Peter and Gerber, Nina and Reinheimer, Benjamin and Rack, Philipp and Braun, Kristoffer and Volkamer, Melanie},
title = {I (Don't) See What You Typed There! Shoulder-Surfing Resistant Password Entry on Gamepads},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300779},
abstract = {Using gamepad-driven devices like games consoles is an activity frequently shared
with others. Thus, shoulder-surfing is a serious threat. To address this threat, we
present the first investigation of shoulder-surfing resistant text password entry
on gamepads by (1) identifying the requirements of this context; (2) assessing whether
shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts
can be viably adapted to meet these requirements; (3) proposing "Colorwheels", a novel
shoulder-surfing resistant authentication scheme specifically geared towards this
context; (4) using two different methodologies proposed in the literature for evaluating
shoulder-surfing resistance to compare "Colorwheels", on-screen keyboards (the de
facto standard in this context), and an existing shoulder-surfing resistant scheme
which we identified during our assessment and adapted for the gamepad context; (5)
evaluating all three schemes regarding their usability. Having applied different methodologies
to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and
derive recommendations for future research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300780,
author = {Kim, Joohwan and Stengel, Michael and Majercik, Alexander and De Mello, Shalini and Dunn, David and Laine, Samuli and McGuire, Morgan and Luebke, David},
title = {NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300780},
abstract = {Quality, diversity, and size of training data are critical factors for learning-based
gaze estimators. We create two datasets satisfying these criteria for near-eye gaze
estimation under infrared illumination: a synthetic dataset using anatomically-informed
eye and face models with variations in face shape, gaze direction, pupil and iris,
skin tone, and external conditions (2M images at 1280x960), and a real-world dataset
collected with 35 subjects (2.5M images at 640x480). Using these datasets we train
neural networks performing with sub-millisecond latency. Our gaze estimation network
achieves 2.06(±0.44)° of accuracy across a wide 30°\texttimes{}40° field of view on real subjects
excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly
trained for one real subject. We also train a pupil localization network which achieves
higher robustness than previous methods.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300781,
author = {Sarkar, Anurag and Cooper, Seth},
title = {Transforming Game Difficulty Curves Using Function Composition},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300781},
abstract = {Player engagement within a game is often influenced by its difficulty curve: the pace
at which in-game challenges become harder. Thus, finding an optimal difficulty curve
is important. In this paper, we present a flexible and formal approach to transforming
game difficulty curves by leveraging function composition. This allows us to describe
changes to difficulty curves, such as making them "smoother", in a more precise way.
In an experiment with 400 players, we used function composition to modify the existing
difficulty curve of the puzzle game Paradox to generate new curves. We found that
transforming difficulty curves in this way impacted player engagement, including the
number of levels completed and the estimated skill needed to complete those levels,
as well as perceived competence. Further, we found some transformed curves dominated
others with respect to engagement, indicating that different design goals can be traded-off
by considering a subset of curves.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7}
}

@inbook{10.1145/3290605.3300782,
author = {Brackenbury, Will and Deora, Abhimanyu and Ritchey, Jillian and Vallee, Jason and He, Weijia and Wang, Guan and Littman, Michael L. and Ur, Blase},
title = {How Users Interpret Bugs in Trigger-Action Programming},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300782},
abstract = {Trigger-action programming (TAP) is a programming model enabling users to connect
services and devices by writing if-then rules. As such systems are deployed in increasingly
complex scenarios, users must be able to identify programming bugs and reason about
how to fix them. We first systematize the temporal paradigms through which TAP systems
could express rules. We then identify ten classes of TAP programming bugs related
to control flow, timing, and inaccurate user expectations. We report on a 153-participant
online study where participants were assigned to a temporal paradigm and shown a series
of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes.
For most of the bug classes, we found that the presence of a bug made it harder for
participants to correctly predict the behavior of the rule. Our findings suggest directions
for better supporting end-user programmers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300783,
author = {Ben-Sasson, Ayelet and Ben-Sasson, Eli and Jacobs, Kayla and Argaman, Elisheva Rotman and Saig, Eden},
title = {Evaluating Expert Curation in a Baby Milestone Tracking App},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300783},
abstract = {Early childhood developmental screening is critical for timely detection and intervention.
babyTRACKS (Formerly Baby CROINC, CROwd INtelligence Curation.) is a free, live, interactive
developmental tracking mobile app with over 3,000 children's diaries. Parents write
or select short milestone texts, like "began taking first steps," to record their
babies' developmental achievements, and receive crowd-based percentiles to evaluate
development and catch potential delays.Currently, an expert-based Curated Crowd Intelligence
(CCI) process manually groups incoming novel parent-authored milestone texts according
to their similarity to existing milestones in the database (for example, starting
to walk), or determining that the milestone represents a new developmental concept
not seen before in another child's diary. CCI cannot scale well, however, and babyTRACKS
is mature enough, with a rich enough database of existing milestone texts, to now
consider machine learning tools to replace or assist the human curators. Three new
studies explore (1) the usefulness of automation, by analyzing the human cost of CCI
and how the work is currently broken down; (2) the validity of automation, by testing
the inter-rater reliability of curators; and (3) the value of automation, by appraising
the "real world" clinical value of milestones when assessing child development.We
conclude that automation can indeed be appropriate and helpful for a large percentage,
though not all, of CCI work. We further establish realistic upper bounds for algorithm
performance; confirm that the babyTRACKS milestones dataset is valid for training
and testing purposes; and verify that it represents clinically meaningful developmental
information.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300784,
author = {Zhang, Yongqi and Xie, Biao and Huang, Haikun and Ogawa, Elisa and You, Tongjian and Yu, Lap-Fai},
title = {Pose-Guided Level Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300784},
abstract = {Player's physical experience is a critical factor to consider in designing motion-based
games that are played through motion sensor gaming consoles or virtual reality devices.
However, adjusting the physical challenge involved in a motion-based game is difficult
and tedious, as it is typically done manually by level designers on a trial-and-error
basis. In this paper, we propose a novel approach for automatically synthesizing levels
for motion-based games that can achieve desired physical movement goals. By formulating
the level design problem as a trans-dimensional optimization problem which is solved
by a reversible-jump Markov chain Monte Carlo technique, we show that our approach
can automatically synthesize a variety of game levels, each carrying the desired physical
movement properties. To demonstrate the generality of our approach, we synthesize
game levels for two different types of motion-based games and conduct a user study
to validate the effectiveness of our approach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300785,
author = {Gutwin, Carl and van der Kamp, Michael and Uddin, Md. Sami and Stanley, Kevin and Stavness, Ian and Vail, Sally},
title = {Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300785},
abstract = {Time-lapse videos are often navigated by scrubbing with a slider. When networks are
slow or images are large, however, even thumbnail versions load so slowly that scrubbing
is limited to the start of the video. We developed a frame-loading technique called
spread-loading that enables scrubbing regardless of delivery rate. Spread-loading
orders frame delivery to maximize coverage of the entire sequence; this provides a
temporal overview of the entire video that can be fully navigated at any time during
delivery. The overview initially has a coarse temporal resolution, becoming finer-grained
with each new frame. We compared spread-loading with traditional linear loading in
a study where participants were asked to find specific episodes in a long time-lapse
sequence, using three views with increasing levels of detail. Results show that participants
found target episodes significantly and substantially faster with spread-loading,
regardless of whether they could click to change the load point. Users rated spread-loading
as requiring less effort, and strongly preferred the new technique.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300786,
author = {Schwab, Michail and Hao, Sicheng and Vitek, Olga and Tompkin, James and Huang, Jeff and Borkin, Michelle A.},
title = {Evaluating Pan and Zoom Timelines and Sliders},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300786},
abstract = {Pan and zoom timelines and sliders help us navigate large time series data. However,
designing efficient interactions can be difficult. We study pan and zoom methods via
crowd-sourced experiments on mobile and computer devices, asking which designs and
interactions provide faster target acquisition. We find that visual context should
be limited for low-distance navigation, but added for far-distance navigation; that
timelines should be oriented along the longer axis, especially on mobile; and that,
as compared to default techniques, double click, hold, and rub zoom appear to scale
worse with task difficulty, whereas brush and especially ortho zoom seem to scale
better. Software and data used in this research are available as open source.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300787,
author = {Lopez, Sarah and Yang, Yi and Beltran, Kevin and Kim, Soo Jung and Cruz Hernandez, Jennifer and Simran, Chelsy and Yang, Bingkun and Yuksel, Beste F.},
title = {Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300787},
abstract = {Previous research has shown that when White people embody a black avatar in virtual
reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial
bias. In this paper, we put men in female and male avatars in VR with full visuomotor
synchrony using wearable trackers and investigated implicit gender bias and embodiment.
We found that participants embodied in female avatars displayed significantly higher
levels of implicit gender bias than those embodied in male avatars. The implicit gender
bias actually increased after exposure to female embodiment in contrast to male embodiment.
Results also showed that participants felt embodied in their avatars regardless of
gender matching, demonstrating that wearable trackers can be used for a realistic
sense of avatar embodiment in VR. We discuss the future implications of these findings
for both VR scenarios and embodiment technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300788,
author = {Seifi, Hasti and Fazlollahi, Farimah and Oppermann, Michael and Sastrillo, John Andrew and Ip, Jessica and Agrawal, Ashutosh and Park, Gunhyuk and Kuchenbecker, Katherine J. and MacLean, Karon E.},
title = {Haptipedia: Accelerating Haptic Device Discovery to Support Interaction &amp; Engineering Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300788},
abstract = {Creating haptic experiences often entails inventing, modifying, or selecting specialized
hardware. However, interaction designers are rarely engineers, and 30 years of haptic
inventions are buried in a fragmented literature that describes devices mechanically
rather than by potential purpose. We conceived of Haptipedia to unlock this trove
of examples: Haptipedia presents a device corpus for exploration through metadata
that matter to both device and interaction designers. It is a taxonomy of device attributes
that go beyond physical description to capture potential utility, applied to a growing
database of 105 grounded force-feedback devices, and accessed through a public visualization
that links utility to morphology. Haptipedia's design was driven by both systematic
review of the haptic device literature and rich input from diverse haptic designers.
We describe Haptipedia's reception (including hopes it will redefine device reporting
standards) and our plans for its sustainability through community participation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300789,
author = {Cheng, Hao-Fei and Wang, Ruotong and Zhang, Zheng and O'Connell, Fiona and Gray, Terrance and Harper, F. Maxwell and Zhu, Haiyi},
title = {Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300789},
abstract = {Increasingly, algorithms are used to make important decisions across society. However,
these algorithms are usually poorly understood, which can reduce transparency and
evoke negative emotions. In this research, we seek to learn design principles for
explanation interfaces that communicate how decision-making algorithms work, in order
to help organizations explain their decisions to stakeholders, or to support users'
"right to explanation". We conducted an online experiment where 199 participants used
different explanation interfaces to understand an algorithm for making university
admissions decisions. We measured users' objective and self-reported understanding
of the algorithm. Our results show that both interactive explanations and "white-box"
explanations (i.e. that show the inner workings of an algorithm) can improve users'
comprehension. Although the interactive approach is more effective at improving comprehension,
it comes with a trade-off of taking more time. Surprisingly, we also find that users'
trust in algorithmic decisions is not affected by the explanation interface or their
level of comprehension of the algorithm.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300790,
author = {Lee, Injung and Kim, Sunjun and Lee, Byungjoo},
title = {Geometrically Compensating Effect of End-to-End Latency in Moving-Target Selection Games},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300790},
abstract = {Effects of unintended latency on gamer performance have been reported. End-to-end
latency can be corrected by post-input manipulation of activation times, but this
gives the player unnatural gameplay experience. For moving-target selection games
such as Flappy Bird, the paper presents a predictive model of latency on error rate
and a novel compensation method for the latency effects by adjusting the game's geometry
design -- e.g., by modifying the size of the selection region. Without manipulation
of the game clock, this can keep the user's error rate constant even if the end-to-end
latency of the system changes. The approach extends the current model of moving-target
selection with two additional assumptions about the effects of latency: (1) latency
reduces players' cue-viewing time and (2) pushes the mean of the input distribution
backward. The model and method proposed have been validated through precise experiments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300791,
author = {Tran O'Leary, Jasper and Zewde, Sara and Mankoff, Jennifer and Rosner, Daniela K.},
title = {Who Gets to Future? Race, Representation, and Design Methods in Africatown},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300791},
abstract = {This paper draws on a collaborative project called the Africatown Activation to examine
the role design practices play in contributing to (or conspiring against) the flourishing
of the Black community in Seattle, Washington. Specifically, we describe the efforts
of a community group called Africatown to design and build an installation that counters
decades of disinvestment and ongoing displacement in the historically Black Central
Area neighborhood. Our analysis suggests that despite efforts to include community,
conventional design practices may perpetuate forms of institutional racism: enabling
activities of community engagement that may further legitimate racialized forms of
displacement. We discuss how focusing on amplifying the legacies of imagination already
at work may help us move beyond a simple reading of design as the solution to systemic
forms of oppression.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300792,
author = {Brudy, Frederik and Holz, Christian and R\"{a}dle, Roman and Wu, Chi-Jui and Houben, Steven and Klokmose, Clemens Nylandsted and Marquardt, Nicolai},
title = {Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300792},
abstract = {Designing interfaces or applications that move beyond the bounds of a single device
screen enables new ways to engage with digital content. Research addressing the opportunities
and challenges of interactions with multiple devices in concert is of continued focus
in HCI research. To inform the future research agenda of this field, we contribute
an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain.
For both new and experienced researchers in the field we provide: an overview, historic
trends and unified terminology of cross-device research; discussion of major and under-explored
application areas; mapping of enabling technologies; synthesis of key interaction
techniques spanning across multiple devices; and review of common evaluation strategies.
We close with a discussion of open issues. Our taxonomy aims to create a unified terminology
and common understanding for researchers in order to facilitate and stimulate future
cross-device research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–28},
numpages = {28}
}

@inbook{10.1145/3290605.3300793,
author = {Das, Maitraye and Hecht, Brent and Gergle, Darren},
title = {The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300793},
abstract = {Millions of people worldwide contribute content to peer production repositories that
serve human information needs and provide vital world knowledge to prominent artificial
intelligence systems. Yet, extreme gender participation disparities exist in which
men significantly outnumber women. A central concern has been that due to self-focus
bias, these disparities can lead to corresponding gender content disparities, in which
content of interest to men is better represented than content of interest to women.
This paper investigates the relationship between participation and content disparities
in OpenStreetMap. We replicate findings that women are dramatically under-represented
as OSM contributors, and observe that men and women contribute different types of
content and do so about different places. However, the character of these differences
confound simple narratives about self-focus bias: we find that on a proportional basis,
men produced a higher proportion of contributions in feminized spaces compared to
women, while women produced a higher proportion of contributions in masculinized spaces
compared to men.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300794,
author = {McVeigh-Schultz, Joshua and Kolesnichenko, Anya and Isbister, Katherine},
title = {Shaping Pro-Social Interaction in VR: An Emerging Design Framework},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300794},
abstract = {Commercial social VR applications represent a diverse and evolving ecology with competing
models of what it means to be social in VR. Drawing from expert interviews, this paper
examines how the creators of different social VR applications think about how their
platforms frame, support, shape, or constrain social interaction. The study covers
a range of applications including: Rec Room, High Fidelity, VRChat, Mozilla Hubs,
Altspace VR, AnyLand, and Facebook Spaces. We contextualize design choices underlying
these applications, with particular attention paid to the ways that industry experts
perceive, and seek to shape, the relationship between user experiences and design
choices. We underscore considerations related to: (1) aesthetics of place (2) embodied
affordances, (3) social mechanics, (4) and tactics for shaping social norms and mitigating
harassment. Drawing on this analysis, we discuss the stakes of these choices, suggest
future research directions, and propose an emerging design framework for shaping pro-social
behavior in VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300795,
author = {Kempe-Cook, Lucas and Sher, Stephen Tsung-Han and Su, Norman Makoto},
title = {Behind the Voices: The Practice and Challenges of Esports Casters},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300795},
abstract = {Casters commentate on a live, streamed video game for a large online audience. Drawing
from 20 semi-structured interviews with amateur casters of either Dota 2 or Rocket
League video games and over 20 hours of participant observations, we describe the
distinctive practices of two types of casters, play-by-play and color commentary.
Play-by-play casters are adept at improvising a rich narrative of hype on top of live
games, whereas color commentators methodically prepare to fill in the gaps of live
play with informative analysis. Casters often start out alone, relying upon reflective
practice to hone their craft. Through examining challenges faced by amateur casters,
we identified three design opportunities for game designers to support casters and
would-be casters as first-class users. Such designs would provide an antidote to the
challenges faced by amateur casters: those of the lack of social support for casting,
camerawork, and data availability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300796,
author = {Baudisch, Patrick and Silber, Arthur and Kommana, Yannis and Gruner, Milan and Wall, Ludwig and Reuss, Kevin and Heilman, Lukas and Kovacs, Robert and Rechlitz, Daniel and Roumen, Thijs},
title = {Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300796},
abstract = {We present an interactive editing system for laser cutting called kyub. Kyub allows
users to create models efficiently in 3D, which it then unfolds into the 2D plates
laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction
based on closed box structures, which allows users to turn very thin material, such
as 4mm plywood, into objects capable of withstanding large forces, such as chairs
users can actually sit on. To afford such sturdy construction, every kyub project
begins with a simple finger-joint "boxel"-a structure we found to be capable of withstanding
over 500kg of load. Users then extend their model by attaching additional boxels.
Boxels merge automatically, resulting in larger, yet equally strong structures. While
the concept of stacking boxels allows kyub to offer the strong affordance and ease
of use of a voxel-based editor, boxels are not confined to a grid and readily combine
with kuyb's various geometry deformation tools. In our technical evaluation, objects
built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers
rated the learnability of kyub 6.1/7.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300797,
author = {Swaminathan, Saiganesh and Ozutemiz, Kadri Bugra and Majidi, Carmel and Hudson, Scott E.},
title = {FiberWire: Embedding Electronic Function into 3D Printed Mechanically Strong, Lightweight Carbon Fiber Composite Objects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300797},
abstract = {3D printing offers significant potential in creating highly customized interactive
and functional objects. However, at present ability to manufacture functional objects
is limited by available materials (e.g., various polymers) and their process properties.
For instance, many functional objects need stronger materials which may be satisfied
with metal printers. However, to create wholly interactive devices, we need both conductors
and insulators to create wiring, and electronic components to complete circuits. Unfortunately,
the single material nature of metal printing, and its inherent high temperatures,
preclude this. Thus, in 3D printed devices, we have had a choice of strong materials,
or embedded interactivity, but not both. In this paper, we introduce a set of techniques
we call FiberWire, which leverages a new commercially available capability to 3D print
carbon fiber composite objects. These objects are light weight and mechanically strong,
and our techniques demonstrate a means to embed circuitry for interactive devices
within them. With FiberWire, we describe a fabrication pipeline takes advantage of
laser etching and fiber printing between layers of carbon-fiber composite to form
low resistance conductors, thereby enabling the fabrication of electronics directly
embedded into mechanically strong objects. Utilizing the fabrication pipeline, we
show a range of sensor designs, their performance characterization on these new materials
and finally three fully printed example object that are both interactive and mechanically
strong -- a bicycle handle bar with interactive controls, a swing and impact sensing
golf club and an interactive game controller (Figure 1).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300798,
author = {Bergstr\"{o}m, Joanna and Mottelson, Aske and Muresan, Andreea and Hornb\ae{}k, Kasper},
title = {Tool Extension in Human-Computer Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300798},
abstract = {Tool use extends people's representations of the immediately actionable space around
them. Physical tools thereby become integrated in people's body schemas. We introduce
a measure for tool extension in HCI by using a visual-tactile interference paradigm.
In this paradigm, an index of tool extension is given by response time differences
between crossmodally congruent and incongruent stimuli; tactile on the hand and visual
on the tool. We use this measure to examine if and how findings on tool extension
apply to interaction with computer-based tools. Our first experiment shows that touchpad
and mouse both provide tool extension over a baseline condition without a tool. A
second experiment shows a higher degree of tool extension for a realistic avatar hand
compared to an abstract pointer for interaction in virtual reality. In sum, our measure
can detect tool extension with computer-based tools and differentiate interfaces by
their degree of extension.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300799,
author = {Flobak, Eivind and Wake, Jo D. and Vindenes, Joakim and Kahlon, Smiti and Nordgreen, Tine and Guribye, Frode},
title = {Participatory Design of VR Scenarios for Exposure Therapy},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300799},
abstract = {Virtual reality (VR) applications for exposure therapy predominantly use computer-generated
imagery to create controlled environments in which users can be exposed to their fears.
Creating 3D animations, however, is demanding and time-consuming. This paper presents
a participatory approach for prototyping VR scenarios that are enabled by 360° video
and grounded in lived experiences. We organized a participatory workshop with adolescents
to prototype such scenarios, consisting of iterative phases of ideation, storyboarding,
live-action plays recorded by a 360° camera, and group evaluation. Through an analysis
of the participants' interactions, we outline how they worked to design prototypes
that depict situations relevant to those with a fear of public speaking. Our analysis
also explores how participants used their experiences and reflections as resources
for design. Six clinical psychologists evaluated the prototypes from the workshop
and concluded they were viable therapeutic tools, emphasizing the immersive, realistic
experience they presented. We argue that our approach makes the design of VR scenarios
more accessible.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300800,
author = {Yamanaka, Shota},
title = {Steering Performance with Error-Accepting Delays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300800},
abstract = {In steering law tasks, deviating from the path is immediately considered an error
operation. However, in navigating a hierarchical menu item, which is a representative
application of the law, a deviation within a short duration is sometimes permitted.
We tested the validity of the steering law model with various durations of such error-accepting
delays and found that it showed high fits for each delay condition (R2 &gt; 0.96) but
poor fits if the delay values were not separated (R2 = 0.58). Because the average
movement speed linearly increased as the delay increased, we refined the model by
taking the delay into account, and the fitness was significantly improved (R2 = 0.97).
Our model will help GUI designers estimate the average operational time on the basis
of the menu item length, width, and error-accepting delay.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300801,
author = {Darzentas, Dimitrios and Velt, Raphael and Wetzel, Richard and Craigon, Peter J. and Wagner, Hanne G. and Urquhart, Lachlan D. and Benford, Steve},
title = {Card Mapper: Enabling Data-Driven Reflections on Ideation Cards},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300801},
abstract = {We explore how usage data captured from ideation cards can enable reflection on design.
We deployed a deck of ideation cards on a Masters level module over two years, developing
the means to capture the students' designs into a digital repository. We created two
visualisations to reveal the relative co-occurrences of the cards as concept space
and the relative proximity of designs (through cards used in common) as design space.
We used these to elicit reflections from the perspectives of students, teachers and
card designers. Our findings inspire ideas for extending the data-driven use of ideation
cards throughout the design process; informing the redesign of cards, the rules for
using them and their live connection to supporting materials and enabling stakeholders
to reflect and recognise challenges and opportunities. We also identified the need,
and potential ways, to capture a richer design rationale, including annotations, discarded
cards and varying card interpretations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300802,
author = {Arakawa, Riku and Yakura, Hiromu},
title = {REsCUE: A Framework for REal-Time Feedback on Behavioral CUEs Using Multimodal Anomaly Detection},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300802},
abstract = {Executive coaching has been drawing more and more attention for developing corporate
managers. While conversing with managers, coach practitioners are also required to
understand internal states of coachees through objective observations. In this paper,
we present REsCUE, an automated system to aid coach practitioners in detecting unconscious
behaviors of their clients. Using an unsupervised anomaly detection algorithm applied
to multimodal behavior data such as the subject's posture and gaze, REsCUE notifies
behavioral cues for coaches via intuitive and interpretive feedback in real-time.
Our evaluation with actual coaching scenes confirms that REsCUE provides the informative
cues to understand internal states of coachees. Since REsCUE is based on the unsupervised
method and does not assume any prior knowledge, further applications beside executive
coaching are conceivable using our framework.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300803,
author = {Guo, Shunan and Du, Fan and Malik, Sana and Koh, Eunyee and Kim, Sungchul and Liu, Zhicheng and Kim, Donghyun and Zha, Hongyuan and Cao, Nan},
title = {Visualizing Uncertainty and Alternatives in Event Sequence Predictions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300803},
abstract = {Data analysts apply machine learning and statistical methods to timestamped event
sequences to tackle various problems but face unique challenges when interpreting
the results. Especially in event sequence prediction, it is difficult to convey uncertainty
and possible alternative paths or outcomes. In this work, informed by interviews with
five machine learning practitioners, we iteratively designed a novel visualization
for exploring event sequence predictions of multiple records where users are able
to review the most probable predictions and possible alternatives alongside uncertainty
information. Through a controlled study with 18 participants, we found that users
are more confident in making decisions when alternative predictions are displayed
and they consider the alternatives more when deciding between two options with similar
top predictions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300804,
author = {Semertzidis, Nathan Arthur and Sargeant, Betty and Dwyer, Justin and Mueller, Florian Floyd and Zambetta, Fabio},
title = {Towards Understanding the Design of Positive Pre-Sleep Through a Neurofeedback Artistic Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300804},
abstract = {Poor sleep has been acknowledged as an increasingly prevalent global health concern,
however, how to design for promoting sleep is relatively underexplored. We propose
neurofeedback technology may potentially facilitate restfulness and sleep onset, and
we explore this through the creation and study of "Inter-Dream", a novel multisensory
interactive artistic experience driven by neurofeedback. Twelve participants individually
rested, augmented by Inter-Dream. Results demonstrated: statistically significant
decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and
negative affect (p = .004). EEG readings were also indicative of restorative restfulness
and cognitive stillness, while interview responses described experiences of mindfulness
and playful self-exploration. Taken together, our work highlights neurofeedback as
a potential pathway for future research in the promotion of sleep, while also suggesting
strategies for designing towards this within the context of pre-sleep.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300805,
author = {Chen, Fanglin and Xia, Kewei and Dhabalia, Karan and Hong, Jason I.},
title = {MessageOnTap: A Suggestive Interface to Facilitate Messaging-Related Tasks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300805},
abstract = {Text messages are sometimes prompts that lead to information related tasks, e.g. checking
one's schedule, creating reminders, or sharing content. We introduce MessageOnTap,
a suggestive inter-face for smartphones that uses the text in a conversation to suggest
task shortcuts that can streamline likely next actions. When activated, MessageOnTap
uses word embeddings to rank relevant external apps, and parameterizes associated
task shortcuts using key phrases mentioned in the conversation, such as times, persons,
or events. MessageOnTap also tailors the auto-complete dictionary based on text in
the conversation, to streamline any text input.We first conducted a month-long study
of messaging behaviors(N=22) that informed our design. We then conducted a lab study
to evaluate the effectiveness of MessageOnTap's suggestive interface, and found that
participants can complete tasks 3.1x faster withMessageOnTap than their typical task
flow.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300806,
author = {Li, Zhuying and Wang, Yan and Wang, Wei and Chen, Weikang and Hoang, Ti and Greuter, Stefan and Mueller, Florian Floyd},
title = {HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300806},
abstract = {Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes.
We propose that ingestible sensors also offer unique opportunities to facilitate intriguing
bodily experiences in a playful manner. To explore this, we present "HeatCraft", a
two-player system that translates the user's body temperature measured by an ingestible
sensor to localized thermal stimuli delivered through a waist belt equipped with heating
pads. We conducted a study with 16 participants. The study revealed three design themes
(Integration of body and technology, Integration of internal body and outside world,
and Integration of play and life) along with some open challenges. In summary, this
work contributes knowledge to the future design of playful experiences with ingestible
sensors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300807,
author = {Chandrasegaran, Senthil and Bryan, Chris and Shidara, Hidekazu and Chuang, Tung-Yen and Ma, Kwan-Liu},
title = {TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300807},
abstract = {Group Support Systems provide ways to review and edit shared content during meetings,
but typically require participants to explicitly generate the content. Recent advances
in speech-to-text conversion and language processing now make it possible to automatically
record and review spoken information. We present the iterative design and evaluation
of TalkTraces, a real-time visualization that helps teams identify themes in their
discussions and obtain a sense of agenda items covered. We use topic modeling to identify
themes within the discussions and word embeddings to compute the discussion "relatedness"
to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct
a comparative between-groups study between two teams using TalkTraces and two teams
using traditional notes, over four sessions. We translate the findings into changes
in the interface, further evaluated by one team over four sessions. Based on our findings,
we discuss design implications for real-time displays of discussion content.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300808,
author = {Dillahunt, Tawanna R. and Lu, Alex},
title = {DreamGigs: Designing a Tool to Empower Low-Resource Job Seekers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300808},
abstract = {Technology allows us to scale the number of jobs we search for and apply to, train
for work, and earn money online. However, these technologies do not benefit all job
seekers equally and must be designed to better support the needs of underserved job
seekers. Research suggests that underserved job seekers prefer employment technologies
that can support them in articulating their skills and experiences and in identifying
pathways to achieve their career goals. Therefore, we present the design, implementation,
and evaluation of DreamGigs, a tool that identifies the skills job seekers need to
reach their dream jobs and presents volunteer and employment opportunities for them
to acquire those skills. Our evaluation results show that DreamGigs aids in the process
of personal empowerment. We contribute design implications for mitigating aspects
of powerlessness that low-resource job seekers experience and discuss ways to promote
action-taking in these job seekers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300809,
author = {Hohman, Fred and Head, Andrew and Caruana, Rich and DeLine, Robert and Drucker, Steven M.},
title = {Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300809},
abstract = {Without good models and the right tools to interpret them, data scientists risk making
decisions based on hidden biases, spurious correlations, and false generalizations.
This has led to a rallying cry for model interpretability. Yet the concept of interpretability
remains nebulous, such that researchers and tool designers lack actionable guidelines
for how to incorporate interpretability into models and accompanying tools. Through
an iterative design process with expert machine learning researchers and practitioners,
we designed a visual analytics system, Gamut, to explore how interactive interfaces
could better support model interpretation. Using Gamut as a probe, we investigated
why and how professional data scientists interpret models, and how interface affordances
can support data scientists in answering questions about model interpretability. Our
investigation showed that interpretability is not a monolithic concept: data scientists
have different reasons to interpret models and tailor explanations for specific audiences,
often balancing competing concerns of simplicity and completeness. Participants also
asked to use Gamut in their work, highlighting its potential to help data scientists
understand their own data.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300810,
author = {de Castro Leal, D\'{e}bora and Kr\"{u}ger, Max and Misaki, Kaoru and Randall, David and Wulf, Volker},
title = {Guerilla Warfare and the Use of New (and Some Old) Technology: Lessons from FARC's Armed Struggle in Colombia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300810},
abstract = {Studying armed political struggles from a CSCW perspective can throw the complex interactions
between culture, technology, materiality and political conflict into sharp relief.
Such studies highlight interrelations that otherwise remain under-remarked upon, despite
their severe consequences. The present paper provides an account of the armed struggle
of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document
how radio-based communication became a crucial, but ambiguous infrastructure of war.
The sudden introduction of localization technologies by the Colombian army presented
a lethal threat to the guerrilla group. Our interviewees report a severe learning
process to diminish this new risk, relying on a combination of informed beliefs and
significant technical understanding. We end with a discussion of the role of HCI in
considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation
as process of adapting one's practices to other's appropriation of technology in conflict.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300811,
author = {Tennent, Paul and Marshall, Joe and Brundell, Patrick and Walker, Brendan and Benford, Steve},
title = {Abstract Machines: Overlaying Virtual Worlds on Physical Rides},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300811},
abstract = {Overlaying virtual worlds onto existing physical rides and altering the sensations
of motion can deliver new experiences of thrill, but designing how motion is mapped
between physical ride and virtual world is challenging. In this paper, we present
the notion of an abstract machine, a new form of intermediate design knowledge that
communicates motion mappings at the level of metaphor, mechanism and implementation.
Following a performance-led, in-the-wild approach we report lessons from creating
and touring VR Playground, a ride that overlays four distinct abstract machines and
virtual worlds on a playground swing. We compare the artist's rationale with riders'
reported experiences and analysis of their physical behaviours to reveal the distinct
thrills of each abstract machine. Finally, we discuss how to make and use abstract
machines in terms of heuristics for designing motion mappings, principles for virtual
world design and communicating experiences to riders.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300812,
author = {Benton, Laura and Vasalou, Asimina and Barendregt, Wolmet and Bunting, Leona and R\'{e}v\'{e}sz, Andrea},
title = {What's Missing: The Role of Instructional Design in Children's Games-Based Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300812},
abstract = {Learning games that address targeted curriculum areas are widely used in schools.
Within games, productive learning episodes can result from breakdowns when followed
by a breakthrough, yet their role in children's learning has not been investigated.
This paper examines the role of game and instructional design during and after breakdowns.
We observed 26 young children playing several popular learning games and conducted
a moment-by-moment analysis of breakdown episodes. Our findings show children achieve
productive breakthroughs independently less than half of the time. In particular,
breakdowns caused by game actions are difficult for children to overcome independently
and prevent engagement with the domain skills. Importantly, we identify specific instructional
game components and their role in fostering strategies that result in successful breakthroughs.
We conclude with intrinsic and extrinsic instructional design implications for both
game designers and primary teachers to better enable children's games-based learning.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300813,
author = {Avellino, Ignacio and Bailly, Gilles and Canlorbe, Geoffroy and Belgihti, J\'{e}r\'{e}mie and Morel, Guillaume and Vitrani, Marie-Aude},
title = {Impacts of Telemanipulation in Robotic Assisted Surgery},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300813},
abstract = {Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes
the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions
for patients. However, introducing new technology oftentimes affects the work of skilled
practitioners. Our goals are to investigate the impacts of telemanipulated surgical
robots on the work practices of surgical teams and to understand their cause. We conducted
a field study observing 21 surgeries, conducting 12 interviews and performing 3 data
validation sessions with surgeons. Using Thematic Analysis, we find that physically
separating surgeons from their teams makes them more autonomous, shifts their use
of perceptual senses, and turns the surgeon's assistant into the robot's assistant.
We open design opportunities for the HCI field by questioning the telemanipulated
approach and discussing alternatives that keep surgeons on the surgical field.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300814,
author = {Lee, Bokyung and Jin, Taeil and Lee, Sung-Hee and Saakes, Daniel},
title = {SmartManikin: Virtual Humans with Agency for Design Tools},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300814},
abstract = {When designing comfort and usability in products, designers need to evaluate aspects
ranging from anthropometrics to use scenarios. Therefore, virtual and poseable mannequins
are employed as a reference in early-stage tools and for evaluation in the later stages.
However, tools to intuitively interact with virtual humans are lacking. In this paper,
we introduceSmartManikin, a mannequin with agency that responds to high-level commands
and to real-time design changes. We first captured human poses with respect to desk
configurations, identified key features of the pose and trained regression functions
to estimate the optimal features at a given desk setup. The SmartManikin's pose is
generated by the predicted features as well as by using forward and inverse kinematics.
We present our design, implementation, and an evaluation with expert designers. The
results revealed that SmartManikin enhances the design experience by providing feedback
concerning comfort and health in real time.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300815,
author = {Mohr, Peter and Tatzgern, Markus and Langlotz, Tobias and Lang, Andreas and Schmalstieg, Dieter and Kalkofen, Denis},
title = {TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300815},
abstract = {The latest generation of consumer market Head-mounted displays (HMD) now include self-contained
inside-out tracking of head motions, which makes them suitable for mobile applications.
However, 3D tracking of input devices is either not included at all or requires to
keep the device in sight, so that it can be observed from a sensor mounted on the
HMD. Both approaches make natural interactions cumbersome in mobile applications.
TrackCap, a novel approach for 3D tracking of input devices, turns a conventional
smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently
operated both inside and outside the HMD's field of view, while it provides additional
2D input and output capabilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300816,
author = {Srivastava, Namrata and Velloso, Eduardo and Lodge, Jason M. and Erfani, Sarah and Bailey, James},
title = {Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300816},
abstract = {With the increased reach and impact of video lectures, it is crucial to understand
how they are experienced. Whereas previous studies typically present questionnaires
at the end of the lecture, they fail to capture students' experience in enough granularity.
In this paper we propose recording the lecture difficulty in real-time with a physical
slider, enabling continuous and fine-grained analysis of the learning experience.
We evaluated our approach in a study with 100 participants viewing two variants of
two short lectures. We demonstrate that our approach helps us paint a more complete
picture of the learning experience. Our analysis has design implications for instructors,
providing them with a method that helps them compare their expectations with students'
beliefs about the lectures and to better understand the specific effects of different
instructional design decisions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300817,
author = {Bhattacharya, Arpita and Windleharth, Travis W. and Ishii, Rio Anthony and Acevedo, Ivy M. and Aragon, Cecilia R. and Kientz, Julie A. and Yip, Jason C. and Lee, Jin Ha},
title = {Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pok\'{e}Mon GO},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300817},
abstract = {Raiding is a format in digital gaming that requires groups of people to collaborate
and/or compete for a common goal. In 2017, the raiding format was introduced in the
location-based mobile game Pok\'{e}mon GO, which offers a mixed reality experience to
friends and strangers coordinating for in-person raids. To understand this technology-mediated
social phenomenon, we conducted over a year of participant observations, surveys with
510 players, and interviews with 25 players who raid in Pok\'{e}mon GO. Using the analytical
lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we
identify global, local, and contextual dynamics in location-based raiding that support
and challenge ad-hoc group formation in real life. Based on this empirical and theoretical
understanding, we discuss implications to design for transparency, social affordances,
and bridging gaps between global and contextual dynamics for increased positive and
inclusive community interactions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300818,
author = {Webb, Andrew M. and Fowler, Hannah and Kerne, Andruid and Newman, Galen and Kim, Jun-Hyun and Mackay, Wendy E.},
title = {Interstices: Sustained Spatial Relationships between Hands and Surfaces Reveal Anticipated Action},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300818},
abstract = {Our observations of landscape architecture students revealed a new phenomenon-interstices.
Their bimanual interactions with a pen and touch surface involved various sustained
hand gestures, interleaved between their regular commands. Positioning of the non-preferred
hand indicates anticipated actions, including: sustained hovering near the surface;
pulled back but still floating above the surface; and resting in their laps. We ran
a second study with 14 landscape architect students which confirmed our observations,
and uncovered a new interstice i.e. stabilizing the preferred hand while handwriting.
We conclude with directions for future research and challenges for designers and researchers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300819,
author = {Marques, Diogo and Guerreiro, Tiago and Carri\c{c}o, Luis and Beschastnikh, Ivan and Beznosov, Konstantin},
title = {Vulnerability &amp; Blame: Making Sense of Unauthorized Access to Smartphones},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300819},
abstract = {Unauthorized physical access to personal devices by people known to the owner of the
device is a common concern, and a common occurrence. But how do people experience
incidents of unauthorized access? Using an online survey, we collected 102 accounts
of unauthorized access. Participants wrote stories about past situations in which
either they accessed the smartphone of someone they know, or someone they know accessed
theirs. We describe the context leading up to these incidents, the course of events,
and the consequences. We then identify two orthogonal themes in how participants conceptualized
these incidents. First, participants understood trust as performative vulnerability:
trust was necessary to sustain relationships, but building trust required displaying
vulnerability to breaches. Second, participants were self-serving in their sensemaking:
they blamed the circumstances, or the other person's shortcomings, but rarely themselves.
We discuss the implications of our findings for security design and practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300820,
author = {Bentley, Frank and Quehl, Katie and Wirfs-Brock, Jordan and Bica, Melissa},
title = {Understanding Online News Behaviors},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300820},
abstract = {The news landscape has been changing dramatically over the past few years. Whereas
news once came from a small set of highly edited sources, now people can find news
from thousands of news sites online, through a variety of channels such as web search,
social media, email newsletters, or direct browsing. We set out to understand how
Americans read news online using web browser logs collected from 174 diverse participants.
We found that 20% of all news sessions started with a web search, that 16% started
from social media, that 61% of news sessions only involved a single news domain, and
that 47% of our participants read news from both sides of the political spectrum.
We conclude with key implications for online news, social media, and search sites
to encourage more balanced news browsing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300821,
author = {Vertanen, Keith and Gaines, Dylan and Fletcher, Crystal and Stanage, Alex M. and Watling, Robbie and Kristensson, Per Ola},
title = {VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300821},
abstract = {Virtual keyboard typing is typically aided by an auto-correct method that decodes
a user's noisy taps into their intended text. This decoding process can reduce error
rates and possibly increase entry rates by allowing users to type faster but less
precisely. However, virtual keyboard decoders sometimes make mistakes that change
a user's desired word into another. This is particularly problematic for challenging
text such as proper names. We investigate whether users can guess words that are likely
to cause auto-correct problems and whether users can adjust their behavior to assist
the decoder. We conduct computational experiments to decide what predictions to offer
in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users
were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute
with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just
as accurately on a simpler keyboard with limited correction options. Our finding suggest
users may be able to type difficult words on a smartwatch simply by tapping precisely
without the use of auto-correct.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300822,
author = {Luo, Yuhan and Liu, Peiyi and Choe, Eun Kyoung},
title = {Co-Designing Food Trackers with Dietitians: Identifying Design Opportunities for Food Tracker Customization},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300822},
abstract = {We report co-design workshops with registered dietitians conducted to identify opportunities
for designing customizable food trackers. Dietitians typically see patients who have
different dietary problems, thus having different information needs. However, existing
food trackers such as paper-based diaries and mobile apps are rarely customizable,
making it difficult to capture necessary data for both patients and dietitians. During
the co-design sessions, dietitians created representative patient personas and designed
food trackers for each persona. We found a wide range of potential tracking items
such as food, reflection, symptom, activity, and physical state. Depending on patients'
dietary problems and dietitians' practice, the necessity and importance of these tracking
items vary. We identify opportunities for patients and healthcare providers to collaborate
around data tracking and sharing through customization. We also discuss how to structure
co-design workshops to solicit the design considerations of self-tracking tools for
patients with specific health problems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300823,
author = {Harrington, Christina N. and Borgos-Rodriguez, Katya and Piper, Anne Marie},
title = {Engaging Low-Income African American Older Adults in Health Discussions through Community-Based Design Workshops},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300823},
abstract = {Community-based approaches to participatory design, such as the design workshop, promise
to engage underserved populations in collaborative dialog and provide a platform for
promoting the views of communities who are not typically given a space to engage in
design. Yet, we know little about how design workshops as a research site can engage
underserved individuals (i.e., due to class, race, or age status) or address personal
concerns (e.g., health). As a way of exploring these issues, we conducted a series
of five design workshops with low-income African-American older adults to understand
their health experiences. Our findings reveal three insights associated with the design
workshop and the topic of health: comfort with community versus personal health; the
sociocultural configuration of interaction; and empowerment in the context of systematic
inequality of opportunity. We discuss the importance of understanding the situated
nature of design workshops, particularly when engaging underserved groups in the topic
of health, and the potential of the design workshop as a mechanism for activism.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300824,
author = {Sun, Kaiwen and Mhaidli, Abraham H. and Watel, Sonakshi and Brooks, Christopher A. and Schaub, Florian},
title = {It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300824},
abstract = {Early warning dashboards in higher education analyze student data to enable early
identification of underperforming students, allowing timely interventions by faculty
and staff. To understand perceptions regarding the ethics and impact of such learning
analytics applications, we conducted a multi-stakeholder analysis of an early-warning
dashboard deployed at the University of Michigan through semi-structured interviews
with the system's developers, academic advisors (the primary users), and students.
We identify multiple tensions among and within the stakeholder groups, especially
with regard to awareness, understanding, access and use of the system. Furthermore,
ambiguity in data provenance and data quality result in differing levels of reliance
and concerns about the system among academic advisors and students. While students
see the system's benefits, they argue for more involvement, control, and informed
consent regarding the use of student data. We discuss our findings' implications for
the ethical design and deployment of learning analytics applications in higher education.
Early warning dashboards in higher education analyze student data to enable early
identification of underperforming students, allowing timely interventions by faculty
and staff. To understand perceptions regarding the ethics and impact of such learning
analytics applications, we conducted a multi-stakeholder analysis of an early-warning
dashboard deployed at the University of Michigan through semi-structured interviews
with the system's developers, academic advisors (the primary users), and students.
We identify multiple tensions among and within the stakeholder groups, especially
with regard to awareness, understanding, access, and use of the system. Furthermore,
ambiguity in data provenance and data quality result in differing levels of reliance
and concerns about the system among academic advisors and students. While students
see the system's benefits, they argue for more involvement, control, and informed
consent regarding the use of student data. We discuss our findings' implications for
the ethical design and deployment of learning analytics applications in higher education.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300825,
author = {Roffo, Giorgio and Vo, Dong-Bach and Tayarani, Mohammad and Rooksby, Maki and Sorrentino, Alessandra and Di Folco, Simona and Minnis, Helen and Brewster, Stephen and Vinciarelli, Alessandro},
title = {Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300825},
abstract = {This article presents the School Attachment Monitor, a novel interactive system that
can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric
test for the assessment of attachment in children) without the supervision of trained
professionals. Attachment problems in children cause significant mental health issues
and costs to society which technology has the potential to reduce. SAM collects, through
instrumented doll-play games, enough information to allow a human assessor to manually
identify the attachment status of children. Experiments show that the system successfully
does this in 87.5% of cases. In addition, the experiments show that an automatic approach
based on deep neural networks can map the information collected into the attachment
condition of the children. The outcome SAM matches the judgment of expert human assessors
in 82.8% of cases. This is the first time an automated tool has been successful in
measuring attachment. This work has significant implications for psychiatry as it
allows professionals to assess many more children cost effectively and to direct healthcare
resources more accurately and efficiently to improve mental health.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300826,
author = {Nebeling, Michael and Madier, Katy},
title = {360proto: Making Interactive Virtual Reality &amp; Augmented Reality Prototypes from Paper},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300826},
abstract = {We explore 360 paper prototyping to rapidly create AR/VR prototypes from paper and
bring them to life on AR/VR devices. Our approach is based on a set of emerging paper
prototyping templates specifically for AR/VR. These templates resemble the key components
of many AR/VR interfaces, including 2D representations of immersive environments,
AR marker overlays and face masks, VR controller models and menus, and 2D screens
and HUDs. To make prototyping with these templates effective, we developed 360proto,
a suite of three novel physical--digital prototyping tools: (1) the 360proto Camera
for capturing paper mockups of all components simply by taking a photo with a smartphone
and seeing 360-degree panoramic previews on the phone or stereoscopic previews in
Google Cardboard; (2) the 360proto Studio for organizing and editing captures, for
composing AR/VR interfaces by layering the captures, and for making them interactive
with Wizard of Oz via live video streaming; (3) the 360proto App for running and testing
the interactive prototypes on AR/VR capable mobile devices and headsets. Through five
student design jams with a total of 86 participants and our own design space explorations,
we demonstrate that our approach with 360proto is useful to create relatively complex
AR/VR applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300827,
author = {Ferron, Michela and Leonardi, Chiara and Massa, Paolo and Schiavo, Gianluca and Murphy, Amy L. and Farella, Elisabetta},
title = {A Walk on the Child Side: Investigating Parents' and Children's Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300827},
abstract = {Technology increasingly offers parents more and more opportunities to monitor children,
reshaping the way control and autonomy are negotiated within families. This paper
investigates the views of parents and primary school children on mobile technology
designed to support child independent mobility in the context of the local walking
school buses. Based on a school-year long field study, we report findings on children's
and parents' experience with proximity detection devices. The results provide insights
into how the parents and children accepted and socially appropriated the technology
into the walking school bus activity, shedding light on the way they understand and
conceptualize a technology that collects data on children's proximity to the volunteers'
smartphone. We discuss parents' needs and concerns toward monitoring technologies
and the related challenges in terms of trust-control balance. These insights are elaborated
to inform the future design of technology for child independent mobility.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300828,
author = {Kwak, Il-Youp and Huh, Jun Ho and Han, Seung Taek and Kim, Iljoo and Yoon, Jiwon},
title = {Voice Presentation Attack Detection through Text-Converted Voice Command Analysis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300828},
abstract = {Voice assistants are quickly being upgraded to support advanced, security-critical
commands such as unlocking devices, checking emails, and making payments. In this
paper, we explore the feasibility of using users' text-converted voice command utterances
as classification features to help identify users' genuine commands, and detect suspicious
commands. To maintain high detection accuracy, our approach starts with a globally
trained attack detection model (immediately available for new users), and gradually
switches to a user-specific model tailored to the utterance patterns of a target user.
To evaluate accuracy, we used a real-world voice assistant dataset consisting of about
34.6 million voice commands collected from 2.6 million users. Our evaluation results
show that this approach is capable of achieving about 3.4% equal error rate (EER),
detecting 95.7% of attacks when an optimal threshold value is used. As for those who
frequently use security-critical (attack-like) commands, we still achieve EER below
5%.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300829,
author = {Singh, Aneesha and Gibbs, Jo and Blandford, Ann},
title = {Emotion and Experience in Negotiating HIV-Related Digital Resources: "It's Not Just a Runny Nose!"},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300829},
abstract = {While digital technologies are increasingly being used to provide support and diagnoses
remotely, it is unclear whether they offer adequate emotional support and appropriate
messages in navigating complex, stigmatised and sensitive conditions that can have
a momentous impact on people's lives. In this paper, we investigate how and why people
access existing HIV resources, and their experiences of using these resources through
a survey with 197 respondents and an interview and think-aloud study with 28 participants.
Our findings indicate that many HIV-related resources do not address the anxiety-provoking
reasons for access, reinforce stigma and neglect to provide important information
and emotional support. We finally discuss potential ways of addressing these issues
in the current environment where more sexual health services are being delivered online.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300830,
author = {Holstein, Kenneth and Wortman Vaughan, Jennifer and Daum\'{e}, Hal and Dudik, Miro and Wallach, Hanna},
title = {Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300830},
abstract = {The potential for machine learning (ML) systems to amplify social inequities and unfairness
is receiving increasing popular and academic attention. A surge of recent work has
focused on the development of algorithmic tools to assess and mitigate such unfairness.
If these tools are to have a positive impact on industry practice, however, it is
crucial that their design be informed by an understanding of real-world needs. Through
35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we
conduct the first systematic investigation of commercial product teams' challenges
and needs for support in developing fairer ML systems. We identify areas of alignment
and disconnect between the challenges faced by teams in practice and the solutions
proposed in the fair ML research literature. Based on these findings, we highlight
directions for future ML and HCI research that will better address practitioners'
needs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300831,
author = {Wang, Danding and Yang, Qian and Abdul, Ashraf and Lim, Brian Y.},
title = {Designing Theory-Driven User-Centric Explainable AI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300831},
abstract = {From healthcare to criminal justice, artificial intelligence (AI) is increasingly
supporting high-consequence human decisions. This has spurred the field of explainable
AI (XAI). This paper seeks to strengthen empirical application-specific investigations
of XAI by exploring theoretical underpinnings of human decision making, drawing from
the fields of philosophy and psychology. In this paper, we propose a conceptual framework
for building human-centered, decision-theory-driven XAI based on an extensive review
across these fields. Drawing on this framework, we identify pathways along which human
cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive
biases. We then put this framework into practice by designing and implementing an
explainable clinical diagnostic tool for intensive care phenotyping and conducting
a co-design exercise with clinicians. Thereafter, we draw insights into how this framework
bridges algorithm-generated explanations and human decision-making theories. Finally,
we discuss implications for XAI design and development.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300832,
author = {Balaam, Madeline and Comber, Rob and Clarke, Rachel E. and Windlin, Charles and St\r{a}hl, Anna and H\"{o}\"{o}k, Kristina and Fitzpatrick, Geraldine},
title = {Emotion Work in Experience-Centered Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300832},
abstract = {Experience Centered Design (ECD) implores us to develop empathic relationships and
understanding of participants, to actively work with our senses and emotions within
the design process. However, theories of experience-centered design do little to account
for emotion work undertaken by design researchers when doing this. As a consequence,
how a design researcher's emotions are experienced, navigated and used as part of
an ECD process are rarely published. So, while emotion is clearly a tool that we use,
we don't share with one another how, why and when it gets used. This has a limiting
effect on how we understand design processes, and opportunities for training. Here,
we share some of our experiences of working with ECD. We analyse these using Hochschild's
framework of emotion work to show how and where this work occurs. We use our analysis
to question current ECD practices and provoke debate.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300833,
author = {Sutton, Selina Jeanne and Foulkes, Paul and Kirk, David and Lawson, Shaun},
title = {Voice as a Design Material: Sociophonetic Inspired Design Strategies in Human-Computer Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300833},
abstract = {While there is a renewed interest in voice user interfaces (VUI) in HCI, little attention
has been paid to the design of VUI voice output beyond intelligibility and naturalness.
We draw on the field of sociophonetics - the study of the social factors that influence
the production and perception of speech - to highlight how current VUIs are based
on a limited and homogenised set of voice outputs. We argue that current systems do
not adequately consider the diversity of peoples' speech, how that diversity represents
sociocultural identities, and how voices have the potential to shape user perceptions
and experiences. Ultimately, as other technological developments have influenced the
ideologies of language, the voice outputs of VUIs will influence the ideologies of
speech. Based on our argument, we pose three design strategies for VUI voice output
design - individualisation, context awareness, and diversification - to motivate new
ways of conceptualising and designing these technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300834,
author = {Frik, Alisa and Malkin, Nathan and Harbach, Marian and Peer, Eyal and Egelman, Serge},
title = {A Promise Is A Promise: The Effect of Commitment Devices on Computer Security Intentions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300834},
abstract = {Commitment devices are a technique from behavioral economics that have been shown
to mitigate the effects of present bias---the tendency to discount future risks and
gains in favor of immediate gratifications. In this paper, we explore the feasibility
of using commitment devices to nudge users towards complying with varying online security
mitigations. Using two online experiments, with over 1,000 participants total, we
offered participants the option to be reminded or to schedule security tasks in the
future. We find that both reminders and commitment nudges can increase users' intentions
to install security updates and enable two-factor authentication, but not to configure
automatic backups. Using qualitative data, we gain insights into the reasons for postponement
and how to improve future nudges. We posit that current nudges may not live up to
their full potential, as the timing options offered to users may be too rigid.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300835,
author = {Distler, Verena and Zollinger, Marie-Laure and Lallemand, Carine and Roenne, Peter B. and Ryan, Peter Y. A. and Koenig, Vincent},
title = {Security - Visible, Yet Unseen?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300835},
abstract = {An unsolved debate in the field of usable security concerns whether security mechanisms
should be visible, or blackboxed away from the user for the sake of usability. However,
tying this question to pragmatic usability factors only might be simplistic. This
study aims at researching the impact of displaying security mechanisms on User Experience
(UX) in the context of e-voting. Two versions of an e-voting application were designed
and tested using a between-group experimental protocol (N=38). Version D displayed
security mechanisms, while version ND did not reveal any security-related information.
We collected data on UX using standardised evaluation scales and semi-structured interviews.
Version D performed better overall in terms of UX and need fulfilment. Qualitative
analysis of the interviews gives further insights into factors impacting perceived
security. Our study adds to existing research suggesting a conceptual shift from usability
to UX and discusses implications for designing and evaluating secure systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300836,
author = {Seering, Joseph and Fang, Tianmi and Damasco, Luca and Chen, Mianhong 'Cherie' and Sun, Likang and Kaufman, Geoff},
title = {Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300836},
abstract = {Ensuring high-quality, civil social interactions remains a vexing challenge in many
online spaces. In the present work, we introduce a novel approach to address this
problem: using psychologically "embedded'' CAPTCHAs containing stimuli intended to
prime positive emotions and mindsets. An exploratory randomized experiment (N = 454
Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented
on a simulated, politically charged comment thread. Results revealed that the two
interventions that were the most successful at activating positive affect also significantly
increased the positivity of tone and analytical complexity of argumentation in participants'
responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed
that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal
positive emotions significantly increased the positivity of sentiment and the levels
of complexity and social connectedness in participants' posts. We offer several explanations
for these results and discuss the practical and ethical implications of designing
interfaces to influence discourse in online forums.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300837,
author = {Cho, Alexander and Herrera, Roxana G. and Chaidez, Luis and Uriostegui, Adilene},
title = {The "Comadre" Project: An Asset-Based Design Approach to Connecting Low-Income Latinx Families to Out-of-School Learning Opportunities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300837},
abstract = {Participation in out-of-school learning programs has been shown to generate significant
academic, social/emotional, and institutional benefits for young learners, and today's
wealthy families are disproportionately reaping these benefits. This paper presents
the results of an asset-based/human-centered design research process and pilot aimed
at connecting low-income families in a Southern California city with local low-cost
out-of-school learning opportunities. Based on background research including qualitative
interviewing, home visits, technology inventories and use walkthroughs with 40 low-income,
majority Latinx families, we created and piloted a free subscription SMS service that
automatically pushes bilingual SMS messages with curated information on local low-cost
enrichment learning opportunities to low-income families. We framed our human-centered
design process through an intersectional, "asset-based approach," which recognizes
that marginalized communities have already developed robust, culturally-specific social
practices to enable them to navigate the world, seeks to amplify them, and refrains
from imposing a top-down or pre-conceived "idea" of intervention.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300838,
author = {Sousa, Maur\'{\i}cio and dos Anjos, Rafael Kufner and Mendes, Daniel and Billinghurst, Mark and Jorge, Joaquim},
title = {Warping Deixis: Distorting Gestures to Enhance Collaboration},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300838},
abstract = {When engaged in communication, people often rely on pointing gestures to refer to
out-of-reach content. However, observers frequently misinterpret the target of a pointing
gesture. Previous research suggests that to perform a pointing gesture, people place
the index finger on or close to a line connecting the eye to the referent, while observers
interpret pointing gestures by extrapolating the referent using a vector defined by
the arm and index finger. In this paper we present Warping Deixis, a novel approach
to improving the perception of pointing gestures and facilitate communication in collaborative
Extended Reality environments. By warping the virtual representation of the pointing
individual, we are able to match the pointing expression to the observer's perception.
We evaluated our approach in a co-located side by side virtual reality scenario. Results
suggest that our approach is effective in improving the interpretation of pointing
gestures in shared virtual environments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300839,
author = {Wang, Xi and Ley, Andreas and Koch, Sebastian and Lindlbauer, David and Hays, James and Holmqvist, Kenneth and Alexa, Marc},
title = {The Mental Image Revealed by Gaze Tracking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300839},
abstract = {Humans involuntarily move their eyes when retrieving an image from memory. This motion
is often similar to actually observing the image. We suggest to exploit this behavior
as a new modality in human computer interaction, using the motion of the eyes as a
descriptor of the image. Interaction requires the user's eyes to be tracked but no
voluntary physical activity. We perform a controlled experiment and develop matching
techniques using machine learning to investigate if images can be discriminated based
on the gaze patterns recorded while users merely think about image. Our results indicate
that image retrieval is possible with an accuracy significantly above chance. We also
show that this result generalizes to images not used during training of the classifier
and extends to uncontrolled settings in a realistic scenario.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300840,
author = {Foley, Sarah and Pantidi, Nadia and McCarthy, John},
title = {Care and Design: An Ethnography of Mutual Recognition in the Context of Advanced Dementia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300840},
abstract = {While there have been considerable developments in designing for dementia within HCI,
there is still a lack of empirical understanding of the experience of people with
advanced dementia and the ways in which design can support and enrich their lives.
In this paper, we present our findings from a long-term ethnographic study, which
aimed to gain an understanding of their lived experience and inform design practices
for and with people with advanced dementia in residential care. We present our findings
using the social theory of recognition as an analytic lens to account for recognition
in practice and its challenges in care and research. We discuss how we, as the HCI
community, can pragmatically engage with people with advanced dementia and propose
a set of considerations for those who wish to design for and with the values of recognition
theory to promote collaboration, agency and social identity in advanced dementia care.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300841,
author = {Feng, Yuanyuan and Li, Katie and Semsar, Azin and McGowan, Hannah and Mun, Jacqueline and Zahiri, H. Reza and George, Ivan and Park, Adrian and Kleinsmith, Andrea and Mentis, Helena M.},
title = {Communication Cost of Single-User Gesturing Tool in Laparoscopic Surgical Training},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300841},
abstract = {Multi-user input over a shared display has been shown to support group process and
improve performance. However, current gesturing systems for instructional collaborative
tasks limit the input to experts and overlook the needs of novices in making references
on a shared display. In this paper, we investigate the effects of a single-user gesturing
tool on the communication between trainer and trainees in a laparoscopic surgical
training. By comparing the communication structure and content between the trainings
with and without the gesturing tool, we show that the communication becomes more imbalanced
and the trainees become less active when using the single-user gesturing tool. Our
findings highlight the needs to grant all parties the same level of access to a shared
display and suggest further directions in designing a shared display for instructional
collaborative tasks.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300842,
author = {Mardanbegi, Diako and Langlotz, Tobias and Gellersen, Hans},
title = {Resolving Target Ambiguity in 3D Gaze Interaction through VOR Depth Estimation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300842},
abstract = {Target disambiguation is a common problem in gaze interfaces, as eye tracking has
accuracy and precision limitations. In 3D environments this is compounded by objects
overlapping in the field of view, as a result of their positioning at different depth
with partial occlusion. We introduce VOR depth estimation, a method based on the Vestibulo-ocular
reflex of the eyes in compensation of head movement, and explore its application to
resolve target ambiguity. The method estimates gaze depth by comparing the rotations
of the eye and the head when the users look at a target and deliberately rotate their
head. We show that VOR eye movement presents an alternative to vergence for gaze depth
estimation, that is feasible also with monocular tracking. In an evaluation of its
use for target disambiguation, our method outperforms vergence for targets presented
at greater depth.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300843,
author = {Shin, Joon-Gi and Onchi, Eiji and Reyes, Maria Jose and Song, Junbong and Lee, Uichin and Lee, Seung-Hee and Saakes, Daniel},
title = {Slow Robots for Unobtrusive Posture Correction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300843},
abstract = {Prolonged static and unbalanced sitting postures during computer usage contribute
to musculoskeletal discomfort. In this paper, we investigated the use of a very slow
moving monitor for unobtrusive posture correction. In a first study, we identified
display velocities below the perception threshold and observed how users (without
being aware) responded by gradually following the monitor's motion. From the result,
we designed a robotic monitor that moves imperceptible to counterbalance unbalanced
sitting postures and induces posture correction. In an evaluation study (n=12), we
had participants work for four hours without and with our prototype (8 in total).
Results showed that actuation increased the frequency of non-disruptive swift posture
corrections and significantly reduced the duration of unbalanced sitting. Most users
appreciated the monitor correcting their posture and reported less physical fatigue.
With slow robots, we make the first step toward using actuated objects for unobtrusive
behavioral changes.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300844,
author = {Curran, Max T. and Gordon, Jeremy Raboff and Lin, Lily and Sridhar, Priyashri Kamlesh and Chuang, John},
title = {Understanding Digitally-Mediated Empathy: An Exploration of Visual, Narrative, and Biosensory Informational Cues},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300844},
abstract = {Digitally sharing our experiences engages a process of empathy shaped by available
informational cues. Biosensory data is one informative cue, but the relationship to
empathy is underexplored. In this study, we investigate this process by showing a
video of a "target'' person's visual perspective watching a virtual reality film to
sixty "observers''. We vary information available to observers via three experimental
conditions: a baseline unmodified video, video with narrative text, or with a graph
of electrodermal activity (EDA) of the target. Compared to baseline, narrative text
increased empathic accuracy (EA) while EDA had an opposite, negative effect. Qualitatively,
observers describe their empathic processes as using their own feelings supplemented
with the information presented depending on the interpretability of that information.
Both narration and EDA prompted observers to reconsider assumptions about another's
experience. Our findings lead to a discussion of digitally-mediated empathy with implications
for associated research and product development.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300845,
author = {Kim, Young-Ho and Choe, Eun Kyoung and Lee, Bongshin and Seo, Jinwook},
title = {Understanding Personal Productivity: How Knowledge Workers Define, Evaluate, and Reflect on Their Productivity},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300845},
abstract = {Productivity tracking tools often determine productivity based on the time interacting
with work-related applications. To deconstruct productivity's diverse and nebulous
nature, we investigate how knowledge workers conceptualize personal productivity and
delimit productive tasks in both work and non-work contexts. We report a 2-week diary
study followed by a semi-structured interview with 24 knowledge workers. Participants
captured productive activities and provided the rationale for why the activities were
assessed to be productive. They reported a wide range of productive activities beyond
typical desk-bound work-ranging from having a personal conversation with dad to getting
a haircut. We found six themes that characterize the productivity assessment-work
product, time management, worker's state, attitude toward work, impact &amp; benefit,
and compound task and identified how participants interleaved multiple facets when
assessing their productivity. We discuss how these findings could inform the design
of a comprehensive productivity tracking system that covers a wide range of productive
activities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300846,
author = {Horak, Tom and Mathisen, Andreas and Klokmose, Clemens N. and Dachselt, Raimund and Elmqvist, Niklas},
title = {Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300846},
abstract = {We present Vistribute, a framework for the automatic distribution of visualizations
and UI components across multiple heterogeneous devices. Our framework consists of
three parts: (i) a design space considering properties and relationships of interactive
visualizations, devices, and user preferences in multi-display environments; (ii)
specific heuristics incorporating these dimensions for guiding the distribution for
a given interface and device ensemble; and (iii) a web-based implementation instantiating
these heuristics to automatically generate a distribution as well as providing interaction
mechanisms for user-defined adaptations. In contrast to existing UI distribution systems,
we are able to infer all required information by analyzing the visualizations and
devices without relying on additional input provided by users or programmers. In a
qualitative study, we let experts create their own distributions and rate both other
manual distributions and our automatic ones. We found that all distributions provided
comparable quality, hence validating our framework.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300847,
author = {Eriksson, Sara and Unander-Scharin, \r{A}sa and Trichon, Vincent and Unander-Scharin, Carl and Kjellstr\"{o}m, Hedvig and H\"{o}\"{o}k, Kristina},
title = {Dancing With Drones: Crafting Novel Artistic Expressions Through Intercorporeality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300847},
abstract = {Movement-based interactions are gaining traction, requiring a better understanding
of how such expressions are shaped by designers. Through an analysis of an artistic
process aimed to deliver a commissioned opera where custom-built drones are performing
on stage alongside human performers, we observed the importance of achieving an intercorporeal
understanding to shape body-based emotional expressivity. Our analysis reveals how
the choreographer moves herself to: (1) imitate and feel the affordances and expressivity
of the drones' 'otherness' through her own bodily experience; (2) communicate to the
engineer of the team how she wants to alter the drones' behaviors to be more expressive;
(3) enact and interactively alter her choreography. Through months of intense development
and creative work, such an intercorporeal understanding was achieved by carefully
crafting the drones' behaviors, but also by the choreographer adjusting her own somatics
and expressions. The choreography arose as a result of the expressivity they enabled
together.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300848,
author = {Tu, Huawei and Huang, Susu and Yuan, Jiabin and Ren, Xiangshi and Tian, Feng},
title = {Crossing-Based Selection with Virtual Reality Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300848},
abstract = {This paper presents the first investigation into using the goal-crossing paradigm
for object selection with virtual reality (VR) head-mounted displays. Two experiments
were carried out to evaluate ray-casting crossing tasks with target discs in 3D space
and goal lines on 2D plane respectively in comparison to ray-casting pointing tasks.
Five factors, i.e. task difficulty, the direction of movement constraint (collinear
vs. orthogonal), the nature of the task (discrete vs. continuous), field of view of
VR devices and target depth, were considered in both experiments. Our findings are:
(1) crossing generally had shorter or no longer time, and higher or similar accuracy
than pointing, indicating crossing can complement or substitute pointing; (2) crossing
tasks can be well modelled with Fitts' Law; (3) crossing performance depended on target
depth; (4) crossing target discs in 3D space differed from crossing goal lines on
2D plane in many aspects such as time and error performance, the effects of target
depth and the parameters of Fitts' models. Based on these findings, we formulate a
number of design recommendations for crossing-based interaction in VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300849,
author = {Wacker, Philipp and Nowak, Oliver and Voelker, Simon and Borchers, Jan},
title = {ARPen: Mid-Air Object Manipulation Techniques for a Bimanual AR System with Pen &amp; Smartphone},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300849},
abstract = {Modeling in Augmented Reality (AR) lets users create and manipulate virtual objects
in mid-air that are aligned to their real environment. We present ARPen, a bimanual
input technique for AR modeling that combines a standard smartphone with a 3D-printed
pen. Users sketch with the pen in mid-air, while holding their smartphone in the other
hand to see the virtual pen traces in the live camera image. ARPen combines the pen's
higher 3D input precision with the rich interactive capabilities of the smartphone
touchscreen. We studied subjective preferences for this bimanual input technique,
such as how people hold the smartphone while drawing, and analyzed the performance
of different bimanual techniques for selecting and moving virtual objects. Users preferred
a bimanual technique casting a ray through the pen tip for both selection and translation.
We provide initial design guidelines for this new class of bimanual AR modeling systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300850,
author = {Matviienko, Andrii and Ananthanarayan, Swamy and El Ali, Abdallah and Heuten, Wilko and Boll, Susanne},
title = {NaviBike: Comparing Unimodal Navigation Cues for Child Cyclists},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300850},
abstract = {Navigation systems for cyclists are commonly screen-based devices mounted on the handlebar
which show map information. Typically, adult cyclists have to explicitly look down
for directions. This can be distracting and challenging for children, given their
developmental differences in motor and perceptual-motor abilities compared with adults.
To address this issue, we designed different unimodal cues and explored their suitability
for child cyclists through two experiments. In the first experiment, we developed
an indoor bicycle simulator and compared auditory, light, and vibrotactile navigation
cues. In the second experiment, we investigated these navigation cues in-situ in an
outdoor practice test track using a mid-size tricycle. To simulate road distractions,
children were given an additional auditory task in both experiments. We found that
auditory navigational cues were the most understandable and the least prone to navigation
errors. However, light and vibrotactile cues might be useful for educating younger
child cyclists.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300851,
author = {Huang, Haikun and Solah, Michael and Li, Dingzeyu and Yu, Lap-Fai},
title = {Audible Panorama: Automatic Spatial Audio Generation for Panorama Imagery},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300851},
abstract = {As 360 deg cameras and virtual reality headsets become more popular, panorama images
have become increasingly ubiquitous. While sounds are essential in delivering immersive
and interactive user experiences, most panorama images, however, do not come with
native audio. In this paper, we propose an automatic algorithm to augment static panorama
images through realistic audio assignment. We accomplish this goal through object
detection, scene classification, object depth estimation, and audio source placement.
We built an audio file database composed of over $500$ audio files to facilitate this
process. We designed and conducted a user study to verify the efficacy of various
components in our pipeline. We run our method on a large variety of panorama images
of indoor and outdoor scenes. By analyzing the statistics, we learned the relative
importance of these components, which can be used in prioritizing for power-sensitive
time-critical tasks like mobile augmented reality (AR) applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300852,
author = {Saquib, Nazmus and Kazi, Rubaiat Habib and Wei, Li-Yi and Li, Wilmot},
title = {Interactive Body-Driven Graphics for Augmented Video Performance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300852},
abstract = {We present a system that augments live presentation videos with interactive graphics
to create a powerful and expressive storytelling environment. Using our system, the
presenter interacts with the graphical elements in real-time with gestures and postures,
thus leveraging our innate, everyday skills to enhance our communication capabilities
with the audience. However, crafting such an interactive and expressive performance
typically requires programming, or highly-specialized tools tailored for experts.
Our core contribution is a flexible, direct manipulation UI which enables amateurs
and experts to craft such presentations beforehand by mapping a variety of body movements
to a wide range of graphical manipulations. By simplifying the mapping between gestures,
postures, and their corresponding output effects, our UI enables users to craft customized,
rich interactions with the graphical elements. Our user study demonstrates the potential
usage and unique affordance of this mixed-reality medium for storytelling and presentation
across a range of application domains.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300853,
author = {Griggio, Carla F. and Nouwens, Midas and McGrenere, Joanna and Mackay, Wendy E.},
title = {Augmenting Couples' Communication with <i>Lifelines</i>: Shared Timelines of Mixed Contextual Information},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300853},
abstract = {Couples exhibit special communication practices, but apps rarely offer couple-specific
functionality. Research shows that sharing streams of contextual information (e.g.
location, motion) helps couples coordinate and feel more connected. Most studies explored
a single, ephemeral stream; we study how couples' communication changes when sharing
multiple, persistent streams. We designed Lifelines, a mobile-app technology probe
that visualizes up to six streams on a shared timeline: closeness to home, battery
level, steps, media playing, texts and calls. A month-long study with nine couples
showed that partners interpreted information mostly from individual streams, but also
combined them for more nuanced interpretations. Persistent streams allowed missing
data to become meaningful and provided new ways of understanding each other. Unexpected
patterns from any stream can trigger calls and texts, whereas seeing expected data
can replace direct communication, which may improve or disrupt established communication
practices. We conclude with design implications for mediating awareness within couples.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300854,
author = {Guzdial, Matthew and Liao, Nicholas and Chen, Jonathan and Chen, Shao-Yu and Shah, Shukan and Shah, Vishwa and Reno, Joshua and Smith, Gillian and Riedl, Mark O.},
title = {Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300854},
abstract = {Machine learning advances have afforded an increase in algorithms capable of creating
art, music, stories, games, and more. However, it is not yet well-understood how machine
learning algorithms might best collaborate with people to support creative expression.
To investigate how practicing designers perceive the role of AI in the creative process,
we developed a game level design tool for Super Mario Bros.-style games with a built-in
AI level designer. In this paper we discuss our design of the Morai Maker intelligent
tool through two mixed-methods studies with a total of over one-hundred participants.
Our findings are as follows: (1) level designers vary in their desired interactions
with, and role of, the AI, (2) the AI prompted the level designers to alter their
design practices, and (3) the level designers perceived the AI as having potential
value in their design practice, varying based on their desired role for the AI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300855,
author = {Hirzle, Teresa and Gugenheimer, Jan and Geiselhart, Florian and Bulling, Andreas and Rukzio, Enrico},
title = {A Design Space for Gaze Interaction on Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300855},
abstract = {Augmented and virtual reality (AR/VR) has entered the mass market and, with it, will
soon eye tracking as a core technology for next generation head-mounted displays (HMDs).
In contrast to existing gaze interfaces, the 3D nature of AR and VR requires estimating
a user's gaze in 3D. While first applications, such as foveated rendering, hint at
the compelling potential of combining HMDs and gaze, a systematic analysis is missing.
To fill this gap, we present the first design space for gaze interaction on HMDs.
Our design space covers human depth perception and technical requirements in two dimensions
aiming to identify challenges and opportunities for interaction design. As such, our
design space provides a comprehensive overview and serves as an important guideline
for researchers and practitioners working on gaze interaction on HMDs. We further
demonstrate how our design space is used in practice by presenting two interactive
applications: EyeHealth and XRay-Vision.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300856,
author = {Shaw, Emily and Roper, Tessa and Nilsson, Tommy and Lawson, Glyn and Cobb, Sue V.G. and Miller, Daniel},
title = {The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300856},
abstract = {Understanding validity of user behaviour in Virtual Environments (VEs) is critical
as they are increasingly being used for serious Health and Safety applications such
as predicting human behaviour and training in hazardous situations. This paper presents
a comparative study exploring user behaviour in VE-based fire evacuation and investigates
whether this is affected by the addition of thermal and olfactory simulation. Participants
(N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative
analyses of participant attitudes and behaviours found deviations from those we would
expect in real life (e.g. pre-evacuation actions), but also valid behaviours like
fire avoidance. Potentially important differences were found between multisensory
and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant
potential in safety-related applications, and that multimodality may afford additional
uses in this context, but the identified limitations of behavioural validity must
be carefully considered to avoid misapplication of the technology.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300857,
author = {Roussou, Maria and Perry, Sara and Katifori, Akrivi and Vassos, Stavros and Tzouganatou, Angeliki and McKinney, Sierra},
title = {Transformation through Provocation?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300857},
abstract = {Can a chatbot enable us to change our conceptions, to be critically reflective? To
what extent can interaction with a technologically 'minimal' medium such as a chatbot
evoke emotional engagement in ways that can challenge us to act on the world? In this
paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at
triggering conversations on complex topics (e.g. death, wealth distribution, gender
equality, privacy) and, ultimately, soliciting specific actions from the user it converses
with. We instantiate our design with a use case in the cultural sector, specifically
a Neolithic archaeological site that acts as a stage of conversation on such hard
themes. Our larger contributions include an interaction framework for bots of conviction,
insights gained from an iterative process of participatory design and evaluation,
and a vision for bot interaction mechanisms that can apply to the HCI community more
widely.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300858,
author = {Yamaoka, Junichi and Dogan, Mustafa Doga and Bulovic, Katarina and Saito, Kazuya and Kawahara, Yoshihiro and Kakehi, Yasuaki and Mueller, Stefanie},
title = {FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300858},
abstract = {We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics
into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it
foldable into a honeycomb structure using a cutting plotter; before folding the sheet
into a 3D structure, users place the electronic components and circuitry onto the
sheet. The fabrication process only takes a few minutes allowing to rapidly prototype
functional interactive devices. The resulting objects are lightweight and rigid, thus
allowing for weight-sensitive and force-sensitive applications. Finally, due to the
nature of the honeycomb structure, the objects can be folded flat along one axis and
thus can be efficiently transported in this compact form factor. We describe the structure
of the foldable sheet, and present a design tool that enables users to quickly prototype
the desired objects. We showcase a range of examples made with our design tool, including
objects with integrated sensors and display elements.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300859,
author = {Khairuddin, Irni Eliana and Sas, Corina},
title = {An Exploration of Bitcoin Mining Practices: Miners' Trust Challenges and Motivations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300859},
abstract = {Bitcoin blockchain technology is a distributed ledger of nodes authorizing transactions
between anonymous parties. Its key actors are miners using computational power to
solve mathematical problems for validating transactions. By sharing blockchain's characteristics,
mining is a decentralized, transparent and unregulated practice, less explored in
HCI, so we know little about miners' motivations and experiences, and how these may
impact on different dimensions of trust. This paper reports on interviews with 20
bitcoin miners about their practices and trust challenges. Findings contribute to
HCI theories by extending the exploration of blockchain's characteristics relevant
to trust with the competitiveness dimension underpinning the social organization of
mining. We discuss the risks of collaborative mining due to centralization and dishonest
administrators, and conclude with design implications highlighting the need for tools
monitoring the distribution of rewards in collaborative mining, tools tracking data
centers' authorization and reputation, and tools supporting the development of decentralized
pools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300860,
author = {Rodger, Sunil and Jackson, Dan and Vines, John and McLaughlin, Janice and Wright, Peter},
title = {JourneyCam: Exploring Experiences of Accessibility and Mobility among Powered Wheelchair Users through Video and Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300860},
abstract = {Recent HCI research has investigated how digital technologies might enable citizens
to identify and express matters of civic concern. We extend this work by describing
JourneyCam, a smartphone-based system that enables powered wheelchair users to capture
video and sensor data about their experiences of mobility. Thirteen participants used
JourneyCam to document journeys, after which the data they collected was used to support
discussions around their experiences. Our findings highlight how the system facilitated
the articulation of complex embodied experiences, and how the collected data might
have particular value in surfacing these experiences to help inform urban design and
policymaking. Participants valued the ways in which JourneyCam's moving image and
sensor data made hard-to-express sensations apparent, as well as how it enabled them
to surface previously unrecognised issues. We conclude by highlighting future opportunities
for how such tools might enable citizens to inform and influence civic governance.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300861,
author = {da Rocha Tom\'{e} Filho, Frederico and Mirza-Babaei, Pejman and Kapralos, Bill and Moreira Mendon\c{c}a Junior, Glaudiney},
title = {Let's Play Together: Adaptation Guidelines of Board Games for Players with Visual Impairment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300861},
abstract = {Board games present accessibility barriers for players with visual impairment since
they often employ visuals alone to communicate gameplay information. Our research
focuses on board game accessibility for those with visual impairment. This paper describes
a three-phase study conducted to develop board game accessibility adaptation guidelines.
These guidelines were developed through a user-centered design approach that included
in-depth interviews and a series of user studies using two adapted board games. Our
findings indicate that participants with and without visual impairment were able to
play the adapted games, exhibiting a balanced experience whereby participants had
complete autonomy and were provided with equal chances of victory. Our paper also
contributes to the game and accessibility communities through the development of adaptation
guidelines that allow board games to become inclusive irrespective of a player's visual
impairment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300862,
author = {Markvicka, Eric and Wang, Guanyun and Lee, Yi-Chin and Laput, Gierad and Majidi, Carmel and Yao, Lining},
title = {ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300862},
abstract = {Wearables have emerged as an increasingly promising interactive platform, imbuing
the human body with always-available computational capabilities. This unlocks a wide
range of applications, including discreet information access, health monitoring, fitness,
and fashion. However, unlike previous platforms, wearable electronics require structural
conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically
appealing. We envision a future where electronics can be temporarily attached to the
body (like bandages or party masks), but in functional and aesthetically pleasing
ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that
simplifies the creation of highly-functional and stretchable wearable electronics
that are conformal and fully untethered by discretizing rigid circuit boards into
individual components. These individual components are wired together using stretchable
electrical wiring and assembled on a spandex blend fabric, to provide high functionality
in a robust form-factor that is reusable. We describe our system in detail- including
our fabrication parameters and its operational limits-which we hope researchers and
practitioners can leverage. We describe a series of example applications that illustrate
the feasibility and utility of our system. Overall, we believe ElectroDermis offers
a complementary approach to wearable electronics-one that places value on the notion
of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic
nature of the human body.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300863,
author = {Koch, Janin and Lucero, Andr\'{e}s and Hegemann, Lena and Oulasvirta, Antti},
title = {May AI? Design Ideation with Cooperative Contextual Bandits},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300863},
abstract = {Design ideation is a prime creative activity in design. However, it is challenging
to support computationally due to its quickly evolving and exploratory nature. The
paper presents cooperative contextual bandits (CCB) as a machine-learning method for
interactive ideation support. A CCB can learn to propose domain-relevant contributions
and adapt their exploration/exploitation strategy. We developed a CCB for an interactive
design ideation tool that 1) suggests inspirational and situationally relevant materials
("may AI?"); 2) explores and exploits inspirational materials with the designer; and
3) explains its suggestions to aid reflection. The application case of digital mood
board design is presented, wherein visual inspirational materials are collected and
curated in collages. In a controlled study, 14 of 16 professional designers preferred
the CCB-augmented tool. The CCB approach holds promise for ideation activities wherein
adaptive and steerable support is welcome but designers must retain full outcome control.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300864,
author = {Xia, Meng and Sun, Mingfei and Wei, Huan and Chen, Qing and Wang, Yong and Shi, Lei and Qu, Huamin and Ma, Xiaojuan},
title = {PeerLens: Peer-Inspired Interactive Learning Path Planning in Online Question Pool},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300864},
abstract = {Online question pools like LeetCode provide hands-on exercises of skills and knowledge.
However, due to the large volume of questions and the intent of hiding the tested
knowledge behind them, many users find it hard to decide where to start or how to
proceed based on their goals and performance. To overcome these limitations, we present
PeerLens, an interactive visual analysis system that enables peer-inspired learning
path planning. PeerLens can recommend a customized, adaptable sequence of practice
questions to individual learners, based on the exercise history of other users in
a similar learning scenario. We propose a new way to model the learning path by submission
types and a novel visual design to facilitate the understanding and planning of the
learning path. We conducted a within-subject experiment to assess the efficacy and
usefulness of PeerLens in comparison with two baseline systems. Experiment results
show that users are more confident in arranging their learning path via PeerLens and
find it more informative and intuitive.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300865,
author = {Cajander, \r{A}sa and Gr\"{u}nloh, Christiane},
title = {Electronic Health Records Are More Than a Work Tool: Conflicting Needs of Direct and Indirect Stakeholders},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300865},
abstract = {The involvement of stakeholders is crucial when designing IT in highly complex application
domains, such as healthcare. Stakeholder relationships are complex and can include
strongly conflicting needs and value tensions. In this case study, we investigate
the different perspectives of patients and physicians related to Patient Accessible
Electronic Health Records (PAEHR) in Sweden. Generally, the introduction of this service
has been heavily criticised by healthcare professionals, but welcomed by patients.
The paper presents an innovative study design where themes from interviews with physicians
are used as a lens to analyse survey data from patients. The findings highlight the
necessity to understand stakeholders' perspectives about other stakeholder groups
by contrasting assumptions and expectations of physicians (indirect stakeholders)
with experience of use by patients (direct stakeholders), and discusses practical
challenges when designing large-scale health information systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300866,
author = {Zhang, Mingrui Ray and Zhai, Shumin and Wobbrock, Jacob O.},
title = {Text Entry Throughput: Towards Unifying Speed and Accuracy in a Single Performance Metric},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300866},
abstract = {Human-computer input performance inherently involves speed-accuracy tradeoffs---the
faster users act, the more inaccurate those actions are. Therefore, comparing speeds
and accuracies separately can result in ambiguous outcomes: Does a fast but inaccurate
technique perform better or worse overall than a slow but accurate one? For pointing,
speed and accuracy has been unified for over 60 years as throughput (bits/s) (Crossman
1957, Welford 1968), but to date, no similar metric has been established for text
entry. In this paper, we introduce a text entry method-independent throughput metric
based on Shannon information theory (1948). To explore the practical usability of
the metric, we conducted an experiment in which 16 participants typed with a laptop
keyboard using different cognitive sets, i.e., speed-accuracy biases. Our results
show that as a performance metric, text entry throughput remains relatively stable
under different speed-accuracy conditions. We also evaluated a smartphone keyboard
with 12 participants, finding that throughput varied least compared to other text
entry metrics. This work allows researchers to characterize text entry performance
with a single unified measure of input efficiency.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300867,
author = {Semmens, Rob and Martelaro, Nikolas and Kaveti, Pushyami and Stent, Simon and Ju, Wendy},
title = {Is Now A Good Time? An Empirical Study of Vehicle-Driver Communication Timing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300867},
abstract = {Advances in automotive sensing systems and speech interfaces provide new opportunities
for smarter driving assistants or infotainment systems. For both safety and consumer
satisfaction reasons, any new system which interacts with drivers must do so at appropriate
times. We asked 63 drivers, ''Is now a good time?'' to receive non-driving information
during a 50-minute drive. We analyzed 2,734 responses and synchronized automotive
and video data, and show that while the chances of choosing a good time can be determined
with better success using easily accessible automotive data, certain nuances in the
problem require a richer understanding of the driver and environment states in order
to achieve higher performance. We illustrate several of these nuances with quantitative
and qualitative analyses to contribute to the understanding of how to design a system
that might simultaneously minimize the risk of interacting at a bad time while maximizing
the window of allowable interruption.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300868,
author = {Mueller, Florian Floyd and Li, Zhuying and Byrne, Richard and Mehta, Yash Dhanpal and Arnold, Peter and Kari, Tuomas},
title = {A 2nd Person Social Perspective on Bodily Play},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300868},
abstract = {Recent HCI work on digital games highlighted the advantage for designers to take on
a 1st person perspective on the human body (referring to the phenomenological "lived"
body) and a 3rd person perspective (the material "fleshy" body, similar to looking
in the mirror). This is useful when designing bodily play, however, we note that there
is not much game design discussion on the 2nd person social perspective that highlights
the unique interplay between human bodies. To guide designers interested in supporting
players to experience their bodies as play, we describe how game designers can engage
with the 2nd person social perspective through a set of design tactics based on four
of our own play systems. With our work, we hope we can aid designers in embracing
this 2nd person perspective so that more people can benefit from engaging their bodies
through games and play.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300869,
author = {Fuentes, Carolina and Porcheron, Martin and Fischer, Joel E. and Costanza, Enrico and Malilk, Obaid and Ramchurn, Sarvapali D.},
title = {Tracking the Consumption of Home Essentials},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300869},
abstract = {Predictions of people's behaviour increasingly drive interactions with a new generation
of IoT services designed to support everyday life in the home, from shopping to heating.
Based on the premise that such automation is difficult due to the contingent nature
of people's practices, in this work we explore the nature of these contingencies in
depth. We have designed and conducted a technology probe that made use of simple linear
predictions as a provocation, and invited people to track the life of their household
essentials over a two-month period. Through a mixed-method approach we demonstrate
the challenges of simple predictions, and in turn identify eight categories of contingencies
that influenced prediction accuracy. We discuss strategies for how designers of future
predictive IoT systems may take the contingencies into account by removing, hiding,
revealing, managing, or exploiting the system uncertainty at the core of the issue.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300870,
author = {Mairena, Aristides and Gutwin, Carl and Cockburn, Andy},
title = {Peripheral Notifications in Large Displays: Effects of Feature Combination and Task Interference},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300870},
abstract = {Visual notifications are integral to interactive computing systems. With large displays,
however, much of the content is in the user's visual periphery, where human capacity
to notice visual effects is diminished. One design strategy for enhancing noticeability
is to combine visual features, such as motion and colour. Yet little is known about
how feature combinations affect noticeability across the visual field, or about how
peripheral noticeability changes when a user's primary task involves the same visual
features as the notification. We addressed these questions by conducting two studies.
Results of the first study showed that noticeability of feature combinations were
approximately equal to the better of the individual features. Results of the second
study suggest that there can be interference between the features of primary tasks
and the visual features in the notifications. Our findings contribute to a better
understanding of how visual features operate when used as peripheral notifications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300871,
author = {Goguey, Alix and Sahoo, Deepak Ranjan and Robinson, Simon and Pearson, Jennifer and Jones, Matt},
title = {Pulp Friction: Exploring the Finger Pad Periphery for Subtle Haptic Feedback},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300871},
abstract = {Current haptic feedback techniques on handheld devices are applied to the finger pad
or the palm of the user. These state-of-the-art approaches are coarse-grained and
tend to be intrusive, rather than subtle. In contrast, we present a new feedback technique
that applies stimuli around the periphery of the finger pulp, demonstrating how this
can provide rich, nuanced haptic information. We use a reconfigurable haptic device
employing a ferromagnetic marble for back-of-the device handheld use, which, for the
first time, probes, without instrumenting the user, the periphery of the distal phalanx
with localised stimulation. We present the design-space afforded by this new technique
and evaluate the human-factors of finger-peripheral touch interaction in a controlled
user-study. We report results with marbles of different diameters, speeds and a combination
of poking, lateral vibration and patterns; present the resulting design guidelines
for finger-periphery haptic feedback; and, illustrate its potential with use case
scenarios.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300872,
author = {Kuo, Pei-Yi and Saran, Rajiv and Argentina, Marissa and Heung, Michael and Bragg-Gresham, Jennifer L. and Chatoth, Dinesh and Gillespie, Brenda and Krein, Sarah and Wingard, Rebecca and Zheng, Kai and Veinot, Tiffany C.},
title = {Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300872},
abstract = {Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis
sessions are complicated by intradialytic hypotension ("IDH"). There is a need for
approaches to preventing IDH that account for their implementation contexts. Using
Activity Theory, we outline the design of a digital diagnostic checklist to identify
patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior
evidence of effectiveness. Drawing on individual interviews with 20 clinicians and
three focus groups with 17 patients, we describe four activity systems within hemodialysis
care. We then outline a novel design process that includes co-design activities with
clinicians, and four rapid-cycle iterations that progressively incorporated activity
system elements into checklist design. We contribute a new type of checklist design
to HCI: one that supports diagnostic thinking rather than consistent task completion.
We further broaden checklist design by including a formal role for patients in checklist
completion.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300873,
author = {Kasahara, Shunichi and Nishida, Jun and Lopes, Pedro},
title = {Preemptive Action: Accelerating Human Reaction Using Electrical Muscle Stimulation Without Compromising Agency},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300873},
abstract = {We enable preemptive force-feedback systems to speed up human reaction time without
fully compromising the user's sense of agency. Typically these interfaces actuate
by means of electrical muscle stimulation (EMS) or mechanical actuators; they preemptively
move the user to perform a task, such as to improve movement performance (e.g., EMS-assisted
drumming). Unfortunately, when using preemptive force-feedback users do not feel in
control and loose their sense of agency. We address this by actuating the user's body,
using EMS, within a particular time window (160 ms after visual stimulus), which we
found to speed up reaction time by 80 ms in our first study. With this preemptive
timing, when the user and system move congruently, the user feels that they initiated
the motion, yet their reaction time is faster than usual. As our second study demonstrated,
this particular timing significantly increased agency when compared to the current
practice in EMS-based devices. We conclude by illustrating, using examples from the
HCI literature, how to leverage our findings to provide more agency to automated haptic
interfaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300874,
author = {Boukhelifa, Nadia and Bezerianos, Anastasia and Trelea, Ioan Cristian and Perrot, Nathalie M\'{e}jean and Lutton, Evelyne},
title = {An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300874},
abstract = {Experts in different domains rely increasingly on simulation models of complex processes
to reach insights, make decisions, and plan future projects. These models are often
used to study possible trade-offs, as experts try to optimise multiple conflicting
objectives in a single investigation. Understanding all the model intricacies, however,
is challenging for a single domain expert. We propose a simple approach to support
multiple experts when exploring complex model results. First, we reduce the model
exploration space, then present the results on a shared interactive surface, in the
form of a scatterplot matrix and linked views. To explore how multiple experts analyse
trade-offs using this setup, we carried out an observational study focusing on the
link between expertise and insight generation during the analysis process. Our results
reveal the different exploration strategies and multi-storyline approaches that domain
experts adopt during trade-off analysis, and inform our recommendations for collaborative
model exploration systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300875,
author = {Strengers, Yolande and Kennedy, Jenny and Arcari, Paula and Nicholls, Larissa and Gregg, Melissa},
title = {Protection, Productivity and Pleasure in the Smart Home: Emerging Expectations and Gendered Insights from Australian Early Adopters},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300875},
abstract = {Interest and uptake of smart home technologies has been lower than anticipated, particularly
among women. Reporting on an academic-industry partnership, we present findings from
an ethnographic study with 31 Australian smart home early adopters. The paper analyses
these households' experiences in relation to three concepts central to Intel's ambient
computing vision for the home: protection, productivity and pleasure, or 'the 3Ps'.
We find that protection is a form of caregiving; productivity provides 'small conveniences',
energy savings and multi-tasking possibilities; and pleasure is derived from ambient
and aesthetic features, and the joy of 'playing around' with tech. Our analysis identifies
three design challenges and opportunities for the smart home: internal threats to
household protection; feminine desires for the smart home; and increased 'digital
housekeeping'. We conclude by suggesting how HCI designers can and should respond
to these gendered challenges.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300876,
author = {Krafft, Peter M. and Spiro, Emma S.},
title = {Keeping Rumors in Proportion: Managing Uncertainty in Rumor Systems},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300876},
abstract = {The study of rumors has garnered wider attention as regulators and researchers turn
towards problems of misinformation on social media. One goal has been to discover
and implement mechanisms that promote healthy information ecosystems. Classically
defined as regarding ambiguous situations, rumors pose the unique difficulty of intrinsic
uncertainty around their veracity. Further complicating matters, rumors can serve
the public when they do spread valuable true information. To address these challenges,
we develop an approach that reifies "rumor proportions" as central to the theory of
systems for managing rumors. We use this lens to advocate for systems that, rather
than aiming to stifle rumors entirely or aiming to stop only false rumors, aim to
prevent rumors from growing out of proportion relative to normative benchmark representations
of intrinsic uncertainty.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300877,
author = {Ion, Alexandra and Lindlbauer, David and Herholz, Philipp and Alexa, Marc and Baudisch, Patrick},
title = {Understanding Metamaterial Mechanisms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300877},
abstract = {In this paper, we establish the underlying foundations of mechanisms that are composed
of cell structures---known as metamaterial mechanisms. Such metamaterial mechanisms
were previously shown to implement complete mechanisms in the cell structure of a
3D printed material, without the need for assembly. However, their design is highly
challenging. A mechanism consists of many cells that are interconnected and impose
constraints on each other. This leads to unobvious and non-linear behavior of the
mechanism, which impedes user design. In this work, we investigate the underlying
topological constraints of such cell structures and their influence on the resulting
mechanism. Based on these findings, we contribute a computational design tool that
automatically creates a metamaterial mechanism from user-defined motion paths. This
tool is only feasible because our novel abstract representation of the global constraints
highly reduces the search space of possible cell arrangements.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300878,
author = {Prabhakar, Annu Sible and Stolterman, Erik and \v{S}abanovi\'{c}, Selma},
title = {Understanding Life Transitions: A Case Study of Support Needs of Low-Income Mothers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300878},
abstract = {Life transitions are an integral part of the human experience. However, research shows
that lack of support during life transitions can result in adverse health outcomes.
To better understand the support needs and structures of low-income women during transition
to motherhood, we interviewed 10 women and their 14 supporters during the transition.
Our findings suggest that support needs and structures of mothers evolve during transition,
and that they also vary by socio-economic contexts. In this paper, we detail our study
design and findings. Informed by our findings, we posit that all life-transitions
are not the same, and that therefore, the optimal support intervention point varies
for different life transitions. Currently there are no tools available to identify
optimal support intervention points during life transitions. To this end, we also
introduce a preliminary framework - the Strength-Stress-Analysis (SSA) framework -
to identify optimal support intervention points during life-transitions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inbook{10.1145/3290605.3300879,
author = {Dillahunt, Tawanna R. and Simioni, Sylvia and Xu, Xuecong},
title = {Online Grocery Delivery Services: An Opportunity to Address Food Disparities in Transportation-Scarce Areas},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300879},
abstract = {Online grocery delivery services present new opportunities to address food disparities,
especially in underserved areas. However, such services have not been systematically
evaluated. This study evaluates such services' potential to provide healthy-food access
and influence healthy-food purchases among individuals living in transportation-scarce
and low-resource areas. We conducted a pilot experiment with 20 participants consisting
of a randomly assigned group's 1-month use of an online grocery delivery service,
and a control group's 1-month collection of grocery receipts, and a set of semi-structured
interviews. We found that online grocery delivery services (a) serve as a feasible
model to healthy-food access if they are affordable and amenable to multiple payment
forms and (b) could lead to healthier selections. We contribute policy recommendations
to bolster affordability of healthy-food access and design opportunities to promote
healthy foods to support the adoption and use of these services among low-resource
and transportation-scarce groups.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300880,
author = {Neate, Timothy and Bourazeri, Aikaterini and Roper, Abi and Stumpf, Simone and Wilson, Stephanie},
title = {Co-Created Personas: Engaging and Empowering Users with Diverse Needs Within the Design Process},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300880},
abstract = {Personas are powerful tools for designing technology and envisioning its usage. They
are widely used to imagine archetypal users around whom to orient design work. We
have been exploring co-created personas as a technique to use in co-design with users
who have diverse needs. Our vision was that this would broaden the demographic and
liberate co-designers of their personal relationship with a health condition. This
paper reports three studies where we investigated using co-created personas with people
who had Parkinson's disease, dementia or aphasia. Observational data of co-design
sessions were collected and analysed. Findings revealed that the co-created personas
encouraged users with diverse needs to engage with co-designing. Importantly, they
also afforded additional benefits including empowering users within a more accessible
design process. Reflecting on the outcomes from the different user groups, we conclude
with a discussion of the potential for co-created personas to be applied more broadly.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300881,
author = {Pater, Jessica A. and Reining, Lauren E. and Miller, Andrew D. and Toscos, Tammy and Mynatt, Elizabeth D.},
title = {"Notjustgirls": Exploring Male-Related Eating Disordered Content across Social Media Platforms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300881},
abstract = {Eating disorders (EDs) are a worldwide public health concern that impact approximately
10% of the U.S. population. Our previous research characterized these behaviors across
online spaces. These characterizations have used clinical terminology, and their lexical
variants, to identify ED content online. However, previous HCI research on EDs (including
our own) suffers from a lack of gender and cultural diversity. In this paper, we designed
a follow-up study of online ED characterizations, extending our previous methodologies
to focus specifically on male/masculine-related content. We highlight the similarities
and differences found in the terminology utilized and media archetypes associated
with the social media content. Finally, we discuss other considerations highlighted
through our analysis of the male-related content that is missing from the previous
research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300882,
author = {Strohmayer, Angelika and Clamen, Jenn and Laing, Mary},
title = {Technologies for Social Justice: Lessons from Sex Workers on the Front Lines},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300882},
abstract = {This paper provides analysis and insight from a collaborative process with a Canadian
sex worker rights organization called Stella, l'amie de Maimie, where we reflect on
the use of and potential for digital technologies in service delivery. We analyze
the Bad Client and Aggressor List - a reporting tool co-produced by sex workers in
the community and Stella staff to reduce violence against sex workers. We analyze
its current and potential future formats as an artefact for communication, in a context
of sex work criminalization and the exclusion of sex workers from traditional routes
for reporting violence and accessing governmental systems for justice. This paper
addresses a novel aspect of HCI research that relates to digital technologies and
social justice. Reflecting on the Bad Client and Aggressor List, we discuss how technologies
can interact with justice-oriented service delivery and develop three implications
for design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300883,
author = {Tomprou, Maria and Dabbish, Laura and Kraut, Robert E. and Liu, Fannie},
title = {Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300883},
abstract = {Although people frequently seek mentoring or advice for their career, most mentoring
is performed in person. Little research has examined the nature and quality of career
mentoring online. To address this gap, we study how people use online Q&amp;A forums for
career advice. We develop a taxonomy of career advice requests based on a qualitative
analysis of posts in a career-related online forum, identifying three key types: best
practices, career threats, and time-sensitive requests. Our quantitative analysis
of responses shows that both requesters and external viewers value general information,
encouragement, and guidance, but not role modeling. We found no relation between the
type of requests and features of responses, nor differences in responses valued by
requesters versus external viewers. We present design recommendations for supporting
online career advice exchange.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300884,
author = {Grundgeiger, Tobias and Huber, Stephan and Reinhardt, Daniel and Steinisch, Andreas and Happel, Oliver and Wurmb, Thomas},
title = {Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-Hospital Emergency Teams},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300884},
abstract = {Cognitive aids - artefacts that support a user in the completion of a task at the
time - have raised great interest to support healthcare staff during medical emergencies.
However, the mechanisms of how cognitive aids support or affect staff remain understudied.
We describe the iterative development of a tablet-based cognitive aid application
to support in-hospital resuscitation team leaders. We report a summative evaluation
of two different versions of the application. Finally, we outline the limitations
of current explanations of how cognitive aids work and suggest an approach based on
embodied cognition. We discuss how cognitive aids alter the task of the team leader
(distributed cognition), the importance of the present team situation (socially situated),
and the result of the interaction between mind and environment (sensorimotor coupling).
Understanding and considering the implications of introducing cognitive aids may help
to increase acceptance and effectiveness of cognitive aids and eventually improve
patient safety.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300885,
author = {Lim, Catherine Y. and Berry, Andrew B.L. and Hartzler, Andrea L. and Hirsch, Tad and Carrell, David S. and Bermet, Zo\"{e} A. and Ralston, James D.},
title = {Facilitating Self-Reflection about Values and Self-Care Among Individuals with Chronic Conditions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300885},
abstract = {Individuals with multiple chronic conditions (MCC) experience the overwhelming burden
of treating MCC and frequently disagree with their providers on priorities for care.
Aligning self-care with patients' values may improve healthcare for these patients.
However, patients' values are not routinely discussed in clinical conversations and
patients may not actively share this information with providers. In a qualitative
field study, we interviewed 15 patients in their homes to investigate techniques that
encourage patients to articulate values, self-care, and how they relate. Study activities
facilitated self-reflection on values and self-care and produced varying responses,
including: raising consciousness, evolving perspectives, identifying misalignments,
and considering changes. We discuss how our findings extend prior work on supporting
reflection in HCI and inform the design of tools for improving care for people with
MCC.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300886,
author = {Shi, Joshua and Shah, Armaan and Hedman, Garrett and O'Rourke, Eleanor},
title = {Pyrus: Designing A Collaborative Programming Game to Promote Problem Solving Behaviors},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300886},
abstract = {While problem solving is a crucial aspect of programming, few learning opportunities
in computer science focus on teaching problem-solving skills like planning. In this
paper, we present Pyrus, a collaborative game designed to encourage novices to plan
in advance while programming. Through Pyrus, we explore a new approach to designing
educational games we call behavior-centered game design, in which designers first
identify behaviors that learners should practice to reach desired learning goals and
then select game mechanics that incentivize those behaviors. Pyrus leverages game
mechanics like a failure condition, distributed resources, and enforced turn-taking
to encourage players to plan and collaborate. In a within-subjects user study, we
found that pairs of novices spent more time planning and collaborated more equally
when solving problems in Pyrus than in pair programming. These findings show that
game mechanics can be used to promote desirable learning behaviors like planning in
advance, and suggest that our behavior-centered approach to educational game design
warrants further study.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300887,
author = {Spence, Jocelyn},
title = {Inalienability: Understanding Digital Gifts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300887},
abstract = {This paper takes on one of the rarely articulated yet important questions pertaining
to digital media objects: how do HCI and design researchers understand 'gifting' when
the object can just as easily be 'shared'? This question has often been implied and
occasionally answered, though only partially. We propose the concept of 'inalienability',
taken from the gifting literature, as a useful theory for clarifying what design researchers
mean by gifting in a digital context. We apply 'inalienability' to three papers from
the ACM Digital Library and one ongoing project, spanning nearly two decades of HCI
and design research, that combine 'gifting and 'sharing' in their frameworks. In this
way we show how applying the concept of 'inalienability' can clarify behaviours that
mark gifting as a unique activity, frame research questions around gifting and sharing,
outline specific next steps for gifting research, and suggest design strategies in
this area.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300888,
author = {Tajadura-Jim\'{e}nez, Ana and Newbold, Joseph and Zhang, Linge and Rick, Patricia and Bianchi-Berthouze, Nadia},
title = {As Light as You Aspire to Be: Changing Body Perception with Sound to Support Physical Activity},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300888},
abstract = {Supporting exercise adherence through technology remains an important HCI challenge.
Recent works showed that altering walking sounds leads people perceiving themselves
as thinner/lighter, happier and walking more dynamically. While this novel approach
shows potential for physical activity, it raises critical questions impacting technology
design. We ran two studies in the context of exertion (gym-step, stairs-climbing)
to investigate how individual factors impact the effect of sound and the duration
of the after-effects. The results confirm that the effects of sound in body-perception
occur even in physically demanding situations and through ubiquitous wearable devices.
We also show that the effect of sound interacted with participants' body weight and
masculinity/femininity aspirations, but not with gender. Additionally, changes in
body-perceptions did not hold once the feedback stopped; however, body-feelings or
behavioural changes appeared to persist for longer. We discuss the results in terms
of malleability of body-perception and highlight opportunities for supporting exercise
adherence.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300889,
author = {G\'{o}mez-Zar\'{a}, Diego and Paras, Matthew and Twyman, Marlon and Lane, Jacqueline N. and DeChurch, Leslie A. and Contractor, Noshir S.},
title = {Who Would You Like to Work With?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300889},
abstract = {People and organizations are increasingly using online platforms to assemble teams.
In response, HCI researchers have theorized frameworks and created systems to support
team assembly. However, little is known about how users search for and choose teammates
on these platforms. We conducted a field study where 530 participants used a team
formation system to assemble project teams. We describe how users' traits and social
networks influence their teammate searches, teammate choices, and team composition.
Our results show that (a) what users initially search for differs from what they finally
choose: initially they search for experts and sociable users, but they are ultimately
more likely to choose their prior social connections as their teammates; (b) users'
decisions lead to non-diverse and segregated teams, where most of the expertise and
social capital are concentrated in a few teams. We discuss the implications of these
results for designing team formation systems than promote users' agency.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300890,
author = {Forman, Jack and Tabb, Taylor and Do, Youngwook and Yeh, Meng-Han and Galvin, Adrian and Yao, Lining},
title = {ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300890},
abstract = {Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction
(HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics,
and human hair, accessible line-based actuators are very limited beyond shape memory
alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel,
yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled
nylon thread actuator with a silicone coating. This composite thread actuator exhibits
unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical
current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily
woven or sewn, hence it has a great potential as an embedded line-based actuator for
HCI purposes. In this paper, we explain the material mechanisms and manufacturing
approaches, followed by some performance tests and application demonstrations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300891,
author = {Marcu, Gabriela and Spiller, Allison and Arevalo Garay, Jonathan and Connell, James E. and Pina, Laura R.},
title = {Breakdowns in Home-School Collaboration for Behavioral Intervention},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300891},
abstract = {For some children, behavioral health services are critical in supporting their development
and preventing adverse outcomes such as school dropout, substance use, or encounters
with juvenile justice. Schools play an important role in identifying problem behavior
and providing appropriate intervention, and these efforts are most effective when
executed in collaboration with parents at home. However, home-school collaboration
is difficult to achieve. In this work, we investigated lack of information sharing
as a barrier to collaboration, through a qualitative study including observation,
contextual inquiry, and interviews. We found that policies, processes, and tools for
documenting behaviors in schools are implemented without significant consideration
toward exchanging information with parents. Consequently, a lack of effective two-way
information sharing tended to hinder collaboration and erode trust. Combining our
empirical findings with evidence-based strategies for parent involvement, we discuss
design opportunities for promoting collaboration toward positive behavioral outcomes
for children.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300892,
author = {Hu, Kevin and Gaikwad, Snehalkumar 'Neil' S. and Hulsebos, Madelon and Bakker, Michiel A. and Zgraggen, Emanuel and Hidalgo, C\'{e}sar and Kraska, Tim and Li, Guoliang and Satyanarayan, Arvind and Demiralp, \c{C}a\u{g}atay},
title = {VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300892},
abstract = {Researchers currently rely on ad hoc datasets to train automated visualization tools
and evaluate the effectiveness of visualization designs. These exemplars often lack
the characteristics of real-world datasets, and their one-off nature makes it difficult
to compare different techniques. In this paper, we present VizNet: a large-scale corpus
of over 31 million datasets compiled from open data repositories and online visualization
galleries. On average, these datasets comprise 17 records over 3 dimensions and across
the corpus, we find 51% of the dimensions record categorical data, 44% quantitative,
and only 5% temporal. VizNet provides the necessary common baseline for comparing
visualization design techniques, and developing benchmark models and algorithms for
automating visual analysis. To demonstrate VizNet's utility as a platform for conducting
online crowdsourced experiments at scale, we replicate a prior study assessing the
influence of user task and data distribution on visual encoding effectiveness, and
extend it by considering an additional task: outlier detection. To contend with running
such studies at scale, we demonstrate how a metric of perceptual effectiveness can
be learned from experimental results, and show its predictive power across test datasets.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300893,
author = {Chidambaram, Subramanian and Zhang, Yunbo and Sundararajan, Venkatraghavan and Elmqvist, Niklas and Ramani, Karthik},
title = {Shape Structuralizer: Design, Fabrication, and User-Driven Iterative Refinement of 3D Mesh Models},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300893},
abstract = {Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users
towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive
design support system that repurposes surface models into structural constructions
using rods and custom 3D-printed joints. Shape Structuralizer embeds a recommendation
system that computationally supports the user during design ideation by providing
design suggestions on local refinements of the design. This strategy enables novice
users to choose designs that both satisfy stress constraints as well as their personal
design intent. The interactive guidance enables users to repurpose existing surface
mesh models, analyze them in-situ for stress and displacement constraints, add movable
joints to increase functionality, and attach a customized appearance. This also empowers
novices to fabricate even complex constructs while ensuring structural soundness.
We validate the Shape Structuralizer tool with a qualitative user study where we observed
that even novice users were able to generate a large number of structurally safe designs
for fabrication.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300894,
author = {Dema, Tshering and Brereton, Margot and Roe, Paul},
title = {Designing Participatory Sensing with Remote Communities to Conserve Endangered Species},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300894},
abstract = {The increasing loss of species globally calls for effective monitoring tools and strategies
to inform conservation action. The dominant approach to citizens engagement has been
smart phone and platform-centric, tasking crowds to collect and analyze data. However,
many critically endangered species inhabit remote areas, characterized by sparsely
populated communities with poor internet connectivity. Approaches need to garner high
engagement relative to population size, with data collection and knowledge synthesis
suited to the local context. We conducted a field study in remote communities to understand
how to enhance conservation of Bhutan's critically endangered White-bellied heron
by exploring existing monitoring practices and trialing acoustic sensing technologies.
We found that knowledge about the species is partial, heterogeneous, situated within
and across communities and rooted in cultural beliefs. Sensors, acoustic interfaces,
and playful probes provided new ways for the community to 'see' and discuss their
local environment fostering them to share and grow their knowledge together. We contribute
a synthesis of key considerations for designing effective participatory sensing to
conserve species in remote communities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300895,
author = {Burgess, Eleanor R. and Reddy, Madhu C. and Davenport, Andrew and Laboi, Paul and Blandford, Ann},
title = {"Tricky to Get Your Head around": Information Work of People Managing Chronic Kidney Disease in the UK},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300895},
abstract = {People diagnosed with a chronic health condition have many information needs which
healthcare providers, patient groups, and resource designers seek to support. However,
as a disease progresses, knowing when, how, and for what purposes patients want to
interact with and construct personal meaning from health-related information is still
unclear. This paper presents findings regarding the information work of chronic kidney
disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians,
and observations at 9 patient group events. We used the stages of the information
journey - recognizing need, seeking, interpreting, and using information - to frame
our data analysis. We identified two distinct but often overlapping information work
phases, 'Learning' and 'Living With' a chronic condition to show how patient information
work activities shift over time. We also describe social and individual factors influencing
information work, and discuss technology design opportunities including customized
education and collaboration tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17}
}

@inbook{10.1145/3290605.3300896,
author = {Dereshev, Dmitry and Kirk, David and Matsumura, Kohei and Maeda, Toshiyuki},
title = {Long-Term Value of Social Robots through the Eyes of Expert Users},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300896},
abstract = {Socially-enabled digital technologies have attracted academic interest for decades,
with recent commercial examples of Siri and Alexa, capturing public attention. However,
despite ubiquitous visions of a robotic future, very few fully-fledged social robots
are currently available to consumers. To improve their designs, studies of their long-term
use are particularly valuable, but are currently unavailable. To address this gap,
we report on interviews with four long-term users of Pepper - a social robot introduced
in 2014. Our thematic analysis elicited insights across three kinds of value Pepper
brought to its users: utilitarian functionality; the community that formed around
Pepper; and a personal value of affection. We focus on two contributions those values
bring to social robot design: social robots as social proxies, alleviating disabilities
or acting akin to social media profiles; and robot nurturing as a design construct,
going beyond purely utilitarian or hedonistic perspectives on robots.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300897,
author = {Li, Jie and Kong, Yiping and R\"{o}ggla, Thomas and De Simone, Francesca and Ananthanarayan, Swamy and de Ridder, Huib and El Ali, Abdallah and Cesar, Pablo},
title = {Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300897},
abstract = {Millions of photos are shared online daily, but the richness of interaction compared
with face-to-face (F2F) sharing is still missing. While this may change with social
Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive
experiences. In this paper, we investigate photo sharing experiences in immersive
environments, focusing on socialVR. Running context mapping (N=10), an expert creative
session (N=6), and an online experience clustering questionnaire (N=20), we develop
and statistically evaluate a questionnaire to measure photo sharing experiences. We
then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing
under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire,
we found that socialVR can closely approximate F2F sharing. We contribute empirical
findings on the immersiveness differences between digital communication media, and
propose a socialVR questionnaire that can in the future generalize beyond photo sharing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300898,
author = {Akbar, Fatema and Bayraktaroglu, Ayse Elvan and Buddharaju, Pradeep and Da Cunha Silva, Dennis Rodrigo and Gao, Ge and Grover, Ted and Gutierrez-Osuna, Ricardo and Jones, Nathan Cooper and Mark, Gloria and Pavlidis, Ioannis and Storer, Kevin and Wang, Zelun and Wesley, Amanveer and Zaman, Shaila},
title = {Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300898},
abstract = {Workplace environments are characterized by frequent interruptions that can lead to
stress. However, measures of stress due to interruptions are typically obtained through
self-reports, which can be affected by memory and emotional biases. In this paper,
we use a thermal imaging system to obtain objective measures of stress and investigate
personality differences in contexts of high and low interruptions. Since a major source
of workplace interruptions is email, we studied 63 participants while multitasking
in a controlled office environment with two different email contexts: managing email
in batch mode or with frequent interruptions. We discovered that people who score
high in Neuroticism are significantly more stressed in batching environments than
those low in Neuroticism. People who are more stressed finish emails faster. Last,
using Linguistic Inquiry Word Count on the email text, we find that higher stressed
people in multitasking environments use more anger in their emails. These findings
help to disambiguate prior conflicting results on email batching and stress.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300899,
author = {Smart, Stephen and Szafir, Danielle Albers},
title = {Measuring the Separability of Shape, Size, and Color in Scatterplots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300899},
abstract = {Scatterplots commonly use multiple visual channels to encode multivariate datasets.
Such visualizations often use size, shape, and color as these dimensions are considered
separable--dimensions represented by one channel do not significantly interfere with
viewers' abilities to perceive data in another. However, recent work shows the size
of marks significantly impacts color difference perceptions, leading to broader questions
about the separability of these channels. In this paper, we present a series of crowdsourced
experiments measuring how mark shape, size, and color influence data interpretation
in multiclass scatterplots. Our results indicate that mark shape significantly influences
color and size perception, and that separability among these channels functions asymmetrically:
shape more strongly influences size and color perceptions in scatterplots than size
and color influence shape. Models constructed from the resulting data can help designers
anticipate viewer perceptions to build more effective visualizations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300900,
author = {Rutjes, Heleen and Willemsen, Martijn C. and IJsselsteijn, Wijnand A.},
title = {Beyond Behavior: The Coach's Perspective on Technology in Health Coaching},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300900},
abstract = {Rapid innovations in electronic healthcare and behavior tracking systems are challenging
health coaches (dietitians, personal trainers, etc.) to rethink their traditional
roles and healthcare practices. At the same time, many current e-coaching systems
have been developed without explicitly incorporating the healthcare professionals'
perspective into the design process. In the current paper, we present three consecutive
qualitative studies, starting from the health coach's perspective on successful coaching,
progressively zooming in on the potential role and impact of technology as part of
the coaching process. Our main finding is that coaches are concerned that introducing
technology in the coaching process puts too much emphasis on behavioral information,
lowering the attention for the client's lived experience, while understanding those
experiences is key for successful coaching. We summarize our insights in a multi-channel
communication model and draw implications for the design of supporting technology
in health coaching.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300901,
author = {McDonald, Nora and Hill, Benjamin Mako and Greenstadt, Rachel and Forte, Andrea},
title = {Privacy, Anonymity, and Perceived Risk in Open Collaboration: A Study of Service Providers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300901},
abstract = {Anonymity can enable both healthy online interactions like support-seeking and toxic
behaviors like hate speech. How do online service providers balance these threats
and opportunities? This two-part qualitative study examines the challenges perceived
by open collaboration service providers in allowing anonymous contributions to their
projects. We interviewed eleven people familiar with organizational decisions related
to privacy and security at five open collaboration projects and followed up with an
analysis of public discussions about anonymous contribution to Wikipedia. We contrast
our findings with prior work on threats perceived by project volunteers and explore
misalignment between policies aiming to serve contributors and the privacy practices
of contributors themselves.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300902,
author = {Teng, Shan-Yuan and Huang, Da-Yuan and Wang, Chi and Gong, Jun and Seyed, Teddy and Yang, Xing-Dong and Chen, Bing-Yu},
title = {Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300902},
abstract = {We propose a new type of haptic output for foreground interactions on an interactive
chair, where input is carried out explicitly in the foreground of the user's consciousness.
This type of force output restricts a user's motion by modulating the resistive force
when rotating a seat, tilting the backrest, or rolling the chair. These interactions
are useful for many applications in a ubiquitous computing environment, ranging from
immersive VR games to rapid and private query of information for people who are occupied
with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed
haptic force output on a standard office chair and determined the recognizability
of five force profiles for rotating, tilting, and rolling the chair. We present the
result of our studies, as well as a set of novel interaction techniques enabled by
this new force output for chairs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300903,
author = {Muender, Thomas and Reinschluessel, Anke V. and Drewes, Sean and Wenig, Dirk and D\"{o}ring, Tanja and Malaka, Rainer},
title = {Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300903},
abstract = {Professionals in domains like film, theater, or architecture often rely on physical
models to visualize spaces. With virtual reality (VR) new tools are available providing
immersive experiences with correct perceptions of depth and scale. However, these
lack the tangibility of physical models. Using tangible objects in VR can close this
gap but creates the challenges of producing suitable objects and interacting with
them with only the virtual objects visible. This work addresses these challenges by
evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for
all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the
virtual shapes. We present results from a comparative study on immersion, performance,
and intuitive interaction and interviews with domain experts. The results show that
3D-printed objects perform best, but Lego offers a good trade-off between fast creation
of tangibles and sufficient fidelity. The experts rate our approach as useful and
would use all three versions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300904,
author = {Jo, Yonggeol and Kim, Minwoo and Han, Kyungsik},
title = {How Do Humans Assess the Credibility on Web Blogs: Qualifying and Verifying Human Factors with Machine Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300904},
abstract = {The purpose of this paper is to understand the factors involved when a human judges
the credibility of information and to develop a classification model for weblogs,
a primary source of information for many people. Considering both computational and
human-centered approaches, we conducted a user study designed to consider two cognitive
procedures--(1) visceral, behavioral and (2) reflective assessments--in the evaluation
of information credibility. The results of the 80-participant study highlight that
human cognitive processing varies according to an individual's purpose and that humans
consider the structures and styles of content in their reflective assessments. We
experimentally proved these findings through the development and analysis of classification
models using 16,304 real blog posts written by 2,944 bloggers. Our models yield greater
accuracy and efficiency than the models with well-known best features identified in
prior research},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300905,
author = {Sra, Misha and Jain, Abhinandan and Maes, Pattie},
title = {Adding Proprioceptive Feedback to Virtual Reality Experiences Using Galvanic Vestibular Stimulation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300905},
abstract = {We present a small and lightweight wearable device that enhances virtual reality experiences
and reduces cybersickness by means of galvanic vestibular stimulation (GVS). GVS is
a specific way to elicit vestibular reflexes that has been used for over a century
to study the function of the vestibular system. In addition to GVS, we support physiological
sensing by connecting heart rate, electrodermal activity and other sensors to our
wearable device using a plug and play mechanism. An accompanying Android app communicates
with the device over Bluetooth (BLE) for transmitting the GVS stimulus to the user
through electrodes attached behind the ears. Our system supports multiple categories
of virtual reality applications with different types of virtual motion such as driving,
navigating by flying, teleporting, or riding. We present a user study in which participants
(N = 20) experienced significantly lower cybersickness when using our device and rated
experiences with GVS-induced haptic feedback as significantly more immersive than
a no-GVS baseline.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300906,
author = {Oh, Seungjae and Yun, Gyeore and Park, Chaeyong and Kim, Jinsoo and Choi, Seungmoon},
title = {VibEye: Vibration-Mediated Object Recognition for Tangible Interactive Applications},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300906},
abstract = {We present VibEye: a vibration-mediated recognition system of objects for tangible
interaction. A user holds an object between two fingers wearing VibEye. VibEye triggers
a vibration from one finger, and the vibration that has propagated through the object
is sensed at the other finger. This vibration includes information about the object's
identity, and we represent it using a spectrogram. Collecting the spectrograms of
many objects, we formulate the object recognition problem to a classical classification
problem among the images. This simple method, when tested with 20 users, shows 92.5%
accuracy for 16 objects of the same shape with various materials. This material-based
classifier is also extended to the recognition of everyday objects. Lastly, we demonstrate
several tangible applications where VibEye provides the needed functionality while
enhancing user experiences. VibEye is particularly effective for recognizing objects
made of different materials, which is difficult to distinguish by other means such
as light and sound.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300907,
author = {Frid, Emma and Lindetorp, Hans and Hansen, Kjetil Falkenberg and Elblaus, Ludvig and Bresin, Roberto},
title = {Sound Forest: Evaluation of an Accessible Multisensory Music Installation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300907},
abstract = {Sound Forest is a music installation consisting of a room with light-emitting interactive
strings, vibrating platforms and speakers, situated at the Swedish Museum of Performing
Arts. In this paper we present an exploratory study focusing on evaluation of Sound
Forest based on picture cards and interviews. Since Sound Forest should be accessible
for everyone, regardless age or abilities, we invited children, teens and adults with
physical and intellectual disabilities to take part in the evaluation. The main contribution
of this work lies in its findings suggesting that multisensory platforms such as Sound
Forest, providing whole-body vibrations, can be used to provide visitors of different
ages and abilities with similar associations to musical experiences. Interviews also
revealed positive responses to haptic feedback in this context. Participants of different
ages used different strategies and bodily modes of interaction in Sound Forest, with
activities ranging from running to synchronized music-making and collaborative play.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300908,
author = {Altarriba Bertran, Ferran and Jhaveri, Samvid and Lutz, Rosa and Isbister, Katherine and Wilde, Danielle},
title = {Making Sense of Human-Food Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300908},
abstract = {Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range
of disciplinary interests and concerns. The dynamic and heterogeneous nature of this
emerging field presents a challenge to scholars wishing to critically engage with
prior work, identify gaps and ensure impact. It also challenges the formation of community.
We present a Systematic Mapping Study of HFI research and an online data visualisation
tool developed to respond to these issues. The tool allows researchers to engage in
new ways with the HFI literature, propose modifications and additions to the review,
and thereby actively engage in community-making. Our contribution is threefold: (1)
we characterize the state of HFI, reporting trends, challenges and opportunities;
(2) we provide a taxonomy and tool for diffractive reading of the literature; and
(3) we offer our approach for adaptation by research fields facing similar challenges,
positing value of the tool and approach beyond HFI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300909,
author = {Wood, Gavin and Dylan, Thomas and Durrant, Abigail and Torres, Pablo E. and Ulrich, Philip and Carr, Amanda and Cukurova, Mutlu and Downey, Denise and McGrath, Phil and Balaam, Madeline and Ferguson, Alice and Vines, John and Lawson, Shaun},
title = {Designing for Digital Playing Out},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300909},
abstract = {We report on a design-led study in the UK that aimed to understand barriers to children
(aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential
of the Internet of Things (IoT) for supporting children's free play that extends outdoors.
The study forms a design ethnography, combining observational fieldwork with design
prototyping and co-creative activities across four linked workshops, where we used
BBC micro:bit devices to co-create new IoT designs with the participating children.
Our collective account contributes new insights about the physical and interactive
features of micro:bits that shaped play, gameplay, and social interaction in the workshops,
illuminating an emerging design space for supporting 'digital playing out' that is
grounded in empirical instances. We highlight opportunities for designing for digital
playing out in ways that promote social negotiation, supports varying participation,
allows for integrating cultural influences, and accounts for the weaving together
of placemaking and play.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300910,
author = {Howell, Noura and Niemeyer, Greg and Ryokai, Kimiko},
title = {Life-Affirming Biosensing in Public: Sounding Heartbeats on a Red Bench},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300910},
abstract = {"Smart city" narratives promise IoT data-driven innovations leveraging biosensing
technologies. We argue this overlooks a potential benefit of city living: affirmation.
We designed the Heart Sounds Bench, which amplifies the heart sounds of those sitting
on it, as well as recording and playing back the heart sounds of previous sitters.
We outline our design intent to invite rest, reflection, and recognition of others'
lives in public space. We share results from a study with 19 participants. Participants
expressed feeling connected to a shared life energy including others and the environment,
and described heart sounds as feeling intimate yet anonymous. Finally, we elaborate
the concept of life-affirmation in terms of recognition of others' lives, feeling
connection, and respecting untranslatable differences with opacity, as a way of helping
"smart city" designs embrace a multiplicity of desires.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3290605.3300911,
author = {Wang, Qianwen and Ming, Yao and Jin, Zhihua and Shen, Qiaomu and Liu, Dongyu and Smith, Micah J. and Veeramachaneni, Kalyan and Qu, Huamin},
title = {ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300911},
abstract = {To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters,
automated machine learning (AutoML) methods have been developed to automatically search
for good models. Due to the huge model search space, it is impossible to try all models.
Users tend to distrust automatic results and increase the search budget as much as
they can, thereby undermining the efficiency of AutoML. To address these issues, we
design and implement ATMSeer, an interactive visualization tool that supports users
in refining the search space of AutoML and in analyzing the results. To guide the
design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine
learning experts. A multi-granularity visualization is proposed to enable users to
monitor the AutoML process, analyze the searched models, and refine the search space
in real time. We demonstrate the utility and usability of ATMSeer through two case
studies, expert interviews, and a user study with 13 end users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300912,
author = {Kim, Yea-Seul and Walls, Logan A. and Krafft, Peter and Hullman, Jessica},
title = {A Bayesian Cognition Approach to Improve Data Visualization},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300912},
abstract = {People naturally bring their prior beliefs to bear on how they interpret the new information,
yet few formal models exist for accounting for the influence of users' prior beliefs
in interactions with data presentations like visualizations. We demonstrate a Bayesian
cognitive model for understanding how people interpret visualizations in light of
prior beliefs and show how this model provides a guide for improving visualization
evaluation. In a first study, we show how applying a Bayesian cognition model to a
simple visualization scenario indicates that people's judgments are consistent with
a hypothesis that they are doing approximate Bayesian inference. In a second study,
we evaluate how sensitive our observations of Bayesian behavior are to different techniques
for eliciting people subjective distributions, and to different datasets. We find
that people don't behave consistently with Bayesian predictions for large sample size
datasets, and this difference cannot be explained by elicitation technique. In a final
study, we show how normative Bayesian inference can be used as an evaluation framework
for visualizations, including of uncertainty.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300913,
author = {Peng, Yi-Hao and Lin, Muh-Tarng and Chen, Yi and Chen, TzuChuan and Ku, Pin Sung and Taele, Paul and Lim, Chin Guan and Chen, Mike Y.},
title = {PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings Based on Individual User's Touchscreen Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300913},
abstract = {Modern touchscreen devices have recently introduced customizable touchscreen settings
to improve accessibility for users with motor impairments. For example, iOS 10 introduced
the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat,
3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings
lead to a total of more than 1 million possible configurations, making it impractical
to manually determine the optimal settings. We present PersonalTouch, which collects
and analyzes touchscreen gestures performed by individual users, and recommends personalized,
optimal touchscreen accessibility settings. Results from our user study show that
PersonalTouch significantly improves touch input success rate for users with motor
impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%,
N=12, p=.032).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300914,
author = {Wong-Villacres, Marisol and Kumar, Neha and DiSalvo, Betsy},
title = {The Parenting Actor-Network of Latino Immigrants in the United States},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300914},
abstract = {The field of Human-Computer Interaction (HCI) has shown a growing interest in how
technology might support parenting. An area that remains underexplored is the design
of technology to support parents from nondominant groups in positively impacting their
children's education. Drawing on Actor-Network Theory (ANT), our paper takes a sociotechnical
view of low-income Latino Spanish-speaking immigrants in the U.S.---a large nondominant
group---attempting to form alliances with other actors such as teachers, the broader
community, and technology to exchange information that might enrich their children's
education. The use of ANT allowed us to advance work on parenting in HCI by providing
a deeper understanding of the reasons---including attributes embedded in technology---impacting
the quality of information channels in the parental engagement network of a nondominant
group. Further, our ANT analysis illuminates a discussion of challenges and opportunities
for technology to intervene in the network in ways that align with all actors' needs
and harness their potentialities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300915,
author = {Du, Ruofei and Li, David and Varshney, Amitabh},
title = {Geollery: A Mixed Reality Social Media Platform},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300915},
abstract = {We present Geollery, an interactive mixed reality social media platform for creating,
sharing, and exploring geotagged information. Geollery introduces a real-time pipeline
to progressively render an interactive mirrored world with three-dimensional (3D)
buildings, internal user-generated content, and external geotagged social media. This
mirrored world allows users to see, chat, and collaborate with remote participants
with the same spatial context in an immersive virtual environment. We describe the
system architecture of Geollery, its key interactive capabilities, and our design
decisions. Finally, we conduct a user study with 20 participants to qualitatively
compare Geollery with another social media system, Social Street View. Based on the
participants' responses, we discuss the benefits and drawbacks of each system and
derive key insights for designing an interactive mirrored world with geotagged social
media. User feedback from our study reveals several use cases for Geollery including
travel planning, virtual meetings, and family gathering.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300916,
author = {Khamis, Mohamed and Seitz, Tobias and Mertl, Leonhard and Nguyen, Alice and Schneller, Mario and Li, Zhe},
title = {Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by Using Graphic Filters for Password Masking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300916},
abstract = {Entering text passwords on mobile devices is a significant challenge. Current systems
either display passwords in plain text: making them visible to bystanders, or replace
characters with asterisks shortly after they are typed: making editing them harder.
This work presents a novel approach to mask text passwords by distorting them using
graphical filters. Distorted passwords are difficult to observe by attackers because
they cannot mentally reverse the distortions. Yet passwords remain readable by their
owners because humans can recognize visually distorted versions of content they saw
before. We present results of an online questionnaire and a user study where we compared
Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks
when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character
passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize
filters significantly improve editing speed, editing accuracy and observation resistance
compared to current approaches.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8}
}

@inbook{10.1145/3290605.3300917,
author = {Li, Zhen and Annett, Michelle and Hinckley, Ken and Singh, Karan and Wigdor, Daniel},
title = {HoloDoc: Enabling Mixed Reality Workspaces That Harness Physical and Digital Content},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300917},
abstract = {Prior research identified that physical paper documents have many positive attributes,
for example natural tangibility and inherent physical flexibility. When documents
are presented on digital devices, however, they can provide unique functionality to
users, such as the ability to search, view dynamic multimedia content, and make use
of indexing. This work explores the fusion of physical and digital paper documents.
It first presents the results of a study that probed how users perform document-intensive
analytical tasks when both physical and digital versions of documents were available.
The study findings then informed the design of HoloDoc, a mixed reality system that
augments physical artifacts with rich interaction and dynamic virtual content. Finally,
we present the interaction techniques that HoloDoc affords, and the results of a second
study that assessed HoloDoc's utility when working with digital and physical copies
of academic articles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300918,
author = {Kim, Lawrence H. and Follmer, Sean},
title = {SwarmHaptics: Haptic Display with Swarm Robots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300918},
abstract = {This paper seeks to better understand the use of haptic feedback in abstract, ubiquitous
robotic interfaces. We introduce and provide preliminary evaluations of SwarmHaptics,
a new type of haptic display using a swarm of small, wheeled robots. These robots
move on a flat surface and apply haptic patterns to the user's hand, arm, or any other
accessible body parts. We explore the design space of SwarmHaptics including individual
and collective robot parameters, and demonstrate example scenarios including remote
social touch using the Zooids platform. To gain insights into human perception, we
applied haptic patterns with varying number of robots, force type, frequency, and
amplitude and obtained user's perception in terms of emotion, urgency, and Human-Robot
Interaction metrics. In a separate elicitation study, users generated a set of haptic
patterns for social touch. The results from the two studies help inform how users
perceive and generate haptic patterns with SwarmHaptics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300919,
author = {Quinn, Philip},
title = {Estimating Touch Force with Barometric Pressure Sensors},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300919},
abstract = {Finger pressure offers a new dimension for touch interaction, where input is defined
by its spatial position and orthogonal force. However, the limited availability and
complexity of integrated force-sensing hardware in mobile devices is a barrier to
exploring this design space. This paper presents a synthesis of two features in recent
mobile devices - a barometric sensor (pressure altimeter) and ingress protection -
to sense a user's touch force. When a user applies force to a device's display, it
flexes inward and causes an increase in atmospheric pressure within the sealed chassis.
This increase in pressure can be sensed by the device's internal barometer. However,
this change is uncontrolled and requires a calibration model to map atmospheric pressure
to touch force. This paper derives such a model and demonstrates its viability on
four commercially-available devices (including two with dedicated force sensors).
The results show this method is sensitive to forces of less than 1 N, and is comparable
to dedicated force sensors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7}
}

@inbook{10.1145/3290605.3300920,
author = {Pitt, Caroline and Bell, Adam and Onofre, Edgar and Davis, Katie},
title = {A Badge, Not a Barrier: Designing for-and Throughout-Digital Badge Implementation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300920},
abstract = {We synthesize insights from a multi-year project involving the design and implementation
of a digital badge system with youth co-designers at a science center. Using stakeholder
interviews and surveys, participatory design session data, and user analytics, we
identify the sociotechnical, sociocultural, and technical challenges of long-term
badge implementation and propose several recommendations for the design and implementation
of future badge systems. By identifying these challenges and providing recommendations
that foreground stakeholder values and participation, we show how to support implementation
throughout the entire design-to-implementation cycle.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300921,
author = {Poretski, Lev and Arazy, Ofer and Lanir, Joel and Shahar, Shalev and Nov, Oded},
title = {Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300921},
abstract = {As technology advances, people increasingly interact with virtual objects in settings
such as augmented reality (AR) where the virtual layer is superimposed on top of the
physical world. Similarly to interactions with physical objects, users may assign
virtual objects with value, experience a sense of relatedness, and develop psychological
ownership over these objects. The objective of this study is to understand how AR's
unique characteristics influences the emergence of meaning and ownership perceptions
amongst users. We conducted a study of users' interactions with a virtual dog over
a three-week period, comparing AR and fully virtual settings. Our findings show that
engagement with the application is a key determinant of the relation users develop
with virtual objects. However, the effect of the background layer-whether physical
or virtual-dominates the development of relatedness and ownership feelings, highlighting
the importance of the "real" physical layer in shaping users' perceptions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300922,
author = {Warner, Mark and Maestre, Juan F. and Gibbs, Jo and Chung, Chia-Fang and Blandford, Ann},
title = {Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps Used by Gay and Bisexual Men},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300922},
abstract = {HIV status disclosure fields in online sex-social applications ("apps") are designed
to help increase awareness, reduce stigma, and promote sexual health. Public disclosure
could also help those diagnosed relate to others with similar statuses to feel less
isolated. However, in our interview study (n=28) with HIV positive and negative men
who have sex with men (MSM), we found some users preferred to keep their status private,
especially when disclosure could stigmatise and disadvantage them, or risk revealing
their status to someone they knew offline in a different context. How do users manage
these tensions between health, stigma, and privacy? We analysed our interview data
using signalling theory as a conceptual framework and identify participants developing 'signal appropriation' strategies, helping them manage the disclosure of their HIV
status. Additionally, we propose a set of design considerations that explore the use
of signals in the design of sensitive disclosure fields.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inbook{10.1145/3290605.3300923,
author = {Zhu, Kening and Chen, Taizhou and Han, Feng and Wu, Yi-Shiun},
title = {HapTwist: Creating Interactive Haptic Proxies in Virtual Reality Using Low-Cost Twistable Artefacts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300923},
abstract = {In this paper, we present a series of studies on using Rubik's Twist, a type of low-cost
twistable artefact, to create haptic proxies for various hand-graspable VR objects.
Our pilot studies validated the feasibility and effectiveness of Rubik's-Twist-based
haptic proxies. The pilot results also revealed user challenges in the physical shape
creation, motivating the development of the HapTwist toolkit. The toolkit consists
of the shape-generation algorithm, the software interface for shape-construction guidance
and interaction authoring, and the hardware modules for constructing interactive haptic
proxies. The user studies showed that HapTwist was easy to learn and use, and it significantly
improved user performance in creating interactive haptic proxies with Rubik's Twist.
Furthermore, HapTwist-generated haptic proxies achieved similar VR experience as the
real objects.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300924,
author = {Moritz, Dominik and Howe, Bill and Heer, Jeffrey},
title = {Falcon: Balancing Interactive Latency and Resolution Sensitivity for Scalable Linked Visualizations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300924},
abstract = {We contribute user-centered prefetching and indexing methods that provide low-latency
interactions across linked visualizations, enabling cold-start exploration of billion-record
datasets. We implement our methods in Falcon, a web-based system that makes principled
trade-offs between latency and resolution to optimize brushing and view switching
times. To optimize latency-sensitive brushing actions, Falcon reindexes data upon
changes to the active view a user is brushing in. To limit view switching times, Falcon
initially loads reduced interactive resolutions, then progressively improves them.
Benchmarks show that Falcon sustains real-time interactivity of 50fps for pixel-level
brushing and linking across multiple visualizations with no costly precomputation.
We show constant brushing performance regardless of data size on datasets ranging
from millions of records in the browser to billions when connected to a backing database
system.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300925,
author = {Bala, Paulo and Masu, Raul and Nisi, Valentina and Nunes, Nuno},
title = {"When the Elephant Trumps": A Comparative Study on Spatial Audio for Orientation in 360º Videos},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300925},
abstract = {Orientation is an emerging issue in cinematic Virtual Reality (VR), as viewers may
fail in locating points of interest. Recent strategies to tackle this research problem
have investigated the role of cues, specifically diegetic sound effects. In this paper,
we examine the use of sound spatialization for orientation purposes, namely by studying
different spatialization conditions ("none", "partial", and "full" spatial manipulation)
of multitrack soundtracks. We performed a between-subject mixed-methods study with
36 participants, aided by Cue Control, a tool we developed for dynamic spatial sound
editing and data collection/analysis. Based on existing literature on orientation
cues in 360º and theories on human listening, we discuss situations in which the spatialization
was more effective (namely, "full" spatial manipulation both when using only music
and when combining music and diegetic effects), and how this can be used by creators
of 360º videos.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300926,
author = {Nishida, Jun and Matsuda, Soichiro and Oki, Mika and Takatori, Hikaru and Sato, Kosuke and Suzuki, Kenji},
title = {Egocentric Smaller-Person Experience through a Change in Visual Perspective},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300926},
abstract = {This paper explores how human perceptions, actions, and interactions can be changed
through an embodied and active experience of being a smaller person in a real-world
environment, which we call an egocentric smaller person experience. We developed a
wearable visual translator that provides the perspective of a smaller person by shifting
the wearer's eyesight level down to their waist using a head-mounted display and a
stereo camera module, while allowing for field of view control through head movements.
In this study, we investigated how the developed device can modify the wearer's body
representation and experiences based on a field study conducted at a nursing school
and museums, and through lab studies. It was observed that the participants changed
their perceptions, actions, and interactions because they are considered to have perceived
themselves as being smaller. Using this device, designers and teachers can understand
the perspectives of other people in an existing environment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300927,
author = {Kim, Jaejeung and Park, Joonyoung and Lee, Hyunsoo and Ko, Minsam and Lee, Uichin},
title = {LocknType: Lockout Task Intervention for Discouraging Smartphone App Use},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300927},
abstract = {Instant access and gratification make it difficult for us to self-limit the use of
smartphone apps. We hypothesize that a slight increase in the interaction cost of
accessing an app could successfully discourage app use. We propose a proactive intervention
that requests users to perform a simple lockout task (e.g., typing a fixed length
number) whenever a target app is launched. We investigate how a lockout task with
varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit
input) influence a user's decision making, by a 3-week, in-situ experiment with 40
participants. Our findings show that even the pause-only task that requires a user
to press a button to proceed discouraged an average of 13.1% of app use, and the 30-digit-input
task discouraged 47.5%. We derived determinants of app use and non-use decision making
for a given lockout task. We further provide implications for persuasive technology
design for discouraging undesired behaviors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3290605.3300928,
author = {Mayer, Sven and Schwind, Valentin and Le, Huy Viet and Weber, Dominik and Vogelsang, Jonas and Wolf, Johannes and Henze, Niels},
title = {Effect of Orientation on Unistroke Touch Gestures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300928},
abstract = {As touchscreens are the most successful input method of current mobile devices, touch
gestures became a widely used input technique. While gestures provide users with advantages
to express themselves, they also introduce challenges regarding accuracy and memorability.
In this paper, we investigate the effect of a gesture's orientation on how well the
gesture can be performed. We conducted a study in which participants performed systematically
rotated unistroke gestures. For straight lines as well as for compound lines, we found
that users tend to align gestures with the primary axes. We show that the error can
be described by a Clausen function with R² = .93. Based on our findings, we suggest
design implications and highlight the potential for recognizing flick gestures, visualizing
gestures and improving recognition of compound gestures.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inbook{10.1145/3290605.3300929,
author = {Groeger, Daniel and Steimle, J\"{u}rgen},
title = {LASEC: Instant Fabrication of Stretchable Circuits Using a Laser Cutter},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300929},
abstract = {This paper introduces LASEC, the first technique for instant do-it-yourself fabrication
of circuits with custom stretchability on a conventional laser cutter and in a single
pass. The approach is based on integrated cutting and ablation of a two-layer material
using parametric design patterns. These patterns enable the designer to customize
the desired stretchability of the circuit, to combine stretchable with non-stretchable
areas, or to integrate areas of different stretchability. For adding circuits on such
stretchable cut patterns, we contribute routing strategies and a real-time routing
algorithm. An interactive design tool assists designers by automatically generating
patterns and circuits from a high-level specification of the desired interface. The
approach is compatible with off-the-shelf materials and can realize transparent interfaces.
Several application examples demonstrate the versatility of the novel technique for
applications in wearable computing, interactive textiles, and stretchable input devices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300930,
author = {Marshall, Joe and Benford, Steve and Byrne, Richard and Tennent, Paul},
title = {Sensory Alignment in Immersive Entertainment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300930},
abstract = {When we use digital systems to stimulate the senses, we typically stimulate only a
subset of users' senses, leaving other senses stimulated by the physical world. This
creates potential for misalignment between senses, where digital and physical stimulation
give conflicting signals to users. We synthesize knowledge from HCI, traditional entertainments,
and underlying sensory science research relating to how senses work when given conflicting
signals. Using this knowledge we present a design dimension of sensory alignment,
and show how this dimension presents opportunities for a range of creative strategies
ranging from full alignment of sensory stimulation, up to extreme conflict between
senses.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300931,
author = {Chang, Minsuk and Truong, Anh and Wang, Oliver and Agrawala, Maneesh and Kim, Juho},
title = {How to Design Voice Based Navigation for How-To Videos},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300931},
abstract = {When watching how-to videos related to physical tasks, users' hands are often occupied
by the task, making voice input a natural fit. To better understand the design space
of voice interactions for how-to video navigation, we conducted three think-aloud
studies using: 1) a traditional video interface, 2) a research probe providing a voice
controlled video interface, and 3) a wizard-of-oz interface. From the studies, we
distill seven navigation objectives and their underlying intents: pace control pause,
content alignment pause, video control pause, reference jump, replay jump, skip jump,
and peek jump. Our analysis found that users' navigation objectives and intents affect
the choice of referent type and referencing approach in command utterances. Based
on our findings, we recommend to 1) support conversational strategies like sequence
expansions and command queues, 2) allow users to identify and refine their navigation
objectives explicitly, and 3) support the seven interaction intents.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3290605.3300932,
author = {Lee, Minha and Ackermans, Sander and van As, Nena and Chang, Hanwen and Lucas, Enzo and IJsselsteijn, Wijnand},
title = {Caring for Vincent: A Chatbot for Self-Compassion},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300932},
abstract = {The digitization of mental health care holds promises of affordable and ubiquitously
available treatment, e.g., with conversational agents (chatbots). While technology
can guide people to care for themselves, we examined how people can care for another
being as a way to care for themselves. We created a self-compassion chatbot (Vincent)
and compared between caregiving and care-receiving conditions. Care-giving Vincent
asked participants to partake in self-compassion exercises. Care-receiving Vincent
shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought
out advice. While self-compassion increased for both conditions, only those with care-receiving
Vincent significantly improved. In tandem, we offer qualitative data on how participants
interacted with Vincent. Our exploratory research shows that when a person cares for
a chatbot, the person's self-compassion can be enhanced. We further reflect on design
implications for strengthening mental health with chatbots.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3290605.3300933,
author = {Salai, Ana-Maria and Baillie, Lynne},
title = {A Wee Bit More Interaction: Designing and Evaluating an Overactive Bladder App},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300933},
abstract = {Overactive Bladder (OAB) is a widespread condition, affecting 20% of the population.
Even though it is a treatable condition, people often do not seek treatment. In this
paper, we describe how we co-designed and evaluated with 30 stakeholders (9 medical
professionals and 21 end-users) an OAB mobile health application that aims to increase
adherence to self-managed treatment. Our results support previous research that visualizing
progress, setting goals, receiving reminders and feedback increases use. We discovered
that games could be used successfully as a distraction technique for urge suppression.
Contrary to the current research direction, automatically calculated features could
be a detriment to app interaction. Regarding evaluation, we found that designers may
not want to rely only on questionnaires when assessing the success of a game and its
emotional impact on users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3290605.3300935,
author = {Yu, Chun and Wei, Xiaoying and Vachher, Shubh and Qin, Yue and Liang, Chen and Weng, Yueting and Gu, Yizheng and Shi, Yuanchun},
title = {HandSee: Enabling Full Hand Interaction on Smartphone with Front Camera-Based Stereo Vision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300935},
abstract = {We present HandSee, a novel sensing technique that can capture the state and movement
of the user's hands touching or gripping a smartphone. We place a right angle prism
mirror on the front camera to achieve a stereo vision of the scene above the touchscreen
surface. We develop a pipeline to extract the depth image of hands from a monocular
RGB image, which consists of three components: a stereo matching algorithm to estimate
the pixel-wise depth of the scene, a CNN-based online calibration algorithm to detect
hand skin, and a merging algorithm that outputs the depth image of the hands. Building
on the output, a substantial set of valuable interaction information, such as fingers'
3D location, gripping posture, and finger identity can be recognized concurrently.
Due to this unique sensing ability, HandSee enables a variety of novel interaction
techniques and expands the design space for full hand interaction on smartphones.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}


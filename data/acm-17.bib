@inproceedings{10.1145/3250108,
author = {Barkhuus, Louise},
title = {Session Details: Papers: Managing Social Media},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250108},
doi = {10.1145/3250108},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470656,
author = {Zhao, Xuan and Salehi, Niloufar and Naranjit, Sasha and Alwaalan, Sara and Voida, Stephen and Cosley, Dan},
title = {The Many Faces of Facebook: Experiencing Social Media as Performance, Exhibition, and Personal Archive},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470656},
doi = {10.1145/2470654.2470656},
abstract = {The growing use of social media means that an increasing amount of people's lives
are visible online. We draw from Goffman's theatrical metaphor and Hogan's exhibition
approach to explore how people manage their personal collection of social media data
over time. We conducted a qualitative study of 13 participants to reveal their day-to-day
decision-making about producing and curating digital traces on Facebook. Their goals
and strategies showed that people experience the Facebook platform as consisting of
three different functional regions: a performance region for managing recent data
and impression management, an exhibition region for longer term presentation of self-image,
and a personal region for archiving meaningful facets of life. Further, users' need
for presenting and archiving data in these three regions is mediated by temporality.
These findings trigger a discussion of how to design social media that support these
dynamic and sometimes conflicting needs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {identity, curation, reminiscing, personal archives, exhibition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470657,
author = {Jung, Yumi and Gray, Rebecca and Lampe, Cliff and Ellison, Nicole},
title = {Favors from Facebook Friends: Unpacking Dimensions of Social Capital},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470657},
doi = {10.1145/2470654.2470657},
abstract = {Past research has demonstrated a link between perceptions of social capital and use
of the popular social network site, Facebook. Williams' Internet Social Capital Scales,
based on Putnam's formulation, tap into sub-dimensions of social capital that have
not been broadly used yet may enlighten our understanding of the different ways in
which connecting with others online can facilitate access to resources embedded within
our social relationships. In this study, we segment Williams' Internet Social Capital
Scales into various sub-dimensions using factor analysis and explicate the distinct
facets of social capital through a lab experiment in which Facebook users (N=98) request
a small favor from their Facebook network. We find that some sub-dimensions play a
significant role in getting favors from Facebook friends while bonding and bridging
social capital do not significantly predict responses to favor requests.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {favor asking, social capital, facebook network},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470658,
author = {Bernstein, Michael S. and Bakshy, Eytan and Burke, Moira and Karrer, Brian},
title = {Quantifying the Invisible Audience in Social Networks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470658},
doi = {10.1145/2470654.2470658},
abstract = {When you share content in an online social network, who is listening? Users have scarce
information about who actually sees their content, making their audience seem invisible
and difficult to estimate. However, understanding this invisible audience can impact
both science and design, since perceived audiences influence content production and
self-presentation online. In this paper, we combine survey and large-scale log data
to examine how well users' perceptions of their audience match their actual audience
on Facebook. We find that social media users consistently underestimate their audience
size for their posts, guessing that their audience is just 27% of its true size. Qualitative
coding of survey responses reveals folk theories that attempt to reverse-engineer
audience size using feedback and friend count, though none of these approaches are
particularly accurate. We analyze audience logs for 222,000 Facebook users' posts
over the course of one month and find that publicly visible signals --- friend count,
likes, and comments --- vary widely and do not strongly indicate the audience of a
single post. Despite the variation, users typically reach 61% of their friends each
month. Together, our results begin to reveal the invisible undercurrents of audience
attention and behavior in online social networks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {social networks, audience, information distribution},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470659,
author = {Wang, Yi-Chia and Burke, Moira and Kraut, Robert E.},
title = {Gender, Topic, and Audience Response: An Analysis of User-Generated Content on Facebook},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470659},
doi = {10.1145/2470654.2470659},
abstract = {Although both men and women communicate frequently on Facebook, we know little about
what they talk about, whether their topics differ and how their network responds.
Using Latent Dirichlet Allocation (LDA), we identify topics from more than half a
million Facebook status updates and determine which topics are more likely to receive
feedback, such as likes and comments. Women tend to share more personal topics (e.g.,
family matters), while men discuss more public ones (e.g., politics and sports). Generally,
women receive more feedback than men, but "male" topics (those more often posted by
men) receive more feedback, especially when posted by women.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–34},
numpages = {4},
keywords = {natural language analysis, gender, computer-mediated communication, social networking sites, topics, facebook},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470660,
author = {Shi, Pan and Xu, Heng and Chen, Yunan},
title = {Using Contextual Integrity to Examine Interpersonal Information Boundary on Social Network Sites},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470660},
doi = {10.1145/2470654.2470660},
abstract = {Although privacy problems in Social Network Sites (SNS) have become more salient than
ever in recent years, interpersonal privacy issues in SNS remain understudied. This
study aims to generate insights in understanding users' interpersonal privacy concerns
by expounding interpersonal privacy boundaries in SNS. Through a case analysis of
Friendship Pages on Facebook, this paper identifies users' interpersonal privacy concerns
that are rooted from informational norms outlined in the theory of contextual integrity,
as well as the tensions that occur within and cross these informational norms. This
paper concludes with a discussion of design implications and future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {35–38},
numpages = {4},
keywords = {social network sites (sns), facebook, privacy boundary, friendship pages, interpersonal privacy concerns},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250109,
author = {Fitzpatrick, Geraldine},
title = {Session Details: Papers: Enhancing Access},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250109},
doi = {10.1145/3250109},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470662,
author = {Waycott, Jenny and Vetere, Frank and Pedell, Sonja and Kulik, Lars and Ozanne, Elizabeth and Gruner, Alan and Downs, John},
title = {Older Adults as Digital Content Producers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470662},
doi = {10.1145/2470654.2470662},
abstract = {Older adults are normally characterized as consumers, rather than producers, of digital
content. Current research concerning the design of technologies for older adults typically
focuses on providing access to digital resources. Access is important, but is often
insufficient, especially when establishing new social relationships. This paper investigates
the nature and role of digital content that has been created by older adults, for
the purpose of forging new relationships. We present a unique field study in which
seven older adults (aged 71-92 years), who did not know each other, used a prototype
iPad application (Enmesh) to create and share photographs and messages. The findings
demonstrate that older adults, even those in the '1c"oldest old'1d" age group, embraced
opportunities to express themselves creatively through digital content production.
We show that self-expression and social engagement with peers can be realized when
socio-technical systems are suitably designed to allow older adults to create and
share their own digital content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {39–48},
numpages = {10},
keywords = {user-generated content, older adults, social connection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470663,
author = {Liu, Leslie S. and Huh, Jina and Neogi, Tina and Inkpen, Kori and Pratt, Wanda},
title = {Health Vlogger-Viewer Interaction in Chronic Illness Management},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470663},
doi = {10.1145/2470654.2470663},
abstract = {Health video blogs (vlogs) allow individuals with chronic illnesses to share their
stories, experiences, and knowledge with the general public. Furthermore, health vlogs
help in creating a connection between the vlogger and the viewers. In this work, we
present a qualitative study examining the various methods that health vloggers use
to establish a connection with their viewers. We found that vloggers used genres to
express specific messages to their viewers while using the uniqueness of video to
establish a deeper connection with their viewers. Health vloggers also explicitly
sought interaction with their viewers. Based on these results, we present design implications
to help facilitate and build sustainable communities for vloggers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {49–58},
numpages = {10},
keywords = {patient-centered, health vlogs, youtube, video blogging, communication, chronic illness management},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470664,
author = {Kuksenok, Katie and Brooks, Michael and Mankoff, Jennifer},
title = {Accessible Online Content Creation by End Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470664},
doi = {10.1145/2470654.2470664},
abstract = {Like most online content, user-generated content (UGC) poses accessibility barriers
to users with disabilities. However, the accessibility difficulties pervasive in UGC
warrant discussion and analysis distinct from other kinds of online content. Content
authors, community culture, and the authoring tool itself all affect UGC accessibility.
The choices, resources available, and strategies in use to ensure accessibility are
different than for other types of online content. We contribute case studies of two
UGC communities with accessible content: Wikipedia, where authors focus on access
to visual materials and navigation, and an online health support forum where users
moderate the cognitive accessibility of posts. Our data demonstrate real world moderation
strategies and illuminate factors affecting success, such as community culture. We
conclude with recommended strategies for creating a culture of accessibility around
UGC.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {59–68},
numpages = {10},
keywords = {accessibility, user-generated content},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470665,
author = {Ban, Yuki and Narumi, Takuji and Fujii, Tatsuya and Sakurai, Sho and Imura, Jun and Tanikawa, Tomohiro and Hirose, Michitaka},
title = {Augmented Endurance: Controlling Fatigue While Handling Objects by Affecting Weight Perception Using Augmented Reality},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470665},
doi = {10.1145/2470654.2470665},
abstract = {The main contribution of this paper is to develop a method for alleviating fatigue
during handling medium-weight objects and augmenting our endurance by affecting our
weight perception with augmented reality technology. To assist people to lift medium-weight
objects without a complex structure or various costs, we focus on the phenomenon that
our weight perception during handling objects is affected by visual properties. Our
hypothesis is that this illusionary effect in weight perception can be applied to
reduce fatigue while handling medium-weight objects without mechatronics-based physical
assistance. In this paper, we propose an augmented reality system that changes the
brightness value of an object in order to reduce fatigue while handling the object.
We conducted two fundamental experiments to investigate the effectiveness of the proposed
system. Our results suggested that the system eliminates the need to use excess energy
for handling objects and reduces fatigue during the handling task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {69–78},
numpages = {10},
keywords = {cross-modal interaction, weight perception, augmented reality, assistance for physical work},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250110,
author = {Kerne, Andruid},
title = {Session Details: Papers: Learning},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250110},
doi = {10.1145/3250110},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470667,
author = {Harpstead, Erik and Myers, Brad A. and Aleven, Vincent},
title = {In Search of Learning: Facilitating Data Analysis in Educational Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470667},
doi = {10.1145/2470654.2470667},
abstract = {The field of Educational Games has seen many calls for added rigor. One avenue for
improving the rigor of the field is developing more generalizable methods for measuring
student learning within games. Throughout the process of development, what is relevant
to measure and assess may change as a game evolves into a finished product. The field
needs an approach for game developers and researchers to be able to prototype and
experiment with different measures that can stand up to rigorous scrutiny, as well
as provide insight into possible new directions for development. We demonstrate a
toolkit and analysis tools that capture and analyze students' performance within open
educational games. The system records relevant events during play, which can be used
for analysis of player learning by designers. The tools support replaying student
sessions within the original game's environment, which allows researchers and developers
to explore possible explanations for student behavior. Using this system, we were
able to facilitate a number of analyses of student learning in an open educational
game developed by a team of our collaborators as well as gain greater insight into
student learning with the game and where to focus as we iterate.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {79–88},
numpages = {10},
keywords = {educational games, toolkits, analysis of learning, logging},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470668,
author = {Lomas, Derek and Patel, Kishan and Forlizzi, Jodi L. and Koedinger, Kenneth R.},
title = {Optimizing Challenge in an Educational Game Using Large-Scale Design Experiments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470668},
doi = {10.1145/2470654.2470668},
abstract = {Online games can serve as research instruments to explore the effects of game design
elements on motivation and learning. In our research, we manipulated the design of
an online math game to investigate the effect of challenge on player motivation and
learning. To test the '1cInverted-U Hypothesis'1d, which predicts that maximum game
engagement will occur with moderate challenge, we produced two large-scale (10K and
70K subjects), multi-factor (2x3 and 2x9x8x4x25) online experiments. We found that,
in almost all cases, subjects were more engaged and played longer when the game was
easier, which seems to contradict the generality of the Inverted-U Hypothesis. Troublingly,
we also found that the most engaging design conditions produced the slowest rates
of learning. Based on our findings, we describe several design implications that may
increase challenge-seeking in games, such as providing feedforward about the anticipated
degree of challenge.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {89–98},
numpages = {10},
keywords = {design, crowdsourcing, games, education},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470669,
author = {Foster, Stephen R. and Esper, Sarah and Griswold, William G.},
title = {From Competition to Metacognition: Designing Diverse, Sustainable Educational Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470669},
doi = {10.1145/2470654.2470669},
abstract = {We investigate the unique educational benefits of 1-on-1 competitive games, arguing
that such games can be just as easy to design as single-player educational games,
while yielding a more diverse and sustainable learning experience. We present a study
of chess and StarCraft II in order to inform the design of similar educational games
and their communities. We discuss a competitive game we designed to teach Java programming.
We evaluate the game by discussing its user study. Our main contributions are 1) an
argument that the use of 1-on-1 competition can solve two existing problems inherent
to single-player games, 2) an analysis of the features that make competitive games
effective learning environments, and 3) an early but encouraging description of the
emergent learning environment one can expect from designing an educational game with
these features.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {99–108},
numpages = {10},
keywords = {games, education},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470670,
author = {Rau, Martina A. and Aleven, Vincent and Rummel, Nikol and Rohrbach, Stacie},
title = {Why Interactive Learning Environments Can Have It All: Resolving Design Conflicts between Competing Goals},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470670},
doi = {10.1145/2470654.2470670},
abstract = {Designing interactive learning environments (ILEs; e.g., intelligent tutoring systems,
educational games, etc.) is a challenging interdisciplinary process that needs to
satisfy multiple stakeholders. ILEs need to function in real educational settings
(e.g., schools) in which a number of goals interact. Several instructional design
methodologies exist to help developers address these goals. However, they often lead
to conflicting recommendations. Due to the lack of an established methodology to resolve
such conflicts, developers of ILEs have to rely on ad-hoc solutions. We present a
principled methodology to resolve such conflicts. We build on a well-established design
process for creating Cognitive Tutors, a highly effective type of ILE. We extend this
process by integrating methods from multiple disciplines to resolve design conflicts.
We illustrate our methodology's effectiveness by describing the iterative development
of the Fractions Tutor, which has proven to be effective in classroom studies with
3,000 4th-6th graders.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {109–118},
numpages = {10},
keywords = {instructional design, cognitive tutors, design conflicts, interactive learning environments},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2470670_R48799,
author = {Godwin, Stewart Mark},
title = {Review ID:R48799 for DOI: 10.1145/2470654.2470670},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470670_R48799}
}

@dataset{10.1145/review-2470654.2470670_R48845,
author = {Hazeltine, Barrett},
title = {Review ID:R48845 for DOI: 10.1145/2470654.2470670},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470670_R48845}
}

@inproceedings{10.1145/3250111,
author = {Jirotka, Marina},
title = {Session Details: Papers: Interaction in the Wild},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250111},
doi = {10.1145/3250111},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470672,
author = {Pierce, James and Paulos, Eric},
title = {Electric Materialities and Interactive Technology},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470672},
doi = {10.1145/2470654.2470672},
abstract = {This paper offers new theoretical and design insights into nteractive technology.
By initially considering electric technology broadly, our work informs how HCI approaches
a range of specific interactive or digital things and materials. Theoretically, we
contribute a rigorous analysis of electric technology using the experiential lens
of phenomenology. A major result is to characterize electric technology by three forms
of materiality: the electric object, its electric materiality, and electric power.
In terms of design, we present and analyze novel interactive form prototypes. Our
theoretical contributions offer new insight into design artifacts, just as our novel
design artifacts help reveal new theoretical insight.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {119–128},
numpages = {10},
keywords = {electricity, interaction design, design theory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470673,
author = {Jacobs, Rachel and Benford, Steve and Selby, Mark and Golembewski, Michael and Price, Dominic and Giannachi, Gabriella},
title = {A Conversation between Trees: What Data Feels like in the Forest},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470673},
doi = {10.1145/2470654.2470673},
abstract = {A study of an interactive artwork shows how artists engaged the public with scientific
climate change data. The artwork visualised live environmental data collected from
remote trees, alongside both historical and forecast global CO2 data. Visitors also
took part in a mobile sensing experience in a nearby forest. Our study draws on the
perspectives of the artists, visitors and a climate scientist to reveal how the work
was designed and experienced. We show that the artists adopted a distinct approach
that fostered an emotional engagement with data rather than an informative or persuasive
one. We chart the performative strategies they used to achieve this including sensory
engagement with data, a temporal structure that balanced liveness with slowness, and
the juxtaposition of different treatments of the data to enable interpretation and
dialogue.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {129–138},
numpages = {10},
keywords = {embodied, climate, liveness, sensory, sustainability, performance, slowness, environmentally engaged art},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470674,
author = {Blythe, Mark and Briggs, Jo and Hook, Jonathan and Wright, Peter and Olivier, Patrick},
title = {Unlimited Editions: Three Approaches to the Dissemination and Display of Digital Art},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470674},
doi = {10.1145/2470654.2470674},
abstract = {The paper reflects on three approaches to the dissemination and display of digital
art. '1c"s[edition]'1d" is a novel, web-based service that offers limited editions
of "'1cdigital prints"'1d. Analysis of user comments suggests that the metaphor
of a '1c"limited digital edition"'1d raises issues and to some extent is resisted.
The second approach is the Flickr Brushes Gallery, where digital painters post images
and comment on one another's work. Analysis of comment boards indicates that the shared
art and comments are a form of gift exchange. Finally, the paper discusses a field
study in which artists exhibited their work as it develops over time in digital frames
and also in an immersive digital projection room. Analysis of field notes and interviews
indicate that the digital frame approach was unsuccessful because of aesthetic and
environmental concerns. The immersive projection suggested that more experiential
approaches may be more interesting. It is argued that there is an inherent resistance
in digital media to previous models of art commoditization. None of the approaches
discussed here resolve the dilemma but rather indicate the scope and complexity of
the issues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {139–148},
numpages = {10},
keywords = {interaction design, digital culture, art, ethnography},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470675,
author = {Fosh, Lesley and Benford, Steve and Reeves, Stuart and Koleva, Boriana and Brundell, Patrick},
title = {See Me, Feel Me, Touch Me, Hear Me: Trajectories and Interpretation in a Sculpture Garden},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470675},
doi = {10.1145/2470654.2470675},
abstract = {We apply the HCI concept of trajectories to the design of a sculpture trail. We crafted
a trajectory through each sculpture, combining textual and audio instructions to drive
directed viewing, movement and touching while listening to accompanying music. We
designed key transitions along the way to oscillate between moments of social interaction
and isolated personal engagement, and to deliver official interpretation only after
visitors had been given the opportunity to make their own. We describe how visitors
generally followed our trajectory, engaging with sculptures and making interpretations
that sometimes challenged the received interpretation. We relate our findings to discussions
of sense-making and design for multiple interpretations, concluding that curators
and designers may benefit from considering '18trajectories of interpretation'.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {149–158},
numpages = {10},
keywords = {trajectories, interpretation, sculpture, collaboration, instructions., audio, museums, galleries, art},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250112,
author = {Cubaud, Pierre},
title = {Session Details: Papers: 3D User Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250112},
doi = {10.1145/3250112},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470677,
author = {Teather, Robert J. and Stuerzlinger, Wolfgang},
title = {Pointing at 3d Target Projections with One-Eyed and Stereo Cursors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470677},
doi = {10.1145/2470654.2470677},
abstract = {We present a study of cursors for selecting 2D-projected 3D targets. We compared a
stereo- and mono-rendered (one-eyed) cursor using two mouse-based and two remote pointing
techniques in a 3D Fitts' law pointing experiment. The first experiment used targets
at fixed depths. Results indicate that one-eyed cursors only improve screen-plane
pointing techniques, and that constant target depth does not influence pointing throughput.
A second experiment included pointing between targets at varying depths and used only
"screen-plane" pointing techniques. Our results suggest that in the absence of stereo
cue conflicts, screen-space projections of Fitts' law parameters (target size and
distance) yield constant throughput despite target depth differences and produce better
models of performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–168},
numpages = {10},
keywords = {fitts'19 law, 3d pointing, cursors, selection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470678,
author = {Schild, Jonas and B\"{o}licke, Liane and LaViola Jr., Joseph J. and Masuch, Maic},
title = {Creating and Analyzing Stereoscopic 3D Graphical User Interfaces in Digital Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470678},
doi = {10.1145/2470654.2470678},
abstract = {Creating graphical user interfaces (GUI) for stereoscopic 3D (S3D) games is a difficult
choice between visual comfort and effect. We present a S3D Game GUI Design Space and
a list of S3D-specific attributes that emphasizes integrating visually comfortable
interfaces into the game world, story and S3D view. To showcase our approach, we created
two GUI concepts and evaluated them with 32 users. Our results show quality improvements
for a combination of bottom position and visual attachment for a menu. In a referencing
interface, placing the reference near to the target depth significantly improved perceived
quality, game integration, and increased presence. These results confirm the need
to create S3D GUIs with perceptual constraints in mind, demonstrating the potential
to extend the user experience. Additionally, our design space offers a formal and
flexible way to create new effects in S3D GUIs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {169–178},
numpages = {10},
keywords = {game, presence, design space, depth, user experience, graphical user interface, visual 3d quality, stereoscopic 3d},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470679,
author = {Sodhi, Rajinder S. and Jones, Brett R. and Forsyth, David and Bailey, Brian P. and Maciocci, Giuliano},
title = {BeThere: 3D Mobile Collaboration with Spatial Input},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470679},
doi = {10.1145/2470654.2470679},
abstract = {We present BeThere, a proof-of-concept system designed to explore 3D input for mobile
collaborative interactions. With BeThere, we explore 3D gestures and spatial input
which allow remote users to perform a variety of virtual interactions in a local user's
physical environment. Our system is completely self-contained and uses depth sensors
to track the location of a user's fingers as well as to capture the 3D shape of objects
in front of the sensor. We illustrate the unique capabilities of our system through
a series of interactions that allow users to control and manipulate 3D virtual content.
We also provide qualitative feedback from a preliminary user study which confirmed
that users can complete a shared collaborative task using our system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {179–188},
numpages = {10},
keywords = {depth sensors, augmented reality, around device interaction, collaboration},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470680,
author = {Lee, Jinha and Olwal, Alex and Ishii, Hiroshi and Boulanger, Cati},
title = {SpaceTop: Integrating 2D and Spatial 3D Interactions in a See-through Desktop Environment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470680},
doi = {10.1145/2470654.2470680},
abstract = {SpaceTop is a concept that fuses spatial 2D and 3D interactions in a single workspace.
It extends the traditional desktop interface with interaction technology and visualization
techniques that enable seamless transitions between 2D and 3D manipulations. SpaceTop
allows users to type, click, draw in 2D, and directly manipulate interface elements
that float in the 3D space above the keyboard. It makes it possible to easily switch
from one modality to another, or to simultaneously use two modalities with different
hands. We introduce hardware and software configurations for co-locating these various
interaction modalities in a unified workspace using depth cameras and a transparent
display. We describe new interaction and visualization techniques that allow users
to interact with 2D elements floating in 3D space. We present the results from a preliminary
user study that indicates the benefit of such hybrid workspaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {189–192},
numpages = {4},
keywords = {augmented reality, 3d ui, desktop management},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470681,
author = {Ortega, Michael},
title = {3D Object Position Using Automatic Viewpoint Transitions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470681},
doi = {10.1145/2470654.2470681},
abstract = {This paper presents IUCA (Interaction Using Camera Animations), a new interaction
technique for 3D objects manipulation. IUCA allows efficient interaction in a full-resolution
perspective view by integrating transients animated transitions to orthographic views
into the manipulation task. This provides an interaction in context, with precise
object positioning and alignment. An evaluation of the technique shows that, compared
to the classical configurations, IUCA allows to reduce pointing time by 14% on average.
Testing with professional 3D designers and novice users indicate that IUCA is easy
to use and to learn; and that users feel comfortable with it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {193–196},
numpages = {4},
keywords = {3d pointing, 3d interaction, 3d modeling, four-views configuration, fitts' law},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250113,
author = {Parikh, Tapan},
title = {Session Details: Papers: Crowdsourcing: People Power},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250113},
doi = {10.1145/3250113},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470683,
author = {O'Neill, Jacki and Roy, Shourya and Grasso, Antonietta and Martin, David},
title = {Form Digitization in BPO: From Outsourcing to Crowdsourcing?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470683},
doi = {10.1145/2470654.2470683},
abstract = {This paper describes an ethnographic study of an outsourced business process - the
digitization of healthcare forms. The aim of the study was to understand how the work
is currently organized, with an eye to uncovering the research challenges which need
to be addressed if that work is to be crowdsourced. The findings are organised under
four emergent themes: Workplace Ecology, Data Entry Skills and Knowledge, Achieving
Targets and Collaborative Working. For each theme a description of how the work is
undertaken in the outsourcer's Indian office locations is given, followed by the implications
for crowdsourcing that work. This research is a first step in understanding how crowdsourcing
might be applied to BPO activities. The paper examines features specific to form digitization
- extreme distribution and form decomposition - and lightly touches on the crowdsourcing
of BPO work more generally.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {197–206},
numpages = {10},
keywords = {ethnography, business process, crowdsourcing, outsourcing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470684,
author = {Komarov, Steven and Reinecke, Katharina and Gajos, Krzysztof Z.},
title = {Crowdsourcing Performance Evaluations of User Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470684},
doi = {10.1145/2470654.2470684},
abstract = {Online labor markets, such as Amazon's Mechanical Turk (MTurk), provide an attractive
platform for conducting human subjects experiments because the relative ease of recruitment,
low cost, and a diverse pool of potential participants enable larger-scale experimentation
and faster experimental revision cycle compared to lab-based settings. However, because
the experimenter gives up the direct control over the participants' environments and
behavior, concerns about the quality of the data collected in online settings are
pervasive. In this paper, we investigate the feasibility of conducting online performance
evaluations of user interfaces with anonymous, unsupervised, paid participants recruited
via MTurk. We implemented three performance experiments to re-evaluate three previously
well-studied user interface designs. We conducted each experiment both in lab and
online with participants recruited via MTurk. The analysis of our results did not
yield any evidence of significant or substantial differences in the data collected
in the two settings: All statistically significant differences detected in lab were
also present on MTurk and the effect sizes were similar. In addition, there were no
significant differences between the two settings in the raw task completion times,
error rates, consistency, or the rates of utilization of the novel interaction mechanisms
introduced in the experiments. These results suggest that MTurk may be a productive
setting for conducting performance evaluations of user interfaces providing a complementary
approach to existing methodologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {207–216},
numpages = {10},
keywords = {crowdsourcing, user interface evaluation, mechanical turk},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470685,
author = {Chilana, Parmit K. and Ko, Amy J. and Wobbrock, Jacob O. and Grossman, Tovi},
title = {A Multi-Site Field Study of Crowdsourced Contextual Help: Usage and Perspectives of End Users and Software Teams},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470685},
doi = {10.1145/2470654.2470685},
abstract = {We present a multi-site field study to evaluate LemonAid, a crowdsourced contextual
help approach that allows users to retrieve relevant questions and answers by making
selections within the interface. We deployed LemonAid on 4 different web sites used
by thousands of users and collected data over several weeks, gathering over 1,200
usage logs, 168 exit surveys, and 36 one-on-one interviews. Our results indicate that
over 70% of users found LemonAid to be helpful, intuitive, and desirable for reuse.
Software teams found LemonAid easy to integrate with their sites and found the analytics
data aggregated by LemonAid a novel way of learning about users' popular questions.
Our work provides the first holistic picture of the adoption and use of a crowdsourced
contextual help system and offers several insights into the social and organizational
dimensions of implementing such help systems for real-world applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–226},
numpages = {10},
keywords = {contextual help, software support=., field deployments, crowdsourced help, field studies, help systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470686,
author = {Dow, Steven and Gerber, Elizabeth and Wong, Audris},
title = {A Pilot Study of Using Crowds in the Classroom},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470686},
doi = {10.1145/2470654.2470686},
abstract = {Industry relies on higher education to prepare students for careers in innovation.
Fulfilling this obligation is especially difficult in classroom settings, which often
lack authentic interaction with the outside world. Online crowdsourcing has the potential
to change this. Our research explores if and how online crowds can support student
learning in the classroom. We explore how scalable, diverse, immediate (and often
ambiguous and conflicting) input from online crowds affects student learning and motivation
for project-based innovation work. In a pilot study with three classrooms, we explore
interactions with the crowd at four key stages of the innovation process: needfinding,
ideating, testing, and pitching. Students reported that online crowds helped them
quickly and inexpensively identify needs and uncover issues with early-stage prototypes,
although they favored face-to-face interactions for more contextual feed-back. We
share early evidence and discuss implications for creating a socio-technical infrastructure
to more effectively use crowdsourcing in education.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {227–236},
numpages = {10},
keywords = {feedback, innovation, crowdsourcing, education},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250114,
author = {Fogarty, James},
title = {Session Details: Papers: Multitouch and Gesture},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250114},
doi = {10.1145/3250114},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470688,
author = {Steimle, J\"{u}rgen and Jordt, Andreas and Maes, Pattie},
title = {Flexpad: Highly Flexible Bending Interactions for Projected Handheld Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470688},
doi = {10.1145/2470654.2470688},
abstract = {Flexpad is an interactive system that combines a depth camera and a projector to transform
sheets of plain paper or foam into flexible, highly deformable, and spatially aware
handheld displays. We present a novel approach for tracking deformed surfaces from
depth images in real time. It captures deformations in high detail, is very robust
to occlusions created by the user's hands and fingers, and does not require any kind
of markers or visible texture. As a result, the display is considerably more deformable
than in previous work on flexible handheld displays, enabling novel applications that
leverage the high expressiveness of detailed deformation. We illustrate these unique
capabilities through three application examples: curved cross-cuts in volumetric images,
deforming virtual paper characters, and slicing through time in videos. Results from
two user studies show that our system is capable of detecting complex deformations
and that users are able to perform them quickly and precisely.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {237–246},
numpages = {10},
keywords = {deformation, volumetric data, tracking, handheld display, depth camera, projection, bending, flexible display},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470689,
author = {Sun, Qian and Lin, Juncong and Fu, Chi-Wing and Kaijima, Sawako and He, Ying},
title = {A Multi-Touch Interface for Fast Architectural Sketching and Massing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470689},
doi = {10.1145/2470654.2470689},
abstract = {Architectural sketching and massing are used by designers to analyze and explore the
design space of buildings. This paper describes a novel multi-touch interface for
fast architectural sketching and massing of tall buildings. It incorporates a family
of multi-touch gestures, enabling one to quickly sketch the 2D contour of a base floor
plan and extrude it to model a building with multi-floor structures. Further, it provides
a set of gestures to users: select and edit a range of floors; scale contours of a
building; copy, paste, and rotate a building, i.e., create a twisted structure; edit
profile curves of a building's profile; and collapse and remove a selected range of
floors. The multi-touch system also allows users to apply textures or geometric facades
to the building, and to compare different designs side-by-side. To guide the design
process, we describe interactions with a domain expert, a practicing architect. The
final interface is evaluated by architects and students in an architecture Dept.,
which demonstrates that the system allows rapid conceptual design and massing of novel
multi-story building structures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {247–256},
numpages = {10},
keywords = {sketching, multi-touch, massing, building design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470690,
author = {L\"{u}, Hao and Li, Yang},
title = {Gesture Studio: Authoring Multi-Touch Interactions through Demonstration and Declaration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470690},
doi = {10.1145/2470654.2470690},
abstract = {The prevalence of multi-touch devices opens the space for rich interactions. However,
the complexity for creating multi-touch interactions hinders this potential. In this
paper, we present Gesture Studio, a tool for creating multi-touch interaction behaviors
by combining the strength of two distinct but complementary approaches: programming
by demonstration and declaration. We employ an intuitive video-authoring metaphor
for developers to demonstrate touch gestures, compose complicated behaviors, test
these behaviors in the tool and export them as source code that can be integrated
into the developers' project.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {257–266},
numpages = {10},
keywords = {programming by demonstration, declaration, probabilistic reasoning, multi-touch gestures, state machines},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470691,
author = {Kim, Ju-Whan and Nam, Tek-Jin},
title = {EventHurdle: Supporting Designers' Exploratory Interaction Prototyping with Gesture-Based Sensors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470691},
doi = {10.1145/2470654.2470691},
abstract = {Prototyping of gestural interactions in the early phase of design is one of the most
challenging tasks for designers without advanced programming skills. Relating users'
input from gesture-based sensor values requires a great deal of effort on the designer's
part and disturbs their reflective and creative thinking. To deal with this problem,
we present EventHurdle, a visual gesture-authoring tool to support designers' explorative
prototyping. It supports remote gestures from a camera, handheld gestures with physical
sensors, and touch gestures by utilizing touch screens. EventHurdle allows designers
to visually define and modify gestures through interaction workspace and graphical
markup language with hurdles. Because the created gestures can be integrated into
a prototype as programming code and automatically recognized, designers do not need
to pay attention in sensor-related implementation. Two user studies and a recognition
test are reported to discuss the acceptance and implications of explorative prototyping
tools for designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {267–276},
numpages = {10},
keywords = {exploratory prototyping, gesture-based interaction, visual programming},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470692,
author = {Vatavu, Radu-Daniel and Casiez, G\'{e}ry and Grisoni, Laurent},
title = {Small, Medium, or Large? Estimating the User-Perceived Scale of Stroke Gestures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470692},
doi = {10.1145/2470654.2470692},
abstract = {We show that large consensus exists among users in the way they articulate stroke
gestures at various scales (i.e., small, medium, and large), and formulate a simple
rule that estimates the user-intended scale of input gestures with 87% accuracy. Our
estimator can enhance current gestural interfaces by leveraging scale as a natural
parameter for gesture input, reflective of user perception (i.e., no training required).
Gesture scale can simplify gesture set design, improve gesture-to-function mappings,
and reduce the need for users to learn and for recognizers to discriminate unnecessary
symbols.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {277–280},
numpages = {4},
keywords = {human factors, gesture size, gesture scale, gesture articulation, gesture recognition, bayes' rule, pen gestures},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470693,
author = {Heo, Seongkook and Lee, Geehyuk},
title = {Indirect Shear Force Estimation for Multi-Point Shear Force Operations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470693},
doi = {10.1145/2470654.2470693},
abstract = {The possibility of using shear forces is being explored recently as a method to enrich
touch screen interaction. However, most of the related studies are restricted to the
case of single-point shear forces, possibly owing to the difficulty of independently
sensing shear forces at multiple touch points. In this paper, we propose indirect
methods to estimate shear forces using the movement of contact areas. These methods
enable multi-point shear force estimation, where the estimation is done for each finger
independently. We show the feasibility of these methods through an informal user study
with a demo application utilizing these methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–284},
numpages = {4},
keywords = {shear force, touch screen, force sensing, multi-touch},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250115,
author = {Bartram, Lyn},
title = {Session Details: Papers: Gaze},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250115},
doi = {10.1145/3250115},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470695,
author = {Stellmach, Sophie and Dachselt, Raimund},
title = {Still Looking: Investigating Seamless Gaze-Supported Selection, Positioning, and Manipulation of Distant Targets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470695},
doi = {10.1145/2470654.2470695},
abstract = {We investigate how to seamlessly bridge the gap between users and distant displays
for basic interaction tasks, such as object selection and manipulation. For this,
we take advantage of very fast and implicit, yet imprecise gaze- and head-directed
input in combination with ubiquitous smartphones for additional manual touch control.
We have carefully elaborated two novel and consistent sets of gaze-supported interaction
techniques based on touch-enhanced gaze pointers and local magnification lenses. These
conflict-free sets allow for fluently selecting and positioning distant targets. Both
sets were evaluated in a user study with 16 participants. Overall, users were fastest
with a touch-enhanced gaze pointer for selecting and positioning an object after some
training. While the positive user feedback for both sets suggests that our proposed
gaze- and head-directed interaction techniques are suitable for a convenient and fluent
selection and manipulation of distant targets, further improvements are necessary
for more precise cursor control.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {285–294},
numpages = {10},
keywords = {mobile touch input, visual attention, gaze interaction, eye tracking, selection, distant displays, positioning},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470696,
author = {Toker, Dereck and Conati, Cristina and Steichen, Ben and Carenini, Giuseppe},
title = {Individual User Characteristics and Information Visualization: Connecting the Dots through Eye Tracking},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470696},
doi = {10.1145/2470654.2470696},
abstract = {There is increasing evidence that users' characteristics such as cognitive abilities
and personality have an impact on the effectiveness of information visualization techniques.
This paper investigates the relationship between such characteristics and fine-grained
user attention patterns. In particular, we present results from an eye tracking user
study involving bar graphs and radar graphs, showing that a user's cognitive abilities
such as perceptual speed and verbal working memory have a significant impact on gaze
behavior, both in general and in relation to task difficulty and visualization type.
These results are discussed in view of our long-term goal of designing information
visualisation systems that can dynamically adapt to individual user characteristics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {295–304},
numpages = {10},
keywords = {eye tracking, adaptive information visualization, user characteristics, information visualization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470697,
author = {Bulling, Andreas and Weichel, Christian and Gellersen, Hans},
title = {EyeContext: Recognition of High-Level Contextual Cues from Human Visual Behaviour},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470697},
doi = {10.1145/2470654.2470697},
abstract = {In this work we present EyeContext, a system to infer high-level contextual cues from
human visual behaviour. We conducted a user study to record eye movements of four
participants over a full day of their daily life, totalling 42.5 hours of eye movement
data. Participants were asked to self-annotate four non-mutually exclusive cues: social
(interacting with somebody vs. no interaction), cognitive (concentrated work vs. leisure),
physical (physically active vs. not active), and spatial (inside vs. outside a building).
We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements
into strings and a spectrum string kernel support vector machine (SVM) classifier.
Our results demonstrate the large information content available in long-term human
visual behaviour and opens up new venues for research on eye-based behavioural monitoring
and life logging.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {305–308},
numpages = {4},
keywords = {eye movement analysis, electrooculography (eog), visual behaviour, context recognition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470698,
author = {Lee, Joong Ho and Kim, Sei-young and Yoon, Hae Cheol and Huh, Bo Kyung and Park, Ji-Hyung},
title = {A Preliminary Investigation of Human Adaptations for Various Virtual Eyes in Video See-through HMDS},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470698},
doi = {10.1145/2470654.2470698},
abstract = {A video see-through head mounted display (HMD) has a different viewing point than
does the real eye, resulting in visual displacement (VD). VD deteriorates visuomotor
performance due to sensory conflict. Previous work has investigated this deterioration
and human adaptation by comparing fixed VD and real eye conditions. In this study
we go a step further to investigate whether any differences in visuomotor and adaptation
trends exist across 16 distinct VD conditions. The performance tasks studied were
of two types: foot placement and finger touch. In contrast to our initial prediction,
the results showed equal task performance levels and adaptation within about 5 minutes
regardless of VD conditions. We found that human adaptation covered a variety of VDs
--- up to 55 mm in the X, Y direction; up to 125mm in the Z direction; and up to 140mm
of interocular distance (IOD). In addition, we found that partial adaptation gave
participants the interesting experience of a sense of body structure distortion for
a few minutes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {309–312},
numpages = {4},
keywords = {immersive reality, adaptation, task performance., hmd, video see-through, visual displacement, visuomotor},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250116,
author = {Bigham, Jeffrey},
title = {Session Details: Papers: Technologies for Life 1},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250116},
doi = {10.1145/3250116},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470700,
author = {Gibson, Lorna and Hanson, Vicki L.},
title = {Digital Motherhood: How Does Technology Help New Mothers?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470700},
doi = {10.1145/2470654.2470700},
abstract = {New mothers can experience social exclusion, particularly during the early weeks when
infants are solely dependent on their mothers. We used ethnographic methods to investigate
whether technology plays a role in supporting new mothers. Our research identified
two core themes: (1) the need to improve confidence as a mother; and (2) the need
to be more than '18just' a mother. We reflect on these findings both in terms of
those interested in designing applications and services for motherhood and also the
wider CHI community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {313–322},
numpages = {10},
keywords = {social support, ethnography, motherhood, new mothers},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470701,
author = {Nicholson, James and Coventry, Lynne and Briggs, Pam},
title = {Age-Related Performance Issues for PIN and Face-Based Authentication Systems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470701},
doi = {10.1145/2470654.2470701},
abstract = {Graphical authentication systems typically claim to be more usable than PIN or password-based
systems, but these claims often follow limited, single-stage paradigm testing on a
young, student population. We present a more demanding test paradigm in which multiple
codes are learned and tested over a three-week period. We use this paradigm with two
user populations, comparing the performance of younger and older adults. We first
establish baseline performance in a study in which populations of younger and older
adults learn PIN codes and we follow this with a second study in which younger and
older adults use two face-based graphical authentication systems employing young faces
vs. old faces as code components. As expected, older adults show relatively poor performance
when compared to younger adults, irrespective of the authentication material, but
this age-related deficit can be markedly reduced by the introduction of age-appropriate
faces. We conclude firstly that this paradigm provides a good basis for the future
evaluation of memory-based authentication systems and secondly that age-appropriate
face-based authentication is viable in the security marketplace.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {323–332},
numpages = {10},
keywords = {graphical codes, older adults, authentication, usable security},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470702,
author = {Lauckner, Carolyn and Hsieh, Gary},
title = {The Presentation of Health-Related Search Results and Its Impact on Negative Emotional Outcomes},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470702},
doi = {10.1145/2470654.2470702},
abstract = {Searching for health information online has become increasingly common, yet few studies
have examined potential negative emotional effects of online health information search.
We present results from an experiment manipulating the presentation of search results
for common symptoms, which shows that the frequency and placement of serious illness
mentions within results can influence perceptions of symptom severity and susceptibility
of having the serious illness, respectively. The increase in severity and susceptibility
can then lead to higher levels of negative emotional outcomes experienced--including
feeling overwhelmed and frightened. Interestingly, health literacy can help reduce
perceived symptom severity, and high online health experience actually increases the
likelihood that individuals use a frequency-based heuristic. Technological implications
and directions for future research are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {333–342},
numpages = {10},
keywords = {online health information, negative effects, health literacy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470703,
author = {Findlater, Leah and Froehlich, Jon E. and Fattal, Kays and Wobbrock, Jacob O. and Dastyar, Tanya},
title = {Age-Related Differences in Performance with Touchscreens Compared to Traditional Mouse Input},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470703},
doi = {10.1145/2470654.2470703},
abstract = {Despite the apparent popularity of touchscreens for older adults, little is known
about the psychomotor performance of these devices. We compared performance between
older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging,
crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results
show that while older adults were significantly slower than younger adults in general,
the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed,
the touchscreen resulted in a significant movement time reduction of 35% over the
mouse for older adults, compared to only 16% for younger adults. Error rates also
decreased.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {343–346},
numpages = {4},
keywords = {older adults, touchscreens, input, accessibility},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470704,
author = {Kane, Shaun K. and Frey, Brian and Wobbrock, Jacob O.},
title = {Access Lens: A Gesture-Based Screen Reader for Real-World Documents},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470704},
doi = {10.1145/2470654.2470704},
abstract = {Gesture-based touch screen user interfaces, when designed to be accessible to blind
users, can be an effective mode of interaction for those users. However, current accessible
touch screen interaction techniques suffer from one serious limitation: they are only
usable on devices that have been explicitly designed to support them. Access Lens
is a new interaction method that uses computer vision-based gesture tracking to enable
blind people to use accessible gestures on paper documents and other physical objects,
such as product packages, device screens, and home appliances. This paper describes
the development of Access Lens hardware and software, the iterative design of Access
Lens in collaboration with blind computer users, and opportunities for future development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {347–350},
numpages = {4},
keywords = {accessibility, computer vision, blindness, augmented reality, gestures},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250117,
author = {Jameson, Anthony},
title = {Session Details: Papers: Evaluation Methods 1},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250117},
doi = {10.1145/3250117},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470706,
author = {Huisman, Gijs and van Hout, Marco and van Dijk, Elisabeth and van der Geest, Thea and Heylen, Dirk},
title = {LEMtool: Measuring Emotions in Visual Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470706},
doi = {10.1145/2470654.2470706},
abstract = {In this paper the development process and validation of the LEMtool (Layered Emotion
Measurement tool) are described. The LEMtool consists of eight images that display
a cartoon figure expressing four positive and four negative emotions using facial
expressions and body postures. The instrument can be used during interaction with
a visual interface, such as a website, and allows participants to select elements
of the interface that elicit a certain emotion. The images of the cartoon figure were
submitted to a validation study, in which participants rated the recognizability of
the images as specific emotions. All images were found to be recognizable above chance
level. In another study, the LEMtool was used to assess visual appeal judgements of
a number of web pages. The LEMtool ratings were supported by visual appeal ratings
of web pages both for very brief (50 milliseconds) and for long (free-viewing) stimulus
exposures. Furthermore, the instrument provided insight into the elements of the web
pages that elicited the emotional responses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {351–360},
numpages = {10},
keywords = {web pages., user experience, visual appeal, lemtool, emotion},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470707,
author = {Nov, Oded and Arazy, Ofer and L\'{o}pez, Claudia and Brusilovsky, Peter},
title = {Exploring Personality-Targeted UI Design in Online Social Participation Systems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470707},
doi = {10.1145/2470654.2470707},
abstract = {We present a theoretical foundation and empirical findings demonstrating the effectiveness
of personality-targeted design. Much like a medical treatment applied to a person
based on his specific genetic profile, we argue that theory-driven, personality-targeted
UI design can be more effective than design applied to the entire population. The
empirical exploration focused on two settings, two populations and two personality
traits: Study 1 shows that users' extraversion level moderates the relationship between
the UI cue of audience size and users' contribution. Study 2 demonstrates that the
effectiveness of social anchors in encouraging online contributions depends on users'
level of emotional stability. Taken together, the findings demonstrate the potential
and robustness of the interactionist approach to UI design. The findings contribute
to the HCI community, and in particular to designers of social systems, by providing
guidelines to targeted design that can increase online participation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {361–370},
numpages = {10},
keywords = {emotional stability, extraversion, theory-driven design, personality, user interface, anchoring., audience size},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470708,
author = {Massung, Elaine and Coyle, David and Cater, Kirsten F. and Jay, Marc and Preist, Chris},
title = {Using Crowdsourcing to Support Pro-Environmental Community Activism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470708},
doi = {10.1145/2470654.2470708},
abstract = {Community activist groups typically rely on core groups of highly motivated members.
In this paper we consider how crowdsourcing strategies can be used to supplement the
activities of pro-environmental community activists, thus increasing the scalability
of their campaigns. We focus on mobile data collection applications and strategies
that can be used to engage casual participants in pro-environmental data collection.
We report the results of a study that used both quantitative and qualitative methods
to investigate the impact of different motivational factors and strategies, including
both intrinsic and extrinsic motivators. The study compared and provides empirical
evidence for the effectiveness of two extrinsic motivation strategies, pointification
- a subset of gamification - and financial incentives. Prior environmental interest
is also assessed as an intrinsic motivation factor. In contrast to previous HCI research
on pro-environmental technology, much of which has focused on individual behavior
change, this paper offers new insights and recommendations on the design of systems
that target groups and communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {371–380},
numpages = {10},
keywords = {crowdsourcing, community activism, gamification, motivation, sustainability, participatory urbanism},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470709,
author = {Reitmaier, Thomas and Benz, Pierre and Marsden, Gary},
title = {Designing and Theorizing Co-Located Interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470709},
doi = {10.1145/2470654.2470709},
abstract = {This paper gives an interwoven account of the theoretical and practical work we undertook
in pursuit of designing co-located interactions. We show how we sensitized ourselves
to theory from diverse intellectual disciplines, to develop an analytical lens to
better think about co-located interactions. By critiquing current systems and their
conceptual foundations, and further interrelating theories particularly in regard
to performative aspects of identity and communication, we develop a more nuanced way
of thinking about co-located interactions. Drawing on our sensitivities, we show how
we generated and are exploring, through the process of design, a set of co-located
interactions that are situated within our social ecologies, and contend that our upfront
theoretical work enabled us to identify and explore this space in the first place.
This highlights the importance of problem framing, especially for projects adopting
design methodologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {381–390},
numpages = {10},
keywords = {theory, design research, co-presence, co-located interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470710,
author = {Kusano, Koki and Nakatani, Momoko and Ohno, Takehiko},
title = {Scenario-Based Interactive UI Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470710},
doi = {10.1145/2470654.2470710},
abstract = {Clearly picturing user behavior is one of the key requirements when designing successful
interactive software. However, covering all possible user behaviors with one UI is
a complex challenge. The Scenario-based Interactive UI Design tool is designed to
support the characterization of user behavior based on scenarios and then using the
information in UI design. Scenarios make it easy to understand and share user behavior
even if we have little design knowledge. However, they have two big weaknesses; 1)
integrating several scenarios in one UI is difficult, even if we can create appropriate
scenarios, 2) maintaining the links between scenarios and the UI is a heavy task in
iterative design. Our tool solves the above problems through its hierarchical scenario
structure and visualized overview of scenarios. It enhances the designer's skill in
writing scenarios and designing UIs smoothly and easily.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {391–394},
numpages = {4},
keywords = {traceability, scenario, design tool, user interface design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470711,
author = {Qu, Yan and Zhang, Jun},
title = {Regularly Visited Patches in Human Mobility},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470711},
doi = {10.1145/2470654.2470711},
abstract = {In this paper, we propose a new analytic unit for human mobility analysis -- the patch.
We developed a process to identify Regularly Visited Patches (RVP) and a set of metrics
to characterize and measure their spatial patterns. Using a large dataset of Foursquare
check-ins as a test bed, we show that RVP analysis reveals fundamental patterns of
human mobility and will lead to promising research with strong implications for businesses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {395–398},
numpages = {4},
keywords = {optics, human mobility, regularly visited patches},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250118,
author = {Parker, Andrea},
title = {Session Details: Papers: Co-Design with Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250118},
doi = {10.1145/3250118},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470713,
author = {Dalsgaard, Peter and Eriksson, Eva},
title = {Large-Scale Participation: A Case Study of a Participatory Approach to Developing a New Public Library},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470713},
doi = {10.1145/2470654.2470713},
abstract = {In this paper, we present a case study of a participatory project that focuses on
interaction in large-scale design, namely, the development of the new Urban Mediaspace
Aarhus. This project, which has been under way for ten years, embodies a series of
issues that arise when participatory design approaches are applied to large-scale,
IT-oriented projects. At the same time, it highlights the issues public knowledge
institutions face, when interactive technologies challenge their fundamental roles
and practices; by extension, this case offers examples of how these challenges may
be explored and addressed through IT-based participatory initiatives. We present a
range of such activities carried out during the past ten years, and present the main
lessons from the project, based on interviews with three key stakeholders. These lessons
focus on how to make participation work in practice, how to align different paradigms
of inquiry and practice in a project of this scale, and how to capture and anchor
the insights from participatory events to inform the ongoing design process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {399–408},
numpages = {10},
keywords = {design methods, interaction design, large-scale projects, participatory design, citizen involvement},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470714,
author = {Yoo, Daisy and Zimmerman, John and Hirsch, Tad},
title = {Probing Bus Stop for Insights on Transit Co-Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470714},
doi = {10.1145/2470654.2470714},
abstract = {Social computing provides a new way for citizens to engage with their public service.
Our research investigates how social computing might support citizens co-design their
transit service. We conducted a field study with public transit riders, exploring
the issues and controversies that reveal conflicting communities. Our analyses revealed
three insights. First, encourage citizens to share what they see as the rationale
for current service offerings. Second, encourage citizens to share the consequences
of current services and of proposed changes and new designs. Third, focus on producing
a shared citizen and service provider understanding of what the goals and mission
of the public service should be.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {409–418},
numpages = {10},
keywords = {social computing, transit, public service, service design, egovernment, political design, co-design, contestational design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470715,
author = {Yoo, Daisy and Huldtgren, Alina and Woelfer, Jill Palzkill and Hendry, David G. and Friedman, Batya},
title = {A Value Sensitive Action-Reflection Model: Evolving a Co-Design Space with Stakeholder and Designer Prompts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470715},
doi = {10.1145/2470654.2470715},
abstract = {We introduce a design method for evolving a co-design space to support stakeholders
untrained in design. Specifically, the purpose of the method is to expand and shape
a co-design space so that stakeholders, acting as designers, focus not only on the
form and function of a tool being envisioned but also on the social context of its
use and values that lie with individuals, groups, and societies. The method introduces
value sensitive stakeholder prompts and designer prompts into a co-design process,
creating a particular kind of reflection-on-action cycle. The prompts provide a means
for bringing empirical data on values and theoretical perspective into the co-design
process. We present the method in terms of a general model, the Value Sensitive Action-Reflection
Model; place the model within discourse on co-design spaces; and illustrate the model
with a discussion of its application in a lo-fi prototyping activity around safety
for homeless young people. We conclude with reflections on the model and method.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {419–428},
numpages = {10},
keywords = {co-design, value sensitive action-reflection model, safety, homeless young people, creativity, design method, value sensitive design, security, mobile technologies, reflection-on-action, value scenarios, prototyping, envisioning cards},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470716,
author = {Vines, John and Clarke, Rachel and Wright, Peter and McCarthy, John and Olivier, Patrick},
title = {Configuring Participation: On How We Involve People in Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470716},
doi = {10.1145/2470654.2470716},
abstract = {The term 'participation' is traditionally used in HCI to describe the involvement
of users and stakeholders in design processes, with a pretext of distributing control
to participants to shape their technological future. In this paper we ask whether
these values can hold up in practice, particularly as participation takes on new meanings
and incorporates new perspectives. We argue that much HCI research leans towards configuring
participation. In exploring this claim we explore three questions that we consider
important for understanding how HCI configures participation; Who initiates, directs
and benefits from user participation in design? In what forms does user participation
occur? How is control shared with users in design? In answering these questions we
consider the conceptual, ethical and pragmatic problems this raises for current participatory
HCI research. Finally, we offer directions for future work explicitly dealing with
the configuration of participation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {429–438},
numpages = {10},
keywords = {participation, participatory design, performance art, participatory media},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250119,
author = {Gweon, Gahgene},
title = {Session Details: Papers: Language and Translation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250119},
doi = {10.1145/3250119},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470718,
author = {Green, Spence and Heer, Jeffrey and Manning, Christopher D.},
title = {The Efficacy of Human Post-Editing for Language Translation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470718},
doi = {10.1145/2470654.2470718},
abstract = {Language translation is slow and expensive, so various forms of machine assistance
have been devised. Automatic machine translation systems process text quickly and
cheaply, but with quality far below that of skilled human translators. To bridge this
quality gap, the translation industry has investigated post-editing, or the manual
correction of machine output. We present the first rigorous, controlled analysis of
post-editing and find that post-editing leads to reduced time and, surprisingly, improved
quality for three diverse language pairs (English to Arabic, French, and German).
Our statistical models and visualizations of experimental data indicate that some
simple predictors (like source text part of speech counts) predict translation time,
and that post-editing results in very different interaction patterns. From these results
we distill implications for the design of new language translation interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {439–448},
numpages = {10},
keywords = {modeling, language translation, post-editing, experiment},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470719,
author = {Gao, Ge and Wang, Hao-Chuan and Cosley, Dan and Fussell, Susan R.},
title = {Same Translation but Different Experience: The Effects of Highlighting on Machine-Translated Conversations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470719},
doi = {10.1145/2470654.2470719},
abstract = {Machine translation (MT) has the potential to allow members of multilingual organizations
to interact via their own native languages, but issues with the quality of MT output
have made it difficult to realize this potential. We hypothesized that highlighting
keywords in MT output might make it easier for people to overlook translation errors
and focus on what was intended by the message. To test this hypothesis, we conducted
a laboratory experiment in which native English speakers interacted with a Mandarin-speaking
confederate using machine translation. Participants performed three brainstorming
tasks, under each of three conditions: no highlighting, keyword highlighting, and
random highlighting. Our results indicated that people consider the identical messages
clearer and less distracting when the keywords in the message are highlighted. Keyword
highlighting also improved subjective impressions of the partner and the quality of
the collaboration. These findings inform the design of future communication tools
to support multilingual communications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {449–458},
numpages = {10},
keywords = {machine translation, brainstorming, multilingual communication, highlighting},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470720,
author = {Tausczik, Yla R. and Pennebaker, James W.},
title = {Improving Teamwork Using Real-Time Language Feedback},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470720},
doi = {10.1145/2470654.2470720},
abstract = {We develop and evaluate a real-time language feedback system that monitors the communication
patterns among students in a discussion group and provides real-time instructions
to shape the way the group works together. As an initial step, we determine which
group processes are related to better outcomes. We then experimentally test the efficacy
of providing real-time instructions which target two of these group processes. The
feedback system was successfully able to shape the way groups worked together. However,
only appropriate feedback given to groups that were not working well together from
the start was able to improve group performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {459–468},
numpages = {10},
keywords = {teamwork, feedback, linguistic analysis, cscw, cmc},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470721,
author = {Edge, Darren and Cheng, Kai-Yin and Whitney, Michael},
title = {SpatialEase: Learning Language through Body Motion},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470721},
doi = {10.1145/2470654.2470721},
abstract = {Games that engage both mind and body by targeting users' kinesthetic intelligence
have the potential to transform the activity of learning across a wide variety of
domains. To investigate this potential in the context of second language learning,
we have developed SpatialEase: a Kinect game for the body-based learning of language
that is grounded in space and motion. In this game, learners respond to audio commands
in the second language by moving their bodies in space, while a game mechanic based
on distributed cued-recall supports learning over time. Our comparison of SpatialEase
with the popular Rosetta Stone software for learner of Mandarin Chinese showed similar
learning gains over a single session and generated several key implications for the
future design of mixed-modality learning systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {469–472},
numpages = {4},
keywords = {language learning, kinesthetic learning, embodied gaming},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250120,
author = {Isenberg, Petra},
title = {Session Details: Papers: Brain Sensing and Analysis},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250120},
doi = {10.1145/3250120},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470723,
author = {Peck, Evan M M. and Yuksel, Beste F. and Ottley, Alvitta and Jacob, Robert J.K. and Chang, Remco},
title = {Using FNIRS Brain Sensing to Evaluate Information Visualization Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470723},
doi = {10.1145/2470654.2470723},
abstract = {We show how brain sensing can lend insight to the evaluation of visual interfaces
and establish a role for fNIRS in visualization. Research suggests that the evaluation
of visual design benefits by going beyond performance measures or questionnaires to
measurements of the user's cognitive state. Unfortunately, objectively and unobtrusively
monitoring the brain is difficult. While functional near-infrared spectroscopy (fNIRS)
has emerged as a practical brain sensing technology in HCI, visual tasks often rely
on the brain's quick, massively parallel visual system, which may be inaccessible
to this measurement. It is unknown whether fNIRS can distinguish differences in cognitive
state that derive from visual design alone. In this paper, we use the classic comparison
of bar graphs and pie charts to test the viability of fNIRS for measuring the impact
of a visual design on the brain. Our results demonstrate that we can indeed measure
this impact, and furthermore measurements indicate that there are not universal differences
in bar graphs and pie charts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–482},
numpages = {10},
keywords = {brain sensing, evaluation, fnirs, visualization, bci},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470724,
author = {Alper, Basak and Bach, Benjamin and Henry Riche, Nathalie and Isenberg, Tobias and Fekete, Jean-Daniel},
title = {Weighted Graph Comparison Techniques for Brain Connectivity Analysis},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470724},
doi = {10.1145/2470654.2470724},
abstract = {The analysis of brain connectivity is a vast field in neuroscience with a frequent
use of visual representations and an increasing need for visual analysis tools. Based
on an in-depth literature review and interviews with neuroscientists, we explore high-level
brain connectivity analysis tasks that need to be supported by dedicated visual analysis
tools. A significant example of such a task is the comparison of different connectivity
data in the form of weighted graphs. Several approaches have been suggested for graph
comparison within information visualization, but the comparison of weighted graphs
has not been addressed. We explored the design space of applicable visual representations
and present augmented adjacency matrix and node-link visualizations. To assess which
representation best support weighted graph comparison tasks, we performed a controlled
experiment. Our findings suggest that matrices support these tasks well, outperforming
node-link diagrams. These results have significant implications for the design of
brain connectivity analysis tools that require weighted graph comparisons. They can
also inform the design of visual analysis tools in other domains, e.g. comparison
of weighted social networks or biological pathways.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {483–492},
numpages = {10},
keywords = {graph comparison, brain connectivity analysis, brain connectivity visualization},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2470724_R49782,
author = {Rosa, Joao Luis Garcia},
title = {Review ID:R49782 for DOI: 10.1145/2470654.2470724},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470724_R49782}
}

@inproceedings{10.1145/2470654.2470725,
author = {Taylor, Alex S. and Piterman, Nir and Ishtiaq, Samin and Fisher, Jasmin and Cook, Byron and Cockerton, Caitlin and Bourton, Sam and Benque, David},
title = {At the Interface of Biology and Computation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470725},
doi = {10.1145/2470654.2470725},
abstract = {Representing a new class of tool for biological modeling, Bio Model Analyzer (BMA)
uses sophisticated computational techniques to determine stabilization in cellular
networks. This paper presents designs aimed at easing the problems that can arise
when such techniques - '14using distinct approaches to conceptualizing networks'14
- are applied in biology. The work also engages with more fundamental issues being
discussed in the philosophy of science and science studies. It shows how scientific
ways of knowing are constituted in routine interactions with tools like BMA, where
the emphasis is on the practical business at hand, even when seemingly deep conceptual
problems exist. For design, this perspective refigures the frictions raised when computation
is used to model biology. Rather than obstacles, they can be seen as opportunities
for opening up different ways of knowing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {493–502},
numpages = {10},
keywords = {computational biology, science studies, philosophy of science, materiality, ethnography, epistemology},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2470725_R48994,
author = {Kalvala, Sara},
title = {Review ID:R48994 for DOI: 10.1145/2470654.2470725},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470725_R48994}
}

@inproceedings{10.1145/3250121,
author = {Gajos, Krzysztof},
title = {Session Details: Papers: Crowdwork and Online Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250121},
doi = {10.1145/3250121},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470727,
author = {Muller, Michael and Geyer, Werner and Soule, Todd and Daniels, Steven and Cheng, Li-Te},
title = {Crowdfunding inside the Enterprise: Employee-Initiatives for Innovation and Collaboration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470727},
doi = {10.1145/2470654.2470727},
abstract = {We describe a first experiment in enterprise crowdfunding - i.e., employees allocating
money for employee-initiated proposals at an Intranet site, including a trial of this
system with 511 employees in IBM Research. Major outcomes include: employee proposals
that addressed diverse individual and organizational needs; high participation rates;
extensive inter-departmental collaboration, including the discovery of large numbers
of previously unknown collaborators; and the development of goals and motivations
based on collective concerns at multiple levels of project groups, communities of
practice, and the organization as a whole. We recommend further, comparative research
into crowd-funding and other forms of employee-initiated innovations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–512},
numpages = {10},
keywords = {social, innovation, enterprise, employee, crowdfunding},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470728,
author = {Matthews, Tara and Whittaker, Steve and Badenes, Hernan and Smith, Barton A. and Muller, Michael and Ehrlich, Kate and Zhou, Michelle X. and Lau, Tessa},
title = {Community Insights: Helping Community Leaders Enhance the Value of Enterprise Online Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470728},
doi = {10.1145/2470654.2470728},
abstract = {Online communities are increasingly being deployed in enterprises to increase productivity
and share expertise. Community leaders are critical for fostering successful communities,
but existing technologies rarely support leaders directly, both because of a lack
of clear data about leader needs, and because existing tools are member- rather than
leader-centric. We present the evidence-based design and evaluation of a novel tool
for community leaders, Community Insights (CI). CI provides actionable analytics that
help community leaders foster healthy communities, providing value to both members
and the organization. We describe empirical and system contributions derived from
a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical
contributions include new data showing: (a) which metrics are most useful for leaders
to assess community health, (b) the need for and how to design actionable metrics,
(c) the need for and how to design contextualized analytics to support sensemaking
about community data. These findings motivate a novel community system that provides
leaders with useful, actionable and contextualized analytics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {513–522},
numpages = {10},
keywords = {system evaluation, online communities, community leaders, workplace, iterative design, enterprise},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470729,
author = {Xu, Anbang and Chen, Jilin and Matthews, Tara and Muller, Michael and Badenes, Hernan},
title = {CommunityCompare: Visually Comparing Communities for Online Community Leaders in the Enterprise},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470729},
doi = {10.1145/2470654.2470729},
abstract = {Online communities are important in enterprises, helping workers to build skills and
collaborate. Despite their unique and critical role fostering successful communities,
community leaders have little direct support in existing technologies. We introduce
CommunityCompare, an interactive visual analytic system to enable leaders to make
sense of their community's activity with comparisons. Composed of a parallel coordinates
plot, various control widgets, and a preview of example posts from communities, the
system supports comparisons with hundreds of related communities on multiple metrics
and the ability to learn by example. We motivate and inform the system design with
formative interviews of community leaders. From additional interviews, a field deployment,
and surveys of leaders, we show how the system enabled leaders to assess community
performance in the context of other comparable communities, learn about community
dynamics through data exploration, and identify examples of top performing communities
from which to learn. We conclude by discussing how our system and design lessons generalize.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {523–532},
numpages = {10},
keywords = {workplace, visualization, system evaluation, iterative design, online communities, enterprise, community leaders},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470730,
author = {Lee, Uichin and Kim, Jihyoung and Yi, Eunhee and Sung, Juyup and Gerla, Mario},
title = {Analyzing Crowd Workers in Mobile Pay-for-Answer Q&amp;a},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470730},
doi = {10.1145/2470654.2470730},
abstract = {Despite the popularity of mobile pay-for-answer Q&amp;A services, little is known about
the people who answer questions on these services. In this paper we examine 18.8 million
question and answer pairs from Jisiklog, the largest mobile pay-foranswer Q&amp;A service
in Korea, and the results of a complementary survey study of 245 Jisiklog workers.
The data are used to investigate key motivators of participation, working strategies
of experienced users, and longitudinal interaction dynamics. We find that answerers
are rarely motivated by social factors but are motivated by financial incentives and
intrinsic motives. Additionally, although answers are provided quickly, an answerer's
topic selection tends to be broad, with experienced workers employing unique strategies
to answer questions and judge relevance. Finally, analysis of longitudinal working
patterns and community dynamics demonstrate the robustness of mobile pay-for-answer
Q&amp;A. These findings have significant implications on the design of mobile pay-for-answer
Q&amp;A.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {533–542},
numpages = {10},
keywords = {user behavior, mobile pay-for-answer q&amp;a},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250122,
author = {Dunlop, Mark},
title = {Session Details: Papers: Keyboards and Hotkeys},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250122},
doi = {10.1145/3250122},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470732,
author = {Bi, Xiaojun and Azenkot, Shiri and Partridge, Kurt and Zhai, Shumin},
title = {Octopus: Evaluating Touchscreen Keyboard Correction and Recognition Algorithms Via},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470732},
doi = {10.1145/2470654.2470732},
abstract = {The time and labor demanded by a typical laboratory-based keyboard evaluation are
limiting resources for algorithmic adjustment and optimization. We propose Remulation,
a complementary method for evaluating touchscreen keyboard correction and recognition
algorithms. It replicates prior user study data through real-time, on-device simulation.
We have developed Octopus, a Remulation-based evaluation tool that enables keyboard
developers to efficiently measure and inspect the impact of algorithmic changes without
conducting resource-intensive user studies. It can also be used to evaluate third-party
keyboards in a "black box" fashion, without access to their algorithms or source code.
Octopus can evaluate both touch keyboards and word-gesture keyboards. Two empirical
examples show that Remulation can efficiently and effectively measure many aspects
of touch screen keyboards at both macro and micro levels. Additionally, we contribute
two new metrics to measure keyboard accuracy at the word level: the Ratio of Error
Reduction (RER) and the Word Score.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {543–552},
numpages = {10},
keywords = {simulation, touch screen interaction, text entry},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470733,
author = {Kim, Sunjun and Son, Jeongmin and Lee, Geehyuk and Kim, Hwan and Lee, Woohun},
title = {TapBoard: Making a Touch Screen Keyboard More Touchable},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470733},
doi = {10.1145/2470654.2470733},
abstract = {A physical keyboard key has three states, whereas a touch screen usually has only
two. Due to this difference, the state corresponding to the touched state of a physical
key is missing in a touch screen keyboard. This touched state is an important factor
in the usability of a keyboard. In order to recover the role of a touched state in
a touch screen, we propose the TapBoard, a touch screen software keyboard that regards
tapping actions as keystrokes and other touches as the touched state. In a series
of user studies, we validate the effectiveness of the TapBoard concept. First, we
show that tapping to type is in fact compatible with the existing typing skill of
most touch screen keyboard users. Second, users quickly adapt to the TapBoard and
learn to rest their fingers in the touched state. Finally, we confirm by a controlled
experiment that there is no difference in text-entry performance between the TapBoard
and a traditional touch screen software keyboard. In addition to these experimental
results, we demonstrate a few new interaction techniques that will be made possible
by the TapBoard.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {553–562},
numpages = {10},
keywords = {tapboard, touch screen keyboard, text-entry method},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470734,
author = {Bailly, Gilles and Pietrzak, Thomas and Deber, Jonathan and Wigdor, Daniel J.},
title = {M\'{e}Tamorphe: Augmenting Hotkey Usage with Actuated Keys},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470734},
doi = {10.1145/2470654.2470734},
abstract = {Hotkeys are an efficient method of selecting commands on a keyboard. However, these
shortcuts are often underused by users. We present M\'{e}tamorphe, a novel keyboard with
keys that can be individually raised and lowered to promote hotkeys usage. M\'{e}tamorphe
augments the output of traditional keyboards with haptic and visual feedback, and
offers a novel design space for user input on raised keys (e.g., gestures such as
squeezing or pushing the sides of a key). We detail the implementation of M\'{e}tamorphe
and discuss design factors. We also report two user studies. The first is a user-defined
interface study that shows that the new input vocabulary is usable and useful, and
provides insights into the mental models that users associate with raised keys. The
second user study shows improved eyes-free selection performance for raised keys as
well as the surrounding unraised keys.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {563–572},
numpages = {10},
keywords = {height-changing keys, user-defined gestures, augmented keyboard, hotkeys, shape-changing interfaces},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470735,
author = {Malacria, Sylvain and Bailly, Gilles and Harrison, Joel and Cockburn, Andy and Gutwin, Carl},
title = {Promoting Hotkey Use through Rehearsal with ExposeHK},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470735},
doi = {10.1145/2470654.2470735},
abstract = {Keyboard shortcuts allow fast interaction, but they are known to be infrequently used,
with most users relying heavily on traditional pointer-based selection for most commands.
We describe the goals, design, and evaluation of ExposeHK, a new interface mechanism
that aims to increase hotkey use. ExposeHK's four key design goals are: 1) enable
users to browse hotkeys; 2) allow non-expert users to issue hotkey commands as a physical
rehearsal of expert performance; 3) exploit spatial memory to assist non-expert users
in identifying hotkeys; and 4) maximise expert performance by using consistent shortcuts
in a flat command hierarchy. ExposeHK supports these objectives by displaying hotkeys
overlaid on their associated commands when a modifier key is pressed. We evaluated
ExposeHK in three empirical studies using toolbars, menus, and a tabbed '18ribbon'
toolbar. Results show that participants used more hotkeys, and used them more often,
with ExposeHK than with other techniques; they were faster with ExposeHK than with
either pointing or other hotkey methods; and they strongly preferred ExposeHK. Our
research shows that ExposeHK can substantially improve the user's transition from
a '18beginner mode' of interaction to a higher level of expertise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {573–582},
numpages = {10},
keywords = {rehearsal, command selection, menus, novice mode, hotkeys, keyboard shortcuts, expert mode},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250123,
author = {Lank, Edward},
title = {Session Details: Papers: Flexible Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250123},
doi = {10.1145/3250123},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470737,
author = {Gomes, Antonio and Nesbitt, Andrea and Vertegaal, Roel},
title = {MorePhone: A Study of Actuated Shape Deformations for Flexible Thin-Film Smartphone Notifications},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470737},
doi = {10.1145/2470654.2470737},
abstract = {We present MorePhone, an actuated flexible smartphone with a thin-film E Ink display.
MorePhone uses shape memory alloys to actuate the entire surface of the display as
well as individual corners. We conducted a participatory study to determine how users
associate urgency and notification type with full screen, 1 corner, 2 corner and 3
corner actuations of the smartphone. Results suggest that with the current prototype,
actuated shape notifications are useful for visual feedback. Urgent notifications
such as alarms and voice calls were best matched with actuation of the entire display
surface, while less urgent notifications, such as software notifications were best
matched to individual corner bends. While different corner actuations resulted in
significantly different matches between notification types, medium urgency notification
types were treated as similar, and best matched to a single corner bend. A follow-up
study suggested that users prefer to dedicate each corner to a specific type of notification.
Users would like to personalize the assignment of corners to notification type. Animation
of shape actuation significantly increased the perceived urgency of any of the presented
shapes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {583–592},
numpages = {10},
keywords = {shape changing interfaces, flexible displays, actuation, organic user interfaces, notification},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470738,
author = {Roudaut, Anne and Karnik, Abhijit and L\"{o}chtefeld, Markus and Subramanian, Sriram},
title = {Morphees: Toward High "Shape Resolution" in Self-Actuated Flexible Mobile Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470738},
doi = {10.1145/2470654.2470738},
abstract = {We introduce the term shape resolution, which adds to the existing definitions of
screen and touch resolution. We propose a framework, based on a geometric model (Non-Uniform
Rational B-splines), which defines a metric for shape resolution in ten features.
We illustrate it by comparing the current related work of shape changing devices.
We then propose the concept of Morphees that are self-actuated flexible mobile devices
adapting their shapes on their own to the context of use in order to offer better
affordances. For instance, when a game is launched, the mobile device morphs into
a console-like shape by curling two opposite edges to be better grasped with two hands.
We then create preliminary prototypes of Morphees in order to explore six different
building strategies using advanced shape changing materials (dielectric electro active
polymers and shape memory alloys). By comparing the shape resolution of our prototypes,
we generate insights to help designers toward creating high shape resolution Morphees.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {593–602},
numpages = {10},
keywords = {shape changing, organic user interface, shape resolution, flexible touchscreen, haptic feedback},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470739,
author = {Hashimoto, Sunao and Suzuki, Ryohei and Kamiyama, Youichi and Inami, Masahiko and Igarashi, Takeo},
title = {LightCloth: Senseable Illuminating Optical Fiber Cloth for Creating Interactive Surfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470739},
doi = {10.1145/2470654.2470739},
abstract = {This paper introduces an input and output device that enables illumination, bi-directional
data communication, and position sensing on a soft cloth. This "LightCloth" is woven
from diffusive optical fibers. Since the fibers are arranged in parallel, the cloth
has one-dimensional position information. Sensor-emitter pairs attached to bundles
of contiguous fibers enable bundle-specific light input and output. We developed a
prototype system that allows full-color illumination and 8-bit data input by infrared
signals. We present as an application a chair with a LightCloth cover whose illumination
pattern is specified using an infrared light pen. Here we describe the implementation
details of the device and discuss possible interactions using the device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {603–606},
numpages = {4},
keywords = {diffusive optical fiber, position sensing, soft deformable user interface, illumination, light communication},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470740,
author = {Warren, Kristen and Lo, Jessica and Vadgama, Vaibhav and Girouard, Audrey},
title = {Bending the Rules: Bend Gesture Classification for Flexible Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470740},
doi = {10.1145/2470654.2470740},
abstract = {Bend gestures have a large number of degrees of freedom and therefore offer a rich
interaction language. We propose a classification scheme for bend gestures, and explore
how users perform these bend gestures along four classification criterion: location,
direction, size, and angle. We collected 36 unique bend gestures performed three times
by each participant. The results suggest a strong agreement among participants for
preferences of location and direction. Size and angle were difficult for users to
differentiate. Finally, users performed and perceived two distinct levels of magnitude.
We propose recommendations for designing bend gestures with flexible displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {607–610},
numpages = {4},
keywords = {flexible display, bend gesture, affordance, deformable user interface, organic user interface},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250124,
author = {Dow, Steven},
title = {Session Details: Papers: Smart Tools, Smart Work},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250124},
doi = {10.1145/3250124},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470742,
author = {Irani, Lilly C. and Silberman, M. Six},
title = {Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470742},
doi = {10.1145/2470654.2470742},
abstract = {As HCI researchers have explored the possibilities of human computation, they have
paid less attention to ethics and values of crowdwork. This paper offers an analysis
of Amazon Mechanical Turk, a popular human computation system, as a site of technically
mediated worker-employer relations. We argue that human computation currently relies
on worker invisibility. We then present Turkopticon, an activist system that allows
workers to publicize and evaluate their relationships with employers. As a common
infrastructure, Turkopticon also enables workers to engage one another in mutual aid.
We conclude by discussing the potentials and challenges of sustaining activist technologies
that intervene in large, existing socio-technical systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {611–620},
numpages = {10},
keywords = {ethics, human computation, activism, design, infrastructure, amazon mechanical turk},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470743,
author = {Huang, Shih-Wen and Fu, Wai-Tat},
title = {Don't Hide in the Crowd! Increasing Social Transparency between Peer Workers Improves Crowdsourcing Outcomes},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470743},
doi = {10.1145/2470654.2470743},
abstract = {This paper studied how social transparency and different peer-dependent reward schemes
(i.e., individual, teamwork, and competition) affect the outcomes of crowdsourcing.
The results showed that when social transparency was increased by asking otherwise
anonymous workers to share their demographic information (e.g., name, nationality)
to the paired worker, they performed significantly better. A more detailed analysis
showed that in a teamwork reward scheme, in which the reward of the paired workers
depended only on the collective outcomes, increasing social transparency could offset
effects of social loafing by making them more accountable to their teammates. In a
competition reward scheme, in which workers competed against each other and the reward
depended on how much they outperformed their opponent, increasing social transparency
could augment effects of social facilitation by providing more incentives for them
to outperform their opponent. The results suggested that a careful combination of
methods that increase social transparency and different reward schemes can significantly
improve crowdsourcing outcomes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {621–630},
numpages = {10},
keywords = {social facilitation, crowdsourcing, social transparency, social loafing, human computation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470744,
author = {Hara, Kotaro and Le, Vicki and Froehlich, Jon},
title = {Combining Crowdsourcing and Google Street View to Identify Street-Level Accessibility Problems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470744},
doi = {10.1145/2470654.2470744},
abstract = {Poorly maintained sidewalks, missing curb ramps, and other obstacles pose considerable
accessibility challenges; however, there are currently few, if any, mechanisms to
determine accessible areas of a city a priori. In this paper, we investigate the feasibility
of using untrained crowd workers from Amazon Mechanical Turk (turkers) to find, label,
and assess sidewalk accessibility problems in Google Street View imagery. We report
on two studies: Study 1 examines the feasibility of this labeling task with six dedicated
labelers including three wheelchair users; Study 2 investigates the comparative performance
of turkers. In all, we collected 13,379 labels and 19,189 verification labels from
a total of 402 turkers. We show that turkers are capable of determining the presence
of an accessibility problem with 81% accuracy. With simple quality control methods,
this number increases to 93%. Our work demonstrates a promising new, highly scalable
method for acquiring knowledge about sidewalk accessibility.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {631–640},
numpages = {10},
keywords = {crowdsourcing accessibility, accessible urban navigation, mechanical turk, image labeling, google street view},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470745,
author = {Musthag, Mohamed and Ganesan, Deepak},
title = {Labor Dynamics in a Mobile Micro-Task Market},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470745},
doi = {10.1145/2470654.2470745},
abstract = {The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets,
where smartphone users participate to perform tasks in the physical world. Mobile
crowdsourcing markets are uniquely different from their online counterparts in that
they require spatial mobility, and are therefore impacted by geographic factors and
constraints that are not present in the online case. Despite the emergence and importance
of such mobile marketplaces, little to none is known about the labor dynamics and
mobility patterns of agents. This paper provides an in-depth exploration of labor
dynamics in mobile task markets based on a year-long dataset from a leading mobile
crowdsourcing platform. We find that a small core group of workers (&lt; 10%) account
for a disproportionately large proportion of activity (&gt; 80%) generated in the market.
We find that these super agents are more efficient than other agents across several
dimensions: a) they are willing to move longer distances to perform tasks, yet they
amortize travel across more tasks, b) they work and search for tasks more efficiently,
c) they have higher data quality in terms of accepted submissions, and d) they improve
in almost all of these efficiency measures over time. We find that super agent efficiency
stems from two simple optimizations --- they are 3x more likely than other agents
to chain tasks and they pick fewer lower priced tasks than other agents. We compare
mobile and online micro-task markets, and discuss differences in demographics, data
quality, and time of use, as well as similarities in super agent behavior. We conclude
with a discussion of how a mobile micro-task market might leverage some of our results
to improve performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {641–650},
numpages = {10},
keywords = {micro task markets, mobile crowdsourcing, crowdsourcing, labor mobility},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250125,
author = {Ko, Andrew},
title = {Session Details: Papers: Creating and Authoring},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250125},
doi = {10.1145/3250125},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470747,
author = {Davis, Nicholas and Zook, Alexander and O'Neill, Brian and Headrick, Brandon and Riedl, Mark and Grosz, Ashton and Nitsche, Michael},
title = {Creativity Support for Novice Digital Filmmaking},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470747},
doi = {10.1145/2470654.2470747},
abstract = {Machinima is a new form of creative digital filmmaking that leverages the real time
graphics rendering of computer game engines. Because of the low barrier to entry,
machinima has become a popular creative medium for hobbyists and novices while still
retaining borrowed conventions from professional filmmaking. Can novice machinima
creators benefit from creativity support tools? A preliminary study shows novices
generally have difficulty adhering to cinematographic conventions. We identify and
document four cinematic conventions novices typically violate. We report on a Wizard-of-Oz
study showing a rule-based intelligent system that can reduce the frequency of errors
that novices make by providing information about rule violations without prescribing
solutions. We discuss the role of error reduction in creativity support tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {651–660},
numpages = {10},
keywords = {creativity support tools, digital filmmaking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470748,
author = {Zhu, Kening and Zhao, Shengdong},
title = {AutoGami: A Low-Cost Rapid Prototyping Toolkit for Automated Movable Paper Craft},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470748},
doi = {10.1145/2470654.2470748},
abstract = {AutoGami is a toolkit for designing automated movable paper craft using the technology
of selective inductive power transmission. AutoGami has hardware and software components
that allow users to design and implement automated movable paper craft without any
prerequisite knowledge of electronics; it also supports rapid prototyping. Apart from
developing the toolkit, we have analyzed the design space of movable paper craft and
developed a taxonomy to facilitate the design of automated paper craft. AutoGami made
consistently strong showings in design workshops, confirming its viability in supporting
engagement and creativity as well as its usability in storytelling through paper craft.
Additional highlights include rapid prototyping of product design as well as interaction
design such as human-robot interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {661–670},
numpages = {10},
keywords = {toolkit, paper computing, selective inductive power transmission, automated paper craft},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470749,
author = {Edge, Darren and Savage, Joan and Yatani, Koji},
title = {HyperSlides: Dynamic Presentation Prototyping},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470749},
doi = {10.1145/2470654.2470749},
abstract = {Presentations are a crucial form of modern communication, yet there is a dissonance
between everyday practices with presentation tools and best practices from the presentation
literature. We conducted a grounded theory study to gain a better understanding of
the activity of presenting, discovering the potential for a more dynamic, automated,
and story-centered approach to prototyping slide presentations that are themselves
dynamic in their ability to help presenters rehearse and deliver their story. Our
prototype tool for dynamic presentation prototyping, which we call HyperSlides, uses
a simple markup language for the creation of hierarchically structured scenes, which
are algorithmically transformed into hyperlinked slides of a consistent and minimalist
style. Our evaluation suggests that HyperSlides helps idea organization, saves authoring
time, creates aesthetic layouts, and supports more flexible rehearsal and delivery
than linear slides, at the expense of reduced layout control and increased navigation
demands.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {671–680},
numpages = {10},
keywords = {slideware, presentations, powerpoint, grounded theory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470750,
author = {Liu, Yefeng and Edge, Darren and Yatani, Koji},
title = {SidePoint: A Peripheral Knowledge Panel for Presentation Slide Authoring},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470750},
doi = {10.1145/2470654.2470750},
abstract = {Presentation authoring is an important activity, but often requires the secondary
task of collecting the information and media necessary for both slides and speech.
Integration of implicit search and peripheral displays into presentation authoring
tools may reduce the effort to satisfy not just active needs the author is aware of,
but also latent needs that she is not aware of until she encounters content of perceived
value. We develop SidePoint, a peripheral panel that supports presentation authoring
by showing concise knowledge items relevant to the slide content. We study SidePoint
as a technology probe to examine the benefits and issues associated with peripheral
knowledge panels for presentation authoring. Our results show that peripheral knowledge
panels have the potential to satisfy both types of needs in ways that transform presentation
authoring for the better.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {681–684},
numpages = {4},
keywords = {presentation authoring, peripheral displays, natural language processing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250126,
author = {Nacke, Lennart},
title = {Session Details: Papers: Exploring Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250126},
doi = {10.1145/3250126},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470752,
author = {Birk, Max and Mandryk, Regan L.},
title = {Control Your Game-Self: Effects of Controller Type on Enjoyment, Motivation, and Personality in Game},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470752},
doi = {10.1145/2470654.2470752},
abstract = {Whether they are made to entertain you, or to educate you, good video games engage
you. Significant research has tried to understand engagement in games by measuring
player experience (PX). Traditionally, PX evaluation has focused on the enjoyment
of game, or the motivation of players; these factors no doubt contribute to engagement,
but do decisions regarding play environment (e.g., the choice of game controller)
affect the player more deeply than that? We apply self-determination theory (specifically
satisfaction of needs and self-discrepancy represented using the five factors model
of personality) to explain PX in an experiment with controller type as the manipulation.
Our study shows that there are a number of effects of controller on PX and in-game
player personality. These findings provide both a lens with which to view controller
effects in games and a guide for controller choice in the design of new games. Our
research demonstrates that including self-characteristics assessment in the PX evaluation
toolbox is valuable and useful for understanding player experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {685–694},
numpages = {10},
keywords = {self-determination theory, motivation, self-discrepancy theory, controller, games, personality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470753,
author = {Huang, Jeff and Zimmermann, Thomas and Nagapan, Nachiappan and Harrison, Charles and Phillips, Bruce C.},
title = {Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470753},
doi = {10.1145/2470654.2470753},
abstract = {How do video game skills develop, and what sets the top players apart? We study this
question of skill through a rating generated from repeated multiplayer matches called
TrueSkill. Using these ratings from 7 months of games from over 3 million players,
we look at how play intensity, breaks in play, skill change over time, and other games
affect skill. These analyzed factors are then combined to model future skill and games
played; the results show that skill change in early matches is a useful metric for
modeling future skill, while play intensity explains eventual games played. The best
players in the 7-month period, who we call "Master Blasters", have varied skill patterns
that often run counter to the trends we see for typical players. The data analysis
is supplemented with a 70 person survey to explore how players' self-perceptions compare
to the gameplay data; most survey responses align well with the data and provide insight
into player beliefs and motivation. Finally, we wrap up with a discussion about hiding
skill information from players, and implications for game designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {695–704},
numpages = {10},
keywords = {learning, online multiplayer, video games, gaming skill},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470754,
author = {Graham, T.C. Nicholas and Schumann, Irina and Patel, Mrunal and Bellay, Quentin and Dachselt, Raimund},
title = {Villains, Architects and Micro-Managers: What Tabula Rasa Teaches Us about Game Orchestration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470754},
doi = {10.1145/2470654.2470754},
abstract = {Players of digital games are limited by the constraints of the game's implementation.
Players cannot fly a kite, plant a tree or make friends with a dragon if these activities
were not coded within the game. Game orchestration relaxes these restrictions by allowing
players to create game narratives and settings as the game is being played. This enables
players to express their creativity beyond the strictures of the game's implementation.
We present Tabula Rasa, a novel game orchestration tool based on an efficient tabletop
interface. Based on a study of 20 game orchestration sessions using Tabula Rasa, we
identify five behavioural patterns adopted by orchestrators, and four styles of collaborative
interaction between orchestrators and players. Finally, we present recommendations
for designers of game orchestration systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {705–714},
numpages = {10},
keywords = {game orchestration, game design, tabletop gaming},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470755,
author = {Peyton, Tamara and Young, Alyson L. and Lutters, Wayne},
title = {Playing with Leadership and Expertise: Military Tropes and Teamwork in an Arg},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470755},
doi = {10.1145/2470654.2470755},
abstract = {Ad-hoc virtual teams often lack tools to formalize leadership and structure collaboration,
yet they are often successful. How does this happen? We argue that the emergence of
leadership and the development of expertise occurs in the process of taking action
and in direct response to a lack of structure. Using a twinned set of eight modality
sliders, we examine the interactions of fourteen players in an alternate reality game.
We find that players adopted military language and culture to structure and arrange
their play. We determine that it is critical to account for the context of play across
these modalities in order to design appropriately for effective in-game virtual organizing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {715–724},
numpages = {10},
keywords = {expertise, team work, computer-supported cooperative work, qualitative research, alternate reality games, leadership},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250127,
author = {Subramanian, Sriram},
title = {Session Details: Papers: Tables and Floors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250127},
doi = {10.1145/3250127},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470757,
author = {Br\"{a}nzel, Alan and Holz, Christian and Hoffmann, Daniel and Schmidt, Dominik and Knaust, Marius and L\"{u}hne, Patrick and Meusel, Ren\'{e} and Richter, Stephan and Baudisch, Patrick},
title = {GravitySpace: Tracking Users and Their Poses in a Smart Room Using a Pressure-Sensing Floor},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470757},
doi = {10.1145/2470654.2470757},
abstract = {We explore how to track people and furniture based on a high-resolution pressure-sensitive
floor. Gravity pushes people and objects against the floor, causing them to leave
imprints of pressure distributions across the surface. While the sensor is limited
to sensing direct contact with the surface, we can sometimes conclude what takes place
above the surface, such as users' poses or collisions with virtual objects. We demonstrate
how to extend the range of this approach by sensing through passive furniture that
propagates pressure to the floor. To explore our approach, we have created an 8 m2
back-projected floor prototype, termed GravitySpace, a set of passive touch-sensitive
furniture, as well as algorithms for identifying users, furniture, and poses. Pressure-based
sensing on the floor offers four potential benefits over camera-based solutions: (1)
it provides consistent coverage of rooms wall-to-wall, (2) is less susceptible to
occlusion between users, (3) allows for the use of simpler recognition algorithms,
and (4) intrudes less on users' privacy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {725–734},
numpages = {10},
keywords = {ubicomp, ftir, iinteractive floor, vision, multitouch, multitoe, smart rooms, tabletop},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470758,
author = {Sutcliffe, Steven W.T. and Ivkovic, Zenja and Flatla, David R. and Pavlovych, Andriy and Stavness, Ian and Gutwin, Carl},
title = {Improving Digital Handoff Using the Space above the Table},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470758},
doi = {10.1145/2470654.2470758},
abstract = {Object handoff - that is, passing an object or tool to another person - is an extremely
common activity in collaborative tabletop work. On digital tables, object handoff
is typically accomplished by sliding them on the table surface - but surface-only
interactions can be slow and error-prone, particularly when there are multiple people
carrying out multiple handoffs. An alternative approach is to use the space above
the table for object handoff; this provides more room to move, but requires above-surface
tracking. We have developed two above-the-surface handoff techniques that use simple
and inexpensive tracking: a force-field technique that uses a depth camera to determine
hand proximity, and an electromagnetic-field technique called ElectroTouch that provides
positive indication when people touch hands over the table. We compared the new techniques
to three kinds of surface-only handoff (sliding, flicking, and surface-only Force-Fields).
The study showed that the above-surface techniques significantly improved both speed
and accuracy, and that ElectroTouch was the best technique overall. This work provides
designers with practical new techniques for substantially increasing performance and
interaction richness on digital tables.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {735–744},
numpages = {10},
keywords = {digital tables, coordination, digital object handoff},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470759,
author = {Voelker, Simon and Wacharamanotham, Chat and Borchers, Jan},
title = {An Evaluation of State Switching Methods for Indirect Touch Systems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470759},
doi = {10.1145/2470654.2470759},
abstract = {Indirect touch systems combine a horizontal touch input surface with a vertical display
for output. While this division is ergonomically superior to simple direct-touch displays
for many tasks, users are no longer looking at their hands when touching. This requires
the system to support an intermediate '1ctracking'1d state that lets users aim at
objects without triggering a selection, similar to the hover state in mouse-based
UIs. We present an empirical analysis of several interaction techniques for indirect
touch systems to switch to this intermediate state, and derive design recommendations
for incorporating it into such systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {745–754},
numpages = {10},
keywords = {three-state model, indirect-touch},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470760,
author = {M\"{o}llers, Max and Dumont, Norbert and Ladwig, Stefan and Borchers, Jan},
title = {Improving Touch Accuracy on Large Tabletops Using Predecessor and Successor},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470760},
doi = {10.1145/2470654.2470760},
abstract = {Touch interfaces provide great flexibility in designing an UI. However, the actual
experience is often frustrating due to bad touch recognition. On small systems, we
can analyze yaw, roll, and pitch of the finger to increase touch accuracy for a single
touch. On larger systems, we need to take additional factors into account as users
have more flexibility for their limb posture and need to aim over larger distances.
Thus, we investigated how people perform touch sequences on those large touch surfaces.
We show that the relative location of the predecessor of a touch has a significant
impact on the orientation and position of the touch ellipsis.We exploited this effect
on an off-the-shelf touch display and showed that with only minimal preparation the
touch accuracy of standard hardware can be improved by at least 7%, allowing better
recognition rates or more UI components on the same screen.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {755–758},
numpages = {4},
keywords = {offset, sequence, tabletops, touch, accuracy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470761,
author = {Nowacka, Diana and Ladha, Karim and Hammerla, Nils Y. and Jackson, Daniel and Ladha, Cassim and Rukzio, Enrico and Olivier, Patrick},
title = {Touchbugs: Actuated Tangibles on Multi-Touch Tables},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470761},
doi = {10.1145/2470654.2470761},
abstract = {We present a novel approach to graspable interfaces using Touchbugs, actuated physical
objects for interacting with interactive surface computing applications. Touchbugs
are active tangibles that are able to move across surfaces by employing vibrating
motors and can communicate with camera based multi-touch surfaces using infrared LEDs.
Touchbug's embedded inertial sensors and computational capabilities open a new interaction
space by providing autonomous capabilities for tangibles that allow goal directed
behavior.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {759–762},
numpages = {4},
keywords = {interactive tabletops, actuated tangibles, user interface device},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250128,
author = {Tatar, Deborah},
title = {Session Details: Papers: Design for Classrooms 1},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250128},
doi = {10.1145/3250128},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470763,
author = {Denny, Paul},
title = {The Effect of Virtual Achievements on Student Engagement},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470763},
doi = {10.1145/2470654.2470763},
abstract = {Badge-based achievement systems are being used increasingly to drive user participation
and engagement across a variety of platforms and contexts. Despite positive anecdotal
reports, there is currently little empirical evidence to support their efficacy in
particular domains. With the recent rapid growth of tools for online learning, an
interesting open question for educators is the extent to which badges can positively
impact student participation.In this paper, we report on a large-scale (n &gt; 1000)
randomized, controlled experiment measuring the impact of incorporating a badge-based
achievement system within an online learning tool. We discover a highly significant
positive effect on the quantity of students' contributions, without a corresponding
reduction in their quality, as well as on the period of time over which students engaged
with the tool. Students enjoyed being able to earn badges, and indicated a strong
preference for having them available in the user interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {763–772},
numpages = {10},
keywords = {peerwise, online learning, gamification, education, achievements, badges},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470764,
author = {Andersen, Erik and Gulwani, Sumit and Popovic, Zoran},
title = {A Trace-Based Framework for Analyzing and Synthesizing Educational Progressions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470764},
doi = {10.1145/2470654.2470764},
abstract = {A key challenge in teaching a procedural skill is finding an effective progression
of example problems that the learner can solve in order to internalize the procedure.
In many learning domains, generation of such problems is typically done by hand and
there are few tools to help automate this process. We reduce this effort by borrowing
ideas from test input generation in software engineering. We show how we can use execution
traces as a framework for abstracting the characteristics of a given procedure and
defining a partial ordering that reflects the relative difficulty of two traces. We
also show how we can use this framework to analyze the completeness of expert-designed
progressions and fill in holes. Furthermore, we demonstrate how our framework can
automatically synthesize new problems by generating large sets of problems for elementary
and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning
game. We present the results of a user study with this game confirming that our partial
ordering can predict user evaluation of procedural difficulty better than baseline
methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {773–782},
numpages = {10},
keywords = {execution traces, education, games, problem generation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470765,
author = {Farzan, Rosta and Kraut, Robert E.},
title = {Wikipedia Classroom Experiment: Bidirectional Benefits of Students' Engagement in Online Production Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470765},
doi = {10.1145/2470654.2470765},
abstract = {Over the last decade, a citizen science movement has tried to engage students, laymen
and other non-scientists in the production of science. However, there has been less
attention in citizen science projects to use the public to disseminate scientific
knowledge. Wikipedia provides a platform to study engagement of citizen scientists
in knowledge dissemination. College and university students are especially appropriate
members of the public to write science articles, because of the course-work and mentorship
they receive from faculty. This paper describes a project to support students' writing
of scientific articles in Wikipedia. In collaboration with a scientific association,
we involved 640 students from 36 courses in editing scientific articles on Wikipedia.
This paper provides details in the design of the program and our quantitative and
qualitative approaches to evaluating it. Our results show that the Wikipedia classroom
experiment benefits both the Wikipedia community and students. Undergraduate and graduate
students substantially improved the scientific content of over 800 articles, at a
level of quality indistinguishable from content written by PhD experts. Both students
and faculty endorsed the motivational benefits of an authentic writing experience
that would be read by thousands of people.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {783–792},
numpages = {10},
keywords = {experiment, socialization, online volunteer community},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470766,
author = {Cross, Andrew and Bayyapunedi, Mydhili and Cutrell, Edward and Agarwal, Anant and Thies, William},
title = {TypeRighting: Combining the Benefits of Handwriting and Typeface in Online Educational Videos},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470766},
doi = {10.1145/2470654.2470766},
abstract = {Recent years have seen enormous growth of online educational videos, spanning K-12
tutorials to university lectures. As this content has grown, so too has grown the
number of presentation styles. Some educators have strong allegiance to handwritten
recordings (using pen and tablet), while others use only typed (PowerPoint) presentations.
In this paper, we present the first systematic comparison of these two presentation
styles and how they are perceived by viewers. Surveys on edX and Mechanical Turk suggest
that users enjoy handwriting because it is personal and engaging, yet they also enjoy
typeface because it is clear and legible. Based on these observations, we propose
a new presentation style, TypeRighting, that combines the benefits of handwriting
and typeface. Each phrase is written by hand, but fades into typeface soon after it
appears. Our surveys suggest that about 80% of respondents prefer TypeRighting over
handwriting. The same fraction of respondents prefer TypeRighting over typeface, for
videos in which the handwriting is sufficiently legible.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {793–796},
numpages = {4},
keywords = {online education, massive open online course, handwriting},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470767,
author = {Birnholtz, Jeremy and Hancock, Jeff and Retelny, Daniela},
title = {Tweeting for Class: Co-Construction as a Means for Engaging Students in Lectures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470767},
doi = {10.1145/2470654.2470767},
abstract = {Motivating students to be active learners is a perennial problem in education, and
is particularly challenging in lectures where instructors typically prepare content
in ad-vance with little direct student participation. We describe our experience using
Twitter as a tool for student "co-construction" of lecture materials. Students were
required to post a tweet prior to each lecture related to that day's topic, and these
tweets -- consisting of questions, examples and reflections -- were incorporated into
the lecture slides and notes. Students reported that they found lectures including
their tweets in the class slides to be engaging, interactive and relevant, and nearly
90% of them recommended we use our co-construction approach again.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {797–800},
numpages = {4},
keywords = {lecture, education, twitter, co-construction., engagement},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250129,
author = {Teevan, Jaime},
title = {Session Details: Papers: Crowds and Activism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250129},
doi = {10.1145/3250129},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470769,
author = {Starbird, Kate},
title = {Delivering Patients to Sacr\'{e} Coeur: Collective Intelligence in Digital Volunteer Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470769},
doi = {10.1145/2470654.2470769},
abstract = {This study examines the information-processing activities of digital volunteers and
other connected ICT users in the wake of crisis events. Synthesizing findings from
several previous research studies of digital volunteerism, this paper offers a new
approach for conceptualizing the activities of digital volunteers, shifting from a
focus on organizing to a focus on information movement. Using the lens of distributed
cognition, this research describes collective intelligence as transformations of information
within a system where cognition is distributed socially across individuals as well
as through their tools and resources. This paper demonstrates how digital volunteers,
through activities such as relaying, amplifying, verifying, and structuring information,
function as a collectively intelligent cognitive system in the wake of disaster events.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {801–810},
numpages = {10},
keywords = {crowdsourcing, distributed cognition, collective intelligence, crisis informatics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470770,
author = {Lee, Yu-Hao and Hsieh, Gary},
title = {Does Slacktivism Hurt Activism? The Effects of Moral Balancing and Consistency in Online Activism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470770},
doi = {10.1145/2470654.2470770},
abstract = {In this paper we explore how the decision of partaking in low-cost, low-risk online
activism - slacktivism - '14may affect subsequent civic action. Based on moral balancing
and consistency effects, we designed an online experiment to test if signing or not
signing an online petition increased or decreased subsequent contribution to a charity.
We found that participants who signed the online petition were significantly more
likely to donate money to a related charity, demonstrating a consistency effect. We
also found that participants who did not sign the petition donated significantly more
money to an unrelated charity, demonstrating a moral balancing effect. The results
suggest that exposure to an online activism influences individual decision on subsequent
civic actions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {811–820},
numpages = {10},
keywords = {online petitions, slacktivism, consistency, moral balancing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470771,
author = {Hutto, C.J. and Yardi, Sarita and Gilbert, Eric},
title = {A Longitudinal Study of Follow Predictors on Twitter},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470771},
doi = {10.1145/2470654.2470771},
abstract = {Follower count is important to Twitter users: it can indicate popularity and prestige.
Yet, holistically, little is understood about what factors -- like social behavior,
message content, and network structure - lead to more followers. Such information
could help technologists design and build tools that help users grow their audiences.
In this paper, we study 507 Twitter users and a half-million of their tweets over
15 months. Marrying a longitudinal approach with a negative binomial auto-regression
model, we find that variables for message content, social behavior, and network structure
should be given equal consideration when predicting link formations on Twitter. To
our knowledge, this is the first longitudinal study of follow predictors, and the
first to show that the relative contributions of social behavior and mes-sage content
are just as impactful as factors related to social network structure for predicting
growth of online social networks. We conclude with practical and theoretical implications
for designing social media technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {821–830},
numpages = {10},
keywords = {computer-mediated communication, social media, social networks},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250130,
author = {Cao, Xiang},
title = {Session Details: Papers: Large and Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250130},
doi = {10.1145/3250130},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470773,
author = {Nancel, Mathieu and Chapuis, Olivier and Pietriga, Emmanuel and Yang, Xing-Dong and Irani, Pourang P. and Beaudouin-Lafon, Michel},
title = {High-Precision Pointing on Large Wall Displays Using Small Handheld Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470773},
doi = {10.1145/2470654.2470773},
abstract = {Rich interaction with high-resolution wall displays is not limited to remotely pointing
at targets. Other relevant types of interaction include virtual navigation, text entry,
and direct manipulation of control widgets. However, most techniques for remotely
acquiring targets with high precision have studied remote pointing in isolation, focusing
on pointing efficiency and ignoring the need to support these other types of interaction.
We investigate high-precision pointing techniques capable of acquiring targets as
small as 4 millimeters on a 5.5 meters wide display while leaving up to 93 % of a
typical tablet device's screen space available for task-specific widgets. We compare
these techniques to state-of-the-art distant pointing techniques and show that two
of our techniques, a purely relative one and one that uses head orientation, perform
as well or better than the best pointing-only input techniques while using a fraction
of the interaction resources.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {831–840},
numpages = {10},
keywords = {handheld devices, pointing, wall displays},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470774,
author = {Walter, Robert and Bailly, Gilles and M\"{u}ller, J\"{o}rg},
title = {StrikeAPose: Revealing Mid-Air Gestures on Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470774},
doi = {10.1145/2470654.2470774},
abstract = {We investigate how to reveal an initial mid-air gesture on interactive public displays.
This initial gesture can serve as gesture registration for advanced operations. We
propose three strategies to reveal the initial gesture: spatial division, temporal
division and integration. Spatial division permanently shows the gesture on a dedicated
screen area. Temporal division interrupts the application to reveal the gesture. Integration
embeds gesture hints directly in the application. We also propose a novel initial
gesture called Teapot to illustrate our strategies. We report on a laboratory and
field study. Our main findings are: A large percentage of all users execute the gesture,
especially with spatial division (56%). Users intuitively discover a gesture vocabulary
by exploring variations of the Teapot gesture by themselves, as well as by imitating
and extending other users' variations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {841–850},
numpages = {10},
keywords = {field study, public displays, initial gesture, revelation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470775,
author = {Zhang, Yanxia and Bulling, Andreas and Gellersen, Hans},
title = {SideWays: A Gaze Interface for Spontaneous Interaction with Situated Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470775},
doi = {10.1145/2470654.2470775},
abstract = {Eye gaze is compelling for interaction with situated displays as we naturally use
our eyes to engage with them. In this work we present SideWays, a novel person-independent
eye gaze interface that supports spontaneous interaction with displays: users can
just walk up to a display and immediately interact using their eyes, without any prior
user calibration or training. Requiring only a single off-the-shelf camera and lightweight
image processing, SideWays robustly detects whether users attend to the centre of
the display or cast glances to the left or right. The system supports an interaction
model in which attention to the central display is the default state, while "sidelong
glances" trigger input or actions. The robustness of the system and usability of the
interaction model are validated in a study with 14 participants. Analysis of the participants'
strategies in performing different tasks provides insights on gaze control strategies
for design of SideWays applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {851–860},
numpages = {10},
keywords = {eye tracking, spontaneous interaction, eye-based interaction, situated display, calibration-free},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250064,
author = {Casiez, G\'{e}ry},
title = {Session Details: Papers: Interacting around Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250064},
doi = {10.1145/3250064},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466112,
author = {Jones, Brett R. and Benko, Hrvoje and Ofek, Eyal and Wilson, Andrew D.},
title = {IllumiRoom: Peripheral Projected Illusions for Interactive Experiences},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466112},
doi = {10.1145/2470654.2466112},
abstract = {IllumiRoom is a proof-of-concept system that augments the area surrounding a television
with projected visualizations to enhance traditional gaming experiences. We investigate
how projected visualizations in the periphery can negate, include, or augment the
existing physical environment and complement the content displayed on the television
screen. Peripheral projected illusions can change the appearance of the room, induce
apparent motion, extend the field of view, and enable entirely new physical gaming
experiences. Our system is entirely self-calibrating and is designed to work in any
room. We present a detailed exploration of the design space of peripheral projected
illusions and we demonstrate ways to trigger and drive such illusions from gaming
content. We also contribute specific feedback from two groups of target users (10
gamers and 15 game designers); providing insights for enhancing game experiences through
peripheral projected illusions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {869–878},
numpages = {10},
keywords = {augmented reality, immersion, gaming, spatial augmented reality, projection mapping, apparent motion},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466113,
author = {Xiao, Robert and Harrison, Chris and Hudson, Scott E.},
title = {WorldKit: Rapid and Easy Creation of Ad-Hoc Interactive Applications on Everyday Surfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466113},
doi = {10.1145/2470654.2466113},
abstract = {Instant access to computing, when and where we need it, has long been one of the aims
of research areas such as ubiquitous computing. In this paper, we describe the WorldKit
system, which makes use of a paired depth camera and projector to make ordinary surfaces
instantly interactive. Using this system, touch-based interactivity can, without prior
calibration, be placed on nearly any unmodified surface literally with a wave of the
hand, as can other new forms of sensed interaction. From a user perspective, such
interfaces are easy enough to instantiate that they could, if desired, be recreated
or modified "each time we sat down" by "painting" them next to us. From the programmer's
perspective, our system encapsulates these capabilities in a simple set of abstractions
that make the creation of interfaces quick and easy. Further, it is extensible to
new, custom interactors in a way that closely mimics conventional 2D graphical user
interfaces, hiding much of the complexity of working in this new domain. We detail
the hardware and software implementation of our system, and several example applications
built using the library.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {879–888},
numpages = {10},
keywords = {depth sensing cameras, augmented reality, touch screens, sensors, interactive spaces, ubiquitous computing, surface computing, smart rooms},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466114,
author = {Gustafson, Sean G. and Rabe, Bernhard and Baudisch, Patrick M.},
title = {Understanding Palm-Based Imaginary Interfaces: The Role of Visual and Tactile Cues When Browsing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466114},
doi = {10.1145/2470654.2466114},
abstract = {Imaginary Interfaces are screen-less ultra-mobile interfaces. Previously we showed
that even though they offer no visual feedback they allow users to interact spatially,
e.g., by pointing at a location on their non-dominant hand.The primary goal of this
paper is to provide a deeper understanding of palm-based imaginary interfaces, i.e.,
why they work. We perform our exploration using an interaction style inspired by interfaces
for visually impaired users. We implemented a system that audibly announces target
names as users scrub across their palm. Based on this interface, we conducted three
studies. We found that (1) even though imaginary interfaces cannot display visual
contents, users' visual sense remains the main mechanism that allows users to control
the interface, as they watch their hands interact. (2) When we remove the visual sense
by blindfolding, the tactile cues of both hands feeling each other in part replace
the lacking visual cues, keeping imaginary interfaces usable. (3) While we initially
expected the cues sensed by the pointing finger to be most important, we found instead
that it is the tactile cues sensed by the palm that allow users to orient themselves
most effectively.While these findings are primarily intended to deepen our understanding
of Imaginary Interfaces, they also show that eyes-free interfaces located on skin
outperform interfaces on physical devices. In particular, this suggests that palm-based
imaginary interfaces may have benefits for visually impaired users, potentially outperforming
the touchscreen-based devices they use today.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {889–898},
numpages = {10},
keywords = {mobile, imaginary interfaces, tactile feedback, non-visual, wearable, visual feedback},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466115,
author = {Hasan, Khalad and Ahlstr\"{o}m, David and Irani, Pourang},
title = {Ad-Binning: Leveraging around Device Space for Storing, Browsing and Retrieving Mobile Device Content},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466115},
doi = {10.1145/2470654.2466115},
abstract = {Exploring information content on mobile devices can be tedious and time consuming.
We present Around-Device Binning, or AD-Binning, a novel mobile user interface that
allows users to off-load mobile content in the space around the device. We informed
our implementation of AD-Binning by exploring various design factors, such as the
minimum around-device target size, suitable item selection methods, and techniques
for placing content in off-screen space. In a task requiring exploration, we find
that AD-Binning improves browsing efficiency by avoiding the minute selection and
flicking mechanisms needed for on-screen interaction. We conclude with design guidelines
for off screen content storage and browsing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {899–908},
numpages = {10},
keywords = {off-screen discretization, data analytics, visual analytics, around-device interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250065,
author = {Weibel, Nadir},
title = {Session Details: Papers: Design for the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250065},
doi = {10.1145/3250065},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466117,
author = {Ylirisku, Salu and Lindley, Si\^{a}n and Jacucci, Giulio and Banks, Richard and Stewart, Craig and Sellen, Abigail and Harper, Richard and Regan, Tim},
title = {Designing Web-Connected Physical Artefacts for the 'aesthetic' of the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466117},
doi = {10.1145/2470654.2466117},
abstract = {Web-based technologies are often built to capitalize on the flexibility and fluidity
that is supported by the internet, with the value of 'access anywhere' underpinning
a blurring of boundaries across home and work. Yet the home is well known in HCI to
have a unique set of qualities that can use-fully be drawn upon when designing to
support domestic life. In this paper we ask what it means to design domestic web-connected
technologies, placing the aesthetic and material properties intrinsic to the home
and home life at the centre of our design exploration. We present three concepts that
were selected and prototyped from a broader process of research-through-design: Tokens
of Search provides tangible handles to web resources; Hole in Space connects the home
intimately to a remote place; and Manhattan enables the tangible exploration of events
in the community, putting the home at the centre. Discussions in the paper consider
not only how aesthetics is articulated in the material and digital properties of the
artefacts, but also how a consideration of the properties of the home can create a
potentially new design space to explore.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {909–918},
numpages = {10},
keywords = {domestic, tangible, search, research through design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466118,
author = {Juhlin, Oskar and \"{O}nnevall, Elin},
title = {On the Relation of Ordinary Gestures to TV Screens: General Lessons for the Design of Collaborative Interactive Techniques},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466118},
doi = {10.1145/2470654.2466118},
abstract = {We present an interaction analysis based on ethnographic fieldwork of how physical
movements, including gestures, are produced by viewers in front of television screens
in a sports bar. Understanding ordinary life and specifically television watching
in social situations will benefit the discussion of the potential of gesture techniques
for controlling interactive televisions in various locations. Challenges for system
design include body movement recognition, since movements can have many different
purposes and are directed simultaneously at the screen and co-viewers. Moreover, gestures
as elements of conversation are sometimes negotiated and overlapping. Since these
ordinary movements are hard to automatically track and analyse, suggested systems
might lead to demands on viewers to restrain their accustomed movements and adapt
them in ways that might be considered awkward. We also reveal new design opportunities
that draw upon the ways viewers' gestures are influenced by ongoing broadcast.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {919–930},
numpages = {12},
keywords = {interaction analysis, everyday practice, ethnomethodology, overlaps, gestures, group watching, gesture tracking adaptation, tv viewing, interactive television},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466119,
author = {Meese, Rupert and Ali, Shakir and Thorne, Emily-Clare and Benford, Steve D. and Quinn, Anthony and Mortier, Richard and Koleva, Boriana N. and Pridmore, Tony and Baurley, Sharon L.},
title = {From Codes to Patterns: Designing Interactive Decoration for Tableware},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466119},
doi = {10.1145/2470654.2466119},
abstract = {We explore the idea of making aesthetic decorative patterns that contain multiple
visual codes. We chart an iterative collaboration with ceramic designers and a restaurant
to refine a recognition technology to work reliably on ceramics, produce a pattern
book of designs, and prototype sets of tableware and a mobile app to enhance a dining
experience. We document how the designers learned to work with and creatively exploit
the technology, enriching their patterns with embellishments and backgrounds and developing
strategies for embedding codes into complex designs. We discuss the potential and
challenges of interacting with such patterns. We argue for a transition from designing 'codes to patterns' that reflects the skills of designers alongside the development
of new technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {931–940},
numpages = {10},
keywords = {patterns, ceramics, barcodes, qr codes, mobile applications, vision, food, recognition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466120,
author = {Yuill, Nicola and Rogers, Yvonne and Rick, Jochen},
title = {Pass the IPad: Collaborative Creating and Sharing in Family Groups},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466120},
doi = {10.1145/2470654.2466120},
abstract = {The increasingly cross-generational use of personal technology portrays families each
absorbed in individual devices. Tablets potentially support multi-user working but
are currently used as personal devices primarily for consumption, or individual or
web-based games. Could tablets support creative co-located groupwork in families and
how does such creative work differ from the same task on paper? We designed and evaluated
an app requiring individual and group co-creation in families. 262 family groups visiting
a science fair played the collaborative drawing game on paper and iPads. Group creations
were rated significantly more original and cohesive on iPads than paper. Detailed
video analysis of seven family groups showed how tablets support embodiment and use
of digital traces, and how the different media sustain individual and shared actions
at different stages in the creative process. We sketch out implications for ownership
and 'scrap computers': going beyond personally-owned devices and developing collaborative
apps to support groupwork with tablets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {941–950},
numpages = {10},
keywords = {tablets, group working, creation, scrap computers, families, collaboration, shareable interfaces},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250066,
author = {Hsieh, Gary},
title = {Session Details: Papers: Social Creativity},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250066},
doi = {10.1145/3250066},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466122,
author = {Leong, Tuck W. and Wright, Peter C.},
title = {Revisiting Social Practices Surrounding Music},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466122},
doi = {10.1145/2470654.2466122},
abstract = {Music shapes our social lives. While previous research has provided a foundational
understanding of the social affordances surrounding people's interactions with music,
there is a need to update this understanding in light of recent key developments in
our digital technological landscape. This paper describes a qualitative study of people's
social activities and practices around music in households. It extends previous research
by revealing the impact key technologies have on how, where, when, and with who people's
interactions surrounding music occur. It also reveals people's creative attempts to
design their musical experiences with others through reconfiguring and connecting
to various digital technologies and digital platforms in order to pursue more opportunities
for communicating, sharing, bonding, and celebrating lives with others.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {951–960},
numpages = {10},
keywords = {digital music, design, household, sociality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466123,
author = {Birnholtz, Jeremy and Steinhardt, Stephanie and Pavese, Antonella},
title = {Write Here, Write Now! An Experimental Study of Group Maintenance in Collaborative Writing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466123},
doi = {10.1145/2470654.2466123},
abstract = {Writing documents together using collaborative editing tools has become extremely
common with the widespread availability of tools such as Google Docs. The design of
such tools, rooted in early CSCW research, has historically been focused on providing
awareness of the presence and activities of one's collaborators. Evidence from a recent
qualitative study, however, suggests that people are also concerned about how their
behaviors -- and they themselves -- will be perceived by others; and take steps to
mitigate possible negative perceptions. We present an experimental study of dyads
composing documents together, focusing in particular on group maintenance, impression
management and relationship-focused behavior. Results suggest that communication is
positively related to social relations, but only for synchronous writing in a shared
space; the reverse can be true in asynchronous commenting and editing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {961–970},
numpages = {10},
keywords = {collaborative writing, awareness, group maintenance.},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466124,
author = {Gross, Shad and Pace, Tyler and Bardzell, Jeffrey and Bardzell, Shaowen},
title = {Machinima Production Tools: A Vernacular History of a Creative Medium},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466124},
doi = {10.1145/2470654.2466124},
abstract = {In recent years, HCI has shown a rising interest in the creative practices associated
with massive online communities, including crafters, hackers, DIY, and other expert
amateurs. One strategy for researching creativity at this scale is through an analysis
of a community's outputs, including its creative works, custom created tools, and
emergent practices. In this paper, we offer one such case study, a historical account
of World of Warcraft (WoW) machinima (i.e., videos produced inside of video games),
which shows how the aesthetic needs and requirements of video making community coevolved
with the community-made creativity support tools in use at the time. We view this
process as inhabiting different layers and practices of appropriation, and through
an analysis of them, we trace the ways that support for emerging stylistic conventions
become built into creativity support tools over time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {971–980},
numpages = {10},
keywords = {hci, creativity, medium, machinima},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466125,
author = {Cui, Yanqing and Kangas, Jari and Holm, Jukka and Grassel, Guido},
title = {Front-Camera Video Recordings as Emotion Responses to Mobile Photos Shared within Close-Knit Groups},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466125},
doi = {10.1145/2470654.2466125},
abstract = {People use social-photography services to tell stories about themselves and to solicit
responses from viewers. State of the-art services concentrate on textual comments,
"Like" buttons, or similar means for viewers to give explicit feedback, but they overlook
other, non-textual means. This paper investigates how emotion responses--as video
clips captured by the front camera of a cell phone and used as tags for the individual
photo viewed--can enhance photo-sharing experiences for close-knit groups. Our exploration
was carried out with a mobile social-photography service called Social Camera. Four
user groups (N=19) used the application for two to four weeks. The study's results
support the value of using front-camera video recordings to glean emotion response.
It supports lightweight phatic social interactions not possible with comments and
"Like" buttons. Most users kept sharing emotion responses throughout the study. They
typically shared the responses right after they saw a just taken photo received from
a remote partner. They used the responses to share their current contexts with others
just as much as to convey nuanced feelings about a photo. We discuss the implications
for future design and research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {981–990},
numpages = {10},
keywords = {emotion response, co-presence, social photography, mobile, feedback, social camera, close-knit group},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250067,
author = {Kay, Judy},
title = {Session Details: Papers: Design for Classrooms 2},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250067},
doi = {10.1145/3250067},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466127,
author = {Coughlan, Tim and Pitt, Rebecca and McAndrew, Patrick},
title = {Building Open Bridges: Collaborative Remixing and Reuse of Open Educational Resources across Organisations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466127},
doi = {10.1145/2470654.2466127},
abstract = {In this paper we analyse the remixing and reuse of online learning materials offered
as Open Educational Resources (OER). We explore the practices that developed as a
set of course materials were released as OER from the UK, remixed for a US context
by a cross-organisational, cross-cultural team, and then reused in a broad range of
educational settings. We analyse the approaches taken during these remixing and reuse
activities as novel forms of creative collaboration. As a basis for comparison, we
explore similarities and differences with openness in other domains. We identify how
openness provoked novel inter-organisational collaboration and forms of ownership;
define forms of open practice that need support, and present issues that should be
considered in devising and supporting open projects in education and beyond.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {991–1000},
numpages = {10},
keywords = {oer, open, collaboration, education},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466128,
author = {Szafir, Daniel and Mutlu, Bilge},
title = {ARTFul: Adaptive Review Technology for Flipped Learning},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466128},
doi = {10.1145/2470654.2466128},
abstract = {Internet technology is revolutionizing education. Teachers are developing massive
open online courses (MOOCs) and using innovative practices such as flipped learning
in which students watch lectures at home and engage in hands-on, problem solving activities
in class. This work seeks to explore the design space afforded by these novel educational
paradigms and to develop technology for improving student learning. Our design, based
on the technique of adaptive content review, monitors student attention during educational
presentations and determines which lecture topic students might benefit the most from
reviewing. An evaluation of our technology within the context of an online art history
lesson demonstrated that adaptively reviewing lesson content improved student recall
abilities 29% over a baseline system and was able to match recall gains achieved by
a full lesson review in less time. Our findings offer guidelines for a novel design
space in dynamic educational technology that might support both teachers and online
tutoring systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1001–1010},
numpages = {10},
keywords = {brain-computer interfaces (bci), learning, adaptive user interfaces (aui), electroencephalography (eeg), massive open online course (mooc), information recall, flipped learning, adaptive content review},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466129,
author = {Kuksenok, Katie and Brooks, Michael and Wang, Qian and Lee, Charlotte P.},
title = {Challenges and Opportunities for Technology in Foreign Language Classrooms},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466129},
doi = {10.1145/2470654.2466129},
abstract = {We present the results of a two-month ethnographic study of three introductory Russian
classrooms. Through observation and interviews, we identify several distinct roles
played by physical artifacts in the classrooms, such as providing a reference to necessary
foreign-language material and serving as props in creative role-play. The range of
roles taken on by artifacts and the attitudes students have toward them provide a
basis for our discussion about how technology might be more effectively introduced
into the socially negotiated environment of the introductory foreign-language classroom.
We identify the need to balance between collaborative and personal technology in a
stressful, but social, context. Our findings inform a range of roles that technology
can undertake in replacing or augmenting existing classroom artifacts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1011–1020},
numpages = {10},
keywords = {russian, students, textbook, language, artifact, classroom, communication, foreign, language-learning},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466130,
author = {Kharrufa, Ahmed and Balaam, Madeline and Heslop, Phil and Leat, David and Dolan, Paul and Olivier, Patrick},
title = {Tables in the Wild: Lessons Learned from a Large-Scale Multi-Tabletop Deployment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466130},
doi = {10.1145/2470654.2466130},
abstract = {This paper presents the results and experiences of a six-week deployment of multiple
digital tabletops in a school. Dillenbourg's orchestration framework was used both
to guide the design and analysis of the study. Four themes, which directly relate
to the design of the technology for the classroom, out of the 15 orchestration factors
are considered. For each theme, we present our design choices, the relevant observations,
feedback from teachers and students, and we conclude with a number of lessons learned
in the form of design recommendations. The distinguishing factors of our study are
its scale (in terms of duration, number of classes, subjects, and teachers), and its 'in-the-wild' character, with the entire study being conducted in a school, led by
the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions
are the analysis of our observations and design recommendations for future multi-tabletop
applications designed for and deployed within the classroom. Our analyses and recommendations
meaningfully extend HCI's current design understandings of such settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1021–1030},
numpages = {10},
keywords = {tabletops, collaborative learning, classroom orchestration},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250068,
author = {Lee, Joonhwan},
title = {Session Details: Papers: Reflecting on Phones},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250068},
doi = {10.1145/3250068},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466132,
author = {Brown, Barry and McGregor, Moira and Laurier, Eric},
title = {IPhone in Vivo: Video Analysis of Mobile Device Use},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466132},
doi = {10.1145/2470654.2466132},
abstract = {Despite the widespread use of mobile devices, details of mobile technology use 'in
the wild' have proven difficult to collect. This paper uses video data to gain new
insight into the use of mobile computing devices. Our new method combines screen-capture
of iPhone use with video recordings from wearable cameras. We use this data to analyse
how mobile device use is threaded into other co-present activities, focusing on the
use of maps and internet searches. Close analysis reveals novel aspects of gestures
on touch screens, how they serve 'double duty' - both as interface gestures but as
as resources for ongoing joint action. We go on to describe how users 'walk the blue
dot' to orientate themselves, and how searches are occasioned by the local environment.
In conclusion, we argue that mobile devices - rather than pushing us away from the
world around us - are instead just another thread in the complex tapestry of everyday
interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1031–1040},
numpages = {10},
keywords = {ethnography, mobility, smartphone use, video methods},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466133,
author = {Devendorf, Laura and Ryokai, Kimiko},
title = {AnyType: Provoking Reflection and Exploration with Aesthetic Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466133},
doi = {10.1145/2470654.2466133},
abstract = {AnyType is a mobile application that generates unique typefaces from photographs of
shapes that people find in their environment. In keeping with the principles of aesthetic
interaction, the design of AnyType supports opportunities for surprise, storytelling,
and expression. This paper presents data collected from two observational studies
of AnyType. In both studies, we found that people appropriated the application to
create highly personalized messages. They found inspiration in unexpected locations,
created memories from nuanced details in their lives, and creatively explored the
design space provided by the system. Drawing from our observations, we discuss possible
roles mobile devices could play in people's personal meaning making, creative process,
and discovery, in interaction with elements of their physical environment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1041–1050},
numpages = {10},
keywords = {user experience design, mobile technology, aesthetic interaction, typography, self-expression},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466134,
author = {Harmon, Ellie and Mazmanian, Melissa},
title = {Stories of the Smartphone in Everyday Discourse: Conflict, Tension &amp; Instability},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466134},
doi = {10.1145/2470654.2466134},
abstract = {As the smartphone proliferates in American society, so too do stories about its value
and impact. In this paper we draw on advertisements and news articles to analyze cultural
discourse about the smartphone. We highlight two common tropes: one calling for increased
technological integration, the other urging individuals to dis-integrate the smartphone
from daily life. We examine the idealized subject positions of these two stories and
show how both simplistic tropes call on the same overarching values to compel individuals
to take opposing actions. We then reflect on the conflicts individuals experience
in trying to align and account for their actions in relation to multiple contradictory
narratives. Finally, we call for CHI researchers to tell and provoke more complicated
stories of technologies and their relationships with values in conversations, publications,
and future designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1051–1060},
numpages = {10},
keywords = {values and design, cultural discourse, smartphones},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466135,
author = {Kujala, Sari and Miron-Shatz, Talya},
title = {Emotions, Experiences and Usability in Real-Life Mobile Phone Use},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466135},
doi = {10.1145/2470654.2466135},
abstract = {Positive emotional experiences with an interactive product are assumed to lead to
good user experience and, ultimately, to product success. However, the path from emotional
experiences to product evaluation may not be direct, as emotions fluctuate over time,
and some experiences are easier to recall than others. In this study, we examined
emotions and experience episodes during real-life mobile phone use over a five-month
period. The goal is to understand how emotions and memories are related to overall
evaluation of a product: usability, user experience and behavioral intentions. The
results show that both emotions and how people remember them had strong unique roles
in the overall evaluation of the product. Positive emotions were mostly related to
good user experience and negative emotions to low usability. In the early stages of
use, users overestimated their positive emotions and seemed to focus on user experience,
the importance of usability increased over time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1061–1070},
numpages = {10},
keywords = {word of mouth, user satisfaction, day reconstruction method, emotions, memories, user experience, usability, mobile phone},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250069,
author = {Klasnja, Predrag},
title = {Session Details: Papers: Technologies for Life 2},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250069},
doi = {10.1145/3250069},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466137,
author = {Isaacs, Ellen and Konrad, Artie and Walendowski, Alan and Lennig, Thomas and Hollis, Victoria and Whittaker, Steve},
title = {Echoes from the Past: How Technology Mediated Reflection Improves Well-Being},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466137},
doi = {10.1145/2470654.2466137},
abstract = {As people document more of their lives online, some recent systems are encouraging
people to later revisit those recordings, a practice we're calling technology-mediated
reflection (TMR). Since we know that unmediated reflection benefits psychological
well-being, we explored whether and how TMR affects well-being. We built Echo, a smartphone
application for recording everyday experiences and reflecting on them later. We conducted
three system deployments with 44 users who generated over 12,000 recordings and reflections.
We found that TMR improves well-being as assessed by four psychological metrics. By
analyzing the content of these entries we discovered two mechanisms that explain this
improvement. We also report benefits of very long-term TMR.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1071–1080},
numpages = {10},
keywords = {recording, technology mediated reflection, well-being, memory, reflection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466138,
author = {Rice, Mark and Tan, Wah Pheow and Ong, Jeremy and Yau, Lih Jie and Wan, Marcus and Ng, Jamie},
title = {The Dynamics of Younger and Older Adult's Paired Behavior When Playing an Interactive Silhouette Game},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466138},
doi = {10.1145/2470654.2466138},
abstract = {In this paper, we report on the findings of an acute trial in which we evaluate the
design of a novel gesture-based game. 60 younger and older players, divided into three
separate group-types: (i) Young-Young, (ii) Old-Old, and (iii) Young-Old, took part
in the study. The primary aim of this work was to evaluate the communicative and cooperative
behavior of same-age and mixed-age pairs, with secondary interests in their perceived
ease-of-use of the game. A mixed-method approach was used, comprising of direct observations,
a post-game questionnaire and paired interviews. Our results identified noticeable
differences between the group-types, with the Young-Old showing more physical cooperation,
as compared to the same-age groups. The work elaborates on how the young and old differ
in expectations and perceived interaction, and concludes with some recommendations
for future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1081–1090},
numpages = {10},
keywords = {intergenerational relations, cooperation, silhouette interaction, older adults, digital games},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466139,
author = {Warnock, David and McGee-Lennon, Marilyn and Brewster, Stephen},
title = {Multiple Notification Modalities and Older Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466139},
doi = {10.1145/2470654.2466139},
abstract = {Multimodal interaction can make home care reminder systems more accessible to their
users, most of whom are older and/or have sensory impairments. Existing research into
the properties of different notification modalities have used younger participants
rather than members of the older population at which they are aimed. This paper presents
the results of a user study with older adults that examined how different notification
modalities affected (a) performance in a card matching game and (b) how effective
the different modalities were at delivering information. Participants were all aged
over 50 and notifications were delivered using textual, pictographic, abstract visual,
speech, Earcon, Auditory Icon, tactile and olfactory modalities while playing the
game. The results showed that older users were influenced by the same factors as younger
users, yet there were subjective differences. The implications for the design of multimodal
reminder systems for home care are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1091–1094},
numpages = {4},
keywords = {notifications, multimodal, older users, reminders},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466140,
author = {Bentley, Frank and Tollmar, Konrad},
title = {The Power of Mobile Notifications to Increase Wellbeing Logging Behavior},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466140},
doi = {10.1145/2470654.2466140},
abstract = {Self-logging is a critical component to many wellbeing systems. However, self-logging
often is difficult to sustain at regular intervals over many weeks. We demonstrate
the power of passive mobile notifications to increase logging of wellbeing data, particularly
food intake, in a mobile health service. Adding notifications increased the frequency
of logging from 12% in a one-month, ten-user pilot study without reminders to 63%
in the full 60-user study with reminders included. We will discuss the benefits of
passive notifications over existing interruptive methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1095–1098},
numpages = {4},
keywords = {mobile, wellbeing, logging, behavior change, notifications, personal informatics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250070,
author = {Li, Yang},
title = {Session Details: Papers: Gesture Studies},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250070},
doi = {10.1145/3250070},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466142,
author = {Nacenta, Miguel A. and Kamber, Yemliha and Qiang, Yizhou and Kristensson, Per Ola},
title = {Memorability of Pre-Designed and User-Defined Gesture Sets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466142},
doi = {10.1145/2470654.2466142},
abstract = {We studied the memorability of free-form gesture sets for invoking actions. We compared
three types of gesture sets: user-defined gesture sets, gesture sets designed by the
authors, and random gesture sets in three studies with 33 participants in total. We
found that user-defined gestures are easier to remember, both immediately after creation
and on the next day (up to a 24% difference in recall rate compared to pre-designed
gestures). We also discovered that the differences between gesture sets are mostly
due to association errors (rather than gesture form errors), that participants prefer
user-defined sets, and that they think user-defined gestures take less time to learn.
Finally, we contribute a qualitative analysis of the tradeoffs involved in gesture
type selection and share our data and a video corpus of 66 gestures for replicability
and further analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1099–1108},
numpages = {10},
keywords = {gesture sets, user-defined gestures, gesture memorability},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466143,
author = {Anderson, Fraser and Bischof, Walter F.},
title = {Learning and Performance with Gesture Guides},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466143},
doi = {10.1145/2470654.2466143},
abstract = {Gesture-based interfaces are becoming more prevalent and complex, requiring non-trivial
learning of gesture sets. Many methods for learning gestures have been proposed, but
they are often evaluated with short-term recall tests that measure user performance,
rather than learning. We evaluated four types of gesture guides using a retention
and transfer paradigm common in motor learning experiments and found results different
from those typically reported with recall tests. The results indicate that many guide
systems with higher levels of guidance exhibit high performance benefits while the
guide is being used, but are ultimately detrimental to user learning. We propose an
adaptive guide that does not suffer from these drawbacks, and that enables a smooth
transition from novice to expert. The results contrasting learning and performance
can be explained by the guidance hypothesis. They have important implications for
the design and evaluation of future gesture learning systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1109–1118},
numpages = {10},
keywords = {learning, gestures, evaluation, guides},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466144,
author = {Annett, Michelle and Bischof, Walter F.},
title = {Your Left Hand Can Do It Too! Investigating Intermanual, Symmetric Gesture Transfer on Touchscreens},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466144},
doi = {10.1145/2470654.2466144},
abstract = {This work examines intermanual gesture transfer, i.e., learning a gesture with one
hand and performing it with the other. Using a traditional retention and transfer
paradigm from the motor learning literature, participants learned four gestures on
a touchscreen. The study found that touchscreen gestures transfer, and do so symmetrically.
Regardless of the hand used during training, gestures were performed with a comparable
level of error and speed by the untrained hand, even after 24 hours. In addition,
the form of a gesture, i.e., its length or curvature, was found to have no influence
on transferability. These results have important implications for the design of stroke-based
gestural interfaces: acquisition could occur with either hand and it is possible to
interchange the hand used to perform gestures. The work concludes with a discussion
of these implications and highlights how they can be applied to gesture learning and
current gestural systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1119–1128},
numpages = {10},
keywords = {motor learning, skill acquisition, gesture transfer, touchscreen, symmetric transfer, gestures, intermanual transfer},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466145,
author = {Oh, Uran and Findlater, Leah},
title = {The Challenges and Potential of End-User Gesture Customization},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466145},
doi = {10.1145/2470654.2466145},
abstract = {The vast majority of work on understanding and supporting the gesture creation process
has focused on professional designers. In contrast, gesture customization by end users'
- which may offer better memorability, efficiency and accessibility than pre-defined
gestures - has received little attention. To understand the end-user gesture creation
process, we conducted a study where 20 participants were asked to: (1) exhaustively
create new gestures for an open-ended use case; (2) exhaustively create new gestures
for 12 specific use cases; (3) judge the saliency of different touchscreen gesture
features. Our findings showed that even when asked to create novel gestures, participants
tended to focus on the familiar. Misconceptions about the gesture recognizer's abilities
were also evident, and in some cases constrained the range of gestures that participants
created. Finally, as a calibration point for future research, we used a simple gesture
recognizer ($N) to analyze recognition accuracy of the participants' custom gesture
sets: accuracy was 68-88% on average, depending on the amount of training and the
customization scenario. We conclude with implications for the design of a mixed-initiative
approach to support custom gesture creation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1129–1138},
numpages = {10},
keywords = {customization, personalization, touchscreen, gestures},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250071,
author = {Feiner, Steven},
title = {Session Details: Papers: Manipulating Video},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250071},
doi = {10.1145/3250071},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466147,
author = {Monserrat, Toni-Jan Keith Palma and Zhao, Shengdong and McGee, Kevin and Pandey, Anshul Vikram},
title = {NoteVideo: Facilitating Navigation of Blackboard-Style Lecture Videos},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466147},
doi = {10.1145/2470654.2466147},
abstract = {Khan Academy's pre-recorded blackboard-style lecture videos attract millions of online
users every month. However, current video navigation tools do not adequately support
the kinds of goals that students typically have, like quickly finding a particular
concept in a blackboard-style lecture video. This paper reports on the development
and evaluation of the new NoteVideo and its improved version, NoteVideo+, systems
for identifying the conceptual 'objects' of a blackboard-based video - and then creating
a summarized image of the video and using it as an in-scene navigation interface that
allows users to directly jump to the video frame where that object first appeared
instead of navigating it linearly through time. The research consisted of iteratively
implementing the system and then having users perform four different navigation tasks
using three different interfaces: Scrubbing, Transcript, and NoteVideo. Results of
the study show that participants perform significantly better on all four tasks while
using the NoteVideo and its improved version - NoteVideo+ - as compared to others.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1139–1148},
numpages = {10},
keywords = {video summary, video, notevideo+, video navigation, online streaming, blackboard-style videos, notevideo},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466148,
author = {Santosa, Stephanie and Chevalier, Fanny and Balakrishnan, Ravin and Singh, Karan},
title = {Direct Space-Time Trajectory Control for Visual Media Editing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466148},
doi = {10.1145/2470654.2466148},
abstract = {We explore the design space for using object motion trajectories to create and edit
visual elements in various media across space and time. We introduce a suite of pen-based
techniques that facilitate fluid stylization, annotation and editing of space-time
content such as video, slide presentations and 2D animation, utilizing pressure and
multi-touch input. We implemented and evaluated these techniques in DirectPaint, a
system for creating free-hand painting and annotation over video.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1149–1158},
numpages = {10},
keywords = {sketching, pen-based interface, optical flow, pressure, video navigation, bimodal},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466149,
author = {Matejka, Justin and Grossman, Tovi and Fitzmaurice, George},
title = {Swifter: Improved Online Video Scrubbing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466149},
doi = {10.1145/2470654.2466149},
abstract = {Online streaming video systems have become extremely popular, yet navigating to target
scenes of interest can be a challenge. While recent techniques have been introduced
to enable real-time seeking, they break down for large videos, where scrubbing the
timeline causes video frames to skip and flash too quickly to be comprehendible. We
present Swifter, a new video scrubbing technique that displays a grid of pre-cached
thumbnails during scrubbing actions. In a series of studies, we first investigate
possible design variations of the Swifter technique, and the impact of those variations
on its performance. Guided by these results we compare an implementation of Swifter
to the previously published Swift technique, in addition to the approaches utilized
by YouTube and Netfilx. Our results show that Swifter significantly outperforms each
of these techniques in a scene locating task, by a factor of up to 48%.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1159–1168},
numpages = {10},
keywords = {online streaming, video navigation, video},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466150,
author = {Nguyen, Cuong and Niu, Yuzhen and Liu, Feng},
title = {Direct Manipulation Video Navigation in 3D},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466150},
doi = {10.1145/2470654.2466150},
abstract = {Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video
by dragging an object along its motion trajectory. These systems have been shown effective
for space-centric video browsing. Their performance, however, is often limited by
temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting
motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion
(x, y, t) to the 2D spatial motion (x, y) in visualizing the motion and dragging the
object. In this paper, we present a 3D DMVN system that maps the spatial-temporal
motion (x, y, t) to 3D space (x, y, z) by mapping time t to depth z, visualizes the
motion and video frame in 3D, and allows to navigate the video by spatial-temporally
manipulating the object in 3D. We show that since our 3D DMVN system preserves all
the motion information, it resolves the temporal ambiguities and supports intuitive
navigation on challenging videos with complex motion.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1169–1172},
numpages = {4},
keywords = {video navigation, direct manipulation, 3d visualization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250072,
author = {Zimmerman, John},
title = {Session Details: Papers: Sustainable Energy},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250072},
doi = {10.1145/3250072},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466152,
author = {Rodden, Tom A. and Fischer, Joel E. and Pantidi, Nadia and Bachour, Khaled and Moran, Stuart},
title = {At Home with Agents: Exploring Attitudes towards Future Smart Energy Infrastructures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466152},
doi = {10.1145/2470654.2466152},
abstract = {Energy systems researchers are proposing a broad range of future "smart" energy infrastructures
to promote more efficient management of energy resources. This paper considers how
consumers might relate to these future smart grids within the UK. To address this
challenge we exploited a combination of demonstration and animated sketches to convey
the nature of a future smart energy infrastructure based on software agents. Users'
reactions suggested that although they felt an obligation to engage with energy issues,
they were principally disinterested. Users showed a considerable lack of trust in
energy companies raising a dilemma of design. While users might welcome agents to
help in engaging with complex energy infrastructures, they had little faith in those
that might provide them. This suggests the need to consider how to design software
agents to enhance trust in these socio-economic settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1173–1182},
numpages = {10},
keywords = {envisioning, whiteboard animations, smart grid, sketching, participatory design, agent-based systems, focus groups},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466152_R49198,
author = {De, Debraj},
title = {Review ID:R49198 for DOI: 10.1145/2470654.2466152},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466152_R49198}
}

@inproceedings{10.1145/2470654.2466153,
author = {Neustaedter, Carman and Bartram, Lyn and Mah, Aaron},
title = {Everyday Activities and Energy Consumption: How Families Understand the Relationship},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466153},
doi = {10.1145/2470654.2466153},
abstract = {Energy consumption is a growing concern and it is important to inform families of
their consumption and how they might reduce it. We conducted an interview study that
focuses on the existing routines of families and how they currently understand their
power and gas consumption based on standard utility bills. We also investigated how
this understanding ties to their everyday activities as might be recorded on their
calendars. This allowed us to assess calendars as an artifact for energy consumption
awareness. Our results show that many people relate changes in energy consumption
to high-level effects such as weather and temperature and not necessarily their own
everyday activities. Events on calendars may aid this understanding but people do
not currently record enough information on their calendars to make a strong tie. This
suggests that if calendars are to be used as artifacts to aid energy consumption understanding,
digital calendars need to provide support to include more energy-related information,
including both activities and patterns of consumption.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1183–1192},
numpages = {10},
keywords = {families, energy consumption, calendars},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466154,
author = {Schwartz, Tobias and Denef, Sebastian and Stevens, Gunnar and Ramirez, Leonardo and Wulf, Volker},
title = {Cultivating Energy Literacy: Results from a Longitudinal Living Lab Study of a Home Energy Management System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466154},
doi = {10.1145/2470654.2466154},
abstract = {This paper presents results of a three-year research project focused on the emplacement
of Home Energy Management Systems (HEMS) in a living lab setting with seven households.
The HEMS used in this study allowed householders to monitor energy consumption both
in real-time and in retrospective on the TV and on mobile devices. Contrasting with
existing research focused on how technology persuades people to consume less energy,
our study uses a grounded approach to analyze HEMS emplacement. As an important result,
we present here the issue of 'energy literacy'. Our study reveals that, by using HEMS,
participants became increasingly literate in understanding domestic electricity consumption.
We discuss the role HEMS played in that process and how the acquired literacy changed
energy consumption patterns. We conclude that literacy in energy consumption has value
on its own and explain how eco feedback system designs can benefit from this understanding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1193–1202},
numpages = {10},
keywords = {energy literacy, energy monitoring, hems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466155,
author = {Erickson, Thomas and Li, Ming and Kim, Younghun and Deshpande, Ajay and Sahu, Sambit and Chao, Tian and Sukaviriya, Piyawadee and Naphade, Milind},
title = {The Dubuque Electricity Portal: Evaluation of a City-Scale Residential Electricity Consumption Feedback System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466155},
doi = {10.1145/2470654.2466155},
abstract = {This paper describes the Dubuque Electricity Portal, a city-scale system aimed at
supporting voluntary reductions of electricity consumption. The Portal provided each
household with fine-grained feedback on its electricity use, as well as using incentives,
comparisons, and goal setting to encourage conservation. Logs, a survey and interviews
were used to evaluate the user experience of the Portal during a 20-week pilot with
765 volunteer households. Although the volunteers had already made a wide range of
changes to conserve electricity prior to the pilot, those who used the Portal decreased
their electricity use by about 3.7%. They also reported increased understanding of
their usage, and reported taking an array of actions - both changing their behavior
and their electricity infrastructure. The paper discusses the experience of the system's
users, and describes challenges for the design of ECF systems, including balancing
accessibility and security, a preference for time-based visualizations, and the advisability
of multiple modes of feedback, incentives and information presentation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1203–1212},
numpages = {10},
keywords = {sustainability, social comparison, smart meters, electricity, consumption feedback systems, ecf, behavior change},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466155_R49760,
author = {Orvalho, Joao},
title = {Review ID:R49760 for DOI: 10.1145/2470654.2466155},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466155_R49760}
}

@inproceedings{10.1145/3250073,
author = {Moffatt, Karyn},
title = {Session Details: Papers: Impairment and Rehabilitation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250073},
doi = {10.1145/3250073},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466157,
author = {Salivia, Guarionex and Hourcade, Juan Pablo},
title = {PointAssist: Assisting Individuals with Motor Impairments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466157},
doi = {10.1145/2470654.2466157},
abstract = {We tested PointAssist, software that assists in pointing tasks by detecting difficulty
through a sub-movement analysis and triggering help, with adjustments proposed to
personalize the assistance provided to individuals with motor impairments. A within-subjects
study with sixteen individuals with fine motor skills impairments resulted in statistically
significant effects on accuracy using Friedman's test with (Χ2(1)=6.4, p=.011 in favor
of personalized PointAssist compared to no assistance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1213–1222},
numpages = {10},
keywords = {sub-movements, motor impairments, pointing tasks, human-computer interaction, older adults},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466158,
author = {Anthony, Lisa and Kim, YooJin and Findlater, Leah},
title = {Analyzing User-Generated Youtube Videos to Understand Touchscreen Use by People with Motor Impairments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466158},
doi = {10.1145/2470654.2466158},
abstract = {Most work on the usability of touchscreen interaction for people with motor impairments
has focused on lab studies with relatively few participants and small cross-sections
of the population. To develop a richer characterization of use, we turned to a previously
untapped source of data: YouTube videos. We collected and analyzed 187 non-commercial
videos uploaded to YouTube that depicted a person with a physical disability interacting
with a mainstream mobile touchscreen device. We coded the videos along a range of
dimensions to characterize the interaction, the challenges encountered, and the adaptations
being adopted in daily use. To complement the video data, we also invited the video
uploaders to complete a survey on their ongoing use of touchscreen technology. Our
findings show that, while many people with motor impairments find these devices empowering,
accessibility issues still exist. In addition to providing implications for more accessible
touchscreen design, we reflect on the application of user-generated content to study
user interface design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1223–1232},
numpages = {10},
keywords = {touchscreen, assistive technology, iphone, ipad, physical disabilities, youtube, motor impairments},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466158_R49366,
author = {Mani, Ganapathy},
title = {Review ID:R49366 for DOI: 10.1145/2470654.2466158},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466158_R49366}
}

@inproceedings{10.1145/2470654.2466159,
author = {Uzor, Stephen and Baillie, Lynne},
title = {Exploring &amp; Designing Tools to Enhance Falls Rehabilitation in the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466159},
doi = {10.1145/2470654.2466159},
abstract = {Falls are the leading cause of accidental injury-related deaths in the elderly; a
fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes
involving exercise have proved the most successful way to reduce the risk of falls.
However, the limitations of standard care (e.g. booklets) could prevent home users
from receiving the full therapeutic benefit that rehabilitation offers. Having consulted
users and health experts, we developed games, and visualizations for falls rehabilitation
that we believe could potentially overcome the main barriers to effective rehabilitation
in the home. In this paper, we describe user studies that we carried out with older
adults to evaluate the use of these visual tools versus standard care, both in the
laboratory and in the home. Our main findings show that our visualizations and games
were able to overcome the major limitations of standard care, and that they were usable
and acceptable to the end users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1233–1242},
numpages = {10},
keywords = {games, rehabilitation, usability, user-centered, falls, visualization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466160,
author = {Boulanger, Cati and Boulanger, Adam and de Greef, Lilian and Kearney, Andy and Sobel, Kiley and Transue, Russell and Sweedyk, Z and Dietz, Paul H. and Bathiche, Steven},
title = {Stroke Rehabilitation with a Sensing Surface},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466160},
doi = {10.1145/2470654.2466160},
abstract = {This paper presents a new sensing and interaction environment for post-stroke and
upper extremity limb rehabilitation. The device is a combination of camera-based multitouch
sensing and a supporting therapeutic software application that advances the treatment,
provides feedback, and records a user's progress. The image-based analysis of hand
position provided by a Microsoft Surface is used as an input into a tabletop game
environment. Tailored image analysis algorithms assess rehabilitative hand movements.
Visual feedback is provided in a game context. Experiments were conducted in a sub-acute
rehabilitation center. Preliminary user studies with a stroke-afflicted population
determined essential design criteria. Hand and wrist sensing, as well as the goals
of the supporting game environment, engage therapeutic flexion and extension as defined
by consulted physicians. Participants valued personalization of the activity, novelty,
reward and the ability to work at their own pace in an otherwise repetitive therapeutic
task. A "character" - game element personifying the participant's movement - was uniquely
motivating relative to the media available in the typical therapeutic routine.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1243–1246},
numpages = {4},
keywords = {hci, rehabilitation, gesture recognition, tabletop, stroke},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466161,
author = {Ananthanarayan, Swamy and Sheh, Miranda and Chien, Alice and Profita, Halley and Siek, Katie},
title = {Pt Viz: Towards a Wearable Device for Visualizing Knee Rehabilitation Exercises},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466161},
doi = {10.1145/2470654.2466161},
abstract = {We present a wearable sensory display for visualizing knee rehabilitation as part
of an in-home physical therapy program. Currently, patients undergoing knee rehabilitation
have limited ways of assessing exercise form and extent of movement at home. To address
this issue, we developed an exploratory wearable electronic prototype to visualize
knee bend. We evaluated the device with physical therapy patients to get feedback
on the design and to help us understand some of the challenges they face. We discovered
that our current design is better suited for patients recovering from surgery as opposed
to patients with chronic conditions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1247–1250},
numpages = {4},
keywords = {knee rehabilitation, user interface device, wearable display},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250074,
author = {Poole, Erika},
title = {Session Details: Papers: Exergames and Beyond},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250074},
doi = {10.1145/3250074},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466163,
author = {Macvean, Andrew and Robertson, Judy},
title = {Understanding Exergame Users' Physical Activity, Motivation and Behavior over Time},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466163},
doi = {10.1145/2470654.2466163},
abstract = {Effective exergames should increase the proportion of time users regularly spend in
moderate to vigorous physical activity. There are currently few studies of exergame
systems which evaluate the impact on physical activity over time. Those which do,
show increases in light intensity exercise which although valuable, do not increase
the proportion of moderate to vigorous activity required for optimal health benefits.
Furthermore, longitudinal studies to date have encountered a plateau effect in physical
activity as the novelty of the game wears off. This paper suggests how exergame designs
based on deeper understandings of player motivations could address these problems.We
report on longitudinal patterns of users' physical activity, motivations and behaviour
when using exergames, based on case studies from a seven week long school based field
trial. These new insights, interpreted through Bandura's theory of self efficacy,
are of value to designers in the HCI community who wish to motivate users with a range
of attitudes towards exercise to undertake regular moderate to vigorous physical activity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1251–1260},
numpages = {10},
keywords = {motivation, behavior change, exergames, self-efficacy, classroom intervention},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466164,
author = {Hernandez, Hamilton A. and Ye, Zi and Graham, T.C. Nicholas and Fehlings, Darcy and Switzer, Lauren},
title = {Designing Action-Based Exergames for Children with Cerebral Palsy},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466164},
doi = {10.1145/2470654.2466164},
abstract = {Children with cerebral palsy (CP) want to play fast-paced action-oriented videogames
similar to those played by their peers without motor disabilities. This is particularly
true of exergames, whose physically-active gameplay matches the fast pace of action
games. But disabilities resulting from CP can make it difficult to play action games.
Guidelines for developing games for people with motor disabilities steer away from
high-paced action, including recommendations to avoid the need for time-sensitive
actions and to keep game pace slow. Through a year-long participatory design process
with children with CP, we have discovered that it is in fact possible to develop action-oriented
exergames for children with CP at level III on the Gross Motor Function Classification
Scale. We followed up the design process with an eight-week home trial, in which we
found the games to be playable and enjoyable. In this paper, we discuss the design
of these games, and present a set of design recommendations for how to achieve both
action-orientation and playability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1261–1270},
numpages = {10},
keywords = {video game design, children with cerebral palsy., exergame},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466165,
author = {Pijnappel, Sebastiaan and Mueller, Florian},
title = {4 Design Themes for Skateboarding},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466165},
doi = {10.1145/2470654.2466165},
abstract = {Interactive technology can support exertion activities, with many examples focusing
on improving athletic performance. We see an opportunity for technology to also support
extreme sports such as skateboarding, which often focus primarily on the experience
of doing tricks rather than on athletic performance. However, there is little knowledge
on how to design for such experiences. In response, we designed 12 basic skateboarding
prototypes inspired by skateboarding theory. Using an autoethnographical approach,
we skated with each of these and reflected on our experiences in order to derive four
design themes : location of feedback in relation to the skater's body, timing of feedback
in relation to peaks in emotions after attempts, aspects of the trick emphasized by
feedback, and aesthetic fittingness of feedback. We hope our work will guide designers
of interactive systems for skateboarding, and extreme sports in general, and will
therefore further our understanding of how to design for the active human body.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1271–1274},
numpages = {4},
keywords = {skateboarding, extreme sports, experience of attempting tricks, autoethnography, exertion},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466166,
author = {Vongsathorn, Linden and O'Hara, Kenton and Mentis, Helena M.},
title = {Bodily Interaction in the Dark},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466166},
doi = {10.1145/2470654.2466166},
abstract = {In light of the growing interest in designing for new body-movement based interfaces
through somaesthetics and somatic awareness, we created a sound-based interaction
using the Microsoft Kinect device, which is performed in the dark. The absence of
visual feedback led participants to deeply focus on the movement of their bodies,
and to have a different awareness of their bodies and the space around them. The notable
difference between performing this interaction in light and dark suggests that non-visual
based interfaces are a fruitful area to explore in somaesthetic interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1275–1278},
numpages = {4},
keywords = {somaesthetics, movement, awareness, vision, dark, body},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250075,
author = {MacLean, Karon},
title = {Session Details: Papers: Full-Body Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250075},
doi = {10.1145/3250075},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466168,
author = {Jung, Jinyung and Bae, Seok-Hyung and Lee, Joon Hyub and Kim, Myung-Suk},
title = {Make It Move: A Movement Design Method of Simple Standing Products Based on Systematic Mapping of Torso Movements &amp; Product Messages},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466168},
doi = {10.1145/2470654.2466168},
abstract = {Human communication significantly relies on the expressivity of their body movements.
Based on these body language experiences, humans tend to extract meanings even from
movements of objects. This paper begins with the above human tendencies to create
a design method that can help product designers make their products move to communicate.
As a research vehicle, we created a robotic torso prototype and utilized it to collaborate
with movement experts, and listed up possible expressive movement components. We then
built a mapping matrix that links these movements to general product messages. A method
which utilizes this mapping matrix was developed to help designers determine a set
of effective movements that can communicate specific product messages. Lastly, a design
workshop was conducted to identify the usefulness of the proposed method. We expect
the procedures and findings of this study to help researchers and designers approach
affective user experience through product movement design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1279–1288},
numpages = {10},
keywords = {product movement, design method},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466169,
author = {Oulasvirta, Antti and Roos, Teemu and Modig, Arttu and Lepp\"{a}nen, Laura},
title = {Information Capacity of Full-Body Movements},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466169},
doi = {10.1145/2470654.2466169},
abstract = {We present a novel metric for information capacity of full-body movements. It accommodates
HCI scenarios involving continuous movement of multiple limbs. Throughput is calculated
as mutual information in repeated motor sequences. It is affected by the complexity
of movements and the precision with which an actor reproduces them. Computation requires
decorrelating co-dependencies of movement features (e.g., wrist and elbow) and temporal
alignment of sequences. HCI researchers can use the metric as an analysis tool when
designing and studying user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1289–1298},
numpages = {10},
keywords = {throughput, measurement, information theory, information capacity, gesture-based interfaces, full-body movement},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466170,
author = {Wagner, Julie and Nancel, Mathieu and Gustafson, Sean G. and Huot, Stephane and Mackay, Wendy E.},
title = {Body-Centric Design Space for Multi-Surface Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466170},
doi = {10.1145/2470654.2466170},
abstract = {We introduce BodyScape, a body-centric design space that allows us to describe, classify
and systematically compare multi-surface interaction techniques, both individually
and in combination. BodyScape reflects the relationship between users and their environment,
specifically how different body parts enhance or restrict movement within particular
interaction techniques and can be used to analyze existing techniques or suggest new
ones. We illustrate the use of BodyScape by comparing two free-hand techniques, on-body
touch and mid-air pointing, first separately, then combined. We found that touching
the torso is faster than touching the lower legs, since it affects the user's balance;
and touching targets on the dominant arm is slower than targets on the torso because
the user must compensate for the applied force.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1299–1308},
numpages = {10},
keywords = {body-centric design space, multi-surface interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466171,
author = {Velloso, Eduardo and Bulling, Andreas and Gellersen, Hans},
title = {MotionMA: Motion Modelling and Analysis by Demonstration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466171},
doi = {10.1145/2470654.2466171},
abstract = {Particularly in sports or physical rehabilitation, users have to perform body movements
in a specific manner for the exercises to be most effective. It remains a challenge
for experts to specify how to perform such movements so that an automated system can
analyse further performances of it. In a user study with 10 participants we show that
experts' explicit estimates do not correspond to their performances. To address this
issue we present MotionMA, a system that: (1) automatically extracts a model of movements
demonstrated by one user, e.g. a trainer, (2) assesses the performance of other users
repeating this movement in real time, and (3) provides real-time feedback on how to
improve their performance. We evaluated the system in a second study in which 10 other
participants used the system to demonstrate arbitrary movements. Our results demonstrate
that MotionMA is able to extract an accurate movement model to spot mistakes and variations
in movement execution.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1309–1318},
numpages = {10},
keywords = {activity assessment, motion modelling, weight lifting, learning by demonstration, real-time user feedback},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250076,
author = {Harrison, Steve},
title = {Session Details: Papers: Video Communication},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250076},
doi = {10.1145/3250076},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466173,
author = {Pece, Fabrizio and Steptoe, William and Wanner, Fabian and Julier, Simon and Weyrich, Tim and Kautz, Jan and Steed, Anthony},
title = {Panoinserts: Mobile Spatial Teleconferencing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466173},
doi = {10.1145/2470654.2466173},
abstract = {We present PanoInserts: a novel teleconferencing system that uses smartphone cameras
to create a surround representation of meeting places. We take a static panoramic
image of a location into which we insert live videos from smartphones. We use a combination
of marker- and image-based tracking to position the video inserts within the panorama,
and transmit this representation to a remote viewer. We conduct a user study comparing
our system with fully-panoramic video and conventional webcam video conferencing for
two spatial reasoning tasks. Results indicate that our system performs comparably
with fully-panoramic video, and better than webcam video conferencing in tasks that
require an accurate surrounding representation of the remote space. We discuss the
representational properties and usability of varying video presentations, exploring
how they are perceived and how they influence users when performing spatial reasoning
tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1319–1328},
numpages = {10},
keywords = {remote collaboration, teleconferencing, camera tracking, mobile phones, mixed reality, telepresence, panoramas},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466174,
author = {Norris, James and Schn\"{a}delbach, Holger M. and Luff, Paul K.},
title = {Putting Things in Focus: Establishing Co-Orientation through Video in Context},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466174},
doi = {10.1145/2470654.2466174},
abstract = {In collaborative video communication systems, establishing co-orientation around physical
objects, virtual objects and people is a critical requirement. This is problematic
as the technical limitations of video fractures the display of conduct in the connected
environments. We present the results of a study of one collaborative system, CamBlend,
which aims to alleviate some of these problems by using screen based pointing tools
to both physical spaces and virtual resources. We report on how participants achieved
co-orientation when using this system. We relate these findings to previous research
into the fractured ecologies of collaborative spaces, describing how the form and
nature of fractures in CamBlend differ from earlier reported work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1329–1338},
numpages = {10},
keywords = {collaboration, interaction analysis, focus+context, cscw},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466175,
author = {Tang, John C. and Xiao, Robert and Hoff, Aaron and Venolia, Gina and Therien, Patrick and Roseway, Asta},
title = {HomeProxy: Exploring a Physical Proxy for Video Communication in the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466175},
doi = {10.1145/2470654.2466175},
abstract = {HomeProxy is a research prototype that explores supporting video communication in
the home among distributed family members through a physical proxy. It leverages a
physical artifact dedicated to representing remote family members to make it easier
to share activities with them. HomeProxy combines a form factor designed for the home
environment with a "no-touch" user experience and an interface that responsively transitions
between recorded and live video messages. We designed and implemented a prototype
and conducted a pilot study with eight pairs of users. Our study demonstrated the
challenges of a no-touch interface and the promise of offering quick video messaging
in the home.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1339–1342},
numpages = {4},
keywords = {asynchronous video, video chat, physical proxies, home},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250077,
author = {Hurst, Amy},
title = {Session Details: Papers: Ideation Methods},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250077},
doi = {10.1145/3250077},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466177,
author = {Faste, Haakon and Rachmel, Nir and Essary, Russell and Sheehan, Evan},
title = {Brainstorm, Chainstorm, Cheatstorm, Tweetstorm: New Ideation Strategies for Distributed HCI Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466177},
doi = {10.1145/2470654.2466177},
abstract = {In this paper we describe the results of a design-driven study of collaborative ideation.
Based on preliminary findings that identified a novel digital ideation paradigm we
refer to as chainstorming, or online communication brainstorming, two exploratory
studies were performed. First, we developed and tested a distributed method of ideation
we call cheatstorming, in which previously generated brainstorm ideas are delivered
to targeted local contexts in response to a prompt. We then performed a more rigorous
case study to examine the cheatstorming method and consider its possible implementation
in the context of a distributed online ideation tool. Based on observations from these
studies, we conclude with the somewhat provocative suggestion that ideation need not
require the generation of new ideas. Rather, we present a model of ideation suggesting
that its value has less to do with the generation of novel ideas than the cultural
influence exerted by unconventional ideas on the ideating team. Thus brainstorming
is more than the pooling of "invented" ideas, it involves the sharing and interpretation
of concepts in unintended and (ideally) unanticipated ways.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1343–1352},
numpages = {10},
keywords = {brainstorming, cheatstorming, tweetstormer, chainstorming, ideation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466178,
author = {Juhlin, Oskar and Zhang, Yanqing and Sundbom, Cristine and Fernaeus, Ylva},
title = {Fashionable Shape Switching: Explorations in Outfit-Centric Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466178},
doi = {10.1145/2470654.2466178},
abstract = {We present a design exercise illustrating how fashion practices and the fashion design
process can be used to create new opportunities both in the mobile domain and in product
design, as well as in wearable computing. We investigate the concept of outfit-centric
design by extending the support for social and visual interaction with digital devices
beyond the currently available shells and stickers, and drawing on the ways in which
people vary their dress ensembles. We designed a set of mock-up samples in a local
fashion style, as a first step in understanding possible applications of the emerging
technology of organic interfaces. Initial user feedback shows how fashion-conscious
participants creatively experimented with the set's variations of shape and color
in outfits created from their personal wardrobes, which revealed the importance of
the objects' size and location on the body. It also points out that a lack of integration
with the fashion system's processes reduces the attractiveness of the samples.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1353–1362},
numpages = {10},
keywords = {outfit, fashion, dressing, mobile interaction, organic interface, wearable computing, product design, design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250078,
author = {Moscovich, Tomer},
title = {Session Details: Papers: Pointing and Fitts Law},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250078},
doi = {10.1145/3250078},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466180,
author = {Bi, Xiaojun and Li, Yang and Zhai, Shumin},
title = {FFitts Law: Modeling Finger Touch with Fitts' Law},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466180},
doi = {10.1145/2470654.2466180},
abstract = {Fitts' law has proven to be a strong predictor of pointing performance under a wide
range of conditions. However, it has been insufficient in modeling small-target acquisition
with finger-touch based input on screens. We propose a dual-distribution hypothesis
to interpret the distribution of the endpoints in finger touch input. We hypothesize
the movement endpoint distribution as a sum of two independent normal distributions.
One distribution reflects the relative precision governed by the speed-accuracy tradeoff
rule in the human motor system, and the other captures the absolute precision of finger
touch independent of the speed-accuracy tradeoff effect. Based on this hypothesis,
we derived the FFitts model - an expansion of Fitts' law for finger touch input. We
present three experiments in 1D target acquisition, 2D target acquisition and touchscreen
keyboard typing tasks respectively. The results showed that FFitts law is more accurate
than Fitts' law in modeling finger input on touchscreens. At 0.91 or a greater R2
value, FFitts' index of difficulty is able to account for significantly more variance
than conventional Fitts' index of difficulty based on either a nominal target width
or an effective target width in all the three experiments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1363–1372},
numpages = {10},
keywords = {fitts' law, touchscreen, finger input},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466181,
author = {Banovic, Nikola and Grossman, Tovi and Fitzmaurice, George},
title = {The Effect of Time-Based Cost of Error in Target-Directed Pointing Tasks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466181},
doi = {10.1145/2470654.2466181},
abstract = {One of the fundamental operations in today's user interfaces is pointing to targets,
such as menus, buttons, and text. Making an error when selecting those targets in
real-life user interfaces often results in some cost to the user. However, the existing
target-directed pointing models do not consider the cost of error when predicting
task completion time. In this paper, we present a model based on expected value theory
that predicts the impact of the error cost on the user's completion time for target-directed
pointing tasks. We then present a target-directed pointing user study, which results
show that time-based costs of error significantly impact the user's performance. Our
results also show that users perform according to an expected completion time utility
function and that optimal performance computed using our model gives good prediction
of the observed task completion times.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1373–1382},
numpages = {10},
keywords = {fitts' law, movement time, pointing errors, pointing time, speed-accuracy tradeoff, error cost},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466182,
author = {Aceituno, Jonathan and Casiez, G\'{e}ry and Roussel, Nicolas},
title = {How Low Can You Go? Human Limits in Small Unidirectional Mouse Movements},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466182},
doi = {10.1145/2470654.2466182},
abstract = {Computer mouse sensors keep increasing in resolution. The smallest displacement they
can detect gets smaller, but little is known on our ability to control such small
movements. Small target acquisition has been previously tackled, but the findings
do not apply to the problem of finding the useful resolution of a user with a mouse,
which corresponds to the smallest displacement (s)he can reliably produce with that
device. We detail this definition and provide an associated experimental protocol
to measure it. We then report on the results of a study suggesting that high-end mice
are not likely to be used to their full potential. We further comment on the different
strategies used by participants to acheive best performance, and derive implications
for user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1383–1386},
numpages = {4},
keywords = {useful resolution, input device, resolution, mouse},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466183,
author = {Fares, Ribel and Fang, Shaomin and Komogortsev, Oleg},
title = {Can We Beat the Mouse with MAGIC?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466183},
doi = {10.1145/2470654.2466183},
abstract = {MAGIC pointing techniques combine eye tracking with manual input. Since the mouse
performs exceptionally well in a desktop setting, previous research on MAGIC pointing
either resulted in minor improvements, or the techniques were applied to alternative
devices or environments. We design Animated MAGIC, a novel, target-agnostic MAGIC
pointing technique, for the specific goal of beating the mouse in a desktop setting.
To improve the eye-tracking accuracy, we develop a dynamic local calibration method
that uses each selection as a local calibration point. We compare Animated MAGIC to
mouse-only and Conservative MAGIC, one of the two original MAGIC pointing methods,
in a Fitts' Law experiment. We conduct a user questionnaire to evaluate the usability
of the interaction methods. Results suggest that Dynamic Local Calibration improves
eye-tracking accuracy and, consequently, MAGIC pointing performance. Powered with
Dynamic Local Calibration, Animated MAGIC outperformed mouse-only by 8% in terms of
throughput. Both MAGIC pointing methods reduced the amount of hand movement by more
than half.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1387–1390},
numpages = {4},
keywords = {local, eye, law, dynamic, mouse, gaze, magic, fitts, interaction, calibration, tracking, animated, input, multimodal},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250079,
author = {Harrison, Chris},
title = {Session Details: Papers: Sensing Touch},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250079},
doi = {10.1145/3250079},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: Magnetic Tangible Bits for Portable and Occlusion-Free near-Surface Interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that
enables 3D tangible interactions in the near-surface space of portable displays. When
a thin magnetic sensor grid is attached to the back of the display, the 3D position
and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar
magnetic field tracking technique. This portable platform can therefore enrich tangible
interactions by extending the design space to the near-surface space. Since non-ferrous
materials, such as the user's hand, do not occlude the magnetic field, interaction
designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous
object to exploit the metaphors of the real-world tasks, and users can freely manipulate
the GaussBits by hands or using other non-ferrous tools without causing interference.
The presented example applications and the collected feedback from an explorative
workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391–1400},
numpages = {10},
keywords = {occlusion-free, portable, magnetism, tangible interactions, near-surface tracking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466186,
author = {Grosse-Puppendahl, Tobias and Braun, Andreas and Kamieth, Felix and Kuijper, Arjan},
title = {Swiss-Cheese Extended: An Object Recognition Method for Ubiquitous Interfaces Based on Capacitive Proximity Sensing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466186},
doi = {10.1145/2470654.2466186},
abstract = {Swiss-Cheese Extended proposes a novel real-time method for recognizing objects with
capacitive proximity sensors. Applying this technique to ubiquitous user interfaces,
it is possible to detect the 3D-position of multiple human hands in different configurations
above a surface that is equipped with a small number of sensors. The retrieved object
configurations can significantly improve a user's interaction experience or an application's
execution context, for example by detecting multi-hand zoom and rotation gestures
or recognizing a grasping hand. We emphasize the broad applicability of the proposed
method with a study of a multi-hand gesture recognition device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1401–1410},
numpages = {10},
keywords = {object recognition, object tracking, ubiquitous interfaces, capacitive proximity sensing, capacitive sensing, 3d interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466187,
author = {Hachisu, Taku and Kajimoto, Hiroyuki},
title = {HACHIStack: Dual-Layer Photo Touch Sensing for Haptic and Auditory Tapping Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466187},
doi = {10.1145/2470654.2466187},
abstract = {We present a novel photo touch sensing architecture, HACHIStack. It can measure the
approaching velocity of an object and predict its contact time with the touch screen
using two optical sensing layers above the surface. The photo sensing layers form
three unique capabilities: high-speed sampling, velocity acquisition, and contact
time prediction. This work quantitatively examines these capabilities through two
laboratory experiments, and confirms that the capabilities of HACHIStack are sufficient
for multimodal interaction, in particular, touch-based interaction with haptic enhancement.
We then present three applications with HACHIStack: 1) chromatic percussions (xylophone
and glockenspiel) with haptic feedback; 2) no-delay haptic feedback with the sensation
of tapping on various simulated materials (e.g., rubber, wood and aluminum); and 3)
a virtual piano instrument that allows players to perform weak and strong strokes
by changing the tapping velocity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1411–1420},
numpages = {10},
keywords = {approaching velocity, hachistack, multimodal interaction, touch sensor},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466188,
author = {Gu, Jiseong and Heo, Seongkook and Han, Jaehyun and Kim, Sunjun and Lee, Geehyuk},
title = {LongPad: A Touchpad Using the Entire Area below the Keyboard of a Laptop Computer},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466188},
doi = {10.1145/2470654.2466188},
abstract = {In this paper, we explore the possibility of a long touchpad that utilizes the entire
area below the keyboard of a laptop computer. An essential prerequisite for such a
touchpad is a robust palm rejection method, which we satisfy using a proximity-sensing
touchpad. We developed LongPad, a proximity-sensing optical touchpad that is as wide
as a laptop keyboard, and implemented a palm rejection algorithm that utilizes proximity
images from LongPad. In a user study conducted, we observed that LongPad rejected
palm touches almost perfectly while participants were repeating typing and pointing
tasks. We also summarize the new design space enabled by LongPad and demonstrate a
few of the interaction techniques it facilitates.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1421–1430},
numpages = {10},
keywords = {proximity-sensing, bimanual interaction, longpad, palm rejection, per-finger force sensing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250080,
author = {Roudaut, Anne},
title = {Session Details: Papers: Displays Everywhere},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250080},
doi = {10.1145/3250080},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466190,
author = {Thimbleby, Harold},
title = {Reasons to Question Seven Segment Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466190},
doi = {10.1145/2470654.2466190},
abstract = {Seven segment number displays are ubiquitous and popular. They are simple and familiar.
They seem to make economic sense, and with only seven segments they require little
wiring and electronics to support. They are cheap to buy and cheap to use; they make
seemingly effective and unproblematic products.This paper illustrates many examples
of problematic uses of seven segment displays that could have been avoided. More generally,
the paper raises design questions and some solutions to be considered when designing
numerical displays, and certainly before uncritically using seven segment displays.
Although there are markets and applications where cost may be an overriding consideration,
for safety critical and other dependable types of use (including general purpose devices
that may sometimes be used for critical tasks) more legible alternatives than standard
seven segment displays should be preferred.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1431–1440},
numpages = {10},
keywords = {seven segment display, calculators, number error, dependable interaction, number display, procurement},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466191,
author = {Leithinger, Daniel and Follmer, Sean and Olwal, Alex and Luescher, Samuel and Hogge, Akimitsu and Lee, Jinha and Ishii, Hiroshi},
title = {Sublimate: State-Changing Virtual and Physical Rendering to Augment Interaction with Shape Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466191},
doi = {10.1145/2470654.2466191},
abstract = {Recent research in 3D user interfaces pushes towards immersive graphics and actuated
shape displays. Our work explores the hybrid of these directions, and we introduce
sublimation and deposition, as metaphors for the transitions between physical and
virtual states. We discuss how digital models, handles and controls can be interacted
with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can
rapidly and fluidly switch between those representations. To explore this space, we
developed two systems that integrate actuated shape displays and augmented reality
(AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through
display provides a single user with head-tracked stereoscopic augmentation, whereas
our handheld devices enable multi-user interaction through video seethrough AR. We
describe interaction techniques and applications that explore 3D interaction for these
new modalities. We conclude by discussing the results from a user study that show
how freehand interaction with physical shape displays and co-located graphics can
outperform wand-based interaction with virtual 3D graphics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1441–1450},
numpages = {10},
keywords = {3d interaction, shape display, actuated tangibles, spatial augmented reality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466192,
author = {Perrault, Simon T. and Lecolinet, Eric and Eagan, James and Guiard, Yves},
title = {Watchit: Simple Gestures and Eyes-Free Interaction for Wristwatches and Bracelets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466192},
doi = {10.1145/2470654.2466192},
abstract = {We present WatchIt, a prototype device that extends interaction beyond the watch surface
to the wristband, and two interaction techniques for command selection and execution.
Because the small screen of wristwatch computers suffers from visual occlusion and
the fat finger problem, we investigated the use of the wristband as an available interaction
resource. Not only does WatchIt use a cheap, energy efficient and invisible technology,
but it involves simple, basic gestures that allow good performance after little training,
as suggested by the results of a pilot study. We propose a novel gesture technique
and an adaptation of an existing menu technique suitable for wristband interaction.
In a user study, we investigated their usage in eyes-free contexts, finding that they
perform well. Finally, we present techniques where the bracelet is used in addition
to the screen to provide precise continuous control over list scrolling. We also report
on a preliminary survey of traditional and digital jewelry that points to the high
frequency of watches and bracelets in both genders and gives a sense of the tasks
people feel like performing on such devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1451–1460},
numpages = {10},
keywords = {eyes-free interaction, watchstrap, watchband, continuous input, watch, watch bracelet, wearable computing, scrolling, input, digital jewelry},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466193,
author = {Su, Chao-Huai and Chan, Liwei and Weng, Chien-Ting and Liang, Rong-Hao and Cheng, Kai-Yin and Chen, Bing-Yu},
title = {NailDisplay: Bringing an Always Available Visual Display to Fingertips},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466193},
doi = {10.1145/2470654.2466193},
abstract = {This work presents a novel and always-available nail mounted display known as NailDisplay.
The proposed display augments the use of a finger by allowing for always-available
visual feedback owing to its fast accessibility and binding user controls with the
display, i.e. what you control is what you see (through the display). Potential benefits
of NailDisplay are demonstrated in three applications: from displaying to combining
it with user controls. In the first application, NailDisplay can reveal what is occluded
under a finger touch, making it a solution to operate small UI elements. In the second
application, NailDisplay is complementary to an imaginary interface, helping users
to learn an imaginary interface (e.g., on the users' arms) and allowing them to reassure
the interface when their memory of it becomes unclear. In the third application, NailDisplay
is integrated with rich finger interactions, such as swiping in the air. We also report
users' feedbacks gathered from an explorative user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1461–1464},
numpages = {4},
keywords = {transparent finger, always-available display, nail-mounted device},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466193_R49572,
author = {Goldfarb, David E.},
title = {Review ID:R49572 for DOI: 10.1145/2470654.2466193},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466193_R49572}
}

@inproceedings{10.1145/2470654.2466194,
author = {Pohl, Norman and Hodges, Steve and Helmes, John and Villar, Nicolas and Paek, Tim},
title = {An Interactive Belt-Worn Badge with a Retractable String-Based Input Mechanism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466194},
doi = {10.1145/2470654.2466194},
abstract = {In this paper we explore a new type of wearable computing device, an interactive identity
badge. An embedded LCD presents dynamic information to the wearer and interaction
is facilitated by sensing movement of the retractable string which attaches the unit
to the wearer's belt. This form-factor makes it possible to interact using a single
hand, providing lightweight and immediate access to a variety of information when
it's not convenient to pick up, unlock and interact directly with a device like a
smartphone. In this paper we present our prototype interactive badge, demonstrate
the underlying technology and describe a number of usage scenarios and interaction
techniques},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1465–1468},
numpages = {4},
keywords = {retractable string, interaction techniques, smart interactive badge, memory lcd},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250081,
author = {Zhou, Xiaomu},
title = {Session Details: Papers: Clinical Settings},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250081},
doi = {10.1145/3250081},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466196,
author = {von Zadow, Ulrich and Buron, Sandra and Harms, Tina and Behringer, Florian and Sostmann, Kai and Dachselt, Raimund},
title = {SimMed: Combining Simulation and Interactive Tabletops for Medical Education},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466196},
doi = {10.1145/2470654.2466196},
abstract = {A large body of work asserts that interactive tabletops are well suited for group
work, and numerous studies have examined these devices in educational contexts. However,
few of the described systems support simulations for collaborative learning, and none
of them explicitly address immersion. We present SimMed, a system allowing medical
students to collaboratively diagnose and treat a virtual patient using an interactive
tabletop. The hybrid user interface combines elements of virtual reality with multitouch
input. The paper delineates the development process of the system and rationale behind
a range of interface design decisions. Thereby, the role of realism in gaining procedural
knowledge is discussed - in particular, the interplay between realism, immersion and
training goals. We implemented several medical test cases and evaluated our approach
with a user study that suggests the great potential of the system. Results show a
high level of immersion, cooperation and engagement by the students.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1469–1478},
numpages = {10},
keywords = {education, interactive surfaces, learning, procedural knowledge, medicine, tabletop, multitouch, collaboration},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466197,
author = {Mentis, Helena M. and Taylor, Alex S.},
title = {Imaging the Body: Embodied Vision in Minimally Invasive Surgery},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466197},
doi = {10.1145/2470654.2466197},
abstract = {Recent years have seen the possibilities of new imaging and interaction technologies
for minimally invasive surgery such as touchless interaction and high definition renderings
of three-dimensional anatomy. With this paper we take a step back to review the historical
introduction and assimilation of imaging technologies in the surgical theatre in parallel
with the productive and cross-referential nature of surgical practice and image use.
We present findings from a field study of image use during neurosurgery where we see
that the work to see medical images is highly constructed and embodied with the action
of manipulating the body. This perspective lends itself to a discussion of the directions
for new imaging interaction technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1479–1488},
numpages = {10},
keywords = {surgery, movement, health, vision, imaging., embodiment},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466198,
author = {Bird, Jon and Byass, Peter and Kahn, Kathleen and Mee, Paul and Fottrell, Edward},
title = {A Matter of Life and Death: Practical and Ethical Constraints in the Development of a Mobile Verbal Autopsy Tool},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466198},
doi = {10.1145/2470654.2466198},
abstract = {Verbal autopsy (VA) involves interviewing relatives of the deceased to identify the
probable cause of death and is typically used in settings where there is no official
system for recording deaths or their causes. Following the interview, physician assessment
to determine probable cause can take several years to complete. The World Health Organization
(WHO) recognizes that there is a pressing need for a mobile device that combines direct
data capture and analysis if this technique is to become part of routine health surveillance.
We conducted a field test in rural South Africa to evaluate a mobile system that we
designed to meet WHO requirements (namely, simplicity, feasibility, adaptability to
local contexts, cost-effectiveness and program relevance). If desired, this system
can provide immediate feedback to respondents about the probable cause of death at
the end of a VA interview. We assessed the ethical implications of this technological
development by interviewing all the stakeholders in the VA process (respondents, fieldworkers,
physicians, population scientists, data managers and community engagement managers)
and highlight the issues that this community needs to debate and resolve.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1489–1498},
numpages = {10},
keywords = {ethics, verbal autopsy, mobile devices, hci4d.},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250082,
author = {Mandryk, Regan},
title = {Session Details: Papers: Game Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250082},
doi = {10.1145/3250082},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466200,
author = {Mirza-Babaei, Pejman and Nacke, Lennart E. and Gregory, John and Collins, Nick and Fitzpatrick, Geraldine},
title = {How Does It Play Better? Exploring User Testing and Biometric Storyboards in Games User Research},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466200},
doi = {10.1145/2470654.2466200},
abstract = {Improving game design is a hard task. Few methods are available in games user research
(GUR) to test formally how game designs work for players. In particular, the usefulness
of user tests (UTs) for game designers has not been fully studied in the CHI community.
We propose a novel GUR method called Biometric Storyboards (BioSt) and present a study
demonstrating how a Classic UT and a BioSt UT both help designers create a better
gameplay experience. In addition, we show that BioSt can help designers deliver significantly
better visuals, more fun, and higher gameplay quality than designing without UTs and
that classic UTs do not provide this significant advantage. Our interviews support
the idea that BioSt provides more nuanced game design improvement. The design implication
is that a game designed with the BioSt method will result in high gameplay quality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1499–1508},
numpages = {10},
keywords = {storyboards, user testing, games, games user research, user experience, visualization, physiological measures},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466201,
author = {Khaled, Rilla and Nelson, Mark J. and Barr, Pippin},
title = {Design Metaphors for Procedural Content Generation in Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466201},
doi = {10.1145/2470654.2466201},
abstract = {Procedural content generation (PCG), the algorithmic creation of game content with
limited or indirect user input, has much to offer to game design. In recent years,
it has become a mainstay of game AI, with significant research being put towards the
investigation of new PCG systems, algorithms, and techniques. But for PCG to be absorbed
into the practice of game design, it must be contextualised within design-centric
as opposed to AI or engineering perspectives. We therefore provide a set of design
metaphors for understanding potential relationships between a designer and PCG. These
metaphors are: tool, material, designer, and domain expert. By examining PCG through
these metaphors, we gain the ability to articulate qualities, consequences, affordances,
and limitations of existing PCG approaches in relation to design. These metaphors
are intended both to aid designers in understanding and appropriating PCG for their
own contexts, and to advance PCG research by highlighting the assumptions implicit
in existing systems and discourse.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1509–1518},
numpages = {10},
keywords = {procedural content generation, game design, metaphor, adaptive games, game ai},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466202,
author = {Bowser, Anne E. and Hansen, Derek L. and Raphael, Jocelyn and Reid, Matthew and Gamett, Ryan J. and He, Yurong R. and Rotman, Dana and Preece, Jenny J.},
title = {Prototyping in PLACE: A Scalable Approach to Developing Location-Based Apps and Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466202},
doi = {10.1145/2470654.2466202},
abstract = {The rising popularity of location-based applications and games (LBAGs) that break
spatial, temporal, and social boundaries creates new challenges for designers. This
paper introduces PLACE, an iterative, mixed-fidelity approach to Prototyping Location,
Activities, Collective experience, and Experience over time in LBAGs. PLACE consists
of 6 design principles: start small and scale up the fidelity, treat participants
as co-designers, test in a representative space, focus on activities more than interfaces,
respect authentic social experience, and represent time authentically. The effectiveness
of PLACE was evaluated by prototyping Floracaching, a geocaching game for citizen
science. This revealed the types of insights that PLACE provides, best practices for
implementing PLACE, and how PLACE com-pares to other prototyping methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1519–1528},
numpages = {10},
keywords = {co-design, location-based games, location, mixed-fidelity prototype, mobile apps, place},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466203,
author = {Hansen, Derek and Bonsignore, Elizabeth and Ruppel, Marc and Visconti, Amanda and Kraus, Kari},
title = {Designing Reusable Alternate Reality Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466203},
doi = {10.1145/2470654.2466203},
abstract = {Successful Alternate Reality Games (ARGs), such as The Lost Experience, I Love Bees
and Urgent EVOKE have solicited thousands of active participants and, often, millions
of spectators from around the world. ARGs require significant resources not only in
terms of initial design, but also in implementation, since live, dynamic interplay
between players and designers is an inherent aspect of their interactive storylines.
This paper outlines a novel design framework for creating reusable ARGs that will
help extend the lifespan of ARGs and allow them to permeate new domains such as education.
The framework includes three key reusable design objectives (replayability, adaptability,
extensibility), each of which can be enacted at different levels of depth. We also
identify barriers to reusable ARGs and design strategies for overcoming those barriers,
drawing upon ARG designer interviews and existing ARGs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1529–1538},
numpages = {10},
keywords = {adaptable, reusable, design, extensible, alternate reality games, replayable, serious games},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250083,
author = {Schmidt, Albrecht},
title = {Session Details: Papers: Design for the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250083},
doi = {10.1145/3250083},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466205,
author = {Ogonowski, Corinna and Ley, Benedikt and Hess, Jan and Wan, Lin and Wulf, Volker},
title = {Designing for the Living Room: Long-Term User Involvement in a Living Lab},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466205},
doi = {10.1145/2470654.2466205},
abstract = {Living Labs provide a research infrastructure for long-term user involvement in Participatory
Design processes. Users take part in software co-creation during context analysis,
for concept development, reflecting on early-stage prototypes and evaluations in the
field. In this paper we describe lessons learned from our Living Lab in the area of
home entertainment, with 27 participants from 16 households, over a 2.5 year period.
We show that this kind of long-term participation of users involves various challenges
over the lifetime of the project. We highlight several aspects that need to be considered
carefully when setting up such a Living Lab, concerning the selection of participants,
maintenance of participants' motivation, establishment of a trust relationship, and
the coordination of collaboration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1539–1548},
numpages = {10},
keywords = {domestic domain, participatory design, living lab, long-term user study},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466206,
author = {Taylor, Nick and Cheverst, Keith and Wright, Peter and Olivier, Patrick},
title = {Leaving the Wild: Lessons from Community Technology Handovers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466206},
doi = {10.1145/2470654.2466206},
abstract = {As research increasingly turns to work 'in the wild' to design and evaluate technologies
under real-world conditions, little consideration has been given to what happens when
research ends. In many cases, users are heavily involved in the design process and
encouraged to integrate the resulting technologies into their lives before they are
withdrawn, while in some cases technologies are being left in place after research
concludes. Often, little is done to assess the impact and legacy of these deployments.
In this paper, we return to two examples in which we designed technologies with the
involvement of communities and examine what steps were taken to ensure their long-term
viability and what happened following the departure of researchers. From these examples,
we provide guidelines for planning and executing technology handovers when conducting
research with communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1549–1558},
numpages = {10},
keywords = {action research, longitudinal, community, research in the wild},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466207,
author = {Chong, Ming Ki and Gellersen, Hans W.},
title = {How Groups of Users Associate Wireless Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466207},
doi = {10.1145/2470654.2466207},
abstract = {Group association, the process of connecting a group of devices, opens up new opportunities
for users to spontaneously share resources. Research has shown numerous techniques
and protocols for group association; however, what people intuitively do to associate
a group of devices remains an open question. We contribute a study of eliciting device
association techniques from groups of non-technical people. In all, we collected and
analysed 496 techniques from 61 participants. Our results show that mobility and physicality
of devices influence how people perceive groups association. We present a complete
set of user-defined techniques with subjective ratings and popularity scores. We examined
people's rationale and the effects of different device form factors. We analysed the
techniques based on the roles that users assume with respect to device association.
Our findings draw out insights from the perspective of users for design of group association.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1559–1568},
numpages = {10},
keywords = {input techniques, wireless, group, spontaneous interaction, guessability study, device association, pairing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466208,
author = {Brown, Anthony and Mortier, Richard and Rodden, Tom},
title = {MultiNet: Reducing Interaction Overhead in Domestic Wireless Networks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466208},
doi = {10.1145/2470654.2466208},
abstract = {We present MultiNet, a novel method for securely associating devices with a domestic
wireless network. We show that MultiNet has usability benefits over currently deployed
commercial solutions while being backwards compatible with existing devices. MultiNet
reduces the interaction overhead of secure association by focusing on users' interactions
rather than the network's requirements. This leads to a novel architectural arrangement
of the home network infrastructure: the network is dynamically re-configured to accept
each pre-configured device, rather than the current norm where each device is configured
to be acceptable to the pre-configured network. Assuming devices are pre-configured
for a unique, device-specific network name and passphrase, MultiNet constructs an
out-of-band visual channel via an intermediary network controller device to convey
the device's configuration to the network. This makes the interaction to join a device
to the wireless network lightweight and identical across all devices, considerably
reducing the interaction overheads for users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1569–1578},
numpages = {10},
keywords = {usable security, domestic environments, 802.11},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250084,
author = {Burnett, Margaret},
title = {Session Details: Papers: Novel Programming},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250084},
doi = {10.1145/3250084},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466210,
author = {Prior, Suzanne and Waller, Annalu and Black, Rolf and Kroll, Thilo},
title = {Use of an Agile Bridge in the Development of Assistive Technology},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466210},
doi = {10.1145/2470654.2466210},
abstract = {Engaging with end users in the development of assistive technologies remains one of
the major challenges for researchers and developers in the field of accessibility
and HCI. Developing usable software systems for people with complex disabilities is
problematic, software developers are wary of using user-centred design, one of the
main methods by which usability can be improved, due to concerns about how best to
work with adults with complex disabilities, in particular Severe Speech and Physical
Impairments (SSPI) and how to involve them in research. This paper reports on how
the adoption of an adapted agile approach involving the incorporation of a user advocate
on the research team helped in meeting this challenge in one software project and
offers suggestions for how this could be used by other development teams.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1579–1588},
numpages = {10},
keywords = {assistive technology, agile methodology, user centred design, severe speech and physical impairments},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466211,
author = {Jacobs, Jennifer and Buechley, Leah},
title = {Codeable Objects: Computational Design and Digital Fabrication for Novice Programmers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466211},
doi = {10.1145/2470654.2466211},
abstract = {The combination of computational design and digital fabrication offers many exciting
possibilities for art, design, and creative expression. We seek to make computational
design accessible by developing tools that allow novices to use programming and digital
fabrication to produce personal and functional objects. In this paper, we describe
our development of Codeable Objects, a preliminary computational-design programing
tool developed to work in conjunction with digital-fabrication machines. We also present
our evaluation of the tool based on a set of user studies in which people built computationally
generated crafts, clothing, and accessories. These studies illuminated the viability
(and challenges) of engaging novice programmers through design and digital fabrication,
and provide a platform for future work in developing programming tools to support
personal expression.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1589–1598},
numpages = {10},
keywords = {computational design, art and craft, software, accessibility},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466212,
author = {Yang, Huahai and Pupons-Wickham, Daina and Chiticariu, Laura and Li, Yunyao and Nguyen, Benjamin and Carreno-Fuentes, Arnaldo},
title = {I Can Do Text Analytics! Designing Development Tools for Novice Developers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466212},
doi = {10.1145/2470654.2466212},
abstract = {Text analytics, an increasingly important application domain, is hampered by the high
barrier to entry due to the many conceptual difficulties novice developers encounter.
This work addresses the problem by developing a tool to guide novice developers to
adopt the best practices employed by expert developers in text analytics and to quickly
harness the full power of the underlying system. Taking a user centered task analytical
approach, the tool development went through multiple design iterations and evaluation
cycles. In the latest evaluation, we found that our tool enables novice developers
to develop high quality extractors on par with the state of art within a few hours
and with minimal training. Finally, we discuss our experience and lessons learned
in the context of designing user interfaces to reduce the barriers to entry into complex
domains of expertise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1599–1608},
numpages = {10},
keywords = {workflow guide, best practices, information extraction, extraction plan, text analytics, novice developer},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466213,
author = {Kuttal, Sandeep Kaur and Sarma, Anita and Rothermel, Gregg},
title = {Debugging Support for End User Mashup Programming},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466213},
doi = {10.1145/2470654.2466213},
abstract = {Programming for the web can be an intimidating task, particularly for non-professional
("end-user") programmers. Mashup programming environments attempt to remedy this by
providing support for such programming. It is well known, however, that mashup programmers
create applications that contain bugs. Furthermore, mashup programmers learn from
examples and reuse other mashups, which causes bugs to propagate to other mashups.
In this paper we classify the bugs that occur in a large corpus of Yahoo! Pipes mashups.
We describe support we have implemented in the Yahoo! Pipes environment to provide
automatic error detection techniques that help mashup programmers localize and correct
these bugs. We present the results of a think-aloud study comparing the experiences
of end-user mashup programmers using and not using our support. Our results show that
our debugging enhancements do help these programmers localize and correct bugs more
effectively and efficiently.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1609–1618},
numpages = {10},
keywords = {end-user programming, mashups, debugging, yahoo! pipes, end-user software engineering, programming barriers},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250085,
author = {Blandford, Ann},
title = {Session Details: Papers: Temporal Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250085},
doi = {10.1145/3250085},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466215,
author = {Thiry, Elizabeth and Lindley, Si\^{a}n and Banks, Richard and Regan, Tim},
title = {Authoring Personal Histories: Exploring the Timeline as a Framework for Meaning Making},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466215},
doi = {10.1145/2470654.2466215},
abstract = {It has been argued that technologies for 'memory' should be designed to support creativity
and meaning building, rather than the passive capture of cues for remembering [25].
We report findings from a study inspired by this insight, in which older people made
personal digital timelines using a new tool called Project Greenwich. We explore how
the constraints of the timeline metaphor offer a framework for authoring, and examine
how timelines can be used to underpin meaning building in relation to personal content.
We highlight the importance of making, this being a vehicle for connecting with others
in the present, and a potential means of emphasizing those elements of the past felt
to be most salient when looking back.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1619–1628},
numpages = {10},
keywords = {authorship, recipient design, older adults, making, storytelling, craft, project greenwich, memory, legacy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466216,
author = {Mankoff, Jennifer and Rode, Jennifer A. and Faste, Haakon},
title = {Looking Past Yesterday's Tomorrow: Using Futures Studies Methods to Extend the Research Horizon},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466216},
doi = {10.1145/2470654.2466216},
abstract = {Doing research is, in part, an act of foresight. Even though it is not explicit in
many projects, we especially value research that is still relevant five, ten or more
years after it is completed. However, published research in the field of interactive
computing (and technology research in general) often lacks evidence of systematic
thinking about the long-term impacts of current trends. For example, trends on an
exponential curve change much more rapidly than intuition predicts. As a result, research
may accidentally emphasize near-term thinking. When thinking about the future is approached
systematically, we can critically examine multiple potential futures, expand the set
of externalities under consideration, and address both negative and positive forecasts
of the future. The field of Futures Studies provides methods that can support analysis
of long-term trends, support the identification of new research areas and guide design
and evaluation. We survey methods for futuristic thinking and discuss their relationship
to Human Computer Interaction. Using the sustainability domain an example, we present
a case study of a Futures Studies approach - the Delphi Method. We show how Futures
Studies can be incorporated into Human Computer Interaction and highlight future work
such as rethinking the role of externalities in the validation process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1629–1638},
numpages = {10},
keywords = {futures studies, sustainability},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466217,
author = {Lundgren, Sus},
title = {Toying with Time: Considering Temporal Themes in Interactive Artifacts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466217},
doi = {10.1145/2470654.2466217},
abstract = {This paper argues that there is a value in deliberately and systematically exploring
potential temporal behaviors of an interactive artifact, either as a means to add
new functions, or to change the interaction with it. An improved version of Temporal
Themes [23] - a vocabulary describing how software can "use" time or sequences of
events - will be presented, alongside a series of design cases. These exemplify how
adding or changing temporal themes in existing applications can enhance functionality
and/or interaction. Moreover, the cases also serve as a basis for a discussion of
the issues coupled to temporality, control and interaction strategies. Finally, a
design approach with focus on temporal aspects is outlined. As a result, the paper
opens up for a more conscious use of time and temporality in interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1639–1648},
numpages = {10},
keywords = {interaction design, design method, temporal themes, temporality, time},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466218,
author = {Rosner, Daniela K. and Ikemiya, Miwa and Kim, Diana and Koch, Kristin},
title = {Designing with Traces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466218},
doi = {10.1145/2470654.2466218},
abstract = {This paper draws on new materialist perspectives to introduce the analytic category
of "material traces" to the field of human-computer interaction (HCI). Material traces
reveal the dynamic and evocative nature of form by concretizing a unique location
in time and space. Traces of skill, use, and time, for example, are valued for their
emotional resonance in addition to the pragmatic goals in which they are embedded.
Using this category, we develop a framework for design pedagogy that offers the lenses
of attributes, entanglements, and trajectories as tools for gaining critical purchase
on the objects produced. Mobilizing this framework within a classroom, design students
envision poignant relationships to the non-human, engaged physics learning, and opportunities
for reflection around breakage and repair. These design examples reveal how the category
of material traces comes alive in practice and pedagogy. We end by discussing how
this study of traces points to new opportunities for critical reflection in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1649–1658},
numpages = {10},
keywords = {traces, prove-nance, design pedagogy, materiality, craft, archeology, design theory, temporality, critical making},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250086,
author = {McGee-Lennon, Marilyn},
title = {Session Details: Papers: Tactile Experiences},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250086},
doi = {10.1145/3250086},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466220,
author = {Obrist, Marianna and Seah, Sue Ann and Subramanian, Sriram},
title = {Talking about Tactile Experiences},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466220},
doi = {10.1145/2470654.2466220},
abstract = {A common problem with designing and developing applications with tactile interfaces
is the lack of a vocabulary that allows one to describe or communicate about haptics.
Here we present the findings from a study exploring participants' verbalizations of
their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related
to two important mechanoreceptors in the human hand. The study, with 14 participants,
applied the explicitation interview technique to capture detailed descriptions of
the diachronic and synchronic structure of tactile experiences. We propose 14 categories
for a human-experiential vocabulary based on the categorization of the findings and
tie them back to neurophysiological and psychophysical data on the human hand. We
finally discuss design opportunities created through this experiential understanding
in relation to the two mechanoreceptors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1659–1668},
numpages = {10},
keywords = {tactile experiences, human hand, user study, mechanoreceptors, non-contact haptic system, explicitation interview technique, human-experiential vocabulary, ultrasound},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466221,
author = {Atkinson, Douglas and Orzechowski, Pawel and Petreca, Bruna and Bianchi-Berthouze, Nadia and Watkins, Penelope and Baurley, Sharon and Padilla, Stefano and Chantler, Mike},
title = {Tactile Perceptions of Digital Textiles: A Design Research Approach},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466221},
doi = {10.1145/2470654.2466221},
abstract = {Current interactive media presentations of textiles provide an impoverished communication
of their 'textile hand', that is their weight, drape, how they feel to touch. These
are complex properties experienced through the visual, tactile, auditory and proprioceptive
senses and are currently lost when textile materials are presented in interactive
video. This paper offers a new perspective from which the production of multi-touch
interactive video representations of the tactile qualities of materials is considered.
Through an understanding of hand properties of textiles and how people inherently
touch and handle them, we are able to develop methods to animate and bring these properties
alive using design methods. Observational studies were conducted, noting gestures
consumers used to evaluate textile hand. Replicating the appropriate textile deformations
for these gestures in interactive video was explored as a design problem. The resulting
digital textile swatches and their interactive behavior were then evaluated for their
ability to communicate tactile qualities similar to those of the real textiles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1669–1678},
numpages = {10},
keywords = {methodology, visualisation, user interactions, multimodal interfaces, design research, design methods},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466222,
author = {Park, Young-Woo and Baek, Kyoung-Min and Nam, Tek-Jin},
title = {The Roles of Touch during Phone Conversations: Long-Distance Couples' Use of POKE in Their Homes},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466222},
doi = {10.1145/2470654.2466222},
abstract = {We report the roles of touch during phone conversations by observing long-distance
couples' one month use of POKE in their homes. POKE enables users to deliver touches
through an inflatable surface on the front of the device that receives index finger
pressure inputs on the back of another device, while allowing the callers to maintain
a conventional phone-calling posture. After a month of use by three couples, we found
unexpected roles of touch in that it supported the couples in developing and sharing
their tactile vocabularies by applying POKE during various conversational situations.
Moreover, the findings confirmed the roles that touch play in face-to-face communication.
In particular, POKE was useful for expressing and understanding emotions, resolving
conversations smoothly by replacing the words, feeling close to the partner at a distance,
and concentrating on the phone conversations. We conclude by discussing the unused
situations, privacy issues, and usable targets to improve POKE as a way of future
tactile phone conversations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1679–1688},
numpages = {10},
keywords = {field trial, tactile phone call, role of touch, tactile vocabulary},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466223,
author = {Tam, Diane and MacLean, Karon E. and McGrenere, Joanna and Kuchenbecker, Katherine J.},
title = {The Design and Field Observation of a Haptic Notification System for Timing Awareness during Oral Presentations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466223},
doi = {10.1145/2470654.2466223},
abstract = {To moderate oral presentations a chair must manage time, and communicate time parameters
to speakers through a variety of means. But speakers often miss time cues, chairs
cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience.
We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System
that delivers tactile cues for time-managing oral presentations, and performed field
observations at university research seminars and two mid-sized academic conferences
(input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that
HaNS can improve a user's awareness of time, facilitate chair-speaker coordination,
and reduce distraction of speaker and audience through its private communication channel.
Eliminating overruns will require improvement in speaker 'internal' control, which
our results suggest HaNS can also support given practice. We conclude with design
guidelines for both conference-deployed and personal timing tools, using touch or
another notification modality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1689–1698},
numpages = {10},
keywords = {vibrotactile, field study, wearable haptics, oral presentation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250087,
author = {Gellersen, Hans},
title = {Session Details: Papers: Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250087},
doi = {10.1145/3250087},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466225,
author = {Kukka, Hannu and Oja, Heidi and Kostakos, Vassilis and Gon\c{c}alves, Jorge and Ojala, Timo},
title = {What Makes You Click: Exploring Visual Signals to Entice Interaction on Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466225},
doi = {10.1145/2470654.2466225},
abstract = {Most studies take for granted the critical first steps that prelude interaction with
a public display: awareness of the interactive affordances of the display, and enticement
to interact. In this paper we investigate mechanisms for enticing interaction on public
displays, and study the effectiveness of visual signals in overcoming the 'first click'
problem. We combined 3 atomic visual elements (color/greyscale, animation/static,
and icon/text) to form 8 visual signals that were deployed on 8 interactive public
displays on a university campus for 8 days. Our findings show that text is more effective
in enticing interaction than icons, color more than greyscale, and static signals
are more effective than animated. Further, we identify gender differences in the effectiveness
of these signals. Finally, we identify a behavior termed "display avoidance" that
people exhibit with interactive public displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1699–1708},
numpages = {10},
keywords = {interaction, public displays, attracting attention, visual signals},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466226,
author = {Alt, Florian and Shirazi, Alireza Sahami and Kubitza, Thomas and Schmidt, Albrecht},
title = {Interaction Techniques for Creating and Exchanging Content with Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466226},
doi = {10.1145/2470654.2466226},
abstract = {Falling hardware prices and ever more displays being connected to the Internet will
lead to large public display networks, potentially forming a novel communication medium.
We envision that such networks are not restricted to display owners and advertisers
anymore, but allow also passersby (e.g., customers) to exchange content, similar to
traditional public notice areas, such as bulletin boards. In this context it is crucial
to understand emerging practices and provide easy and straight forward interaction
techniques to be used for creating and exchanging content. In this paper, we present
Digifieds, a digital public notice area we built to investigate and compare possible
interaction techniques. Based on a lab study we show that using direct touch at the
display as well as using the mobile phone as a complementing interaction technology
are most suitable. Direct touch at the display closely resembles the interaction known
from classic bulletin boards and provides the highest usability. Mobile phones preserve
the users' privacy as they exchange (sensitive) data with the display and at the same
time allow content to be created on-the-go or to be retrieved.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1709–1718},
numpages = {10},
keywords = {digifieds, classified ads, public displays, interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466227,
author = {Schmidt, Constantin and M\"{u}ller, J\"{o}rg and Bailly, Gilles},
title = {Screenfinity: Extending the Perception Area of Content on Very Large Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466227},
doi = {10.1145/2470654.2466227},
abstract = {We propose and validate a model of the perception area of content on public displays
in order to predict from where users can read. From this model, we derive Screenfinity,
a technique to rotate, translate, and zoom content in order to enable reading while
passing by very large displays. Screenfinity is comfortable to read when close, supports
different content for different users, does not waste screen real estate and allows
expert passers-by to read content while walking. A laboratory study shows that expert
users are able to perceive content when it moves. A field study evaluates the effect
of Screenfinity on novice users in an ecologically valid setting. We find 1) first
time users can read content without slowing down or stopping; 2) Passers-by stopping
did so to explore the technology. Users explore the interaction, the limits of the
system, manipulate the technology, and look behind the screen.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1719–1728},
numpages = {10},
keywords = {large public displays, visual acuity, perception area},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466228,
author = {Beyer, Gilbert and K\"{o}ttner, Florian and Schiewe, Manuel and Haulsen, Ivo and Butz, Andreas},
title = {Squaring the Circle: How Framing Influences User Behavior around a Seamless Cylindrical Display},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466228},
doi = {10.1145/2470654.2466228},
abstract = {Recent research has presented large public displays in novel non-flat shapes such
as spheres, curved planes and cylinders, and looked at the influence of the form factor
on user behavior. Yet, the basic shape cannot be considered in isolation when interpreting
the behavior of passers-by around such displays. In this paper we investigate two
further display factors, framedness and seamlessness, that have to be considered in
conjunction with the form factor to understand user behavior in front of large non-flat
displays. We present the findings from a field study with an interactive column display
and take a closer look at how these factors influence actor and bystander behavior.
Our results show that rectangular frames act as a sort of funnel for user position
and can easily override effects of the non-flat shape on user position and interaction,
even though the users didn't recall the presence of these frames.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1729–1738},
numpages = {10},
keywords = {public displays, form factor, audience behavior, non-flat displays, seamless, framing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250088,
author = {Chen, Yunan},
title = {Session Details: Papers: Communicating Health},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250088},
doi = {10.1145/3250088},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466230,
author = {Sun, Si and Zhou, Xiaomu and Denny, Joshua C. and Rosenbloom, Trent S. and Xu, Hua},
title = {Messaging to Your Doctors: Understanding Patient-Provider Communications via a Portal System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466230},
doi = {10.1145/2470654.2466230},
abstract = {The patient portal is a relatively new healthcare information technology that enables
patients more convenient access to their healthcare information and allows them to
send messages to their doctors. Our study examines the themes discussed in these messages
and the different ways in which patients communicate with their providers via a portal
employed in a large medical center. We also explore the differences between the patient
portal and more traditional communication media, and investigated the advantages and
potential problems of the portal system. Our findings show a wide variety of topics
discussed in the communication messages (such as medication, appointments, laboratory
tests, etc.) and how patients provide information, consult with their providers, and
express psychosocial and emotional needs. We argue that the patient portal improves
the accuracy of communication and could facilitate illness management for patients,
especially over a longer term. However, messaging through the patient portal is not
popular among patients and the simultaneous use of multiple communication media may
create information gaps. More research is needed to better elucidate barriers to the
use of patient portals and the optimal methods of communication and information integration
given different contexts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1739–1748},
numpages = {10},
keywords = {emr, computer mediated communication, patient-provider communication, patient portal, health information system},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466231,
author = {Curmi, Franco and Ferrario, Maria Angela and Southern, Jen and Whittle, Jon},
title = {HeartLink: Open Broadcast of Live Biometric Data to Social Networks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466231},
doi = {10.1145/2470654.2466231},
abstract = {A number of studies in the literature have looked into the use of real-time biometric
data to improve one's own physiological performance and wellbeing. However, there
is limited research that looks into the effects that sharing biometric data with others
could have on one's social network. Following a period of research on existing mobile
applications and prototype testing, we developed a system, HeartLink, which collects
real-time personal biometric data such as heart rate and broadcasts this data online.
Insights gained on designing systems to broadcast real-time biometric data are presented.
In this paper we also report emerging results from testing HeartLink in a pilot study
and a user study that were conducted during sport events. The results showed that
sharing heart rate data does influence the relationship of the persons involved and
that the degree of influence seems related to the tie strength prior to visualizing
the data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1749–1758},
numpages = {10},
keywords = {digital economy, biometric data, social networks, data broadcast, mobile computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466232,
author = {Pang, Carolyn E. and Neustaedter, Carman and Riecke, Bernhard E. and Oduor, Erick and Hillman, Serena},
title = {Technology Preferences and Routines for Sharing Health Information during the Treatment of a Chronic Illness},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466232},
doi = {10.1145/2470654.2466232},
abstract = {When a patient has a chronic illness, such as heart disease or cancer, it can be challenging
for distributed family members to stay aware of the patient's health status. A variety
of technologies are available to support health information sharing (e.g., phone,
video chat, social media), yet we still do not have a detailed understanding of which
technologies are preferred and what challenges people still face when sharing information
with them. To explore this, we conducted a mixed-method study-involving a survey and
in-depth interviews--with people about their health information sharing routines and
preferences for different technologies. Regardless of physical distance between distributed
family members, synchronous methods of communication afforded the opportunity to provide
affective support while asynchronous methods of communication were deemed to be the
least intrusive. With family members adopting certain roles during the treatment of
chronic illnesses, our findings suggest the need to design tools that mediate sharing
health information across distance and age gaps, with consideration to respecting
patient privacy while sharing health information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1759–1768},
numpages = {10},
keywords = {families, health informatics, social support, communication},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466233,
author = {Yun, Tae-Jung and Arriaga, Rosa I.},
title = {A Text Message a Day Keeps the Pulmonologist Away},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466233},
doi = {10.1145/2470654.2466233},
abstract = {The goal of this study was to extend and replicate an SMS health intervention for
pediatric asthma patients. This intervention was designed using the Health Belief
Model (HBM). Thirty patients were randomly assigned to one of three conditions. In
the Knowledge condition patients were queried about their asthma knowledge every other
day. In the Knowledge and Symptoms condition patients received a daily text message.
They were queried about their symptoms and knowledge of asthma on alternate days.
The Control group received no texts. Our main finding is that daily text messages
lead to improved health outcomes.We explain our results in the context of interview
data and the HBM. We conclude by suggesting that the HBM can be used to inform and
evaluate system design for chronic care beyond asthma and by considering the role
that replication studies can play in HCI research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1769–1778},
numpages = {10},
keywords = {asthma, sms, replichi, rct, text message},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250089,
author = {Ren, Xiangshi},
title = {Session Details: Papers: Reading and Writing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250089},
doi = {10.1145/3250089},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466235,
author = {Lafreniere, Benjamin and Grossman, Tovi and Fitzmaurice, George},
title = {Community Enhanced Tutorials: Improving Tutorials with Multiple Demonstrations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466235},
doi = {10.1145/2470654.2466235},
abstract = {Web-based tutorials are a popular help resource for learning how to perform unfamiliar
tasks in complex software. However, in their current form, web tutorials are isolated
from the applications that they support. In this paper we present FollowUs, a web-tutorial
system that integrates a fully-featured application into a web-based tutorial. This
novel architecture enables community enhanced tutorials, which continuously improve
as more users work with them. FollowUs captures video demonstrations of users as they
perform a tutorial. Subsequent users can use the original tutorial, or choose from
a library of captured community demonstrations of each tutorial step. We conducted
a user study to test the benefits of making multiple demonstrations available to users,
and found that users perform significantly better using our system with a library
of multiple demonstrations in comparison to its equivalent baseline system with only
the original authored content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1779–1788},
numpages = {10},
keywords = {learning, community, tutorials, help},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466236,
author = {Leitner, Jakob F. and Perteneder, Florian and Liu, Can and Rendl, Christian and Haller, Michael},
title = {Kolibri: Tiny and Fast Gestures for Large Pen-Based Surfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466236},
doi = {10.1145/2470654.2466236},
abstract = {Triggering commands on large interactive surfaces is less efficient than on desktop
PCs. It requires either large physical movements to reach an interaction area (e.g.,
buttons) or additional operations to call context menus (e.g., dwell). There is a
lack of efficient ways to trigger shortcuts. We introduce Kolibri - a pen-based gesture
system that allows fast access of commands on interactive whiteboards. Users can draw
tiny gestures (approx. 3 mm) anywhere on the surface to trigger commands without interfering
with normal inking. This approach does neither require entering a gesture mode, nor
dedicated gesture areas. The implementation relies on off-the-shelf hardware only.
We tested the feasibility and explored the properties of this technique with several
studies. The results from a controlled experiment show significant benefits of Kolibri
comparing to an existing approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1789–1798},
numpages = {10},
keywords = {fluid inking, pen-input, small gestures, large interactive interfaces, whiteboard application, shortcuts},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466237,
author = {Chen, Nicholas and Guimbreti\`{e}re, Fran\c{c}ois and Sellen, Abigail},
title = {Graduate Student Use of a Multi-Slate Reading System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466237},
doi = {10.1145/2470654.2466237},
abstract = {In laboratory studies, multi-surface slate-based reading systems have shown great
promise as platforms for active reading. However, the true utility of such a system
can only be ascertained through the rigors of real world use. We conducted month-long
deployments of a multi-slate reading system to support the active reading activities
of graduate students in the humanities. During these deployments we documented how
the added display area and increased micro-mobility of multiple devices enhanced navigation
and reading comfort. We also noted the essential role of writing and annotation. Finally,
we observed how electronic affordances like synchronization across devices helped
provide functionality that would not have been possible with paper documents. This
paper contributes new information about how electronic reading solutions fit into
real world reading workflows.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1799–1808},
numpages = {10},
keywords = {academia, reading, e-reading, tablet, graduate students, deployment, e-book, multi-screen computing, multi-slate},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466238,
author = {Wilfinger, David and Murer, Martin and Osswald, Sebastian and Meschtscherjakov, Alexander and Tscheligi, Manfred},
title = {The Wheels Are Turning: Content Rotation on Steering Wheel Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466238},
doi = {10.1145/2470654.2466238},
abstract = {The steering wheel is a promising space for the integration of displays since in the
car there is very limited space for integrating interactive modalities for the driver
that are close to the preferred field of view as well as in an easy to reach position.
When the wheel is turned, the screen content could change its orientation to increase
the readability and therefore reduce the distraction from the road. Thus, this paper
describes three different content rotation behaviors for steering wheel displays.
To investigate what effect these behaviors have on the driver in terms of visual distraction
from the road we conducted a user study with eye tracking asking participants to read
the current speed. We found no differences in terms of distraction and response time
between the different rotation behaviors. Compared to a similar display in a dashboard
position the visual distraction was reduced.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1809–1812},
numpages = {4},
keywords = {steering wheel, rotation, distraction, display},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250090,
author = {Lindley, Si\^{a}n},
title = {Session Details: Papers: Studying Digital Artifacts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250090},
doi = {10.1145/3250090},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466240,
author = {Gulotta, Rebecca and Odom, William and Forlizzi, Jodi and Faste, Haakon},
title = {Digital Artifacts as Legacy: Exploring the Lifespan and Value of Digital Data},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466240},
doi = {10.1145/2470654.2466240},
abstract = {Legacy is the meaningful and complex way in which information, values, and possessions
are passed on to others. As digital systems and information become meaningfully parts
of people's everyday and social relationships, it is essential to develop new insights
about how technology intersects with legacy and inheritance practices. We designed
three interactive systems to investigate how digital materials might be passed down
in the future. We conducted in-home interviews with ten parents using the systems
to provoke discussion about how technology might support or complicate their existing
practices. Sessions revealed parents desired to treat their digital information in
ways not fully supported by technology. Findings are interpreted to describe design
considerations for future work in this emerging space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1813–1822},
numpages = {10},
keywords = {interviews, legacy, reflective design, technology probes, speculative design, design, digital artifacts, inheritance},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466241,
author = {Sas, Corina and Whittaker, Steve},
title = {Design for Forgetting: Disposing of Digital Possessions after a Breakup},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466241},
doi = {10.1145/2470654.2466241},
abstract = {People are increasingly acquiring huge collections of digital possessions. Despite
some pleas for 'forgetting', most theorists argue for retaining all these possessions
to enhance 'total recall' of our everyday lives. However, there has been little exploration
of the negative role of digital possessions when people want to forget aspects of
their lives. We report on interviews with 24 people about their possessions after
a romantic breakup. We found that digital possessions were often evocative and upsetting
in this context, leading to distinct disposal strategies with different outcomes.
We advance theory by finding strong evidence for the value of intentional forgetting
and provide new data about complex practices associated with the disposal of digital
possessions. Our findings led to a number of design implications to help people better
manage this process, including automatic harvesting of digital possessions, tools
for self-control, artifact crafting as sense-making, and digital spaces for shared
possessions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1823–1832},
numpages = {10},
keywords = {intentional forgetting, disposal, sense of self, digital possessions, relationship dissolution, autobiographical memories},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466242,
author = {Odom, William and Zimmerman, John and Forlizzi, Jodi and L\'{o}pez Higuera, Ana and Marchitto, Mauro and Ca\~{n}as, Jos\'{e} and Lim, Youn-kyung and Nam, Tek-Jin and Lee, Moon-Hwan and Lee, Yeoreum and Kim, Da-jung and Row, Yea-kyung and Seok, Jinmin and Sohn, Bokyung and Moore, Heather},
title = {Fragmentation and Transition: Understanding Perceptions of Virtual Possessions among Young Adults in Spain, South Korea and the United States},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466242},
doi = {10.1145/2470654.2466242},
abstract = {People worldwide are increasingly acquiring collections of virtual possessions. While
virtual possessions have become ubiquitous, little work exists on how people value
and form attachments to these things. To investigate, we conducted a study with 48
young adults from South Korea, Spain and the United States. The study probed on participants'
perceived value of their virtual possessions as compared to their material things,
and the comparative similarities and differences across cultures. Findings show that
young adults live in unfinished spaces and that they often experience a sense of fragmentation
when trying to integrate their virtual possessions into their lives. These findings
point to several design opportunities, such as tools for life story-oriented archiving,
and insights on better forms of Cloud storage.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1833–1842},
numpages = {10},
keywords = {digital things, human-centered architectures, virtual possessions, interactive systems design, young adults},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466243,
author = {Weilenmann, Alexandra and Hillman, Thomas and Jungselius, Beata},
title = {Instagram at the Museum: Communicating the Museum Experience through Social Photo Sharing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466243},
doi = {10.1145/2470654.2466243},
abstract = {The everyday use of smartphones with high quality built-in cameras has lead to an
increase in museum visitors' use of these devices to document and share their museum
experiences. In this paper, we investigate how one particular photo sharing application,
Instagram, is used to communicate visitors' experiences while visiting a museum of
natural history. Based on an analysis of 222 instagrams created in the museum, as
well as 14 interviews with the visitors who created them, we unpack the compositional
resources and concerns contributing to the creation of instagrams in this particular
context. By re-categorizing and re-configuring the museum environment, instagrammers
work to construct their own narratives from their visits. These findings are then
used to discuss what emerging multimedia practices imply for the visitors' engagement
with and documentation of museum exhibits. Drawing upon these practices, we discuss
the connection between online social media dialogue and the museum site.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1843–1852},
numpages = {10},
keywords = {social media, museum of natural history, museum studies, photography, camera phones, instagram, smartphones.},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250091,
author = {Massimi, Michael},
title = {Session Details: Papers: Ethics in HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250091},
doi = {10.1145/3250091},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466245,
author = {McMillan, Donald and Morrison, Alistair and Chalmers, Matthew},
title = {Categorised Ethical Guidelines for Large Scale Mobile HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466245},
doi = {10.1145/2470654.2466245},
abstract = {The recent rise in large scale trials of mobile software using 'app stores' has moved
current researcher practice beyond available ethical guidelines. By surveying this
recent and growing body of literature, as well as established professional principles
adopted in psychology, we propose a set of ethical guidelines for large scale HCI
user trials. These guidelines come in two parts: a set of general principles and a
framework into which individual app store-based trials can be assessed and ethical
concerns exposed. We categorise existing literature using our scheme, and explain
how researchers could use our framework to classify their future user trials to determine
ethical responsibility, and the steps required to meet these obligations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1853–1862},
numpages = {10},
keywords = {app stores, large-scale trials, ethics, mass participation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466246,
author = {Adar, Eytan and Tan, Desney S. and Teevan, Jaime},
title = {Benevolent Deception in Human Computer Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466246},
doi = {10.1145/2470654.2466246},
abstract = {Though it has been asserted that "good design is honest", [42] deception exists throughout
human-computer interaction research and practice. Because of the stigma associated
with deception - in many cases rightfully so - the research community has focused
its energy on eradicating malicious deception, and ignored instances in which deception
is positively employed. In this paper we present the notion of benevolent deception,
deception aimed at benefitting the user as well as the developer. We frame our discussion
using a criminology-inspired model and ground components in various examples. We assert
that this provides us with a set of tools and principles that not only helps us with
system and interface design, but that opens new research areas. After all, as Cockton
claims in his 2004 paper "Value-Centered HCI" [13], "Traditional disciplines have
delivered truth. The goal of HCI is to deliver value."},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1863–1872},
numpages = {10},
keywords = {design principles, benevolent deception, criminology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466247,
author = {Vines, John and Thieme, Anja and Comber, Rob and Blythe, Mark and Wright, Peter C. and Olivier, Patrick},
title = {HCI in the Press: Online Public Reactions to Mass Media Portrayals of HCI Research},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466247},
doi = {10.1145/2470654.2466247},
abstract = {HCI researchers working in publically funded institutions are increasingly encouraged
to engage the public in their research. Mass media is often seen as an effective medium
with which to communicate research to large parts of the population. We present an
account of three HCI projects that have used engagements with mass media in order
to communicate research to the public. We describe the motivations for working with
mass media and the mechanics of writing press releases. A grounded theory analysis
of online public responses to the projects in the mass media leads us to identify
a number of concerns about how research is portrayed by news outlets and thus interpreted
by the public. Tensions about technologies and wider societal issues were revealed
that might normally be hidden when using traditional user-centred methods. We critically
reflect on the efficacy of using the mass media in research and provide guidance for
HCI researchers wishing to engage in dialogues with the public in the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1873–1882},
numpages = {10},
keywords = {public engagement, navigation systems, digital banking, sustainability, older people, mass media},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466248,
author = {Moncur, Wendy},
title = {The Emotional Wellbeing of Researchers: Considerations for Practice},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466248},
doi = {10.1145/2470654.2466248},
abstract = {As technology progressively pervades all aspects of our lives, members of the HCI
community are engaging with increasingly sensitive contexts in their research - for
example, end of life, genocide, computer-mediated communication under oppressive regimes.
The considerations generated by research in such contexts can go well beyond those
addressed by generic ethical approval processes and institutional practice. Whilst
it is standard to ensure that the wellbeing of participants is taken into account
in research design and the ethical approval process, it is much less common for the
researcher's own emotional wellbeing to be considered explicitly. This paper describes
the role that a researcher's emotions may play in research, and the impact which research
in sensitive contexts can have on researchers' emotional wellbeing and on research
validity. A qualitative survey is described which investigated the support mechanisms
which HCI researchers have in place in case they are distressed/troubled as a result
of their research. The results of the survey are used, in combination with insights
into how other disciplines address the topic, to synthesize suggestions for ways in
which the HCI community can proactively incorporate consideration for the emotional
wellbeing of the researcher into the research process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1883–1890},
numpages = {8},
keywords = {qualitative research, thanatosensitive design, ethics, reflection, emotion, methodology, participatory design, end of life, validity, research governance},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250092,
author = {Loke, Lian},
title = {Session Details: Papers: Embodied Interaction 2},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250092},
doi = {10.1145/3250092},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466250,
author = {Doucette, Andre and Mandryk, Regan L. and Gutwin, Carl and Nacenta, Miguel and Pavlovych, Andriy},
title = {The Effects of Tactile Feedback and Movement Alteration on Interaction and Awareness with Digital Embodiments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466250},
doi = {10.1145/2470654.2466250},
abstract = {Collaborative tabletop systems can employ direct touch, where people's real arms and
hands manipulate objects, or indirect input, where people are represented on the table
with digital embodiments. The input type and the resulting embodiment dramatically
influence tabletop interaction: in particular, the touch avoidance that naturally
governs people's touching and crossing behavior with physical arms is lost with digital
embodiments. One result of this loss is that people are less aware of each others'
arms, and less able to coordinate actions and protect personal territories. To determine
whether there are strategies that can influence group interaction on shared digital
tabletops, we studied augmented digital arm embodiments that provide tactile feedback
or movement alterations when people touched or crossed arms. The study showed that
both augmentation types changed people's behavior (people crossed less than half as
often) and also changed their perception (people felt more aware of the other person's
arm, and felt more awkward when touching). This work shows how groupware designers
can influence people's interaction, awareness, and coordination abilities when physical
constraints are absent.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1891–1900},
numpages = {10},
keywords = {coordination, tabletop groupware, awareness, embodiments},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466251,
author = {Deckers, Eva and Wensveen, Stephan and Levy, Pierre and Ahn, Rene},
title = {Designing for Perceptual Crossing: Designing and Comparing Three Behaviors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466251},
doi = {10.1145/2470654.2466251},
abstract = {Perceptual crossing is the reciprocal interplay of perceiving while being perceived.
In this paper we discuss the last iteration of our ongoing research project on designing
for perceptive qualities in systems of interactive products. We describe the design
of explorative behavior in an artifact to enable the artifact and a person to engage
in perceptual crossing. The explorative behavior is compared to the following and
active behavior, the results of two earlier iterations. Through the iterations we
formulated, applied and evaluated design relevant knowledge in the form of seven design
notions. These notions inform design-researchers and design-practitioners on how to
design for perceptive qualities in systems of interactive products. Here we specifically
focus on how the artifact detects active perceptive behavior of a person, and how
the artifact becomes aware of bygone perception and anticipates on future perception.
An experiment shows how participants preferred the resulting explorative behavior
that is closest to our theoretical framework based on phenomenology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1901–1910},
numpages = {10},
keywords = {product behavior, research through design, perceptive qualities, design theory, phenomenology, perceptual crossing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466252,
author = {Cafaro, Francesco and Panella, Alessandro and Lyons, Leilah and Roberts, Jessica and Radinsky, Josh},
title = {I See You There! Developing Identity-Preserving Embodied Interaction for Museum Exhibits},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466252},
doi = {10.1145/2470654.2466252},
abstract = {Museums are increasingly embracing technologies that provide highly-individualized
and highly-interactive experiences to visitors. With embodied interaction experiences,
increased localization accuracy supports greater nuance in interaction design, but
there is usually a tradeoff between fast, accurate tracking and the ability to preserve
the identity of users. Customization of experience relies on the ability to detect
the identity of visitors, however. We present a method that combines fine-grained
indoor tracking with robust preservation of the unique identities of multiple users.
Our model merges input from an RFID reader with input from a commercial camera-based
tracking system. We developed a probabilistic Bayesian model to infer at run-time
the correct identification of the subjects in the camera's field of view. This method,
tested in a lab and at a local museum, requires minimal modification to the exhibition
space, while addressing several identity-preservation problems for which many indoor
tracking systems do not have robust solutions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1911–1920},
numpages = {10},
keywords = {rfid, tracking, localization, museum exhibits, ambient displays, embodied interaction, cameras, identification},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466253,
author = {Rae, Irene and Takayama, Leila and Mutlu, Bilge},
title = {In-Body Experiences: Embodiment, Control, and Trust in Robot-Mediated Communication},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466253},
doi = {10.1145/2470654.2466253},
abstract = {Communication technologies are becoming increasingly diverse in form and functionality,
making it important to identify which aspects of these technologies actually improve
geographically distributed communication. Our study examines two potentially important
aspects of communication technologies which appear in robot-mediated communication
- physical embodiment and control of this embodiment. We studied the impact of physical
embodiment and control upon interpersonal trust in a controlled laboratory experiment
using three different videoconferencing settings: (1) a handheld tablet controlled
by a local user, (2) an embodied system controlled by a local user, and (3) an embodied
system controlled by a remote user (n = 29 dyads). We found that physical embodiment
and control by the local user increased the amount of trust built between partners.
These results suggest that both physical embodiment and control of the system influence
interpersonal trust in mediated communication and have implications for future system
designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1921–1930},
numpages = {10},
keywords = {robot-mediated communication, trust, control, embodiment, videoconferencing, computer-mediated communication, computer-supported collaborative work},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250093,
author = {Busse, Daniela K.},
title = {Session Details: Papers: Design Research},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250093},
doi = {10.1145/3250093},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466255,
author = {Vermeulen, Jo and Luyten, Kris and van den Hoven, Elise and Coninx, Karin},
title = {Crossing the Bridge over Norman's Gulf of Execution: Revealing Feedforward's True Identity},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466255},
doi = {10.1145/2470654.2466255},
abstract = {Feedback and affordances are two of the most well-known principles in interaction
design. Unfortunately, the related and equally important notion of feedforward has
not been given as much consideration. Nevertheless, feedforward is a powerful design
principle for bridging Norman's Gulf of Execution. We reframe feedforward by disambiguating
it from related design principles such as feedback and perceived affordances, and
identify new classes of feedforward. In addition, we present a reference framework
that provides a means for designers to explore and recognize different opportunities
for feedforward.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1931–1940},
numpages = {10},
keywords = {feedforward, theory, design, affordances, feedback},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466256,
author = {O'Leary, Kathleen and Wobbrock, Jacob O. and Riskin, Eve A.},
title = {Q-Methodology as a Research and Design Tool for HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466256},
doi = {10.1145/2470654.2466256},
abstract = {A "discount" version of Q-methodology for HCI, called "HCI-Q", can be used in iterative
design cycles to explore, from the point of view of users and other stakeholders,
what makes technologies personally significant. Initially, designers critically reflect
on their own assumptions about how a design may affect social and individual behavior.
Then, designers use these assumptions as stimuli to elicit other people's points of
view. This process of critical self-reflection and evaluation helps the designer to
assess the fit between a design and its intended social context of use. To demonstrate
the utility of HCI-Q for research and design, we use HCI-Q to explore stakeholders'
responses to a prototype Alternative and Augmentative Communication (AAC) application
called Vid2Speech. We show that our adaptation of Q-methodology is useful for revealing
the structure of consensus and conflict among stakeholder perspectives, helping to
situate design within the context of relevant value tensions and norms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1941–1950},
numpages = {10},
keywords = {user studies, personal significance, qualitative methods, design methodology, quantitative methods, psychology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466257,
author = {Roedl, David J. and Stolterman, Erik},
title = {Design Research at CHI and Its Applicability to Design Practice},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466257},
doi = {10.1145/2470654.2466257},
abstract = {This note describes our analysis of 35 papers from CHI 2011 that aim to improve or
support interaction design practice. In our analysis, we characterize how these CHI
authors conceptualize design practice and the types of contributions they propose.
This work is motivated by the recognition that design methods proposed by HCI researchers
often do not fit the needs and constraints of professional design practice. As a complement
to the analysis of the CHI papers we also interviewed 13 practitioners about their
attitudes towards learning new methods and approaches. We conclude the note by offering
some critical reflections about how HCI research can better support actual design
practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1951–1954},
numpages = {4},
keywords = {interaction design, design practice, design research},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466258,
author = {Bauer, Jared S. and Kientz, Julie A.},
title = {DesignLibs: A Scenario-Based Design Method for Ideation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466258},
doi = {10.1145/2470654.2466258},
abstract = {Generating potential design ideas through ideation often benefits from the spontaneity
of random ideas. Having potential users participate in this process can be beneficial,
but is often difficult to implement. We present a new method for generating design
ideas with potential users. The method uses scenarios with missing words, which potential
users fill in to generate ideas for features and attributes of new technology designs,
similar to the children's game of Mad Libs. We developed three different formats of
DesignLibs, including 1) "Mad Libs-style": blanks presented before seeing the scenario,
2) "Fill-in-the-Blanks": blanks presented within the context of the scenario, and
3) "Q&amp;A": blanks presented as questions and answers. We found that Design-Libs generated
a number of new ideas, with the Fill-in-the-Blanks method providing the highest ratings
for usefulness, feasibility, and diversity of answers. All three formats provided
equal ratings for creativity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1955–1958},
numpages = {4},
keywords = {ideation, user-centered design, scenarios, design methods},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250094,
author = {Froehlich, Jon},
title = {Session Details: Papers: Developing the World},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250094},
doi = {10.1145/3250094},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466260,
author = {Wyche, Susan P. and Murphy, Laura L.},
title = {Powering the Cellphone Revolution: Findings from Mobile Phone Charging Trials in off-Grid Kenya},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466260},
doi = {10.1145/2470654.2466260},
abstract = {Can human-powered devices solve the electricity gap for the millions of rural Africans
adopting mobile phones? Findings from our long-term evaluation of two personal crank-based
charging systems in Kenya reveal that small hand and leg-powered devices do have potential
to meet the needs of rural mobile phone users. Unfortunately, device breakage, theft
and incompatibility with handsets, coupled with lack of consumer credit and poorly
functioning markets for these goods mean these represent only a partial solution to
the mobile phone charging problem. Drawing from our fieldwork, we motivate a HCI4D/ICTD
design and evaluation agenda that better accounts for unique individuals' geographic,
financial, and economic circumstances or their human computer ecosystem. Key strategies
for implementing this agenda are engaging with diverse users on their own terms and
conducting long-term qualitative evaluations to reveal how acceptance and usability
change over time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1959–1968},
numpages = {10},
keywords = {design, off-grid power, mobile phones, human factors, hci4d/ictd, rural africa, human-powered},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466261,
author = {Shrinivasan, Yedendra B. and Jain, Mohit and Seetharam, Deva P. and Choudhary, Abhishek and Huang, Elaine M. and Dillahunt, Tawanna and Mankoff, Jennifer},
title = {Deep Conservation in Urban India and Its Implications for the Design of Conservation Technologies},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466261},
doi = {10.1145/2470654.2466261},
abstract = {Rapid depletion of fossil fuels and water resources has become an international problem.
Urban residential households are among the primary consumers of resources and are
deeply affected by resource shortages. Despite the global nature of these problems,
most of the solutions being developed to address these issues are based on studies
done in the developed world. We present a study of energy, water and fuel conservation
practices in urban India. Our study highlights a culture of deep conservation and
the results raise questions about the viability of typical solutions such as home
energy monitors. We identify new opportunities for design such as point-of-use feedback
technologies, modular solutions, distributed energy storage, harnessing by-products
and automated load shifting.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1969–1978},
numpages = {10},
keywords = {sustainability, energy, ict4d, developing world},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466262,
author = {Wulf, Volker and Aal, Konstantin and Abu Kteish, Ibrahim and Atam, Meryem and Schubert, Kai and Rohde, Markus and Yerousis, George P. and Randall, David},
title = {Fighting against the Wall: Social Media Use by Political Activists in a Palestinian Village},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466262},
doi = {10.1145/2470654.2466262},
abstract = {We analyze practices of political activists in a Palestinian village located in the
West Bank. Activists organize weekly demonstrations against Israel's settlement policy
and the separation wall. Over a period of 28 months, we conducted a field study consisting
of eight days 'on the ground' observation and interviewing, and extensive monitoring
of Internet communication. We describe the activists' background and their efforts
to organize these demonstrations under conditions of military occupation. Over time,
we observe the role both digital and material factors play in the organization of
protest. Specifically, we analyze how Email and Facebook were appropriated to facilitate
interaction 'on the ground'.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1979–1988},
numpages = {10},
keywords = {field study, social media, appropriation, political protest},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466263,
author = {Kumar, Neha and Rangaswamy, Nimmi},
title = {The Mobile Media Actor-Network in Urban India},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466263},
doi = {10.1145/2470654.2466263},
abstract = {Building on a growing body of human-computer interaction (HCI) literature on information
and communication technology (ICT) use in the developing world, this paper describes
the vast, growing mobile media consumption culture in India, which relies on the ubiquity
of informal socioeconomic practices for reproducing, sharing, and distributing pirated
digital media. Using an Actor-Network Theory (ANT) based approach, we show how piracy
not only fuels media consumption, but also drives further technology adoption and
promotes digital literacy. To do this, we first uncover the role of piracy as a legitimate
actor that brings ICT capability to underserved communities and reveal the heterogeneous
character of the pirated mobile media distribution and consumption infrastructure
in India. We then emphasize the benefits of an ANT-based theory-driven analysis to
HCI's efforts in this arena. In particular, ANT enables us to one, draw attention
to the ties in the pirate media network that facilitate the increased decentralization
of piracy in India; two, highlight the progressive transition from the outsourcing
to the self-sourcing of users' media needs as this network evolves; and three, recognize
the agency of human and non-human entities in this inherently sociotechnical ecosystem.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1989–1998},
numpages = {10},
keywords = {mobile, ictd, actor-network theory, media, hci4d, piracy, entertainment},
location = {Paris, France},
series = {CHI '13}
}


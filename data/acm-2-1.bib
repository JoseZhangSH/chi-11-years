@inproceedings{10.1145/3313831.3376362,
author = {Lattie, Emily G. and Kornfield, Rachel and Ringland, Kathryn E. and Zhang, Renwen and Winquist, Nathan and Reddy, Madhu},
title = {Designing Mental Health Technologies That Support the Social Ecosystem of College Students},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376362},
doi = {10.1145/3313831.3376362},
abstract = {The last decade has seen increased reports of mental health problems among college
students, with college counseling centers struggling to keep up with the demand for
services. Digital mental health tools offer a potential solution to expand the reach
of mental health services for college students. In this paper, we present findings
from a series of design activities conducted with college students and counseling
center staff aimed at identifying needs and preferences for digital mental health
tools. Results emphasize the social ecosystems and social support networks in a college
student's life. Our findings highlight the predominant role of known peers, and the
ancillary roles of unknown peers and non-peers (e.g., faculty, family) in influencing
the types of digital mental health tools students desire, and the ways in which they
want to learn about mental health tools. We identify considerations for designing
digital mental health tools for college students that take into account the identified
social factors and roles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {user centered design, college students, mental health, co-design, support technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376363,
author = {Hui, Julie and Barber, Nefer Ra and Casey, Wendy and Cleage, Suzanne and Dolley, Danny C. and Worthy, Frances and Toyama, Kentaro and Dillahunt, Tawanna R.},
title = {Community Collectives: Low-Tech Social Support for Digitally-Engaged Entrepreneurship},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376363},
doi = {10.1145/3313831.3376363},
abstract = {With the rise of social media, entrepreneurs are feeling the pressure to adopt digital
tools for their work. However, the upfront effort and resources needed to participate
on these platforms is ever more complex, particularly in underresourced contexts.
Through participatory action research over two years in Detroit's Eastside, we found
that local entrepreneurs preferred to become engaged digitally through a community
collective, which involved (a) resource-connecting organizations, (b) regular in-person
meetings, (c) paper planning tools, and (d) practice and validation. Together, these
elements combined to provide (1) awareness and willingness to use digital tools, (2)
regular opportunities to build internet self-efficacy, and (3) ways to collectively
overcome digital obstacles. We discuss our findings in the context of digital engagement
and entrepreneurship, and outline recommendations for digital platforms seeking to
better support economic mobility more broadly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {community informatics, digital divide, participatory action research, qualitative methods, digital literacy, entrepreneurship},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376364,
author = {Pschetz, Larissa and Dixon, Billy and Pothong, Kruakae and Bailey, Arlene and Glean, Allister and Soares, Luis Louren\c{c}o and Enright, Jessica A.},
title = {Designing Distributed Ledger Technologies for Social Change: The Case of CariCrop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376364},
doi = {10.1145/3313831.3376364},
abstract = {Distributed ledger technologies (DLTs) have been celebrated for promoting transparency,
trust, and efficiency in several domains. However, recent research has also pointed
out the potential of these technologies to increase power asymmetries and deepen social
inequality. In this paper, we contribute to this discussion by reporting on a collective
effort of academics, development partners, local authorities, businesses, and farming
groups to look at the potential of DLTs, particularly Blockchains, to support socio-economic
development in rural communities in the Caribbean. We present a series of design concepts
resulting from this effort and reflect on a method to facilitate stakeholders' experience
of possible implementations and enable them to voice concerns, preferences, and expectations.
Results from workshops with different groups of stakeholders contribute insights into
opportunities and limitations of these applications to enable social development and
to level the playing field in agricultural exchanges in developing countries.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {agricultural development, blockchain, farming, distributed ledger technologies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376365,
author = {Karduni, Alireza and Wesslen, Ryan and Cho, Isaac and Dou, Wenwen},
title = {Du Bois Wrapped Bar Chart: Visualizing Categorical Data with Disproportionate Values},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376365},
doi = {10.1145/3313831.3376365},
abstract = {We propose a visualization technique, Du Bois wrapped bar chart, inspired by work
of W.E.B Du Bois. Du Bois wrapped bar charts enable better large-to-small bar comparison
by wrapping large bars over a certain threshold. We first present two crowdsourcing
experiments comparing wrapped and standard bar charts to evaluate (1) the benefit
of wrapped bars in helping participants identify and compare values; (2) the characteristics
of data most suitable for wrapped bars. In the first study (n=98) using real-world
datasets, we find that wrapped bar charts lead to higher accuracy in identifying and
estimating ratios between bars. In a follow-up study (n=190) with 13 simulated datasets,
we find participants were consistently more accurate with wrapped bar charts when
certain category values are disproportionate as measured by entropy and H-spread.
Finally, in an in-lab study, we investigate participants' experience and strategies,
leading to guidelines for when and how to use wrapped bar charts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {evaluation, mechanical turk, user study, bar chart, crowdsourcing, graphical perception, information visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376366,
author = {Nittala, Aditya Shekhar and Khan, Arshad and Kruttwig, Klaus and Kraus, Tobias and Steimle, J\"{u}rgen},
title = {PhysioSkin: Rapid Fabrication of Skin-Conformal Physiological Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376366},
doi = {10.1145/3313831.3376366},
abstract = {Advances in rapid prototyping platforms have made physiological sensing accessible
to a wide audience. However, off-the-shelf electrodes commonly used for capturing
biosignals are typically thick, non-conformal and do not support customization. We
present PhysioSkin, a rapid, do-it-yourself prototyping method for fabricating custom
multi-modal physiological sensors, using commercial materials and a commodity desktop
inkjet printer. It realizes ultrathin skin-conformal patches (~1μm) and interactive
textiles that capture sEMG, EDA and ECG signals. It further supports fabricating devices
with custom levels of thickness and stretchability. We present detailed fabrication
explorations on multiple substrate materials, functional inks and skin adhesive materials.
Informed from the literature, we also provide design recommendations for each of the
modalities. Evaluation results show that the sensor patches achieve a high signal-to-noise
ratio. Example applications demonstrate the functionality and versatility of our approach
for prototyping a next generation of physiological devices that intimately couple
with the human body.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {fabrication, ink-jet printing, physiological sensing, rapid prototyping, e-textile, wearable devices, electronic skin},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376367,
author = {Yang, Yalong and Marriott, Kim and Butler, Matthew and Goncu, Cagatay and Holloway, Leona},
title = {Tactile Presentation of Network Data: Text, Matrix or Diagram?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376367},
doi = {10.1145/3313831.3376367},
abstract = {Visualisations are commonly used to understand social, biological and other kinds
of networks. Currently we do not know how to effectively present network data to people
who are blind or have low-vision (BLV). We ran a controlled study with 8 BLV participants
comparing four tactile representations: organic node-link diagram, grid node-link
diagram, adjacency matrix and braille list. We found that the node-link representations
were preferred and more effective for path following and cluster identification while
the matrix and list were better for adjacency tasks. This is broadly in line with
findings for the corresponding visual representations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {blindness, vision impairment, accessibility, graphvisualization, adjacency matrix},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376368,
author = {Meena, Yogesh Kumar and Seunarine, Krishna and Sahoo, Deepak Ranjan and Robinson, Simon and Pearson, Jennifer and Zhang, Chi and Carnie, Matt and Pockett, Adam and Prescott, Andrew and Thomas, Suzanne K. and Lee, Harrison Ka Hin and Jones, Matt},
title = {PV-Tiles: Towards Closely-Coupled Photovoltaic and Digital Materials for Useful, Beautiful and Sustainable Interactive Surfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376368},
doi = {10.1145/3313831.3376368},
abstract = {The interactive, digital future with its seductive vision of Internet-of-Things connected
sensors, actuators and displays comes at a high cost in terms of both energy demands
and the clutter it brings to the physical world. But what if such devices were made
of materials that enabled them to self-power their interactive features? And, what
if those materials were directly used to build aesthetically pleasing environments
and objects that met practical physical needs as well as digital ones? In this paper
we introduce PV-Tiles ? a novel material that closely couples photovoltaic energy
harvesting and light sensing materials with digital interface components. We consider
potential contexts, use-cases and light gestures surfaced through co-creation workshops;
and, present initial technological designs and prototypes. The work opens a new set
of opportunities and collaborations between HCI and material science, stimulating
technical and design pointers to accommodate and exploit the material's properties.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {connected home, sustainability, self-powered devices, internet of things, interaction design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376369,
author = {Avrahami, Daniel and Williams, Kristin and Lee, Matthew L. and Tokunaga, Nami and Tjahjadi, Yulius and Marlow, Jennifer},
title = {Celebrating Everyday Success: Improving Engagement and Motivation Using a System for Recording Daily Highlights},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376369},
doi = {10.1145/3313831.3376369},
abstract = {The demands of daily work offer few opportunities for workers to take stock of their
own progress, big or small, which can lead to lower motivation, engagement, and higher
risk of burnout. We present Highlight Matome, a personal online tool that encourages
workers to quickly record and rank a single work highlight each day, helping them
gain awareness of their own successes. We describe results from a field experiment
investigating our tool's effectiveness for improving workers' engagement, perceptions,
and affect. Thirty-three knowledge workers in Japan and the U.S. used Highlight Matome
for six weeks. Our results show that using our tool for less than one minute each
day significantly increased measures of work engagement, dedication, and positivity.
A qualitative analysis of the highlights offers a window into participants' emotions
and perceptions. We discuss implications for theories of inner work life and worker
well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {well-being, work engagement, knowledge workers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376370,
author = {Honary, Mahsa and Bell, Beth and Clinch, Sarah and Vega, Julio and Kroll, Leo and Sefi, Aaron and McNaney, Roisin},
title = {Shaping the Design of Smartphone-Based Interventions for Self-Harm},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376370},
doi = {10.1145/3313831.3376370},
abstract = {Self-harm is a prevalent issue amongst young people, yet it is thought around 40%
will never seek professional help due to stigma surrounding it. It is generally a
way of coping with emotional distress and can have a range of triggers which are highly
heterogeneous to the individual. In a move towards enhancing the accessibility of
personalized interventions for self-harm, we undertook a three-stage study. We first
conducted interviews with 4 counsellors in self-harm to understand how they clinically
respond to self-harm triggers. We then ran a survey with 37 young people, to explore
perceptions of mobile sensing, and current and future uses for smartphone-based interventions.
Finally, we ran a workshop with 11 young people to further explore how a context-aware
self-management application might be used to support them. We contribute an in-depth
understanding of how triggers for self-harm might be identified and subsequently predicted
and prevented using mobile-sensing technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {situation-aware app, mobile sensing, trust, intervention, non-suicidal self-injury, co-design, mental health, self-harm},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376371,
author = {Yoo, Soojeong and Gough, Phillip and Kay, Judy},
title = {Embedding a VR Game Studio in a Sedentary Workplace: Use, Experience and Exercise Benefits},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376371},
doi = {10.1145/3313831.3376371},
abstract = {Many people, especially those in sedentary occupations, fail to achieve the recommended
levels of physical activity. Virtual reality (VR) games have the potential to overcome
this because they are fun and also can be physically demanding. This paper explores
whether a VR game studio can help workers in sedentary jobs to get valuable levels
of exercise. We studied how 11 participants used our VR game studio in a sedentary
workplace over 8-weeks and their perceptions of the experience. We analysed the physical
exertion in the VR game studio, comparing this to their step counts from a smartwatch.
All participants achieved valuable levels of physical activity and mood benefits.
Importantly, for 6 participants, only with the VR game studio did they meet recommended
activity levels. Our key contributions are insights about the use of a workplace VR
game studio and its health benefits.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {head-mounted display, exercise, virtual reality game, sedentary workplace},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376372,
author = {Kontogiorgos, Dimosthenis and van Waveren, Sanne and Wallberg, Olle and Pereira, Andre and Leite, Iolanda and Gustafson, Joakim},
title = {Embodiment Effects in Interactions with Failing Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376372},
doi = {10.1145/3313831.3376372},
abstract = {The increasing use of robots in real-world applications will inevitably cause users
to encounter more failures in interactions. While there is a longstanding effort in
bringing human-likeness to robots, how robot embodiment affects users' perception
of failures remains largely unexplored. In this paper, we extend prior work on robot
failures by assessing the impact that embodiment and failure severity have on people's
behaviours and their perception of robots. Our findings show that when using a smart-speaker
embodiment, failures negatively affect users' intention to frequently interact with
the device, however not when using a human-like robot embodiment. Additionally, users
significantly rate the human-like robot higher in terms of perceived intelligence
and social presence. Our results further suggest that in higher severity situations,
human-likeness is distracting and detrimental to the interaction. Drawing on quantitative
findings, we discuss benefits and drawbacks of embodiment in robot failures that occur
in guided tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {guided tasks, common ground, conversational failures, social robots, time pressure, smart-speakers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376373,
author = {Adams, Alexander T. and Mandel, Ilan and Shats, Anna and Robin, Alina and Choudhury, Tanzeem},
title = {PuffPacket: A Platform for Unobtrusively Tracking the Fine-Grained Consumption Patterns of E-Cigarette Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376373},
doi = {10.1145/3313831.3376373},
abstract = {The proliferation of e-cigarettes and portable vaporizers presents new opportunities
for accurately and unobtrusively tracking e-cigarette use. PuffPacket is a hardware
and soft-ware research platform that leverages the technology built into vaporizers,
e-cigarettes and other electronic drug delivery devices to ubiquitously track their
usage. The system piggybacks on the signals these devices use to directly measure
and track the nicotine consumed by users. PuffPacket augments e-cigarettes with Bluetooth
to calculate the frequency, intensity, and duration of each inhalation. This information
is augmented with smartphone-based location and activity information to help identify
potential contextual triggers. Puff-Packet is generalizable to a wide variety of electronic
nicotine,THC, and other drug delivery devices currently on the mar-ket. The hardware
and software for PuffPacket is open-source so it can be expanded upon and leveraged
for mobile health tracking research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {topology, addiction, e-cigarettes, health, ends, sud, mobile sensing, research platform},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376374,
author = {Jiang, Xinlong and Chen, Yiqiang and Huang, Wuliang and Zhang, Teng and Gao, Chenlong and Xing, Yunbing and Zheng, Yi},
title = {WeDA: Designing and Evaluating A Scale-Driven Wearable Diagnostic Assessment System for Children with ADHD},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376374},
doi = {10.1145/3313831.3376374},
abstract = {Attention Deficit Hyperactivity Disorder (ADHD) is one of the most common mental disorders
affecting children. Because the etiology of ADHD is complex and its symptoms are not
specific, there is a lack of feasible quantitative diagnostic methods. Pursuing objective
and non-invasive detection methods and standards is of great practical significance
to prevent the development of the disease. In this study, we aim to address one specific
concern about the objectivity and quantification of ADHD diagnosis. Over a year, we
iteratively designed and tested WeDA, a scale-driven wearable diagnostic assessment
system. This system contains an Android computer machine with a large touchscreen,
a suite of 3D printed interactive devices, and six wearable motion sensors. We implement
ten diagnostic tasks drawing on the symptoms of ADHD based on DSM-5. The experimental
results of classifying children with ADHD and typically developing children and subjective
evaluations from doctors, parents, and children validate the effectiveness and acceptability
of WeDA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {scale-driven, neurodevelopmental disorder, wearable computing, diagnostic assessment, attention deficit hyperactivity disorder (adhd)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376375,
author = {Huffaker, Jordan S. and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Ackerman, Mark S.},
title = {Crowdsourced Detection of Emotionally Manipulative Language},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376375},
doi = {10.1145/3313831.3376375},
abstract = {Detecting rhetoric that manipulates readers' emotions requires distinguishing intrinsically
emotional content (IEC; e.g., a parent losing a child) from emotionally manipulative
language (EML; e.g., using fear-inducing language to spread anti-vaccine propaganda).
However, this remains an open classification challenge for both automatic and crowdsourcing
approaches. Machine Learning approaches only work in narrow domains where labeled
training data is available, and non-expert annotators tend to conflate IEC with EML.
We introduce an approach, anchor comparison, that leverages workers' ability to identify
and remove instances of EML in text to create a paraphrased "anchor text", which is
then used as a comparison point to classify EML in the original content. We evaluate
our approach with a dataset of news-style text snippets and show that precision and
recall can be tuned for system builders' needs. Our contribution is a crowdsourcing
approach that enables non-expert disentanglement of social references from content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {rhetoric, emotion, media manipulation, crowdsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376376,
author = {Valencia, Stephanie and Pavel, Amy and Santa Maria, Jared and Yu, Seunga (Gloria) and Bigham, Jeffrey P. and Admoni, Henny},
title = {Conversational Agency in Augmentative and Alternative Communication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376376},
doi = {10.1145/3313831.3376376},
abstract = {Augmented communicators (ACs) use augmentative and alternative communication (AAC)
technologies to speak. Prior work in AAC research has looked to improve efficiency
and expressivity of AAC via device improvements and user training. However, ACs also
face constraints in communication beyond their device and individual abilities such
as when they can speak, what they can say, and who they can address. In this work,
we recast and broaden this prior work using conversational agency as a new frame to
study AC communication. We investigate AC conversational agency with a study examining
different conversational tasks between four triads of expert ACs, their close conversation
partners (paid aide or parent), and a third party (experimenter). We define metrics
to analyze AAC conversational agency quantitatively and qualitatively. We conclude
with implications for future research to enable ACs to easily exercise conversational
agency.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {conversation, agency, accessibility, aac, cerebral palsy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376377,
author = {Sarma, Abhraneel and Kay, Matthew},
title = {Prior Setting in Practice: Strategies and Rationales Used in Choosing Prior Distributions for Bayesian Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376377},
doi = {10.1145/3313831.3376377},
abstract = {Bayesian statistical analysis is steadily growing in popularity and use. Choosing
priors is an integral part of Bayesian inference. While there exist extensive normative
recommendations for prior setting, little is known about how priors are chosen in
practice. We conducted a survey (N = 50) and interviews (N = 9) where we used interactive
visualizations to elicit prior distributions from researchers experienced withBayesian
statistics and asked them for rationales for those priors. We found that participants'
experience and philosophy influence how much and what information they are willing
to incorporate into their priors, manifesting as different levels of informativeness
and skepticism. We also identified three broad strategies participants use to set
their priors: centrality matching, interval matching, and visual mass allocation.
We discovered that participants' understanding of the notion of 'weakly informative
priors"-a commonly-recommended normative approach to prior setting-manifests very
differently across participants. Our results have implications both for how to develop
prior setting recommendations and how to design tools to elicit priors in Bayesian
analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {descriptive analysis, prior distributions, bayesian inference},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376378,
author = {Lam, Amy T. and Griffin, Jonathan and Loeun, Matthew Austin and Cira, Nate J. and Lee, Seung Ah and Riedel-Kruse, Ingmar H.},
title = {Pac-Euglena: A Living Cellular Pac-Man Meets Virtual Ghosts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376378},
doi = {10.1145/3313831.3376378},
abstract = {The advancement of biotechnology enabled the development of "biotic video games",
where human players manipulate real biological samples for fun and educational human-biology
interactions. However, new design principles are needed to both leverage and mitigate
biological properties (e.g., variability and stochasticity), and create unique play
experiences that transcend traditional video games. This paper describes the implementation
of Pac-Euglena, a biotic Pac-Man analog, where players guide live microscopic Euglena
cells with light stimuli through a physical microfluidic maze. Through use of multi-modal
stimuli, a mixed biology-digital-human reality is achieved, enabling cell interactions
with virtual ghosts and collectibles. Through an iterative design process, we illustrate
challenges and strategies for designing games with living organisms. A user study
(n=18, conducted at a university event) showed that Pac-Euglena was fun, stimulated
curiosity, and taught users about Euglena. We conclude with five general guidelines
for the design and development of biotic games and HBI interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {biological user interfaces, human-biology interaction (hbi), euglena gracilis, augmented reality, mixed reality, biotic games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376379,
author = {Gr\o{}nb\ae{}k, Jens Emil and Knudsen, Mille Skovhus and O'Hara, Kenton and Krogh, Peter Gall and Vermeulen, Jo and Petersen, Marianne Graves},
title = {Proxemics Beyond Proximity: Designing for Flexible Social Interaction Through Cross-Device Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376379},
doi = {10.1145/3313831.3376379},
abstract = {Cross-device interactions enable ad hoc sharing of content and control in co-located
collaboration. Cross-device research often draws from proxemics theory for designing
interactions based on detection of spatial relations such as distance and orientation
between people and devices. However, detection of human-human or human-device proximity
also constrains flexibility in co-located social interaction. We suggest a proxemics-based
approach to designing flexible cross-device interactions. From observations in a field
study, we articulate how co-located sharing practices are shaped by the interplay
between everyday mobile devices and the physical environment. Based on these insights,
we present three cross-device prototypes as proofs-of-concept, demonstrating three
design sensitivities for considering proxemics beyond proximity; incorporating features
in the environment, enabling flexibility in interpersonal distance and orientation,
and providing multiple alternative action possibilities. Drawing from characteristics
of our prototypes, we discuss concrete proposals for designing cross-device interactions
to enable flexible social interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sensing systems, proximity sensing, cross-device interaction, interaction proxemics, ad hoc collaboration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376380,
author = {Yen, Yu-Chun Grace and Kim, Joy O. and Bailey, Brian P.},
title = {Decipher: An Interactive Visualization Tool for Interpreting Unstructured Design Feedback from Multiple Providers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376380},
doi = {10.1145/3313831.3376380},
abstract = {Feedback from diverse audiences can vary in focus, differ in structure, and contradict
each other, making it hard to interpret and act on. While prior work has explored
generating quality feedback, our work helps a designer interpret that feedback. Through
a formative study with professional designers (N=10), we discovered that the interpretation
process includes categorizing feedback, identifying valuable feedback, and prioritizing
which feedback to incorporate in a revision. We also found that designers leverage
feedback topic and sentiment, and the status of the provider to aid interpretation.
Based on the findings, we created a new tool (Decipher) that enables designers to
visualize and navigate a collection of feedback using its topic and sentiment structure.
In a preliminary evaluation (N=20), we found that Decipher helped users feel less
overwhelmed during feedback interpretation tasks and better attend to critical issues
and conflicting opinions compared to using a typical document-editing tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {creativity, feedback, sense-making, creativity support tools},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376381,
author = {Nobre, Carolina and Wootton, Dylan and Harrison, Lane and Lex, Alexander},
title = {Evaluating Multivariate Network Visualization Techniques Using a Validated Design and Crowdsourcing Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376381},
doi = {10.1145/3313831.3376381},
abstract = {Visualizing multivariate networks is challenging because of the trade-offs necessary
for effectively encoding network topology and encoding the attributes associated with
nodes and edges. A large number of multivariate network visualization techniques exist,
yet there is little empirical guidance on their respective strengths and weaknesses.
In this paper, we describe a crowdsourced experiment, comparing node-link diagrams
with on-node encoding and adjacency matrices with juxtaposed tables. We find that
node-link diagrams are best suited for tasks that require close integration between
the network topology and a few attributes. Adjacency matrices perform well for tasks
related to clusters and when many attributes need to be considered. We also reflect
on our method of using validated designs for empirically evaluating complex, interactive
visualizations in a crowdsourced setting. We highlight the importance of training,
compensation, and provenance tracking.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {multivariate networks visualization, crowdsourced evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376382,
author = {Zhang, Tianyi and Hartmann, Bj\"{o}rn and Kim, Miryung and Glassman, Elena L.},
title = {Enabling Data-Driven API Design with Community Usage Data: A Need-Finding Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376382},
doi = {10.1145/3313831.3376382},
abstract = {APIs are becoming the fundamental building block of modern software and their usability
is crucial to programming efficiency and software quality. Yet API designers find
it hard to gather and interpret user feedback on their APIs. To close the gap, we
interviewed 23 API designers from 6 companies and 11 open-source projects to understand
their practices and needs. The primary way of gathering user feedback is through bug
reports and peer reviews, as formal usability testing is prohibitively expensive to
conduct in practice. Participants expressed a strong desire to gather real-world use
cases and understand users' mental models, but there was a lack of tool support for
such needs. In particular, participants were curious about where users got stuck,
their workarounds, common mistakes, and unanticipated corner cases. We highlight several
opportunities to address those unmet needs, including developing new mechanisms that
systematically elicit users' mental models, building mining frameworks that identify
recurring patterns beyond shallow statistics about API usage, and exploring alternative
design choices made in similar libraries.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {community, tool support, api design, information needs},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376383,
author = {Im, Jane and Tandon, Sonali and Chandrasekharan, Eshwar and Denby, Taylor and Gilbert, Eric},
title = {Synthesized Social Signals: Computationally-Derived Social Signals from Account Histories},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376383},
doi = {10.1145/3313831.3376383},
abstract = {Social signals are crucial when we decide if we want to interact with someone online.
However, social signals are typically limited to the few that platform designers provide,
and most can be easily manipulated. In this paper, we propose a new idea called synthesized
social signals (S3s): social signals computationally derived from an account's history,
and then rendered into the profile. Unlike conventional social signals such as profile
bios, S3s use computational summarization to reduce receiver costs and raise the cost
of faking signals. To demonstrate and explore the concept, we built Sig, an extensible
Chrome extension that computes and visualizes S3s. After a formative study, we conducted
a field deployment of Sig on Twitter, targeting two well-known problems on social
media: toxic accounts and misinformation. Results show that Sig reduced receiver costs,
added important signals beyond conventionally available ones, and that a few users
felt safer using Twitter as a result. We conclude by reflecting on the opportunities
and challenges S3s provide for augmenting interaction on social platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social computing, social signals, social platform, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376385,
author = {Bitton, Ron and Boymgold, Kobi and Puzis, Rami and Shabtai, Asaf},
title = {Evaluating the Information Security Awareness of Smartphone Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376385},
doi = {10.1145/3313831.3376385},
abstract = {Information security awareness (ISA) is a practice focused on the set of skills which
help a user successfully mitigate social engineering (SE) attacks. Evaluating the
ISA of users is crucial, since early identification of users who are more vulnerable
to SE attacks improves system security. Previous studies for evaluating the ISA of
smartphone users rely on subjective data sources (questionnaires) and do not address
the differences between classes of SE attacks. This paper presents a framework for
evaluating the ISA of smartphone users for specific attack classes. In addition to
questionnaires, we utilize objective data sources: a mobile agent, a network traffic
monitor, and cybersecurity challenges. We evaluated the framework by conducting a
long-term user study involving 162 users. The results show that: the self-reported
behavior of users differs significantly from their actual behavior and the ISA level
derived from the actual behavior of users is highly correlated with their ability
to mitigate SE attacks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile devices, information security awareness, social engineering, human factors},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376386,
author = {Bellini, Rosanna and Forrest, Simon and Westmarland, Nicole and Jackson, Dan and Smeddinck, Jan David},
title = {Choice-Point: Fostering Awareness and Choice with Perpetrators in Domestic Violence Interventions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376386},
doi = {10.1145/3313831.3376386},
abstract = {Learning about alternatives to violence is an essential part of change work with domestic
violence perpetrators. This is complex work, seeking to tackle a sensitive issue by
involving the development of deep, embodied learning for perpetrators who may lack
perspective on their behaviour. Interactive storytelling has been providing users
with the opportunity to explore speculative scenarios in a controlled environment.
We discuss the design of Choice-Point: a web-based application that allows perpetrators
adopt the role of different fictional characters in an abusive scenario for conveying
the essential skill of perspective-taking. We evaluated Choice-Point through trials
with three groups of perpetrators, a support group of victim-survivors and an expert
critique from support workers. We discuss challenges in using such technologies -
such as our system - for engagement; the value of perpetrator agency in supporting
non-violent behaviours, and the potential to positively shape perpetrators' journeys
to non-violence within social care settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {family violence, domestic violence, intimate partner violence, batterers intervention programmes, domestic violence prevention programmes, interactive storytelling, third-sector},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376387,
author = {Zhang, Hechuan and Chen, Zhiyong and Guo, Shihui and Lin, Juncong and Shi, Yating and Liu, Xiangyang and Ma, Yong},
title = {Sensock: 3D Foot Reconstruction with Flexible Sensors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376387},
doi = {10.1145/3313831.3376387},
abstract = {Capturing 3D foot models is important for applications such as manufacturing customized
shoes and creating clubfoot orthotics. In this paper, we propose a novel prototype,
Sensock, to offer a fully wearable solution for the task of 3D foot reconstruction.
The prototype consists of four soft stretchable sensors, made from silk fibroin yarn.
We identify four characteristic foot girths based on the existing knowledge of foot
anatomy, and measure their lengths with the resistance value of the stretchable sensors.
A learning-based model is trained offline and maps the foot girths to the corresponding
3D foot shapes. We compare our method with existing solutions using red-green-blue
(RGB) or RGBD (RGB-depth) cameras, and show the advantages of our method in terms
of both efficiency and accuracy. In the user experiment, we find that the relative
error of Sensock is lower than 0.55%. It performs consistently across different trials
and is considered comfortable and suitable for long-term wearing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {flexible sensors, 3d reconstruction, foot modeling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376388,
author = {Spillane, Brendan and Hoe, Isla and Brady, Mike and Wade, Vincent and Lawless, S\'{e}amus},
title = {Tabloidization versus Credibility: Short Term Gain for Long Term Pain},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376388},
doi = {10.1145/3313831.3376388},
abstract = {Print news agencies have been under pressure from falling sales and advertising revenue
and increased competition. As the Internet became the dominant medium, news agencies
invested heavily in their websites and apps, providing their news for free, rather
than selling a print edition. Reducing the cost of production and removing access
barriers such as geographic location had the potential to increase readership and
advertising, covering costs and maintaining profits. Unfortunately, this business
model has for the most part failed. Many higher quality news agencies are now implementing
paywalls on their news websites to once again monetize their product. Others have
begun to emulate the look and feel of tabloid news websites to increase readership
and stickiness and advertising revenue. This study shows the negative impact of such
visual tabloidization on initial impressions of credibility, which may have long term
detrimental effects on the news agency.The authors would like to dedicate this paper
to the memory of Professor S\'{e}amus "Shay" Lawless, the supervisor of this work who
died on May 16th 2019 after fulfilling his dream of summiting Mount Everest.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {credibility, tabloidization, news website design, news website aesthetics, first impressions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376389,
author = {Colnago, Jessica and Feng, Yuanyuan and Palanivel, Tharangini and Pearman, Sarah and Ung, Megan and Acquisti, Alessandro and Cranor, Lorrie Faith and Sadeh, Norman},
title = {Informing the Design of a Personalized Privacy Assistant for the Internet of Things},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376389},
doi = {10.1145/3313831.3376389},
abstract = {Internet of Things (IoT) devices create new ways through which personal data is collected
and processed by service providers. Frequently, end users have little awareness of,
and even less control over, these devices' data collection. IoT Personalized Privacy
Assistants (PPAs) can help overcome this issue by helping users discover and, when
available, control the data collection practices of nearby IoT resources. We use semi-structured
interviews with 17 participants to explore user perceptions of three increasingly
more autonomous potential implementations of PPAs, identifying benefits and issues
associated with each implementation. We find that participants weigh the desire for
control against the fear of cognitive overload. We recommend solutions that address
users' differing automation preferences and reduce notification overload. We discuss
open issues related to opting out from public data collections, automated consent,
the phenomenon of user resignation, and designing PPAs with at-risk communities in
mind.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personalized privacy assistants, internet of things, inteviews},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376390,
author = {Yang, Saelyne and Lee, Changyoon and Shin, Hijung Valentina and Kim, Juho},
title = {Snapstream: Snapshot-Based Interaction in Live Streaming for Visual Art},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376390},
doi = {10.1145/3313831.3376390},
abstract = {Live streaming visual art such as drawing or using design software is gaining popularity.
An important aspect of live streams is the direct and real-time communication between
streamers and viewers. However, currently available text-based interaction limits
the expressiveness of viewers as well as streamers, especially when they refer to
specific moments or objects in the stream. To investigate the feasibility of using
snapshots of streamed content as a way to enhance streamer-viewer interaction, we
introduce Snapstream, a system that allows users to take snapshots of the live stream,
annotate them, and share the annotated snapshots in the chat. Streamers can also verbally
reference a specific snapshot during streaming to respond to viewers' questions or
comments. Results from live deployments show that participants communicate more expressively
and clearly with increased engagement using Snapstream. Participants used snapshots
to reference part of the artwork, give suggestions on it, make fun images or memes,
and log intermediate milestones. Our findings suggest that visual interaction enables
richer experiences in live streaming.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online interaction, chat interaction, context sharing, live streaming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376391,
author = {Kotut, Lindah and Horning, Michael and Stelter, Timothy L. and McCrickard, D. Scott},
title = {Preparing for the Unexpected: Community Framework for Social Media Use and Social Support by Trail Thru-Hikers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376391},
doi = {10.1145/3313831.3376391},
abstract = {A months-long hike of the Appalachian Trail often involve long-term preparation and
life-altering decisions. Would-be hikers leverage institutional knowledge from literature
and online forums to physically and mentally prepare for such an arduous hike. Their
use of social platforms provide useful insights on motivations for undertaking the
thru-hike, how they deal with unexpected conditions on the trail and understand choices
made in conditions of scarcity. By analyzing over 100,000 Reddit posts and comments
in r/AppalachianTrail and applying a Sense of Community theory, we sought to understand
hikers' identity as community members, how their emotional and practical needs are
met, and how they evolve. We found that the role and language of thru-hikers change
as they progress from pre-hike, on-hike, and post-hike stages, from a questioner early
on, to an expert post-hike. We conclude with design recommendations to support offline
communities online.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {rural computing, information seeking, appalachian trail, trail community, thru-hike, long-distance hiking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376392,
author = {Ogbonnaya-Ogburu, Ihudiya Finda and Smith, Angela D.R. and To, Alexandra and Toyama, Kentaro},
title = {Critical Race Theory for HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376392},
doi = {10.1145/3313831.3376392},
abstract = {The human-computer interaction community has made some efforts toward racial diversity,
but the outcomes remain meager. We introduce critical race theory and adapt it for
HCI to lay a theoretical basis for race-conscious efforts, both in research and within
our community. Building on the theory's original tenets, we argue that racism is pervasive
in everyday socio-technical systems; that the HCI community is prone to "interest
convergence", where concessions to inclusion require benefits to those in power; and
that the neoliberal underpinnings of the technology industry itself propagate racism.
Critical race theory uses storytelling as a means to upend deep-seated assumptions,
and we relate several personal stories to highlight ongoing problems of race in HCI.
The implications: all HCI research must be attuned to issues of race; participation
of underrepresented minorities must be sought in all of our activities; and as a community,
we cannot become comfortable while racial disparities exist.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {theory, race, storytelling, racism, critical race theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376393,
author = {Wong, Pui Chung and Zhu, Kening and Yang, Xing-Dong and Fu, Hongbo},
title = {Exploring Eyes-Free Bezel-Initiated Swipe on Round Smartwatches},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376393},
doi = {10.1145/3313831.3376393},
abstract = {Bezel-based gestures expand the interaction space of touch-screen devices (e.g., smartphones
and smartwatches). Existing works have mainly focused on bezel-initiated swipe (BIS)
on square screens. To investigate the usability of BIS on round smartwatches, we design
six different circular bezel layouts, by dividing the bezel into 6, 8, 12, 16, 24,
and 32 segments. We evaluate the user performance of BIS on these layouts in an eyes-free
situation. The results show that the performance of BIS is highly orientation dependent,
and varies significantly among users. Using the Support-Vector-Machine (SVM) model
significantly increases the accuracy on 6-, 8-, 12-, and 16-segment layouts. We then
compare the performance of personal and general SVM models, and find that personal
models significantly improve the accuracy for 8-, 12-, 16-, and 24-segment layouts.
Lastly, we discuss the potential smartwatch applications enabled by the BIS.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {bezel-initiated gestures, bezel, eyes-free, round smartwatches},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376394,
author = {Duchowski, Andrew T. and Krejtz, Krzysztof and Gehrer, Nina A. and Bafna, Tanya and B\ae{}kgaard, Per},
title = {The Low/High Index of Pupillary Activity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376394},
doi = {10.1145/3313831.3376394},
abstract = {A novel eye-tracked measure of pupil diameter oscillation is derived as an indicator
of cognitive load. The new metric, termed the Low/High Index of Pupillary Activity
(LHIPA), is able to discriminate cognitive load (vis-a-vis task difficulty) in several
experiments where the Index of Pupillary Activity fails to do so. Rationale for the
LHIPA is tied to the functioning of the human autonomic nervous system yielding a
hybrid measure based on the ratio of Low/High frequencies of pupil oscillation. The
paper's contribution is twofold. First, full documentation is provided for the calculation
of the LHIPA. As with the IPA, it is possible for researchers to apply this metric
to their own experiments where a measure of cognitive load is of interest. Second,
robustness of the LHIPA is shown in analysis of three experiments, a restrictive fixed-gaze
number counting task, a less restrictive fixed-gaze n-back task, and an applied eye-typing
task.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {task difficulty, eye tracking, pupillometry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376395,
author = {Seifi, Hasti and Oppermann, Michael and Bullard, Julia and MacLean, Karon E. and Kuchenbecker, Katherine J.},
title = {Capturing Experts' Mental Models to Organize a Collection of Haptic Devices: Affordances Outweigh Attributes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376395},
doi = {10.1145/3313831.3376395},
abstract = {Humans rely on categories to mentally organize and understand sets of complex objects.
One such set, haptic devices, has myriad technical attributes that affect user experience
in complex ways. Seeking an effective navigation structure for a large online collection,
we elicited expert mental categories for grounded force-feedback haptic devices: 18
experts (9 device creators, 9 interaction designers) reviewed, grouped, and described
75 devices according to their similarity in a custom card-sorting study. From the
resulting quantitative and qualitative data, we identify prominent patterns of tagging
versus binning, and we report 6 uber-attributes that the experts used to group the
devices, favoring affordances over device specifications. Finally, we derive 7 device
categories and 9 subcategories that reflect the imperfect yet semantic nature of the
expert mental models. We visualize these device categories and similarities in the
online haptic collection, and we offer insights for studying expert understanding
of other human-centered technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information visualization, haptics, mental model, expert-sourced categorization, haptic hardware collection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376396,
author = {Kruzan, Kaylee Payne and Whitlock, Janis and Bazarova, Natalya N. and Miller, Katherine D. and Chapman, Julia and Won, Andrea Stevenson},
title = {Supporting Self-Injury Recovery: The Potential for Virtual Reality Intervention},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376396},
doi = {10.1145/3313831.3376396},
abstract = {In this paper, we explore the use of virtual reality (VR) in assisting individuals
who self-injure. Past work on self-injury in HCI has focused almost exclusively on
mobile applications and message boards. As VR systems become more common, it is worth
exploring what unique affordances of the technology can be leveraged to support self-injury
reduction and cessation. Research on VR intervention and self-injury treatment informed
the design of three novel virtual reality experiences. Nineteen interviews were conducted
with individuals with current, or a past history of, self-injury with the goals of
uncovering overall impressions of the perceived efficacy of VR with this population,
as well as better understanding key mechanisms which impact their experience. Our
analysis reveals four key elements common across all experiences: transportation,
embodiment, immersion/distraction, and sense of control, and additional themes within
each unique experience. We discuss the implications of these findings for future intervention
design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {intervention, self-injury, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376397,
author = {Park, Sun Young and Seo, Woosuk and Berry, Andrew B.L. and Kim, Hyeryoung and Verma, Sanya and Choi, Sung Won and Buyuktur, Ayse G.},
title = {Learning from Positive Adaptations of Pediatric Cancer Patients to Design Health Technologies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376397},
doi = {10.1145/3313831.3376397},
abstract = {The diagnosis of cancer brings about significant changes in the life of a child. In
addition to physical pain, pediatric patients face psychological and social challenges.
At the same time, some patients also have positive experiences with and attitudes
toward their illness and treatment. Drawing on 19 semi-structured interviews with
pairs of pediatric cancer patients and their parental caregivers, we examined patients'
perspectives on their experience of living with cancer. We identified four salient
themes in patients' positive experiences: future-oriented thinking, developing strong
personal bonds and relationships, gaining knowledge and life experience, and developing
self-management and coping skills. Collectively, the patients' positive experiences
indicate that they adapt to their new lives through an evolving process. Based on
this process, we provide design implications for health technologies to support and
promote positive experiences during illness and treatment.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {cancer, pediatric patient, positive experience, adaptation, health technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376398,
author = {Lee, Kyungjun and Sato, Daisuke and Asakawa, Saki and Kacorri, Hernisa and Asakawa, Chieko},
title = {Pedestrian Detection with Wearable Cameras for the Blind: A Two-Way Perspective},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376398},
doi = {10.1145/3313831.3376398},
abstract = {Blind people have limited access to information about their surroundings, which is
important for ensuring one's safety, managing social interactions, and identifying
approaching pedestrians. With advances in computer vision, wearable cameras can provide
equitable access to such information. However, the always-on nature of these assistive
technologies poses privacy concerns for parties that may get recorded. We explore
this tension from both perspectives, those of sighted passersby and blind users, taking
into account camera visibility, in-person versus remote experience, and extracted
visual information. We conduct two studies: an online survey with MTurkers (N=206)
and an in-person experience study between pairs of blind (N=10) and sighted (N=40)
participants, where blind participants wear a working prototype for pedestrian detection
and pass by sighted participants. Our results suggest that both of the perspectives
of users and bystanders and the several factors mentioned above need to be carefully
considered to mitigate potential social tensions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {face recognition, pedestrian detection, crowdsourcing, wearable camera, social acceptance, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376399,
author = {Miranda, Fabio and Hosseini, Maryam and Lage, Marcos and Doraiswamy, Harish and Dove, Graham and Silva, Cl\'{a}udio T.},
title = {Urban Mosaic: Visual Exploration of Streetscapes Using Large-Scale Image Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376399},
doi = {10.1145/3313831.3376399},
abstract = {Urban planning is increasingly data driven, yet the challenge of designing with data
at a city scale and remaining sensitive to the impact at a human scale is as important
today as it was for Jane Jacobs. We address this challenge with Urban Mosaic, a tool
for exploring the urban fabric through a spatially and temporally dense data set of
7.7 million street-level images from New York City, captured over the period of a
year. Working in collaboration with professional practitioners, we use Urban Mosaic
to investigate questions of accessibility and mobility, and preservation and retrofitting.
In doing so, we demonstrate how tools such as this might provide a bridge between
the city and the street, by supporting activities such as visual comparison of geographically
distant neighborhoods, and temporal analysis of unfolding urban development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {interactive visualization, urban data, data analysis, urban planning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376400,
author = {Razi, Afsaneh and Badillo-Urquiola, Karla and Wisniewski, Pamela J.},
title = {Let's Talk about Sext: How Adolescents Seek Support and Advice about Their Online Sexual Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376400},
doi = {10.1145/3313831.3376400},
abstract = {We conducted a thematic content analysis of 4,180 posts by adolescents (ages 12-17)
on an online peer support mental health forum to understand what and how adolescents
talk about their online sexual interactions. Youth used the platform to seek support
(83%), connect with others (15%), and give advice (5%) about sexting, their sexual
orientation, sexual abuse, and explicit content. Females often received unwanted nudes
from strangers and struggled with how to turn down sexting requests from people they
knew. Meanwhile, others who sought support complained that they received unwanted
sexual solicitations while doing so-to the point that adolescents gave advice to one
another on which users to stay away from. Our research provides insight into the online
sexual experiences of adolescents and how they seek support around these issues. We
discuss how to design peer-based social media platforms to support the well-being
and safety of youth.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online sexual experiences, sexual risks, adolescent online safety, sexting, peer support, social support seeking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376401,
author = {Kepplinger, Daniel and Wallner, G\"{u}nter and Kriglstein, Simone and Lankes, Michael},
title = {See, Feel, Move: Player Behaviour Analysis through Combined Visualization of Gaze, Emotions, and Movement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376401},
doi = {10.1145/3313831.3376401},
abstract = {Playtesting of games often relies on a mixed-methods approach to obtain more holistic
insights about and, in turn, improve the player experience. However, triangulating
the different data sources and visualizing them in an integrated manner such that
they contextualize each other still proves challenging. Despite its potential value
for gauging player behaviour, this area of research continues to be underexplored.
In this paper, we propose a visualization approach that combines commonly tracked
movement data with - from a visualization perspective rarely considered - gaze behaviour
and emotional responses. We evaluated our approach through a qualitative expert study
with five professional game developers. Our results show that both the individual
visualization of gaze, emotions, and movement but especially their combination are
valuable to understand and form hypotheses about player behaviour. At the same time,
our results stress that careful attention needs to be paid to ensure that the visualization
remains legible and does not obfuscate information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {playtesting, visual game analytics, emotions, information visualization, movement analysis, gaze},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376402,
author = {Carros, Felix and Meurer, Johanna and L\"{o}ffler, Diana and Unbehaun, David and Matthies, Sarah and Koch, Inga and Wieching, Rainer and Randall, Dave and Hassenzahl, Marc and Wulf, Volker},
title = {Exploring Human-Robot Interaction with the Elderly: Results from a Ten-Week Case Study in a Care Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376402},
doi = {10.1145/3313831.3376402},
abstract = {Ageing societies and the associated pressure on the care systems are major drivers
for new developments in socially assistive robotics. To understand better the real-world
potential of robot-based assistance, we undertook a 10-week case study in a care home
involving groups of residents, caregivers and managers as stakeholders. We identified
both, enablers and barriers to the potential implementation of robot systems. The
study employed the robot platform Pepper, which was deployed with a view to understanding
better multi-domain interventions with a robot supporting physical activation, cognitive
training and social facilitation. We employed the robot in a group setting in a care
facility over the course of 10 weeks and 20 sessions, observing how stakeholders,
including residents and caregivers, appropriated, adapted to, and perceived the robot.
We also conducted interviews with 11 residents and caregivers. Our results indicate
that the residents were positively engaged in the training sessions that were moderated
by the robot. The study revealed that such humanoid robots can work in a care home
but that there is a moderating person needed, that is in control of the robot.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {elderly care, social robots, ethics, user studies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376403,
author = {Qiu, Sihang and Gadiraju, Ujwal and Bozzon, Alessandro},
title = {Improving Worker Engagement Through Conversational Microtask Crowdsourcing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376403},
doi = {10.1145/3313831.3376403},
abstract = {The rise in popularity of conversational agents has enabled humans to interact with
machines more naturally. Recent work has shown that crowd workers in microtask marketplaces
can complete a variety of human intelligence tasks (HITs) using conversational interfaces
with similar output quality compared to the traditional Web interfaces. In this paper,
we investigate the effectiveness of using conversational interfaces to improve worker
engagement in microtask crowdsourcing. We designed a text-based conversational agent
that assists workers in task execution, and tested the performance of workers when
interacting with agents having different conversational styles. We conducted a rigorous
experimental study on Amazon Mechanical Turk with 800 unique workers, to explore whether
the output quality, worker engagement and the perceived cognitive load of workers
can be affected by the conversational agent and its conversational styles. Our results
show that conversational interfaces can be effective in engaging workers, and a suitable
conversational style has potential to improve worker engagement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user engagement, cognitive task load, conversational style, conversational interface, microtask crowdsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376404,
author = {Stangl, Abigale and Morris, Meredith Ringel and Gurari, Danna},
title = {"Person, Shoes, Tree. Is the Person Naked?" What People with Vision Impairments Want in Image Descriptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376404},
doi = {10.1145/3313831.3376404},
abstract = {Access to digital images is important to people who are blind or have low vision (BLV).
Many contemporary image description efforts do not take into account this population's
nuanced image description preferences. In this paper, we present a qualitative study
that provides insight into 28 BLV people's experiences with descriptions of digital
images from news websites, social networking sites/platforms, eCommerce websites,
employment websites, online dating websites/platforms, productivity applications,
and e-publications. Our findings reveal how image description preferences vary based
on the source where digital images are encountered and the surrounding context. We
provide recommendations for the development of next-generation image description technologies
inspired by our empirical analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {image captions, accessibility, alt text, visual impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376405,
author = {Burova, Alisa and M\"{a}kel\"{a}, John and Hakulinen, Jaakko and Keskinen, Tuuli and Heinonen, Hanna and Siltanen, Sanni and Turunen, Markku},
title = {Utilizing VR and Gaze Tracking to Develop AR Solutions for Industrial Maintenance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376405},
doi = {10.1145/3313831.3376405},
abstract = {Augmented reality (AR) presents a variety of possibilities for industrial maintenance.
However, the development of real-world AR solutions has been limited due to the technological
capabilities and uncertainty with respect to safety at deployment. We introduce the
approach of using AR simulation in virtual reality (VR) coupled with gaze tracking
to enable resource-efficient AR development. We tested in-field AR guidance and safety
awareness features in an iterative development-evaluation process with experts from
the elevator maintenance industry. We further conducted a survey, utilizing actual
gaze data from the evaluation to elicit comments from industry experts on the usefulness
of AR simulation and gaze tracking. Our results show the potential of AR within VR
approach combined with gaze tracking. With this framework, AR solutions can be iteratively
and safely tested without actual implementation, while gaze data provide advanced
objective means to evaluate the designed AR content, documentation usage, and safety
awareness.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gaze tracking, industrial maintenance, safety, virtual reality, virtual prototyping, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376406,
author = {Goodman, Steven and Kirchner, Susanne and Guttman, Rose and Jain, Dhruv and Froehlich, Jon and Findlater, Leah},
title = {Evaluating Smartwatch-Based Sound Feedback for Deaf and Hard-of-Hearing Users Across Contexts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376406},
doi = {10.1145/3313831.3376406},
abstract = {We present a qualitative study with 16 deaf and hard of hearing (DHH) participants
examining reactions to smartwatch-based visual + haptic sound feedback designs. In
Part 1, we conducted a Wizard-of-Oz (WoZ) evaluation of three smartwatch feedback
techniques (visual alone, visual + simple vibration, and visual + tacton) and investigated
vibrational patterns (tactons) to portray sound loudness, direction, and identity.
In Part 2, we visited three public or semi-public locations where we demonstrated
sound feedback on the smartwatch in situ to examine contextual influences and explore
sound filtering options. Our findings characterize uses for vibration in multimodal
sound awareness, both for push notification and for immediately actionable sound information
displayed through vibrational patterns (tactons). In situ experiences caused participants
to request sound filtering - particularly to limit haptic feedback - as a method for
managing soundscape complexity. Additional concerns arose related to learnability,
possibility of distraction, and system trust. Our findings have implications for future
portable sound awareness systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {deaf and hard of hearing, sound awareness, smartwatches},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376407,
author = {Superti Pantoja, Luiza and Diederich, Kyle and Crawford, Liam and Corbett, Megan and Klemm, Samantha and Peterman, Kerry and Currin, Flannery and Hourcade, Juan Pablo},
title = {Play-Based Design: Giving 3- to 4-Year-Old Children a Voice in the Design Process},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376407},
doi = {10.1145/3313831.3376407},
abstract = {There has been a dramatic growth in interactive technology use by children under the
age of 5 during the past decade. Despite this growth, children under the age of 5
typically participate only as users or testers in the design process in the overwhelming
majority of projects targeting this population presented in key child-computer interaction
venues. In this paper we introduce play-based design, an age-appropriate design method
to give 3-4-year-old children a voice in the design process. More specifically, we
contribute a thorough analysis of the use of existing methods to design technologies
for children under the age of 5, a summary of the process that resulted in the development
of play-based design, a detailed description of play-based design, a qualitative analysis
of our experience implementing play-based design with two groups of children, and
a discussion of play-based design's place among other methods, its advantages, and
limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design methods, play, children, preschool},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376408,
author = {Tsai, Hsin-Ruey and Hung, Ching-Wen and Wu, Tzu-Chun and Chen, Bing-Yu},
title = {ElastOscillation: 3D Multilevel Force Feedback for Damped Oscillation on VR Controllers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376408},
doi = {10.1145/3313831.3376408},
abstract = {Force feedback from damped oscillation is a common effect in our daily lives, especially
when shaking an elastic object, an object hanging or containing other stuff, or a
container with liquid, e.g., casting with a fishing pole or wine-swirling. Such a
force, affected by complex physical variations and collisions, is difficult to properly
simulate using current force feedback methods. Therefore, we propose ElastOscillation
on a virtual reality (VR) controller to provide 3D multilevel force feedback for damped
oscillation to enhance VR experiences. ElastOscillation consists of a proxy, six elastic
bands and DC motors. It leverages the motors to control the bands' elasticity to restrain
the movement of the proxy, which is connected with the bands. Therefore, when users
shake the ElastOscillation device, the proxy shakes or moves in corresponding ranges
of movement. The users then perceive the force from oscillation at different levels.
In addition, elastic force from the bands further reinforces the oscillation force
feedback. We conducted a force perception study to understand users' distinguishability
for perceiving oscillation forces in 1D and 2D movement, respectively. Based on the
results, we performed a VR experience study to show that the force feedback provided
by ElastOscillation enhances VR realism.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {oscillation, elastic force, force feedback, virtual reality, haptic feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376409,
author = {Paneva, Viktorija and Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Levitation Simulator: Prototyping Ultrasonic Levitation Interfaces in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376409},
doi = {10.1145/3313831.3376409},
abstract = {We present the Levitation Simulator, a system that enables researchers and designers
to iteratively develop and prototype levitation interface ideas in Virtual Reality.
This includes user tests and formal experiments. We derive a model of the movement
of a levitating particle in such an interface. Based on this, we develop an interactive
simulation of the levitation interface in VR, which exhibits the dynamical properties
of the real interface. The results of a Fitts' Law pointing study show that the Levitation
Simulator enables performance, comparable to the real prototype. We developed the
first two interactive games, dedicated for levitation interfaces: LeviShooter and
BeadBounce, in the Levitation Simulator, and then implemented them on the real interface.
Our results indicate that participants experienced similar levels of user engagement
when playing the games, in the two environments. We share our Levitation Simulator
as Open Source, thereby democratizing levitation research, without the need for a
levitation apparatus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ultrasonic levitation, modeling, virtual prototyping, simulation, vr},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376410,
author = {Tholander, Jakob and Normark, Maria},
title = {Crafting Personal Information - Resistance, Imperfection, and Self-Creation in Bullet Journaling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376410},
doi = {10.1145/3313831.3376410},
abstract = {Bullet journals are hand-written and self-created combinations of calendar, journal
and planner. Central to this practice is how personal information is managed through
a craft-based process. Based on a qualitative study, we discuss a set of themes that
emerged in our analysis of this practice. We discuss how open-ended use of various
materials for crafting of personal information engages in: 1) deliberate and strategic
boundary work of what information to include and how combinations of data provide
holistic and novel views of practitioner's life situations; 2) processes of self-creation
and reflection on personal life trajectories; 3) appreciation of ourselves and the
world around us as imperfect; and 4) ways of resisting the "business-like efficiency"
that come with the large quantities of information that permeate contemporary life.
We propose that this opens up new directions for thinking about how technologies of
personal information may come into play in people's lives.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal informatics, making by hand, bullet journaling, imperfection, analogue materials, crafts, self-creation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376411,
author = {Zuckerman, Oren and Walker, Dina and Grishko, Andrey and Moran, Tal and Levy, Chen and Lisak, Barak and Wald, Iddo Yehoshua and Erel, Hadas},
title = {Companionship Is Not a Function: The Effect of a Novel Robotic Object on Healthy Older Adults' Feelings of "Being-Seen"},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376411},
doi = {10.1145/3313831.3376411},
abstract = {One of the challenges faced by healthy older adults is experiencing feelings of not
"being-seen". Companion robots, commonly designed with zoomorphic or humanoid appearance
show success among clinical older adults, but healthy older adults find them degrading.
We present the design and implementation of a novel non-humanoid robot. The robot's
primary function is a cognitive word game. Social interaction is conveyed as a secondary
function, using non-verbal gestures, inspired by dancers' movement. In a lab study,
39 healthy older adults interacted with the prototype in 3 conditions: Companion-Function;
Game-Function; and No-Function. Results show the non-verbal gestures were associated
with feelings of "being-seen", and willingness to accept the robot into their home
was influenced by its function, with game significantly higher than companion. We
conclude that robot designers should further explore the potential of non-humanoid
robots as a new class of companion robots, with a primary function that is not companionship.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {non-humanoid robot, tangible interaction, social-interaction, loneliness, acceptance, older adults, successful aging},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376412,
author = {Burnell, Edward and Damen, Nicole B. and Hoburg, Warren},
title = {GPkit: A Human-Centered Approach to Convex Optimization in Engineering Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376412},
doi = {10.1145/3313831.3376412},
abstract = {We present GPkit, a Python toolkit for Geometric and Signomial Programming that prioritizes
explainability and incremental complexity. GPkit was designed through an ethnographic
approach in the firms, classrooms, and research labs where it became part of the fabric
of daily engineering work. Organizations have approached GPkit both in ways which
centralize and in ways which distribute design work, usecases which emerged from and
inspired new toolkit features. This two-way flow between mathematical structure and
practitioner knowledge resulted in several novel contributions to the formulation
and interpretation of convex programs and to our understanding of early-stage engineering
design. For example, dual solutions (often considered incidental) can be more valuable
to a design process than the "optimal design" itself, and we present novel algorithms
and design methods based on this insight.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {geometric programming, human-centered design, modeling languages, convex optimization, toolkits, design models},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376413,
author = {Pusateri, Juliet and Leng, Judith and Wang, Qian and Chen, Xiangzhu and Hammer, Jessica},
title = {Designing Games for Healthy Sleep},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376413},
doi = {10.1145/3313831.3376413},
abstract = {A sleep deficit has far-reaching consequences, but for many people, healthy sleep
is not a priority or a possibility. We explore the potential for "sleepy games" as
a genre of transformational games. To explore this design space, we prototyped nine
games through an iterative design process. Based on analysis of design decisions and
the games as artifacts, we identify seven design challenges for sleepy games: agency
and control; physiological and mental arousal; intervention timing; social embeddedness;
multisensory experience; vulnerability; and identity and values. We expand on three
games with playtesting to show how these design challenges unfold for players in practice,
show the impact on players' lives, and discuss sleepy games as creative, social, and
situated practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {transformational games, game design, games for health, sleep},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376414,
author = {Mahmud, Shareen and Alvina, Jessalyn and Chilana, Parmit K. and Bunt, Andrea and McGrenere, Joanna},
title = {Learning Through Exploration: How Children, Adults, and Older Adults Interact with a New Feature-Rich Application},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376414},
doi = {10.1145/3313831.3376414},
abstract = {Feature-rich applications such as word processors and spreadsheets are not only being
used by adults but increasingly by children and older adults as well. Learning these
applications is challenging as they offer hundreds of commands throughout the interface.
We investigate how newcomers from different age groups explore the user interface
of a feature-rich application to determine, locate, and use relevant features. We
conducted an in-lab observational study with 10 children (10-12), 10 adults (20-35)
and 10 older adults (60-75) who were first-time users of Microsoft OneNote. Our results
illustrate key exploration differences across age groups, including that children
were careful and performed as efficiently as the adults, whereas older adults spent
a longer time and repeated sequences of failed selections. Further, their exploration
style was negatively influenced by their past knowledge of similar applications. We
discuss design interventions to accommodate these exploration differences and to improve
software onboarding for newcomers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {newcomers' exploration strategies, lab study, age-related differences, desktop/laptop gui},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376415,
author = {Hanson, Julia and Wei, Miranda and Veys, Sophie and Kugler, Matthew and Strahilevitz, Lior and Ur, Blase},
title = {Taking Data Out of Context to Hyper-Personalize Ads: Crowdworkers' Privacy Perceptions and Decisions to Disclose Private Information},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376415},
doi = {10.1145/3313831.3376415},
abstract = {Data brokers and advertisers increasingly collect data in one context and use it in
another. When users encounter a misuse of their data, do they subsequently disclose
less information? We report on human-subjects experiments with 25 in-person and 280
online participants. First, participants provided personal information amidst distractor
questions. A week later, while participants completed another survey, they received
either a robotext or online banner ad seemingly unrelated to the study. Half of the
participants received an ad containing their name, partner's name, preferred cuisine,
and location; others received a generic ad. We measured how many of 43 potentially
invasive questions participants subsequently chose to answer. Participants reacted
negatively to the personalized ad, yet answered nearly all invasive questions accurately.
We unpack our results relative to the privacy paradox, contextual integrity, and power
dynamics in crowdworker platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hyper-personalization, targeted advertising, user study, creepy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376416,
author = {Xu, Ying and Warschauer, Mark},
title = {What Are You Talking To?: Understanding Children's Perceptions of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376416},
doi = {10.1145/3313831.3376416},
abstract = {Conversational agents (CAs) available in smart phones or smart speakers play an increasingly
important role in young children's technological landscapes and life worlds. While
a handful of studies have documented children's natural interactions with CAs, little
is known about children's perceptions of CAs. To fill this gap, we examined three-
to six-year-olds' perceptions of CAs' animate/artifact domain membership and properties,
as well as their justifications for these perceptions. We found that children sometimes
take a more nuanced position and spontaneously attribute both artifact and animate
properties to CAs or view them as neither artifacts nor animate objects. This study
extends current research on children's perceptions of intelligent artifacts by adding
CAs as a new genre of study and provides some underlying knowledge that may guide
the development of CAs to support young children's cognitive and social development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {children, child-agent interactions, conversational agents, perceptions, animacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376417,
author = {Taranta, Eugene M. and Pittman, Corey R. and Oakley, Jack P. and Maslych, Mykola and Maghoumi, Mehran and LaViola, Joseph J.},
title = {Moving Toward an Ecologically Valid Data Collection Protocol for 2D Gestures In Video Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376417},
doi = {10.1145/3313831.3376417},
abstract = {Those who design gesture recognizers and user interfaces often use data collection
applications that enable users to comfortably produce gesture training samples. In
contrast, games present unique contexts that impact cognitive load and have the potential
to elicit rapid gesticulations as players react to dynamic conditions, which can result
in high gesture form variability. However, the extent to which these gestures differ
is presently unknown. To this end, we developed two games with unique mechanics, Follow
the Leader (FTL) and Sleepy Town, as well as a standard data collection application.
We collected gesture samples from 18 participants across all conditions for gestures
of varying complexity, and through an analysis using relative, global, and distribution
coverage measures, we confirm significant differences between conditions. We discuss
the implications of our findings, and show that our FTL design is closer to being
an ecologically valid data collection protocol with low implementation complexity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gestures, ecologically validity, games, follow the leader},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376418,
author = {Jensen, Emily and Dale, Meghan and Donnelly, Patrick J. and Stone, Cathlyn and Kelly, Sean and Godley, Amanda and D'Mello, Sidney K.},
title = {Toward Automated Feedback on Teacher Discourse to Enhance Teacher Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376418},
doi = {10.1145/3313831.3376418},
abstract = {Like anyone, teachers need feedback to improve. Due to the high cost of human classroom
observation, teachers receive infrequent feedback which is often more focused on evaluating
performance than on improving practice. To address this critical barrier to teacher
learning, we aim to provide teachers with detailed and actionable automated feedback.
Towards this end, we developed an approach that enables teachers to easily record
high-quality audio from their classes. Using this approach, teachers recorded 142
classroom sessions, of which 127 (89%) were usable. Next, we used speech recognition
and machine learning to develop teacher-generalizable computer-scored estimates of
key dimensions of teacher discourse. We found that automated models were moderately
accurate when compared to human coders and that speech recognition errors did not
influence performance. We conclude that authentic teacher discourse can be recorded
and analyzed for automatic feedback. Our next step is to incorporate the automatic
models into an interactive visualization tool that will provide teachers with objective
feedback on the quality of their discourse.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {classroom discourse, natural language processing, automatic speech recognition, dialogic instruction, audio recording},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376419,
author = {Peck, Tabitha C. and Good, Jessica J. and Bourne, Kimberly A.},
title = {Inducing and Mitigating Stereotype Threat Through Gendered Virtual Body-Swap Illusions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376419},
doi = {10.1145/3313831.3376419},
abstract = {A psychological phenomenon termed "stereotype threat" has been shown to contribute
to women's underperformance and underrepresentation in math and science fields. Within
the virtual reality literature, a recent study utilized gendered body-swap illusions
(i.e., women in male virtual bodies) to mitigate the effects of stereotype threat
among a sample of female participants. The present research provides a much needed
replication of this intervention, as well as a critical extension of virtual reality
research on the Proteus Effect to test whether stereotype threat can be induced among
male participants immersed in a female virtual body. Results supported both the replication
and extension hypotheses; female participants embodied in male avatars were buffered
from stereotype threat whereas male participants embodied in female avatars suffered
from stereotype threat. Avatar gender also influenced participants' math confidence
and awareness of the negative societal stereotype regarding women's math ability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gender, proteus effect, virtual reality, embodiment, self-avatars, gender identity, stereotype threat, body-swap illusions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376420,
author = {McNutt, Andrew and Kindlmann, Gordon and Correll, Michael},
title = {Surfacing Visualization Mirages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376420},
doi = {10.1145/3313831.3376420},
abstract = {Dirty data and deceptive design practices can undermine, invert, or invalidate the
purported messages of charts and graphs. These failures can arise silently: a conclusion
derived from a particular visualization may look plausible unless the analyst looks
closer and discovers an issue with the backing data, visual specification, or their
own assumptions. We term such silent but significant failures . We describe a conceptual
model of mirages and show how they can be generated at every stage of the visual analytics
process. We adapt a methodology from software testing, , as a way of automatically
surfacing potential mirages at the visual encoding stage of analysis through modifications
to the underlying data and chart specification. We show that metamorphic testing can
reliably identify mirages across a variety of chart types with relatively little prior
knowledge of the data or the domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {information visualization, visualization testing, deceptive visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376421,
author = {Lin, Ying-Ju and Punpongsanon, Parinya and Wen, Xin and Iwai, Daisuke and Sato, Kosuke and Obrist, Marianna and Mueller, Stefanie},
title = {FoodFab: Creating Food Perception Illusions Using Food 3D Printing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376421},
doi = {10.1145/3313831.3376421},
abstract = {Personalization of eating such that everyone consumes only what they need allows improving
our management of food waste. In this paper, we explore the use of food 3D printing
to create perceptual illusions for controlling the level of perceived satiety given
a defined amount of calories. We present FoodFab, a system that allows users to control
their food intake through modifying a food's internal structure via two 3D printing
parameters: infill pattern and infill density. In two experiments with a total of
30 participants, we studied the effect of these parameters on users' chewing time
that is known to affect people's feeling of satiety. Our results show that we can
indeed modify the chewing time by varying infill pattern and density, and thus control
perceived satiety. Based on the results, we propose two computational models and integrate
them into a user interface that simplifies the creation of personalized food structures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {food-interaction design, food perception, fabrication techniques, food 3D printer, personal fabrication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376422,
author = {Larsen-Ledet, Ida and Korsgaard, Henrik and B\o{}dker, Susanne},
title = {Collaborative Writing Across Multiple Artifact Ecologies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376422},
doi = {10.1145/3313831.3376422},
abstract = {Research focusing on how collaborative writing takes place across multiple applications
and devices and over longer projects is sparse. We respond to this gap by presenting
the results of a qualitative study of longer-term academic writing projects, showing
how co-writers employ multiple tools when working on a common text. We identify three
patterns of multi-application collaboration as well as four common types of motivations
for transitions between applications. We also extend existing taxonomies of collaborative
writing by proposing a categorization of the functions served by the text as object
and backbone of the collaboration. Together, these contributions offer a framing for
understanding transitions within and across artifact ecologies in work around a common
object. Our findings highlight ways in which features like concurrent editing may
in fact challenge the collaborative writing process, and we point to opportunities
for alternative application models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {collaborative writing, github, computer-supported cooperative work, text function, overleaf, collaboration, aligned artifact ecology, google docs, personal artifact ecology, sharelatex, latex, artifact ecology, collaborative academic writing, academic writing, cscw, potential artifact ecology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376423,
author = {Pfau, Johannes and Smeddinck, Jan David and Malaka, Rainer},
title = {Enemy Within: Long-Term Motivation Effects of Deep Player Behavior Models for Dynamic Difficulty Adjustment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376423},
doi = {10.1145/3313831.3376423},
abstract = {Balancing games and producing content that remains interesting and challenging is
a main cost factor in the design and maintenance of games. Dynamic difficulty adjustments
(DDA) can successfully tune challenge levels to player abilities, but when implemented
with classic heuristic parameter tuning (HPT) often turns out to be very noticeable,
e.g. as "rubber-banding". Deep learning techniques can be employed for deep player
behavior modeling (DPBM), enabling more complex adaptivity, but effects over frequent
and longer-lasting game engagements, as well as how it compares to HPT has not been
empirically investigated. We present a situated study of the effects of DDA via DPBM
as compared to HPT on intrinsic motivation, perceived challenge and player motivation
in a real-world MMORPG. The results indicate that DPBM can lead to significant improvements
in intrinsic motivation and players prefer game experience episodes featuring DPBM
over experience episodes with classic difficulty management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {neural networks, deep learning, games, MMORPGs, dynamic difficulty adjustment, player modeling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376424,
author = {Xiao, Sijia and Metaxa, Dana\"{e} and Park, Joon Sung and Karahalios, Karrie and Salehi, Niloufar},
title = {Random, Messy, Funny, Raw: Finstas as Intimate Reconfigurations of Social Media},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376424},
doi = {10.1145/3313831.3376424},
abstract = {Among many young people, the creation of a finsta-a portmanteau of "fake" and "Instagram"
which describes secondary Instagram accounts-provides an outlet to share emotional,
low-quality, or indecorous content with their close friends. To study why people create
and maintain finstas, we conducted a qualitative study through interviews with finsta
users and content analysis of video bloggers exposing their finsta on YouTube. We
found that one way that young people deal with mounting social pressures is by reconfiguring
online platforms and changing their purposes, norms, expectations, and currencies.
Carving out smaller spaces accessible only to close friends allows users the opportunity
for a more unguarded, vulnerable, and unserious performance. Drawing on feminist theory,
we term this process intimate reconfiguration. Through this reconfiguration finsta
users repurpose an existing and widely-used social platform to create opportunities
for more meaningful and reciprocal forms of social support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reconfiguration, feminist hci, finsta, performance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376425,
author = {Vasquez, Joshua and Twigg-Smith, Hannah and Tran O'Leary, Jasper and Peek, Nadya},
title = {Jubilee: An Extensible Machine for Multi-Tool Fabrication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376425},
doi = {10.1145/3313831.3376425},
abstract = {We present Jubilee, an open-source hardware machine with automatic tool-changing and
interchangeable bed plates. As digital fabrication tools have become more broadly
accessible, tailoring those machines to new users and novel workflows has become central
to HCI research. However, the lack of hardware infrastructure makes custom application
development cumbersome. We identify a need for an extensible platform to allow HCI
researchers to develop workflows for fabrication, material exploration, and other
applications. Jubilee addresses this need. It can automatically and repeatably change
tools in the same operation. It can be built with a combination of simple 3D-printed
and readily available parts. It has several standard head designs for a variety of
applications including 3D printing, syringe-based liquid handling, imaging, and plotting.
We present Jubilee with a comprehensive set of assembly instructions and kinematic
mount templates for user-designed tools and bed plates. Finally we demonstrate Jubilee's
multi-tool workflow functionality with a series of example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {digital fabrication, multi-tool workflows, toolchanging},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376426,
author = {Hong, Matthew K. and Lakshmi, Udaya and Do, Kimberly and Prahalad, Sampath and Olson, Thomas and Arriaga, Rosa I. and Wilcox, Lauren},
title = {Using Diaries to Probe the Illness Experiences of Adolescent Patients and Parental Caregivers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376426},
doi = {10.1145/3313831.3376426},
abstract = {Adolescents with chronic conditions must work with family caregivers to manage their
illness experiences. To explore how technology can support collaborative documentation
of these experiences, we designed and distributed a paper diary probe kit in a two-week
field deployment with 12 adolescent-parent dyads (24 participants). Three insights
emerged from the study that highlight how technology can support shared illness management:
1) provide scaffolds to recognize physical and emotional experiences in the context
of daily activities; 2) help families reconstruct patient experiences; and 3) adapt
to individual preferences for capturing, representing and sharing experiences. We
discuss opportunities for HCI research that follow from these findings and conclude
by reflecting on the benefits and limitations of using diary probes with adolescent
patients and their parental caregivers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {health, adolescents, probes, family informatics, family-centered design, chronic illness, diary studies, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376427,
author = {Yang, Jackie (Junrui) and Banerjee, Gaurab and Gupta, Vishesh and Lam, Monica S. and Landay, James A.},
title = {Soundr: Head Position and Orientation Prediction Using a Microphone Array},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376427},
doi = {10.1145/3313831.3376427},
abstract = {Although state-of-the-art smart speakers can hear a user's speech, unlike a human
assistant these devices cannot figure out users' verbal references based on their
head location and orientation. Soundr presents a novel interaction technique that
leverages the built-in microphone array found in most smart speakers to infer the
user's spatial location and head orientation using only their voice. With that extra
information, Soundr can figure out users references to objects, people, and locations
based on the speakers' gaze, and also provide relative directions. To provide training
data for our neural network, we collected 751 minutes of data (50x that of the best
prior work) from human speakers leveraging a virtual reality headset to accurately
provide head tracking ground truth. Our results achieve an average positional error
of 0.31m and an orientation angle accuracy of 34.3° for each voice command. A user
study to evaluate user preferences for controlling IoT appliances by talking at them
found this new approach to be fast and easy to use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {smart speakers, acoustic source localization, internet of things, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376428,
author = {Hong, Jonggi and Lee, Kyungjun and Xu, June and Kacorri, Hernisa},
title = {Crowdsourcing the Perception of Machine Teaching},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376428},
doi = {10.1145/3313831.3376428},
abstract = {Teachable interfaces can empower end-users to attune machine learning systems to their
idiosyncratic characteristics and environment by explicitly providing pertinent training
examples. While facilitating control, their effectiveness can be hindered by the lack
of expertise or misconceptions. We investigate how users may conceptualize, experience,
and reflect on their engagement in machine teaching by deploying a mobile teachable
testbed in Amazon Mechanical Turk. Using a performance-based payment scheme, Mechanical
Turkers (N=100) are called to train, test, and re-train a robust recognition model
in real-time with a few snapshots taken in their environment. We find that participants
incorporate diversity in their examples drawing from parallels to how humans recognize
objects independent of size, viewpoint, location, and illumination. Many of their
misconceptions relate to consistency and model capabilities for reasoning. With limited
variation and edge cases in testing, the majority of them do not change strategies
on a second training attempt.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {personalization, teachable interfaces, interactive machine learning, crowdsourcing, object recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376429,
author = {Biggs, Heidi R. and Desjardins, Audrey},
title = {High Water Pants: Designing Embodied Environmental Speculation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376429},
doi = {10.1145/3313831.3376429},
abstract = {In this paper, we present the High Water Pants: speculative wearable technology which
makes climate change tangible for everyday cyclists. The pants work by mechanically
shortening when a cyclist wearing the pants enters an area of Seattle, USA, which
is projected to be impacted by sea-level rise in 30-80 years. This interaction 'bends
time' by allowing cyclists to feel future climate change data in the present. First,
we discuss the research through design process of creating the High Water Pants including
foundational research, a description of the design concept and results of a preliminary
study with the pants. Second, we discuss three implications of the pants for human-computer
interaction (HCI): (1) they offer the concept of a 'present/future' paradigm for embodied
speculation, (2) our research process demonstrates how to successfully involve more-than-human
perspectives, and (3) we articulate how the High Water Pants respond to shifts in
HCI's framing of sustainability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sustainability, research through design, embodied speculation, wearables, speculative design, cycling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376430,
author = {Svan\ae{}s, Dag and Barkhuus, Louise},
title = {The Designer's Body as Resource in Design: Exploring Combinations of Point-of-View and Tense},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376430},
doi = {10.1145/3313831.3376430},
abstract = {The design of wearable, tangible and embedded interactive products requires a focus
on bodily/kinesthetic aspects of the user experience, that is, how the product "feels"
in use. Although best practice in user-centered design (such as iterative design,
prototyping, user testing) also applies for this new type of product, the designer's
skill set needs to be supplemented with design methods and practices that utilize
bodily intelligence and empathy with the user. We present a framework for categorizing
such body-centered design practices based on two dimensions: point-of-view (1st, 2nd,
3rd person) and tense (past, present, future). Inspired by Merleau-Ponty's phenomenology
of the body, Shusterman's work on somaesthetics, and Buber's theories on intersubjectivity,
the framework provides a language for talking about different ways designers and co-designers
can utilize their body as a design resource. The intention is not to be prescriptive
on method, but to provide guidance during planning, execution and analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {phenomenology, design process, designer training, body-centered design, somaesthetics, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376431,
author = {Shi, Lei and Zhao, Yuhang and Gonzalez Penuela, Ricardo and Kupferstein, Elizabeth and Azenkot, Shiri},
title = {Molder: An Accessible Design Tool for Tactile Maps},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376431},
doi = {10.1145/3313831.3376431},
abstract = {Tactile materials are powerful teaching aids for students with visual impairments
(VIs). To design these materials, designers must use modeling applications, which
have high learning curves and rely on visual feedback. Today, Orientation and Mobility
(O&amp;M) specialists and teachers are often responsible for designing these materials.
However, most of them do not have professional modeling skills, and many are visually
impaired themselves. To address this issue, we designed Molder, an accessible design
tool for interactive tactile maps, an important type of tactile materials that can
help students learn O&amp;M skills. A designer uses Molder to design a map using tangible
input techniques, and Molder provides auditory feedback and high-contrast visual feedback.
We evaluated Molder with 12 participants (8 with VIs, 4 sighted). After a 30-minute
training session, the participants were all able to use Molder to design maps with
customized tactile and interactive information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visual impairments, design tool, tactile maps},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376432,
author = {Dixon, Emma and Lazar, Amanda},
title = {Approach Matters: Linking Practitioner Approaches to Technology Design for People with Dementia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376432},
doi = {10.1145/3313831.3376432},
abstract = {Technology design for dementia is an active and growing area. Though work to date
has largely addressed functional needs, there is a growing recognition of the importance
of supporting meaningful activities. However, technology for active, rather than passive,
engagement is relatively novel beyond specific applications (e.g., music or reminiscence
therapy). To better understand how to support active engagement of people with dementia
in activities, we interviewed nineteen practitioners. Our findings reveal differing
approaches to making sense of the actions of people with dementia, as well as to engaging
them in activities. We discuss the importance of tracing epistemological understandings
of dementia to different configurations of technology for people living with dementia
and provide a practical guide to support designers to do so. Finally, we discuss considerations
for the design of dementia technologies around facilitating self-actualization and
managing emotional exposure for care-providers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {practitioners, design, meaningful activities, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376433,
author = {Robinson, Raquel Breejon and Reid, Elizabeth and Fey, James Collin and Depping, Ansgar E. and Isbister, Katherine and Mandryk, Regan L.},
title = {Designing and Evaluating 'In the Same Boat', A Game of Embodied Synchronization for Enhancing Social Play},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376433},
doi = {10.1145/3313831.3376433},
abstract = {Social closeness is important for health and well-being, but is difficult to maintain
over a distance. Games can help connect people by strengthening existing relationships
or creating new ones through shared playful experiences. We present the design and
evaluation of 'In the Same Boat' (ITSB), a two-player infinite runner designed to
foster social closeness in distributed dyads. ITSB leverages the synchronization of
both players' input to steer a canoe down a river and avoid obstacles. We created
two versions: embodied controls, which use players' physiological signals (breath
rate, facial expressions), and standard keyboard controls. Results from a study with
35 dyads indicate that ITSB fostered affiliation, and while embodied controls were
less intuitive, people enjoyed them more. Further, photos of the dyads were rated
as happier and closer in the embodied condition, indicating the potential of embodied
controls to foster social closeness in synchronized play over a distance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {social games, physiological data, body games, emotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376434,
author = {Browne, Kieran and Swift, Ben and Nurmikko-Fuller, Terhi},
title = {Camera Adversaria},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376434},
doi = {10.1145/3313831.3376434},
abstract = {In this paper we introduce Camera Adversaria; a mobile app designed to disrupt the
automatic surveillance of personal photographs by technology companies. The app leverages
the brittleness of deep neural networks with respect to high-frequency signals, adding
generative adversarial perturbations to users' photographs. These perturbations confound
image classification systems but are virtually imperceptible to human viewers. Camera
Adversaria builds on methods developed by machine learning researchers as well as
a growing body of work, primarily from art and design, which transgresses contemporary
surveillance systems. We map the design space of responses to surveillance and identify
an under-explored region where our project is situated. Finally we show that the language
typically used in the adversarial perturbation literature serves to affirm corporate
surveillance practices and malign resistance. This raises significant questions about
the function of the research community in countenancing systems of surveillance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {surveillance capitalism, adversarial examples, critical design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376435,
author = {Ernala, Sindhu Kiranmai and Burke, Moira and Leavitt, Alex and Ellison, Nicole B.},
title = {How Well Do People Report Time Spent on Facebook? An Evaluation of Established Survey Questions with Recommendations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376435},
doi = {10.1145/3313831.3376435},
abstract = {Many studies examining social media use rely on self-report survey questions about
how much time participants spend on social media platforms. Because they are challenging
to answer accurately and susceptible to various biases, these self-reported measures
are known to contain error -- although the specific contours of this error are not
well understood. This paper compares data from ten self-reported Facebook use survey
measures deployed in 15 countries (N = 49,934) against data from Facebook's server
logs to describe factors associated with error in commonly used survey items from
the literature. Self-reports were moderately correlated with actual Facebook use (r
= 0.42 for the best-performing question), though participants significantly overestimated
how much time they spent on Facebook and underestimated the number of times they visited.
People who spent a lot of time on the platform were more likely to misreport their
time, as were teens and younger adults, which is notable because of the high reliance
on college-aged samples in many fields. We conclude with recommendations on the most
accurate ways to collect time-spent data via surveys.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {time spent, survey validation, self-reports, well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376436,
author = {Chen, Zhutian and Tong, Wai and Wang, Qianwen and Bach, Benjamin and Qu, Huamin},
title = {Augmenting Static Visualizations with PapARVis Designer},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376436},
doi = {10.1145/3313831.3376436},
abstract = {This paper presents an authoring environment for augmenting static visualizations
with virtual content in augmented reality.Augmenting static visualizations can leverage
the best of both physical and digital worlds, but its creation currently involves
different tools and devices, without any means to explicitly design and debug both
static and virtual content simultaneously. To address these issues, we design an environment
that seamlessly integrates all steps of a design and deployment workflow through its
main features: i) an extension to Vega, ii) a preview, and iii) debug hints that facilitate
valid combinations of static and augmented content. We inform our design through a
design space with four ways to augment static visualizations. We demonstrate the expressiveness
of our tool through examples, including books, posters, projections, wall-sized visualizations.
A user study shows high user satisfaction of our environment and confirms that participants
can create augmented visualizations in an average of 4.63 minutes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visualization in augmented reality, data visualization authoring, augmented static visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376437,
author = {Fraser, C. Ailie and Kim, Joy O. and Shin, Hijung Valentina and Brandt, Joel and Dontcheva, Mira},
title = {Temporal Segmentation of Creative Live Streams},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376437},
doi = {10.1145/3313831.3376437},
abstract = {Many artists broadcast their creative process through live streaming platforms like
Twitch and YouTube, and people often watch archives of these broadcasts later for
learning and inspiration. Unfortunately, because live stream videos are often multiple
hours long and hard to skim and browse, few can leverage the wealth of knowledge hidden
in these archives. We present an approach for automatic temporal segmentation of creative
live stream videos. Using an audio transcript and a log of software usage, the system
segments the video into sections that the artist can optionally label with meaningful
titles. We evaluate this approach by gathering feedback from expert streamers and
comparing automatic segmentations to those made by viewers. We find that, while there
is no one "correct" way to segment a live stream, our automatic method performs similarly
to viewers, and streamers find it useful for navigating their streams after making
slight adjustments and adding section titles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {creativity, live streaming, video segmentation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376438,
author = {Sidenmark, Ludwig and Clarke, Christopher and Zhang, Xuesong and Phu, Jenny and Gellersen, Hans},
title = {Outline Pursuits: Gaze-Assisted Selection of Occluded Objects in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376438},
doi = {10.1145/3313831.3376438},
abstract = {In 3D environments, objects can be difficult to select when they overlap, as this
affects available target area and increases selection ambiguity. We introduce Outline
Pursuits which extends a primary pointing modality for gaze-assisted selection of
occluded objects. Candidate targets within a pointing cone are presented with an outline
that is traversed by a moving stimulus. This affords completion of the selection by
gaze attention to the intended target's outline motion, detected by matching the user's
smooth pursuit eye movement. We demonstrate two techniques implemented based on the
concept, one with a controller as the primary pointer, and one in which Outline Pursuits
are combined with head pointing for hands-free selection. Compared with conventional
raycasting, the techniques require less movement for selection as users do not need
to reposition themselves for a better line of sight, and selection time and accuracy
are less affected when targets become highly occluded.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smooth pursuits, occlusion, eye tracking, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376439,
author = {Gao, Ge and Sun, Yuling and Zhang, Yongle},
title = {Engaging the Commons in Participatory Sensing: Practice, Problems, and Promise in the Context of Dockless Bikesharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376439},
doi = {10.1145/3313831.3376439},
abstract = {Participatory sensing refers to the sensing paradigm where human participants use
personal mobile devices to generate and share data from their surroundings. It holds
the promise of providing information that is otherwise challenging to access, which
sets the stage for understanding and resolving various social issues. However, difficulties
in engaging participants often hinder the fulfillment of this promise. The current
paper presents a qualitative study in the context of dockless bikesharing, where participatory
sensing constitutes a backbone of the bike status monitoring system. We conducted
in-depth interviews with 30 participants. These participants came from different emergent
groups who took part in filing status reports for shared bikes. Our analysis indicated
close associations among participants' models of engagement, their perceived (dis)connections
with the sensing data, and their situated interpretation of the incentives. Based
on these findings, we propose ways to engage the commons in participatory sensing
for dockless bikesharing and beyond.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {smart city, dockless bikesharing, participatory sensing, engagement, urban transportation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376440,
author = {Abu-Salma, Ruba and Livshits, Benjamin},
title = {Evaluating the End-User Experience of Private Browsing Mode},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376440},
doi = {10.1145/3313831.3376440},
abstract = {In this paper, we investigate why users of private browsing mode misunderstand the
benefits and limitations of private browsing. We design and conduct a three-part study:
(1) an analytic evaluation of the user interface of private mode in different browsers;
(2) a qualitative user study to explore user mental models of private browsing; (3)
a participatory design study to investigate why existing browser disclosures, the
in-browser explanations of private mode, do not communicate the actual protection
of private mode. We find the user interface of private mode in different browsers
violated well-established design guidelines and heuristics. Further, most participants
had incorrect mental models of private browsing, influencing their understanding and
usage of private mode. We also find existing browser disclosures did not explain the
primary security goal of private mode. Drawing from the results of our study, we extract
a set of recommendations to improve the design of disclosures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {usable security and privacy, human-computer interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376441,
author = {Yi, Xin and Wang, Chen and Bi, Xiaojun and Shi, Yuanchun},
title = {PalmBoard: Leveraging Implicit Touch Pressure in Statistical Decoding for Indirect Text Entry},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376441},
doi = {10.1145/3313831.3376441},
abstract = {We investigated how to incorporate implicit touch pressure, finger pressure applied
to a touch surface during typing, to improve text entry performance via statistical
decoding. We focused on one-handed touch-typing on indirect interface as an example
scenario. We first collected typing data on a pressure-sensitive touchpad, and analyzed
users' typing behavior such as touch point distribution, key-to-finger mappings, and
pressure images. Our investigation revealed distinct pressure patterns for different
keys. Based on the findings, we performed a series of simulations to iteratively optimize
the statistical decoding algorithm. Our investigation led to a Markov-Bayesian decoder
incorporating pressure image data into decoding. It improved the top-1 accuracy from
53% to 74% over a naive Bayesian decoder. We then implemented PalmBoard, a text entry
method that implemented the Markov-Bayesian decoder and effectively supported one-handed
touch-typing on indirect interfaces. A user study showed participants achieved an
average speed of 32.8 WPM with 0.6% error rate. Expert typists could achieve 40.2
WPM with 30 minutes of practice. Overall, our investigation showed that incorporating
implicit touch pressure is effective in improving text entry decoding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {input prediction, text entry, touch-typing, touch pressure},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376442,
author = {Drosos, Ian and Barik, Titus and Guo, Philip J. and DeLine, Robert and Gulwani, Sumit},
title = {Wrex: A Unified Programming-by-Example Interaction for Synthesizing Readable Code for Data Scientists},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376442},
doi = {10.1145/3313831.3376442},
abstract = {Data wrangling is a difficult and time-consuming activity in computational notebooks,
and existing wrangling tools do not fit the exploratory workflow for data scientists
in these environments. We propose a unified interaction model based on programming-by-example
that generates readable code for a variety of useful data transformations, implemented
as a Jupyter notebook extension called Wrex. User study results demonstrate that data
scientists are significantly more effective and efficient at data wrangling with Wrex
over manual programming. Qualitative participant feedback indicates that Wrex was
useful and reduced barriers in having to recall or look up the usage of various data
transform functions. The synthesized code allowed data scientists to verify the intended
data transformation, increased their trust and confidence in Wrex, and fit seamlessly
within their cell-based notebook workflows. This work suggests that presenting readable
code to professional data scientists is an indispensable component of offering data
wrangling tools in notebooks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {program synthesis, computational notebooks, data science},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376443,
author = {Lai, Chufan and Lin, Zhixian and Jiang, Ruike and Han, Yun and Liu, Can and Yuan, Xiaoru},
title = {Automatic Annotation Synchronizing with Textual Description for Visualization},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376443},
doi = {10.1145/3313831.3376443},
abstract = {In this paper, we propose a technique for automatically annotating visualizations
according to the textual description. In our approach, visual elements in the target
visualization, along with their visual properties, are identified and extracted with
a Mask R-CNN model. Meanwhile, the description is parsed to generate visual search
requests. Based on the identification results and search requests, each descriptive
sentence is displayed beside the described focal areas as annotations. Different sentences
are presented in various scenes of the generated animation to promote a vivid step-by-step
presentation. With a user-customized style, the animation can guide the audience's
attention via proper highlighting such as emphasizing specific features or isolating
part of the data. We demonstrate the utility and usability of our method through a
user study with use cases.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, machine learning, annotation, natural language interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376444,
author = {Chatterjee, Soujanya and Rahman, Md Mahbubur and Ahmed, Tousif and Saleheen, Nazir and Nemati, Ebrahim and Nathan, Viswam and Vatanparvar, Korosh and Kuang, Jilong},
title = {Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376444},
doi = {10.1145/3313831.3376444},
abstract = {Obstructive pulmonary diseases cause limited airflow from the lung and severely affect
patients' quality of life. Wheeze is one of the most prominent symptoms for them.
High requirements imposed by traditional diagnosis methods make regular monitoring
of pulmonary obstruction challenging, which hinders the opportunity of early intervention
and prevention of significant exacerbation. In this work, we explore the feasibility
of developing a mobile sensor-based system as a convenient means of assessing the
severity of pulmonary obstruction via respiration phase-based symptomatic wheeze sensing.
We conduct a 131 subjects' (91 patients and 40 healthy) study for the detection (F1:
87.96%) and characterization (F1: 79.47%) of wheeze. Subsequently, we develop novel
wheeze metrics, which show a significant correlation (Pearson's correlation: -0.22,
p-value: 0.024) with standard spirometry measure of pulmonary obstruction severity.
This work takes a principal step towards the unobtrusive assessment of pulmonary condition
from mobile sensor interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wheezing, mobile application, mobile health (mhealth), pulmonary monitoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376445,
author = {Madaio, Michael A. and Stark, Luke and Wortman Vaughan, Jennifer and Wallach, Hanna},
title = {Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376445},
doi = {10.1145/3313831.3376445},
abstract = {Many organizations have published principles intended to guide the ethical development
and deployment of AI systems; however, their abstract nature makes them difficult
to operationalize. Some organizations have therefore produced AI ethics checklists,
as well as checklists for more specific concepts, such as fairness, as applied to
AI systems. But unless checklists are grounded in practitioners' needs, they may be
misused. To understand the role of checklists in AI ethics, we conducted an iterative
co-design process with 48 practitioners, focusing on fairness. We co-designed an AI
fairness checklist and identified desiderata and concerns for AI fairness checklists
in general. We found that AI fairness checklists could provide organizational infrastructure
for formalizing ad-hoc processes and empowering individual advocates. We highlight
aspects of organizational culture that may impact the efficacy of AI fairness checklists,
and suggest future design directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ML, ethics, checklists, co-design, fairness, AI},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376446,
author = {Frommel, Julian and Sagl, Valentin and Depping, Ansgar E. and Johanson, Colby and Miller, Matthew K. and Mandryk, Regan L.},
title = {Recognizing Affiliation: Using Behavioural Traces to Predict the Quality of Social Interactions in Online Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376446},
doi = {10.1145/3313831.3376446},
abstract = {Online social interactions in multiplayer games can be supportive and positive or
toxic and harmful; however, few methods can easily assess interpersonal interaction
quality in games. We use behavioural traces to predict affiliation between dyadic
strangers, facilitated through their social interactions in an online gaming setting.
We collected audio, video, in-game, and self-report data from 23 dyads, extracted
75 features, trained Random Forest and Support Vector Machine models, and evaluated
their performance predicting binary (high/low) as well as continuous affiliation toward
a partner. The models can predict both binary and continuous affiliation with up to
79.1% accuracy (F1) and 20.1% explained variance (R2) on unseen data, with features
based on verbal communication demonstrating the highest potential. Our findings can
inform the design of multiplayer games and game communities, and guide the development
of systems for matchmaking and mitigating toxic behaviour in online games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {evaluation, affiliation, recognition, social interaction, prediction, bonding, machine learning, cooperative games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376447,
author = {Yan, Jing Nathan and Gu, Ziwei and Lin, Hubert and Rzeszotarski, Jeffrey M.},
title = {Silva: Interactively Assessing Machine Learning Fairness Using Causality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376447},
doi = {10.1145/3313831.3376447},
abstract = {Machine learning models risk encoding unfairness on the part of their developers or
data sources. However, assessing fairness is challenging as analysts might misidentify
sources of bias, fail to notice them, or misapply metrics. In this paper we introduce
Silva, a system for exploring potential sources of unfairness in datasets or machine
learning models interactively. Silva directs user attention to relationships between
attributes through a global causal view, provides interactive recommendations, presents
intermediate results, and visualizes metrics. We describe the implementation of Silva,
identify salient design and technical challenges, and provide an evaluation of the
tool in comparison to an existing fairness optimization tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive system, bias, machine learning fairness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376448,
author = {Wacharamanotham, Chat and Eisenring, Lukas and Haroz, Steve and Echtler, Florian},
title = {Transparency of CHI Research Artifacts: Results of a Self-Reported Survey},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376448},
doi = {10.1145/3313831.3376448},
abstract = {Several fields of science are experiencing a "replication crisis" that has negatively
impacted their credibility. Assessing the validity of a contribution via replicability
of its experimental evidence and reproducibility of its analyses requires access to
relevant study materials, data, and code. Failing to share them limits the ability
to scrutinize or build-upon the research, ultimately hindering scientific progress.Understanding
how the diverse research artifacts in HCI impact sharing can help produce informed
recommendations for individual researchers and policy-makers in HCI. Therefore, we
surveyed authors of CHI 2018-2019 papers, asking if they share their papers' research
materials and data, how they share them, and why they do not. The results (34% response
rate) show that sharing is uncommon, partly due to misunderstandings about the purpose
of sharing and reliable hosting. We conclude with recommendations for fostering open
research practices.This paper and all data and materials are freely available at https://osf.io/3bu6t.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {open data, open science, public data sharing, data availability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376449,
author = {B\^{a}ce, Mihai and Staal, Sander and Bulling, Andreas},
title = {Quantification of Users' Visual Attention During Everyday Mobile Device Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376449},
doi = {10.1145/3313831.3376449},
abstract = {We present the first real-world dataset and quantitative evaluation of visual attention of mobile device users in-situ, i.e. while using their devices during everyday routine. Understanding user attention is a core research challenge in mobile HCI but previous approaches relied on usage logs or self-reports that are only proxies and consequently do neither reflect attention completely nor accurately. Our evaluations are based on Everyday Mobile Visual Attention (EMVA) – a new 32-participant dataset containing around 472 hours of video snippets recorded over more than two weeks in real life using the front-facing camera as well as associated usage logs, interaction events, and sensor data. Using an eye contact detection method, we are first to quantify the highly dynamic nature of everyday visual attention across users, mobile applications, and usage contexts. We discuss key insights from our analyses that highlight the potential and inform the design of future mobile attentive user interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {eye contact detection, in-the-wild study, visual attention, mobile devices, attentive user interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376450,
author = {Park, Sunjeong and Lim, Youn-kyung},
title = {Investigating User Expectations on the Roles of Family-Shared AI Speakers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376450},
doi = {10.1145/3313831.3376450},
abstract = {AI assistants that use a voice user interface (VUI), such as AI speakers, have become
popular in family homes. However, it is still unclear what roles the AI speaker can
support within the family unit. We investigated the roles of an AI speaker as a family-shared
technology. By conducting a one-week participatory user study, we discovered that
family members' co-ownership toward the AI speaker was the key in the development
of its family-oriented roles. Our findings showed seven domains of user expectations
on these roles, and we realized that all the expectations can be represented as family
cohesion. In addition, privacy awareness was emphasized regarding personal supports.
Finally, we discuss a new perspective for AI speaker design and offer two suggestions:
1) leveraging human-likeness to develop its potential roles of supporting the unit
of a family and 2) interpreting the home context to seamlessly connect family and
personal supporting roles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {family, participatory design study, AI speaker},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376451,
author = {Wu, Tongshuang and Wongsuphasawat, Kanit and Ren, Donghao and Patel, Kayur and DuBois, Chris},
title = {Tempura: Query Analysis with Structural Templates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376451},
doi = {10.1145/3313831.3376451},
abstract = {Analyzing queries from search engines and intelligent assistants is difficult. A key
challenge is organizing queries into interpretable, context-preserving, representative,
and flexible groups. We present structural templates, abstract queries that replace
tokens with their linguistic feature forms, as a query grouping method. The templates
allow analysts to create query groups with structural similarity at different granularities.
We introduce Tempura, an interactive tool that lets analysts explore a query dataset
with structural templates. Tempura summarizes a query dataset by selecting a representative
subset of templates to show the query distribution. The tool also helps analysts navigate
the template space by suggesting related templates likely to yield further explorations.
Our user study shows that Tempura helps analysts examine the distribution of a query
dataset, find labeling errors, and discover model error patterns and outliers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {error analysis, query analysis, natural language processing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376452,
author = {Son, Kihoon and Chun, Hwiwon and Park, Sojin and Hyun, Kyung Hoon},
title = {C-Space: An Interactive Prototyping Platform for Collaborative Spatial Design Exploration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376452},
doi = {10.1145/3313831.3376452},
abstract = {C-Space is an interactive prototyping platform for collaborative spatial design exploration.
Spatial design projects often begin with conceptualization that includes abstract
diagramming, zoning, and massing to provide a foundation for making design decisions.
Specifically, abstract diagrams guide designers to explore alternative designs without
thinking prematurely about the details. However, complications arise when communicating
ambiguous and incomplete designs to collaborators. To overcome this drawback, designers
devote considerable amounts of time and resources into searching for design references
and creating rough prototypes to explicate their design concepts better. Therefore,
this study proposes C-Space, a novel design support system that integrates the abstract
diagram with design reference retrieval and prototyping through a tangible user interface
and augmented reality. Through a user study with 12 spatial designers, we verify that
C-Space promotes rapid and robust spatial design exploration, inducing collaborative
discussions and motivating users to interact with designs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design support system, augmented reality, human-computer interaction, design collaboration, prototyping, spatial design, tangible user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376453,
author = {Encinas, Enrique and Durrant, Abigail C. and Mitchell, Robb and Blythe, Mark},
title = {Metaprobes, Metaphysical Workshops and Sketchy Philosophy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376453},
doi = {10.1145/3313831.3376453},
abstract = {The intersection of philosophy and HCI is a longstanding site of interest for the
field that has been attracting special attention in recent years. In this paper, we
present metaphysical probes (Metaprobes) as a tool for design-led philosophical inquiry.
A Metaprobe is a design artifact used to study a metaphysical idea without concealing
the philosophical tools mobilized by the designers or the designerly knowledge attained
after deployment. We introduce the concept of a Metaphysical Workshop. This is the
set of sketchy philosophical notions that a designer mobilizes in order to research
a philosophical idea through design. We then present a case study that comprises:
the philosophical issue under examination, the Metaprobes designed to study it, the
metaphysical workshop used and the designerly insight produced. We conclude with a
discussion of the potentials and weaknesses of Metaprobes in relation to other critical
and speculative research-through-design practices. We aim to provide one way to make
philosophies already present in design more explicit and make other philosophical
concepts relevant to HCI more accessible and workable for designers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ontology, cultural probes, research through design, design fiction, philosophy, metaphysics, research fiction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376454,
author = {Hofman, Jake M. and Goldstein, Daniel G. and Hullman, Jessica},
title = {How Visualizing Inferential Uncertainty Can Mislead Readers About Treatment Effects in Scientific Results},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376454},
doi = {10.1145/3313831.3376454},
abstract = {When presenting visualizations of experimental results, scientists often choose to
display either inferential uncertainty (e.g., uncertainty in the estimate of a population
mean) or outcome uncertainty (e.g., variation of outcomes around that mean) about
their estimates. How does this choice impact readers' beliefs about the size of treatment
effects? We investigate this question in two experiments comparing 95% confidence
intervals (means and standard errors) to 95% prediction intervals (means and standard
deviations). The first experiment finds that participants are willing to pay more
for and overestimate the effect of a treatment when shown confidence intervals relative
to prediction intervals. The second experiment evaluates how alternative visualizations
compare to standard visualizations for different effect sizes. We find that axis rescaling
reduces error, but not as well as prediction intervals or animated hypothetical outcome
plots (HOPs), and that depicting inferential uncertainty causes participants to underestimate
variability in individual outcomes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {prediction intervals, judgment and decision making, effect sizes, uncertainty visualization, confidence intervals},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376455,
author = {Asai, Kentaro and Fukusato, Tsukasa and Igarashi, Takeo},
title = {Integrated Development Environment with Interactive Scatter Plot for Examining Statistical Modeling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376455},
doi = {10.1145/3313831.3376455},
abstract = {The development of a statistical modeling program requires example data to observe
and verify the behavior of the program. Such example data are either taken from an
existing dataset or synthesized using commands. Programmers may want to directly design
an arbitrary dataset or modify it interactively, but it is difficult to do so in current
development environments. We therefore propose combining a code editor with an interactive
scatter plot editor to efficiently understand the behavior of statistical modeling
algorithms. The user interactively creates and modifies the dataset on the scatter
plot editor, while the system continuously executes the code in the editor, taking
the data as input, and shows the result in the editor. This paper presents the design
rationale behind the system and introduces several usage scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {statistical modeling, live programming, interactive data design and editing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376456,
author = {Phadke, Shruti and Mitra, Tanushree},
title = {Many Faced Hate: A Cross Platform Study of Content Framing and Information Sharing by Online Hate Groups},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376456},
doi = {10.1145/3313831.3376456},
abstract = {Hate groups are increasingly using multiple social media platforms to promote extremist
ideologies. Yet we know little about their communication practices across platforms.
How do hate groups (or "in-groups"), frame their hateful agenda against the targeted
group or the "out-group?" How do they share information? Utilizing "framing" theory
from social movement research and analyzing domains in the shared links, we juxtapose
the Facebook and Twitter communication of 72 Southern Poverty Law Center (SPLC) designated
hate groups spanning five hate ideologies. Our findings show that hate groups use
Twitter for educating the audience about problems with the out-group, maintaining
positive self-image by emphasizing in-group's high social status, and for demanding
policy changes to negatively affect the out-group. On Facebook, they use fear appeals,
call for active participation in group events (membership requests), all while portraying
themselves as being oppressed by the out-group and failed by the system. Our study
unravels the ecosystem of cross-platform communication by hate groups, suggesting
that they use Facebook for group radicalization and recruitment, while Twitter for
reaching a diverse follower base.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cross-platform, information sharing, hate groups, framing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376457,
author = {Abbott, Jacob and Patil, Sameer},
title = {How Mandatory Second Factor Affects the Authentication User Experience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376457},
doi = {10.1145/3313831.3376457},
abstract = {Recent years have seen growing organizational adoption of two-factor authentication
as organizations seek to limit the damage caused by password breaches. However, research
on the user experience of two-factor authentication in a real-world setting is relatively
scant. To fill this gap, we conducted multiple waves of an online survey of users
at a large public university during its multi-phase rollout of mandatory two-factor
authentication for faculty, staff, and students. In addition, we examined multiple
months of logs of all authentication events at the university. We found no significant
changes in user experience and acceptance of two-factor authentication when it was
mandatory for select systems that dealt with sensitive information. However, these
factors degraded when users were forced to use two-factor authentication for logging
into every single university resource. Our findings can serve as important guidance
for the implementation of two-factor authentication in organizations in a way that
can help achieve a balance between security and user experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {two-factor authentication, login, multi-factor authentication, university it, user experience, 2fa, security, ux},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376458,
author = {Tachtler, Franziska and Michel, Toni and Slov\'{a}k, Petr and Fitzpatrick, Geraldine},
title = {Supporting the Supporters of Unaccompanied Migrant Youth: Designing for Social-Ecological Resilience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376458},
doi = {10.1145/3313831.3376458},
abstract = {Unaccompanied migrant youth, fleeing to a new country without their parents, are exposed
to mental health risks. Resilience interventions mitigate such risks, but access can
be hindered by systemic and personal barriers. While much work has recently addressed
designing technology to promote mental health, none has focused on the needs of these
populations. This paper presents the results of interviews with 18 professional/ volunteer
support workers and 5 unaccompanied migrant youths, followed by three design workshops.
The results point to the diverse systems that can facilitate youths' resilience development.
The relationship between the youth and volunteers acting as mentors is particularly
important for increasing resilience but comes with challenges. This suggests the relevance
of a social-ecological model of resilience with a focus on designing technology to
support the mentors in order to help them better support the youth. We conclude by
mapping out the design space for mentor support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {care, resilience, mental health technology, refugees},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376459,
author = {Chivukula, Shruthi Sai and Watkins, Chris Rhys and Manocha, Rhea and Chen, Jingle and Gray, Colin M.},
title = {Dimensions of UX Practice That Shape Ethical Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376459},
doi = {10.1145/3313831.3376459},
abstract = {HCI researchers are increasingly interested in describing the complexity of design
practice, including ethical, organizational, and societal concerns. Recent studies
have identified individual practitioners as key actors in driving the design process
and culture within their respective organizations, and we build upon these efforts
to reveal practitioner concerns regarding ethics on their own terms. In this paper,
we report on the results of an interview study with eleven UX practitioners, capturing
their experiences that highlight dimensions of design practice that impact ethical
awareness and action. Using a bottom-up thematic analysis, we identified five dimensions
of design complexity that influence ethical outcomes and span individual, collaborative,
and methodological framing of UX activity. Based on these findings, we propose a set
of implications for the creation of ethically-centered design methods that resonate
with this complexity and inform the education of future UX practitioners.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {UX practice, practice-led research, values, ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376460,
author = {Smith, Taliesin L. and Moore, Emily B.},
title = {Storytelling to Sensemaking: A Systematic Framework for Designing Auditory Description Display for Interactives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376460},
doi = {10.1145/3313831.3376460},
abstract = {Auditory description display is verbalized text typically used to describe live, recorded,
or graphical displays to support access for people who are blind or visually impaired.
Significant prior research has resulted in guidelines for auditory description for
non-interactive or minimally interactive contexts. A lack of auditory description
for complex interactive environments remains a tremendous barrier to access for people
with visual impairments. In this work, we present a systematic design framework for
designing auditory description within complex interactive environments. We illustrate
how modular descriptions aligned with this framework can result in an interactive
storytelling experience constructed through user interactions. This framework has
been used in a set of published and widely used interactive science simulations, and
in its generalized form could be applied to a variety of contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {description design, auditory description display, non-visual access, interactive information spaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376461,
author = {Chin, Hyojin and Molefi, Lebogang Wame and Yi, Mun Yong},
title = {Empathy Is All You Need: How a Conversational Agent Should Respond to Verbal Abuse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376461},
doi = {10.1145/3313831.3376461},
abstract = {With the popularity of AI-infused systems, conversational agents (CAs) are becoming
essential in diverse areas, offering new functionality and convenience, but simultaneously,
suffering misuse and verbal abuse. We examine whether conversational agents' response
styles under varying abuse types influence those emotions found to mitigate peoples'
aggressive behaviors, involving three verbal abuse types (Insult, Threat, Swearing)
and three response styles (Avoidance, Empathy, Counterattacking). Ninety-eight participants
were assigned to one of the abuse type conditions, interacted with the three spoken
(voice-based) CAs in turn, and reported their feelings about guiltiness, anger, and
shame after each session. The results show that the agent's response style has a significant
effect on user emotions. Participants were less angry and more guilty with the empathy
agent than the other two agents. Furthermore, we investigated the current status of
commercial CAs' responses to verbal abuse. Our study findings have direct implications
for the design of conversational agents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart speaker, agent abuse, virtual assistant, verbal abuse, conversational agent, intelligent personal assistant},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376462,
author = {Concannon, Shauna and Rajan, Natasha and Shah, Parthiv and Smith, Davy and Ursu, Marian and Hook, Jonathan},
title = {Brooke Leave Home: Designing a Personalized Film to Support Public Engagement with Open Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376462},
doi = {10.1145/3313831.3376462},
abstract = {Brooke Leave Home is a personalized film designed to engage a non-expert audience
with open data about the support young adults receive when leaving the care system
in England. The film draws upon a range of video-based data storytelling techniques
to present each viewer with a personalized perspective on the topic based on data
from their own local area. We present the film's design and describe how its storytelling
techniques were developed to support viewers in understanding, and fostering empathic
connections with, the data sources featured and the implications they have for care
leavers. We also present a study with 47 viewers, which explores how these techniques
were experienced and how effective they were in aiding engagement with the data included
and its meaning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {film, narrative, data, storytelling, video, personalization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376463,
author = {Spagnolli, Anna and Mora, Diletta and Fanchin, Matteo and Orso, Valeria and Gamberini, Luciano},
title = {Automation and Creativity: A Case Study of DJs' and VJs' Ambivalent Positions on Automated Visual Software},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376463},
doi = {10.1145/3313831.3376463},
abstract = {Computerized solutions in the domain of creativity and expressive performance increasingly
provide art and artists with exciting new opportunities. However, the combination
of automation and creativity also raises controversies and resistance in some user
groups. This paper considers the case of software-generated visuals in live music
performance and tries to make sense of the ambivalent response given by its intended
users (i.e., DJs and VJs). We carried out seven face-to-face interviews, an online
survey (N = 102) and 25 interviews at a distance to unravel DJs' and VJs' positions
on automated visual software. Four core controversies were eventually identified,
gravitating around the implications of using such software on DJs' and VJs' identities
as artists and on their competitive advantage in their activity sector. The conclusions
reconnect these findings with the larger issue of understanding the users' responses
to automation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {argumentation, ambivalence, creativity, automation, visual software, live music performance, acceptance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376464,
author = {Johnson, Ian G. and Al-Shahrabi, Dalya and Vines, John},
title = {From Creating Spaces for Civic Discourse to Creating Resources for Action},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376464},
doi = {10.1145/3313831.3376464},
abstract = {In this paper, we investigate the role of technology to address the concerns of a
civil society group carrying out community-level consultation on the allocation of
£1 million of community funds. We explore issues of devolved decision-making through
the evaluation of a sociodigital system designed to foster deliberative virtues. We
describe the ways in which this group used our system in their consultation practices.
Our findings highlight how they adopted our technology to privilege specific forms
of expression, ascertain issues in their community, make use of and make sense of
community data, and create resources for action within their existing practices. Based
on related fieldwork we discuss the impacts of structuring and configuring tools for 'talk-based' consultation in order to turn attention to the potential pitfalls and
prospects for designing civic technologies that create resources for action for civil
society.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {civic technology, civil society, digital civics, deliberation, civic participation, sociodigital systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376465,
author = {Pendse, Sachin R. and Lalani, Faisal M. and De Choudhury, Munmun and Sharma, Amit and Kumar, Neha},
title = {"Like Shock Absorbers": Understanding the Human Infrastructures of Technology-Mediated Mental Health Support},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376465},
doi = {10.1145/3313831.3376465},
abstract = {Significant research in HCI and beyond has sought to understand end-user needs in formal and informal technology-mediated mental health support (TMMHS) systems. However, little work has been done to understand the experiences and needs of the individuals who power or support these systems, particularly in the Global South. We present a qualitative study of one of the most accessible forms of mental health care in India — helplines. Through in-depth interviews conducted with 12 helpline volunteers, we research the human infrastructure responsible for the functioning of helplines. We foreground the often invisible labor involved in erecting and maintaining the institutional, interpersonal, and individual boundaries that are critical to realizing the goals of these helplines. Finally, we discuss the implications of our research for future work examining human infrastructures, particularly in mental health settings, and for the design of future TMMHS systems that deliver on-demand care to diverse, underserved, and stigmatized populations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {HCI4D, India, helplines, help-seeking, mental health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376466,
author = {Pu, Xiaoying and Kay, Matthew},
title = {A Probabilistic Grammar of Graphics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376466},
doi = {10.1145/3313831.3376466},
abstract = {Visualizations depicting probabilities and uncertainty are used everywhere from medical
risk communication to machine learning, yet these probabilistic visualizations are
difficult to specify, prone to error, and their designs are cumbersome to explore.
We propose a Probabilistic Grammar of Graphics (PGoG), an extension to Wilkinson's
original framework. Inspired by the success of probabilistic programming languages,
PGoG makes probability expressions, such as P(A|B), a first-class citizen in the language.
PGoG abstractions also reflect the distinction between probability and frequency framing,
a concept from the uncertainty communication literature. It is expressive, encompassing
product plots, density plots, icon arrays, and dotplots, among other visualizations.
Its coherent syntax ensures correctness (that the proportions of visual elements and
their spatial placement reflect the underlying probability distribution) and reduces
edit distance between probabilistic visualization specifications, potentially supporting
more design exploration. We provide a proof-of-concept implementation of PGoG in R.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {uncertainty visualization, grammar of graphics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376467,
author = {Kim, Dae Hyun and Hoque, Enamul and Agrawala, Maneesh},
title = {Answering Questions about Charts and Generating Visual Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376467},
doi = {10.1145/3313831.3376467},
abstract = {People often use charts to analyze data, answer questions and explain their answers
to others. In a formative study, we find that such human-generated questions and explanations
commonly refer to visual features of charts. Based on this study, we developed an
automatic chart question answering pipeline that generates visual explanations describing
how the answer was obtained. Our pipeline first extracts the data and visual encodings
from an input Vega-Lite chart. Then, given a natural language question about the chart,
it transforms references to visual attributes into references to the data. It next
applies a state-of-the-art machine learning algorithm to answer the transformed question.
Finally, it uses a template-based approach to explain in natural language how the
answer is determined from the chart's visual features. A user study finds that our
pipeline-generated visual explanations significantly outperform in transparency and
are comparable in usefulness and trust to human-generated explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {explainable ai, question answering, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376468,
author = {Soni, Nikita and Gleaves, Schuyler and Neff, Hannah and Morrison-Smith, Sarah and Esmaeili, Shaghayegh and Mayne, Ian and Bapat, Sayli and Schuman, Carrie and Stofer, Kathryn A. and Anthony, Lisa},
title = {Adults' and Children's Mental Models for Gestural Interactions with Interactive Spherical Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376468},
doi = {10.1145/3313831.3376468},
abstract = {Interactive spherical displays offer numerous opportunities for engagement and education
in public settings. Prior work established that users' touch-gesture patterns on spherical
displays differ from those on flatscreen tabletops, and speculated that these differences
stem from dissimilarity in how users conceptualize interactions with these two form
factors. We analyzed think-aloud data collected during a gesture elicitation study
to understand adults' and children's (ages 7 to 11) conceptual models of interaction
with spherical displays and compared them to conceptual models of interaction with
tabletop displays from prior work. Our findings confirm that the form factor strongly
influenced users' mental models of interaction with the sphere. For example, participants
conceptualized that the spherical display would respond to gestures in a similar way
as real-world spherical objects like physical globes. Our work contributes new understanding
of how users draw upon the perceived affordances of the sphere as well as prior touchscreen
experience during their interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touchscreen gestures, interactive spherical displays, adults, touchscreen displays, children, mental models},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376469,
author = {Diana, Nicholas and Stamper, John and Koedinger, Ken},
title = {Towards Value-Adaptive Instruction: A Data-Driven Method for Addressing Bias in Argument Evaluation Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376469},
doi = {10.1145/3313831.3376469},
abstract = {As the media landscape is increasingly populated by less than reputable sources of
information, educators have turned to argument evaluation training as a potential
solution. Unfortunately, the bias literature suggests that our ability to objectively
evaluate an argument is, to a large extent, determined by the relationship between
our own beliefs and the beliefs latent in the argument we are evaluating. If the argument
supports our worldview, we are much more likely to overlook logical errors. Teachers
recognize this need to adapt argument evaluation instruction to the specific beliefs
of students. For instance, a teacher might intentionally assign a student an argument
that the student disagrees with. Unfortunately, this kind of value-adaptive instruction
is infrequent due to its unscalability. We propose a novel method for data-driven
value-adaptive instruction in instructional technologies. This method can be used
to combat bias in real-world contexts and support human reasoning during media consumption.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {educational technology, human-computer interaction, civic education, civic technology, adaptive instruction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376470,
author = {Fang, Cathy and Zhang, Yang and Dworman, Matthew and Harrison, Chris},
title = {Wireality: Enabling Complex Tangible Geometries in Virtual Reality with Worn Multi-String Haptics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376470},
doi = {10.1145/3313831.3376470},
abstract = {Today's virtual reality (VR) systems allow users to explore immersive new worlds and
experiences through sight. Unfortunately, most VR systems lack haptic feedback, and
even high-end consumer systems use only basic vibration motors. This clearly precludes
realistic physical interactions with virtual objects. Larger obstacles, such as walls,
railings, and furniture are not simulated at all. In response, we developed Wireality,
a self-contained worn system that allows for individual joints on the hands to be
accurately arrested in 3D space through the use of retractable wires that can be programmatically
locked. This allows for convincing tangible interactions with complex geometries,
such as wrapping fingers around a railing. Our approach is lightweight, low-cost,
and low-power, criteria important for future, worn consumer uses. In our studies,
we further show that our system is fast-acting, spatially-accurate, high-strength,
comfortable, and immersive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {haptics, string-driven, force feedback, touch, grasp, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376471,
author = {Campo Woytuk, Nadia and S\o{}ndergaard, Marie Louise Juul and Ciolfi Felice, Marianela and Balaam, Madeline},
title = {Touching and Being in Touch with the Menstruating Body},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376471},
doi = {10.1145/3313831.3376471},
abstract = {We describe a Research through Design project-Curious Cycles-a collection of objects
and interactions which encourage people to be in close contact with their menstruating
body. Throughout a full menstrual cycle, five participants used Curious Cycles to
look at their bodies in unfamiliar ways and to touch their bodily fluids, specifically,
menstrual blood, saliva, and cervical mucus. The act of touching and looking led to
the construction of new knowledge about the self and to a nurturing appreciation for
the changing body. Yet, participants encountered and reflected upon frictions within
themselves, their home, and their social surroundings, which stem from societal stigma
and preconceptions about menstruation and bodily fluids. We call for and show how
interaction design can engage with technologies that mediate self-touch as a first
step towards reconfiguring the way menstruating bodies are treated in society.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {research through design, women's health, menstruation, menstrual cycles, touching, feminist hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376472,
author = {Colley, Mark and Walch, Marcel and Gugenheimer, Jan and Askari, Ali and Rukzio, Enrico},
title = {Towards Inclusive External Communication of Autonomous Vehicles for Pedestrians with Vision Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376472},
doi = {10.1145/3313831.3376472},
abstract = {People with vision impairments (VIP) are among the most vulnerable road users in traffic.
Autonomous vehicles are believed to reduce accidents but still demand some form of
external communication signaling relevant information to pedestrians. Recent research
on the design of vehicle-pedestrian communication (VPC) focuses strongly on concepts
for a non-disabled population. Our work presents an inclusive user-centered design
for VPC, beneficial for both vision impaired and seeing pedestrians. We conducted
a workshop with VIP (N=6), discussing current issues in road traffic and comparing
communication concepts proposed by literature. A thematic analysis unveiled two important
themes: number of communicating vehicles and content (affecting duration). Subsequently,
we investigated these in a second user study in virtual reality (N=33, 8 VIP) comparing
the VPC between groups of abilities. We found that trust and understanding is enhanced
and cognitive load reduced when all relevant vehicles communicate; high content messages
also reduce cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {external communication, autonomous vehicles, vulnerable road users, accessibility, inclusive design research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376473,
author = {Wang, Yihong and Papangelis, Konstantinos and Saker, Michael and Lykourentzou, Ioanna and Chamberlain, Alan and Khan, Vassilis-Javed},
title = {Crowdsourcing in China: Exploring the Work Experiences of Solo Crowdworkers and Crowdfarm Workers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376473},
doi = {10.1145/3313831.3376473},
abstract = {Recent research highlights the potential of crowdsourcing in China. Yet very few studies
explore the workplace context and experiences of Chinese crowdworkers. Those that
do, focus mainly on the work experiences of solo crowdworkers but do not deal with
issues pertaining to the substantial amount of people working in 'crowdfarms'. This
article addresses this gap as one of its primary concerns. Drawing on a study that
involves 48 participants, our research explores, compares and contrasts the work experiences
of solo crowdworkers to those of crowdfarm workers. Our findings illustrate that the
work experiences and context of the solo workers and crowdfarm workers are substantially
different, with regards to their motivations, the ways they engage with crowdsourcing,
the tasks they work on, and the crowdsourcing platforms they utilize. Overall, our
study contributes to furthering the understandings on the work experiences of crowdworkers
in China.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {crowdworkers, work experience, crowdfarms, reputation management, motivations and attitudes, work life balance, crowdsourcing, tasks, platform satisfaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376474,
author = {Hudson, Lorraine and Amponsah, Clement and Bampoe, Josephine Ohenewa and Marshall, Julie and Owusu, Nana Akua Victoria and Hussein, Khalid and Linington, Jess and Banks Gross, Zoe and Stokes, Jane and McNaney, R\'{o}is\'{\i}n},
title = {Co-Designing Digital Tools to Enhance Speech and Language Therapy Training in Ghana},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376474},
doi = {10.1145/3313831.3376474},
abstract = {Ghana has a population of over 27 million people, of which 1 in 15 may have a communication
disability. The number of speech and language therapists (SLTs) available to support
these people remains remarkably small, presenting a major workforce challenge. As
an emerging profession, there remain significant challenges around educating the first
generation of SLTs. Ghana, however, has a healthy digital infrastructure which can
be taken advantage of. We describe a comprehensive study which aimed to co-design
a set of locally appropriate digital tools to enhance SLT training in Ghana. We contribute
insights into how digital tools could support social learning and the transition from
student to independent practitioner and future clinical supervisor. We offer a set
of design recommendations for creating an online Community of Practice to enhance
continuing professional development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile learning, co-design, speech and language therapy, ghana},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376475,
author = {Lee, Kwangyoung and Cho, Hyewon and Toshnazarov, Kobiljon and Narziev, Nematjon and Rhim, So Young and Han, Kyungsik and Noh, YoungTae and Hong, Hwajung},
title = {Toward Future-Centric Personal Informatics: Expecting Stressful Events and Preparing Personalized Interventions in Stress Management},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376475},
doi = {10.1145/3313831.3376475},
abstract = {Stress is caused by a variety of events in our daily lives. By anticipating stressful situations, we can prepare and better cope with stressors when they actually occur. However, many past-centric personal informatics (PI) tools focus on capturing events that already happened and analyzing the data. In this work, we examine how anticipation — a future-centric self-tracking practice — could be used to manage daily stress levels. To address this, we built MindForecaster, a calendar- mediated stress anticipation application that allows users to expect stressful events in advance, generates activities to mitigate stress, and evaluates actual stress levels compared to previously estimated stress levels. In a 30-day deployment with 47 users, the users who explicitly planned and executed coping interventions reported reduced stress more than those who only expected stressful events. We suggest design implications for stress management by incorporating the properties of anticipation into current PI models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {anticipation, intervention, stress, future-centric personal informatics, coping planning, self-experimentation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376476,
author = {Huang, Hsin-Yu and Ning, Chih-Wei and Wang, Po-Yao and Cheng, Jen-Hao and Cheng, Lung-Pan},
title = {Haptic-Go-Round: A Surrounding Platform for Encounter-Type Haptics in Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376476},
doi = {10.1145/3313831.3376476},
abstract = {We present Haptic-go-round, a surrounding platform that allows deploying props and
devices to provide haptic feedbacks in any direction in virtual reality experiences.
The key component of Haptic-go-round is a motorized turntable that rotates the correct
haptic device to the right direction at the right time to match what users are about
to touch. We implemented a working platform including plug-and-play prop cartridges
and a software interface that allow experience designers to agilely add their haptic
components and use the platform for their applications. We conducted technical experiments
and two user studies on Haptic-go-round to evaluate its performance. We report the
results and discuss our insights and limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {props, virtual reality, encounter-type haptic feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376477,
author = {Das, Maitraye and Borgos-Rodriguez, Katya and Piper, Anne Marie},
title = {Weaving by Touch: A Case Analysis of Accessible Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376477},
doi = {10.1145/3313831.3376477},
abstract = {The rise of maker communities and fabrication tools creates new opportunities for
participation in design work. With this has come an interest in increasing the accessibility
of making for people with disabilities, which has mainly emphasized independence and
empowerment through the creation of more accessible fabrication tools. To understand
and rethink the notion of accessible making, we analyze the context and practices
of a particular site of making: the communal weaving studio within an assisted living
facility for people with vision impairments. Our analysis helps reconsider the material
and social processes that constitute accessible making, including the ways makers
attend to interactive material properties, negotiate co-creative embodied work, and
value the labor of making. We discuss future directions for design and research on
accessible making while highlighting tensions around assistance, collaboration, and
how disabled labor is valued.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {materiality, disability, making, vision impairments, design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376478,
author = {Murnane, Elizabeth L. and Jiang, Xin and Kong, Anna and Park, Michelle and Shi, Weili and Soohoo, Connor and Vink, Luke and Xia, Iris and Yu, Xin and Yang-Sammataro, John and Young, Grace and Zhi, Jenny and Moya, Paula and Landay, James A.},
title = {Designing Ambient Narrative-Based Interfaces to Reflect and Motivate Physical Activity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376478},
doi = {10.1145/3313831.3376478},
abstract = {Numerous technologies now exist for promoting more active lifestyles. However, while
quantitative data representations (e.g., charts, graphs, and statistical reports)
typify most health tools, growing evidence suggests such feedback can not only fail
to motivate behavior but may also harm self-integrity and fuel negative mindsets about
exercise. Our research seeks to devise alternative, more qualitative schemes for encoding
personal information. In particular, this paper explores the design of data-driven
narratives, given the intuitive and persuasive power of stories. We present WhoIsZuki,
a smartphone application that visualizes physical activities and goals as components
of a multi-chapter quest, where the main character's progress is tied to the user's.
We report on our design process involving online surveys, in-lab studies, and in-the-wild
deployments, aimed at refining the interface and the narrative and gaining a deep
understanding of people's experiences with this type of feedback. From these insights,
we contribute recommendations to guide future development of narrative-based applications
for motivating healthy behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {narrative feedback, mobile health, ambient display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376479,
author = {Mayer, Sven and Laput, Gierad and Harrison, Chris},
title = {Enhancing Mobile Voice Assistants with WorldGaze},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376479},
doi = {10.1145/3313831.3376479},
abstract = {Contemporary voice assistants require that objects of inter-est be specified in spoken
commands. Of course, users are often looking directly at the object or place of interest
? fine-grained, contextual information that is currently unused. We present WorldGaze,
a software-only method for smartphones that provides the real-world gaze location
of a user that voice agents can utilize for rapid, natural, and precise interactions.
We achieve this by simultaneously opening the front and rear cameras of a smartphone.
The front-facing camera is used to track the head in 3D, including estimating its
direction vector. As the geometry of the front and back cameras are fixed and known,
we can raycast the head vector into the 3D world scene as captured by the rear-facing
camera. This allows the user to intuitively define an object or region of interest
using their head gaze. We started our investigations with a qualitative exploration
of competing methods, before developing a functional, real-time implementation. We
conclude with an evaluation that shows WorldGaze can be quick and accurate, opening
new multimodal gaze+voice interactions for mobile voice agents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {worldgaze, interaction techniques, mobile interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376480,
author = {Schneider, Adrian L. Jessup and Keiver, Kathy and Pritchard Orr, Alison and Reynolds, James N. and Golubovich, Neven and Graham, T.C. Nicholas},
title = {Toward the Design of Enjoyable Games for Children with Fetal Alcohol Spectrum Disorder},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376480},
doi = {10.1145/3313831.3376480},
abstract = {Fetal Alcohol Spectrum Disorder (FASD) is a heterogeneous and complex set of disorders
caused by prenatal alcohol exposure, estimated to affect 2-5% of the North American
population. Deficits associated with FASD affect social skill development and executive
function, including emotional regulation and impulse control. These deficits can increase
the difficulty of playing digital games. While considerable research has been performed
in understanding how to design games for people with neurodevelopmental disorders
in general, there is little data on how to design engaging games for children with
FASD. We conducted a ten-week in-school gaming trial with eleven elementary-aged children
with diagnosed or suspected FASD. Participants enjoyed playing together and responded
well to the in-game reward system, while some game elements caused unexpected frustration.
Based on our observations, we advise that games for FASD be designed to have low cost
of failure, avoid retracting options, account for taking breaks when needed, show
progression in rewards, and enable cooperative play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social play, executive function, FASD, game design, fetal alcohol spectrum disorder},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376481,
author = {Wilberz, Alexander and Leschtschow, Dominik and Trepkowski, Christina and Maiero, Jens and Kruijff, Ernst and Riecke, Bernhard},
title = {FaceHaptics: Robot Arm Based Versatile Facial Haptics for Immersive Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376481},
doi = {10.1145/3313831.3376481},
abstract = {This paper introduces FaceHaptics, a novel haptic display based on a robot arm attached
to a head-mounted virtual reality display. It provides localized, multi-directional
and movable haptic cues in the form of wind, warmth, moving and single-point touch
events and water spray to dedicated parts of the face not covered by the head-mounted
display.The easily extensible system, however, can principally mount any type of compact
haptic actuator or object. User study 1 showed that users appreciate the directional
resolution of cues, and can judge wind direction well, especially when they move their
head and wind direction is adjusted dynamically to compensate for head rotations.
Study 2 showed that adding FaceHaptics cues to a VR walkthrough can significantly
improve user experience, presence, and emotional responses.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, emotion, haptics, immersive environments, perception, presence, robot arm, user study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376482,
author = {Burke, Moira and Cheng, Justin and de Gant, Bethany},
title = {Social Comparison and Facebook: Feedback, Positivity, and Opportunities for Comparison},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376482},
doi = {10.1145/3313831.3376482},
abstract = {People compare themselves to one another both offline and online. The specific online
activities that worsen social comparison are partly understood, though much existing
research relies on people recalling their own online activities post hoc and is situated
in only a few countries. To better understand social comparison worldwide and the
range of associated behaviors on social media, a survey of 38,000 people from 18 countries
was paired with logged activity on Facebook for the prior month. People who reported
more frequent social comparison spent more time on Facebook, had more friends, and
saw proportionally more social content on the site. They also saw greater amounts
of feedback on friends' posts and proportionally more positivity. There was no evidence
that social comparison happened more with acquaintances than close friends. One in
five respondents recalled recently seeing a post that made them feel worse about themselves
but reported conflicting views: half wished they hadn't seen the post, while a third
felt very happy for the poster. Design opportunities are discussed, including hiding
feedback counts, filters for topics and people, and supporting meaningful interactions,
so that when comparisons do occur, people are less affected by them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {facebook, well-being, social media, envy, social comparison},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376483,
author = {Lewis, Blaine and d'Eon, Greg and Cockburn, Andy and Vogel, Daniel},
title = {KeyMap: Improving Keyboard Shortcut Vocabulary Using Norman's Mapping},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376483},
doi = {10.1145/3313831.3376483},
abstract = {We introduce a new shortcut interface called KeyMap that is designed to leverage Norman's
principle of natural mapping. Rather than displaying shortcut command labels in linear
menus, KeyMap displays a virtual keyboard with command labels displayed directly on
its keys. A crowdsourced experiment compares KeyMap to Malacria et al.'s ExposeHK
using an extension of their protocol to also test recall. Results show KeyMap users
remembered 1 more shortcut than ExposeHK immediately after training, and this advantage
increased to 4.5 more shortcuts when tested again after 24 hours. KeyMap users also
incidentally learned more shortcuts that they had never practised. We demonstrate
how KeyMap can be added to existing web-based applications using a Chrome extension.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {learning, keyboard shortcuts, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376484,
author = {Faas, Stefanie M. and Kao, Andrea C. and Baumann, Martin},
title = {A Longitudinal Video Study on Communicating Status and Intent for Self-Driving Vehicle – Pedestrian Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376484},
doi = {10.1145/3313831.3376484},
abstract = {With self-driving vehicles (SDVs), pedestrians cannot rely on communication with the
driver anymore. Industry experts and policymakers are proposing an external Human-Machine
Interface (eHMI) communicating the automated status. We investigated whether additionally
communicating SDVs' intent to give right of way further improves pedestrians' street
crossing. To evaluate the stability of these eHMI effects, we conducted a three-session
video study with N=34 pedestrians where we assessed subjective evaluations and crossing
onset times. This is the first work capturing long-term effects of eHMIs. Our findings
add credibility to prior studies by showing that eHMI effects last (acceptance, user
experience) or even increase (crossing onset, perceived safety, trust, learnability,
reliance) with time. We found that pedestrians benefit from an eHMI communicating
SDVs' status, and that additionally communicating SDVs' intent adds further value.
We conclude that SDVs should be equipped with an eHMI communicating both status and
intent.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {information need, self-driving vehicles, external human-machine interface, pedestrians, intent, status},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376485,
author = {Gathani, Sneha and Lim, Peter and Battle, Leilani},
title = {Debugging Database Queries: A Survey of Tools, Techniques, and Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376485},
doi = {10.1145/3313831.3376485},
abstract = {Database management systems (or DBMSs) have been around for decades, and yet are still
difficult to use, particularly when trying to identify and fix errors in user programs
(or queries). We seek to understand what methods have been proposed to help people
debug database queries, and whether these techniques have ultimately been adopted
by DBMSs (and users). We conducted an interdisciplinary review of 112 papers and tools
from the database, visualisation and HCI communities. To better understand whether
academic and industry approaches are meeting the needs of users, we interviewed 20
database users (and some designers), and found surprising results. In particular,
there seems to be a wide gulf between users' debugging strategies and the functionality
implemented in existing DBMSs, as well as proposed in the literature. In response,
we propose new design guidelines to help system designers to build features that more
closely match users debugging strategies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {debugging databases, empirical study, visualization, literature review, survey},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376486,
author = {Heshmat, Yasamin and Neustaedter, Carman and McCaffrey, Kyle and Odom, William and Wakkary, Ron and Yang, Zikun},
title = {FamilyStories: Asynchronous Audio Storytelling for Family Members Across Time Zones},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376486},
doi = {10.1145/3313831.3376486},
abstract = {Family members who are separated across time zones can easily miss out on feeling
connected. We designed and studied the usage of an asynchronous storytelling system,
called FamilyStories, to explore the use of audio-based sharing. FamilyStories allows
family members to share activities and experiences over distance in different time
zones using three different devices that contain different contextual features. To
evaluate the design, we conducted a five-week long field study with two family member
pairs. Our results show the value of slow, flexible, and non-suggestive interfaces
for asynchronous audio communication. We also found ephemerality helped in the sharing
of 'instant' feelings, while large time zone differences could be 'synchronized' with
time delayed messages. We raise these as design opportunities for asynchronous audio
storytelling systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {asynchronous communication, family communication, domestic, audio, slow technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376488,
author = {Cryan, Jenna and Tang, Shiliang and Zhang, Xinyi and Metzger, Miriam and Zheng, Haitao and Zhao, Ben Y.},
title = {Detecting Gender Stereotypes: Lexicon vs. Supervised Learning Methods},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376488},
doi = {10.1145/3313831.3376488},
abstract = {Biases in language influence how we interact with each other and society at large.
Language affirming gender stereotypes is often observed in various contexts today,
from recommendation letters and Wikipedia entries to fiction novels and movie dialogue.
Yet to date, there is little agreement on the methodology to quantify gender stereotypes
in natural language (specifically the English language). Common methodology (including
those adopted by companies tasked with detecting gender bias) rely on a lexicon approach
largely based on the original BSRI study from 1974.In this paper, we reexamine the
role of gender stereotype detection in the context of modern tools, by comparatively
analyzing efficacy of lexicon-based approaches and end-to-end, ML-based approaches
prevalent in state-of-the-art natural language processing systems. Our efforts using
a large dataset show that even compared to an updated lexicon-based approach, end-to-end
classification approaches are significantly more robust and accurate, even when trained
by moderately sized corpora.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gender bias, machine learning, lexicon, natural language processing, gender stereotypes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376489,
author = {Henrikson, Rorik and Grossman, Tovi and Trowbridge, Sean and Wigdor, Daniel and Benko, Hrvoje},
title = {Head-Coupled Kinematic Template Matching: A Prediction Model for Ray Pointing in VR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376489},
doi = {10.1145/3313831.3376489},
abstract = {This paper presents a new technique to predict the ray pointer landing position for
selection movements in virtual reality (VR) environments. The technique adapts and
extends a prior 2D kinematic template matching method to VR environments where ray
pointers are used for selection. It builds on the insight that the kinematics of a
controller and Head-Mounted Display (HMD) can be used to predict the ray's final landing
position and angle. An initial study provides evidence that the motion of the head
is a key input channel for improving prediction models. A second study validates this
technique across a continuous range of distances, angles, and target sizes. On average,
the technique's predictions were within 7.3° of the true landing position when 50%
of the way through the movement and within 3.4° when 90%. Furthermore, compared to
a direct extension of Kinematic Template Matching, which only uses controller movement,
this head-coupled approach increases prediction accuracy by a factor of 1.8x when
40% of the way through the movement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ray pointing, target prediction, kinematics, endpoint prediction, vr, virtual reality, template matching},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376490,
author = {Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane and Cruice, Madeline},
title = {CreaTable Content and Tangible Interaction in Aphasia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376490},
doi = {10.1145/3313831.3376490},
abstract = {Multimedia digital content (combining pictures, text and music) is ubiquitous. The
process of creating such content using existing tools typically requires complex,
language-laden interactions which pose a challenge for users with aphasia (a language
impairment following brain injury). Tangible interactions offer a potential means
to address this challenge, however, there has been little work exploring their potential
for this purpose. In this paper, we present CreaTable a platform that enables us to
explore tangible interaction as a means of supporting digital content creation for
people with aphasia. We report details of the co-design of CreaTable and findings
from a digital creativity workshop. Workshop findings indicated that CreaTable enabled
people with aphasia to create something they would not otherwise have been able to.
We report how users' aphasia profiles affected their experience, describe tensions
in collaborative content creation and provide insight into more accessible content
creation using tangibles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {creativity, creativity support, aphasia, accessibility, content creation, tangibles, multimedia, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376491,
author = {Muthukumarana, Sachith and Elvitigala, Don Samitha and Forero Cortes, Juan Pablo and Matthies, Denys J.C. and Nanayakkara, Suranga},
title = {Touch Me Gently: Recreating the Perception of Touch Using a Shape-Memory Alloy Matrix},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376491},
doi = {10.1145/3313831.3376491},
abstract = {We present a wearable forearm augmentation that enables the recreation of natural
touch sensation by applying shear-forces onto the skin. In contrast to previous approaches,
we arrange light-weight and stretchable 3x3cm plasters in a matrix onto the skin.
Individual plasters were embedded with lines of shape-memory alloy (SMA) wires to
generate shear-forces. Our design is informed by a series of studies investigating
the perceptibility of different sizes, spacings, and attachments of plasters on the
forearm. Our matrix arrangement enables the perception of touches, for instance, feeling
ones wrist being grabbed or the arm being stroked. Users rated the recreated touch
sensations as being fairly similar to a real touch (4.1/5). Even without a visual
representation, users were able to correctly distinguish them with an overall accuracy
of 94.75%. Finally, we explored two use cases showing how AR and VR could be empowered
with experiencing recreated touch sensations on the forearm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {haptics, pinching, wearable, shape memory alloys, touch perception, recreation of touch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376492,
author = {Gen\c{c}, H\"{u}seyin Ugur and Coskun, Aykut},
title = {Designing for Social Interaction in the Age of Excessive Smartphone Use},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376492},
doi = {10.1145/3313831.3376492},
abstract = {Excessive smartphone use has negative effects on our social relations as well as on
our mental and psychological health. Most of the previous work to avoid these negative
effects is based on a top-down approach such as restricting or limiting users' use
of smartphones. Diverging from previous work, we followed a bottom-up approach to
understand the practice of smartphone use in public settings from the users' perspective.
We conducted observations in four coffeehouses, six focus group sessions with 46 participants
and three design workshops with 15 designers. We identified five themes that help
better understand smartphone use behavior in public settings and four alternative
design approaches to mediate this behavior, namely enlighteners, preventers, supporters,
and compliers. We discuss the implications of these themes and approaches for designing
future interactive technologies aimed at mediating excessive smartphone use behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smartphone, design for behavioral change, focus group design workshop},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376493,
author = {Wirfs-Brock, Jordan and Mennicken, Sarah and Thom, Jennifer},
title = {Giving Voice to Silent Data: Designing with Personal Music Listening History},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376493},
doi = {10.1145/3313831.3376493},
abstract = {Music streaming services collect listener data to support personalization and discovery
of their extensive catalogs. Yet this data is typically used in ways that are not
immediately apparent to listeners. We conducted design workshops with ten Spotify
listeners to imagine future voice assistant (VA) interactions leveraging logged music
data. We provided participants with detailed personal music listening data, such as
play-counts and temporal patterns, which grounded their design ideas in their current
behaviors. In the interactions participants designed, VAs did not simply speak their
data out loud; instead, participants envisioned how data could implicitly support
introspection, behavior change, and exploration. We present reflections on how VAs
could evolve from voice-activated remote controls to intelligent music coaches and
how personal data can be leveraged as a design resource.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {music, voice assistants, participatory design, co-design, personal informatics, speculative design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376494,
author = {Lerner, Sorin},
title = {Projection Boxes: On-the-Fly Reconfigurable Visualization for Live Programming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376494},
doi = {10.1145/3313831.3376494},
abstract = {Live programming is a regime in which the programming environment provides continual
feedback, most often in the form of runtime values. In this paper, we present Projection
Boxes, a novel visualization technique for displaying runtime values of programs.
The key idea behind projection boxes is to start with a full semantics of the program,
and then use projections to pick a subset of the semantics to display. By varying
the projection used, projection boxes can encode both previously known visualization
techniques, and also new ones. As such, projection boxes provide an expressive and
configurable framework for displaying runtime information. Through a user study we
demonstrate that (1) users find projection boxes and their configurability useful
(2) users are not distracted by the always-on visualization (3) a key driving force
behind the need for a configurable visualization for live programming lies with the
wide variation in programmer preferences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {debugging, program visualization, live programming, programming environment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376495,
author = {Bourdeau, Simon and Lesage, Annemarie and Couturier Caron, B\'{e}atrice and L\'{e}ger, Pierre-Majorique},
title = {When Design Novices and LEGO® Meet: Stimulating Creative Thinking for Interface Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376495},
doi = {10.1145/3313831.3376495},
abstract = {Design thinking is an iterative, human-centered approach to innovation. Its success
rests on collaboration within a multidisciplinary project team going through cycles
of divergent and convergent ideations. In these teams, nondesigners risk diminishing
the divergent reach because they are generally reluctant to sketch, thus missing out
on theambiguous, imprecise early conceptual divergent phases. We hypothesized that
LEGO® could advantageously be a substitute to sketching. In this comparative study,
44 nondesigners randomly paired in 22 dyads did two conceptual ideations of healthcare
landing pages, one using pen/paper (spontaneously writing words on sticky notes) and
the other using LEGO, assessed through Torrance and Guilford frameworks for divergent
thinking. Results show that LEGO interfaces gathered significantly higher divergent
thinking scores because their concepts were significantly more elaborated. Furthermore,
when using LEGO, teams who generated more elements were likely to also generate more
ideas, more categories of ideas and more original ideas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tangibles, design methods, user experience design, creativity support},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376496,
author = {Cockburn, Andy and Lewis, Blaine and Quinn, Philip and Gutwin, Carl},
title = {Framing Effects Influence Interface Feature Decisions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376496},
doi = {10.1145/3313831.3376496},
abstract = {Studies in psychology have shown that framing effects, where the positive or negative
attributes of logically equivalent choices are emphasised, influence people's decisions.
When outcomes are uncertain, framing effects also induce patterns of choice reversal,
where decisions tend to be risk averse when gains are emphasised and risk seeking
when losses are emphasised. Studies of these effects typically use potent framing
stimuli, such as the mortality of people suffering from diseases or personal financial
standing. We examine whether these effects arise in users' decisions about interface
features, which typically have less visceral consequences, using a crowd-sourced study
based on snap-to-grid drag-and-drop tasks (n = 842). The study examined several framing
conditions: those similar to prior psychological research, and those similar to typical
interaction choices (enabling/disabling features). Results indicate that attribute
framing strongly influences users' decisions, that these decisions conform to patterns
of risk seeking for losses, and that patterns of choice reversal occur.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {framing effects, interface decisions, attribute framing, risky choice framing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376497,
author = {Walker, Ashley Marie and DeVito, Michael A.},
title = {"'More Gay' Fits in Better": Intracommunity Power Dynamics and Harms in Online LGBTQ+ Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376497},
doi = {10.1145/3313831.3376497},
abstract = {Online spaces play crucial roles in the lives of most LGBTQ+ people, but can also
replicate and exacerbate existing intracommunity tensions and power dynamics, potentially
harming subgroups within this marginalized community. Using qualitative probes and
interviews, we engaged a diverse group of 25 bi+ (attracted to more than one gender)
people to explore these dynamics. We identify two types of intracommunity conflict
that bi+ users face (validity and normative conflicts), and a resulting set of what
we call latent harms, or coping strategies for dealing with conflict that have delayed
negative psychological effects for bi+ users. Using intersectionality as a sensitizing
concept to understand shifting power dynamics embedded in sociotechnical contexts,
we discuss challenges for future design work including the need to account for intracommunity
dynamics within marginalized groups and the utility of disentangling conflict from
harm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {pansexuality, harm, power dynamics, bisexuality, online communities, intersectionality, conflict, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376498,
author = {Li, Yifang and Vishwamitra, Nishant and Hu, Hongxin and Caine, Kelly},
title = {Towards A Taxonomy of Content Sensitivity and Sharing Preferences for Photos},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376498},
doi = {10.1145/3313831.3376498},
abstract = {Determining which photos are sensitive is difficult. Although emerging computer vision
systems can label content items, previous attempts to distinguish private or sensitive
content fall short. There is no human-centered taxonomy that describes what content
is sensitive or how sharing preferences for content differs across recipients. To
fill this gap, we introduce a new sensitive content elicitation method which surmounts
limitations of previous approaches, and, using this new method, collected sensitive
content from 116 participants. We also recorded participants' sharing preferences
with 20 recipient groups. Next, we conducted a card sort to surface user-defined categories
of sensitive content. Using data from these studies, we generated a taxonomy that
identifies 28 categories of sensitive content. We also establish how sharing preferences
for content differs across groups of recipients. This taxonomy can serve as a framework
for understanding photo privacy, which can, in turn, inform new photo privacy protection
mechanisms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sensitive content, security, privacy, photo privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376499,
author = {Tuncer, Sylvaine and Brown, Barry},
title = {E-Scooters on the Ground: Lessons for Redesigning Urban Micro-Mobility},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376499},
doi = {10.1145/3313831.3376499},
abstract = {The worldwide deployment of rental electric scooters has generated new opportunities
for urban mobility, but also intensified conflict over public space. This article
reports on an ethnographic study of both rental and privately-owned e-scooters, mapping
out the main problems and potentials around this new form of 'micro-mobility'. While
it suffers from problems of reliability and conflict, user experience is an important
part of e-scooters' appeal, an enjoyable way of 'hacking the city'. E-scooters have
a hybrid character: weaving through the city, riders can switch between riding as
a pedestrian, a car or a bicycle. Building on these results, we discuss how e-scooters,
ridesharing services, and their apps could develop further, alongside the role for
HCI in re-thinking urban transport and vehicle design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {electric scooters, co-ordination in mobile interactions, intermodal mobility, micro-mobility, user experience, vehicle design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376500,
author = {Chidziwisano, George Hope and Wyche, Susan and Oduor, Erick},
title = {GridAlert: Using a Sensor-Based Technology to Monitor Power Blackouts in Kenyan Homes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376500},
doi = {10.1145/3313831.3376500},
abstract = {Power blackouts (outages) are a common occurrence in Kenyan households. They affect
people's livelihoods, and damage their property (household electrical items). We explore
the role of GridAlert-a sensor-based technology we designed-in monitoring power blackouts.
We worked with local technicians to design GridAlert's housing and integrate GridAlert
with Kenya's electricity infrastructure. Then, we used interview, observation, diary,
and data logging methods to understand 18 households' experiences using the system.
Our findings provide insights for using sensor-based technology to monitor power usage
and blackouts in Kenyan households. We also present participants' thoughts about GridAlert's
housing, and about how it influenced their actions when using the system. We use these
findings to discuss design insights for power monitoring systems, and to offer new
perspectives on the role of technology in monitoring blackouts in Kenyan households.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hardware, domestic technology, sensors, monitoring, blackouts, electricity, kenya},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376501,
author = {Chiang, Yi-Shyuan and Chang, Ruei-Che and Chuang, Yi-Lin and Chou, Shih-Ya and Lee, Hao-Ping and Lin, I-Ju and Jiang Chen, Jian-Hua and Chang, Yung-Ju},
title = {Exploring the Design Space of User-System Communication for Smart-Home Routine Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376501},
doi = {10.1145/3313831.3376501},
abstract = {AI-enabled smart-home agents that automate household routines are increasingly viable,
but the design space of how and what such systems should communicate with their users
remains underexplored. Through a user-enactment study, we identified various interpretations
of and feelings toward such a system's confidence in its automated acts. That confidence
and their own mental models influenced what and how the participants wanted the system
to communicate, as well as how they would assess, diagnose, and subsequently improve
it. Automated acts resulted from false predictions were not generally considered improper,
provided that they were perceived as reasonable or potentially useful. The participants'
improvement strategies were of four general types, all of which will be discussed.
Factors affecting their preferred levels of involvement in automated acts and their
interest in system confidence were also identified. We conclude by making practical
design recommendations for the user-system communication design spaces of smart-home
routine assistants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {user enactment, routine assistant, intelligent agent, smart-home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376502,
author = {Salminen, Joni and Guan, Kathleen and Jung, Soon-Gyo and Chowdhury, Shammur A. and Jansen, Bernard J.},
title = {A Literature Review of Quantitative Persona Creation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376502},
doi = {10.1145/3313831.3376502},
abstract = {Quantitative persona creation (QPC) has tremendous potential, as HCI researchers and
practitioners can leverage user data from online analytics and digital media platforms
to better understand their users and customers. However, there is a lack of a systematic
overview of the QPC methods and progress made, with no standard methodology or known
best practices. To address this gap, we review 49 QPC research articles from 2005
to 2019. Results indicate three stages of QPC research: Emergence, Diversification,
and Sophistication. Sharing resources, such as datasets, code, and algorithms, is
crucial to achieving the next stage (Maturity). For practitioners, we provide guiding
questions for assessing QPC readiness in organizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {literature review, quantitative persona creation, personas},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376503,
author = {Iravantchi, Yasha and Goel, Mayank and Harrison, Chris},
title = {Digital Ventriloquism: Giving Voice to Everyday Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376503},
doi = {10.1145/3313831.3376503},
abstract = {Smart speakers with voice agents are becoming increasingly common. However, the agent's
voice always emanates from the device, even when that information is contextually
and spatially relevant elsewhere. Digital Ventriloquism allows smart speakers to render
sound onto everyday objects, such that it appears they are speaking and are interactive.
This can be achieved without any modification of objects or the environment. For this,
we used a highly directional pan-tilt ultrasonic array. By modulating a 40 kHz ultrasonic
signal, we can emit sound that is inaudible "in flight" and demodulates to audible
frequencies when impacting a surface through acoustic parametric interaction. This
makes it appear as though the sound originates from an object and not the speaker.
We ran a study in which we projected speech onto five objects in three environments,
and found that participants were able to correctly identify the source object 92%
of the time and correctly repeat the spoken message 100% of the time, demonstrating
our digital ventriloquy is both directional and intelligible.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {ultrasound, iot, vr/ar, smart speakers, interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376504,
author = {Wampfler, Rafael and Klingler, Severin and Solenthaler, Barbara and Schinazi, Victor R. and Gross, Markus},
title = {Affective State Prediction Based on Semi-Supervised Learning from Smartphone Touch Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376504},
doi = {10.1145/3313831.3376504},
abstract = {Gaining awareness of the user's affective states enables smartphones to support enriched
interactions that are sensitive to the user's context. To accomplish this on smartphones,
we propose a system that analyzes the user's text typing behavior using a semi-supervised
deep learning pipeline for predicting affective states measured by valence, arousal,
and dominance. Using a data collection study with 70 participants on text conversations
designed to trigger different affective responses, we developed a variational auto-encoder
to learn efficient feature embeddings of two-dimensional heat maps generated from
touch data while participants engaged in these conversations. Using the learned embedding
in a cross-validated analysis, our system predicted three levels (low, medium, high)
of valence (AUC up to 0.84), arousal (AUC up to 0.82), and dominance (AUC up to 0.82).
These results demonstrate the feasibility of our approach to accurately predict affective
states based only on touch data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {affective computing, deep learning, classification, smartphone},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376505,
author = {Huang, Kai-Chieh and Sun, Chen-Kuo and Huang, Da-Yuan and Chen, Yu-Chun and Chang, Ruei-Che and Hsu, Shuo-wen and Yang, Chih-Yun and Chen, Bing-Yu},
title = {Glissade: Generating Balance Shifting Feedback to Facilitate Auxiliary Digital Pen Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376505},
doi = {10.1145/3313831.3376505},
abstract = {This paper introduces Glissade, a digital pen that generates balance shifting feedback by changing the weight distribution of the pen. A pulley system shifts a brass mass inside the pen to change the pen's center of mass and moment of inertia. When the mass is stationary, the pen delivers a constant yet natural sensation of weight, which can be used to convey a status. The pen can also generate a variety of haptic clues by actuating the mass according to the tilt or rotation of the pen, two commonly-used auxiliary pen input channels. Glissade demonstrates new possibilities that balance shifting feedback can bring to digital pen interactions. We validated the usability of this feedback by determining the recognizability of six balance patterns – a mix of static and dynamic patterns chosen based on our design considerations – in two controlled experiments. The results show that, on average, the participants could distinguish between the patterns with a 94.25% accuracy. At the end, we demonstrate a set of novel interactions enabled by Glissade and discuss the directions for future research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {balance shifting feedback, sensation of weight, digital pen, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376506,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-Aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
doi = {10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing
promise in medicine. However, medical assessments can be contentious, leading to expert
disagreement. This raises the question of how AI assistants should be designed to
handle the classification of ambiguous cases. Our study compared two AI assistants
that provide classification labels for medical time series data along with quantitative
uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware
AI based on real-world expert discussions to highlight cases likely to lead to expert
disagreement, and to present arguments for conflicting classification choices. Our
results demonstrate that ambiguity-aware AI can alter expert workflows by significantly
increasing the proportion of contentious cases reviewed. We also found that the relevance
of AI-provided arguments (selected from guidelines either randomly or by experts)
affected experts' accuracy at revising AI-suggested labels. Our work contributes a
novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {medical data analysis, artificial intelligence, ambiguity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376507,
author = {D\"{o}rrenb\"{a}cher, Judith and L\"{o}ffler, Diana and Hassenzahl, Marc},
title = {Becoming a Robot - Overcoming Anthropomorphism with Techno-Mimesis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376507},
doi = {10.1145/3313831.3376507},
abstract = {Employing anthropomorphism in physical appearance and behavior is the most widespread
strategy for designing social robots. In the present paper, we argue that imitating
humans impedes the full exploration of robots' social abilities. In fact, their very 'thingness' (e.g., sensors, rationality) is able to create 'superpowers' that go beyond
human abilities, such as endless patience. To better identify these special abilities,
we develop a performative method called 'Techno-Mimesis' and explore it in a series
of workshops with robot designers. Specifically, we create 'prostheses' to allow designers
to transform themselves into their future robot to experience use cases from the robot's
perspective, e.g., 'seeing' with a distance sensor rather than with eyes. This imperfect
imitation helps designers to experience being human and being robot at the same time,
making differences apparent and facilitating the discovery of a number of potential
physical, cognitive, and communicational robotic superpowers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {new animism, social robots, performative design method, service robots, anthropomorphism},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376508,
author = {Melfi, Giuseppe and M\"{u}ller, Karin and Schwarz, Thorsten and Jaworek, Gerhard and Stiefelhagen, Rainer},
title = {Understanding What You Feel: A Mobile Audio-Tactile System for Graphics Used at Schools with Students with Visual Impairment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376508},
doi = {10.1145/3313831.3376508},
abstract = {A lot of information is nowadays presented graphically. However, students with blindness
do not have access to visual information. Providing an alternative text is not always
the appropriate solution as exploring graphics to discover information independently
is a fundamental part of the learning process. In this work, we introduce a mobile
audio-tactile learning environment, which facilitates the incorporation of real educational
material. We evaluate our system by comparing three methods of interaction with tactile
graphics: A tactile graphic augmented by (1) a document with key index information
in Braille, (2) a digital document with key index information and (3) the TPad system,
an audio-tactile solution meeting the specific needs within the school context. Our
study shows that the TPad system is suitable for educational environments. Moreover,
compared to the other methods TPad is faster to explore tactile graphics and it suggests
a promising effect on the memorization of information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {tactile graphics, visually impaired, access technology, blind, touch screen devices},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376509,
author = {Kj\ae{}rup, Maria and Skov, Mikael B. and Agerholm, Niels},
title = {Digital-Enabled Last Mile: A Study of Passenger Trips in Rural, Low-Density Populated Areas},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376509},
doi = {10.1145/3313831.3376509},
abstract = {Public transportation in rural areas is difficult due to low numbers of passengers
and diverse needs, also reflected in the last mile problem that points to the distance
to access transportation hubs in order to connect with core networks of transportation.
In this paper, we study public transportation in rural areas using a digital-enabled,
demand-responsive service called Plustur. This service was recently introduced as
an effort to increase mobility in underserved rural areas by creating routes ad-hoc
to answer to the last mile(s). We study how passengers and drivers understand Plustur,
as well as experience the role of passenger. Our findings show that Plustur is viewed
as a benefit for autonomy of mobility in rural areas, however is lacking in addressing
integration of modes of mobilities, flexibility and spontaneous trips. We contribute
with design implications for digital multimodal mobility services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {demand-responsive transit, digital-enabled passenger trips, mobility as a service, mobility on demand},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376510,
author = {Stawarz, Katarzyna and Preist, Chris and Tallon, Deborah and Thomas, Laura and Turner, Katrina and Wiles, Nicola and Kessler, David and Shafran, Roz and Coyle, David},
title = {Integrating the Digital and the Traditional to Deliver Therapy for Depression: Lessons from a Pragmatic Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376510},
doi = {10.1145/3313831.3376510},
abstract = {Traditional approaches to psychotherapy emphasise face-to-face contact between patients
and therapists. In contrast, current computerised approaches tend to minimise this
contact. This can limit the range of mental health difficulties for which computerised
approaches are effective. Here, we explore an alternative approach that integrates
face-to-face contact, electronic contact, online collaboration, and support for between-session
activities. Our discussion is grounded in the design of a platform to deliver psychotherapy
for depression. We report findings of an 11-month pragmatic study in which 17 patients
received treatment for depression via the platform. Results show how design decisions
had a significant impact on the dynamics of therapeutic sessions and the establishment
of patient-therapist relationships. For example, the use of instant messaging for
synchronous, in-session contact slowed communication, but also provided a valuable
space for reflection and helped to maintain session focus. We discuss the impact of
flexibility and the potential of integrated approaches to both enhance and reduce
patient engagement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {patient-therapist communication, blended therapy, health technology, mental health, cognitive behavioural therapy, integrated approach, cbt, depression},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376511,
author = {Habib, Hana and Pearman, Sarah and Wang, Jiamin and Zou, Yixin and Acquisti, Alessandro and Cranor, Lorrie Faith and Sadeh, Norman and Schaub, Florian},
title = {"It's a Scavenger Hunt": Usability of Websites' Opt-Out and Data Deletion Choices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376511},
doi = {10.1145/3313831.3376511},
abstract = {We conducted an in-lab user study with 24 participants to explore the usefulness and
usability of privacy choices offered by websites. Participants were asked to find
and use choices related to email marketing, targeted advertising, or data deletion
on a set of nine websites that differed in terms of where and how these choices were
presented. They struggled with several aspects of the interaction, such as selecting
the correct page from a site's navigation menu and understanding what information
to include in written opt-out requests. Participants found mechanisms located in account
settings pages easier to use than options contained in privacy policies, but many
still consulted help pages or sent email to request assistance. Our findings indicate
that, despite their prevalence, privacy choices like those examined in this study
are difficult for consumers to exercise in practice. We provide design and policy
recommendations for making these website opt-out and deletion choices more useful
and usable for consumers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data deletion, privacy controls, privacy, usability, targeted advertising, email marketing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376512,
author = {Preechayasomboon, Pornthep and Israr, Ali and Samad, Majed},
title = {Chasm: A Screw Based Expressive Compact Haptic Actuator},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376512},
doi = {10.1145/3313831.3376512},
abstract = {We present a compact broadband linear actuator, Chasm, that renders expressive haptic
feedback on wearable and handheld devices. Unlike typical motor-based haptic devices
with integrated gearheads, Chasm utilizes a miniature leadscrew coupled to a motor
shaft, thereby directly translating the high-speed rotation of the motor to the linear
motion of a nut carriage without an additional transmission. Due to this simplicity,
Chasm can render low-frequency skin-stretch and high-frequency vibrations, simultaneously
and independently. We present the design of the actuator assembly and validate its
electromechanical and perceptual performance. We then explore use cases and show design
solutions for embedding Chasm in device prototypes. Finally, we report investigations
with Chasm in two VR embodiments, i.e., in a headgear band to induce locomotion cues
and in a handheld pointer to enhance dynamic manual interactions. Our explorations
show wide use for Chasm in enhancing user interactions and experience in virtual and
augmented settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {handheld haptics, skin stretch, wearable haptics, haptic devices, multidimensional haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376513,
author = {Davis, Josh Urban and Wu, Te-Yen and Shi, Bo and Lu, Hanyi and Panotopoulou, Athina and Whiting, Emily and Yang, Xing-Dong},
title = {TangibleCircuits: An Interactive 3D Printed Circuit Education Tool for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376513},
doi = {10.1145/3313831.3376513},
abstract = {We present a novel haptic and audio feedback device that allows blind and visually
impaired (BVI) users to understand circuit diagrams. TangibleCircuits allows users
to interact with a 3D printed tangible model of a circuit which provides audio tutorial
directions while being touched. Our system comprises an automated parsing algorithm
which extracts 3D printable models as well as an audio interfaces from a Fritzing
diagram. To better understand the requirements of designing technology to assist BVI
users in learning hardware computing, we conducted a series of formative inquiries
into the accessibility limitations of current circuit tutorial technologies. In addition,
we derived insights and design considerations gleaned from conducting a formal comparative
user study to understand the effectiveness of TangibleCircuits as a tutorial system.
We found that BVI users were better able to understand the geometric, spatial and
structural circuit information using TangibleCircuits, as well as enjoyed learning
with our tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {circuit prototyping, universal design, education tools, tangible user interfaces, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376514,
author = {Frid, Emma and Gomes, Celso and Jin, Zeyu},
title = {Music Creation by Example},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376514},
doi = {10.1145/3313831.3376514},
abstract = {Short online videos have become the dominating media on social platforms. However,
finding suitable music to accompany videos can be a challenging task to some video
creators, due to copyright constraints, limitations in search engines, and required
audio-editing expertise. One possible solution to these problems is to use AI music
generation. In this paper we present a user interface (UI) paradigm that allows users
to input a song to an AI engine and then interactively regenerate and mix AI-generated
music. To arrive at this design, we conducted user studies with a total of 104 video
creators at several stages of our design and development process. User studies supported
the effectiveness of our approach and provided valuable insights about human-AI interaction
as well as the design and evaluation of mixed-initiative interfaces in creative practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {music generation, artificial intelligence, algorithmic composition, mixed-initiative interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376515,
author = {Wong, Richmond Y. and Khovanskaya, Vera and Fox, Sarah E. and Merrill, Nick and Sengers, Phoebe},
title = {Infrastructural Speculations: Tactics for Designing and Interrogating Lifeworlds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376515},
doi = {10.1145/3313831.3376515},
abstract = {This paper introduces "infrastructural speculations," an orientation toward speculative
design that considers the complex and long-lived relationships of technologies with
broader systems, beyond moments of immediate invention and design. As modes of speculation
are increasingly used to interrogate questions of broad societal concern, it is pertinent
to develop an orientation that foregrounds the "lifeworld" of artifacts-the social,
perceptual, and political environment in which they exist. While speculative designs
often imply a lifeworld, infrastructural speculations place lifeworlds at the center
of design concern, calling attention to the cultural, regulatory, environmental, and
repair conditions that enable and surround particular future visions. By articulating
connections and affinities between speculative design and infrastructure studies research,
we contribute a set of design tactics for producing infrastructural speculations.
These tactics help design researchers interrogate the complex and ongoing entanglements
among technologies, institutions, practices, and systems of power when gauging the
stakes of alternate lifeworlds.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {infrastructure, infrastructure studies, futures, design research, speculative design, lifeworld},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376516,
author = {Zhao, Yuhang and Kupferstein, Elizabeth and Rojnirun, Hathaitorn and Findlater, Leah and Azenkot, Shiri},
title = {The Effectiveness of Visual and Audio Wayfinding Guidance on Smartglasses for People with Low Vision},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376516},
doi = {10.1145/3313831.3376516},
abstract = {Wayfinding is a critical but challenging task for people who have low vision, a visual
impairment that falls short of blindness. Prior wayfinding systems for people with
visual impairments focused on blind people, providing only audio and tactile feedback.
Since people with low vision use their remaining vision, we sought to determine how
audio feedback compares to visual feedback in a wayfinding task. We developed visual
and audio wayfinding guidance on smartglasses based on de facto standard approaches
for blind and sighted people and conducted a study with 16 low vision participants.
We found that participants made fewer mistakes and experienced lower cognitive load
with visual feedback. Moreover, participants with a full field of view completed the
wayfinding tasks faster when using visual feedback. However, many participants preferred
audio feedback because of its shorter learning curve. We propose design guidelines
for wayfinding systems for low vision.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {accessibility, visual feedback, augmented reality, audio feedback, wayfinding, low vision},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376517,
author = {Williford, Blake and Runyon, Matthew and Li, Wayne and Linsey, Julie and Hammond, Tracy},
title = {Exploring the Potential of an Intelligent Tutoring System for Sketching Fundamentals},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376517},
doi = {10.1145/3313831.3376517},
abstract = {Sketching is a practical and useful skill that can benefit communication and problem
solving. However, it remains a difficult skill to learn because of low confidence
and motivation among students and limited availability for instruction and personalized
feedback among teachers. There is an need to improve the educational experience for
both groups, and we hypothesized that integrating technology could provide a variety
of benefits. We designed and developed an intelligent tutoring system for sketching
fundamentals called Sketchtivity, and deployed it in to six existing courses at the
high school and university level during the 2017-2018 school year. 268 students used
the tool and produced more than 116,000 sketches of basic primitives. We conducted
semi-structured interviews with the six teachers who implemented the software, as
well as nine students from a course where the tool was used extensively. Using grounded
theory, we found ten categories which unveiled the benefits and limitations of integrating
an intelligent tutoring system for sketching fundamentals in to existing pedagogy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design education, human-computer interaction, drawing, art education, sketch recognition, intelligent tutoring system, sketching, user experience design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376518,
author = {Bassen, Jonathan and Balaji, Bharathan and Schaarschmidt, Michael and Thille, Candace and Painter, Jay and Zimmaro, Dawn and Games, Alex and Fast, Ethan and Mitchell, John C.},
title = {Reinforcement Learning for the Adaptive Scheduling of Educational Activities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376518},
doi = {10.1145/3313831.3376518},
abstract = {Adaptive instruction for online education can increase learning gains and decrease
the work required of learners, instructors, and course designers. Reinforcement Learning
(RL) is a promising tool for developing instructional policies, as RL models can learn
complex relationships between course activities, learner actions, and educational
outcomes. This paper demonstrates the first RL model to schedule educational activities
in real time for a large online course through active learning. Our model learns to
assign a sequence of course activities while maximizing learning gains and minimizing
the number of items assigned. Using a controlled experiment with over 1,000 learners,
we investigate how this scheduling policy affects learning gains, dropout rates, and
qualitative learner feedback. We show that our model produces better learning gains
using fewer educational activities than a linear assignment condition, and produces
similar learning gains to a self-directed condition using fewer educational activities
and with lower dropout rates.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {adaptive learning, online education, reinforcement learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376519,
author = {Leake, Mackenzie and Shin, Hijung Valentina and Kim, Joy O. and Agrawala, Maneesh},
title = {Generating Audio-Visual Slideshows from Text Articles Using Word Concreteness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376519},
doi = {10.1145/3313831.3376519},
abstract = {We present a system that automatically transforms text articles into audio-visual
slideshows by leveraging the notion of word concreteness, which measures how strongly
a word or phrase is related to some perceptible concept. In a formative study we learn
that people not only prefer such audio-visual slideshows but find that the content
is easier to understand compared to text articles or text articles augmented with
images. We use word concreteness to select search terms and find images relevant to
the text. Then, based on the distribution of concrete words and the grammatical structure
of an article, we time-align selected images with audio narration obtained through
text-to-speech to produce audio-visual slideshows. In a user evaluation we find that
our concreteness-based algorithm selects images that are highly relevant to the text.
The quality of our slideshows is comparable to slideshows produced manually using
standard video editing tools, and people strongly prefer our slideshows to those generated
using a simple keyword-search based approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {text-to-video, word concreteness, audio-visual slideshows},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376520,
author = {Shi, Yang and Cao, Nan and Ma, Xiaojuan and Chen, Siji and Liu, Pei},
title = {EmoG: Supporting the Sketching of Emotional Expressions for Storyboarding},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376520},
doi = {10.1145/3313831.3376520},
abstract = {Storyboarding is an important ideation technique that uses sequential art to depict
important scenarios of user experience. Existing data-driven support for storyboarding
focuses on constructing user stories, but fail to address its benefit as a graphic
narrative device. Instead, we propose to develop a data-driven design support tool
that increases the expressiveness of user stories by facilitating sketching storyboards.
To explore this, we focus on supporting the sketching of emotional expressions of
characters in storyboards. In this paper, we present EmoG, an interactive system that
generates sketches of characters with emotional expressions based on input strokes
from the user. We evaluated EmoG with 21 participants in a controlled user study.
The results showed that our tool has significantly better performance in usefulness,
ease of use, and quality of results than the baseline system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data-driven design, storyboarding, creativity support tools, emotional expression generation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376521,
author = {Kim, Sunyoung and Li, Muyang},
title = {Awareness, Understanding, and Action: A Conceptual Framework of User Experiences and Expectations about Indoor Air Quality Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376521},
doi = {10.1145/3313831.3376521},
abstract = {With the advent of new sensors and technologies, smart devices that monitor the level
of indoor air quality (IAQ) are increasingly available to create a healthy home environment.
However, little has been studied regarding design principles for effective IAQ visualizations
to help better understand and improve IAQ. We analyzed Amazon reviews of IAQ monitors
and their design components for IAQ visualizations. Based on our findings, we created
a conceptual framework to explain the process of facilitating an effective IAQ visualization
with a proposed set of design considerations in each stage. The process includes helping
users easily understand what is happing to IAQ (awareness), what it means to them
(understanding), and what to do with the information (action), which results in two
outcomes, knowledge gain and emotional relief. We hope our framework can help practitioners
and researchers in designing eco-feedback system and beyond to advance both research
and practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {peripheral display, indoor air quality, design principles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376522,
author = {Murad, Christine and Munteanu, Cosmin},
title = {Designing Voice Interfaces: Back to the (Curriculum) Basics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376522},
doi = {10.1145/3313831.3376522},
abstract = {Voice user interfaces (VUIs) are rapidly increasing in popularity in the consumer
space. This leads to a concurrent explosion of available applications for such devices,
with many industries rushing to offer voice interactions for their products. This
pressure is then transferred to interface designers; however, a large majority of
designers have been only trained to handle the usability challenges specific to Graphical
User Interfaces (GUIs). Since VUIs differ significantly in design and usability from
GUIs, we investigate in this paper the extent to which current educational resources
prepare designers to handle the specific challenges of VUI design. For this, we conducted
a preliminary scoping scan and syllabi meta review of HCI curricula at more than twenty
top international HCI departments, revealing that the current offering of VUI design
training within HCI education is rather limited. Based on this, we advocate for the
updating of HCI curricula to incorporate VUI design, and for the development of VUI-specific
pedagogical artifacts to be included in new curricula.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {hci curriculum, hci education, conversational interface, speech, vui design, voice user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376523,
author = {Suzuki, Ryo and Hedayati, Hooman and Zheng, Clement and Bohn, James L. and Szafir, Daniel and Do, Ellen Yi-Luen and Gross, Mark D. and Leithinger, Daniel},
title = {RoomShift: Room-Scale Dynamic Haptics for VR with Furniture-Moving Swarm Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376523},
doi = {10.1145/3313831.3376523},
abstract = {RoomShift is a room-scale dynamic haptic environment for virtual reality, using a
small swarm of robots that can move furniture. RoomShift consists of nine shape-changing
robots: Roombas with mechanical scissor lifts. These robots drive beneath a piece
of furniture to lift, move and place it. By augmenting virtual scenes with physical
objects, users can sit on, lean against, place and otherwise interact with furniture
with their whole body; just as in the real world. When the virtual scene changes or
users navigate within it, the swarm of robots dynamically reconfigures the physical
environment to match the virtual content. We describe the hardware and software implementation,
applications in virtual tours and architectural design and interaction techniques.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {room-scale haptics, virtual reality, swarm robots, haptic interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376524,
author = {August, Tal and Card, Dallas and Hsieh, Gary and Smith, Noah A. and Reinecke, Katharina},
title = {Explain like I Am a Scientist: The Linguistic Barriers of Entry to r/Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376524},
doi = {10.1145/3313831.3376524},
abstract = {As an online community for discussing research findings, r/science has the potential
to contribute to science outreach and communication with a broad audience. Yet previous
work suggests that most of the active contributors on r/science are science-educated
people rather than a lay general public. One potential reason is that r/science contributors
might use a different, more specialized language than used in other subreddits. To
investigate this possibility, we analyzed the language used in more than 68 million
posts and comments from 12 subreddits from 2018. We show that r/science uses a specialized
language that is distinct from other subreddits. Transient (newer) authors of posts
and comments on r/science use less specialized language than more frequent authors,
and those that leave the community use less specialized language than those that stay,
even when comparing their first comments. These findings suggest that the specialized
language used in r/science has a gatekeeping effect, preventing participation by people
whose language does not align with that used in r/science. By characterizing r/science's
specialized language, we contribute guidelines and tools for increasing the number
of contributors in r/science.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {science communication, reddit, social computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376525,
author = {Kristensson, Per Ola and Lilley, James and Black, Rolf and Waller, Annalu},
title = {A Design Engineering Approach for Quantitatively Exploring Context-Aware Sentence Retrieval for Nonspeaking Individuals with Motor Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376525},
doi = {10.1145/3313831.3376525},
abstract = {Nonspeaking individuals with motor disabilities typically have very low communication
rates. This paper proposes a design engineering approach for quantitatively exploring
context-aware sentence retrieval as a promising complementary input interface, working
in tandem with a word-prediction keyboard. We motivate the need for complementary
design engineering methodology in the design of augmentative and alternative communication
and explain how such methods can be used to gain additional design insights. We then
study the theoretical performance envelopes of a context-aware sentence retrieval
system, identifying potential keystroke savings as a function of the parameters of
the subsystems, such as the accuracy of the underlying auto-complete word prediction
algorithm and the accuracy of sensed context information under varying assumptions.
We find that context-aware sentence retrieval has the potential to provide users with
considerable improvements in keystroke savings under reasonable parameter assumptions
of the underlying subsystems. This highlights how complementary design engineering
methods can reveal additional insights into design for augmentative and alternative
communication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {augmentative and alternative communication, information retrieval, sentence prediction, context-aware text entry, text entry, design engineering},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376526,
author = {Kozubaev, Sandjar and Elsden, Chris and Howell, Noura and S\o{}ndergaard, Marie Louise Juul and Merrill, Nick and Schulte, Britta and Wong, Richmond Y.},
title = {Expanding Modes of Reflection in Design Futuring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376526},
doi = {10.1145/3313831.3376526},
abstract = {Design futuring approaches, such as speculative design, design fiction and others,
seek to (re)envision futures and explore alternatives. As design futuring becomes
established in HCI design research, there is an opportunity to expand and develop
these approaches. To that end, by reflecting on our own research and examining related
work, we contribute five modes of reflection. These modes concern formgiving, temporality,
researcher positionality, real-world engagement, and knowledge production. We illustrate
the value of each mode through careful analysis of selected design exemplars and provide
questions to interrogate the practice of design futuring. Each reflective mode offers
productive resources for design practitioners and researchers to articulate their
work, generate new directions for their work, and analyze their own and others' work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {design methods, futures, speculative design, futures-oriented design, research through design, design futuring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376527,
author = {Carstensdottir, Elin and Partlan, Nathan and Sutherland, Steven and Duke, Tyler and Ferris, Erika and Richter, Robin M. and Valladares, Maria and Seif El-Nasr, Magy},
title = {Progression Maps: Conceptualizing Narrative Structure for Interaction Design Support},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376527},
doi = {10.1145/3313831.3376527},
abstract = {Interactive narratives are frequently designed for learning and training applications,
such as social training. In these contexts, designers may be inexperienced in storytelling
and interaction design, and it may be difficult to quickly build an effective experience,
even for experienced designers. Designers often approach this problem through iterative
design. To augment and reduce iteration, we argue for the utility of employing models
to reason about, evaluate, and improve designs. While there has been much previous
work on interactive narrative models, none of them capture aspects of the interaction
design necessary for testing and evaluation. In this paper we propose a new computational
model called Progression Maps, which abstracts interaction design elements of the
narrative's structure and visualizes its interaction properties. We report on the
model, its implementation, and two studies evaluating its use. Our results demonstrate
Progression Maps' effectiveness in communicating the underlying design through an
easily understandable visualization.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive narrative, interaction design, interactive narrative model, visualization, design assistance tools, game design, graph-based models},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376528,
author = {Homewood, Sarah and Boer, Laurens and Vallg\r{a}rda, Anna},
title = {Designers in White Coats: Deploying Ovum, a Fertility Tracking Device},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376528},
doi = {10.1145/3313831.3376528},
abstract = {As self-tracking practices continue to proliferate, there has been a call for a consideration
of how the design of these devices influence the users experience of themselves and
their bodies beyond utility, efficacy and accuracy. The research product Ovum was
designed to facilitate a DIY, shared, domestic experience, rather than an expert-led,
individual, clinical experience of fertility tracking. Ovum uses the method of saliva
sampling to determine ovulation. This paper unpacks the findings from a three-month
long deployment of Ovum with seven couples trying to conceive. Besides an evaluation
of the device in terms of the three experiential qualities aimed for in the design
process, we report on the consequences of executing a design deployment that resembles
a clinical trial. We contribute our experience in order to develop an understanding
of how designing for the body places interaction designers in novel and complex situations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {menstrual cycles, self-tracking, research through design, fertility, women's health, ovulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376529,
author = {Huang, Yue and Obada-Obieh, Borke and Beznosov, Konstantin (Kosta)},
title = {Amazon vs. My Brother: How Users of Shared Smart Speakers Perceive and Cope with Privacy Risks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376529},
doi = {10.1145/3313831.3376529},
abstract = {With the rapid adoption of smart speakers in people's homes, there is a corresponding
increase in users' privacy and security concerns. In contrast to previous studies
of users' concerns about smart speakers' divulging private information to their manufacturers,
our study focused on investigating users' concerns with regard to housemates and external
entities. We conducted semi-structured interviews with 26 participants living in 21
households. Our results suggest that users often have an inadequate understanding
of what data their smart speakers makes available to all users and what is kept private.
Although participants expressed different privacy concerns about their housemates
and external entities, they adopted similar, yet suboptimal, risk management strategies.
We provide recommendations for future speaker design to support more optimal coping
with the perceived risks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mitigation strategies, security and privacy concerns, shared smart speaker},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376530,
author = {Roldan, Wendy and Gao, Xin and Hishikawa, Allison Marie and Ku, Tiffany and Li, Ziyue and Zhang, Echo and Froehlich, Jon E. and Yip, Jason},
title = {Opportunities and Challenges in Involving Users in Project-Based HCI Education},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376530},
doi = {10.1145/3313831.3376530},
abstract = {Users are fundamental to HCI. However, little is known about how HCI education introduces
students to working with users, particularly those different from themselves. To better
understand design students' engagement, reactions, and reflections with users, we
investigate a case study of a graduate-level 10-week prototyping studio course that
partnered with a children's co-design team. HCI students participated in two co-design
sessions with children to design a STEM learning experience for youth. We conducted
participant observations, interviews with 14 students, and analyzed final artifacts.
Our findings demonstrate the communication challenges and strategies students experienced,
how students observed issues of power dynamics, and students' perceived value in engaging
with users. We contribute empirical evidence of how HCI students directly interact
with target users, principles for reflective HCI pedagogy, and highlight the need
for more intentional investigation into HCI educational practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {hci education, user-centered design, reflection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376531,
author = {Wallace, Jayne and Montague, Kyle and Duncan, Trevor and Carvalho, Lu\'{\i}s P. and Koulidou, Nantia and Mahoney, Jamie and Morrissey, Kellie and Craig, Claire and Groot, Linnea Iris and Lawson, Shaun and Olivier, Patrick and Trueman, Julie and Fisher, Helen},
title = {ReFind: Design, Lived Experience and Ongoingness in Bereavement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376531},
doi = {10.1145/3313831.3376531},
abstract = {We describe the design and use of ReFind, a handheld artefact made for people who
are bereaved and are ready to re-explore their relationship to the deceased person.
ReFind was made within a project seeking to develop new ways to curate and create
digital media to support ongoingness - an active, dynamic component of continuing
bonds. We draw on bereavement theory and care championing practices that enable a
continued sense of connection between someone bereaved and a person who has died.
We present the design development of ReFind and the lived experience of the piece
by the first author. We discuss our wider methodology which includes autobiographical
design and reflections on if and how the piece supported ongoing connections, the
challenges faced, and insights gained.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {digital images, design, photographs, grief, continuing bonds, death, autobiographical, lived experience, bereavement, autoethnography, physical/digital, relational selves, ongoingness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376532,
author = {Parker, Callum and Tomitsch, Martin and Davies, Nigel and Valkanova, Nina and Kay, Judy},
title = {Foundations for Designing Public Interactive Displays That Provide Value to Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376532},
doi = {10.1145/3313831.3376532},
abstract = {Public interactive displays (PID) are a promising technology for providing information
and collecting feedback in public spaces. Research on PIDs has shown that, like all
public displays, their efficacy is reduced by display blindness. Rather than increase
the visual attention-grabbing nature of PIDs, we propose that additional understanding
is required around how and when these displays are able to offer value to users. We
tackle this through a systematic analysis of PID studies published in the literature,
which led to 9 aspects of value across 4 factors: people, location, community, and
time. We discuss the identified aspects and their utility for the design of PIDs through
a review of our own deployments carried out by 4 different labs across 5 countries.
We conclude with a set of recommendations for identifying and optimising the intended
value of future PIDs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design recommendations, literature review, public interactive displays, deployments, in-the-wild, public displays, value},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376533,
author = {Liu, Yang and Althoff, Tim and Heer, Jeffrey},
title = {Paths Explored, Paths Omitted, Paths Obscured: Decision Points &amp; Selective Reporting in End-to-End Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376533},
doi = {10.1145/3313831.3376533},
abstract = {Drawing reliable inferences from data involves many, sometimes arbitrary, decisions
across phases of data collection, wrangling, and modeling. As different choices can
lead to diverging conclusions, understanding how researchers make analytic decisions
is important for supporting robust and replicable analysis. In this study, we pore
over nine published research studies and conduct semi-structured interviews with their
authors. We observe that researchers often base their decisions on methodological
or theoretical concerns, but subject to constraints arising from the data, expertise,
or perceived interpretability. We confirm that researchers may experiment with choices
in search of desirable results, but also identify other reasons why researchers explore
alternatives yet omit findings. In concert with our interviews, we also contribute
visualizations for communicating decision processes throughout an analysis. Based
on our results, we identify design opportunities for strengthening end-to-end analysis,
for instance via tracking and meta-analysis of multiple decision paths.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {reproducibility, analytic decision making, garden of forking paths, multiverse analysis, interview study, data analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376534,
author = {Schr\"{o}der, Christoph and Al Zaidawi, Sahar Mahdie Klim and Prinzler, Martin H.U. and Maneth, Sebastian and Zachmann, Gabriel},
title = {Robustness of Eye Movement Biometrics Against Varying Stimuli and Varying Trajectory Length},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376534},
doi = {10.1145/3313831.3376534},
abstract = {Recent results suggest that biometric identification based on human's eye movement
characteristics can be used for authentication. In this paper, we present three new
methods and benchmark them against the state-of-the-art. The best of our new methods
improves the state-of-the-art performance by 5.2 percentage points. Furthermore, we
investigate some of the factors that affect the robustness of the recognition rate
of different classifiers on gaze trajectories, such as the type of stimulus and the
tracking trajectory length. We find that the state-of-the-art method only works well
when using the same stimulus for testing that was used for training. By contrast,
our novel method more than doubles the identification accuracy for these transfer
cases. Furthermore, we find that with only 90 seconds of eye tracking data, 86.7%
accuracy can be achieved.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {eye tracking, gaze detection, eye movement biometrics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376535,
author = {Rumsey, Alyssa and Le Dantec, Christopher A.},
title = {Manufacturing Change: The Impact of Virtual Environments on Real Organizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376535},
doi = {10.1145/3313831.3376535},
abstract = {Manufacturing workplaces are becoming sites of intense change as technologies like
IoT and AR/VR are beginning to make deep inroads into how complex products are engi-neered
and assembled. These categories of technologies are becoming prominent in manufacturing
because they offer potential solutions to the problems of unskilled labor and workforce
shortages. Technology has the potential to shift manufacturing in both large and small
ways, to better un-derstand how a manufacturing organization might appropri-ate VR,
we ran a study with a global aviation manufacturer headquartered the United States.
To document the changing nature of work via this class of technologies we conducted
a VR study which facilitated access to participant observation and interviews (n=21).
Our findings provide initial insights into the organizational impact of VR on human
perfor-mance augmentation and skill acquisition revealing the larger infrastructural
challenges facing the adoption of con-sumer grade smart technologies in industrial
workplace settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, qualitative methods, field studies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376536,
author = {Lehmann, Florian and Buschek, Daniel},
title = {Heartbeats in the Wild: A Field Study Exploring ECG Biometrics in Everyday Life},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376536},
doi = {10.1145/3313831.3376536},
abstract = {This paper reports on an in-depth study of electrocardiogram (ECG) biometrics in everyday
life. We collected ECG data from 20 people over a week, using a non-medical chest
tracker. We evaluated user identification accuracy in several scenarios and observed
equal error rates of 9.15% to 21.91%, heavily depending on 1) the number of days used
for training, and 2) the number of heartbeats used per identification decision. We
conclude that ECG biometrics can work in the wild but are less robust than expected
based on the literature, highlighting that previous lab studies obtained highly optimistic
results with regard to real life deployments. We explain this with noise due to changing
body postures and states as well as interrupted measures. We conclude with implications
for future research and the design of ECG biometrics systems for real world deployments,
including critical reflections on privacy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {biometrics, electrocardiogram, field study, ecg},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376537,
author = {Draxler, Fiona and Labrie, Audrey and Schmidt, Albrecht and Chuang, Lewis L.},
title = {Augmented Reality to Enable Users in Learning Case Grammar from Their Real-World Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376537},
doi = {10.1145/3313831.3376537},
abstract = {Augmented Reality (AR) provides a unique opportunity to situate learning content in
one's environment. In this work, we investigated how AR could be developed to provide
an interactive context-based language learning experience. Specifically, we developed
a novel handheld-AR app for learning case grammar by dynamically creating quizzes,
based on real-life objects in the learner's surroundings. We compared this to the
experience of learning with a non-contextual app that presented the same quizzes with
static photographic images. Participants found AR suitable for use in their everyday
lives and enjoyed the interactive experience of exploring grammatical relationships
in their surroundings. Nonetheless, Bayesian tests provide substantial evidence that
the interactive and context-embedded AR app did not improve case grammar skills, vocabulary
retention, and usability over the experience with equivalent static images. Based
on this, we propose how language learning apps could be designed to combine the benefits
of contextual AR and traditional approaches.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {self-directed learning, language learning, augmented reality, grammar, contextual learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376538,
author = {Raissi, Reyhaneh and Dimara, Evanthia and Berry, Jacquelyn H. and Gray, Wayne D. and Bailly, Gilles},
title = {Retroactive Transfer Phenomena in Alternating User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376538},
doi = {10.1145/3313831.3376538},
abstract = {We investigated retroactive transfer when users alternate between different interfaces.
Retroactive transfer is the influence of a newly learned interface on users' performance
with a previously learned interface. In an interview study, participants described
their experiences when alternating between different interfaces, e.g. different operating
systems, devices or techniques. Negative retroactive transfer related to text entry
was the most frequently reported incident. We then reported a laboratory experiment
that investigated the impact of similarity between two abstract keyboard layouts,
and the number of alternations between them, on retroactive interference. Results
indicated that even small changes in the interference interface produced a significant
performance drop for the entire previously learned interface. The amplitude of this
performance drop decreases with the number of alternations. We suggest that retroactive
transfer should receive more attention in HCI, as the ubiquitous nature of interactions
across applications and systems requires users to increasingly alternate between similar
interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {retroactive interference, skill transfer, keyboard layout},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376539,
author = {Hauser, Sabrina and Suto, Melinda J. and Holsti, Liisa and Ranger, Manon and MacLean, Karon E.},
title = {Designing and Evaluating Calmer, a Device for Simulating Maternal Skin-to-Skin Holding for Premature Infants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376539},
doi = {10.1145/3313831.3376539},
abstract = {We describe the design and deployment of Calmer, a technology that simulates key aspects
of maternal skin-to-skin holding for prematurely born infants: its inspiration, approach,
physical design, and introduction into the Neonatal Intensive Care Unit. Maternal
skin-to-skin holding can mitigate neonatal pain during medical procedures by as much
as 50%, which can improve weight gain, sleep and later development. However, parents
cannot always be present, and some infants are too fragile to be held. Interventions
targeting this gap could be perceived as supplanting the mother in this intimate role,
exposing her to depression and endangering her maternal bond. Over 10 years, we iteratively
developed Calmer and demonstrated infant health benefit in a randomized clinical trial.
Here, we report and reflect on pursuing this goal in a socially and technologically
complex context: constraints, strategies, features, reception of the device, and surprises,
such as leading to mothers feeling channeled rather than replaced.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {research through design, premature infants, automation, neonatal intensive care, parents, pain reduction, nicu},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376540,
author = {Zagermann, Johannes and Pfeil, Ulrike and von Bauer, Philipp and Fink, Daniel and Reiterer, Harald},
title = {"It's in My Other Hand!" – Studying the Interplay of Interaction Techniques and Multi-Tablet Activities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376540},
doi = {10.1145/3313831.3376540},
abstract = {Cross-device interaction with tablets is a popular topic in HCI research. Recent work
has shown the benefits of including multiple devices into users' workflows while various
interaction techniques allow transferring content across devices. However, users are
only reluctantly using multiple devices in combination. At the same time, research
on cross-device interaction struggles to find a frame of reference to compare techniques
or systems. In this paper, we try to address these challenges by studying the interplay
of interaction techniques, device utilization, and task-specific activities in a user
study with 24 participants from different but complementary angles of evaluation using
an abstract task, a sensemaking task, and three interaction techniques. We found that
different interaction techniques have a lower influence than expected, that work behaviors
and device utilization depend on the task at hand, and that participants value specific
aspects of cross-device interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interaction techniques, evaluation, cross-device interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376541,
author = {Wells, Thomas and Houben, Steven},
title = {CollabAR – Investigating the Mediating Role of Mobile AR Interfaces on Co-Located Group Collaboration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376541},
doi = {10.1145/3313831.3376541},
abstract = {Mobile Augmented Reality (AR) technology is enabling new applications for different
domains including architecture, education or medical work. As AR interfaces project
digital data, information and models into the real world, it allows for new forms
of collaborative work. However, despite the wide availability of AR applications,
very little is known about how AR interfaces mediate and shape collaborative practices.
This paper presents a study which examines how a mobile AR (M-AR) interface for inspecting
and discovering AR models of varying complexity impacts co-located group practices.
We contribute new insights into how current mobile AR interfaces impact co-located
collaboration. Our results show that M-AR interfaces induce high mental load and frustration,
cause a high number of context switches between devices and group discussion, and
overall leads to a reduction in group interaction. We present design recommendations
for future work focusing on collaborative AR interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile augmented reality, co-located collaboration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376542,
author = {Rho, Eugenia Ha Rim and Mazmanian, Melissa},
title = {Political Hashtags &amp; the Lost Art of Democratic Discourse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376542},
doi = {10.1145/3313831.3376542},
abstract = {In this work, we investigate whether and how the presence of political hashtags in
social media news articles influences the way people discuss news content. Specifically,
we examine how political hashtags in news posts act as a design characteristic that
affects the quality of online discourse. We use a randomized control experiment to
assess how the presence versus absence of political hashtags (particularly the most
prevalently used #MeToo and #BlackLivesMatter) in social media news posts shapes discourse
across a general audience (n=3205). Key findings show differences in topical focus,
emotional tone of discourse, and rhetorical styles between commenters who were shown
news posts with political hashtags versus those shown news posts without the hashtags.
Compared to the control group, those shown hashtagged news posts heavily focus on
the politics of the hashtag, use more words associated with fear, anger, and disgust
in their comments, and exhibit black-and-white rhetoric and less emotionally temperate
expressions in their arguments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {civil discourse, political hashtags, social media news, digital journalism, online social movements, control experiment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376543,
author = {Hanton, Ollie and Wessely, Michael and Mueller, Stefanie and Fraser, Mike and Roudaut, Anne},
title = {ProtoSpray: Combining 3D Printing and Spraying to Create Interactive Displays with Arbitrary Shapes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376543},
doi = {10.1145/3313831.3376543},
abstract = {ProtoSpray is a fabrication method that combines 3D printing and spray coating, to
create interactive displays of arbitrary shapes. Our approach makes novel use of 3D
printed conductive channels to create base electrodes on 3D shapes. This is then combined
with spraying active materials to produce illumination. We demonstrate the feasibility
and benefits of this combined approach in 6 evaluations exploring different shaped
topologies. We analyze factors such as spray orientations, surface topologies and
printer resolutions, to discuss how spray nozzles can be integrated into traditional
3D printers. We present a series of ProtoSprayed objects demonstrating how our technique
goes beyond existing fabrication techniques by allowing creation of displays on objects
with curvatures as complex as a Mobius strip. Our work provides a platform to empower
makers to use displays as a fabrication material.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {spraying, fabrication, rapid prototyping, electroluminescence, display, 3d printing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376544,
author = {Moorthy, K. L. Bhanu and Kumar, Moneish and Subramanian, Ramanathan and Gandhi, Vineet},
title = {GAZED– Gaze-Guided Cinematic Editing of Wide-Angle Monocular Video Recordings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376544},
doi = {10.1145/3313831.3376544},
abstract = {We present GAZED– eye GAZe-guided EDiting for videos captured by a solitary, static, wide-angle and high-resolution camera. Eye-gaze has been effectively employed in computational applications as a cue to capture interesting scene content; we employ gaze as a proxy to select shots for inclusion in the edited video. Given the original video, scene content and user eye-gaze tracks are combined to generate an edited video comprising cinematically valid actor shots and shot transitions to generate an aesthetic and vivid representation of the original narrative. We model cinematic video editing as an energy minimization problem over shot selection, whose constraints capture cinematographic editing conventions. Gazed scene locations primarily determine the shots constituting the edited video. Effectiveness of GAZED against multiple competing methods is demonstrated via a psychophysical study involving 12 users and twelve performance videos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gaze potential, cinematic video editing, stage performance, shot selection, eye gaze, dynamic programming, static wide-angle recording},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376545,
author = {Dourish, Paul and Lawrence, Christopher and Leong, Tuck Wah and Wadley, Greg},
title = {On Being Iterated: The Affective Demands of Design Participation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376545},
doi = {10.1145/3313831.3376545},
abstract = {Iteration is a central feature of most HCI design methods, creating as it does opportunities
for engagements with stakeholder groups. But what does iteration demand of those groups?
Under what conditions do iterative engagements arise, and with what stakes? Building
on experiences with Aboriginal Australian communities, and drawing on feminist and
decolonial thinking, we examine the nature of iteration for HCI and how it frames
encounters between design and use, with a focus on the affective dimension of engagement
in iterative design processes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {participation, iteration, feminist theory, user-centered design, cultural computing, decolonial theory, postcolonial theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376546,
author = {Kuzminykh, Anastasia and Rintel, Sean},
title = {Classification of Functional Attention in Video Meetings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376546},
doi = {10.1145/3313831.3376546},
abstract = {Participants in video meetings have long struggled with asymmetrical attention levels,
especially when participants are distributed unevenly. While technological advances
offer exciting opportunities to augment remote users' attention, the phenomenological
complexity of attention means that to design attention-fostering features we must
first understand what aspects of it are functionally meaningful to support. In this
paper, we present a functional classification of observable attention for video meetings.
The classification was informed by two studies on sense-making and selectiveness of
attention in work meetings. It includes categories of attention accessible for technological
support, their functions in a meeting process, and meeting-related activities that
correspond to these functions. This classification serves as a multi-level representation
of attention and informs the design of features aiming to support remote participants'
attention in video meetings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {features, meetings, video-mediated communication, attention, engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376547,
author = {Michaelis, Joseph E. and Siebert-Evenstone, Amanda and Shaffer, David Williamson and Mutlu, Bilge},
title = {Collaborative or Simply Uncaged? Understanding Human-Cobot Interactions in Automation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376547},
doi = {10.1145/3313831.3376547},
abstract = {Collaborative robots, or cobots, represent a breakthrough technology designed for
high-level (e.g. collaborative) interactions between workers and robots with capabilities
for flexible deployment in industries such as manufacturing. Understanding how workers
and companies use and integrate cobots is important to inform the future design of
cobot systems and educational technologies that facilitate effective worker-cobot
interaction. Yet, little is known about typical training for collaboration and the
application of cobots in manufacturing. To close this gap, we interviewed nine experts
in manufacturing about their experience with cobots. Our thematic analysis revealed
that, contrary to the envisioned use, experts described most cobot applications as
only low-level (e.g. pressing start/stop buttons) interactions with little flexible
deployment, and experts felt traditional robotics skills were needed for collaborative
and flexible interaction with cobots. We conclude with design recommendations for
improved future robots, including programming and interface designs, and educational
technologies to support collaborative use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {educational technology, technology adoption, human-robot collaboration, collaborative robots, human-robot interaction (hri), end-user programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376548,
author = {Hua, Yiqing and Naaman, Mor and Ristenpart, Thomas},
title = {Characterizing Twitter Users Who Engage in Adversarial Interactions against Political Candidates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376548},
doi = {10.1145/3313831.3376548},
abstract = {Social media provides a critical communication platform for political figures, but
also makes them easy targets for harassment. In this paper, we characterize users
who adversarially interact with political figures on Twitter using mixed-method techniques.
The analysis is based on a dataset of 400 thousand users' 1.2 million replies to 756
candidates for the U.S. House of Representatives in the two months leading up to the
2018 midterm elections. We show that among moderately active users, adversarial activity
is associated with decreased centrality in the social graph and increased attention
to candidates from the opposing party. When compared to users who are similarly active,
highly adversarial users tend to engage in fewer supportive interactions with their
own party's candidates and express negativity in their user profiles. Our results
can inform the design of platform moderation mechanisms to support political figures
countering online harassment.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online harassment, user behavior, twitter, political candidates},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376549,
author = {Trieu, Penny and Baym, Nancy K.},
title = {Private Responses for Public Sharing: Understanding Self-Presentation and Relational Maintenance via Stories in Social Media},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376549},
doi = {10.1145/3313831.3376549},
abstract = {With nearly two billion users, social media Stories-an ephemeral format of sharing-are
increasingly popular and projected to overtake sharing via public feeds. Sharing via
Stories differs from Feeds sharing by removing the visible feedback (e.g. "likes"
and "comments") which has come to characterize social media. Given the salience of
responses visibility to self-presentation and relational maintenance in social media
literature, we conducted semi-structured interviews (N = 22) to explore how people
understand these processes when using Stories. We find that users have lower expectations
for responses with Stories and experience lower pressure for self-presentation. This
fosters more frequent sharing and a sense of daily connectedness, which strong ties
can find valuable. Finally, the act of viewing takes on new significance of signaling
attention when made known to the sharer. Our findings point to the importance of effort
and attention in understanding responses on social media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {stories, relational maintenance, self-presentation, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376550,
author = {Bai, Huidong and Sasikumar, Prasanth and Yang, Jing and Billinghurst, Mark},
title = {A User Study on Mixed Reality Remote Collaboration with Eye Gaze and Hand Gesture Sharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376550},
doi = {10.1145/3313831.3376550},
abstract = {Supporting natural communication cues is critical for people to work together remotely
and face-to-face. In this paper we present a Mixed Reality (MR) remote collaboration
system that enables a local worker to share a live 3D panorama of his/her surroundings
with a remote expert. The remote expert can also share task instructions back to the
local worker using visual cues in addition to verbal communication. We conducted a
user study to investigate how sharing augmented gaze and gesture cues from the remote
expert to the local worker could affect the overall collaboration performance and
user experience. We found that by combing gaze and gesture cues, our remote collaboration
system could provide a significantly stronger sense of co-presence for both the local
and remote users than using the gaze cue alone. The combined cues were also rated
significantly higher than the gaze in terms of ease of conveying spatial actions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3d panorama, virtual reality, remote collaboration, mixed reality, hand gesture, augmented reality, eye gaze, scene reconstruction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376551,
author = {Cho, Eugene and Sundar, S. Shyam and Abdullah, Saeed and Motalebi, Nasim},
title = {Will Deleting History Make Alexa More Trustworthy? Effects of Privacy and Content Customization on User Experience of Smart Speakers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376551},
doi = {10.1145/3313831.3376551},
abstract = {"Always-on" smart speakers have raised privacy and security concerns, to address which
vendors have introduced customizable privacy settings. But, does the act of customizing
one's privacy preferences have any effects on user experience and trust? To address
this question, we developed an app for Amazon Alexa and conducted a user study (N
= 90). Our data show that the affordance to customize privacy settings enhances trust
and usability for regular users, while it has adverse effects on power users. In addition,
only enabling privacy-setting customization without allowing content customization
negatively affects trust among users with higher privacy concerns. When they can customize
both content and privacy settings, user trust is highest. That is, while privacy customization
may cause reactance among power users, allowing privacy-concerned individuals to simultaneously
customize content can help to alleviate the resultant negative effect on trust. These
findings have implications for designing more privacy-sensitive and trustworthy smart
speakers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {security, voice assistant(s), privacy concern, power usage, smart speaker(s), customization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376552,
author = {Yasu, Kentaro},
title = {MagneLayer: Force Field Fabrication by Layered Magnetic Sheets},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376552},
doi = {10.1145/3313831.3376552},
abstract = {Magnets are very useful for the rapid prototyping of haptic interactions. However,
it is difficult to arrange fine and complex magnetic fields rapidly. Therefore, we
invented a method for fabricating complex geometric magnetic patterns by overlaying
multiple magnetic rubber sheets. This method resolves the tradeoff between magnetized
pattern complexity and the time required for magnetization. By layering multiple magnetic
sheets that have simple magnetic patterns, various types of geometric magnetic patterns,
such as checkered and diamond ones, can be generated on the top surface. By applying
superposed magnetic fields, various types of tactile stimuli and haptic interaction
can be created rapidly. Furthermore, the superposed magnetic fields can be changed
dynamically by rotating the layered magnetic sheets. In this paper, we clarify the
material requirements and describe the design method for creating these geometric
magnetic patterns. We also demonstrate several of their applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {tactile, fabrication, rapid prototyping, diy, magnet, haptic},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376553,
author = {Dayama, Niraj Ramesh and Todi, Kashyap and Saarelainen, Taru and Oulasvirta, Antti},
title = {GRIDS: Interactive Layout Design with Integer Programming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376553},
doi = {10.1145/3313831.3376553},
abstract = {Grid layouts are used by designers to spatially organise user interfaces when sketching
and wireframing. However, their design is largely time consuming manual work. This
is challenging due to combinatorial explosion and complex objectives, such as alignment,
balance, and expectations regarding positions. This paper proposes a novel optimisation
approach for the generation of diverse grid-based layouts. Our mixed integer linear
programming (MILP) model offers a rigorous yet efficient method for grid generation
that ensures packing, alignment, grouping, and preferential positioning of elements.
Further, we present techniques for interactive diversification, enhancement, and completion
of grid layouts. These capabilities are demonstrated using GRIDS, a wireframing tool
that provides designers with real-time layout suggestions. We report findings from
a ratings study (N = 13) and a design study (N = 16), lending evidence for the benefit
of computational grid generation during early stages of design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed-initiative, grid layouts, creativity support, design tools, computational design, optimisation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376554,
author = {Blaga, Andreea Dalia and Frutos-Pascual, Maite and Creed, Chris and Williams, Ian},
title = {Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376554},
doi = {10.1145/3313831.3376554},
abstract = {Influence of interaction fidelity and rendering quality on perceived user experience
have been largely explored in Virtual Reality (VR). However, differences in interaction
choices triggered by these rendering cues have not yet been explored. We present a
study analysing the effect of thermal visual cues and contextual information on 50
participants' approach to grasp and move a virtual mug. This study comprises 3 different
temperature cues (baseline empty, hot and cold) and 4 contextual representations;
all embedded in a VR scenario. We evaluate 2 different hand representations (abstract
and human) to assess grasp metrics. Results show temperature cues influenced grasp
location, with the mug handle being predominantly grasped with a smaller grasp aperture
for the hot condition, while the body and top were preferred for baseline and cold
conditions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {grasping metrics, hand interaction, virtual reality, hand tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376555,
author = {Bossauer, Paul and Neifer, Thomas and Stevens, Gunnar and Pakusch, Christina},
title = {Trust versus Privacy: Using Connected Car Data in Peer-to-Peer Carsharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376555},
doi = {10.1145/3313831.3376555},
abstract = {Trust is the lubricant of the sharing economy. This is true especially in peer-to-peer
carsharing, in which one leaves a highly valuable good to a stranger in the hope of
getting it back unscathed. Nowadays, ratings of other users are major mechanisms for
establishing trust. To foster uptake of peer-to-peer carsharing, connected car technology
opens new possibilities to support trust-building, e.g., by adding driving behavior
statistics to users' profiles. However, collecting such data intrudes into rentees'
privacy. To explore the tension between the need for trust and privacy demands, we
conducted three focus group and eight individual interviews. Our results show that
connected car technologies can increase trust for car owners and rentees not only
before but also during and after rentals. The design of such systems must allow a
differentiation between information in terms of type, the context, and the negotiability
of information disclosure.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {peer-to-peer carsharing, trust, privacy, connected car},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376556,
author = {Schroeder, Kay and Ajdadilish, Batoul and Henkel, Alexander P. and Calero Valdez, Andr\'{e}},
title = {Evaluation of a Financial Portfolio Visualization Using Computer Displays and Mixed Reality Devices with Domain Experts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376556},
doi = {10.1145/3313831.3376556},
abstract = {With the advent of mixed reality devices such as the Microsoft HoloLens, developers
have been faced with the challenge to utilize the third dimension in information visualization
effectively. Research on stereoscopic devices has shown that three-dimensional representation
can improve accuracy in specific tasks (e.g., network visualization). Yet, so far
the field has remained mute on the underlying mechanism. Our study systematically
investigates the differences in user perception between a regular monitor and a mixed
reality device. In a real-life within-subject experiment in the field with twenty-eight
investment bankers, we assessed subjective and objective task performance with two-
and three-dimensional systems, respectively. We tested accuracy with regard to position,
size, and color using single and combined tasks. Our results do not show a significant
difference in accuracy between mixed-reality and standard 2D monitor visualizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {UX study, user study, information visualization, hololens, mixed reality displays},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376557,
author = {Tian, Yang and Bai, Yuming and Zhao, Shengdong and Fu, Chi-Wing and Yang, Tianpei and Heng, Pheng Ann},
title = {Virtually-Extended Proprioception: Providing Spatial Reference in VR through an Appended Virtual Limb},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376557},
doi = {10.1145/3313831.3376557},
abstract = {Selecting targets directly in the virtual world is difficult due to the lack of haptic
feedback and inaccurate estimation of egocentric distances. Proprioception, the sense
of self-movement and body position, can be utilized to improve virtual target selection
by placing targets on or around one's body. However, its effective scope is limited
closely around one's body. We explore the concept of virtually-extended proprioception
by appending virtual body parts mimicking real body parts to users' avatars, to provide
spatial reference to virtual targets. Our studies suggest that our approach facilitates
more efficient target selection in VR as compared to no reference or using an everyday
object as reference. Besides, by cultivating users' sense of ownership on the appended
virtual body part, we can further enhance target selection performance. The effects
of transparency and granularity of the virtual body part on target selection performance
are also discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {proprioception, spatial reference, virtual reality, target selection, appended limb},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376558,
author = {Tsenova, Violeta and Wood, Gavin and Dolfini, Andrea and Tindley, Annie and Kirk, David},
title = {Un-Authorised View: Leveraging Volunteer Expertise in Heritage},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376558},
doi = {10.1145/3313831.3376558},
abstract = {Volunteers are an underused but important resource in presenting plural heritages
within large heritage organizations. We report on a qualitative study at a heritage
site in the UK which combined explorations of volunteers' practice and digital design.
The study comprised of observational fieldwork with co-creative activities across
eight linked workshops, where we explored the site with volunteers, and how we might
leverage existing working structures to make new design prototypes. Our collective
account contributes new insights on working with volunteers and the opportunities
that arise from acknowledging them as genius loci - recognising them as experts of
their own experience and capturing and supporting their skills as storytellers. Working
with the volunteering staff in a co-design process we created innovative designs including
our Un-authorised View, which draws out the unique perspectives and the personal stories
at heritage destinations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cultural probes, digital storytelling, genius loci, critical heritage, plural heritages, vr design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376559,
author = {Masson, Damien and Malacria, Sylvain and Lank, Edward and Casiez, G\'{e}ry},
title = {Chameleon: Bringing Interactivity to Static Digital Documents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376559},
doi = {10.1145/3313831.3376559},
abstract = {Documents such as presentations, instruction manuals, and research papers are disseminated
using various file formats, many of which barely support the incorporation of interactive
content. To address this lack of interactivity, we present Chameleon, a system-wide
tool that combines computer vision algorithms used for image identification with an
open database format to allow for the layering of dynamic content. Using Chameleon,
static documents can be easily upgraded by layering user-generated interactive content
on top of static images, all while preserving the original static document format
and without modifying existing applications. We describe the development of Chameleon,
including the design and evaluation of vision-based image replacement algorithms,
the new document-creation pipeline as well as a user study evaluating Chameleon.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactivity, feature matching, augmented documents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376560,
author = {Gorkovenko, Katerina and Burnett, Daniel J. and Thorp, James K. and Richards, Daniel and Murray-Rust, Dave},
title = {Exploring The Future of Data-Driven Product Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376560},
doi = {10.1145/3313831.3376560},
abstract = {Connected devices present new opportunities to advance design through data collection
in the wild, similar to the way digital services evolve through analytics. However,
it is still unclear how live data transmitted by connected devices informs the design
of these products, going beyond performance optimisation to support creative practices.
Design can be enriched by data captured by connected devices, from usage logs to environmental
sensors, and data about the devices and people around them. Through a series of workshops,
this paper contributes industry and academia perspectives on the future of data-driven
product design. We highlight HCI challenges, issues and implications, including sensemaking
and the generation of design insight. We further challenge current notions of data-driven
design and envision ways in which future HCI research can develop ways to work with
data in the design process in a connected, rich, human manner.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {iot, smart devices, in the wild, human-centred design, data-driven design, design research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376561,
author = {Wang, Jinping and Yang, Hyun and Shao, Ruosi and Abdullah, Saeed and Sundar, S. Shyam},
title = {Alexa as Coach: Leveraging Smart Speakers to Build Social Agents That Reduce Public Speaking Anxiety},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376561},
doi = {10.1145/3313831.3376561},
abstract = {Public speaking anxiety is one of the most common social phobias. We explore the feasibility
of using a conversational agent to reduce this anxiety. We developed a public-speaking
tutor on the Amazon Alexa platform that enables users to engage in cognitive reconstruction
exercises. We also investigated how the sociability of the agent might affect its
performance as a tutor. A user study of 53 college students with fear of public speaking
showed that the interaction with the agent served to assuage pre-speech state anxiety.
Agent sociability improved the sense of interpersonal closeness, which was associated
with lower pre-speech anxiety. Moreover, sociability of the agent increased participants'
satisfaction and their willingness to continue engagement. Our findings, thus, have
implications not only for addressing public speaking anxiety in a scalable way but
also for the design of future conversational agents using smart speaker platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {experiment, conversational agent, sociability, public speaking anxiety},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376562,
author = {Ogawa, Nami and Narumi, Takuji and Kuzuoka, Hideaki and Hirose, Michitaka},
title = {Do You Feel Like Passing Through Walls?: Effect of Self-Avatar Appearance on Facilitating Realistic Behavior in Virtual Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376562},
doi = {10.1145/3313831.3376562},
abstract = {Preventing users from walking through virtual boundaries (e.g., walls) is an important
issue to be addressed in room-scale virtual environments (VEs), considering the safety
and design limitations. Sensory feedback from wall collisions has been shown to be
effective; however, it can disrupt the immersion. We assumed that a greater sense
of presence would discourage users from walking through walls and conducted a two-factor
between-subjects experiment (N = 92) that controls the anthropomorphism (realistic
or abstract) and visibility (full-body or hand-only) of self-avatars. We analyzed
the participants' behaviors and the moment they first penetrated the wall in game-like
VEs that gradually instigated participants to penetrate the walls. The results showed
that the realistic full-body self-avatar was the most effective for discouraging the
participants from penetrating the walls. Furthermore, the participants with lower
presence tended to walk through the walls sooner. This study can contribute to applications
that require realistic user responses in VEs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {presence, self-avatar, body ownership},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376563,
author = {Alonzo, Oliver and Seita, Matthew and Glasser, Abraham and Huenerfauth, Matt},
title = {Automatic Text Simplification Tools for Deaf and Hard of Hearing Adults: Benefits of Lexical Simplification and Providing Users with Autonomy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376563},
doi = {10.1145/3313831.3376563},
abstract = {Automatic Text Simplification (ATS), which replaces text with simpler equivalents,
is rapidly improving. While some research has examined ATS reading-assistance tools,
little has examined preferences of adults who are deaf or hard-of-hearing (DHH), and
none empirically evaluated lexical simplification technology (replacement of individual
words) with these users. Prior research has revealed that U.S. DHH adults have lower
reading literacy on average than their hearing peers, with unique characteristics
to their literacy profile. We investigate whether DHH adults perceive a benefit from
lexical simplification applied automatically or when users are provided with greater
autonomy, with on-demand control and visibility as to which words are replaced. Formative
interviews guided the design of an experimental study, in which DHH participants read
English texts in their original form and with lexical simplification applied automatically
or on-demand. Participants indicated that they perceived a benefit form lexical simplification,
and they preferred a system with on-demand simplification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reading assistance, lexical simplification, people who are deaf or hard of hearing, autonomy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376564,
author = {Mudliar, Preeti},
title = {Whither Humane-Computer Interaction? Adult and Child Value Conflicts in the Biometric Fingerprinting for Food},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376564},
doi = {10.1145/3313831.3376564},
abstract = {This paper reports on the value conflicts that beneficiaries experience when engaging
in the monthly ritual of the biometric authentication of their fingerprints to claim
state-sponsored food entitlements in India. Drawing on value-based orientations to
HCI inquiry, the study locates the interactions around the biometric process to illustrate
the ways in which beneficiaries find their values of time, dignity, and privacy, consistently
disregarded by the interactive demands of the biometric system. Additionally, to cope
with these value conflicts, some beneficiaries pass on the responsibilities of completing
the biometric process to the children in their families. While adult beneficiaries
are vocal and articulate about the value tensions in their lives, children cope with
the anxieties of interacting with the biometric process, silently; even as they experience
conflicts in their education, play, and study time.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {values, aadhaar, social justice, food security, biometrics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376565,
author = {Mostajeran, Fariba and Steinicke, Frank and Ariza Nunez, Oscar Javier and Gatsios, Dimitrios and Fotiadis, Dimitrios},
title = {Augmented Reality for Older Adults: Exploring Acceptability of Virtual Coaches for Home-Based Balance Training in an Aging Population},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376565},
doi = {10.1145/3313831.3376565},
abstract = {Balance training has been shown to be effective in reducing risks of falling, which
is a major concern for older adults. Usually, exercise programs are individually prescribed
and monitored by physiotherapeutic or medical experts. Unfortunately, supervision
and motivation of older adults during home-based exercises cannot be provided on a
large scale, in particular, considering an ageing population. Augmented reality (AR)
in combination with virtual coaches could provide a reasonable solution to this challenge.We
present a first investigation of the acceptance of an AR coaching system for balance
training, which can be performed at home. In a human-centered design approach we developed
several mock-ups and prototypes, and evaluated them with 76 older adults. The results
suggest that older adults find the system encouraging and stimulating. The virtual
coach is perceived as an alive, calm, intelligent, and friendly human. However, usability
of the entire AR system showed a significant negative correlation with participants'
age.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {health and well-being, older adults, balance training, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376566,
author = {Babaei, Ebrahim and Srivastava, Namrata and Newn, Joshua and Zhou, Qiushi and Dingler, Tilman and Velloso, Eduardo},
title = {Faces of Focus: A Study on the Facial Cues of Attentional States},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376566},
doi = {10.1145/3313831.3376566},
abstract = {Automatically detecting attentional states is a prerequisite for designing interventions
to manage attention - knowledge workers' most critical resource. As a first step towards
this goal, it is necessary to understand how different attentional states are made
discernible through visible cues in knowledge workers. In this paper, we demonstrate
the important facial cues to detect attentional states by evaluating a data set of
15 participants that we tracked over a whole workday, which included their challenge
and engagement levels. Our evaluation shows that gaze, pitch, and lips part action
units are indicators of engaged work; while pitch, gaze movements, gaze angle, and
upper-lid raiser action units are indicators of challenging work. These findings reveal
a significant relationship between facial cues and both engagement and challenge levels
experienced by our tracked participants. Our work contributes to the design of future
studies to detect attentional states based on facial cues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {facial expression, attentional state, focus, challenge, engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376567,
author = {Anjani, Laurensia and Mok, Terrance and Tang, Anthony and Oehlberg, Lora and Goh, Wooi Boon},
title = {Why Do People Watch Others Eat Food? An Empirical Study on the Motivations and Practices of Mukbang Viewers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376567},
doi = {10.1145/3313831.3376567},
abstract = {We present a mixed-methods study of viewers on their practices and motivations around watching mukbang — video streams of people eating large quantities of food. Viewers' experiences provide insight on future technologies for multisensorial video streams and technology-supported commensality (eating with others). We surveyed 104 viewers and interviewed 15 of them about their attitudes and reflections on their mukbang viewing habits, their physiological aspects of watching someone eat, and their perceived social relationship with mukbangers. Based on our findings, we propose design implications for remote commensality, and for synchronized multisensorial video streaming content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mukbang, video streams},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376568,
author = {Bennett, Cynthia L. and Rosner, Daniela K. and Taylor, Alex S.},
title = {The Care Work of Access},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376568},
doi = {10.1145/3313831.3376568},
abstract = {Current approaches to AI and Assistive Technology (AT) often foreground task completion
over other encounters such as expressions of care. Our paper challenges and complements
such task-completion approaches by attending to the care work of access-the continual
affective and emotional adjustments that people make by noticing and attending to
one another. We explore how this work impacts encounters among people with and without
vision impairments who complete tasks together. We find that bound up in attempts
to get things done are concerns for one another and how well people are doing together.
Reading this work through emerging disability studies and feminist STS scholarship,
we account for two important forms of work that give rise to access: (1) mundane attunements
and (2) non-innocent authorizations. Together these processes work as sensitizing
concepts to help HCI scholars account for the ways that intelligent ATs both produce
access while sometimes subverting people with disabilities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {assistance, blind, care, disability, interdependence, artificial intelligence, vision impaired},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376569,
author = {Choi, Dasom and Kwak, Daehyun and Cho, Minji and Lee, Sangsu},
title = {"Nobody Speaks That Fast!" An Empirical Study of Speech Rate in Conversational Agents for People with Vision Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376569},
doi = {10.1145/3313831.3376569},
abstract = {The number of people with vision impairments using Conversational Agents (CAs) has
increased because of the potential of this technology to support them. As many visually
impaired people are accustomed to understanding fast speech, most screen readers or
voice assistant systems offer speech rate settings. However, current CAs are designed
to interact at a human-like speech rate without considering their accessibility. In
this study, we tried to understand how people with vision impairments use CA at a
fast speech rate. We conducted a 20-day in-home study that examined the CA use of
10 visually impaired people at default and fast speech rates. We investigated the
difference in visually impaired people's CA use with different speech rates and their
perception toward CA at each rate. Based on these findings, we suggest considerations
for the future design of CA speech rate for those with visual impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational agents, people with vision impairments, accessibility, speech rate},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376570,
author = {Zou, Yixin and Roundy, Kevin and Tamersoy, Acar and Shintre, Saurabh and Roturier, Johann and Schaub, Florian},
title = {Examining the Adoption and Abandonment of Security, Privacy, and Identity Theft Protection Practices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376570},
doi = {10.1145/3313831.3376570},
abstract = {Users struggle to adhere to expert-recommended security and privacy practices. While
prior work has studied initial adoption of such practices, little is known about the
subsequent implementation and abandonment. We conducted an online survey (n=902) examining
the adoption and abandonment of 30 commonly recommended practices. Security practices
were more widely adopted than privacy and identity theft protection practices. Manual
and fully automatic practices were more widely adopted than practices requiring recurring
user interaction. Participants' gender, education, technical background, and prior
negative experience are correlated with their levels of adoption. Furthermore, practices
were abandoned when they were perceived as low-value, inconvenient, or when users
overrode them with subjective judgment. We discuss how security, privacy, and identity
theft protection recommendations and tools can be better aligned with user needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {user behavior, security and privacy decision-making, adoption, abandonment, technology non-use, risk perception, usable security and privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376571,
author = {Mohaddesi, Omid and Sun, Yifan and Azghandi, Rana and Doroudi, Rozhin and Snodgrass, Sam and Ergun, Ozlem and Griffin, Jacqueline and Kaeli, David and Marsella, Stacy and Harteveld, Casper},
title = {Introducing Gamettes: A Playful Approach for Capturing Decision-Making for Informing Behavioral Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376571},
doi = {10.1145/3313831.3376571},
abstract = {Agent-based simulations are widely used for modeling human behavior in various contexts.
However, such simulations may oversimplify human decision-making. We propose the use
of Gamettes to extract rich data on human decision-making and help in improving the
human behavioral aspects of models underlying agent-based simulations. We show how
Gamettes are designed and provide empirical validation for using Gamettes in an experimental
supply chain setting to study human decision-making. Our results show that Gamettes
are successful in capturing the expected behaviors and patterns in supply chain decisions,
and, thus, we find evidence for the capability of Gamettes to inform behavioral models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {simulation, agent-based model, beer game, decision-making, gamette, supply chain, human behavior},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376572,
author = {Mim, Nusrat Jahan and Ahmed, Syed Ishtiaque},
title = {Others' Images: Online Social Media, Architectural Improvisations, and Spatial Marginalization in Bangladesh},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376572},
doi = {10.1145/3313831.3376572},
abstract = {This paper joins the growing body of work in postcolonial computing in HCI, and critically
examines the impacts of online social media on the urban architecture in the Global
South. Based on our nine-month long ethnography at eight residential areas in Dhaka,
Bangladesh, this paper reports how online fame drives local users to produce digital
images of their houses mimicking various Western standards, which in turn, brings
changes to the organization, aesthetics, and functions of domestic spaces. This paper
also describes how such digital image mediated transformations to local architecture
are diminishing traditional spaces, altering their usual functions, and limiting the
movement of many women inside their home. Drawing from a rich body of literature in
postcolonialism, critical image theory, architecture, and Islamic feminism, we explain
how these practices demonstrate a subaltern experience of using social media in the
Global South. We further discuss design implications to both HCI and architecture
to address these issues, and connect our findings to the broader agendas of HCI around
social justice and global development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {image sharing, architecture, global south, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376573,
author = {Petelka, Justin and Van Kleunen, Lucy and Albright, Liam and Murnane, Elizabeth and Voida, Stephen and Snyder, Jaime},
title = {Being (In)Visible: Privacy, Transparency, and Disclosure in the Self-Management of Bipolar Disorder},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376573},
doi = {10.1145/3313831.3376573},
abstract = {Research in personal informatics (PI) calls for systems to sup- port social forms
of tracking, raising questions about how privacy can and should support intentionally
sharing sensitive health information. We focus on the case of personal data related
to the self-tracking of bipolar disorder (BD) in order to explore the ways in which
disclosure activities intersect with other privacy experiences. While research in
HCI of- ten discusses privacy as a disclosure activity, this does not reflect the
ways in which privacy can be passively experienced. In this paper we broaden conceptions
of privacy by defining transparency experiences and contributing factors in contrast
to disclosure activities and preferences. Next, we ground this theoretical move in
empirical analysis of personal narratives shared by people managing BD. We discuss
the resulting emer- gent model of transparency in terms of implications for the design
of socially-enabled PI systems. CAUTION: This paper contains references to experiences
of mental illness, including self-harm, depression, suicidal ideation, etc.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {privacy, personal informatics, bipolar disorder, serious mental illness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376574,
author = {Freiwald, Jann Philipp and Ariza, Oscar and Janeh, Omar and Steinicke, Frank},
title = {Walking by Cycling: A Novel In-Place Locomotion User Interface for Seated Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376574},
doi = {10.1145/3313831.3376574},
abstract = {We introduce VR Strider, a novel locomotion user interface (LUI) for seated virtual
reality (VR) experiences, which maps cycling biomechanics of the user's legs to virtual
walking movements. The core idea is to translate the motion of pedaling on a mini
exercise bike to a corresponding walking animation of a virtual avatar while providing
audio-based tactile feedback on virtual ground contacts. We conducted an experiment
to evaluate the LUI and our novel anchor-turning rotation control method regarding
task performance, spatial cognition, VR sickness, sense of presence, usability and
comfort in a path-integration task. The results show that VR Strider has a significant
positive effect on the participants' angular and distance estimation, sense of presence
and feeling of comfort compared to other established locomotion techniques, such as
teleportation and joystick-based navigation. A confirmatory study further indicates
the necessity of synchronized avatar animations for virtual vehicles that rely on
pedalling.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {embodied interaction, locomotion, input techniques, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376575,
author = {Ebert, Nico and Ackermann, Kurt Alexander and Heinrich, Peter},
title = {Does Context in Privacy Communication Really Matter? — A Survey on Consumer Concerns and Preferences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376575},
doi = {10.1145/3313831.3376575},
abstract = {Privacy policies as a means of communicating with customers still prove ineffective.
Researchers have recently suggested that a specific usage context should be considered
to make privacy notices more relevant to users. To explore this approach further,
we conducted an explorative online survey of privacy concerns and privacy information
preferences with 642 participants for two different contexts (loyalty cards and fitness
tracking). Our data shows some support for the suggestion that context may be a significant
moderator of concerns and preferences. However, the corresponding effects are rather
small and limited to specific concerns and information categories. In line with other
research, the data supports the known hierarchy of concerns regarding unauthorized
secondary use and improper data access, which seem to exceed concerns about erroneous
data processing or excessive data collection in both contexts. Furthermore, participants
considered information on personal rights and processing purposes more relevant than
information on contact persons.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {privacy concerns, user preferences, policy, privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376576,
author = {Rakhmetulla, Gulnar and Arif, Ahmed Sabbir},
title = {Senorita: A Chorded Keyboard for Sighted, Low Vision, and Blind Mobile Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376576},
doi = {10.1145/3313831.3376576},
abstract = {Senorita is a novel two-thumb virtual chorded keyboard for mobile devices. It arranges
the letters on eight keys in a single row by the bottom edge of the device based on
letter frequencies and the anatomy of the thumbs. Unlike most chorded methods, it
provides visual cues to perform the chording actions in sequence, instead of simultaneously,
when the actions are unknown, facilitating "learning by doing". Its compact design
leaves most of the screen available and its position near the edge accommodates eyes-free
text entry. In a longitudinal study with a smartphone, Senorita yielded on average
14 wpm. In a short-term study with a tablet, it yielded on average 9.3 wpm. In the
final longitudinal study, it yielded 3.7 wpm with blind users, surpassing their Qwerty
performance. Low vision users yielded 5.8 wpm. Further, almost all users found Senorita
effective, easy to learn, and wanted to keep use it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chords, accessibility, tablets, text input, blind, mobile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376577,
author = {Houben, Maarten and Brankaert, Rens and Bakker, Saskia and Kenning, Gail and Bongers, Inge and Eggen, Berry},
title = {The Role of Everyday Sounds in Advanced Dementia Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376577},
doi = {10.1145/3313831.3376577},
abstract = {The representation of sounds derived from everyday life can be beneficial for people
with dementia by evoking memories and emotional responses. Despite this potential,
integrating sound and sound-based interventions in care facilities has not received
much research attention. In this paper, we present the findings from a field study
that explored the responses of 19 people with advanced dementia to a selection of
everyday sounds presented to them in a care home and the role of these responses in
the care environment. To study this, we deployed Vita, a 'pillow-like' sound player,
in two dementia care facilities for four weeks, during which observations were recorded.
Afterwards, we conducted interviews with caregivers who used Vita in everyday care
practice. Our findings reveal how everyday sounds provided by Vita stimulated meaningful
conversation, playfulness, and connection between residents and caregivers. Furthermore,
we propose design implications for integrating everyday sounds in dementia care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {soundscapes, everyday sounds, care home, design, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376578,
author = {Voelker, Simon and Hueber, Sebastian and Holz, Christian and Remy, Christian and Marquardt, Nicolai},
title = {GazeConduits: Calibration-Free Cross-Device Collaboration through Gaze and Touch},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376578},
doi = {10.1145/3313831.3376578},
abstract = {We present GazeConduits, a calibration-free ad-hoc mobile interaction concept that
enables users to collaboratively interact with tablets, other users, and content in
a cross-device setting using gaze and touch input. GazeConduits leverages recently
introduced smartphone capabilities to detect facial features and estimate users' gaze
directions. To join a collaborative setting, users place one or more tablets onto
a shared table and position their phone in the center, which then tracks users present
as well as their gaze direction to determine the tablets they look at. We present
a series of techniques using GazeConduits for collaborative interaction across mobile
devices for content selection and manipulation. Our evaluation with 20 simultaneous
tablets on a table shows that GazeConduits can reliably identify which tablet or collaborator
a user is looking at.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {touch input, cross-device interaction, gaze input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376579,
author = {Sengupta, Korok and Bhattarai, Sabin and Sarcar, Sayan and MacKenzie, I. Scott and Staab, Steffen},
title = {Leveraging Error Correction in Voice-Based Text Entry by Talk-and-Gaze},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376579},
doi = {10.1145/3313831.3376579},
abstract = {We present the design and evaluation of Talk-and-Gaze (TaG), a method for selecting
and correcting errors with voice and gaze. TaG uses eye gaze to overcome the inability
of voice-only systems to provide spatial information. The user's point of gaze is
used to select an erroneous word either by dwelling on the word for 800 ms (D-TaG)
or by uttering a "select" voice command (V-TaG). A user study with 12 participants
compared D-TaG, V-TaG, and a voice-only method for selecting and correcting words.
Corrections were performed more than 20% faster with D-TaG compared to the V-TaG or
voice-only methods. As well, D-TaG was observed to require 24% less selection effort
than V-TaG and 11% less selection effort than voice-only error correction. D-TaG was
well received in a subjective assessment with 66% of users choosing it as their preferred
choice for error correction in voice-based text entry.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {eye tracking, interaction design, voice, multimodal, text entry, usability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376580,
author = {Maye, Laura and Robinson, Sarah and Pantidi, Nadia and Ganea, Liana and Ganea, Oana and Linehan, Conor and McCarthy, John},
title = {Considerations for Implementing Technology to Support Community Radio in Rural Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376580},
doi = {10.1145/3313831.3376580},
abstract = {Rural communities often lack platforms to support civic engagement and local deliberation.
Community radio is intended to facilitate such functions, yet, radio technologies
can be expensive and complex to use. To tackle this challenge, low-barrier radio technologies
are becoming available. We argue that technology to support civic engagement and local
deliberation are important, and design of such platforms must take into consideration
specific community needs. We contribute by exploring the needs of three rural European
communities. Findings indicate that communities are now distributed beyond place.
Platforms for deliberation must include both hyper-local and geographically dispersed
populations. Rural values of accountability, reliability and maintaining social harmony
are important design considerations. Community radio platforms should support geographically
distributed community connections, sharing of health and emergency information, preservation
of heritage and as a space for advocacy and civic action.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {community media, community radio, rural},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376581,
author = {Gupta, Maya and Abdolrahmani, Ali and Edwards, Emory and Cortez, Mayra and Tumang, Andrew and Majali, Yasmin and Lazaga, Marc and Tarra, Samhitha and Patil, Prasad and Kuber, Ravi and Branham, Stacy M.},
title = {Towards More Universal Wayfinding Technologies: Navigation Preferences Across Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376581},
doi = {10.1145/3313831.3376581},
abstract = {Accessibility researchers have been studying wayfinding technologies for people with
disabilities for decades, typically focusing on solutions within disability populations
- for example, technologies to support blind navigation. Yet, we know little about
wayfinding needs across disabilities. In this paper, we describe a qualitative interview
study examining the urban navigational experiences of 27 people who identified as
older adults and/or who had cognitive, visual, hearing, and/or mobility disabilities.
We found that many navigation route preferences were shared across disabilities (e.g.,
desire to avoid carpeted areas), while others diverged or were in tension (e.g., the
need to avoid noisy areas while staying near main thoroughfares). To support design
for multiple disability groups, we identify four dimensions of navigation preferences
- technology, route, assistance, experience - and describe how these might usefully
inform design of more universally usable wayfinding technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {navigation, cognitive impairment, accessibility, older adults, deaf, visual impairment, mobility impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376582,
author = {Bahng, Sojung and Kelly, Ryan M. and McCormack, Jon},
title = {Reflexive VR Storytelling Design Beyond Immersion: Facilitating Self-Reflection on Death and Loneliness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376582},
doi = {10.1145/3313831.3376582},
abstract = {This research examines the reflexive dimensions of cinematic virtual reality (CVR)
storytelling. We created Anonymous, an interactive CVR piece that employs a reflexive
storytelling method. This method is based on distancing effects and is used to elicit
audience awareness and self-reflection about loneliness and death. To understand the
audience's experiences, we conducted in-depth interviews to study which design factors
and elements prompted reflexive thoughts and feelings. Our findings highlight how
the audience experience was impacted by four reflexive dimensions: abstract and minimal
aesthetics, everyday materials and textures, the restriction of control, and multiple,
disembodied points of view. We use our findings to discuss how these dimensions can
inform the design of VR storytelling experiences that provoke self and social reflection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {distancing effect, cinematic vr, immersive storytelling, virtual reality, alienation, estrangement, reflexivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376583,
author = {Hsu, Silas and Vaccaro, Kristen and Yue, Yin and Rickman, Aimee and Karahalios, Karrie},
title = {Awareness, Navigation, and Use of Feed Control Settings Online},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376583},
doi = {10.1145/3313831.3376583},
abstract = {Control settings are abundant and have significant effects on user experiences. One
example of an impactful but understudied area is feed settings. In this study, we
investigated awareness, navigation, and use of feed settings. We began by creating
a taxonomy of feed settings on social media and search sites. Via an online survey,
we measured awareness of Facebook feed settings. An in-person interview study then
investigated how people navigated to and chose to set feed settings on their own feeds.
We discovered that many participants did not believe ad personalization feed settings
existed. Furthermore, we discovered a misalignment in the expectation and the function
of settings, especially of ad personalization settings for many participants. Despite
all participants struggling to find at least one setting, participants overall wanted
to use settings: 94% altered at least one setting they encountered. From these results,
we discuss implications and suggest design guidelines for settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {feeds, control, social media, settings},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376584,
author = {Daskalova, Nediyana and Yoon, Jina and Wang, Yibing and Araujo, Cintia and Beltran, Guillermo and Nugent, Nicole and McGeary, John and Williams, Joseph Jay and Huang, Jeff},
title = {SleepBandits: Guided Flexible Self-Experiments for Sleep},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376584},
doi = {10.1145/3313831.3376584},
abstract = {Self-experiments allow people to explore what behavioral changes lead to improved
health and wellness. However, it is challenging to run such experiments in a scientifically
valid way that is also flexible and able to accommodate the realities of daily life.
We present a set of design principles for guided self-experiments that aim to lower
this barrier to self-experimentation. We demonstrate the value of the principles by
implementing them in SleepBandits, an integrated system that includes a smartphone
application for sleep experiments. SleepBandits guides users through the steps of
a single-case experiment, automatically collecting data from the built-in sensors
and user input and calculating and presenting results in real-time. We released SleepBandits
to the Google Play Store and people voluntarily downloaded and used it. Based on the
data from 365 active users from this in-the-wild study, we discuss opportunities and
challenges with the design principles and the SleepBandits system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal informatics, self-experiments, sleep tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376585,
author = {Song, Yunpeng and Huang, Yun and Cai, Zhongmin and Hong, Jason I.},
title = {I'm All Eyes and Ears: Exploring Effective Locators for Privacy Awareness in IoT Scenarios},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376585},
doi = {10.1145/3313831.3376585},
abstract = {With the proliferation of IoT devices, there are growing concerns about being sensed
or monitored by these devices unawares, especially in places perceived as private.
We explore the design space of IoT locators to help people physically find nearby
IoT devices. We first conducted a survey to understand people's willingness, current
practices, and challenges in finding IoT devices. Our survey findings motivated us
to design and implement low-cost locators (visual, auditory, and contextualized pictures)
to help people find nearby devices. Through an iterative design process and two rounds
of experiments, we found that these locators greatly reduced people's search time
over a baseline of no locators. Many participants found the visual and auditory locators
enjoyable. Some participants also appropriated the use of our system for other purposes,
e.g., to learn about new IoT devices, instead of for privacy awareness.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy awareness, internet of things, locator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376586,
author = {Guillou, Hayley and Chow, Kevin and Fritz, Thomas and McGrenere, Joanna},
title = {Is Your Time Well Spent? Reflecting on Knowledge Work More Holistically},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376586},
doi = {10.1145/3313831.3376586},
abstract = {The modern workplace is more demanding than ever before. Yet, since the industrial
age, productivity measures have predominantly stayed narrowly focused on the output
of the work, and not accounted for the big shift in the cognitive demands placed on
the workers or the interleaving of work and life that is so common today. We posit
that a more holistic conceptualization of Time Well Spent (TWS) at work could mitigate
this issue. In our 1-week study, 40 knowledge workers used the experience sampling
method (ESM) to rate their TWS and then define TWS at the end of the week. Our work
contributes a preliminary characterization of TWS and empirical evidence that this
term can capture a more holistic notion of work that also includes the worker's feelings
and well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {experience sampling method, time tracking, productivity tools, productivity, knowledge worker, well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376587,
author = {Pei, Lucy and Crooks, Roderic},
title = {Attenuated Access: Accounting for Startup, Maintenance, and Affective Costs in Resource-Constrained Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376587},
doi = {10.1145/3313831.3376587},
abstract = {The term "digital divide" indexes a body of research at the intersection of digital
technology and social equity, including research on inequality that criticizes and
recapitulates the original concept. Based on a qualitative study at a community literacy
center serving resettled refugees and immigrants, we show that the digital divide
framework rests on a distributive logic, one that implies that distributing access
to digital technology constitutes a form of social equity. Because this framework
only considers valorized goods, skills, and uses, research has frequently ignored
the startup, maintenance, and affective costs we found accompanied digital access
for our participants. To account for these costs, we propose a theoretical adjustment
to the digital divide framework, one where design is an act of configuring both costs
and benefits together. We argue that considering such costs enables HCI researchers
to engage more effectively with host communities in the non-innocent work of confronting
inequity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {equity, social justice, immigrants and resettled refugees, digital access, digital divide},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376588,
author = {Barrios, Liliana and Oldrati, Pietro and Lindlbauer, David and Hilty, Marc and Hayward-Koennecke, Helen and Holz, Christian and Lutterotti, Andreas},
title = {A Rapid Tapping Task on Commodity Smartphones to Assess Motor Fatigability},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376588},
doi = {10.1145/3313831.3376588},
abstract = {Fatigue is a common debilitating symptom of many autoimmune diseases, including multiple
sclerosis. It negatively impacts patients' every-day life and productivity. Despite
its prevalence, fatigue is still poorly understood. Its subjective nature makes quantification
challenging and it is mainly assessed by questionnaires, which capture the magnitude
of fatigue insufficiently. Motor fatigability, the objective decline of performance
during a motor task, is an underrated aspect in this regard. Currently, motor fatigability
is assessed using a handgrip dynamometer. This approach has been proven valid and
accurate but requires special equipment and trained personnel. We propose a technique
to objectively quantify motor fatigability using a commodity smartphone. The method
comprises a simple exertion task requiring rapid alternating tapping. Our study with
20 multiple sclerosis patients and 35 healthy participants showed a correlation of
rho = 0.8 with the baseline handgrip method. This smartphone-based approach is a first
step towards ubiquitous, more frequent, and remote monitoring of fatigability and
disease progression.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {mobile health, fatigability, smartphones},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376589,
author = {Duan, Peitong and Wierzynski, Casimir and Nachman, Lama},
title = {Optimizing User Interface Layouts via Gradient Descent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376589},
doi = {10.1145/3313831.3376589},
abstract = {Automating parts of the user interface (UI) design process has been a longstanding
challenge. We present an automated technique for optimizing the layouts of mobile
UIs. Our method uses gradient descent on a neural network model of task performance
with respect to the model's inputs to make layout modifications that result in improved
predicted error rates and task completion times. We start by extending prior work
on neural network based performance prediction to 2-dimensional mobile UIs with an
expanded interaction space. We then apply our method to two UIs, including one that
the model had not been trained on, to discover layout alternatives with significantly
improved predicted performance. Finally, we confirm these predictions experimentally,
showing improvements up to 9.2 percent in the optimized layouts. This demonstrates
the algorithm's efficacy in improving the task performance of a layout, and its ability
to generalize and improve layouts of new interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {gradient descent, performance modeling, lstm, deep learning, optimization, data-driven design, mobile interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376590,
author = {Liao, Q. Vera and Gruen, Daniel and Miller, Sarah},
title = {Questioning the AI: Informing Design Practices for Explainable AI User Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376590},
doi = {10.1145/3313831.3376590},
abstract = {A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic
work on the topic. While many recognize the necessity to incorporate explainability
features in AI systems, how to address real-world user needs for understanding AI
remains an open question. By interviewing 20 UX and design practitioners working on
various AI products, we seek to identify gaps between the current XAI algorithmic
work and practices to create explainable AI products. To do so, we develop an algorithm-informed
XAI question bank in which user needs for explainability are represented as prototypical
questions users might ask about the AI, and use it as a study probe. Our work contributes
insights into the design space of XAI, informs efforts to support design practices
in this space, and identifies opportunities for future XAI work. We also provide an
extended XAI question bank and discuss how it can be used for creating user-centered
XAI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {explainable AI, user experience, human-AI interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376591,
author = {Lee, Sooyeon and Reddie, Madison and Tsai, Chun-Hua and Beck, Jordan and Rosson, Mary Beth and Carroll, John M.},
title = {The Emerging Professional Practice of Remote Sighted Assistance for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376591},
doi = {10.1145/3313831.3376591},
abstract = {People with visual impairments (PVI) must interact with a world they cannot see. Remote
sighted assistance (RSA) has emerged as a conversational assistive technology. We
interviewed RSA assistants ("agents") who provide assistance to PVI via a conversational
prosthetic called Aira (https://aira.io/) to understand their professional practice.
We identified four types of support provided: scene description, navigation, task
performance, and social engagement. We discovered that RSA provides an opportunity
for PVI to appropriate the system as a richer conversational/social support tool.
We studied and identified patterns in how agents provide assistance and how they interact
with PVI as well as the challenges and strategies associated with each context. We
found that conversational interaction is highly context-dependent. We also discuss
implications for design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human powered accessibility, remote sighted assistance, assistive technology, visual impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376592,
author = {Chen, Yuan and Katsuragawa, Keiko and Lank, Edward},
title = {Understanding Viewport- and World-Based Pointing with Everyday Smart Devices in Immersive Augmented Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376592},
doi = {10.1145/3313831.3376592},
abstract = {Personal smart devices have demonstrated a variety of efficient techniques for pointing
and selecting on physical displays. However, when migrating these input techniques
to augmented reality, it is both unclear what the relative performance of different
techniques will be given the immersive nature of the environment, and it is unclear
how viewport-based versus world-based pointing methods will impact performance. To
better understand the impact of device and viewing perspectives on pointing in augmented
reality, we present the results of two controlled experiments comparing pointing conditions
that leverage various smartphone- and smartwatch-based external display pointing techniques
and examine viewport-based versus world-based target acquisition paradigms. Our results
demonstrate that viewport-based techniques offer faster selection and that both smartwatch-
and smartphone-based pointing techniques represent high-performance options for performing
distant target acquisition tasks in augmented reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, input devices, mobile devices, 3D pointing, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376593,
author = {Swearngin, Amanda and Wang, Chenglong and Oleson, Alannah and Fogarty, James and Ko, Amy J.},
title = {Scout: Rapid Exploration of Interface Layout Alternatives through High-Level Design Constraints},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376593},
doi = {10.1145/3313831.3376593},
abstract = {Although exploring alternatives is fundamental to creating better interface designs,
current processes for creating alternatives are generally manual, limiting the alternatives
a designer can explore. We present Scout, a system that helps designers rapidly explore
alternatives through mixed-initiative interaction with high-level constraints and
design feedback. Prior constraint-based layout systems use low-level spatial constraints
and generally produce a single design. Tosupport designer exploration of alternatives,
Scout introduces high-level constraints based on design concepts (e.g.,~semantic structure,
emphasis, order) and formalizes them into low-level spatial constraints that a solver
uses to generate potential layouts. In an evaluation with 18 interface designers,
we found that Scout: (1) helps designers create more spatially diverse layouts with
similar quality to those created with a baseline tool and (2) can help designers avoid
a linear design process and quickly ideate layouts they do not believe they would
have thought of on their own.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interface design, program synthesis, constraints, alternatives},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376594,
author = {Zhu, Haining and Moffa, Zachary J. and Gui, Xinning and Carroll, John M.},
title = {Prehabilitation: Care Challenges and Technological Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376594},
doi = {10.1145/3313831.3376594},
abstract = {Millions of surgeries are performed in the US annually, and numbers are trending upwards.
Traditional rehabilitative interventions are struggling to meet current demands, and
researchers have turned to pre-operative interventions, or prehabilitation, to improve
patient functions. However, existing literature primarily discusses efficacy or the
use of commercial sensing devices, and lacks a clear comprehension of healthcare professionals'
(HPs') needs and perspectives. User-centered stakeholder understandings are crucial
for a technology's adoption, but prehabilitation literature lacks such understandings.
Therefore we conduct semi-structured interviews with 12 prehabilitation healthcare
professionals (HPs) to offer descriptions of care challenges, tool usage, and perspectives
regarding suitable and effective technologies. These data can assist designers in
fostering prehabilitation processes via tailored prehabilitation tools which meet
HPs' needs and expectations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user-centered design, psychological health, physical health, prehabilitation, surgical care, nutritional health, rehabilitation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376595,
author = {Huang, Xiaoyun and Vitak, Jessica and Tausczik, Yla},
title = {"You Don't Have To Know My Past": How WeChat Moments Users Manage Their Evolving Self-Presentation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376595},
doi = {10.1145/3313831.3376595},
abstract = {Most social media platforms record, display, and archive users' personal histories.
This persistence of posts over time can be problematic, as users' self-presentation
goals and network composition change, but old content remains. In this paper, we explore
an alternative feature that provides control over content persistence. We present
findings from interviews with 16 users of the popular Chinese social media platform
WeChat Moments. We focused on Moments' Time Limit setting, which makes social media
data ephemeral to audiences, but persistent to posters. Interviewees described changes
in their self-presentation goals and social network composition over time and reported
the Time Limit feature helped them effortlessly manage their desired self-presentation
as they matured. Drawing on these findings, we discuss design implications for social
media to facilitate greater control over content visibility and persistence, which
may have significant benefits for social media users with large and diverse networks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ephemerality, self-presentation, persistence, wechat moments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376596,
author = {Barathi, Soumya C. and Proulx, Michael and O'Neill, Eamonn and Lutteroth, Christof},
title = {Affect Recognition Using Psychophysiological Correlates in High Intensity VR Exergaming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376596},
doi = {10.1145/3313831.3376596},
abstract = {User experience estimation of VR exergame players by recognising their affective state
could enable us to personalise and optimise their experience. Affect recognition based
on psychophysiological measurements has been successful for moderate intensity activities.
High intensity VR exergames pose challenges as the effects of exercise and VR headsets
interfere with those measurements. We present two experiments that investigate the
use of different sensors for affect recognition in a VR exergame. The first experiment
compares the impact of physical exertion and gamification on psychophysiological measurements
during rest, conventional exercise, VR exergaming, and sedentary VR gaming. The second
experiment compares underwhelming, overwhelming and optimal VR exergaming scenarios.
We identify gaze fixations, eye blinks, pupil diameter and skin conductivity as psychophysiological
measures suitable for affect recognition in VR exergaming and analyse their utility
in determining affective valence and arousal. Our findings provide guidelines for
researchers of affective VR exergames.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {affect recognition, psychophysiological correlates, VR exergaming, high intensity exercise},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376597,
author = {Yoo, Daisy and Tabard, Aur\'{e}lien and Ducros, Alix and Dalsgaard, Peter and Klokmose, Clemens Nylandsted and Eriksson, Eva and Serholt, Sofia},
title = {Computational Alternatives Vignettes for Place- and Activity-Centered Digital Services in Public Libraries},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376597},
doi = {10.1145/3313831.3376597},
abstract = {We investigate how to design community technologies for public events. We do so with
a focus on technologies that give rise to new forms of participation and knowledge
co-production in public libraries. Specifically, we deployed a digital service at
a major public library during its four-week creative workshop series. The system offered
an alternative way for people to work together as a community, to go beyond achieving
individual goals, and to contribute to the achievement of public goals (e.g., building
community bookshelves). We report on how the system has reconfigured physical spaces
and afforded new social practices in the library. We propose Computational Alternatives
as a fruitful approach for gaining situated, nuanced insights into a technology's
possible adoption. We offer key insights in the form of computational alternatives
vignettes -- grounded stories that encapsulate sociotechnical implications of technology,
pointing to plausible alternative futures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {third places, library events, place-centric, computational alternatives, knowledge sharing, public libraries},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376598,
author = {Troiano, Giovanni Maria and Wood, Matthew and Harteveld, Casper},
title = {"And This, Kids, Is How I Met Your Mother": Consumerist, Mundane, and Uncanny Futures with Sex Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376598},
doi = {10.1145/3313831.3376598},
abstract = {Sex Robots are no longer science fiction and may soon be-come widespread. While much
discussion has developed in academia on their moral and social impact, sex robots
have yet to be examined from a critical design perspective and are under-explored
in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions
around futures with sex robots and discuss those from a critical design perspective.
Thirty five participants completed a story stem of a human encountering a sex robot
or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships
between humans and sex robots, stories that describe sex robots as highly-efficient
sex workers that (out)perform humans in routinal sex activities, and narratives that
explore sex robots as empathetic and sentient beings. Our participant-created stories
both reinforce and challenge established norms of sex robots and raise questions that
concern responsible design and ethics in HCI. Finally, we show opportunities and limitations
of using multiple-perspective story stems in SCM},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {speculative design, story completion method, research fiction, human-robot interaction, sex robots, sexual HCI, ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376599,
author = {Semertzidis, Nathan and Scary, Michaela and Andres, Josh and Dwivedi, Brahmi and Kulwe, Yutika Chandrashekhar and Zambetta, Fabio and Mueller, Florian Floyd},
title = {Neo-Noumena: Augmenting Emotion Communication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376599},
doi = {10.1145/3313831.3376599},
abstract = {The subjective experience of emotion is notoriously difficult to interpersonally communicate.
We believe that technology can challenge this notion through the design of neuroresponsive
systems for interpersonal communication. We explore this through "Neo-Noumena", a
communicative neuroresponsive system that uses brain-computer interfacing and artificial
intelligence to read one's emotional states and dynamically represent them to others
in mixed reality through two head-mounted displays. In our study five participant
pairs were given Neo-Noumena for three days, using the system freely. Measures of
emotional competence demonstrated a statistically significant increase in participants'
ability to interpersonally regulate emotions. Furthermore, participant interviews
revealed themes regarding Spatiotemporal Actualization, Objective Representation,
and Preternatural Transmission. We also suggest design strategies for future augmented
emotion communication systems. We intend that work gives guidance towards a future
in which our ability to interpersonally communicate emotion is augmented beyond traditional
experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eeg, mixed reality, emotion recognition, brain-computer interfacing, emotion communication, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376600,
author = {Di Geronimo, Linda and Braz, Larissa and Fregnan, Enrico and Palomba, Fabio and Bacchelli, Alberto},
title = {UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376600},
doi = {10.1145/3313831.3376600},
abstract = {A Dark Pattern (DP) is an interface maliciously crafted to deceive users into performing
actions they did not mean to do. In this work, we analyze Dark Patterns in 240 popular
mobile apps and conduct an online experiment with 589 users on how they perceive Dark
Patterns in such apps. The results of the analysis show that 95% of the analyzed apps
contain one or more forms of Dark Patterns and, on average, popular applications include
at least seven different types of deceiving interfaces. The online experiment shows
that most users do not recognize Dark Patterns, but can perform better in recognizing
malicious designs if informed on the issue. We discuss the impact of our work and
what measures could be applied to alleviate the issue.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {dark patterns, user experiments, ethical design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376601,
author = {Zhou, Qian and Wu, Fan and Fels, Sidney and Stavness, Ian},
title = {Closer Object Looks Smaller: Investigating the Duality of Size Perception in a Spherical Fish Tank VR Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376601},
doi = {10.1145/3313831.3376601},
abstract = {Fish Tank Virtual Reality (FTVR) displays provide compelling 3D experiences by rendering
view-dependent imagery on a 2D screen. While users perceive a 3D object in space,
they are actually looking at pixels on a 2D screen, thus, a perceptual duality exists
between the object's pixels and the 3D percept potentially interfering with the experience.
To investigate, we conducted an experiment to see whether the on-screen size of the
2D imagery affects the perceived object size in 3D space with different viewing conditions,
including stereopsis. We found that the size of on-screen imagery significantly influenced
object size perception, causing 83.3% under/overestimation of perceived size when
viewing without stereopsis and reducing to 64.7% with stereopsis. Contrary to reality,
objects look smaller when the viewer gets closer. Understanding the perceptual duality
helps us to provide accurate perception of real-world objects depicted in the virtual
environment and pave the way for 3D applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {spherical display, 3d perception, fish tank virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376602,
author = {Miniukovich, Aliaksei and Marchese, Maurizio},
title = {Relationship Between Visual Complexity and Aesthetics of Webpages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376602},
doi = {10.1145/3313831.3376602},
abstract = {Substantial HCI research investigated the relationship between webpage complexity
and aesthetics, but without a definitive conclusion. Some research showed an inverse
linear correlation, some other showed an inverted u-shaped curve, while the rest showed
no relationship at all. Such a lack of clarity complicates hypothesis formulation
and result interpretation for future research, and lowers the reliability and generalizability
of potential advice for Web design practice. We re-collected complexity and aesthetics
ratings for five datasets previously used in webpage aesthetics and complexity research.
The results were mixed, but suggested an inverse linear relationship with a weaker
u-shaped sub-component. A subsequent visual inspection of revealed several confounding
factors that may have led to the mixed results, including some webpages looking broken
or archaic. The second data collection showed that accounting for these factors generally
eliminates the u-shaped tendency of the complexity-aesthetics relationship, at least,
for a relatively homogeneous sample of English-speaking participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {graphical user interfaces, quantitative analyses, user study, visual aesthetics, web design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376603,
author = {Bardzell, Jeffrey and Freeman, Guo and Bardzell, Shaowen and Chen, Pei-Ying},
title = {Join.Love: A Sociotechnical Genealogy of the Legalization of Same-Sex Marriage},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376603},
doi = {10.1145/3313831.3376603},
abstract = {HCI researchers interested in enhancing democracy have introduced methods and technologies
that support democratic political processes, such as voting, and more broadly on empowering
people to more fully participate in an increasingly technologized world. The aspiration
for technologies to support meaningful democratic outcomes is not misplaced. In 2019,
headlines around the world announced that Taiwan had become the first Asian country
to legalize same-sex marriage, an impressive political achievement. But it was also
an impressive technical achievement, the outcome of a concerted effort to develop
responsive and impactful direct democracy platforms. We offer a sociotechnical genealogy
of the process, informed by theory of deliberative democracy. We identify three opportunities
for future HCI contributions: supporting less visible consensus-es, developing civic
journeys, and engaging in deliberative experience design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {same-sex marriage, sociotechnical ecology, citizen journeys, deliberative democracy, deliberative experience design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376604,
author = {Lilija, Klemen and Pohl, Henning and Hornb\ae{}k, Kasper},
title = {Who Put That There? Temporal Navigation of Spatial Recordings by Direct Manipulation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376604},
doi = {10.1145/3313831.3376604},
abstract = {Spatial recordings allow viewers to move within them and freely choose their viewpoint.
However, such recordings make it easy to miss events and difficult to follow moving
objects when skipping through the recording. To alleviate these problems we present
the Who Put That There system that allows users to navigate through time by directly
manipulating objects in the scene. By selecting an object, the user can navigate to
moments where the object changed. Users can also view trajectories of objects that
changed location and directly manipulate them to navigate. We evaluated the system
with a set of sensemaking questions in a think-aloud study. Participants understood
the system and found it useful for finding events of interest, while being present
and engaged in the recording.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {navigation techniques, temporal navigation, spatial recordings, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376605,
author = {Watson, Hue and Moju-Igbene, Eyitemi and Kumari, Akanksha and Das, Sauvik},
title = {"We Hold Each Other Accountable": Unpacking How Social Groups Approach Cybersecurity and Privacy Together},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376605},
doi = {10.1145/3313831.3376605},
abstract = {Digital resources are often collectively owned and shared by small social groups (e.g.,
friends sharing Netflix accounts, roommates sharing game consoles, families sharing
WhatsApp groups). Yet, little is known about (i) how these groups jointly navigate
cybersecurity and privacy (S&amp;P) decisions for shared resources, (ii) how shared experiences
influence individual S&amp;P attitudes and behaviors, and (iii) how well existing S&amp;P
controls map onto group needs. We conducted group interviews and a supplemental diary
study with nine social groups (n=34) of varying relationship types. We identified
why, how and what resources groups shared, their jointly construed threat models,
and how these factors influenced group strategies for securing shared resources. We
also identified missed opportunities for cooperation and stewardship among group members
that could have led to improved S&amp;P behaviors, and found that existing S&amp;P controls
often fail to meet the needs of these small social groups.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {privacy, interviews, security, groups, qualitative methods, social cybersecurity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376606,
author = {Tanenbaum, Theresa Jean and Hartoonian, Nazely and Bryan, Jeffrey},
title = {"How Do I Make This Thing Smile?": An Inventory of Expressive Nonverbal Communication in Commercial Social Virtual Reality Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376606},
doi = {10.1145/3313831.3376606},
abstract = {Despite the proliferation of platforms for social Virtual Reality (VR) communicating
emotional expression via an avatar remains a significant design challenge. In order
to better understand the design space for expressive Nonverbal Communication (NVC)
in social VR we undertook an inventory of the ten most prominent social VR platforms.
Our inventory identifies the dominant design strategies for movement, facial control,
and gesture in commercial VR applications, and identifies opportunities and challenges
for future design and research into social expression in VR. Specifically, we highlight
the paucity of interaction paradigms for facial expression and the near nonexistence
of meaningful control over ambient aspects of nonverbal communication such as posture,
pose, and social status.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {nonverbal communication, virtual reality, social interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376607,
author = {Foong, Pin Sym and Lim, Charis Anne and Wong, Joshua and Lim, Chang Siang and Perrault, Simon Tangi and Koh, Gerald CH},
title = {"You Cannot Offer Such a Suggestion": Designing for Family Caregiver Input in Home Care Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376607},
doi = {10.1145/3313831.3376607},
abstract = {Previous work has looked closely at the challenges of using patient-generated data
to enable remote assessment and monitoring by healthcare professionals. In this paper,
we examine family caregivers who act as proxies for patients who may not have the
capacity of capturing the necessary data. We worked with occupational therapists to
develop an application for remote assessment of the safety of patients' homes by occupational
therapists with the assistance of family caregivers. We evaluated the application
with family caregivers and found two features unique to communication between family
caregivers and healthcare professionals: Caregivers want to be able to direct healthcare
professionals' attention to support problem-solving at home, and they include their
perspective on how to best meet the patient's health needs. We discuss the importance
of these findings for home systems in the domain of long-term chronic care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chronic care, healthcare, informatics, caregivers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376608,
author = {Alshehri, Taghreed and Kirkham, Reuben and Olivier, Patrick},
title = {Scenario Co-Creation Cards: A Culturally Sensitive Tool for Eliciting Values},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376608},
doi = {10.1145/3313831.3376608},
abstract = {Values are an integral part of human identity and have a pervasive impact upon human
behavior. This makes understanding them a central concern in the design of technology,
as exemplified by approaches such as Value Sensitive Design ("VSD"). Identifying and
concreting the values held by a given population can be a difficult endeavor, especially
where there is a cultural barrier limiting an effective discussion of them, for example
in societies where freedom of expression is discouraged. Addressing this concern requires
an in-depth consideration of appropriate value elicitation methods, which responds
to the fact that it is not possible to understand values detached from their cultural
context. We introduce a novel implicit method, Scenario Co-Creation Cards, and show
how it can be used to incorporate existing models of culture in the value elicitation
process. We demonstrate this in a case study of Saudi women's visibility in the digital
media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {vsd, values, value elicitation, method, saudi arabia, scenarios, cards, user research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376609,
author = {Lee, Sung-Chul and Song, Jaeyoon and Ko, Eun-Young and Park, Seongho and Kim, Jihee and Kim, Juho},
title = {SolutionChat: Real-Time Moderator Support for Chat-Based Structured Discussion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376609},
doi = {10.1145/3313831.3376609},
abstract = {Online chat is an emerging channel for discussing community problems. It is common
practice for communities to assign dedicated moderators to maintain a structured discussion
and enhance the problem-solving experience. However, due to the synchronous nature
of online chat, moderators face a high managerial overhead in tasks like discussion
stage management, opinion summarization, and consensus-building support. To assist
moderators with facilitating a structured discussion for community problem-solving,
we introduce SolutionChat, a system that (1) visualizes discussion stages and featured
opinions and (2) recommends contextually appropriate moderator messages. Results from
a controlled lab study (n=55, 12 groups) suggest that participants' perceived discussion
trackability was significantly higher with SolutionChat than without. Also, moderators
provided better summarization with less effort and better managerial support using
system-generated messages with SolutionChat than without. With SolutionChat, we envision
untrained moderators to effectively facilitate chat-based discussions of important
community matters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online discussion, moderator, computer mediated communication, structured discussion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376610,
author = {Jiang, Yue and Stuerzlinger, Wolfgang and Zwicker, Matthias and Lutteroth, Christof},
title = {ORCSolver: An Efficient Solver for Adaptive GUI Layout with OR-Constraints},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376610},
doi = {10.1145/3313831.3376610},
abstract = {OR-constrained (ORC) graphical user interface layouts unify conventional constraint-based
layouts with flow layouts, which enables the definition of flexible layouts that adapt
to screens with different sizes, orientations, or aspect ratios with only a single
layout specification. Unfortunately, solving ORC layouts with current solvers is time-consuming
and the needed time increases exponentially with the number of widgets and constraints.
To address this challenge, we propose ORCSolver, a novel solving technique for adaptive
ORC layouts, based on a branch-and-bound approach with heuristic preprocessing. We
demonstrate that ORCSolver simplifies ORC specifications at runtime and our approach
can solve ORC layout specifications efficiently at near-interactive rates.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {constraint-based layout, visual interface design, visual programming, layout manager, optimization, gui builder},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376611,
author = {Jeong, Rebecca and Chiasson, Sonia},
title = { 'Lime', 'Open Lock', and 'Blocked': Children's Perception of Colors, Symbols, and Words in Cybersecurity Warnings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376611},
doi = {10.1145/3313831.3376611},
abstract = {Cybersecurity warnings are frequently ignored or misinterpreted by even experienced
adults. While studies have been conducted to examine warning design for adults, there
is little data to establish recommendations for children. We conducted user studies
with 22 children (ages 10-12) and with 22 adults. We compare their risk perception
of warning design parameters (signal colors, symbols, words) via card sorting and
ranking activities followed by interviews. While our findings suggest similarities
in how both groups interpret the design parameters (e.g., red, skull, and fatal convey
danger), we also uncovered potential concerns with items currently used as security
indicators (e.g., both groups had mixed interpretations of the open lock and police
officer symbols). Individual risk perception, particularly for children, appears dependent
on personal preferences and experience. Our findings suggest implications and future
research directions for the design of cybersecurity warnings for children.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {risk perception, cybersecurity warnings, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376612,
author = {Lu, Zhicong and Jiang, Yue and Lu, Cheng and Naaman, Mor and Wigdor, Daniel},
title = {The Government's Dividend: Complex Perceptions of Social Media Misinformation in China},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376612},
doi = {10.1145/3313831.3376612},
abstract = {The social media environment in China has become the dominant source of information
and news over the past decade. This news environment has naturally suffered from challenges
related to mis- and dis-information, encumbered by an increasingly complex landscape
of factors and players including social media services, fact-checkers, censorship
policies, and astroturfing. Interviews with 44 Chinese WeChat users were conducted
to understand how individuals perceive misinformation and how it impacts their news
consumption practices. Overall, this work exposes the diverse attitudes and coping
strategies that Chinese users employ in complex social media environments. Due to
the complex nature of censorship in China and participants' lack of understanding
of censor-ship, they expressed varied opinions about its influence on the credibility
of online information sources. Further, although most participants claimed that their
opinions would not be easily swayed by astroturfers, many admitted that they could
not effectively distinguish astroturfers from ordinary Internet users. Participants'
inability to make sense of comments found online lead many participants to hold pro-censorship
attitudes: the Government's Dividend.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {trust, social media, fake news, astroturfing, misinformation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376613,
author = {Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim},
title = {Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376613},
doi = {10.1145/3313831.3376613},
abstract = {We present Embodied Axes, a controller which supports selection operations for 3D
imagery and data visualisations in Augmented Reality. The device is an embodied representation
of a 3D data space -- each of its three orthogonal arms corresponds to a data axis
or domain specific frame of reference. Each axis is composed of a pair of tangible,
actuated range sliders for precise data selection, and rotary encoding knobs for additional
parameter tuning or menu navigation. The motor actuated sliders support alignment
to positions of significant values within the data, or coordination with other input:
e.g., mid-air gestures in the data space, touch gestures on the surface below the
data, or another Embodied Axes device supporting multi-user scenarios. We conducted
expert enquiries in medical imaging which provided formative feedback on domain tasks
and refinements to the design. Additionally, a controlled user study was performed
and found that the Embodied Axes was overall more accurate than conventional tracked
controllers for selection tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {actuation, tangible interaction, 3d visualisation, augmented reality, device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376614,
author = {Lin, Chuan-en and Cheng, Ta Ying and Ma, Xiaojuan},
title = {ARchitect: Building Interactive Virtual Experiences from Physical Affordances by Bringing Human-in-the-Loop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376614},
doi = {10.1145/3313831.3376614},
abstract = {Automatic generation of Virtual Reality (VR) worlds which adapt to physical environments
have been proposed to enable safe walking in VR. However, such techniques mainly focus
on the avoidance of physical objects as obstacles and overlook their interaction affordances
as passive haptics. Current VR experiences involving interaction with physical objects
in surroundings still require verbal instruction from an assisting partner. We present
ARchitect, a proof-of-concept prototype that allows flexible customization of a VR
experience with human-in-the-loop. ARchitect brings in an assistant to map physical
objects to virtual proxies of matching affordances using Augmented Reality (AR). In
a within-subjects study (9 user pairs) comparing ARchitect to a baseline condition,
assistants and players experienced decreased workload and players showed increased
VR presence and trust in the assistant. Finally, we defined design guidelines of ARchitect
for future designers and implemented three demonstrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {affordance, architect, virtual reality, asymmetric, passive haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376615,
author = {Abdul, Ashraf and von der Weth, Christian and Kankanhalli, Mohan and Lim, Brian Y.},
title = {COGAM: Measuring and Moderating Cognitive Load in Machine Learning Model Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376615},
doi = {10.1145/3313831.3376615},
abstract = {Interpretable machine learning models trade -off accuracy for simplicity to make explanations
more readable and easier to comprehend. Drawing from cognitive psychology theories
in graph comprehension, we formalize readability as visual cognitive chunks to measure
and moderate the cognitive load in explanation visualizations. We present Cognitive-GAM
(COGAM) to generate explanations with desired cognitive load and accuracy by combining
the expressive nonlinear generalized additive models (GAM) with simpler sparse linear
models. We calibrated visual cognitive chunks with reading time in a user study, characterized
the trade-off between cognitive load and accuracy for four datasets in simulation
studies, and evaluated COGAM against baselines with users. We found that COGAM can
decrease cognitive load without decreasing accuracy and/or increase accuracy without
increasing cognitive load. Our framework and empirical measurement instruments for
cognitive load will enable more rigorous assessment of the human interpretability
of explainable AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {explainable artificial intelligence, generalized additive models, cognitive load, explanations, visual explanations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376616,
author = {Luo, Yuhan and Lee, Bongshin and Choe, Eun Kyoung},
title = {TandemTrack: Shaping Consistent Exercise Experience by Complementing a Mobile App with a Smart Speaker},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376616},
doi = {10.1145/3313831.3376616},
abstract = {Smart speakers such as Amazon Echo present promising opportunities for exploring voice
interaction in the domain of in-home exercise tracking. In this work, we examine if
and how voice interaction complements and augments a mobile app in promoting consistent
exercise. We designed and developed TandemTrack, which combines a mobile app and an
Alexa skill to support exercise regimen, data capture, feedback, and reminder. We
then conducted a four-week between-subjects study deploying TandemTrack to 22 participants
who were instructed to follow a short daily exercise regimen: one group used only
the mobile app and the other group used both the app and the skill. We collected rich
data on individuals' exercise adherence and performance, and their use of voice and
visual interactions, while examining how TandemTrack as a whole influenced their exercise
experience. Reflecting on these data, we discuss the benefits and challenges of incorporating
voice interaction to assist daily exercise, and implications for designing effective
multimodal systems to support self-tracking and promote consistent exercise.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {field deployment study, smart speaker, multimodal interaction, exercise, self-tracking, mobile app},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376617,
author = {Zhu, Junyi and Blumberg, Lotta-Gili and Zhu, Yunyi and Nisser, Martin and Carlson, Ethan Levi and Wen, Xin and Shum, Kevin and Quaye, Jessica Ayeley and Mueller, Stefanie},
title = {CurveBoards: Integrating Breadboards into Physical Objects to Prototype Function in the Context of Form},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376617},
doi = {10.1145/3313831.3376617},
abstract = {CurveBoards are breadboards integrated into physical objects. In contrast to traditional
breadboards, CurveBoards better preserve the object's look and feel while maintaining
high circuit fluidity, which enables designers to exchange and reposition components
during design iteration. Since CurveBoards are fully functional, i.e., the screens
are displaying content and the buttons take user input, designers can test interactive
scenarios and log interaction data on the physical prototype while still being able
to make changes to the component layout and circuit design as needed. We present an
interactive editor that enables users to convert 3D models into CurveBoards and discuss
our fabrication technique for making CurveBoard prototypes. We also provide a technical
evaluation of CurveBoard's conductivity and durability and summarize informal user
feedback.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {breadboards, electronic prototyping, personal fabrication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376618,
author = {Zhao, Nanxuan and Kim, Nam Wook and Herman, Laura Mariah and Pfister, Hanspeter and Lau, Rynson W.H. and Echevarria, Jose and Bylinskii, Zoya},
title = {ICONATE: Automatic Compound Icon Generation and Ideation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376618},
doi = {10.1145/3313831.3376618},
abstract = {Compound icons are prevalent on signs, webpages, and infographics, effectively conveying
complex and abstract concepts, such as "no smoking" and "health insurance", with simple
graphical representations. However, designing such icons requires experience and creativity,
in order to efficiently navigate the semantics, space, and style features of icons.
In this paper, we aim to automate the process of generating icons given compound concepts,
to facilitate rapid compound icon creation and ideation. Informed by ethnographic
interviews with professional icon designers, we have developed ICONATE, a novel system
that automatically generates compound icons based on textual queries and allows users
to explore and customize the generated icons. At the core of ICONATE is a computational
pipeline that automatically finds commonly used icons for sub-concepts and arranges
them according to inferred conventions. To enable the pipeline, we collected a new
dataset, Compicon1k, consisting of 1000 compound icons annotated with semantic labels
(i.e., concepts). Through user studies, we have demonstrated that our tool is able
to automate or accelerate the compound icon design process for both novices and professionals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {compound icon, pictogram, ideogram, icon design, graphic design, design tools},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376619,
author = {Kim, Jinsoo and Oh, Seungjae and Park, Chaeyong and Choi, Seungmoon},
title = {Body-Penetrating Tactile Phantom Sensations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376619},
doi = {10.1145/3313831.3376619},
abstract = {In tactile interaction, a phantom sensation refers to an illusion felt on the skin
between two distant points at which vibrations are applied. It can improve the perceptual
spatial resolution of tactile stimulation with a few tactors. All phantom sensations
reported in the literature act on the skin or out of the body, but no such reports
exist for those eliciting sensations penetrating the body. This paper addresses tactile
phantom sensations in which two vibration actuators on the dorsal and palmar sides
of the hand present an illusion of vibration passing through the hand. We also demonstrate
similar tactile illusions for the torso. For optimal design, we conducted user studies
while varying vibration frequency, envelope function, stimulus duration, and penetrating
direction. Based on the results, we present design guidelines on penetrating phantom
sensations for its use in immersive virtual reality applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {penetrating tactile sensation, vibrotactile feedback, tactile illusion, phantom sensation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376620,
author = {Waern, Annika and Rajkowska, Paulina and Johansson, Karin B. and Bac, Jon and Spence, Jocelyn and L\o{}vlie, Anders Sundnes},
title = {Sensitizing Scenarios: Sensitizing Designer Teams to Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376620},
doi = {10.1145/3313831.3376620},
abstract = {Concepts and theories that emerge within the social sciences tend to be nuanced, dealing
with complex social phenomena. While their relevance to design could be high, it is
difficult to make sense of them in design projects, especially when participants have
a variety of backgrounds. We report on our experiences using role-play scenarios as
a way to sensitize heterogeneous designer teams to complex theoretical concepts related
to museology as social and cultural phenomena. We discuss design requirements on such
scenarios, and the importance of connecting their execution closely to the context
of the design and the current stage of the design process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {role-play, social science theory, sensitizing concepts, sensitizing designers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376621,
author = {Yildirim, Nur and McCann, James and Zimmerman, John},
title = {Digital Fabrication Tools at Work: Probing Professionals' Current Needs and Desired Futures},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376621},
doi = {10.1145/3313831.3376621},
abstract = {Digital fabrication tools have transformed how people work in micro- and small-scale
manufacturing settings. While increasing efficiency and precision, these tools raise
concerns around user agency and control. This paper describes an exploratory study
investigating the felt work experience and desired futures of professionals who use
fabrication tools. We conducted co-design workshops with 23 professionals who use
3D printers, laser cutters, and CNC routers. We probed about current practices; machine
awareness and autonomy; and user agency. Our findings reveal that current tools are
not very professional. They are unreliable and untrustworthy. Participants desired
smarter tools that can actively prevent errors and perform self-calibration and self-maintenance.
They had few concerns that more intelligence would impact agency. They desired tools
that could negotiate trade-offs between time, cost, and quality; and that can operate
as super-human shop assistants. We discuss the implications of these findings as opportunities
for research that can improve professionals' work experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {laser cutting, cnc, digital fabrication, intelligent systems, user experience, co-design, 3d printing, future of work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376622,
author = {Mentis, Helena M. and Feng, Yuanyuan and Semsar, Azin and Ponsky, Todd A.},
title = {Remotely Shaping the View in Surgical Telementoring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376622},
doi = {10.1145/3313831.3376622},
abstract = {Distributed collaboration on physical tasks is a social process that involves all
actors iteratively proposing, assessing and modifying the view of a shared workspace.
In this paper, we describe the ways in which a view of a shared workspace is shaped
by a remote expert to weave their expertise into the accomplishment of a complex physical
task during surgical telementoring. We focus on the communicative functions of talk
and actions used by the remote experts and local workers and identify strategies the
experts employ to remotely shape the view. This analysis reveals the possibility for
collaborative shaping of a view in surgical telementoring as well as other mechanism
for a remote expert to craft and present a view of the shared workspace.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {instruction, video, distributed, surgery training, tele-conferencing, telestration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376623,
author = {Marcu, Gabriela and Spiller, Allison N.},
title = {Collaborative Aspects of Collecting and Reflecting on Behavioral Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376623},
doi = {10.1145/3313831.3376623},
abstract = {Direct observation of behavior provides a unique type of data for reflecting on during
a process of behavioral intervention. This study focuses on practitioners who specialize
in operationalizing, recording, and monitoring behavior using data collection through
paper-and-pencil or, increasingly, mobile computing. Applying an action research approach,
we conducted fieldwork to understand observational data collection among practitioners
providing children with special education support for behavioral needs. We present
a model of collaborative data collection, which describes how practices are situated
in the process of collecting data that are useful for reflection by teams of practitioners.
We discuss how computer-assisted data collection could promote more systematic and
rigorous practices, and design considerations for the collaborative aspects of collecting
and reflecting on behavioral data. This study builds on research describing the practices
of individuals who track their own behavioral data, and improves our understanding
of informal documentation practices in organizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {computer-assisted data collection, behavioral intervention, action research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}


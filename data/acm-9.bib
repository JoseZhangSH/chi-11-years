@inproceedings{10.1145/2858036.2858222,
author = {Alan, Alper T. and Shann, Mike and Costanza, Enrico and Ramchurn, Sarvapali D. and Seuken, Sven},
title = {It is Too Hot: An In-Situ Study of Three Designs for Heating},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858222},
doi = {10.1145/2858036.2858222},
abstract = {Smart energy systems that leverage machine learning techniques are increasingly integrated
in all aspects of our lives. To better understand how to design user interaction with
such systems, we implemented three different smart thermostats that automate heating
based on users' heating preferences and real-time price variations. We evaluated our
designs through a field study, where 30 UK households used our thermostats to heat
their homes over a month. Our findings through thematic analysis show that the participants
formed different understandings and expectations of our smart thermostat, and used
it in various ways to effectively respond to real-time prices while maintaining their
thermal comfort. Based on the findings, we present a number of design and research
implications, specifically for designing future smart thermostats that will assist
us in controlling home heating with real-time pricing, and for future intelligent
autonomous systems.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5262–5273},
numpages = {12},
keywords = {smart grid, heating, design, real-time pricing, field study},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858261,
author = {Desjardins, Audrey and Wakkary, Ron},
title = {Living In A Prototype: A Reconfigured Space},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858261},
doi = {10.1145/2858036.2858261},
abstract = {In this paper, we present a twenty-three months autobiographical design project of
converting a Mercedes Sprinter van into a camper van. This project allows us to investigate
the complexities and nuances of a case where people engage in a process of making,
transforming and adapting a space they live in. This example opens a radically different
and productive context for revisiting concepts that are currently at the center of
human-computer interaction (HCI) research: ubiquitous computing, home automation,
smart homes, and the Internet of Things. We offer six qualities characterizing the
evolving relationship between the makers and the lived-in environment: the van. We
conclude with a discussion on the two themes of living in a reconfigured home and
prototype qualities in a reconfigured space, and a critical reflection around the
theme of the invariably unfinished home.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5274–5285},
numpages = {12},
keywords = {lived-with, iot, everyday design, making, autobiographical design, smart home, maker, DIY},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858288,
author = {Luger, Ewa and Sellen, Abigail},
title = {"Like Having a Really Bad PA": The Gulf between User Expectation and Experience of Conversational Agents},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858288},
doi = {10.1145/2858036.2858288},
abstract = {The past four years have seen the rise of conversational agents (CAs) in everyday
life. Apple, Microsoft, Amazon, Google and Facebook have all embedded proprietary
CAs within their software and, increasingly, conversation is becoming a key mode of
human-computer interaction. Whilst we have long been familiar with the notion of computers
that speak, the investigative concern within HCI has been upon multimodality rather
than dialogue alone, and there is no sense of how such interfaces are used in everyday
life. This paper reports the findings of interviews with 14 users of CAs in an effort
to understand the current interactional factors affecting everyday use. We find user
expectations dramatically out of step with the operation of the systems, particularly
in terms of known machine intelligence, system capability and goals. Using Norman's 'gulfs of execution and evaluation' [30] we consider the implications of these findings
for the design of future systems.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5286–5297},
numpages = {12},
keywords = {evaluation, mental models, conversational agents},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858208,
author = {Bailly, Gilles and Sahdev, Sidharth and Malacria, Sylvain and Pietrzak, Thomas},
title = {LivingDesktop: Augmenting Desktop Workstation with Actuated Devices},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858208},
doi = {10.1145/2858036.2858208},
abstract = {We investigate the potential benefits of actuated devices for the desktop workstation
which remains the most used environment for daily office works. A formative study
reveals that the desktop workstation is not a fixed environment because users manually
change the position and the orientation of their devices. Based on these findings,
we present the LivingDesktop, an augmented desktop workstation with devices (mouse,
keyboard, monitor) capable of moving autonomously. We describe interaction techniques
and applications illustrating how actuated desktop workstations can improve ergonomics,
foster collaboration, leverage context and reinforce physicality. Finally, the findings
of a scenario evaluation are (1) the perceived usefulness of ergonomics and collaboration
applications; (2) how the LivingDesktop inspired our participants to elaborate novel
accessibility and social applications; (3) the location and user practices should
be considered when designed actuated desktop devices.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5298–5310},
numpages = {13},
keywords = {desktop workstation, augmented desktop, mouse, actuated devices, keyboard, monitor},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858260,
author = {Piper, Anne Marie and Cornejo, Raymundo and Hurwitz, Lisa and Unumb, Caitlin},
title = {Technological Caregiving: Supporting Online Activity for Adults with Cognitive Impairments},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858260},
doi = {10.1145/2858036.2858260},
abstract = {With much of the population now online, the field of HCI faces new and pressing issues
of how to help people sustain online activity throughout their lives, including through
periods of disability. The onset of cognitive impairment later in life affects whether
and how individuals are able to stay connected online and manage their digital information.
While caregivers play a critical role in the offline lives of adults with cognitive
impairments, less is known about how they support and enable online interaction. Using
a constructivist grounded theory approach, data from focus groups with caregivers
of adults with cognitive impairments reveal four forms of cooperative work caregivers
perform in the context of supporting online activity. We find that staying active
online is a way of empowering and engaging adults with cognitive impairments, yet
this introduces new forms of risk, surrogacy, and cooperative technology use to the
already demanding work of caregiving.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5311–5323},
numpages = {13},
keywords = {vulnerable populations, social computing, caregiving},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858240,
author = {Pollack, Ari H. and Backonja, Uba and Miller, Andrew D. and Mishra, Sonali R. and Khelifi, Maher and Kendall, Logan and Pratt, Wanda},
title = {Closing the Gap: Supporting Patients' Transition to Self-Management after Hospitalization},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858240},
doi = {10.1145/2858036.2858240},
abstract = {Patients going home after a hospitalization face many challenges. This transition
period exposes patients to unnecessary risks related to inadequate preparation prior
to leaving the hospital, potentially leading to errors and patient harm. Although
patients engaging in self-management have better health outcomes and increased self-efficacy,
little is known about the processes in place to support and develop these skills for
patients leaving the hospital. Through qualitative interviews and observations of
28 patients during and after their hospitalizations, we explore the challenges they
face transitioning from hospital care to self-management. We identify three key elements
in this process: knowledge, resources, and self-efficacy. We describe how both system
and individual factors contribute to breakdowns leading to ineffective patient management.
This work expands our understanding of the unique challenges faced by patients during
this difficult transition and uncovers important design opportunities for supporting
crucial yet unmet patient needs.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5324–5336},
numpages = {13},
keywords = {self-efficacy, pediatric, self-management, medical informatics, hospital, discharge, health informatics},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858508,
author = {Hong, Matthew K. and Wilcox, Lauren and Machado, Daniel and Olson, Thomas A. and Simoneaux, Stephen F.},
title = {Care Partnerships: Toward Technology to Support Teens' Participation in Their Health Care},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858508},
doi = {10.1145/2858036.2858508},
abstract = {Adolescents with complex chronic illnesses, such as cancer and blood disorders, must
partner with family and clinical caregivers to navigate risky procedures with life-altering
implications, burdensome symptoms and lifelong treatments. Yet, there has been little
investigation into how technology can support these partnerships. We conducted 38
in-depth interviews (15 with teenage adolescents with chronic forms of cancer and
blood disorders, 15 with their parents, and eight with clinical caregivers) along
with nine non-participant observations of clinical consultations, to better understand
common challenges and needs that could be supported through design. Participants faced
challenges primarily concerning: 1) teens' limited participation in their care, 2)
communicating emotionally-sensitive information, and 3) managing physical and emotional
responses. We draw on these findings to propose design goals for sociotechnical systems
to support teens in partnering in their care, highlighting the need for design to
support gradually-evolving partnerships.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5337–5349},
numpages = {13},
keywords = {adolescents, personal health, chronic illnesses, self-management, health information management, families},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858523,
author = {Zhang, Xiang and Brown, Hans-Frederick and Shankar, Anil},
title = {Data-Driven Personas: Constructing Archetypal Users with Clickstreams and User Telemetry},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858523},
doi = {10.1145/2858036.2858523},
abstract = {User Experience (UX) research teams following a user centered design approach harness
personas to better understand a user's workflow by examining that user's behavior,
goals, needs, wants, and frustrations. To create target personas these researchers
rely on workflow data from surveys, self-reports, interviews, and user observation.
However, this data not directly related to user behavior, weakly reflects a user's
actual workflow in the product, is costly to collect, is limited to a few hundred
responses, and is outdated as soon as a persona's workflows evolve. To address these
limitations we present a quantitative bottom-up data-driven approach to create personas.
First, we directly incorporate user behavior via clicks gathered automatically from
telemetry data related to the actual product use in the field; since the data collection
is automatic it is also cost effective. Next, we aggregate 3.5 million clicks from
2400 users into 39,000 clickstreams and then structure them into 10 workflows via
hierarchical clustering; we thus base our personas on a large data sample. Finally,
we use mixed models, a statistical approach that incorporates these clustered workflows
to create five representative personas; updating our mixed model ensures that these
personas remain current. We also validated these personas with our product's user
behavior experts to ensure that workflows and the persona goals represent actual product
use.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5350–5359},
numpages = {10},
keywords = {personas, data science, user experience research, user analytics, machine learning, data-driven design},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858368,
author = {Hogan, Bernie and Melville, Joshua R. and Phillips II, Gregory Lee and Janulis, Patrick and Contractor, Noshir and Mustanski, Brian S. and Birkett, Michelle},
title = {Evaluating the Paper-to-Screen Translation of Participant-Aided Sociograms with High-Risk Participants},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858368},
doi = {10.1145/2858036.2858368},
abstract = {While much social network data exists online, key network metrics for high-risk populations
must still be captured through self-report. This practice has suffered from numerous
limitations in workflow and response burden. However, advances in technology, network
drawing libraries and databases are making interactive network drawing increasingly
feasible. We describe the translation of an analog-based technique for capturing personal
networks into a digital framework termed netCanvas that addresses many existing shortcomings
such as: 1) complex data entry; 2) extensive interviewer intervention and field setup;
3) difficulties in data reuse; and 4) a lack of dynamic visualizations. We test this
implementation within a health behavior study of a high-risk and difficult-to-reach
population. We provide a within--subjects comparison between paper and touchscreens.
We assert that touchscreen-based social network capture is now a viable alternative
for highly sensitive data and social network data entry tasks.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5360–5371},
numpages = {12},
keywords = {social networks, participant-aided sociograms},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858388,
author = {Yuksel, Beste F. and Oleson, Kurt B. and Harrison, Lane and Peck, Evan M. and Afergan, Daniel and Chang, Remco and Jacob, Robert JK},
title = {Learn Piano with BACh: An Adaptive Learning Interface That Adjusts Task Difficulty Based on Brain State},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858388},
doi = {10.1145/2858036.2858388},
abstract = {We present Brain Automated Chorales (BACh), an adaptive brain-computer system that
dynamically increases the levels of difficulty in a musical learning task based on
pianists' cognitive workload measured by functional near-infrared spectroscopy. As
users' cognitive workload fell below a certain threshold, suggesting that they had
mastered the material and could handle more cognitive information, BACh automatically
increased the difficulty of the learning task. We found that learners played with
significantly increased accuracy and speed in the brain-based adaptive task compared
to our control condition. Participant feedback indicated that they felt they learned
better with BACh and they liked the timings of the level changes. The underlying premise
of BACh can be applied to learning situations where a task can be broken down into
increasing levels of difficulty.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5372–5384},
numpages = {13},
keywords = {adaptive, piano, learning, brain-computer interface (BCI), cognitive workload, music, functional near infrared spectroscopy (FNIRS)},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858276,
author = {Pike, Matthew and Ramchurn, Richard and Benford, Steve and Wilson, Max L.},
title = {#Scanners: Exploring the Control of Adaptive Films Using Brain-Computer Interaction},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858276},
doi = {10.1145/2858036.2858276},
abstract = {This paper explores the design space of bio-responsive entertainment, in this case
using a film that responds to the brain and blink data of users. A film was created
with four parallel channels of footage, where blinking and levels of attention and
meditation, as recorded by a commercially available EEG device, affected which footage
participants saw. As a performance-led piece of research in the wild, this experience,
named #Scanners, was presented at a week long national exhibition in the UK. We examined
the experiences of 35 viewers, and found that these forms of partially-involuntary
control created engaging and enjoyable, but sometimes distracting, experiences. We
translate our findings into a two-dimensional design space between the extent of voluntary
control that a physiological measure can provide against the level of conscious awareness
that the user has of that control. This highlights that novel design opportunities
exist when deviating from these two-dimensions - when giving up conscious control
and when abstracting the affect of control. Reflection on of how viewers negotiated
this space during an experience reveals novel design tactics.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5385–5396},
numpages = {12},
keywords = {control, interactive multimedia, BCI, TV &amp; film},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858577,
author = {Xiao, Xiao and Ishii, Hiroshi},
title = {Inspect, Embody, Invent: A Design Framework for Music Learning and Beyond},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858577},
doi = {10.1145/2858036.2858577},
abstract = {This paper introduces a new framework to guide the design of interactive music learning
systems, focusing on the piano. Taking a Reflective approach, we identify the implicit
assumption behind most existing systems-that learning music is learning to play correctly
according to the score-and offer an alternative approach. We argue that systems should
help cultivate higher levels of musicianship beyond correctness alone for students
of all levels. Drawing from both pedagogical literature and the personal experience
of learning to play the piano, we identify three skills central to musicianship-listening,
embodied understanding, and creative imagination-which we generalize to the Inspect,
Embody, Invent framework. To demonstrate how this framework translates to design,
we discuss two existing interfaces from our own research-MirrorFugue and Andante-both
built on a digitally controlled player piano augmented by in-situ projection. Finally,
we discuss the framework's relevance toward bigger themes of embodied interactions
and learning beyond the domain of music.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5397–5408},
numpages = {12},
keywords = {reflexive design, embodied interaction, auto-ethnography, learning interfaces, digital arts, music learning, musical expression, reflective design, piano},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858150,
author = {Badam, Sriram Karthik and Zhao, Jieqiong and Sen, Shivalik and Elmqvist, Niklas and Ebert, David},
title = {TimeFork: Interactive Prediction of Time Series},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858150},
doi = {10.1145/2858036.2858150},
abstract = {We present TimeFork, an interactive prediction technique to support users predicting
the future of time-series data, such as in financial, scientific, or medical domains.
TimeFork combines visual representations of multiple time series with prediction information
generated by computational models. Using this method, analysts engage in a back-and-forth
dialogue with the computational model by alternating between manually predicting future
changes through interaction and letting the model automatically determine the most
likely outcomes, to eventually come to a common prediction using the model. This computer-supported
prediction approach allows for harnessing the user's knowledge of factors influencing
future behavior, as well as sophisticated computational models drawing on past performance.
To validate the TimeFork technique, we conducted a user study in a stock market prediction
game. We present evidence of improved performance for participants using TimeFork
compared to fully manual or fully automatic predictions, and characterize qualitative
usage patterns observed during the user study.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5409–5420},
numpages = {12},
keywords = {time series, user study, human-in-the-loop, visual analytics, visual prediction},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858063,
author = {Matejka, Justin and Glueck, Michael and Grossman, Tovi and Fitzmaurice, George},
title = {The Effect of Visual Appearance on the Performance of Continuous Sliders and Visual Analogue Scales},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858063},
doi = {10.1145/2858036.2858063},
abstract = {Sliders and Visual Analogue Scales (VASs) are input mechanisms which allow users to
specify a value within a predefined range. At a minimum, sliders and VASs typically
consist of a line with the extreme values labeled. Additional decorations such as
labels and tick marks can be added to give information about the gradations along
the scale and allow for more precise and repeatable selections. There is a rich history
of research about the effect of labelling in discrete scales (i.e., Likert scales),
however the effect of decorations on continuous scales has not been rigorously explored.
In this paper we perform a 2,000 user, 250,000 trial online experiment to study the
effects of slider appearance, and find that decorations along the slider considerably
bias the distribution of responses received. Using two separate experimental tasks,
the trade-offs between bias, accuracy, and speed-of-use are explored and design recommendations
for optimal slider implementations are proposed.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5421–5432},
numpages = {12},
keywords = {visual analogue scales, slider, tick marks, crowdsourced study},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858408,
author = {Battle, Leilani and Fisher, Danyel and DeLine, Robert and Barnett, Mike and Chandramouli, Badrish and Goldstein, Jonathan},
title = {Making Sense of Temporal Queries with Interactive Visualization},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858408},
doi = {10.1145/2858036.2858408},
abstract = {As real-time monitoring and analysis become increasingly important, researchers and
developers turn to data stream management systems (DSMS's) for fast, efficient ways
to pose temporal queries over their datasets. However, these systems are inherently
complex, and even database experts find it difficult to understand the behavior of
DSMS queries. To help analysts better understand these temporal queries, we developed
StreamTrace, an interactive visualization tool that breaks down how a temporal query
processes a given dataset, step-by-step. The design of StreamTrace is based on input
from expert DSMS users; we evaluated the system with a lab study of programmers who
were new to streaming queries. Results from the study demonstrate that StreamTrace
can help users to verify that queries behave as expected and to isolate the regions
of a query that may be causing unexpected results.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5433–5443},
numpages = {11},
keywords = {data visualization, data analysts, streaming data},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858300,
author = {Adnan, Muhammad and Just, Mike and Baillie, Lynne},
title = {Investigating Time Series Visualisations to Improve the User Experience},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858300},
doi = {10.1145/2858036.2858300},
abstract = {Research on graphical perception of time series visualisations has focused on visual
representation, and not on interaction. Even for visual representation, there has
been limited study of the impact on users of visual encodings and the strengths and
weaknesses of Cartesian and Polar coordinate systems. In order to address this research
gap, we performed a comprehensive graphical perception study that measured the effectiveness
of time series visualisations with different interactions, visual encodings and coordinate
systems for several tasks. Our results show that, while positional and colour visual
encodings were better for most tasks, area visual encoding performed better for data
comparison. Most importantly, we identified that introducing interactivity within
time series visualisations considerably enhances the user experience, without any
loss of efficiency or accuracy. We believe that our findings can greatly improve the
development of visual analytics tools using time series visualisations in a variety
of domains.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5444–5455},
numpages = {12},
keywords = {visual encoding, graphical perception, time series, visualization, evaluation, coordinate system, interaction technique},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858522,
author = {Pizza, Stefania and Brown, Barry and McMillan, Donald and Lampinen, Airi},
title = {Smartwatch in <i>Vivo</i>},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858522},
doi = {10.1145/2858036.2858522},
abstract = {In recent years, the smartwatch has returned as a form factor for mobile computing
with some success. Yet it is not clear how smartwatches are used and integrated into
everyday life differently from mobile phones. For this paper, we used wearable cameras
to record twelve participants' daily use of smartwatches, collecting and analysing
incidents where watches were used from over 34 days of user recording. This allows
us to analyse in detail 1009 watch uses. Using the watch as a timepiece was the most
common use, making up 50% of interactions, but only 14% of total watch usage time.
The videos also let us examine why and how smartwatches are used for activity tracking,
notifications, and in combination with smartphones. In discussion, we return to a
key question in the study of mobile devices: how are smartwatches integrated into
everyday life, in both the actions that we take and the social interactions we are
part of?},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5456–5469},
numpages = {14},
keywords = {smartwatches, wearable computing, wrist watches},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858224,
author = {Zagermann, Johannes and Pfeil, Ulrike and R\"{a}dle, Roman and Jetter, Hans-Christian and Klokmose, Clemens and Reiterer, Harald},
title = {When Tablets Meet Tabletops: The Effect of Tabletop Size on Around-the-Table Collaboration with Personal Tablets},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858224},
doi = {10.1145/2858036.2858224},
abstract = {Cross-device collaboration with tablets is an increasingly popular topic in HCI. Previous
work has shown that tablet-only collaboration can be improved by an additional shared
workspace on an interactive tabletop. However, large tabletops are costly and need
space, raising the question to what extent the physical size of shared horizontal
surfaces really pays off. In order to analyse the suitability of smaller-than-tabletop
devices (e.g. tablets) as a low-cost alternative, we studied the effect of the size
of a shared horizontal interactive workspace on users' attention, awareness, and efficiency
during cross-device collaboration. In our study, 15 groups of two users executed a
sensemaking task with two personal tablets (9.7") and a horizontal shared display
of varying sizes (10.6", 27", and 55"). Our findings show that different sizes lead
to differences in participants' interaction with the tabletop and in the groups' communication
styles. To our own surprise we found that larger tabletops do not necessarily improve
collaboration or sensemaking results, because they can divert users' attention away
from their collaborators and towards the shared display.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5470–5481},
numpages = {12},
keywords = {display size, tabletops, cross-device interaction, group work, tablets},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858382,
author = {Chi, Pei-Yu (Peggy) and Li, Yang and Hartmann, Bj\"{o}rn},
title = {Enhancing Cross-Device Interaction Scripting with Interactive Illustrations},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858382},
doi = {10.1145/2858036.2858382},
abstract = {Cross-device interactions involve input and output on multiple computing devices.
Implementing and reasoning about interactions that cover multiple devices with a diversity
of form factors and capabilities can be complex. To assist developers in programming
cross-device interactions, we created DemoScript, a technique that automatically analyzes
a cross-device interaction program while it is being written. DemoScript visually
illustrates the step-by-step execution of a selected portion or the entire program
with a novel, automatically generated cross-device storyboard visualization. In addition
to helping developers understand the behavior of the program, DemoScript also allows
developers to revise their program by interactively manipulating the cross-device
storyboard. We evaluated DemoScript with 8 professional programmers and found that
DemoScript significantly improved development efficiency by helping developers interpret
and manage cross-device interaction; it also encourages testing to think through the
script in a development process.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5482–5493},
numpages = {12},
keywords = {storyboards, interactive illustration, scripting, cross-device interaction},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858048,
author = {Nebeling, Michael and Dey, Anind K.},
title = {XDBrowser: User-Defined Cross-Device Web Page Designs},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858048},
doi = {10.1145/2858036.2858048},
abstract = {There is a significant gap in the body of research on cross-device interfaces. Research
has largely focused on enabling them technically, but when and how users want to use
cross-device interfaces is not well understood. This paper presents an exploratory
user study with XDBrowser, a cross-device web browser we are developing to enable
non-technical users to adapt existing single-device web interfaces for cross-device
use while viewing them in the browser. We demonstrate that an end-user customization
tool like XDBrowser is a powerful means to conduct user-driven elicitation studies
useful for understanding user preferences and design requirements for cross-device
interfaces. Our study with 15 participants elicited 144 desirable multi-device designs
for five popular web interfaces when using two mobile devices in parallel. We describe
the design space in this context, the usage scenarios targeted by users, the strategies
used for designing cross-device interfaces, and seven concrete mobile multi-device
design patterns that emerged. We discuss the method, compare the cross-device interfaces
from our users and those defined by developers in prior work, and establish new requirements
from observed user behavior. In particular, we identify the need to easily switch
between different interface distributions depending on the task and to have more fine-grained
control over synchronization.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5494–5505},
numpages = {12},
keywords = {cross-device web design, end-user customization study},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858116,
author = {Morris, Meredith Ringel and Zolyomi, Annuska and Yao, Catherine and Bahram, Sina and Bigham, Jeffrey P. and Kane, Shaun K.},
title = {"With Most of It Being Pictures Now, I Rarely Use It": Understanding Twitter's Evolving Accessibility to Blind Users},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858116},
doi = {10.1145/2858036.2858116},
abstract = {Social media is an increasingly important part of modern life. We investigate the
use of and usability of Twitter by blind users, via a combination of surveys of blind
Twitter users, large-scale analysis of tweets from and Twitter profiles of blind and
sighted users, and analysis of tweets containing embedded imagery. While Twitter has
traditionally been thought of as the most accessible social media platform for blind
users, Twitter's increasing integration of image content and users' diverse uses for
images have presented emergent accessibility challenges. Our findings illuminate the
importance of the ability to use social media for people who are blind, while also
highlighting the many challenges such media currently present this user base, including
difficulty in creating profiles, in awareness of available features and settings,
in controlling revelations of one's disability status, and in dealing with the increasing
pervasiveness of image-based content. We propose changes that Twitter and other social
platforms should make to promote fuller access to users with visual impairments.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5506–5516},
numpages = {11},
keywords = {blindness, accessibility, social media, twitter},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858437,
author = {Mark, Gloria and Wang, Yiran Department of Informatics and Niiya, Melissa and Reich, Stephanie},
title = {Sleep Debt in Student Life: Online Attention Focus, Facebook, and Mood},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858437},
doi = {10.1145/2858036.2858437},
abstract = {The amount of sleep college students receive has become a pressing societal concern.
While studies show that information technology (IT) use affects sleep, here we examine
the converse: how sleep duration might affect IT use. We conducted an in situ study,
and logged computer and phone use and collected sleep diaries and daily surveys of
76 college students for seven days, all waking hours. We examined effects of sleep
duration and sleep debt. Our results show that with less sleep, people report higher
perceived work pressure and productivity. Also, computer focus duration is significantly
shorter suggesting higher multitasking. The more sleep debt, the more Facebook use
and the higher the negative mood. With less sleep, people may seek out activities
requiring less attentional resources such as social media use. Our results have theoretical
implications for multitasking: physiological and cognitive reasons could explain more
computer activity switches: related to less sleep.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5517–5528},
numpages = {12},
keywords = {mobile phone, mood, facebook, in situ study, sensors, sleep, multitasking, social media, computer logging, productivity},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858379,
author = {Brewer, Robin and Piper, Anne Marie},
title = {"Tell It Like It Really Is": A Case of Online Content Creation and Sharing Among Older Adult Bloggers},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858379},
doi = {10.1145/2858036.2858379},
abstract = {While the majority of older adults are now active online, they are often perceived
as passive consumers of online information rather than active creators of content.
As a counter to this view, we examine the practices of older adult bloggers (N=20)
through in-depth interviews. We study this group of older adults as a unique case
of content creation and sharing. We find that the practice of creating and sharing
through blogging meets several important psychological and social needs for older
adults. Specifically, blogging supports the development of identity in older adulthood;
fosters self-expression that supports older adults' values; provides meaningful engagement
during retirement; and enables a sense of community and social interaction that is
important for wellbeing in late-life. We argue for a focus on designing for late-life
development and detail opportunities for online systems to better support the dynamic
experience of growing older through online content creation and sharing.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5529–5542},
numpages = {14},
keywords = {identity, older adults, blogging, creative expression},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858234,
author = {Garimella, Venkata Rama Kiran and Alfayad, Abdulrahman and Weber, Ingmar},
title = {Social Media Image Analysis for Public Health},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858234},
doi = {10.1145/2858036.2858234},
abstract = {Several projects have shown the feasibility to use emph{textual} social media data
to track public health concerns, such as temporal influenza patterns or geographical
obesity patterns. In this paper, we look at whether geo-tagged emph{images} from Instagram
also provide a viable data source. Especially for "lifestyle" diseases, such as obesity,
drinking or smoking, images of social gatherings could provide information that is
not necessarily shared in, say, tweets. In this study, we explore whether (i) tags
provided by the users and (ii) annotations obtained via automatic image tagging are
indeed valuable for studying public health. We find that both user-provided and machine-generated
tags provide information that can be used to infer a county's health statistics. Whereas
for most statistics user-provided tags are better features, for predicting excessive
drinking machine-generated tags such as "liquid' and "glass' yield better models.
This hints at the potential of using machine-generated tags to study substance abuse.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5543–5547},
numpages = {5},
keywords = {obesity, image analysis, public health, instagram, substance abuse},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858203,
author = {Reno, Corbin and Poole, Erika S.},
title = {It Matters If My Friends Stop Smoking: Social Support for Behavior Change in Social Media},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858203},
doi = {10.1145/2858036.2858203},
abstract = {A growing body of research has examined whether and how an individual can leverage
online social networks to receive social support for health behavior change. This
prior research largely focuses on attributes of the post content and the experiences
and concerns of people posting. Less is known about moderators and mediators that
influence whether and how one's social network will respond to a request for support.
Using a factorial survey experiment, we find evidence that attitudes toward specific
types of health behaviors greatly increase likelihood of response to a post, and that
targeting close-tie relationships may increase effectiveness of social media based
behavior change interventions, particularly related to smoking cessation.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5548–5552},
numpages = {5},
keywords = {social media, health behavior change},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858253,
author = {Khajah, Mohammad M. and Roads, Brett D. and Lindsey, Robert V. and Liu, Yun-En and Mozer, Michael C.},
title = {Designing Engaging Games Using Bayesian Optimization},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858253},
doi = {10.1145/2858036.2858253},
abstract = {We use Bayesian optimization methods to design games that maximize user engagement.
Participants are paid to try a game for several minutes, at which point they can quit
or continue to play voluntarily with no further compensation. Engagement is measured
by player persistence, projections of how long others will play, and a post-game survey.
Using Gaussian process surrogate-based optimization, we conduct efficient experiments
to identify game design characteristics---specifically those influencing difficulty---that
lead to maximal engagement. We study two games requiring trajectory planning, the
difficulty of each is determined by a three-dimensional continuous design space. Two
of the design dimensions manipulate the game in user-transparent manner (e.g., the
spacing of obstacles), the third in a subtle and possibly covert manner (incremental
trajectory corrections). Converging results indicate that overt difficulty manipulations
are effective in modulating engagement only when combined with the covert manipulation,
suggesting the critical role of a user's self-perception of competence.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5571–5582},
numpages = {12},
keywords = {engagement, persistence, difficulty manipulation, optimization, Gaussian processes, motivation, games},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858563,
author = {Klarkowski, Madison and Johnson, Daniel and Wyeth, Peta and McEwan, Mitchell and Phillips, Cody and Smith, Simon},
title = {Operationalising and Evaluating Sub-Optimal and Optimal Play Experiences through Challenge-Skill Manipulation},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858563},
doi = {10.1145/2858036.2858563},
abstract = {The study examines the relationship of challenge-skill balance and the player experience
through evaluation of competence, autonomy, presence, interest/enjoyment, and positive
and negative affect states. To manipulate challenge-skill balance, three video game
modes -- boredom (low challenge), balance (medium challenge), and overload (high challenge)
-- were developed and experimentally tested (n = 45). The study showed that self-reported
positive affect, autonomy, presence, and interest/enjoyment differed between the levels.
The balance condition generally performed well in terms of positive player experiences,
confirming the key role challenge-skill balance plays in designing for optimal play
experiences. Interestingly, the study found significantly lower negative affect scores
when playing the boredom condition. Greater feelings of competence were also reported
for the boredom condition than the balance and overload conditions. Finally, some
measures point to overload as a more enjoyable experience than boredom, suggesting
possible player preference for challenge &gt; skill imbalance over skill &gt; challenge
imbalance. Implications for design and future research are presented.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5583–5594},
numpages = {12},
keywords = {challenge, video games, self-determination, presence, player experience},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858574,
author = {Smeddinck, Jan D. and Mandryk, Regan L. and Birk, Max V. and Gerling, Kathrin M. and Barsilowski, Dietrich and Malaka, Rainer},
title = {How to Present Game Difficulty Choices? Exploring the Impact on Player Experience},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858574},
doi = {10.1145/2858036.2858574},
abstract = {Matching game difficulty to player ability is a crucial step toward a rewarding player
experience, yet making difficulty adjustments that are effective yet unobtrusive can
be challenging. This paper examines the impact of automatic and player-initiated difficulty
adjustment on player experience through two studies. In the first study, 40 participants
played the casual game THYFTHYF either in motion-based or sedentary mode, using menu-based,
embedded, or automatic difficulty adjustment. In the second study, we created an adapted
version of the commercially available game fl0w to allow us to carry out a more focused
study of sedentary casual play. Results from both studies demonstrate that the type
of difficulty adjustment has an impact on perceived autonomy, but other player experience
measures were not affected as expected. Our findings suggest that most players express
a preference for manual difficulty choices, but that overall game experience was not
notably impacted by automated difficulty adjustments.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5595–5607},
numpages = {13},
keywords = {dynamic difficulty adjustments, feedback, player experience, game-user research, game difficulty, flow},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858419,
author = {Gutwin, Carl and Rooke, Christianne and Cockburn, Andy and Mandryk, Regan L. and Lafreniere, Benjamin},
title = {Peak-End Effects on Player Experience in Casual Games},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858419},
doi = {10.1145/2858036.2858419},
abstract = {The peak-end rule is a psychological heuristic observing that people's retrospective
assessment of an experience is strongly influenced by the intensity of the peak and
final moments of that experience. We examine how aspects of game player experience
are influenced by peak-end manipulations to the sequence of events in games that are
otherwise objectively identical. A first experiment examines players' retrospective
assessments of two games (a pattern matching game based on Bejeweled and a point-and-click
reaction game) when the sequence of difficulty is manipulated to induce positive,
negative and neutral peak-end effects. A second experiment examines assessments of
a shootout game in which the balance between challenge and skill is similarly manipulated.
Results across the games show that recollection of challenge was strongly influenced
by peak-end effects; however, results for fun, enjoyment, and preference to repeat
were varied -- sometimes significantly in favour of the hypothesized effects, sometimes
insignificant, but never against the hypothesis.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5608–5619},
numpages = {12},
keywords = {player experience, game design, peak-end theory},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858145,
author = {Kim, Yoojung and Ji, Sookyoung and Lee, Hyunjeong and Kim, Jeong-Whun and Yoo, Sooyoung and Lee, Joongseek},
title = {"My Doctor is Keeping an Eye on Me!": Exploring the Clinical Applicability of a Mobile Food Logger},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858145},
doi = {10.1145/2858036.2858145},
abstract = {By enabling people to track their lifestyles, including activity level, sleeping,
and diet, technology helps clinicians to treat patients suffering from "lifestyle
diseases." However, despite its importance compared to other lifestyle factors, it
is not easy to record food intake consistently. Although researchers have attempted
to solve this problem, most have not considered its applicability in the clinical
context. In this paper, we aim to (1) understand food-journaling practices and (2)
explore the applicability of lifestyle data in the clinical context. By observing
20 patients who recorded data including food logs, steps, and sleeping time, we found
that patients recorded their food logs diligently, as they were conscious of clinicians.
Clinicians were surprised by the high adherence rate of journaling and tried to overlap
food data with other data, such as steps, sleeping time, etc. This paper contributes
by providing qualitative insights for designing applicable strategies utilizing lifestyle
data in the clinical context.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5620–5631},
numpages = {12},
keywords = {personal informatics, lifestyle disease, food journaling, clinical context, self-tracking},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858044,
author = {Epstein, Daniel A. and Cordeiro, Felicia and Fogarty, James and Hsieh, Gary and Munson, Sean A.},
title = {Crumbs: Lightweight Daily Food Challenges to Promote Engagement and Mindfulness},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858044},
doi = {10.1145/2858036.2858044},
abstract = {Many people struggle with efforts to make healthy behavior changes, such as healthy
eating. Several existing approaches promote healthy eating, but present high barriers
and yield limited engagement. As a lightweight alternative approach to promoting mindful
eating, we introduce and examine crumbs: daily food challenges completed by consuming
one food that meets the challenge. We examine crumbs through developing and deploying
the iPhone application Food4Thought. In a 3 week field study with 61 participants,
crumbs supported engagement and mindfulness while offering opportunities to learn
about food. Our 2x2 study compared nutrition versus non-nutrition crumbs coupled with
social versus non-social features. Nutrition crumbs often felt more purposeful to
participants, but non-nutrition crumbs increased mindfulness more than nutrition crumbs.
Social features helped sustain engagement and were important for engagement with non-nutrition
crumbs. Social features also enabled learning about the variety of foods other people
use to meet a challenge.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5632–5644},
numpages = {13},
keywords = {mindfulness, personal informatics, daily challenges, food},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858554,
author = {Chaudhry, Beenish M. and Schaefbauer, Christopher and Jelen, Ben and Siek, Katie A. and Connelly, Kay},
title = {Evaluation of a Food Portion Size Estimation Interface for a Varying Literacy Population},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858554},
doi = {10.1145/2858036.2858554},
abstract = {Portion size estimation is important for managing dietary intake in many chronic conditions.
We conducted a 6-week field study with nine varying literacy dialysis patients to
explore the usability and feasibility of a dietary intake mobile application that
emphasizes portion size estimation. Seven participants demonstrated sustained use
of the application and improved their self-efficacy, knowledge, and ability to estimate
portion sizes in pre- and post-study assessments. Participants reported moments when
portion size information in the application differed from their prior understanding,
challenging them to reconcile dissonant information. Although participants acquired
new knowledge about portion sizes, they struggled to accurately estimate portion sizes
in situ for most foods. Despite using the application consistently, rating it highly,
and exhibiting learning, we found that self-efficacy and knowledge are not sufficient
to support improved behaviors in everyday life.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5645–5657},
numpages = {13},
keywords = {health, mobile devices, behavior change, user interface design, portion estimate, low literacy, self-efficacy},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858360,
author = {Zhang, Xiaoyi and Pina, Laura R. and Fogarty, James},
title = {Examining Unlock Journaling with Diaries and Reminders for In Situ Self-Report in Health and Wellness},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858360},
doi = {10.1145/2858036.2858360},
abstract = {In situ self-report is widely used in human-computer interaction, ubiquitous computing,
and for assessment and intervention in health and wellness. Unfortunately, it remains
limited by high burdens. We examine unlock journaling as an alternative. Specifically,
we build upon recent work to introduce single-slide unlock journaling gestures appropriate
for health and wellness measures. We then present the first field study comparing
unlock journaling with traditional diaries and notification-based reminders in self-report
of health and wellness measures. We find unlock journaling is less intrusive than
reminders, dramatically improves frequency of journaling, and can provide equal or
better timeliness. Where appropriate to broader design needs, unlock journaling is
thus an overall promising method for in situ self-report.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5658–5664},
numpages = {7},
keywords = {self-tracking, experience sampling, personal informatics},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858536,
author = {Tsiamyrtzis, Panagiotis and Dcosta, Malcolm and Shastri, Dvijesh and Prasad, Eswar and Pavlidis, Ioannis},
title = {Delineating the Operational Envelope of Mobile and Conventional EDA Sensing on Key Body Locations},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858536},
doi = {10.1145/2858036.2858536},
abstract = {Electrodermal activity (EDA) is an important affective indicator, measured conventionally
on the fingers with desktop sensing instruments. Recently, a new generation of wearable,
battery-powered EDA devices came into being, encouraging the migration of EDA sensing
to other body locations. To investigate the implications of such sensor/location shifts
in psychophysiological studies we performed a validation experiment. In this experiment
we used startle stimuli to instantaneously arouse the sympathetic system of n=23 subjects
while sitting. Startle stimuli are standard but minimal stressors, and thus ideal
for determining the sensor and location resolution limit. The experiment revealed
that precise measurement of small EDA responses on the fingers and palm is feasible
either with conventional or mobile EDA sensors. By contrast, precise measurement of
small EDA responses on the sole is challenging, while on the wrist even detection
of such responses is problematic for both EDA modalities. Given that affective wristbands
have emerged as the dominant form of EDA sensing, researchers should beware of these
limitations.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5665–5674},
numpages = {10},
keywords = {startle, wearable sensors, affective sensors, skin conductance, electrodermal activity (EDA)},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858401,
author = {Goel, Mayank and Saba, Elliot and Stiber, Maia and Whitmire, Eric and Fromm, Josh and Larson, Eric C. and Borriello, Gaetano and Patel, Shwetak N.},
title = {SpiroCall: Measuring Lung Function over a Phone Call},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858401},
doi = {10.1145/2858036.2858401},
abstract = {Cost and accessibility have impeded the adoption of spirometers (devices that measure
lung function) outside clinical settings, especially in low-resource environments.
Prior work, called SpiroSmart, used a smartphone's built-in microphone as a spirometer.
However, individuals in low- or middle-income countries do not typically have access
to the latest smartphones. In this paper, we investigate how spirometry can be performed
from any phone-using the standard telephony voice channel to transmit the sound of
the spirometry effort. We also investigate how using a 3D printed vortex whistle can
affect the accuracy of common spirometry measures and mitigate usability challenges.
Our system, coined SpiroCall, was evaluated with 50 participants against two gold
standard medical spirometers. We conclude that SpiroCall has an acceptable mean error
with or without a whistle for performing spirometry, and advantages of each are discussed.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5675–5685},
numpages = {11},
keywords = {machine learning, health sensing, signal processing, mobile phone sensing, spirometry},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858529,
author = {Krause, Josua and Perer, Adam and Ng, Kenney},
title = {Interacting with Predictions: Visual Inspection of Black-Box Machine Learning Models},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858529},
doi = {10.1145/2858036.2858529},
abstract = {Understanding predictive models, in terms of interpreting and identifying actionable
insights, is a challenging task. Often the importance of a feature in a model is only
a rough estimate condensed into one number. However, our research goes beyond these
na\"{\i}ve estimates through the design and implementation of an interactive visual analytics
system, Prospector. By providing interactive partial dependence diagnostics, data
scientists can understand how features affect the prediction overall. In addition,
our support for localized inspection allows data scientists to understand how and
why specific datapoints are predicted as they are, as well as support for tweaking
feature values and seeing how the prediction responds. Our system is then evaluated
using a case study involving a team of data scientists improving predictive models
for detecting the onset of diabetes from electronic medical records.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5686–5697},
numpages = {12},
keywords = {interactive machine learning, partial dependence, predictive modeling},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858302,
author = {Newbold, Joseph W. and Bianchi-Berthouze, Nadia and Gold, Nicolas E. and Tajadura-Jim\'{e}nez, Ana and Williams, Amanda CdC},
title = {Musically Informed Sonification for Chronic Pain Rehabilitation: Facilitating Progress &amp; Avoiding Over-Doing},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858302},
doi = {10.1145/2858036.2858302},
abstract = {In self-directed chronic pain physical rehabilitation it is important that the individual
can progress as physical capabilities and confidence grow. However, people with chronic
pain often struggle to pass what they have identified as safe boundaries. At the same
time, over-activity due to the desire to progress fast or function more normally,
may lead to setbacks. We investigate how musically-informed movement sonification
can be used as an implicit mechanism to both avoid overdoing and facilitate progress
during stretching exercises. We sonify an end target-point in a stretch exercise,
using a stable sound (i.e., where the sonification is musically resolved) to encourage
movements ending and an unstable sound (i.e., musically unresolved) to encourage continuation.
Results on healthy participants show that instability leads to progression further
beyond the target-point while stability leads to a smoother stop beyond this point.
We conclude discussing how these findings should generalize to the CP population.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5698–5703},
numpages = {6},
keywords = {physical rehabilitation, musically informed sonification, auditory feedback},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858185,
author = {You, Chuang-Wen and Lin, Ya-Fang and Li, Cheng-Yuan and Tsai, Yu-Lun and Huang, Ming-Chyi and Lee, Chao-Hui and Wang, Hao-Chuan and Chu, Hao-Hua},
title = {KeDiary: Using Mobile Phones to Assist Patients in Recovering from Drug Addiction},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858185},
doi = {10.1145/2858036.2858185},
abstract = {Ketamine is an addictive drug that has been shown to inflict considerable physical
and mental damage on users. Due in part to its low cost, ketamine has become one of
the most popular club drugs among young adults and teenagers in Southeast Asia. This
paper proposes a phone-based support system (KeDiary) with Bluetooth-enabled device
for the screening of saliva, as a means of assisting ketamine-dependent patients to
self-monitor their ketamine use following acute withdrawal treatment. We also conducted
a practical experiment to evaluate the feasibility of the proposed system, wherein
three ketamine-dependent patients self-administered tests at least once per day over
a period of three weeks. Follow-up interviews with the same users helped in the further
refinement of the proposed self-monitoring system.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5704–5709},
numpages = {6},
keywords = {drug addiction, CHI4good, addiction recovery, mobile system},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858255,
author = {Bentley, Frank R. and Kaye, Joseph 'Jofish' and Shamma, David A. and Guerra-Gomez, John Alexis},
title = {The 32 Days of Christmas: Understanding Temporal Intent in Image Search Queries},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858255},
doi = {10.1145/2858036.2858255},
abstract = {Temporal terms, such as 'winter', 'Christmas', or 'January' are often used in search
queries for personal images. But how do people's memories and perceptions of time
match with the actual dates when their images were captured? We compared the temporal
terms that 74 Flickr users used to search their own photo collections, and compared
them to the date captured data in the target image. We also conducted a larger study
across several billion images, comparing user-applied tags for holidays and seasons
to the dates the images were captured. We demonstrate that various query terms and
tags can be in conflict with the actual dates photos were taken for specific types
of temporal terms up to 40% of the time. We will conclude by highlighting implications
for search systems where users are querying for personal content by date.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5710–5714},
numpages = {5},
keywords = {search, memory, temporal, photos, date},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858497,
author = {Yue, Yanzhen and Ma, Xiaojuan and Jiang, Zhenhui},
title = {Influence of Content Layout and Motivation on Users' Herd Behavior in Social Discovery},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858497},
doi = {10.1145/2858036.2858497},
abstract = {Social product discovery is an emerging paradigm that enables users to seek information
and inspiration from peer-contributed contents. Researchers have observed herd behaviors
in social discovery, i.e., basing beliefs and decisions on what similarly situated
others have done. In this paper, we explore the effects of content layout and motivation
on users' herd behaviors in social discovery. We conduct an eye-tracking study with
120 participants to compare goal- and action-oriented users' behaviors on a grid versus
waterfall style social discovery site. The results show that users have a higher tendency
to herd on a grid-style website, more so for goal-oriented users.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5715–5719},
numpages = {5},
keywords = {waterfall, layout, motivation, grid, social discovery, herd},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858444,
author = {Karanam, Saraschandra and van Oostendorp, Herre},
title = {Age-Related Differences in the Content of Search Queries When Reformulating},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858444},
doi = {10.1145/2858036.2858444},
abstract = {This study investigated the change in the content of the queries when performing reformulations
in relation to age and task difficulty. Results showed that both generalization and
specialization strategies were applied significantly more often for difficult tasks
compared to simple tasks. Young participants were found to use specialization strategy
significantly more often than old participants. Generalization strategy was also used
significantly more often by young participants, especially for difficult tasks. Young
participants were found to reformulate much longer than old participants. The semantic
relevance of queries with the target information was found to be significantly higher
for difficult tasks compared to simple tasks. It showed a decreasing trend across
reformulations for old participants and remained constant for young participants,
indicating that as old participants reformulated, they produced queries that were
further away from the target information. Implications of these findings for design
of information search systems are discussed.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5720–5730},
numpages = {11},
keywords = {aging, reformulation strategies, information search, task difficulty},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858309,
author = {Vasilevitsky, Tatyana and Zoran, Amit},
title = {Steel-Sense: Integrating Machine Elements with Sensors by Additive Manufacturing},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858309},
doi = {10.1145/2858036.2858309},
abstract = {Many interactive devices use both machine elements and sensors, simultaneously but
redundantly enabling and measuring the same physical function. We present Steel-Sense,
an approach to joining these two families of elements to create a new type of HCI
design primitive. We leverage recent developments in 3D printing to embed sensing
in metal structures that are otherwise difficult to equip with sensors, and present
four design principles, implementing (1) an electronic switch integrated within a
ball bearing; (2) a voltage divider within a gear; (3) a variable capacitor embedded
in a hinge; and (4) a pressure sensor within a screw. Each design demonstrates a different
sensing principle, and signals its performance through (1) movement; (2) position;
(3) angle (4) or stress. We mirror our elements physical performance in a virtual
environment, evaluate our designs electronically and structurally, and discuss future
work and implications for HCI research.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5731–5742},
numpages = {12},
keywords = {3D printing, additive manufacturing, metal printing, digital fabrication, sensors, machine elements, hybrid design},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858281,
author = {Wang, Guanyun and Yao, Lining and Wang, Wen and Ou, Jifei and Cheng, Chin-Yi and Ishii, Hiroshi},
title = {XPrint: A Modularized Liquid Printer for Smart Materials Deposition},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858281},
doi = {10.1145/2858036.2858281},
abstract = {To meet the increasing requirements of HCI researchers who are looking into using
liquid-based materials (e.g., hydrogels) to create novel interfaces, we present a
design strategy for HCI researchers to build and customize a liquid-based smart material
printing platform with off-the-shelf or easy-to-machine parts. For the hardware, we
suggest a magnetic assembly-based modular design. These modularized parts can be easily
and precisely reconfigured with off-the-shelf or easy-to-machine parts that can meet
different processing requirements such as mechanical mixing, chemical reaction, light
activation, and solution vaporization. In addition, xPrint supports an open-source,
highly customizable software design and simulation platform, which is applicable for
simulating and facilitating smart material constructions. Furthermore, compared to
inkjet or pneumatic syringe-based printing systems, xPrint has a large range of printable
materials from synthesized polymers to natural micro-organism-living cells with a
printing resolution from 10μm up to 5mm (droplet size). In this paper, we will introduce
the system design in detail and three use cases to demonstrate the material variability
and the customizability for users with different demands (e.g., designers, scientific
researchers, or artists).},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5743–5752},
numpages = {10},
keywords = {functional material printing, smart material printing, smart material interface, shape changing interface, responsive material printing, 3D printing, physical interface, liquid deposition modeling printer},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858257,
author = {Ou, Jifei and Dublon, Gershon and Cheng, Chin-Yi and Heibeck, Felix and Willis, Karl and Ishii, Hiroshi},
title = {Cilllia: 3D Printed Micro-Pillar Structures for Surface Texture, Actuation and Sensing},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858257},
doi = {10.1145/2858036.2858257},
abstract = {This work presents a method for 3D printing hair-like structures on both flat and
curved surfaces. It allows a user to design and fabricate hair geometries that are
smaller than 100 micron. We built a software platform to let users quickly define
the hair angle, thickness, density, and height. The ability to fabricate customized
hair-like structures not only expands the library of 3D-printable shapes, but also
enables us to design passive actuators and swipe sensors. We also present several
applications that show how the 3D-printed hair can be used for designing everyday
interactive objects.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5753–5764},
numpages = {12},
keywords = {3D printing, surface texture, hair, digital fabrication, actuated interfaces, acoustic sensing},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858135,
author = {C, Varun Perumal and Wigdor, Daniel},
title = {Foldem: Heterogeneous Object Fabrication via Selective Ablation of Multi-Material Sheets},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858135},
doi = {10.1145/2858036.2858135},
abstract = {Foldem, a novel method of rapid fabrication of objects with multi-material properties
is presented. Our specially formulated Foldem sheet allows users to fabricate and
easily assemble objects with rigid, bendable, and flexible properties using a standard
laser-cutter. The user begins by creating his designs in a vector graphics software
package. A laser cutter is then used to fabricate the design by selectively ablating/vaporizing
one or more layers of the Foldem sheet to achieve the desired physical properties
for each joint. Herein the composition of the Foldem sheet, as well as various design
considerations taken into account while building and designing the method, are described.
Sample objects made with Foldem are demonstrated, each showcasing the unique attributes
of Foldem. Additionally, a novel method for carefully calibrating a laser cutter for
precise ablation is presented.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5765–5775},
numpages = {11},
keywords = {fabrication, folding objects, heterogeneous objects, laser ablation, multi-material},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858117,
author = {Pfleging, Bastian and Fekety, Drea K. and Schmidt, Albrecht and Kun, Andrew L.},
title = {A Model Relating Pupil Diameter to Mental Workload and Lighting Conditions},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858117},
doi = {10.1145/2858036.2858117},
abstract = {In this paper, we present a proof-of-concept approach to estimating mental workload
by measuring the user's pupil diameter under various controlled lighting conditions.
Knowing the user's mental workload is desirable for many application scenarios, ranging
from driving a car, to adaptive workplace setups. Typically, physiological sensors
allow inferring mental workload, but these sensors might be rather uncomfortable to
wear. Measuring pupil diameter through remote eye-tracking instead is an unobtrusive
method. However, a practical eye-tracking-based system must also account for pupil
changes due to variable lighting conditions. Based on the results of a study with
tasks of varying mental demand and six different lighting conditions, we built a simple
model that is able to infer the workload independently of the lighting condition in
75% of the tested conditions.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5776–5788},
numpages = {13},
keywords = {eye-tracking, estimation of mental workload, compensation of pupillary light reflex, task-evoked pupillary response, cognitive workload, adaptive user interfaces, psychophysiology, lighting},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858480,
author = {Serim, Baris and Jacucci, Giulio},
title = {Pointing While Looking Elsewhere: Designing for Varying Degrees of Visual Guidance during Manual Input},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858480},
doi = {10.1145/2858036.2858480},
abstract = {We propose using eye tracking to support interface use with decreased reliance on
visual guidance. While the design of most graphical user interfaces take visual guidance
during manual input for granted, eye tracking allows distinguishing between the cases
when the manual input is conducted with or without guidance. We conceptualize the
latter cases as input with uncertainty that require separate handling. We describe
the design space of input handling by utilizing input resources available to the system,
possible actions the system can realize and various feedback techniques for informing
the user. We demonstrate the particular action mechanisms and feedback techniques
through three applications we developed for touch interaction on a large screen. We
conducted a two stage study of positional accuracy during target acquisition with
varying visual guidance, to determine the selection range around a touch point due
to positional uncertainty. We also conducted a qualitative evaluation of example applications
with participants to identify perceived utility and hand eye coordination challenges
while using interfaces with decreased visual guidance.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5789–5800},
numpages = {12},
keywords = {eye tracking, interactive surface, uncertain input, interaction techniques, multimodal interaction, gaze input},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858584,
author = {Jalaliniya, Shahram and Mardanbegi, Diako},
title = {EyeGrip: Detecting Targets in a Series of Uni-Directional Moving Objects Using Optokinetic Nystagmus Eye Movements},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858584},
doi = {10.1145/2858036.2858584},
abstract = {EyeGrip proposes a novel and yet simple technique of analysing eye movements for automatically
detecting the user's objects of interest in a sequence of visual stimuli moving horizontally
or vertically in front of the user's view. We assess the viability of this technique
in a scenario where the user looks at a sequence of images moving horizontally on
the display while the user's eye movements are tracked by an eye tracker. We conducted
an experiment that shows the performance of the proposed approach. We also investigated
the influence of the speed and maximum number of visible images in the screen, on
the accuracy of EyeGrip. Based on the experiment results, we propose guidelines for
designing EyeGrip-based interfaces. EyeGrip can be considered as an implicit gaze
interaction technique with potential use in broad range of applications such as large
screens, mobile devices and eyewear computers. In this paper, we demonstrate the rich
capabilities of EyeGrip with two example applications: 1) a mind reading game, and
2) a picture selection system. Our study shows that by selecting an appropriate speed
and maximum number of visible images in the screen the proposed method can be used
in a fast scrolling task where the system accurately (87%) detects the moving images
that are visually appealing to the user, stops the scrolling and brings the item(s)
of interest back to the screen.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5801–5811},
numpages = {11},
keywords = {implicit interaction, optokinetic nystagmus (okn) eye movements, scrolling, gaze tracking},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858578,
author = {Templier, Thomas and Bektas, Kenan and Hahnloser, Richard H.R.},
title = {Eye-Trace: Segmentation of Volumetric Microscopy Images with Eyegaze},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858578},
doi = {10.1145/2858036.2858578},
abstract = {We introduce an image annotation approach for the analysis of volumetric electron
microscopic imagery of brain tissue. The core task is to identify and link tubular
objects (neuronal fibers) in images taken from consecutive ultrathin sections of brain
tissue. In our approach an individual 'flies' through the 3D data at a high speed
and maintains eye gaze focus on a single neuronal fiber, aided by navigation with
a handheld gamepad controller. The continuous foveation on a fiber of interest constitutes
an intuitive means to define a trace that is seamlessly recorded with a desktop eyetracker
and transformed into precise 3D coordinates of the annotated fiber (skeleton tracing).
In a participant experiment we validate the approach by demonstrating a tracing accuracy
of about the respective radiuses of the traced fibers with browsing speeds of up to
40 brain sections per second.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5812–5823},
numpages = {12},
keywords = {eye tracking, brain mapping, annotation, neural circuit reconstruction, user interface design, connectomics, array tomography, segmentation},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858429,
author = {Claes, Sandy and Slegers, Karin and Vande Moere, Andrew},
title = {The Bicycle Barometer: Design and Evaluation of Cyclist-Specific Interaction for a Public Display},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858429},
doi = {10.1145/2858036.2858429},
abstract = {As cycling is increasingly promoted as an environment-friendly, cheap and even fast
alternative, there exists an increasing need to civically involve the potentially
engaged and opinionated user group of cyclists. Therefore, we designed and evaluated
Bicycle Barometer, an interactive bicycle count display that gathers the opinions
from cyclists and conveys real-time, multi-dimensional data to them regarding cycling
behavior. Our user-centered design process focused on optimizing the user experience
by comparing several alternative cyclist-specific interaction designs, which resulted
in the combination of a pressure sensitive floor mat, push button and low-resolution
LED display. An in-the-wild evaluation study resulted in a set of design recommendations
for cyclist-specific interaction, providing concrete insights into how a specifically
targeted interaction method for public display is able to afford engagement and enthusiasm
from a particular target audience.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5824–5835},
numpages = {12},
keywords = {bicycle HCI, public polling, in the wild, urban visualization, cyclist-specific interaction, citizen participation},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858211,
author = {Uddin, Md. Sami and Gutwin, Carl and Lafreniere, Benjamin},
title = {HandMark Menus: Rapid Command Selection and Large Command Sets on Multi-Touch Displays},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858211},
doi = {10.1145/2858036.2858211},
abstract = {Command selection on large multi-touch surfaces can be difficult, because the large
surface means that there are few landmarks to help users build up familiarity with
controls. However, people's hands and fingers are landmarks that are always present
when interacting with a touch display. To explore the use of hands as landmarks, we
designed two hand-centric techniques for multi-touch displays -- one allowing 42 commands,
and one allowing 160 -- and tested them in an empirical comparison against standard
tab widgets. We found that the small version (HandMark-Fingers) was significantly
faster at all stages of use, and that the large version (HandMark-Multi) was slower
at the start but equivalent to tabs after people gained experience with the technique.
There was no difference in error rates, and participants strongly preferred both of
the HandMark menus over tabs. We demonstrate that people's intimate knowledge of their
hands can be the basis for fast and feasible interaction techniques that can improve
the performance and usability of interactive tables and other multi-touch systems.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5836–5848},
numpages = {13},
keywords = {command selection, landmarks, tabletops., multi-touch},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858524,
author = {Perteneder, Florian and Grossauer, Eva-Maria Beatrix and Leong, Joanne and Stuerzlinger, Wolfgang and Haller, Michael},
title = {Glowworms and Fireflies: Ambient Light on Large Interactive Surfaces},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858524},
doi = {10.1145/2858036.2858524},
abstract = {Ambient light is starting to be commercially used to enhance the viewing experience
for watching TV. We believe that ambient light can add value in meeting and control
rooms that use large vertical interactive surfaces. Therefore, we equipped a large
interactive whiteboard with a peripheral ambient light display and explored its utility
for different scenarios by conducting two controlled experiments. In the first experiment,
we investigated how ambient light can be used for peripheral notifications, and how
perception is influenced by the user's position and the type of work they are engaged
in. The second experiment investigated the utility of ambient light for off-screen
visualization. We condense our findings into several design recommendations that we
then applied to application scenarios to show the versatility and usefulness of ambient
light for large surfaces.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5849–5861},
numpages = {13},
keywords = {ambient light display, large interactive surfaces, evaluations, peripheral display, interactive whiteboard},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858083,
author = {Markussen, Anders and Boring, Sebastian and Jakobsen, Mikkel R. and Hornb\ae{}k, Kasper},
title = {Off-Limits: Interacting Beyond the Boundaries of Large Displays},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858083},
doi = {10.1145/2858036.2858083},
abstract = {The size of information spaces often exceeds the limits of even the largest displays.
This makes navigating such spaces through on-screen interactions demanding. However,
if users imagine the information space extending in a plane beyond the display's boundaries,
they might be able to use the space beyond the display for input. This paper investigates
Off-Limits, an interaction concept extending the input space of a large display into
the space beyond the screen through the use of mid-air pointing. We develop and evaluate
the concept through three empirical studies in one-dimensional space: First, we explore
benefits and limitations of off-screen pointing compared to touch interaction and
mid-air on-screen pointing; next, we assess users' accuracy in off-screen pointing
to model the distance-to-screen vs. accuracy trade-off; and finally, we show how Off-Limits
is further improved by applying that model to the na\"{\i}ve approach. Overall, we found
that the final Off-Limits concept provides significant performance benefits over on-screen
and touch pointing conditions.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5862–5873},
numpages = {12},
keywords = {mid-air pointing, spatial user interfaces, in-air pointing, off-screen pointing, freehand pointing},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858325,
author = {Kerlin, Lianne and Cox, Jasmine and Jolly, Stephen and Evans, Michael and Green, George and Regan, David},
title = {Pressing Not Tapping: Comparing a Physical Button with a Smartphone App for Tagging Music in Radio Programmes},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858325},
doi = {10.1145/2858036.2858325},
abstract = {A physical hardware prototype--The Button was developed as a research probe to understand
how radio audiences could discover, organise and consume music radio content at the
touch of a physical button, the only control on a tiny handheld device. The Button
allows listeners to tag tracks they like via a simple one-touch interaction method,
and save them to a non-commercial online playlist service: BBC Playlister. Users can
then export these tags to other music streaming platforms, such as Spotify, Deezer,
etc. Following a user-centric design process, a large in-the-wild study was conducted
over several weeks to investigate the value of the Button in aiding listeners' discovery
of music. One group of participants was given a mobile phone app designed to facilitate
tagging music heard on BBC radio stations; two other groups were given both the app
and a Button (in one of two hardware versions). The findings revealed that Button
users made significantly more tags on average than app users, indicating that a physical
device could add significant value for radio listeners who want to tag music. Participants
valued the simple one-touch interaction method, especially in situations where their
smartphones were out of reach or contextual constraints meant that interaction with
a complex device was undesirable or difficult.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5874–5884},
numpages = {11},
keywords = {interactive product design, research in the wild, internet of things, connected devices, radio, user-centred design, music},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858249,
author = {Li, Hanchuan and Brockmeyer, Eric and Carter, Elizabeth J. and Fromm, Josh and Hudson, Scott E. and Patel, Shwetak N. and Sample, Alanson},
title = {PaperID: A Technique for Drawing Functional Battery-Free Wireless Interfaces on Paper},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858249},
doi = {10.1145/2858036.2858249},
abstract = {We describe techniques that allow inexpensive, ultra-thin, battery-free Radio Frequency
Identification (RFID) tags to be turned into simple paper input devices. We use sensing
and signal processing techniques that determine how a tag is being manipulated by
the user via an RFID reader and show how tags may be enhanced with a simple set of
conductive traces that can be printed on paper, stencil-traced, or even hand-drawn.
These traces modify the behavior of contiguous tags to serve as input devices. Our
techniques provide the capability to use off-the-shelf RFID tags to sense touch, cover,
overlap of tags by conductive or dielectric (insulating) materials, and tag movement
trajectories. Paper prototypes can be made functional in seconds. Due to the rapid
deployability and low cost of the tags used, we can create a new class of interactive
paper devices that are drawn on demand for simple tasks. These capabilities allow
new interactive possibilities for pop-up books and other papercraft objects.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5885–5896},
numpages = {12},
keywords = {tangible, RFID, paper interfaces, battery free},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858243,
author = {Spielberg, Andrew and Sample, Alanson and Hudson, Scott E. and Mankoff, Jennifer and McCann, James},
title = {RapID: A Framework for Fabricating Low-Latency Interactive Objects with RFID Tags},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858243},
doi = {10.1145/2858036.2858243},
abstract = {RFID tags can be used to add inexpensive, wireless, batteryless sensing to objects.
However, quickly and accurately estimating the state of an RFID tag is difficult.
In this work, we show how to achieve low-latency manipulation and movement sensing
with off-the-shelf RFID tags and readers. Our approach couples a probabilistic filtering
layer with a monte-carlo-sampling-based interaction layer, preserving uncertainty
in tag reads until they can be resolved in the context of interactions. This allows
designers' code to reason about inputs at a high level. We demonstrate the effectiveness
of our approach with a number of interactive objects, along with a library of components
that can be combined to make new designs.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5897–5908},
numpages = {12},
keywords = {RFID, computational fabrication, probabilistic modeling},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858177,
author = {de Freitas, Adrian A. and Nebeling, Michael and Chen, Xiang 'Anthony' and Yang, Junrui and Karthikeyan Ranithangam, Akshaye Shreenithi Kirupa and Dey, Anind K.},
title = {Snap-To-It: A User-Inspired Platform for Opportunistic Device Interactions},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858177},
doi = {10.1145/2858036.2858177},
abstract = {The ability to quickly interact with any nearby appliance from a mobile device would
allow people to perform a wide range of one-time tasks (e.g., printing a document
in an unfamiliar office location). However, users currently lack this capability,
and must instead manually configure their devices for each appliance they want to
use. To address this problem, we created Snap-To-It, a system that allows users to
opportunistically interact with any appliance simply by taking a picture of it. Snap-To-It
shares the image of the appliance a user wants to interact with over a local area
network. Appliances then analyze this image (along with the user's location and device
orientation) to see if they are being "selected," and deliver the corresponding control
interface to the user's mobile device. Snap-To-It's design was informed by two technology
probes that explored how users would like to select and interact with appliances using
their mobile phone. These studies highlighted the need to be able to select hardware
and software via a camera, and identified several novel use cases not supported by
existing systems (e.g., interacting with disconnected objects, transferring settings
between appliances). In this paper, we show how Snap-To-It's design is informed by
our probes and how developers can utilize our system. We then show that Snap-To-It
can identify appliances with over 95.3% accuracy, and demonstrate through a two-month
deployment that our approach is robust to gradual changes to the environment.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5909–5920},
numpages = {12},
keywords = {mobile interaction, internet of things},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858051,
author = {Matthews, Tara and Liao, Kerwell and Turner, Anna and Berkovich, Marianne and Reeder, Robert and Consolvo, Sunny},
title = {"She'll Just Grab Any Device That's Closer": A Study of Everyday Device &amp; Account Sharing in Households},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858051},
doi = {10.1145/2858036.2858051},
abstract = {Many technologies assume a single user will use an account or device. But account
and device sharing situations (when 2+ people use a single device or account) may
arise during everyday life. We present results from a multiple-methods study of device
and account sharing practices among household members and their relations. Among our
findings are that device and account sharing was common, and mobile phones were often
shared despite being considered "personal" devices. Based on our study results, we
organize sharing practices into a taxonomy of six sharing types--distinct patterns
of what, why, and how people shared. We also present two themes that cut across sharing
types: that (1) trust in sharees and (2) convenience highly influenced sharing practices.
Based on these findings, we discuss implications for study and technology design.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5921–5932},
numpages = {12},
keywords = {user study, usable privacy and security, cscw, household, account sharing, device sharing},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858518,
author = {Fischer, Joel E. and Crabtree, Andy and Rodden, Tom and Colley, James A. and Costanza, Enrico and Jewell, Michael O. and Ramchurn, Sarvapali D.},
title = {"Just Whack It on until It Gets Hot": Working with IoT Data in the Home},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858518},
doi = {10.1145/2858036.2858518},
abstract = {This paper presents findings from a co-design project that aims to augment the practices
of professional energy advisors with environmental data from sensors deployed in clients'
homes. Premised on prior ethnographic observations we prototyped a sensor platform
to support the work of tailoring advice-giving to particular homes. We report on the
deployment process and the findings to emerge, particularly the work involved in making
sense of or accounting for the data in the course of advice-giving. Our ethnomethodological
analysis focuses on the ways in which data is drawn upon as a resource in the home
visit, and how understanding and advice-giving turns upon unpacking the indexical
relationship of the data to the situated goings-on in the home. This insight, coupled
with further design workshops with the advisors, shaped requirements for an interactive
system that makes the sensor data available for visual inspection and annotation to
support the situated sense-making that is key to giving energy advice.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5933–5944},
numpages = {12},
keywords = {data work, internet of things, energy advice, non-profit, ethnomethodology, sensor data},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858069,
author = {Uriu, Daisuke and Odom, William},
title = {Designing for Domestic Memorialization and Remembrance: A Field Study of Fenestra in Japan},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858069},
doi = {10.1145/2858036.2858069},
abstract = {We describe the design, implementation, and deployment of Fenestra, a domestic technology
embodied in the form of a wirelessly connected round mirror, photo frame, and candle
that displays photos of departed loved ones. Fenestra's interaction design, form,
and materials are inspired by Japanese domestic practices of memorializing departed
loved ones with a home altar called butsudan. We deployed Fenestra in three Japanese
households to explore how this design artifact might support everyday domestic practices
of memorialization, and where complications might potentially emerge. Findings reveal
that a range of outcomes emerged across our participants' experiences of living with
Fenestra--from profound remembrance to unexpected uses to unsettling encounters. These
findings are interpreted to present opportunities for future research and practice
initiatives in the HCI community.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5945–5957},
numpages = {13},
keywords = {domestic memorialization, research through design, thanato-sensitive design, techno-spirituality},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858168,
author = {Mennicken, Sarah and Kim, David and Huang, Elaine May},
title = {Integrating the Smart Home into the Digital Calendar},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858168},
doi = {10.1145/2858036.2858168},
abstract = {With the growing adoption of smart home technologies, inhabitants are faced with the
challenge of making sense of the data that their homes can collect to configure automated
behaviors that benefit their routines. Current commercial smart home interfaces usually
provide information on individual devices instead of a more comprehensive overview
of a home's behavior. To reduce the complexity of smart home data and integrate it
better into inhabitants' lives, we turned to the familiar metaphor of a calendar and
developed our smart home interface Casalendar. In order to investigate the concept
and evaluate our goals to facilitate the understanding of smart home data, we created
a prototype that we installed in two commercial smart homes for a month. The results
we present in this paper are based on our analysis of user data from questionnaires,
semi-structured interviews, participant-driven audio and screenshot feedback as well
as logged interactions with our system. Our findings exposed advantages and disadvantages
of this metaphor, emerging usage patterns, privacy concerns and challenges for information
visualization. We further report on implications for design and open challenges we
revealed through this work.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5958–5969},
numpages = {12},
keywords = {interface design, domestic routines, in-the-wild study, smart home, home automation, calendar},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858459,
author = {Tsaknaki, Vasiliki and Fernaeus, Ylva},
title = {Expanding on Wabi-Sabi as a Design Resource in HCI},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858459},
doi = {10.1145/2858036.2858459},
abstract = {The material foundations of computer systems and interactive technology is a topic
that gained an increased interest within the HCI community during the last years.
In this paper we discuss this topic through the Japanese concept of Wabi-Sabi, a philosophy
that embraces three basic realities of the material world: 'nothing lasts', 'nothing
is finished', and 'nothing is perfect'. We use these concepts to reflect on four unique
interactive artefacts, which all in different ways embrace aspects of Wabi-Sabi, in
terms of their design gestalt, materiality, but also in terms of use practices. Further,
we use our analysis to articulate three high-level principles that may help addressing
the long-term realities faced in physical interaction design, and for the design of
interactive systems in general.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5970–5983},
numpages = {14},
keywords = {design practice, wabi-sabi, impermanence, incompleteness, imperfection, interaction design, materiality},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858441,
author = {Efrat, Tamara Anna and Mizrahi, Moran and Zoran, Amit},
title = {The Hybrid Bricolage: Bridging Parametric Design with Craft through Algorithmic Modularity},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858441},
doi = {10.1145/2858036.2858441},
abstract = {The digital design space, unlimited by its virtual freedom, differs from traditional
craft, which is bounded by a fixed set of given materials. We study how to introduce
parametric design tools to craftspersons. Our hypothesis is that the arrangement of
parametric design in modular representation, in the form of a catalog, can assist
makers unfamiliar with this practice. We evaluate this assumption in the realm of
bag design, through a Honeycomb Smocking Pattern Catalog and custom Computer-Aided
Smocking (CAS) design software. We describe the technical work and designs made with
our tools, present a user study that validates our assumptions, and conclude with
ideas for future work developing additional tools to bridge computational design and
craft.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5984–5995},
numpages = {12},
keywords = {bricolage, fabrication, tinkering, smocking, craft, parametric design, computer-aided design (cad)},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858576,
author = {Gannon, Madeline and Grossman, Tovi and Fitzmaurice, George},
title = {ExoSkin: On-Body Fabrication},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858576},
doi = {10.1145/2858036.2858576},
abstract = {There is a long tradition for crafting wearable objects directly on the body, such
as garments, casts, and orthotics. However, these high-skill, analog practices have
yet to be augmented by digital fabrication techniques. In this paper, we explore the
use of hybrid fabrication workflows for on-body printing. We outline design considerations
for creating on-body fabrication systems, and identify several human, machine, and
material challenges unique to this endeavor. Based on our explorations, we present
ExoSkin, a hybrid fabrication system for designing and printing digital artifacts
directly on the body. ExoSkin utilizes a custom built fabrication machine designed
specifically for on-body printing. We demonstrate the potential of on-body fabrication
with a set of sample workflows, and share feedback from initial observation sessions.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5996–6007},
numpages = {12},
keywords = {skin input, exoskin, fabrication},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858475,
author = {Saegusa, Hidekazu and Tran, Thomas and Rosner, Daniela K.},
title = {Mimetic Machines: Collaborative Interventions in Digital Fabrication with Arc},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858475},
doi = {10.1145/2858036.2858475},
abstract = {This paper examines the collaborative process of developing Arc, a computer numerical
controlled (CNC) engraving tool for ceramics that offers a new window onto traditional
forms of craft. In reflecting on this case and scholarship from the social sciences,
we make two contributions. First, we show that fabrication tools may integrate multiple
and distinct roles (as copiers, translators and connectors) in their production of
form, selectively limiting the agency of the maker and machine. Second, we situate
small-scale manufacturing in a wider historical context of "mimetic machinery": machines
for mechanical reproduction that draw their symbolic power from a material connection
with the phenomena represented (in this case, sound and gesture). We end by sharing
lessons learned for fabrication research based on this study.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {6008–6013},
numpages = {6},
keywords = {digital fabrication, mimesis, design inquiry, performance, digital craft},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858486,
author = {M\'{a}rquez Segura, Elena and Turmo Vidal, Laia and Rostami, Asreen and Waern, Annika},
title = {Embodied Sketching},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858486},
doi = {10.1145/2858036.2858486},
abstract = {Designing bodily experiences is challenging. In this paper, we propose embodied sketching
as a way of practicing design that involves understanding and designing for bodily
experiences early in the design process. Embodied sketching encompasses ideation methods
that are grounded in, and inspired by, the lived experience and includes the social
and spatial settings as design resources in the sketching. Embodied sketching is also
based on harnessing play and playfulness as the principal way to elicit creative physical
engagement. We present three different ways to implement and use embodied sketching
in the application domain of co-located social play. These include bodystorming of
ideas, co-designing with users, and sensitizing designers. The latter helps to uncover
and articulate significant, as well as novel embodied experiences, whilst the first
two are useful for developing a better understanding of possible design resources.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {6014–6027},
numpages = {14},
keywords = {sensitizing, embodied interaction, design methods, ideation, embodied sketching, bodystorming, somaesthetics},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858192,
author = {Devendorf, Laura and Lo, Joanne and Howell, Noura and Lee, Jung Lin and Gong, Nan-Wei and Karagozler, M. Emre and Fukuhara, Shiho and Poupyrev, Ivan and Paulos, Eric and Ryokai, Kimiko},
title = {"I Don't Want to Wear a Screen": Probing Perceptions of and Possibilities for Dynamic Displays on Clothing},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858192},
doi = {10.1145/2858036.2858192},
abstract = {This paper explores the role dynamic textile displays play in relation to personal
style: What does it mean to wear computationally responsive clothing and why would
one be motivated to do so? We developed a novel textile display technology, called
Ebb, and created several woven and crochet fabric swatches that explored clothing-specific
design possibilities. We engaged fashion designers and non-designers in imagining
how Ebb would integrate into their design practice or personal style of dressing.
Participants evaluated the appeal and utility of clothing-based displays according
to a very different set of criteria than traditional screen-based computational displays.
Specifically, the slowness, low-resolution, and volatility of Ebb tended to be seen
as assets as opposed to technical limitations in the context of personal style. Additionally,
participants envisioned various ways that ambiguous, ambient, and abstract displays
of information could prompt new experiences in their everyday lives. Our paper details
the complex relationships between display and personal style and offers a new design
metaphor and extension of Gaver et al.'s original descriptions of ambiguity in order
to guide the design of clothing-based displays for everyday life.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {6028–6039},
numpages = {12},
keywords = {dynamic textiles, ambiguity, clothing-based display, crochet, weaving, style},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858561,
author = {Shin, Jaemyung and Kang, Bumsoo and Park, Taiwoo and Huh, Jina and Kim, Jinhan and Song, Junehwa},
title = {BeUpright: Posture Correction Using Relational Norm Intervention},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858561},
doi = {10.1145/2858036.2858561},
abstract = {Research shows the critical role of social relationships in behavior change, and the
advancement of mobile technologies brings new opportunities of using online social
support for persuasive applications. In this paper, we propose Relational Norm Intervention
(RNI) model for behavior change, which involves two individuals as a target user and
a helper respectively. RNI model uses Negative Reinforcement and Other-Regarding Preferences
as motivating factors for behavior change. The model features the passive participation
of a helper who will undergo artificially generated discomforts (e.g., limited access
to a mobile device) when a target user performs against a target behavior. Based on
in-depth discussions from a two-phase design workshop, we designed and implemented
BeUpright, a mobile application employing RNI model to correct sitting posture of
a target user. Also, we conducted a two-week study to evaluate the effectiveness and
user experience of BeUpright. The study showed that the RNI model has a potential
to increase efficacy, in terms of behavior change, compared to conventional notification
approaches. The most influential factor of RNI model in the changing the behavior
of target users was the intention to avoid discomforting their helpers. RNI model
also showed a potential to help unmotivated individuals in behavior change. We discuss
the mechanism of the RNI model in relation to prior literature on behavior change
and implications of exploiting discomfort in mobile behavior change services.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {6040–6052},
numpages = {13},
keywords = {relational norm intervention, posture correction, negative reinforcement, other-regarding preferences, behavior change, social persuasion},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858538,
author = {Leigh, Sang-won and Maes, Pattie},
title = {Body Integrated Programmable Joints Interface},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858538},
doi = {10.1145/2858036.2858538},
abstract = {Physical interfaces with actuation capability enable the design of wearable devices
that augment human physical capabilities. Extra machine joints integrated to our biological
body may allow us to achieve additional skills through programmatic reconfiguration
of the joints. To that end, we present a wearable multi-joint interface that offers
"synergistic interactions" by providing additional fingers, structural supports, and
physical user interfaces. Motions of the machine joints can be controlled via interfacing
with our muscle signals, as a direct extension of our body. On the basis of implemented
applications, we demonstrate our design guidelines for creating a desirable human-machine
synergy -- that enhances our innate capabilities, not replacing or obstructing, and
also without enforcing the augmentation. Finally we describe technical details of
our muscle-based control method and implementations of the presented applications.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {6053–6057},
numpages = {5},
keywords = {synergistic interaction, programmable joints interface},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858282,
author = {Saakes, Daniel and Yeo, Hui-Shyong and Noh, Seung-Tak and Han, Gyeol and Woo, Woontack},
title = {Mirror Mirror: An On-Body T-Shirt Design System},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858282},
doi = {10.1145/2858036.2858282},
abstract = {Virtual fitting rooms equipped with magic mirrors let people evaluate fashion items
without actually putting them on. The mirrors superimpose virtual clothes on the user's
reflection. We contribute the Mirror Mirror system, which not only supports mixing
and matching of existing fashion items, but also lets users design new items in front
of the mirror and export designs to fabric printers. While much of the related work
deals with interactive cloth simulation on live user data, we focus on collaborative
design activities and explore various ways of designing on the body with a mirror.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {6058–6063},
numpages = {6},
keywords = {magic mirror, design interface, fashion, augmented reality},
location = {San Jose, California, USA},
series = {CHI '16}
}


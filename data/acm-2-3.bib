@inproceedings{10.1145/3313831.3376624,
author = {Smith-Renner, Alison and Fan, Ron and Birchfield, Melissa and Wu, Tongshuang and Boyd-Graber, Jordan and Weld, Daniel S. and Findlater, Leah},
title = {No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376624},
doi = {10.1145/3313831.3376624},
abstract = {Automatically generated explanations of how machine learning (ML) models reason can
help users understand and accept them. However, explanations can have unintended consequences:
promoting over-reliance or undermining trust. This paper investigates how explanations
shape users' perceptions of ML models with or without the ability to provide feedback
to them: (1) does revealing model flaws increase users' desire to "fix" them; (2)
does providing explanations cause users to believe - wrongly - that models are introspective,
and will thus improve over time. Through two controlled experiments - varying model
quality - we show how the combination of explanations and user feedback impacted perceptions,
such as frustration and expectations of model improvement. Explanations without opportunity
for feedback were frustrating with a lower quality model, while interactions between
explanation and feedback for the higher quality model suggest that detailed feedback
should not be requested without explanation. Users expected model correction, regardless
of whether they provided feedback or received explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive machine learning, explainable machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376625,
author = {Rajcic, Nina and McCormack, Jon},
title = {Mirror Ritual: An Affective Interface for Emotional Self-Reflection},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376625},
doi = {10.1145/3313831.3376625},
abstract = {This paper introduces a new form of real-time affective interface that engages the user in a process of conceptualisation of their emotional state. Inspired by Barrett's Theory of Constructed Emotion, 'Mirror Ritual' aims to expand upon the user's accessible emotion concepts, and to ultimately provoke emotional reflection and regulation. The interface uses classified emotions – obtained through facial expression recognition -- as a basis for dynamically generating poetry. The perceived emotion is used to seed a poetry generation system based on OpenAI's GPT-2 model, fine-tuned on a specially curated corpus. We evaluate the device's ability to foster a personalised, meaningful experience for individual users over a sustained period. A qualitative analysis revealed that participants were able to affectively engage with the mirror, with each participant developing a unique interpretation of its poetry in the context of their own emotional landscape.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {computational creativity, affective computing, generative networks, emotion, theory of constructed emotion, affective interface, poetry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376626,
author = {von Willich, Julius and Schmitz, Martin and M\"{u}ller, Florian and Schmitt, Daniel and M\"{u}hlh\"{a}user, Max},
title = {Podoportation: Foot-Based Locomotion in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376626},
doi = {10.1145/3313831.3376626},
abstract = {Virtual Reality (VR) allows for infinitely large environments. However, the physical
traversable space is always limited by real-world boundaries. This discrepancy between
physical and virtual dimensions renders traditional locomotion methods used in real
world unfeasible. To alleviate these limitations, research proposed various artificial
locomotion concepts such as teleportation, treadmills, and redirected walking. However,
these concepts occupy the user's hands, require complex hardware or large physical
spaces. In this paper, we contribute nine VR locomotion concepts for foot-based locomotion,
relying on the 3D position of the user's feet and the pressure applied to the sole
as input modalities. We evaluate our concepts and compare them to state-of-the-art
point &amp; teleport technique in a controlled experiment with 20 participants. The results
confirm the viability of our approaches for foot-based and engaging locomotion. Further,
based on the findings, we contribute a wireless hardware prototype implementation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {locomotion, foot-based input, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376627,
author = {Hodge, James and Foley, Sarah and Brankaert, Rens and Kenning, Gail and Lazar, Amanda and Boger, Jennifer and Morrissey, Kellie},
title = {Relational, Flexible, Everyday: Learning from Ethics in Dementia Research},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376627},
doi = {10.1145/3313831.3376627},
abstract = {Engaging in participatory research in HCI raises numerous ethical complexities such
as consent, researcher relationships, and participant compensation. Doing HCI work
in the area of dementia amplifies these issues, and researchers in this area are modelling
ethical stances to ensure researcher-participant relationships focus on meaningful
engagement and care. This paper presents an insight into the kinds of ethical foci
required when doing design research with people living with dementia and their carers.
We interviewed 22 HCI researchers with experience working in dementia care contexts.
Our qualitative analysis outlines subsequent lessons-learned, such as recognition
of the participants, self-care, research impact, and subjectivity in ethical review
boards. Furthermore, we found the complexity of navigating both "everyday" and more
formal, institutional ethics in dementia research has implications beyond the context
of working with people with dementia and outline key considerations for ethical practices
in socially orientated HCI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {dementia, ethics, care, relational, emotion, lived experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376628,
author = {Drey, Tobias and Gugenheimer, Jan and Karlbauer, Julian and Milo, Maximilian and Rukzio, Enrico},
title = {VRSketchIn: Exploring the Design Space of Pen and Tablet Interaction for 3D Sketching in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376628},
doi = {10.1145/3313831.3376628},
abstract = {Sketching in virtual reality (VR) enhances perception and understanding of 3D volumes,
but is currently a challenging task, as spatial input devices (e.g., tracked controllers)
do not provide any scaffolding or constraints for mid-air interaction. We present
VRSketchIn, a VR sketching application using a 6DoF-tracked pen and a 6DoF-tracked
tablet as input devices, combining unconstrained 3D mid-air with constrained 2D surface-based
sketching. To explore what possibilities arise from this combination of 2D (pen on
tablet) and 3D input (6DoF pen), we present a set of design dimensions and define
the design space for 2D and 3D sketching interaction metaphors in VR. We categorize
prior art inside our design space and implemented a subset of metaphors for pen and
tablet sketching in our prototype. To gain a deeper understanding which specific sketching
operations users perform with 2D and which with 3D metaphors, we present findings
of usability walkthroughs with six participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sketching, interaction metaphors, design space, pen and tablet, virtual reality, mid-air painting},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376631,
author = {Garg, Radhika and Sengupta, Subhasree},
title = {Conversational Technologies for In-Home Learning: Using Co-Design to Understand Children's and Parents' Perspectives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376631},
doi = {10.1145/3313831.3376631},
abstract = {Today, Conversational Agents (CA) are deeply integrated into the daily lives of millions
of families, which has led children to extensively interact with such devices. Studies
have suggested that the social nature of CA makes them a good learning companion for
children. Therefore, to understand children's preferences for the use of CAs for the
purpose of in-home learning, we conducted three participatory design sessions. In
order to identify parents' requirements in this regard, we also included them in the
third session. We found that children expect such devices to possess a personality
and an advanced level of intelligence, and support multiple content domains and learning
modes and human-like conversations. Parents desire such devices to include them in
their children's learning activities, foster social engagement, and to allow them
to monitor their children's use. This understanding will inform the design of future
CAs for the purpose of in-home learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {learning, conversational agents, parents, cooperative inquiry, learning companion, participatory design, children, home, co-design, learning technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376632,
author = {Obada-Obieh, Borke and Huang, Yue and Beznosov, Konstantin},
title = {The Burden of Ending Online Account Sharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376632},
doi = {10.1145/3313831.3376632},
abstract = {Many people share online accounts, even in situations where high privacy and security
are expected. Naturally, the sharing of these accounts does not endure forever. This
paper reports the privacy and security challenges that people experience when they
stop online account sharing. We conducted semi-structured interviews with 25 participants
who stopped sharing at least one online account in the 12 months preceding the study.
Our results suggest that users experience cognitive and psychosocial burdens when
ending account sharing. We offer suggestions for how to improve the design of online
accounts to support users better when they end account sharing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {usable security and privacy, online shared accounts},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376633,
author = {Tseng, Emily and Okeke, Fabian and Sterling, Madeline and Dell, Nicola},
title = {"We Can Learn. Why Not?": Designing Technologies to Engender Equity for Home Health Aides},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376633},
doi = {10.1145/3313831.3376633},
abstract = {HCI researchers have increasingly studied how technology might improve the lives of
marginalized workers. We explored this question through a qualitative study with home
health aides in New York City, a vulnerable group of frontline caregivers whose work
with patients is poorly paid and highly stressful, often involving life-or-death situations.
To elicit the perspectives of aides and their supervisors on how technology interventions
might contribute to moving aides towards a better future, we created a design provocation
that centers aides' needs and suggests more equitable roles for them within the home
care ecosystem. Findings from design sessions with 16 aides, nurses, and aide coordinators
illuminate the ethical and pragmatic dilemmas inherent in this complex ecosystem,
and show that designing technology for equity requires attention to structural problems
in addition to workers' stated needs. We analyze our findings through the lens of
social justice-oriented interaction design, and discuss how our work extends key strategies
within this framework.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {home care, design for social justice, home health aides, design provocation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376634,
author = {Kow, Yong Ming and Nardi, Bonnie and Cheng, Wai Kuen},
title = {Be Water: Technologies in the Leaderless Anti-ELAB Movement in Hong Kong},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376634},
doi = {10.1145/3313831.3376634},
abstract = {We examine a leaderless social movement characterized by participants' autonomy and
the absence of leaders and organizations. We conducted a participant observation study
of the Anti-ELAB movement in Hong Kong. Focusing on the organization of a protest
march, we collected thousands of lines of discourse in the LIHKG Forum and the Telegram
instant messaging system. Our grounded theory analysis revealed hundreds of groups
acting within a symbiotic network. Participants promoted an ethos of empowering individual
participants and groups to act autonomously. At the same time, participants' extensive
use of hyperlinks and polls orchestrated a coherent social movement. We discuss how
this novel formation can mediate successful leaderless movements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {hong kong, leaderless social movement, anti-elab, ethnography},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376635,
author = {E, Jane L. and Fried, Ohad and Lu, Jingwan and Zhang, Jianming and Mech, Radom\'{\i}r and Echevarria, Jose and Hanrahan, Pat and Landay, James A.},
title = {Adaptive Photographic Composition Guidance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376635},
doi = {10.1145/3313831.3376635},
abstract = {Photographic composition is often taught as alignment with composition grids-most
commonly, the rule of thirds. Professional photographers use more complex grids, like
the harmonic armature, to achieve more diverse dynamic compositions. We are interested
in understanding whether these complex grids are helpful to amateurs.In a formative
study, we found that overlaying the harmonic armature in the camera can help less
experienced photographers discover and achieve different compositions, but it can
also be overwhelming due to the large number of lines. Photographers actually use
subsets of lines from the armature to explain different aspects of composition. However,
this occurs mainly offline to analyze existing images. We propose bringing this mental
model into the camera-by adaptively highlighting relevant lines to the current scene
and point of view. We describe a saliency-based algorithm for selecting these lines
and present an evaluation of the system that shows that photographers found the proposed
adaptive armatures helpful for capturing more well-composed images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {composition, camera interfaces, photography, dynamic symmetry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376636,
author = {Sabie, Dina and Sabie, Samar and Ahmed, Syed Ishtiaque},
title = {Memory through Design: Supporting Cultural Identity for Immigrants through a Paper-Based Home Drafting Tool},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376636},
doi = {10.1145/3313831.3376636},
abstract = {Current research in HCI with immigrants predominantly focuses on their practical needs
and little attention is given to their cultural identities. As such, we aim to understand
how newcomers reflect their cultural values within domestic settings. We explore this
by provoking memories immigrants associate with physical spaces inside their homes.
Hence, we built "Our Home Sketcher": a paper-based home drafting tool that allows
novice users to design their homes by sketching and implicitly expressing their space,
light, and privacy preferences. The collected drawings are then fed into a computer
algorithm that produces 3D models of the sketched houses. This process of design acts
as an artifact-driven storytelling for heritage sharing and rapport building within
migrant communities. We engage 13 Middle Eastern newcomers in Canada with the tool
and use Halbwachs' [44] theory of collective memory to frame how home sketching provokes
former experiences. Our findings show a strong longing for reclaiming the past, narrating
space-related oral history, and designing beyond current limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {2d sketching, culture, hci, house design, ictd, immigrants, memory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376637,
author = {Nebeling, Michael and Lewis, Katy and Chang, Yu-Cheng and Zhu, Lihan and Chung, Michelle and Wang, Piaoyang and Nebeling, Janet},
title = {XRDirector: A Role-Based Collaborative Immersive Authoring System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376637},
doi = {10.1145/3313831.3376637},
abstract = {Immersive authoring is an increasingly popular technique to design AR/VR scenes because
design and testing can be done concurrently. Most existing systems, however, are single-user
and limited to either AR or VR, thus constrained in the interaction techniques. We
present XRDirector, a role-based collaborative immersive authoring system that enables
designers to freely express interactions using AR and VR devices as puppets to manipulate
virtual objects in 3D physical space. In XRDirector, we adapt roles known from filmmaking
to structure the authoring process and help coordinate multiple designers in immersive
authoring tasks. We study how novice AR/VR creators can take advantage of the roles
and modes in XRDirector to prototype complex scenes with animated 3D characters, light
effects, and camera movements, and also simulate interactive system behavior in a
Wizard of Oz style. XRDirector's design was informed by case studies around complex
3D movie scenes and AR/VR games, as well as workshops with novice AR/VR creators.
We show that XRDirector makes it easier and faster to create AR/VR scenes without
the need for coding, characterize the issues in coordinating designers between AR
and VR, and identify the strengths and weaknesses of each role and mode to mitigate
the issues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mixed-reality collaboration, immersive authoring, ar/vr},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376638,
author = {De-Arteaga, Maria and Fogliato, Riccardo and Chouldechova, Alexandra},
title = {A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous Algorithmic Scores},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376638},
doi = {10.1145/3313831.3376638},
abstract = {The increased use of algorithmic predictions in sensitive domains has been accompanied
by both enthusiasm and concern. To understand the opportunities and risks of these
technologies, it is key to study how experts alter their decisions when using such
tools. In this paper, we study the adoption of an algorithmic tool used to assist
child maltreatment hotline screening decisions. We focus on the question: Are humans
capable of identifying cases in which the machine is wrong, and of overriding those
recommendations? We first show that humans do alter their behavior when the tool is
deployed. Then, we show that humans are less likely to adhere to the machine's recommendation
when the score displayed is an incorrect estimate of risk, even when overriding the
recommendation requires supervisory approval. These results highlight the risks of
full automation and the importance of designing decision pipelines that provide humans
with autonomy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {algorithm assisted decision making, child welfare, algorithm aversion, decision support, human-in-the-loop, automation bias},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376639,
author = {Zindulka, Tim and Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Performance and Experience of Throwing in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376639},
doi = {10.1145/3313831.3376639},
abstract = {Throwing is a fundamental movement in many sports and games. Given this, accurate
throwing in VR applications today is surprisingly difficult. In this paper we explore
the nature of the difficulties of throwing in VR in more detail. We present the results
of a user study comparing throwing in VR and in the physical world. In a short pre-study
with 3 participants we determine an optimal number of throwing repetitions for the
main study by exploring the learning curve and subjective fatigue of throwing in VR.
In the main study, with 12 participants, we find that throwing precision and accuracy
in VR are lower particularly in the distance and height dimensions. It also requires
more effort and exhibits different kinematic patterns.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {throwing, virtual reality, user study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376640,
author = {Gorichanaz, Tim},
title = {Engaging with Public Art: An Exploration of the Design Space},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376640},
doi = {10.1145/3313831.3376640},
abstract = {At its best, public art can promote moral learning in individuals and societies, and
digital technology can help achieve this value. As a first step in creating such systems,
this paper presents a probe study exploring the design space of reflective engagement
with public art. The probe took the form of a mural journal, which was distributed
to participants in Philadelphia. The findings show how public art journaling can be
integrated into one's life, both logistically and psychologically, and the value of
art journaling for introspection, cultivating attention and having fun. This study
surfaces a number of tensions in the design space that designers must navigate, such
as the question of reflecting with public art on site (now) versus at home (later).
This work provides designers with the grounds for informed inspiration to ideate systems
that deepen people's experiences with public art.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design probe, reflection, public art, moral learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376641,
author = {Khan, Taslim Arefin and Yoon, Dongwook and McGrenere, Joanna},
title = {Designing an Eyes-Reduced Document Skimming App for Situational Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376641},
doi = {10.1145/3313831.3376641},
abstract = {Listening to text using read-aloud applications is a popular way for people to consume
content when their visual attention is situationally impaired (e.g., commuting, walking,
tired eyes). However, due to the linear nature of audio, such apps do not support
skimming---a non-linear, rapid form of reading---essential for quickly grasping the
gist and organization of difficult texts, like academic or professional documents.
To support auditory skimming for situational impairments, we (1) identified the user
needs and challenges in auditory skimming through a formative study (N=20), (2) derived
the concept of "eyes-reduced" skimming that blends auditory and visual modes of reading,
inspired by how participants mixed visual and non-visual interactions, (3) generated
a set of design guidelines for eyes-reduced skimming, and (4) designed and evaluated
a novel audio skimming app that embodies the guidelines. Our in-situ preliminary observation
study (N=6) suggested that participants were positive about our design and were able
to auditorily skim documents. We discuss design implications for eyes-reduced reading,
read-aloud apps, and text-to-speech engines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {situational impairments, interactive prototype, eyes-reduced, mobile device, eyes-free, design guidelines, accessibility, text-to-speech, skim reading},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376642,
author = {Wang, Cheng Yao and Sakashita, Mose and Ehsan, Upol and Li, Jingjin and Won, Andrea Stevenson},
title = {Again, Together: Socially Reliving Virtual Reality Experiences When Separated},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376642},
doi = {10.1145/3313831.3376642},
abstract = {To share a virtual reality (VR) experience remotely together, users usually record
videos from an individual's point of view and then co-watch these videos. However,
co-watching recorded videos limits users to reliving their memories from the perspective
from which the video was captured. In this paper, we describe ReliveInVR, a new time-machine-like
VR experience sharing method. ReliveInVR allows multiple users to immerse themselves
in the relived experience together and independently view the experience from any
perspective. We conducted a 1x3 within-subject study with 26 dyads to compare ReliveInVR
with (1) co-watching 360-degree videos on desktop, and (2) co-watching 360-degree
videos in VR. Our results suggest that participants reported higher levels of immersion
and social presence in ReliveInVR. Participants in ReliveInVR also understood the
shared experience better, discovered unnoticed things together and found the sharing
experience more fulfilling. We discuss the design implications for sharing VR experiences
over time and space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social, replay, shared experience, presence, immersion, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376643,
author = {Frey, J\'{e}r\'{e}my and Ostrin, Gilad and Grabli, May and Cauchard, Jessica R.},
title = {Physiologically Driven Storytelling: Concept and Software Tool},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376643},
doi = {10.1145/3313831.3376643},
abstract = {We put forth Physiologically Driven Storytelling, a new approach to interactive storytelling
where narratives adaptively unfold based on the reader's physiological state. We first
describe a taxonomy framing how physiological signals can be used to drive interactive
systems both as input and output. We then propose applications to interactive storytelling
and describe the implementation of a software tool to create Physiological Interactive
Fiction (PIF). The results of an online study (N=140) provided guidelines towards
augmenting the reading experience. PIF was then evaluated in a lab study (N=14) to
determine how physiological signals can be used to infer a reader's state. Our results
show that breathing, electrodermal activity, and eye tracking can help differentiate
positive from negative tones, and monotonous from exciting events. This work demonstrates
how PIF can support storytelling in creating engaging content and experience tailored
to the reader. Moreover, it opens the space to future physiologically driven systems
within broader application areas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {storytelling, physiology, physiological computing, interactive fiction, affective computing, taxonomy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376644,
author = {Park, So Yeon and Moore, Dylan James and Sirkin, David},
title = {What a Driver Wants: User Preferences in Semi-Autonomous Vehicle Decision-Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376644},
doi = {10.1145/3313831.3376644},
abstract = {Autonomous vehicle (AV) systems are developing at a rapid pace, not only in technological
capabilities, but also in human-centered directions. Despite this development, we
lack a nuanced understanding of driver preference in decision scenarios that semi-AVs
will face, and of possible misalignment between semi-AV decisions and user preference.
Using an online survey, we explore how participants would like semi-AVs to act and
alert them of the vehicles' decisions in various scenarios. Participants reported
varying levels of comfort with autonomy, desire to takeover control, and desire for
AV informing. Individual differences, including level of experience with autonomy
and situation awareness, affected perceptions of the vehicle. Our results highlight
the importance of considering driver preference in AV decision-making, and we present
an influence diagram that situates this factor among others. We also derive five design
principles, including that a previous positive AV experience can lead to more harmful
consequences for AVs when not aligned with driver preference.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online study, driver preferences, autonomous vehicles, decision-making, notifications, transition of control},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376645,
author = {Rubin, Jennifer D. and Blackwell, Lindsay and Conley, Terri D.},
title = {Fragile Masculinity: Men, Gender, and Online Harassment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376645},
doi = {10.1145/3313831.3376645},
abstract = {Harassment is a persistent problem in contemporary online environments, with women
disproportionately experiencing its most severe forms. While critical scholars posit
that online gender harassment may be linked to men's anxieties about fulfilling normative
masculine gender roles, this relationship has not been examined by empirical research.
We survey 264 young men between the ages of 18-24 about their masculinity anxieties
and their perceptions of harassment directed at a woman on Twitter. We find that men
who perceive themselves as less masculine than average men report higher endorsement
of harassment. Further, we find that the relationship between masculinity anxieties
and harassment endorsement is mediated by men's adherence to masculine norms and toxic
disinhibition. We interpret these results through the lens of social media's specific
affordances, and we discuss their implications for technology designers and other
practitioners who wish to better detect, prevent, and remediate online harassment
by accounting for the role of gender.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {misogyny, social media, masculinity, gender, online harassment, women},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376646,
author = {Menon, Sanju and Zhang, Weiyu and Perrault, Simon T.},
title = {Nudge for Deliberativeness: How Interface Features Influence Online Discourse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376646},
doi = {10.1145/3313831.3376646},
abstract = {Cognitive load is a significant challenge to users for being deliberative. Interface
design has been used to mitigate this cognitive state. This paper surveys literature
on the anchoring effect, partitioning effect and point-of-choice effect, based on
which we propose three interface nudges, namely, the word-count anchor, partitioning
text fields, and reply choice prompt. We then conducted a 2\texttimes{}2\texttimes{}2 factorial experiment
with 80 participants (10 for each condition), testing how these nudges affect deliberativeness.
The results showed a significant positive impact of the word-count anchor. There was
also a significant positive impact of the partitioning text fields on the word count
of response. The reply choice prompt showed a surprisingly negative affect on the
quantity of response, hinting at the possibility that the reply choice prompt induces
a fear of evaluation, which could in turn dampen the willingness to reply.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online discussion, portioning text fields, reply choice prompt, word count, nudges, deliberativeness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376647,
author = {Gautam, Aakash and Tatar, Deborah and Harrison, Steve},
title = {Crafting, Communality, and Computing: Building on Existing Strengths To Support a Vulnerable Population},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376647},
doi = {10.1145/3313831.3376647},
abstract = {In Nepal, sex-trafficking survivors and the organizations that support them have limited resources to assist the survivors in their on-going journey towards reintegration. We take an asset-based approach wherein we identify and build on the strengths possessed by such groups. In this work, we present reflections from introducing a voice-annotated web application to a group of survivors. The web application tapped into and built upon two elements of pre-existing strengths possessed by the survivors — the social bond between them and knowledge of crafting as taught to them by the organization. Our findings provide insight into the array of factors influencing how the survivors act in relation to one another as they created novel use practices and adapted the technology. Experience with the application seemed to open knowledge of computing as a potential source of strength. Finally, we articulate three design desiderata that could help promote communal spaces: make activity perceptible to the group, create appropriable steps, and build in fun choices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {global south, communal space, sensitive setting, asset-based, ictd, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376648,
author = {Unbehaun, David and Aal, Konstantin and Vaziri, Daryoush Daniel and Tolmie, Peter David and Wieching, Rainer and Randall, David and Wulf, Volker},
title = {Social Technology Appropriation in Dementia: Investigating the Role of Caregivers in Engaging People with Dementia with a Videogame-Based Training System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376648},
doi = {10.1145/3313831.3376648},
abstract = {There has been increasing interest in designing for dementia in recent years. Empirical
investigation is now needed of the long-term role of caregivers in appropriating ICTs
into the complex daily life of people with dementia (PwD). We present here the outcomes
of a 4-month evaluation of the individual, social and institutional impact of a videogame-based
training system. The everyday behavior and interactions of 52 PwD and 25 caregivers
was studied qualitatively, focusing on the role played by caregivers in integrating
the system into daily routines. Our results indicate that the successful appropriation
of ICT for PwD depends partly on the physical, cognitive and social benefits for PwD,
but especially on the added value perceived by their social care-network. We discuss
the need for design in dementia to develop more socially embedded innovations that
can address the social actors involved and thus contribute to practical solutions
for professional and private care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {exergame, ICT, caregiver, appropriation, dementia, care},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376649,
author = {Glowacki, David R. and Wonnacott, Mark D. and Freire, Rachel and Glowacki, Becca R. and Gale, Ella M. and Pike, James E. and de Haan, Tiu and Chatziapostolou, Mike and Metatla, Oussama},
title = {Isness: Using Multi-Person VR to Design Peak Mystical Type Experiences Comparable to Psychedelics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376649},
doi = {10.1145/3313831.3376649},
abstract = {Studies combining psychotherapy with psychedelic drugs (Ds) have demonstrated positive
outcomes that are often associated with 'Ds' ability to induce 'mystical-type' experiences
(MTEs) i.e., subjective experiences whose characteristics include a sense of connectedness,
transcendence, and ineffability. We suggest that both PsiDs and virtual reality can
be situated on a broader spectrum of psychedelic technologies. To test this hypothesis,
we used concepts, methods, and analysis strategies from D research to design and evaluate 'Isness', a multi-person VR journey where participants experience the collective emergence,
fluctuation, and dissipation of their bodies as energetic essences. A study (N=57)
analyzing participant responses to a commonly used D experience questionnaire (MEQ30)
indicates that Isness participants reported MTEs comparable to those reported in double-blind
clinical studies after high doses of psilocybin and LSD. Within a supportive setting
and conceptual framework, VR phenomenology can create the conditions for MTEs from
which participants derive insight and meaning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mystical-type experiences, psychedelic drugs, user experience, altered states, meaning in HCI, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376650,
author = {Richardson, Dan and Kharrufa, Ahmed},
title = {We Are the Greatest Showmen: Configuring a Framework for Project-Based Mobile Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376650},
doi = {10.1145/3313831.3376650},
abstract = {Little research has explored how mobile-learning technologies could be used by students
to produce interactive artefacts during project-based learning processes. Following
a design-based approach, we report on engagements spanning classroom and outdoor learning
with students (ages 6-13) and teachers from three different UK schools and a summer
school of Travelling Showchildren. Working within the time constraints of each context,
we deployed a variety of configurations of a project-based mobile learning (PBML)
framework intended to support the production of student-designed mobile-learning activities.
We contribute insights gained from these engagements, including how mobile technologies
can harness students' existing desire for independence and how they can be configured
to leverage the physical and social attributes of place and community as learning
resources. We argue for further exploration of the potential roles for mobile technologies
within project-based learning, and contribute our PBML framework with recommendations
for its re-configuration in response to contextual constraints.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {digital civics, project-based learning, mobile-learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376651,
author = {Gabriele, Sandra and Chiasson, Sonia},
title = {Understanding Fitness Tracker Users' Security and Privacy Knowledge, Attitudes and Behaviours},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376651},
doi = {10.1145/3313831.3376651},
abstract = {Personal data collected by fitness trackers can leave users open to security and privacy
threats, often without their knowledge. Using an online survey with 212 fitness tracker
users, we asked questions to understand participants' knowledge, attitudes and behaviours
related to security and privacy, associated with the use of their fitness trackers.
We found that users do little to protect their data. While they seem confident about
the type of data being collected, they are unsure about how it is being used. Understandably,
users are more comfortable sharing their data with friends and work colleagues. We
also found that users differentiate between the types of data they are willing to
share, suggesting a need for improved sharing preferences. When considering scenarios
describing data uses with security and privacy implications, participants recognized
that many scenarios were plausible but frequently felt that the scenarios were unlikely
to occur. Overall, our findings lead us to believe that fitness tracker users require
a greater awareness of the collection, ownership, storage, and sharing practices related
to the tracking of their data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data sharing, fitness trackers, online, privacy, survey},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376652,
author = {Jetter, Hans-Christian and R\"{a}dle, Roman and Feuchtner, Tiare and Anthes, Christoph and Friedl, Judith and Klokmose, Clemens Nylandsted},
title = {"In VR, Everything is Possible!": Sketching and Simulating Spatially-Aware Interactive Spaces in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376652},
doi = {10.1145/3313831.3376652},
abstract = {We propose using virtual reality (VR) as a design tool for sketching and simulating
spatially-aware interactive spaces. Using VR, designers can quickly experience their
envisioned spaces and interactions by simulating technologies such as motion tracking,
multiple networked devices, or unusual form factors such as spherical touchscreens
or bezel-less display tiles. Design ideas can be rapidly iterated without restrictions
by the number, size, or shape and availability of devices or sensors in the lab. To
understand the potentials and challenges of designing in VR, we conducted a user study
with 12 interaction designers. As their tool, they used a custom-built virtual design
environment with finger tracking and physics simulations for natural interactions
with virtual devices and objects. Our study identified the designers' experience of
space in relation to their own bodies and playful design explorations as key opportunities.
Key challenges were the complexities of building a usable yet versatile VR-based "World
Editor".},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {design tools, sketching, interaction design, prototyping, spatial awareness, interactive spaces, simulation, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376653,
author = {Tuli, Anupriya and Chopra, Shaan and Singh, Pushpendra and Kumar, Neha},
title = {Menstrual (Im)Mobilities and Safe Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376653},
doi = {10.1145/3313831.3376653},
abstract = {In cultural contexts where menstruation is a stigmatized health topic, daily management
of menstrual hygiene comes with its set of challenges. Our research aims to identify
and examine such challenges faced during menstruation in the urban environs of Delhi,
India. Through participatory design activities and interviews conducted with 35 participants
who identified as menstruating and female, and a survey with 139 responses, we investigate
how participants deal with their periods on the go. We also examine participants'
conceptualizations of safe spaces, where they are able to deal with their period on
their own terms. Finally, we discuss how menstrual mobilities are being, and might
be, supported through technology-based interventions for a third space, targeting
the legibility, literacy, and legitimacy of surrounding environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {menstrual health, mobilities, menstruation, india, menstrual hygiene, safe spaces, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376654,
author = {G\'{o}mez-Zar\'{a}, Diego and Guo, Mengzi and DeChurch, Leslie A. and Contractor, Noshir},
title = {The Impact of Displaying Diversity Information on the Formation of Self-Assembling Teams},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376654},
doi = {10.1145/3313831.3376654},
abstract = {Despite the benefits of team diversity, individuals often choose to work with similar
others. Online team formation systems have the potential to help people assemble diverse
teams. Systems can connect people to collaborators outside their networks, and features
can quantify and raise the salience of diversity to users as they search for prospective
teammates. But if we build a feature indicating diversity into the tool, how will
people react to it? Two experiments manipulating the presence or absence of a "diversity
score" feature within a teammate recommender demonstrate that, when present, individuals
avoid collaborators who would increase team diversity in favor of those who lower
team diversity. These results have important practical implications. Though the increased
access to diverse teammates provided by recommender systems may benefit diversity,
designers are cautioned against creating features that raise the salience of diversity
as this information may undermine diversity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {diversity, social recommenders, mixed-effect logistic regressions, team formation, teams},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376655,
author = {Chang, Zekun and Ta, Tung D. and Narumi, Koya and Kim, Heeju and Okuya, Fuminori and Li, Dongchi and Kato, Kunihiro and Qi, Jie and Miyamoto, Yoshinobu and Saito, Kazuya and Kawahara, Yoshihiro},
title = {Kirigami Haptic Swatches: Design Methods for Cut-and-Fold Haptic Feedback Mechanisms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376655},
doi = {10.1145/3313831.3376655},
abstract = {Kirigami Haptic Swatches demonstrate how kirigami and origami based structures enable
sophisticated haptic feedback through simple cut-and-fold fabrication techniques.
We leverage four types of geometric patterns: rotational erection system (RES), split-fold
waterbomb (SFWB), the overlaid structure of SFWB and RES (SFWB+RES), and cylindrical
origami, to render different sets of haptic feedback (i.e. linear, bistable, bouncing
snap-through, and rotational force behaviors, respectively). In each structure, not
only the form factor but also the force feedback properties can be tuned through geometric
parameters. We experimentally analyzed and modeled the structures, and implemented
software to automatically generate 2D patterns for desired haptic properties. We also
demonstrate five example applications including an assistive custom keyboard, rotational
switch, multi-sensory toy, task checklist, and phone accessories. We believe the Kirigami
Haptic Swatches helps tinkerers, designers, and even researchers to create interactions
that enrich our haptic experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {haptics, design methods, computational fabrication, paper button, Kirigami structure},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376656,
author = {Uhde, Alarith and Schlicker, Nadine and Wallach, Dieter P. and Hassenzahl, Marc},
title = {Fairness and Decision-Making in Collaborative Shift Scheduling Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376656},
doi = {10.1145/3313831.3376656},
abstract = {The strains associated with shift work decrease healthcare workers' well-being. However,
shift schedules adapted to their individual needs can partially mitigate these problems.
From a computing perspective, shift scheduling was so far mainly treated as an optimization
problem with little attention given to the preferences, thoughts, and feelings of
the healthcare workers involved. In the present study, we explore fairness as a central,
human-oriented attribute of shift schedules as well as the scheduling process. Three
in-depth qualitative interviews and a validating vignette study revealed that while
on an abstract level healthcare workers agree on equality as the guiding norm for
a fair schedule, specific scheduling conflicts should foremost be resolved by negotiating
the importance of individual needs. We discuss elements of organizational fairness,
including transparency and team spirit. Finally, we present a sketch for fair scheduling
systems, summarizing key findings for designers in a readily usable way.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {roster, organizational justice, conflict resolution, nurse scheduling problem, interview, shift scheduling, allocation norms, fairness, healthcare, equality, equity, work-life balance, shift work, need, hospital},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376657,
author = {Wang, Xiyao and Besan\c{c}on, Lonni and Rousseau, David and Sereno, Mickael and Ammi, Mehdi and Isenberg, Tobias},
title = {Towards an Understanding of Augmented Reality Extensions for Existing 3D Data Analysis Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376657},
doi = {10.1145/3313831.3376657},
abstract = {We present an observational study with domain experts to understand how augmented
reality (AR) extensions to traditional PC-based data analysis tools can help particle
physicists to explore and understand 3D data. Our goal is to allow researchers to
integrate stereoscopic AR-based visual representations and interaction techniques
into their tools, and thus ultimately to increase the adoption of modern immersive
analytics techniques in existing data analysis workflows. We use Microsoft's HoloLens
as a lightweight and easily maintainable AR headset and replicate existing visualization
and interaction capabilities on both the PC and the AR view. We treat the AR headset
as a second yet stereoscopic screen, allowing researchers to study their data in a
connected multi-view manner. Our results indicate that our collaborating physicists
appreciate a hybrid data exploration setup with an interactive AR extension to improve
their understanding of particle collision events.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3D visualization, immersive analytics, hybrid visualization system, user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376658,
author = {Barbareschi, Giulia and Holloway, Catherine and Arnold, Katherine and Magomere, Grace and Wetende, Wycliffe Ambeyi and Ngare, Gabriel and Olenja, Joyce},
title = {The Social Network: How People with Visual Impairment Use Mobile Phones in Kibera, Kenya},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376658},
doi = {10.1145/3313831.3376658},
abstract = {Living in an informal settlement with a visual impairment can be very challenging
resulting in social exclusion. Mobile phones have been shown to be hugely beneficial
to people with sight loss in formal and high-income settings. However, little is known
about whether these results hold true for people with visual impairment (VIPs) in
informal settlements. We present the findings of a case study of mobile technology
use by VIPs in Kibera, an informal settlement in Nairobi. We used contextual interviews,
ethnographic observations and a co-design workshop to explore how VIPs use mobile
phones in their daily lives, and how this use influences the social infrastructure
of VIPs. Our findings suggest that mobile technology supports and shapes the creation
of social infrastructure. However, this is only made possible through the existing
support networks of the VIPs, which are mediated through four types of interaction:
direct, supported, dependent and restricted.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {ICT4D, participatory design, Kenya, Kibera, accessibility, informal settlements, HCI4D},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376659,
author = {Fernando, Piyum and Kuznetsov, Stacey},
title = {OScH in the Wild: Dissemination of Open Science Hardware and Implications for HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376659},
doi = {10.1145/3313831.3376659},
abstract = {Open Science Hardware (OScH) refers to open-source alternatives for proprietary scientific
equipment. While the OScH movement aims to reduce barriers for scientific experimentation
both in and beyond professional labs, disseminating OScH for widespread adoption proves
to be challenging in practice. To this end, we examined real-world practices related
to the dissemination of OScH through a two-part study. First, we developed an open
science hardware, a DIY incubator, and disseminated it through the Instructables website
and maker workshops. In parallel, we interviewed eight open science hardware practitioners
from different parts of the world. Insights from interviews together with our own
self-reflections revealed how different OScH dissemination modalities serve unique
purposes. Our findings also reveal several challenges for widespread adoption of OScH
and the importance of collaborations between OScH developers. We conclude by discussing
the opportunities for HCI to lower barriers for customization, support internationalization
of OScH, and scaffold proactive distributed collaborations between developers and
users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {open science hardware, diy, maker movement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376660,
author = {Cila, Nazli and Ferri, Gabriele and de Waal, Martijn and Gloerich, Inte and Karpinski, Tara},
title = {The Blockchain and the Commons: Dilemmas in the Design of Local Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376660},
doi = {10.1145/3313831.3376660},
abstract = {This paper addresses the design dilemmas that arise when distributed ledger technologies
(DLT) are to be applied in the governance of artificial material commons. DLTs, such
as blockchain, are often presented as enabling technologies for self-governing communities,
provided by their consensus mechanisms, transparent administration, and incentives
for collaboration and cooperation. Yet, these affordances may also undermine public
values such as privacy and displace human agency in governance procedures. In this
paper, the conflicts regarding the governance of communities which collectively manage
and produce a commons are discussed through the case of a fictional energy community.
Three mechanisms are identified in this process: tracking use of and contributions
to the commons; managing resources, and negotiating the underlying rule sets and user
rights. Our effort is aimed at contributing to the HCI community by introducing a
framework of three mechanisms and six design dilemmas that can aid in balancing conflicting
values in the design of local platforms for commons-based resource management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {blockchain, commons, governance, design dilemmas, platformization, energy community},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376661,
author = {Koulouris, Jordan and Jeffery, Zoe and Best, James and O'Neill, Eamonn and Lutteroth, Christof},
title = {Me vs. Super(Wo)Man: Effects of Customization and Identification in a VR Exergame},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376661},
doi = {10.1145/3313831.3376661},
abstract = {Customised avatars are a powerful tool to increase identification, engagement and
intrinsic motivation in digital games. We investigated the effects of customisation
in a self-competitive VR exergame by modelling players and their previous performance
in the game with customised avatars. In a first study we found that, similar to non-exertion
games, customisation significantly increased identification and intrinsic motivation,
as well as physical performance in the exergame. In a second study we identified a
more complex relationship with the customisation style: idealised avatars increased
wishful identification but decreased exergame performance compared to realistic avatars.
In a third study, we found that 'enhancing' realistic avatars with idealised characteristics
increased wishful identification, but did not have any adverse effects. We discuss
the findings based on feedforward and self-determination theory, proposing notions
of intrinsic identification (fostering a sense of self) and extrinsic identification
(drawing away from the self) to explain the results.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {feedforward, avatar customisation, identification, exergaming, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376662,
author = {Shipman, Frank M. and Marshall, Catherine C.},
title = {Ownership, Privacy, and Control in the Wake of Cambridge Analytica: The Relationship between Attitudes and Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376662},
doi = {10.1145/3313831.3376662},
abstract = {Has widespread news of abuse changed the public's perceptions of how user-contributed
content from social networking sites like Facebook and LinkedIn can be used? We collected
two datasets that reflect participants' attitudes about content ownership, privacy,
and control, one in April 2018, while Cambridge Analytica was still in the news, and
another in February 2019, after the event had faded from the headlines, and aggregated
the data according to participants' awareness of the story, contrasting the attitudes
of those who reported the greatest awareness with those who reported the least. Participants
with the greatest awareness of the news story's details have more polarized attitudes
about reuse, especially the reuse of content as data. They express a heightened desire
for data mobility, greater concern about networked privacy rights, increased skepticism
of algorithmically targeted advertising and news, and more willingness for social
media platforms to demand corrections of inaccurate or deceptive content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social media attitudes, ownership, cambridge analytica, data use, data monetization, facebook, linkedin, privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376663,
author = {Vella, Kellie and Oliver, Jessica L. and Dema, Tshering and Brereton, Margot and Roe, Paul},
title = {Ecology Meets Computer Science: Designing Tools to Reconcile People, Data, and Practices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376663},
doi = {10.1145/3313831.3376663},
abstract = {Ecoacoustics draws together computer scientists and ecologists to achieve an understanding
of ecosystems and wildlife using acoustic recordings of the environment. Computer
scientists are challenged to manage increasingly large datasets while developing analytic
and visualisation tools. Ecologists struggle to find and use tools that answer highly
heterogeneous research questions. These two fields are naturally drawn together at
the tool interface, however, less attention has been paid to how their practices influence
tool design and use. We interviewed and collected email correspondence from four computer
scientists and eight ecologists to learn how their practices indicate opportunities
for reconciling difference through design. We found that different temporal rhythms,
relationships to data, and data-driven questions demand tool configuration, data integration,
and standardisation. This research outlines interfacing opportunities for new ecological
research utilising large acoustic datasets, and also contributes to evolving HCI approaches
in areas making use of big data and human-in-the-loop processes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interface, interdisciplinary, ecology, design, computer science, ecoacoustics, human-computer interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376664,
author = {Prpa, Mirjana and Fdili-Alaoui, Sarah and Schiphorst, Thecla and Pasquier, Philippe},
title = {Articulating Experience: Reflections from Experts Applying Micro-Phenomenology to Design Research in HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376664},
doi = {10.1145/3313831.3376664},
abstract = {Third wave HCI initiated a slow transformation in the methods of UX research: from widely used quantitative approaches to more recently employed qualitative techniques. Articulating the nuances, complexity, and diversity of a user's experience beyond surface descriptions remains a challenge within design. One qualitative method — micro-phenomenology — has been used in HCI/Design research since 2001. Yet, no systematic understanding of micro-phenomenology has been presented, particularly from the perspective of HCI/Design researchers who actively use it in design contexts. We interviewed 5 HCI/Design experts who utilize micro-phenomenology and present their experiences with the method. We illustrate how this method has been applied by the selected experts through developing a practice, and present conditions under which the descriptions of the experience unfold, and the values that this method can provide to HCI/Design field. Our contribution highlights the value of micro-phenomenology in articulating the experience of designers and participants, developing vocabulary for multi-sensory experiences, and unfolding embodied tacit knowledge.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {micro-phenomenology, empirical methods, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376665,
author = {Kuzminykh, Anastasia and Sun, Jenny and Govindaraju, Nivetha and Avery, Jeff and Lank, Edward},
title = {Genie in the Bottle: Anthropomorphized Perceptions of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376665},
doi = {10.1145/3313831.3376665},
abstract = {This paper presents a qualitative multi-phase study seeking to identify patterns in
users' anthropomorphized perceptions of conversational agents. Through a comparative
analysis of behavioral perceptions and visual conceptions of three agents - Alexa,
Google Assistant, and Siri - we first show that the perceptions of an agent's character
are structured according to five categories: approachability, sentiment toward a user,
professionalism, intelligence, and individuality. We then explore visualizations of
the agents' appearance and discuss the specifics assigned to each agent. Finally,
we analyze associative explanations for these perceptions. We demonstrate that the
anthropomorphized behavioral and visual perceptions of agents yield structural consistency
and discuss how these perceptions are linked with each other and system features.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personification, conversational agents, user perception, visual, anthropomorphism, interaction, behavioral},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376666,
author = {Masaki, Hiroaki and Shibata, Kengo and Hoshino, Shui and Ishihama, Takahiro and Saito, Nagayuki and Yatani, Koji},
title = {Exploring Nudge Designs to Help Adolescent SNS Users Avoid Privacy and Safety Threats},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376666},
doi = {10.1145/3313831.3376666},
abstract = {A nudge is a method to influence individual choices without taking away freedom of
choice. We are interested in whether nudges can help adolescents avoid privacy and
safety threats on social network services (SNS). We conducted an online survey to
compare how 11 different nudge designs influence decisions on 9 scenarios featuring
various privacy and safety threats. We collected 29,608 responses from adolescent
SNS users (self-claimed high school and university students), and found that nudges
can help to educe potentially risk choices. Participants were more likely to avoid
potentially risky choices when presented with negative frames (e.g., "90% of users
would not share a photo without permission'') than affirmative ones (e.g., "10% of
users would''). Social nudges displaying statistics on how likely other people would
make potentially risky decisions can have a negative effect in comparison to a nudge
with only general privacy and safety suggestions. We conclude by providing design
considerations for privacy/safety nudges targeting adolescent SNS users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {adolescent sns users, large-scale survey, social nudges, online privacy and safety},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376667,
author = {Gelsomini, Mirko and Leonardi, Giulia and Garzotto, Franca},
title = {Embodied Learning in Immersive Smart Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376667},
doi = {10.1145/3313831.3376667},
abstract = {This paper presents the design and evaluation of IMAGINE, a novel interactive immersive
smart space for embodied learning. In IMAGINE children use full-body movements and
gestures to interact with multimedia educational contents projected on the wall and
on the floor, while synchronized light effects enhance immersivity. A controlled study
performed at a primary school with 48 children aged 6-8 highlights the educational
potential of an immersive embodied solution, also compared to traditional teaching
methods, and draws some implications for smart-space technology adoption in educational
contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {kinect, smart spaces, education, immersive environment, children, embodied learning, primary school},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376668,
author = {Rutten, Isa and Geerts, David},
title = {Better Because It's New: The Impact of Perceived Novelty on the Added Value of Mid-Air Haptic Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376668},
doi = {10.1145/3313831.3376668},
abstract = {Mid-air haptic (MAH) feedback, providing touch feedback through ultrasound, has been
considered an attractive substitute for the absence of physical touch during gesture-based
interaction. Although the impact of MAH feedback on workload has already received
some attention, the impact on other qualities of the user experience, including general
attractiveness and experienced pleasure have been less investigated. In this preregistered
study, involving 32 participants, we observed an added value of MAH feedback, on top
of visual feedback, by increasing the attractiveness and experienced pleasure during
gesture-based interaction, but not by decreasing workload. The added value regarding
pleasure and attractiveness disappeared however after statistically controlling for
perceived novelty. This paper highlights the importance of statistically controlling
for novelty when testing the user experience of new technology during first-time use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {novelty, mid-air haptic feedback, user experience, gesture-based interaction, workload, pleasure, attractiveness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376669,
author = {Haimson, Oliver L. and Gorrell, Dykee and Starks, Denny L. and Weinger, Zu},
title = {Designing Trans Technology: Defining Challenges and Envisioning Community-Centered Solutions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376669},
doi = {10.1145/3313831.3376669},
abstract = {Transgender and non-binary people face substantial challenges in the world, ranging
from social inequities and discrimination to lack of access to resources. Though technology
cannot fully solve these problems, technological solutions may help to address some
of the challenges trans people and communities face. We conducted a series of participatory
design sessions (total N = 21 participants) to understand trans people's most pressing
challenges and to involve this population in the design process. We detail four types
of technologies trans people envision: technologies for changing bodies, technologies
for changing appearances / gender expressions, technologies for safety, and technologies
for finding resources. We found that centering trans people in the design process
enabled inclusive technology design that primarily focused on sharing community resources
and prioritized connection between community members.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {non-binary, participatory design, safety, transgender, lgbtq+, resources, technology design, community},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376670,
author = {Huang, Gaoping and Rao, Pawan S. and Wu, Meng-Han and Qian, Xun and Nof, Shimon Y. and Ramani, Karthik and Quinn, Alexander J.},
title = {Vipo: Spatial-Visual Programming with Functions for Robot-IoT Workflows},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376670},
doi = {10.1145/3313831.3376670},
abstract = {Mobile robots and IoT (Internet of Things) devices can increase productivity, but
only if they can be programmed by workers who understand the domain. This is especially
true in manufacturing. Visual programming in the spatial context of the operating
environment can enable mental models at a familiar level of abstraction. However,
spatial-visual programming is still in its infancy; existing systems lack IoT integration
and fundamental constructs, such as functions, that are essential for code reuse,
encapsulation, or recursive algorithms. We present Vipo, a spatial-visual programming
system for robot-IoT workflows. Vipo was designed with input from managers at six
factories using mobile robots. Our user study (n=22) evaluated efficiency, correctness,
comprehensibility of spatial-visual programming with functions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {robots, internet of things, spatial visual programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376671,
author = {Bentley, Frank and O'Neill, Kathleen and Quehl, Katie and Lottridge, Danielle},
title = {Exploring the Quality, Efficiency, and Representative Nature of Responses Across Multiple Survey Panels},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376671},
doi = {10.1145/3313831.3376671},
abstract = {A common practice in HCI research is to conduct a survey to understand the generalizability
of findings from smaller-scale qualitative research. These surveys are typically deployed
to convenience samples, on low-cost platforms such as Amazon's Mechanical Turk or
Survey Monkey, or to more expensive market research panels offered by a variety of
premium firms. Costs can vary widely, from hundreds of dollars to tens of thousands
of dollars depending on the platform used. We set out to understand the accuracy of
ten different survey platforms/panels compared to ground truth data for a total of
6,007 respondents on 80 different aspects of demographic and behavioral questions.
We found several panels that performed significantly better than others on certain
topics, while different panels provided longer and more relevant open-ended responses.
Based on this data, we highlight the benefits and pitfalls of using a variety of survey
distribution options in terms of the quality, efficiency, and representative nature
of the respondents and the types of responses that can be obtained.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mturk, survey, representative, surveymonkey},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376672,
author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Seymour, William and Webb, Helena and Jirotka, Marina and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
title = { 'I Just Want to Hack Myself to Not Get Distracted': Evaluating Design Interventions for Self-Control on Facebook},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376672},
doi = {10.1145/3313831.3376672},
abstract = {Beyond being the world's largest social network, Facebook is for many also one of
its greatest sources of digital distraction. For students, problematic use has been
associated with negative effects on academic achievement and general wellbeing. To
understand what strategies could help users regain control, we investigated how simple
interventions to the Facebook UI affect behaviour and perceived control. We assigned
58 university students to one of three interventions: goal reminders, removed newsfeed,
or white background (control). We logged use for 6 weeks, applied interventions in
the middle weeks, and administered fortnightly surveys. Both goal reminders and removed
newsfeed helped participants stay on task and avoid distraction. However, goal reminders
were often annoying, and removing the newsfeed made some fear missing out on information.
Our findings point to future interventions such as controls for adjusting types and
amount of available information, and flexible blocking which matches individual definitions
of 'distraction'.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {addiction, self-control, interruptions, focus, distraction, problematic use, ict non-use, facebook},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376673,
author = {Fu, Xinyi and Zhu, Yaxin and Xiao, Zhijing and Xu, Yingqing and Ma, Xiaojuan},
title = {RestoreVR: Generating Embodied Knowledge and Situated Experience of Dunhuang Mural Conservation via Interactive Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376673},
doi = {10.1145/3313831.3376673},
abstract = {In Dunhuang Mogao Grottoes, unique Buddhist murals of ancient China are preserved.
Unfortunately, the exquisite murals are suffering from degradation. Experts have been
trying to enhance public's awareness of mural protection, but there's no efficacious
means to attract interest and popularize knowledge yet. In this paper, we propose
RestoreVR, an interactive virtual reality (VR) system engaging users to experience
Dunhuang mural restoration in a digital tour in the cave. Based on an online survey
with the public and in-depth interviews with five Dunhuang experts, we derive a set
of design requirements for generating embodied knowledge and situated experience in
VR to bridge the gap between highly specialized experts and general audiences. Accordingly,
we design RestoreVR and conduct a between-subjects user study to compare our system
with traditional methods. The results suggest that RestoreVR significantly improves
user experience and awareness of CH protection over existing methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {survey, implementation, mural conservation, dunhuang, interactive virtual reality, cultural heritage},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376674,
author = {Thakkar, Divy and Kumar, Neha and Sambasivan, Nithya},
title = {Towards an AI-Powered Future That Works for Vocational Workers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376674},
doi = {10.1145/3313831.3376674},
abstract = {The future of work is speculated to undergo profound change with increased automation.
Predictable jobs are projected to face high susceptibility to technological developments.
Many economies in Global South are built around outsourcing and manual labour, facing
a risk of job insecurity. In this paper, we examine the perceptions and practices
around automated futures of work among a population that is highly vulnerable to algorithms
and robots entering rule-based and manual domains: vocational technicians. We present
results from participatory action research with 38 vocational technician students
of low socio-economic status in Bangalore, India. Our findings show that technicians
were unfamiliar with the growth of automation, but upon learning about it, articulated
an emic vision for a future of work in-line with their value systems. Participants
felt excluded by current technological platforms for skilling and job-seeking. We
present opportunities for technology industry and policy makers to build a future
of work for vulnerable communities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci4d, india, automation, ai, future of work, policy, algorithmic fairness, vocational technicians, skills},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376675,
author = {Kraus, Matthias and Angerbauer, Katrin and Buchm\"{u}ller, Juri and Schweitzer, Daniel and Keim, Daniel A. and Sedlmair, Michael and Fuchs, Johannes},
title = {Assessing 2D and 3D Heatmaps for Comparative Analysis: An Empirical Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376675},
doi = {10.1145/3313831.3376675},
abstract = {Heatmaps are a popular visualization technique that encode 2D density distributions
using color or brightness. Experimental studies have shown though that both of these
visual variables are inaccurate when reading and comparing numeric data values. A
potential remedy might be to use 3D heatmaps by introducing height as a third dimension
to encode the data. Encoding abstract data in 3D, however, poses many problems, too.
To better understand this tradeoff, we conducted an empirical study (N=48) to evaluate
the user performance of 2D and 3D heatmaps for comparative analysis tasks. We test
our conditions on a conventional 2D screen, but also in a virtual reality environment
to allow for real stereoscopic vision. Our main results show that 3D heatmaps are
superior in terms of error rate when reading and comparing single data items. However,
for overview tasks, the well-established 2D heatmap performs better.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, visual analytics, heatmaps},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376676,
author = {Hoggenmueller, Marius and Hespanhol, Luke and Tomitsch, Martin},
title = {Stop and Smell the Chalk Flowers: A Robotic Probe for Investigating Urban Interaction with Physicalised Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376676},
doi = {10.1145/3313831.3376676},
abstract = {HCI researchers have begun to more systematically study non-digital transient approaches
for displaying information in public space, for example, in the form of chalk infographics.
These approaches provide several benefits compared to digital displays, such as: ad-hoc
deployment, barrier-free interaction, and being more sustainable. However, one limitation
is their hyperlocal scale and impact. Speculating on urban robots as agents for scaling
up physicalised displays, we describe the exploratory design and deployment of Woodie,
a slow-moving robot that draws on the ground using conventional chalk sticks. We deployed
Woodie for three weeks in a quiet laneway situated within a highly urbanised area.
Data collected from observations, video logs and interviews revealed that Woodie successfully
attracted people's attention and acted as a facilitator for collaborative, creative
placemaking. Furthermore, Woodie provoked emotional responses and was perceived as
a living being. Findings are interpreted to describe opportunities urban robots provide
for the design of future pervasive urban displays.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {urban robotic displays, physicalised displays, design, urban probe, pervasive displays, urban media, human-robot interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376677,
author = {Oppenlaender, Jonas and Milland, Kristy and Visuri, Aku and Ipeirotis, Panos and Hosio, Simo},
title = {Creativity on Paid Crowdsourcing Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376677},
doi = {10.1145/3313831.3376677},
abstract = {Crowdsourcing platforms are increasingly being harnessed for creative work. The platforms'
potential for creative work is clearly identified, but the workers' perspectives on
such work have not been extensively documented. In this paper, we uncover what the
workers have to say about creative work on paid crowdsourcing platforms. Through a
quantitative and qualitative analysis of a questionnaire launched on two different
crowdsourcing platforms, our results revealed clear differences between the workers
on the platforms in both preferences and prior experience with creative work. We identify
common pitfalls with creative work on crowdsourcing platforms, provide recommendations
for requesters of creative work, and discuss the meaning of our findings within the
broader scope of creativity-oriented research. To the best of our knowledge, we contribute
the first extensive worker-oriented study of creative work on paid crowdsourcing platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {creative work, creative tasks, creativity support tools, crowdsourcing, creativity, creativity tests},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376678,
author = {Eriksson, Sara and H\"{o}\"{o}k, Kristina and Shusterman, Richard and Svanes, Dag and Unander-Scharin, Carl and Unander-Scharin, \r{A}sa},
title = {Ethics in Movement: Shaping and Being Shaped in Human-Drone Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376678},
doi = {10.1145/3313831.3376678},
abstract = {How is ethics shaped by the particularities of a design? Through a detailed video
analysis, we explore how ethicality is shaped in interaction between a choreographer,
a performer and a choir of five drones, performing together on the opera stage. We
pinpoint how movements enabled by the human-drone assemblage may limit or liberate
artistic expressions vis-\`{a}-vis the norms of operatic performance. From a somaesthetics
perspective on ethics, we show how the process of crafting rich experiences together
with drones can deepen sensory appreciation skills, leading to an increased understanding
of underlying somatic drivers and imposed norms. Somatic awareness thereby enables
a richer repertoire of movements, expanding the ability to freely choose how to act,
and cultivating empathy towards others. This shifts our understanding of ethics in
HCI as solely about abstract rules or policies 'out there' to also concern the specifics
of how technology informs or dictates movement and experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {movement, ethics, drones, somaesthetics, soma design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376679,
author = {Edwards, Gregory W. and Gonzales, Michael J. and Sullivan, Marc A.},
title = {Robocalling: STIRRED AND SHAKEN! - An Investigation of Calling Displays on Trust and Answer Rates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376679},
doi = {10.1145/3313831.3376679},
abstract = {Billions of robocalls annually have undermined the public's trust in the entire phone
system. New functionality, called STIR/SHAKEN (S/S), hopes to help fix this issue
by detecting whether a call is coming from the number it says it is. However, due
to the nature of the system, at first only a portion of calls would go through the
S/S system. This led us to question whether presenting this information would confuse
users more than help. In this paper, we detail the results of online surveys, in-person
interviews, and a lab-based simulation. The research recommends "Valid Number" for
the label on the display and found that even with only 30% of calls being validated,
S/S increased trust, answer frequency and consumer satisfaction. Based on these results,
the launch of S/S could positively affect the current phone system and re-establish
consumer trust.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {spoofing, robocalling, lab simulation, UX research, survey},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376680,
author = {Andalibi, Nazanin and Buss, Justin},
title = {The Human in Emotion Recognition on Social Media: Attitudes, Outcomes, Risks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376680},
doi = {10.1145/3313831.3376680},
abstract = {Emotion recognition algorithms recognize, infer, and harvest emotions using data sources
such as social media behavior, streaming service use, voice, facial expressions, and
biometrics in ways often opaque to the people providing these data. People's attitudes
towards emotion recognition and the harms and outcomes they associate with it are
important yet unknown. Focusing on social media, we interviewed 13 adult U.S. social
media users to fill this gap. We find that people view emotions as insights to behavior,
prone to manipulation, intimate, vulnerable, and complex. Many find emotion recognition
invasive and scary, associating it with autonomy and control loss. We identify two
categories of emotion recognition's risks: individual and societal. We discuss findings'
implications for algorithmic accountability and argue for considering emotion data
as sensitive. Using a Science and Technology Studies lens, we advocate that technology
users should be considered as a relevant social group in emotion recognition advancements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {privacy, ethics, social media, emotion recognition, fairness, algorithmic accountability, emotion AI, AI ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376681,
author = {Wu, Te-Yen and Qi, Shutong and Chen, Junchi and Shang, MuJie and Gong, Jun and Seyed, Teddy and Yang, Xing-Dong},
title = {Fabriccio: Touchless Gestural Input on Interactive Fabrics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376681},
doi = {10.1145/3313831.3376681},
abstract = {We present Fabriccio, a touchless gesture sensing technique developed for interactive
fabrics using Doppler motion sensing. Our prototype was developed using a pair of
loop antennas (one for transmitting and the other for receiving), made of conductive
thread that was sewn onto a fabric substrate. The antenna type, configuration, transmission
lines, and operating frequency were carefully chosen to balance the complexity of
the fabrication process and the sensitivity of our system for touchless hand gestures,
performed at a 10 cm distance. Through a ten-participant study, we evaluated the performance
of our proposed sensing technique across 11 touchless gestures as well as 1 touch
gesture. The study result yielded a 92.8% cross-validation accuracy and 85.2% leave-one-session-out
accuracy. We conclude by presenting several applications to demonstrate the unique
interactions enabled by our technique on soft objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {touchless gesture, interactive fabrics, doppler effect},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376682,
author = {El Ali, Abdallah and Yang, Xingyu and Ananthanarayan, Swamy and R\"{o}ggla, Thomas and Jansen, Jack and Hartcher-O'Brien, Jess and Jansen, Kaspar and Cesar, Pablo},
title = {ThermalWear: Exploring Wearable On-Chest Thermal Displays to Augment Voice Messages with Affect},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376682},
doi = {10.1145/3313831.3376682},
abstract = {Voice is a rich modality for conveying emotions, however emotional prosody production
can be situationally or medically impaired. Since thermal displays have been shown
to evoke emotions, we explore how thermal stimulation can augment perception of neutrally-spoken
voice messages with affect. We designed ThermalWear, a wearable on-chest thermal display,
then tested in a controlled study (N=12) the effects of fabric, thermal intensity,
and direction of change. Thereafter, we synthesized 12 neutrally-spoken voice messages,
validated (N=7) them, then tested (N=12) if thermal stimuli can augment their perception
with affect. We found warm and cool stimuli (a) can be perceived on the chest, and
quickly without fabric (4.7-5s) (b) do not incur discomfort (c) generally increase
arousal of voice messages and (d) increase / decrease message valence, respectively.
We discuss how thermal displays can augment voice perception, which can enhance voice
assistants and support individuals with emotional prosody impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {emotion, voice, display, affect, wearable, thermal, prosody, chest},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376683,
author = {Naseem, Mustafa and Saleem, Bilal and St-Onge Ahmad, Sacha and Chen, Jay and Raza, Agha Ali},
title = {An Empirical Comparison of Technologically Mediated Advertising in Under-Connected Populations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376683},
doi = {10.1145/3313831.3376683},
abstract = {Information and Communication Technology interventions have the potential to improve
outcomes in health and other development sectors in low-income settings. Large-scale
impact, however, remains the central challenge for the HCI4D community as significant
and diverse resources are typically required to scale such interventions beyond the
pilot stage. In contrast, voice-based entertainment services accessible over simple
phones, designed for similarly low-income, low-literate populations manage to scale 'virally' to tens of thousands of users with little to no advertising cost. Our study
compares the outcomes of using voice-based entertainment to spread a maternal-health
hotline against conventional advertisement channels including paper flyers, posters,
radio, TV, social media and robocalls. Through an 11-week deployment in Pakistan where
the hotline reached 21,770 users over 32,625 calls, we find that the entertainment
service outperformed other channels on all popular user acquisition metrics, with
the exception of robocalls, which lead in terms of spread.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pakistan, television, tv, low-literate, banners, interactive voice response, social media, robocalls, advertisement, radio, flyers, ivr, mobile phone, ict4d, under-connected, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376684,
author = {Alfaras, Miquel and Tsaknaki, Vasiliki and Sanches, Pedro and Windlin, Charles and Umair, Muhammad and Sas, Corina and H\"{o}\"{o}k, Kristina},
title = {From Biodata to Somadata},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376684},
doi = {10.1145/3313831.3376684},
abstract = {Biosensing technologies are increasingly available as off-the-shelf products, yet
for many designers, artists and non-engineers, these technologies remain difficult
to design with. Through a soma design stance, we devised a novel approach for exploring
qualities in biodata. Our explorative process culminated in the design of three artefacts,
coupling biosignals to tangible actuation formats. By making biodata perceivable as
sound, in tangible form or directly on the skin, it became possible to link qualities
of the measurements to our own somatics - our felt experience of our bodily bioprocesses
- as they dynamically unfold, spurring somatically-grounded design discoveries of
novel possible interactions. We show that making biodata attainable for a felt experience
- or as we frame it: turning biodata into somadata - enables not only first-person
encounters, but also supports collaborative design processes as the somadata can be
shared and experienced dynamically, right at the moment when we explore design ideas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {first-person perspective, interaction design, soma design, affective technology, biosensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376685,
author = {Slegers, Karin and Kouwenberg, Kristel and Lou\v{c}ova, Tereza and Daniels, Ramon},
title = {Makers in Healthcare: The Role of Occupational Therapists in the Design of DIY Assistive Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376685},
doi = {10.1145/3313831.3376685},
abstract = {Advancements in personal fabrication technologies (e.g. 3D printing) resulted in a
rising interest in 'do-it-yourself assistive technology' (DIY AT). Clinical knowledge
is considered fundamental for DIY AT design, but research into making DIY AT by clinicians
is limited. In this paper, we explore occupational therapists' attitudes towards 3D
printing both before and after gaining hands-on experience with 3D modelling software.
In addition, as clinicians indicate to prefer collaborations with experienced designers,
we organized a codesign study with occupational therapists and professional designers
to conceptualize a feasible collaborative DIY-AT design process. The results of our
studies show an overall enthusiasm of occupational therapists towards 3D printing,
but the perceived impact of 3D printing on their job performance decreased after gaining
hands-on experience. Collaborating with designers seems a viable way forward. We propose
a model for a collaborative design process, highlighting different phases and the
roles that occupational therapists and designers play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {digital fabrication, 3D printing, DIY assistive technology, occupational therapy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376686,
author = {Saksono, Herman and Castaneda-Sceppa, Carmen and Hoffman, Jessica and Morris, Vivien and Seif El-Nasr, Magy and Parker, Andrea G.},
title = {Storywell: Designing for Family Fitness App Motivation by Using Social Rewards and Reflection},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376686},
doi = {10.1145/3313831.3376686},
abstract = {Physical activity (PA) is critical for reducing the risk of obesity, a prevalent health
concern that burdens low-socioeconomic status (SES) households. While self-tracking
apps can increase PA, encouraging app engagement remains a challenge, thus limiting
the app's efficacy. To understand how to better support caregiver's motivation to
use family health apps, we designed and evaluated Storywell?a mobile app for promoting
family PA. Guided by Self-Determination Theory, Storywell provides social rewards
(e.g., storybooks with interactive reflective questions) aimed at supporting relatedness
and motivation. Our 3-month qualitative study with 18 families revealed satisfying
moments that can affect caregiver's motivation. We contribute new knowledge on designing
satisfying moments that heighten the motivation to use health apps, especially for
low-SES families who face many barriers to using such systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gamification, children, family, self-tracking, physical activity, self-determination theory, motivation, health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376687,
author = {Wentzel, Johann and d'Eon, Greg and Vogel, Daniel},
title = {Improving Virtual Reality Ergonomics Through Reach-Bounded Non-Linear Input Amplification},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376687},
doi = {10.1145/3313831.3376687},
abstract = {Input amplification enables easier movement in virtual reality (VR) for users with
mobility issues or in confined spaces. However, current techniques either do not focus
on maintaining feelings of body ownership, or are not applicable to general VR tasks.
We investigate a general purpose non-linear transfer function that keeps the user's
reach within reasonable bounds to maintain body ownership. The technique amplifies
smaller movements from a user-definable neutral point into the expected larger movements
using a configurable Hermite curve. Two experiments evaluate the approach. The first
establishes that the technique has comparable performance to the state-of-the-art,
increasing physical comfort while maintaining task performance and body ownership.
The second explores the characteristics of the technique over a wide range of amplification
levels. Using the combined results, design and implementation recommendations are
provided with potential applications to related VR transfer functions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interaction techniques, ergonomics, input re-mapping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376688,
author = {Cao, Yuanzhi and Qian, Xun and Wang, Tianyi and Lee, Rachel and Huo, Ke and Ramani, Karthik},
title = {An Exploratory Study of Augmented Reality Presence for Tutoring Machine Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376688},
doi = {10.1145/3313831.3376688},
abstract = {Machine tasks in workshops or factories are often a compound sequence of local, spatial,
and body-coordinated human-machine interactions. Prior works have shown the merits
of video-based and augmented reality (AR) tutoring systems for local tasks. However,
due to the lack of a bodily representation of the tutor, they are not as effective
for spatial and body-coordinated interactions. We propose avatars as an additional
tutor representation to the existing AR instructions. In order to understand the design
space of tutoring presence for machine tasks, we conduct a comparative study with
32 users. We aim to explore the strengths/limitations of the following four tutor
options: video, non-avatar-AR, half-body+AR, and full-body+AR. The results show that
users prefer the half-body+AR overall, especially for the spatial interactions. They
have a preference for the full-body+AR for the body-coordinated interactions and the
non-avatar-AR for the local interactions. We further discuss and summarize design
recommendations and insights for future machine task tutoring systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tutoring system design, avatar tutor, exploratory study, augmented reality, machine task},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376689,
author = {Claisse, Caroline and Petrelli, Daniela and Ciolfi, Luigina and Dulake, Nick and Marshall, Mark T. and Durrant, Abigail C.},
title = {Crafting Critical Heritage Discourses into Interactive Exhibition Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376689},
doi = {10.1145/3313831.3376689},
abstract = {This paper argues how a more reflective design practice that embraces critical discourses
can transform interactive exhibition design and therefore the museum visiting experience.
Four framing arguments underpin our exhibition design making: the value of materiality,
visiting as an aesthetic experience, challenging the authorized voice, and heritage
as a process. These arguments were embodied through design, art and craft practice
into one interactive exhibition at a house museum. We draw from our design process
discussing the implications that adopting an approach informed by critical heritage
debates has on exhibition design and suggest three sensitizing concepts (polyvocal
narratives, dialogical interaction, interweaving time and space) bridging the practice
of interactive exhibition design and critical heritage theory.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tangible interaction, exhibition design, reflective practice, craft practice, critical heritage},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376690,
author = {Ahmad, Wajeeha and Liccardi, Ilaria},
title = {Addressing Anonymous Abuses: Measuring the Effects of Technical Mechanisms on Reported User Behaviors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376690},
doi = {10.1145/3313831.3376690},
abstract = {Anonymous networks intended to enhance privacy and evade censorship are also being
exploited for abusive activities. Technical schemes have been proposed to selectively
revoke the anonymity of abusive users, or simply limit them from anonymously accessing
online service providers. We designed an empirical survey study to assess the effects
of deploying these schemes on 75 users of the Tor anonymous network. We evaluated
proposed schemes based on examples of the intended or abusive use cases they may address,
their technical implementation and the types of entities responsible for enforcing
them. Our results show that revocable anonymity schemes would particularly deter the
intended uses of anonymous networks. We found a lower reported decrease in usage for
schemes addressing spam than those directly compromising free expression. However,
participants were concerned that all technical mechanisms for addressing anonymous
abuses could be exploited beyond their intended goals (51.7%) to harm users (43.8%).
Participants were distrustful of the enforcing entities involved (43.8%) and concerned
about being unable to verify (49.3%) how particular mechanisms were applied.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {anonymous networks, empirical study, tor, abuse, trust},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376691,
author = {Alrashed, Tarfah and Almahmoud, Jumana and Zhang, Amy X. and Karger, David R.},
title = {ScrAPIr: Making Web Data APIs Accessible to End Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376691},
doi = {10.1145/3313831.3376691},
abstract = {Users have long struggled to extract and repurpose data from websites by laboriously
copying or scraping content from web pages. An alternative is to write scripts that
pull data through APIs. This provides a cleaner way to access data than scraping;
however, APIs are effortful for programmers and nigh-impossible for non-programmers
to use. In this work, we empower users to access APIs without programming. We evolve
a schema for declaratively specifying how to interact with a data API. We then develop
ScrAPIr: a standard query GUI that enables users to fetch data through any API for
which a specification exists, and a second GUI that lets users author and share the
specification for a given API. From a lab evaluation, we find that even non-programmers
can access APIs using ScrAPIr, while programmers can access APIs 3.8 times faster
on average using ScrAPIr than using programming.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {web apis, web scraping, api description language},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376692,
author = {Mlakar, Sara and Haller, Michael},
title = {Design Investigation of Embroidered Interactive Elements on Non-Wearable Textile Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376692},
doi = {10.1145/3313831.3376692},
abstract = {As smart textiles are becoming more present in our lives, investigating and designing
textile interfaces has started getting more and more attention. Still, very little
research has been done on how to design interactive elements for non-wearable textile
interfaces for the best recognition, perception, and interaction. In this paper, we
present initial assumptions for designing such interfaces, which we derived from working
intensively with our partners from the industry. These have been further explored
with experts from the field during interviews, and finally tested in a user study.
As a conclusion of the study, we define five design recommendations for textile interfaces
and present several prototypes that demonstrate them in practice. Our recommendations
cover tactile contrast between textures, heights, and shapes; minimal recognizable
size of elements; perception of concave and convex shapes as interactive elements;
indication of interaction through shape; and recognition of tactile symbols.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {embroidery, smart textiles, design recommendations, non-wearables, user study, expert interviews, textile interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376693,
author = {Bellini, Rosanna and Forrest, Simon and Westmarland, Nicole and Smeddinck, Jan David},
title = {Mechanisms of Moral Responsibility: Rethinking Technologies for Domestic Violence Prevention Work},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376693},
doi = {10.1145/3313831.3376693},
abstract = {This paper provides a critical examination of how digital systems within a charitable
organisation in the North of England are being used to both support and challenge
male perpetrators of domestic violence. While there exists a range of digital tools
to support the victim-survivors of domestic violence, no tools are available to challenge
the abusive and harmful behaviours of perpetrators. Through this work, we uncovered
the compelling moral responsibilities intrinsic within interactions with technological
systems between perpetrators and support workers. As such, we highlight four spaces
of negotiation concerning a person's responsibility in changing their abusive behaviour,
which we have coined as mechanisms to represent their fundamental and interconnected
nature. These mechanisms include self-awareness, acknowledging the extent of harms,
providing peer support and respecting authorities. These insights are the basis for
offering some practical considerations for HCI scholars, policymakers and intervention
designers in their work with perpetrators of violence.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {moral responsibility, domestic violence, violence prevention, civic technology, social care, third sector},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376694,
author = {Varghese, Delvin and Olivier, Patrick and Bartindale, Tom and Baillie Smith, Matt},
title = {Towards Participatory Video 2.0},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376694},
doi = {10.1145/3313831.3376694},
abstract = {Participatory video (PV) is an established practice for enabling communities to "speak
truth to power" and has been widely used by local, national and international Non-Governmental
Organizations (NGOs). However, the digital media landscape has changed dramatically
since PV became widely accessible with the rise of the camcorder in the 1980s. Current
media practices have evolved considerably since, yet PV remains essentially unchanged.
We report on an investigation of current PV practices and reflect on these in terms
of what the future for PV holds. We conducted interviews with staff at a global humanitarian
network who directly and indirectly engage in community story capture; and explore
their reflections on the potentials and barriers to PV use. We propose a new vision
for PV that draws on current visual media production, consumption and distribution
technologies and practices, and propose principles on which PV 2.0, a new generation
of Participatory Video can be founded.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ICTD, participatory film-making, HCI4D, object based media, international development, iDocs, participatory video},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376695,
author = {Peng, Zhenhui and Guo, Qingyu and Tsang, Ka Wing and Ma, Xiaojuan},
title = {Exploring the Effects of Technological Writing Assistance for Support Providers in Online Mental Health Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376695},
doi = {10.1145/3313831.3376695},
abstract = {Textual comments from peers with informational and emotional support are beneficial
to members of online mental health communities (OMHCs). However, many comments are
not of high quality in reality. Writing support technologies that assess (AS) the
text or recommend (RE) writing examples on the fly could potentially help support
providers to improve the quality of their comments. However, how providers perceive
and work with such technologies are under-investigated. In this paper, we present
a technological prototype MepsBot which offers providers in-situ writing assistance
in either AS or RE mode. Results of a mixed-design study with 30 participants show
that both types of MepsBots improve users' confidence in and satisfaction with their
comments. The AS-mode MepsBot encourages users to refine expressions and is deemed
easier to use, while the RE-mode one stimulates more support-related content re-editions.
We report concerns on MepsBot and propose design considerations for writing support
technologies in OMHCs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mental health, informational support, writing support tools, online community, emotional support},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376696,
author = {Vezzoli, Yvonne and Kalantari, Sara and Kucirkova, Natalia and Vasalou, Asimina},
title = {Exploring the Design Space for Parent-Child Reading},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376696},
doi = {10.1145/3313831.3376696},
abstract = {Given the significant potential of shared book reading to promote children's learning,
the design of e-books has focused on maximising this learning experience. However,
recent studies have begun to show that shared reading is a broader opportunity for
the family to spend quality time together. Our study aims to explore this perspective
further, focusing on the types of parent-child interactions during shared reading
and the ways in which shared reading may foster intimacy when parents and children
read digital books. We used cultural probes and contextual interviews to capture the
shared reading experiences of 7 parents and 6 children in their homes. We discuss
the different nuances of the shared reading practices identified. We use these findings
to suggest new design opportunities that support the complex practices of shared reading
with technologies at home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {digital books, parent-child reading, cultural probes, shared reading, families},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376697,
author = {Wiley, Katelyn and Vedress, Sarah and Mandryk, Regan L.},
title = {How Points and Theme Affect Performance and Experience in a Gamified Cognitive Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376697},
doi = {10.1145/3313831.3376697},
abstract = {Cognitive tasks are increasingly being gamified in an attempt to leverage the motivational
power of games; however, they are sensitive to manipulation and literature is divided
on how adding game elements affects participant performance and experience. We applied
two popular gamification approaches (points/feedback and theme/narrative) to a typical
cognitive task (the dot probe) and measured performance and experience in two studies
(N1=287, N2=321). Similar to prior work, we confirm in Study1 that points increase
reaction time and error rate, and positive affect. We replicated these results in
Study2, and expanded our analysis to investigate participant experience. Our findings
suggest that theme creates expectations of an interesting game, which gamified tasks
fail to deliver, whereas points maintain enjoyment better throughout the task itself.
Important for the development of gamified cognitive tasks, our findings suggest that
novel approaches to gameful assessment may be better than the status quo.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {games, cognitive tasks, dot probe, gamification, assessment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376698,
author = {Li, Nianlong and Han, Teng and Tian, Feng and Huang, Jin and Sun, Minghui and Irani, Pourang and Alexander, Jason},
title = {Get a Grip: Evaluating Grip Gestures for VR Input Using a Lightweight Pen},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376698},
doi = {10.1145/3313831.3376698},
abstract = {The use of Virtual Reality (VR) in applications such as data analysis, artistic creation,
and clinical settings requires high precision input. However, the current design of
handheld controllers, where wrist rotation is the primary input approach, does not
exploit the human fingers' capability for dexterous movements for high precision pointing
and selection. To address this issue, we investigated the characteristics and potential
of using a pen as a VR input device. We conducted two studies. The first examined
which pen grip allowed the largest range of motion---we found a tripod grip at the
rear end of the shaft met this criterion. The second study investigated target selection
via 'poking' and ray-casting, where we found the pen grip outperformed the traditional
wrist-based input in both cases. Finally, we demonstrate potential applications enabled
by VR pen input and grip postures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {handheld controller, pen input, spatial target selection, virtual reality, finger and wrist dexterity, grip postures},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376699,
author = {Ding, Xianghua and Gui, Xinning and Ma, Xiaojuan and Ding, Zhaofei and Chen, Yunan},
title = {Getting the Healthcare We Want: The Use of Online "Ask the Doctor" Platforms in Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376699},
doi = {10.1145/3313831.3376699},
abstract = {Online Ask the Doctor (AtD) services allow access to health professionals anytime
anywhere beyond existing patient-provider relationships. Recently, many free-market
AtD platforms have emerged and been adopted by a large scale of users. However, it
is still unclear how people make use of these AtD platforms in practice. In this paper,
we present an interview study with 12 patients/caregivers who had experience using
AtD in China, highlighting patient agency in seeking more reliable and cost-effective
healthcare beyond clinic settings. Specifically, we illustrate how they make strategic
choices online on AtD platforms, and how they strategically integrate online and offline
services together for healthcare. This paper contributes an empirical study of the
use of large-scale AtD platforms in practice, demonstrates patient agency for healthcare
beyond clinic settings, and recommends design implications for online healthcare services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ask the doctor services, patient agency, AtD, online healthcare services, healthcare navigation, healthcare engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376700,
author = {Tseng, Wen-Jie and Lee, Yi-Chen and Peiris, Roshan Lalintha and Chan, Liwei},
title = {A Skin-Stroke Display on the Eye-Ring Through Head-Mounted Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376700},
doi = {10.1145/3313831.3376700},
abstract = {We present the Skin-Stroke Display, a system mounted on the lens inside the head-mounted
display, which exerts subtle yet recognizable tactile feedback on the eye-ring using
a motorized air jet. To inform our design of noticeable air-jet haptic feedback, we
conducted a user study to identify absolute detection thresholds. Our results show
that the tactile sensation had different sensitivity around the eyes, and we determined
a standard intensity (8 mbar) to prevent turbulent airflow blowing into the eyes.
In the second study, we asked participants to adjust the intensity around the eye
for equal sensation based on standard intensity. Next, we investigated the recognition
of point and stroke stimuli with or without inducing cognitive load on eight directions
on the eye-ring. Our longStroke stimulus can achieve an accuracy of 82.6% without
cognitive load and 80.6% with cognitive load simulated by the Stroop test. Finally,
we demonstrate example applications using the skin-stroke display as the off-screen
indicator, tactile I/O progress display, and tactile display.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, air jet, skin-stroke display, head-mounted display, haptics, eye-ring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376701,
author = {Cheema, Noshaba and Frey-Law, Laura A. and Naderi, Kourosh and Lehtinen, Jaakko and Slusallek, Philipp and H\"{a}m\"{a}l\"{a}inen, Perttu},
title = {Predicting Mid-Air Interaction Movements and Fatigue Using Deep Reinforcement Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376701},
doi = {10.1145/3313831.3376701},
abstract = {A common problem of mid-air interaction is excessive arm fatigue, known as the "Gorilla
arm" effect. To predict and prevent such problems at a low cost, we investigate user
testing of mid-air interaction without real users, utilizing biomechanically simulated
AI agents trained using deep Reinforcement Learning (RL). We implement this in a pointing
task and four experimental conditions, demonstrating that the simulated fatigue data
matches human fatigue data. We also compare two effort models: 1) instantaneous joint
torques commonly used in computer animation and robotics, and 2) the recent Three
Compartment Controller (3CC-) model from biomechanical literature. 3CC- yields movements
that are both more efficient and relaxed, whereas with instantaneous joint torques,
the RL agent can easily generate movements that are quickly tiring or only reach the
targets slowly and inaccurately. Our work demonstrates that deep RL combined with
the 3CC- provides a viable tool for predicting both interaction movements and user
experiencein silico, without users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user modeling, reinforcement learning, computational interaction, biomechanical simulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376702,
author = {McGill, Mark and Brewster, Stephen and McGookin, David and Wilson, Graham},
title = {Acoustic Transparency and the Changing Soundscape of Auditory Mixed Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376702},
doi = {10.1145/3313831.3376702},
abstract = {Auditory headsets capable of actively or passively intermixing both real and virtual
sounds are in-part acoustically transparent. This paper explores the consequences
of acoustic transparency, both on the perception of virtual audio content, given the
presence of a real-world auditory backdrop, and more broadly in facilitating a wearable,
personal, private, always-available soundspace. We experimentally compare passive
acoustically transparent, and active noise cancelling, orientation-tracked auditory
headsets across a range of content types, both indoors and outdoors for validity.
Our results show differences in terms of presence, realness and externalization for
select content types. Via interviews and a survey, we discuss attitudes toward acoustic
transparency (e.g. being perceived as safer), the potential shifts in audio usage
that might be precipitated by adoption, and reflect on how such headsets and experiences
fit within the area of Mixed Reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {acoustic transparency, mixed reality, audio},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376703,
author = {Arakawa, Riku and Yakura, Hiromu},
title = {INWARD: A Computer-Supported Tool for Video-Reflection Improves Efficiency and Effectiveness in Executive Coaching},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376703},
doi = {10.1145/3313831.3376703},
abstract = {Video-Reflection is a common approach to realize reflection in the field of executive
coaching for professional development, which presents a video recording of the coaching
session to a coachee in order to make the coachee reflectively think about oneself.
However, it requires a great deal of time to watch the full length of the video and
is highly dependent on the skills of the coach. We expect that the quality and efficiency
of video-reflection can be improved with the support of computers. In this paper,
we introduce INWARD, a computational tool that leverages human behavior analysis and
video-based interaction techniques. The results of a user study involving 20 coaching
sessions with five coaches indicate that INWARD enables efficient video-reflection
and, by leveraging meta-reflection, realizes the ameliorated outcome of executive
coaching. Moreover, discussions based on comments from the participants support the
effectiveness of INWARD and suggest further possibilities of computer-supported approaches.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {meta-reflection, video-reflection, executive coaching},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376704,
author = {Gan, Yumei and Greiffenhagen, Christian and Reeves, Stuart},
title = {Connecting Distributed Families: Camera Work for Three-Party Mobile Video Calls},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376704},
doi = {10.1145/3313831.3376704},
abstract = {Mobile video calling technologies have become a critical link to connect distributed
families. However, these technologies have been principally designed for video calling
between two parties, whereas family video calls involve young children often comprise
three parties, namely a co-present adult (a parent or grandparent) helping with the
interaction between the child and another remote adult. We examine how manipulation
of phone cameras and management of co-present children is used to stage parent-child
interactions. We present results from a video-ethnographic study based on 40 video
recordings of video calls between 'left-behind' children and their migrant parents
in China. Our analysis reveals a key practice of 'facilitation work', performed by
grandparents, as a crucial feature of three-party calls. Facilitation work offers
a new concept for HCI's broader conceptualisation of mobile video calling, suggesting
revisions that design might take into consideration for triadic interactions in general.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobile video calls, conversation analysis, facilitation work, camera work, distributed families},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376705,
author = {Maekawa, Azumi and Matsubara, Seito and Wakisaka, Sohei and Uriu, Daisuke and Hiyama, Atsushi and Inami, Masahiko},
title = {Dynamic Motor Skill Synthesis with Human-Machine Mutual Actuation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376705},
doi = {10.1145/3313831.3376705},
abstract = {This paper presents an approach for coupling robotic capability with human ability
in dynamic motor skills, called "Human-Machine Mutual Actuation (HMMA)." We focus
specifically on throwing motions and propose a method to control the release timing
computationally. A system we developed achieves our concept, HMMA, by a robotic handheld
device that acts as a release controller. We conducted user studies to validate the
feasibility of the concept and clarify related technical issues to be tackled. We
recognized that the system successfully performs on throwing according to the target
while it exploits human ability. These empirical experiments suggest that robotic
capability can be embedded into the users' motions without losing their senses of
control. Throughout the user study, we also revealed several issues to be tackled
in further research contributing to HMMA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {robotic device, motion sensing, human augmentation, motor skill, human-machine mutual actuation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376706,
author = {Kelliher, Aisling and Zilevu, Setor and Rikakis, Thanassis and Ahmed, Tamim and Truong, Yen and Wolf, Steven L.},
title = {Towards Standardized Processes for Physical Therapists to Quantify Patient Rehabilitation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376706},
doi = {10.1145/3313831.3376706},
abstract = {Physical rehabilitation typically requires therapists to make judgements about patient
movement and functional improvement using subjective observation. This process makes
it challenging to quantitatively track, compute and predict long-term patient improvement.
We therefore propose a novel methodical approach to the standardized and interpretable
quantification of patient movement during rehabilitation. We describe the expert-led
development of a movement assessment rubric and an accompanying quantitative rating
system. We present our movement capture and annotation computational tools designed
to implement the rubric and assist therapists in the quantitative documentation and
assessment of rehabilitation. We describe results from a movement capture study of
the tool with nine stroke survivors and a movement rating study with four therapists.
Findings from these studies highlight potential optimal methodical process paths for
individuals engaged in capturing, understanding and predicting human movement performance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {stroke rehabilitation, human movement assessment, human movement capture, home based rehabilitation therapy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376707,
author = {Schneegass, Christina and Kosch, Thomas and Baumann, Andrea and Rusu, Marius and Hassib, Mariam and Hussmann, Heinrich},
title = {BrainCoDe: Electroencephalography-Based Comprehension Detection during Reading and Listening},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376707},
doi = {10.1145/3313831.3376707},
abstract = {The pervasive availability of media in foreign languages is a rich resource for language
learning. However, learners are forced to interrupt media consumption whenever comprehension
problems occur. We present BrainCoDe, a method to implicitly detect vocabulary gaps
through the evaluation of event-related potentials (ERPs). In a user study (N=16),
we evaluate BrainCoDe by investigating differences in ERP amplitudes during listening
and reading of known words compared to unknown words. We found significant deviations
in N400 amplitudes during reading and in N100 amplitudes during listening when encountering
unknown words. To evaluate the feasibility of ERPs for real-time applications, we
trained a classifier that detects vocabulary gaps with an accuracy of 87.13% for reading
and 82.64% for listening, identifying eight out of ten words correctly as known or
unknown. We show the potential of BrainCoDe to support media learning through instant
translations or by generating personalized learning content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {language learning, implicit comprehension detection, EEG},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376708,
author = {Seering, Joseph and Luria, Michal and Ye, Connie and Kaufman, Geoff and Hammer, Jessica},
title = {It Takes a Village: Integrating an Adaptive Chatbot into an Online Gaming Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376708},
doi = {10.1145/3313831.3376708},
abstract = {While the majority of research in chatbot design has focused on creating chatbots
that engage with users one-on-one, less work has focused on the design of conversational
agents for online communities. In this paper we present results from a three week
test of a social chatbot in an established online community. During this study, the
chatbot "grew up" from "birth" through its teenage years, engaging with community
members and "learning" vocabulary from their conversations. We discuss the design
of this chatbot, how users' interactions with it evolved over the course of the study,
and how it impacted the community as a whole. We discuss how we addressed challenges
in developing a chatbot whose vocabulary could be shaped by users, and conclude with
implications for the role of machine learning in social interactions in online communities
and potential future directions for design of community-based chatbots.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {long-term study, community interaction, babybot, chatbot, machine learning, interaction design, AI, twitch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376709,
author = {Saint-Lot, Julie and Imbert, Jean-Paul and Dehais, Fr\'{e}d\'{e}ric},
title = {Red Alert: A Cognitive Countermeasure to Mitigate Attentional Tunneling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376709},
doi = {10.1145/3313831.3376709},
abstract = {Attentional tunneling, that is the inability to detect unexpected changes in the environment,
has been shown to have critical consequences in air traffic control. The motivation
of this study was to assess the design of a cognitive countermeasure dedicated to
mitigate such failure of attention. The Red Alert cognitive countermeasure relies
on a brief orange-red flash (300 ms) that masks the entire screen with a 15% opacity.
Twenty-two air traffic controllers faced two demanding scenarios, with or without
the cognitive countermeasure. The volunteers were not told about the Red Alert so
as to assess the intuitiveness of the design without prior knowledge. Behavioral results
indicated that the cognitive countermeasure reduced reaction time and improved the
detection of the notification when compared to the classical operational design. Further
analyses showed this effect was even stronger for half of our participants (91.7%
detection rate) who intuitively understood the purpose of this design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {attentional tunneling, interruption, air traffic controller (atco), air traffic control, countermeasure, notification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376710,
author = {Laschke, Matthias and Braun, Christoph and Neuhaus, Robin and Hassenzahl, Marc},
title = {Meaningful Technology at Work - A Reflective Design Case of Improving Radiologists' Wellbeing Through Medical Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376710},
doi = {10.1145/3313831.3376710},
abstract = {In radiology, medical technology providers (MTP) focus mainly on technology-related
issues, such as image quality or efficiency of reporting. Broader notions of radiology
as "meaningful work" are largely seen as out of scope for an MTP. The present paper
challenges this. In a real-world case with a large MTP, we showed that medical technology
could be designed more holistically to explicitly improve radiologists' wellbeing.
We first gathered work practices experienced as especially conducive to wellbeing.
From there, we distilled ideal practices to increase wellbeing and turned them into
two software applications. The MTP's initial skepticism dissolved, while radiologists
unanimously emphasized wellbeing and demonstrated how they work towards improving
it. Based on our insights, the applications resonated well among the radiologists
involved, the healthcare provider, and other customers of the MTP. We close with a
critical reflection of the challenges and opportunities of designing wellbeing-driven
technology in the work domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {technology at work, practice-based, job design, wellbeing-driven design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376711,
author = {Jiang, Xinhui and Li, Yang and Jokinen, Jussi P.P. and Hirvola, Viet Ba and Oulasvirta, Antti and Ren, Xiangshi},
title = {How We Type: Eye and Finger Movement Strategies in Mobile Typing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376711},
doi = {10.1145/3313831.3376711},
abstract = {Relatively little is known about eye and finger movement in typing with mobile devices.
Most prior studies of mobile typing rely on log data, while data on finger and eye
movements in typing come from studies with physical keyboards. This paper presents
new findings from a transcription task with mobile touchscreen devices. Movement strategies
were found to emerge in response to sharing of visual attention: attention is needed
for guiding finger movements and detecting typing errors. In contrast to typing on
physical keyboards, visual attention is kept mostly on the virtual keyboard, and glances
at the text display are associated with performance. When typing with two fingers,
although users make more errors, they manage to detect and correct them more quickly.
This explains part of the known superiority of two-thumb typing over one-finger typing.
We release the extensive dataset on everyday typing on smartphones.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {eye movement, finger movement, eye-hand coordination, mobile device, text input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376712,
author = {Arimatsu, Kazuyuki and Mori, Hideki},
title = {Evaluation of Machine Learning Techniques for Hand Pose Estimation on Handheld Device with Proximity Sensor},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376712},
doi = {10.1145/3313831.3376712},
abstract = {Tracking finger movement for natural interaction using hand is commonly studied. For
vision-based implementations of finger tracking in virtual reality (VR) application,
finger movement is occluded by a handheld device which is necessary for auxiliary
input, thus tracking finger movement using cameras is still challenging. Finger tracking
controllers using capacitive proximity sensors on the surface are starting to appear.
However, research on estimating articulated hand pose from curved capacitance sensing
electrodes is still immature. Therefore, we built a prototype with 62 electrodes and
recorded training datasets using an optical tracking system. We have introduced 2.5D
representation to apply convolutional neural network methods on a capacitive image
of the curved surface, and two types of network architectures based on recent achievements
in the computer vision field were evaluated with our dataset. We also implemented
real-time interactive applications using the prototype and demonstrated the possibility
of intuitive interaction using fingers in VR applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human computer interactiton, hand pose estimation, finger tracking controller, virtual reality, capacitive image},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376713,
author = {Dema, Tshering and Brereton, Margot and Esteban, Michael and Soro, Alessandro and Sherub, Sherub and Roe, Paul},
title = {Designing in the Network of Relations for Species Conservation: The Playful Tingtibi Community Birdhouse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376713},
doi = {10.1145/3313831.3376713},
abstract = {This paper investigates connecting people in remote communities through nature in
order to foster stewardship and conservation of endangered species. Global citizen
science technologies have found success in urban, developed countries, but they typically
rely on large distributed populations to gather or analyze data and do not suit sparsely
populated and remote contexts. We undertook a long-term field study to iteratively
co-design a tangible and playful nature engagement prototype in a remote World Heritage
Area community. The prototype design fosters learning through ambient sounds as well
as exploration and discovery of species through nature soundscape recordings. We found
that the prototypes amplified locals' interest, became embedded in community relations
and gradually led to placemaking of new engagement 'spaces' and of newer forms. We
contribute lessons learned on how design can foster nature engagement and stewardship
of endangered species by heeding Suchman's call for design to "enter networks of relations
that make technology possible". We contribute design implications and new design foci
HCI/Citizen science engagement for species conservation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {social and playful, network of relations, nature engagement, endangered species stewardship, wilderness soundscapes, tingtibi birdhouse, citizen science interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376714,
author = {Dehesa, Javier and Vidler, Andrew and Lutteroth, Christof and Padget, Julian},
title = {Touch\'{e}: Data-Driven Interactive Sword Fighting in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376714},
doi = {10.1145/3313831.3376714},
abstract = {VR games offer new freedom for players to interact naturally using motion. This makes
it harder to design games that react to player motions convincingly. We present a
framework for VR sword fighting experiences against a virtual character that simplifies
the necessary technical work to achieve a convincing simulation. The framework facilitates
VR design by abstracting from difficult details on the lower "physical" level of interaction,
using data-driven models to automate both the identification of user actions and the
synthesis of character animations. Designers are able to specify the character's behaviour
on a higher "semantic" level using parameterised building blocks, which allow for
control over the experience while minimising manual development work. We conducted
a technical evaluation, a questionnaire study and an interactive user study. Our results
suggest that the framework produces more realistic and engaging interactions than
simple hand-crafted interaction logic, while supporting a controllable and understandable
behaviour design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {animation, sword fighting, virtual reality, gesture recognition, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376715,
author = {Huang, Chieh-Yang and Huang, Shih-Hong and Huang, Ting-Hao Kenneth},
title = {Heteroglossia: In-Situ Story Ideation with the Crowd},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376715},
doi = {10.1145/3313831.3376715},
abstract = {Ideation is essential for creative writing. Many authors struggle to come up with
ideas throughout the writing process, yet modern writing tools fail to provide on-the-spot
assistance for writers when they get stuck. This paper introduces Heteroglossia, an
add-on for Google Docs that allows writers to elicit story ideas from the online crowd
using their text editors. Writers can share snippets of their working drafts and ask
the crowd to provide follow-up story ideas based on it. Heteroglossia employs a strategy
called "role play", where each worker is assigned a fictional character in a story
and asked to brainstorm plot ideas from that character's perspective. Our deployment
with two experienced story writers shows that Heteroglossia is easy to use and can
generate interesting ideas. Heteroglossia allows us to gain insight into how future
technologies can be developed to support ideation in creative writing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {role play, crowdsourcing, story, ideation, creative writing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376716,
author = {Ahmadi, Michael and Eilert, Rebecca and Weibert, Anne and Wulf, Volker and Marsden, Nicola},
title = {Feminist Living Labs as Research Infrastructures for HCI: The Case of a Video Game Company},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376716},
doi = {10.1145/3313831.3376716},
abstract = {The number of women in IT is still low and companies struggle to integrate female
professionals. The aim of our research is to provide methodological support for understanding
and sharing experiences of gendered practices in the IT industry and encouraging sustained
reflection about these matters over time. We established a Living Lab with that end
in view, aiming to enhance female participation in the IT workforce and committing
ourselves to a participatory approach to the sharing of women's experiences. Here,
using the case of a German video game company which participated in our Lab, we detail
our lessons learned. We show that this kind of long-term participation involves challenges
over the lifetime of the project but can lead to substantial benefits for organizations.
Our findings demonstrate that Living Labs are suitable for giving voice to marginalized
groups, addressing their concerns and evoking change possibilities. Nevertheless,
uncertainties about long-term sustainability remain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {feminist research, feminist HCI, participatory action research, methodology, living lab, gender, ethnography},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376717,
author = {Dillahunt, Tawanna R. and Hsiao, Joey Chiao-Yin},
title = {Positive Feedback and Self-Reflection: Features to Support Self-Efficacy among Underrepresented Job Seekers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376717},
doi = {10.1145/3313831.3376717},
abstract = {Technologies play a key role in finding employment in today's job market. However,
the majority of those who are unemployed, e.g., individuals who have limited education
or who are racial and ethnic minorities, are not well supported by existing digital
employment tools. Therefore, we conducted an 8-month randomized field experiment to
evaluate two tools-Review-Me and Interview4-designed to address these job seekers'
key employment needs. We used the Theory of Planned Behavior to examine the tools'
effects on three factors influencing job seekers' job search intention: job search
self-efficacy, subjective norms, and job search attitudes. Our interview data suggested
that the tools positively affected all factors, but our survey results were mixed.
Interview results suggest that these trends were caused by positive feedback and self-reflection.
We contribute ways to integrate these two features into future tools for, and techniques
to increase study retention among, underrepresented job seekers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {underrepresented job seekers, theory of planned behavior, employment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376718,
author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
title = {A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376718},
doi = {10.1145/3313831.3376718},
abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes.
However, these gains have yet to be fully demonstrated in real world clinical settings.
In this paper, we describe a human-centered study of a deep learning system used in
clinics for the detection of diabetic eye disease. From interviews and observation
across eleven clinics in Thailand, we characterize current eye-screening workflows,
user expectations for an AI-assisted screening process, and post-deployment experiences.
Our findings indicate that several socio-environmental factors impact model performance,
nursing workflows, and the patient experience. We draw on these findings to reflect
on the value of conducting human-centered evaluative research alongside prospective
evaluations of model accuracy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human-centered ai, deep learning, diabetes, health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376719,
author = {Hoppe, Matthias and Rossmy, Beat and Neumann, Daniel Peter and Streuber, Stephan and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {A Human Touch: Social Touch Increases the Perceived Human-Likeness of Agents in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376719},
doi = {10.1145/3313831.3376719},
abstract = {Virtual Reality experiences and games present believable virtual environments based
on graphical quality, spatial audio, and interactivity. The interaction with in-game
characters, controlled by computers (agents) or humans (avatars), is an important
part of VR experiences. Pre-captured motion sequences increase the visual humanoid
resemblance. However, this still precludes realistic social interactions (eye contact,
imitation of body language), particularly for agents. We aim to make social interaction
more realistic via social touch. Social touch is non-verbal, conveys feelings and
signals (coexistence, closure, intimacy). In our research, we created an artificial
hand to apply social touch in a repeatable and controlled fashion to investigate its
effect on the perceived human-likeness of avatars and agents. Our results show that
social touch is effective to further blur the boundary between computer- and human-controlled
virtual characters and contributes to experiences that closely resemble human-to-human
interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {human-likeness, social touch, agency, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376720,
author = {B\"{u}ttner, Sebastian and Prilla, Michael and R\"{o}cker, Carsten},
title = {Augmented Reality Training for Industrial Assembly Work - Are Projection-Based AR Assistive Systems an Appropriate Tool for Assembly Training?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376720},
doi = {10.1145/3313831.3376720},
abstract = {Augmented Reality (AR) systems are on their way to industrial application, e.g. projection-based
AR is used to enhance assembly work. Previous studies showed advantages of the systems
in permanent-use scenarios, such as faster assembly times. In this paper, we investigate
whether such systems are suitable for training purposes. Within an experiment, we
observed the training with a projection-based AR system over multiple sessions and
compared it with a personal training and a paper manual training. Our study shows
that projection-based AR systems offer only small benefits in the training scenario.
While a systematic mislearning of content is prevented through immediate feedback,
our results show that the AR training does not reach the personal training in terms
of speed and recall precision after 24 hours. Furthermore, we show that once an assembly
task is properly trained, there are no differences in the long-term recall precision,
regardless of the training method.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {projection-based augmented reality, industrial augmented reality, training, assistive system, assembly, experiment, empirical study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376721,
author = {Zhong, Ce and Wakkary, Ron and Zhang, Xiao and Chen, Amy Yo Sue},
title = {TransTexture Lamp: Understanding Lived Experiences with Deformation Through a Materiality Lens},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376721},
doi = {10.1145/3313831.3376721},
abstract = {This paper provides a materiality perspective to understanding lived experiences with
a deformable domestic artefact, named transTexture lamp. The lamp is an interactive
light with a deformable lampshade surface. We deployed transTexture lamps in the homes
of three professional designers for two months with the aim of exploring possible
interactions and engagements with the deformable lamp. Our findings show how participants
experienced transTexture through pleasurable interactions and how they experienced
deformation over time from reflections on these interactions. Analyzing the data through
a materiality lens unpacked a creative process of drawing on the deformable lampshade
surface, which results in the accumulation of substrates and transformations of deformations.
These findings suggest opportunities for future material-centered interaction design
research and practices in HCI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {deformation, materiality, computational design, material-centered interaction design, research-through-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376722,
author = {Ashtari, Narges and Bunt, Andrea and McGrenere, Joanna and Nebeling, Michael and Chilana, Parmit K.},
title = {Creating Augmented and Virtual Reality Applications: Current Practices, Challenges, and Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376722},
doi = {10.1145/3313831.3376722},
abstract = {Augmented Reality (AR) and Virtual Reality (VR) devices are becoming easier to access
and use, but the barrier to entry for creating AR/VR applications remains high. Although
the recent spike in HCI research on novel AR/VR tools is promising, we lack insights
into how AR/VR creators use today's state-of-the-art authoring tools as well as the
types of challenges that they face. We interviewed 21 AR/VR creators, which we grouped
into hobbyists, domain experts, and professional designers. Despite having a variety
of motivations and skillsets, they described similar challenges in designing and building
AR/VR applications. We synthesize 8 key barriers that AR/VR creators face nowadays,
starting from prototyping the initial experiences to dealing with "the many unknowns"
during implementation, to facing difficulties in testing applications. Based on our
analysis, we discuss the importance of considering end-user developers as a growing
population of AR/VR creators, how we can build learning opportunities into AR/VR tools,
and the need for building AR/VR toolchains that integrate debugging and testing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {AR/VR authoring, AR/VR design, AR/VR development, augmented reality, end-user development, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376723,
author = {Tyack, April and Mekler, Elisa D.},
title = {Self-Determination Theory in HCI Games Research: Current Uses and Open Questions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376723},
doi = {10.1145/3313831.3376723},
abstract = {Self-Determination Theory (SDT), a major psychological theory of human motivation,
has become increasingly popular in Human-Computer Interaction (HCI) research on games
and play. However, it remains unclear how SDT has advanced HCI games research, or
how HCI games scholars engage with the theory. We reviewed 110 CHI and CHI PLAY papers
that cited SDT to gain a better understanding of the ways the theory has contributed
to HCI games research. We find that SDT, and in particular, the concepts of need satisfaction
and intrinsic motivation, have been widely applied to analyse the player experience
and inform game design. Despite the popularity of SDT-based measures, however, prominent
core concepts and mini-theories are rarely considered explicitly, and few papers engage
with SDT beyond descriptive accounts. We highlight conceptual gaps at the intersection
of SDT and HCI games research, and identify opportunities for SDT propositions, concepts,
and measures to more productively inform future work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–22},
numpages = {22},
keywords = {theory, gamification, self-determination theory, games, motivation, player experience, play},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376724,
author = {Ruvimova, Anastasia and Kim, Junhyeok and Fritz, Thomas and Hancock, Mark and Shepherd, David C.},
title = {"Transport Me Away": Fostering Flow in Open Offices through Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376724},
doi = {10.1145/3313831.3376724},
abstract = {Open offices are cost-effective and continue to be popular. However, research shows
that these environments, brimming with distractions and sensory overload, frequently
hamper productivity. Our research investigates the use of virtual reality (VR) to
mitigate distractions in an open office setting and improve one's ability to be in
flow. In a lab study, 35 participants performed visual programming tasks in four combinations
of physical (open or closed office) and virtual environments (beach or virtual office).
While participants both preferred and were in flow more in a closed office without
VR, in an open office, the VR environments outperformed the no VR condition in all
measures of flow, performance, and preference. Especially considering the recent rapid
advancements in VR, our findings illustrate the potential VR has to improve flow and
satisfaction in open offices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {work, open offices, flow, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376725,
author = {Park, Eunji and Lee, Byungjoo},
title = {An Intermittent Click Planning Model},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376725},
doi = {10.1145/3313831.3376725},
abstract = {Pointing is the task of tracking a target with a pointer and confirming the target
selection through a click action when the pointer is positioned within the target.
Little is known about the mechanism by which users plan and execute the click action
in the middle of the target tracking process. The Intermittent Click Planning model
proposed in this study describes the process by which users plan and execute optimal
click actions, from which the model predicts the pointing error rates. In two studies
in which users pointed to a stationary target and a moving target, the model proved
to accurately predict the pointing error rates (R2 = 0.992 and 0.985, respectively).
The model has also successfully identified differences in cognitive characteristics
among first-person shooter game players.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cue integration, pointing, intermittent control, click model, temporal pointing, internal clock},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376726,
author = {Wang, Xingbo and Zeng, Haipeng and Wang, Yong and Wu, Aoyu and Sun, Zhida and Ma, Xiaojuan and Qu, Huamin},
title = {VoiceCoach: Interactive Evidence-Based Training for Voice Modulation Skills in Public Speaking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376726},
doi = {10.1145/3313831.3376726},
abstract = {The modulation of voice properties, such as pitch, volume, and speed, is crucial for
delivering a successful public speech. However, it is challenging to master different
voice modulation skills. Though many guidelines are available, they are often not
practical enough to be applied in different public speaking situations, especially
for novice speakers. We present VoiceCoach, an interactive evidence-based approach
to facilitate the effective training of voice modulation skills. Specifically, we
have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED
Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically
recommends good voice modulation examples from the dataset based on the similarity
of both sentence structures and voice modulation skills. Immediate and quantitative
visual feedback is provided to guide further improvement. The expert interviews and
the user study provide support for the effectiveness and usability of VoiceCoach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {public speaking, evidence-based training, data visualization, voice modulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376727,
author = {Long, Duri and Magerko, Brian},
title = {What is AI Literacy? Competencies and Design Considerations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376727},
doi = {10.1145/3313831.3376727},
abstract = {Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology,
but public understanding of these technologies is often limited. There is a need for
additional HCI research investigating a) what competencies users need in order to
effectively interact with and critically evaluate AI and b) how to design learner-centered
AI technologies that foster increased user understanding of AI. This paper takes a
step towards realizing both of these goals by providing a concrete definition of AI
literacy based on existing research. We synthesize a variety of interdisciplinary
literature into a set of core competencies of AI literacy and suggest several design
considerations to support AI developers and educators in creating learner-centered
AI. These competencies and design considerations are organized in a conceptual framework
thematically derived from the literature. This paper's contributions can be used to
start a conversation about and guide future research on AI literacy within the HCI
community.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {machine learning, artificial intelligence, computing education, AI literacy, AI education, AI for K-12},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376728,
author = {Gleason, Cole and Pavel, Amy and McCamey, Emma and Low, Christina and Carrington, Patrick and Kitani, Kris M. and Bigham, Jeffrey P.},
title = {Twitter A11y: A Browser Extension to Make Twitter Images Accessible},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376728},
doi = {10.1145/3313831.3376728},
abstract = {Social media platforms are integral to public and private discourse, but are becoming
less accessible to people with vision impairments due to an increase in user-posted
images. Some platforms (i.e. Twitter) let users add image descriptions (alternative
text), but only 0.1% of images include these. To address this accessibility barrier,
we created Twitter A11y, a browser extension to add alternative text on Twitter using
six methods. For example, screenshots of text are common, so we detect textual images,
and create alternative text using optical character recognition. Twitter A11y also
leverages services to automatically generate alternative text or reuse them from across
the web. We compare the coverage and quality of Twitter A11y's six alt-text strategies
by evaluating the timelines of 50 self-identified blind Twitter users. We find that
Twitter A11y increases alt-text coverage from 7.6% to 78.5%, before crowdsourcing
descriptions for the remaining images. We estimate that 57.5% of returned descriptions
are high-quality. We then report on the experiences of 10 participants with visual
impairments using the tool during a week-long deployment. Twitter A11y increases access
to social media platforms for people with visual impairments by providing high-quality
automatic descriptions for user-posted images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessibility, social media, screen reader, twitter},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376729,
author = {Chattopadhyay, Souti and Prasad, Ishita and Henley, Austin Z. and Sarma, Anita and Barik, Titus},
title = {What's Wrong with Computational Notebooks? Pain Points, Needs, and Design Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376729},
doi = {10.1145/3313831.3376729},
abstract = {Computational notebooks - such as Azure, Databricks, and Jupyter - are a popular,
interactive paradigm for data scientists to author code, analyze data, and interleave
visualizations, all within a single document. Nevertheless, as data scientists incorporate
more of their activities into notebooks, they encounter unexpected difficulties, or
pain points, that impact their productivity and disrupt their workflow. Through a
systematic, mixed-methods study using semi-structured interviews (n=20) and survey
(n=156) with data scientists, we catalog nine pain points when working with notebooks.
Our findings suggest that data scientists face numerous pain points throughout the
entire workflow - from setting up notebooks to deploying to production - across many
notebook environments. Our data scientists report essential notebook requirements,
such as supporting data exploration and visualization. The results of our study inform
and inspire the design of computational notebooks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {computational notebooks, data science, survey, challenges, interviews, pain points},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376730,
author = {Sterman, Sarah and Huang, Evey and Liu, Vivian and Paulos, Eric},
title = {Interacting with Literary Style through Computational Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376730},
doi = {10.1145/3313831.3376730},
abstract = {Style is an important aspect of writing, shaping how audiences interpret and engage
with literary works. However, for most people style is difficult to articulate precisely.
While users frequently interact with computational word processing tools with well-defined
metrics, such as spelling and grammar checkers, style is a significantly more nuanced
concept. In this paper, we present a computational technique to help surface style
in written text. We collect a dataset of crowdsourced human judgments of style, derive
a model of style by training a neural net on this data, and present novel applications
for visualizing and browsing style across broad bodies of literature, as well as an
interactive text editor with real-time style feedback. We study these interactive
style applications with users and discuss implications for enabling this novel approach
to style.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {artifact or system, text/speech/language, creativity support, humanities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376731,
author = {Arawjo, Ian},
title = {To Write Code: The Cultural Fabrication of Programming Notation and Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376731},
doi = {10.1145/3313831.3376731},
abstract = {Writing and its means have become detached. Unlike written and drawn practices developed
prior to the 20th century, notation for programming computers developed in concert
and conflict with discretizing infrastructure such as the shift-key typewriter and
data processing pipelines. In this paper, I recall the emergence of high-level notation
for representing computation. I show how the earliest inventors of programming notations
borrowed from various written cultural practices, some of which came into conflict
with the constraints of digitizing machines, most prominently the typewriter. As such,
I trace how practices of "writing code" were fabricated along social, cultural, and
material lines at the time of their emergence. By juxtaposing early visions with the
modern status quo, I question long-standing terminology, dichotomies, and epistemological
tendencies in the field of computer programming. Finally, I argue that translation
work is a fundamental property of the practice of writing code by advancing an intercultural
lens on programming practice rooted in history.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {programming, materiality, notation, culture, infrastructure},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376732,
author = {Wambsganss, Thiemo and Niklaus, Christina and Cetto, Matthias and S\"{o}llner, Matthias and Handschuh, Siegfried and Leimeister, Jan Marco},
title = {AL: An Adaptive Learning Support System for Argumentation Skills},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376732},
doi = {10.1145/3313831.3376732},
abstract = {Recent advances in Natural Language Processing (NLP) bear the opportunity to analyze
the argumentation quality of texts. This can be leveraged to provide students with
individual and adaptive feedback in their personal learning journey. To test if individual
feedback on students' argumentation will help them to write more convincing texts,
we developed AL, an adaptive IT tool that provides students with feedback on the argumentation
structure of a given text. We compared AL with 54 students to a proven argumentation
support tool. We found students using AL wrote more convincing texts with better formal
quality of argumentation compared to the ones using the traditional approach. The
measured technology acceptance provided promising results to use this tool as a feedback
application in different learning settings. The results suggest that learning applications
based on NLP may have a beneficial use for developing better writing and reasoning
for students in traditional learning settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {pedagogical systems, educational applications, argumentation learning, adaptive learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376733,
author = {Batch, Andrea and Patnaik, Biswaksen and Akazue, Moses and Elmqvist, Niklas},
title = {Scents and Sensibility: Evaluating Information Olfactation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376733},
doi = {10.1145/3313831.3376733},
abstract = {Olfaction---the sense of smell---is one of the least explored of the human senses
for conveying abstract information. In this paper, we conduct a comprehensive perceptual
experiment on information olfactation: the use of olfactory and cross-modal sensory
marks and channels to convey data. More specifically, following the example from graphical
perception studies, we design an experiment that studies the perceptual accuracy of
four cross-modal sensory channels---scent type, scent intensity, airflow, and temperature---for
conveying three different types of data---nominal, ordinal, and quantitative. We also
present details of a 24-scent multi-sensory display and its software framework that
we designed in order to run this experiment. Our results yield a ranking of olfactory
and cross-modal sensory channels that follows similar principles as classic rankings
for visual channels.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {evaluation, olfactory displays, scents, information olfactation, olfactory perception, smell},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376734,
author = {Dechant, Martin and Poeller, Susanne and Johanson, Colby and Wiley, Katelyn and Mandryk, Regan L.},
title = {In-Game and Out-of-Game Social Anxiety Influences Player Motivations, Activities, and Experiences in MMORPGs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376734},
doi = {10.1145/3313831.3376734},
abstract = {Socializing is an important part of why people choose to play games and is at the core of many game mechanics. Anxiety and fear about social interactions can lead to withdrawal from socializing in the physical world, yet players with social anxiety preferentially choose MMORPGs — a highly social genre — raising questions of whether social anxiety expresses differently during in-game interactions. In the present study (N=181), we explore whether and how social anxiety translates into MMORPGs. By developing a measure of in-game social anxiety, we find that although fear and apprehension of socializing in the physical and game worlds are related, they differently affect preferences, behaviours, and experiences. Social anxiety in the physical world drives reasons for playing, whereas in-game anxiety affects behaviours, reducing participation in activities related to socializing and difficult in-game challenges. Our findings can inform the design of social games and the links between social anxiety and social gaming.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {online gaming, MMORPG, socializing, social anxiety},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376735,
author = {Kim, Sunjun and Lee, Byungjoo and van Gemert, Thomas and Oulasvirta, Antti},
title = {Optimal Sensor Position for a Computer Mouse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376735},
doi = {10.1145/3313831.3376735},
abstract = {Computer mice have their displacement sensors in various locations (center, front,
and rear). However, there has been little research into the effects of sensor position
or on engineering approaches to exploit it. This paper first discusses the mechanisms
via which sensor position affects mouse movement and reports the results from a study
of a pointing task in which the sensor position was systematically varied. Placing
the sensor in the center turned out to be the best compromise: improvements over front
and rear were in the 11-14% range for throughput and 20--23% for path deviation. However,
users varied in their personal optima. Accordingly, variable-sensor-position mice
are then presented, with a demonstration that high accuracy can be achieved with two
static optical sensors. A virtual sensor model is described that allows software-side
repositioning of the sensor. Individual-specific calibration should yield an added
4% improvement in throughput over the default center position.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pointing performance, optimization, mouse, virtual sensor position, computer, sensor position},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376736,
author = {Okuya, Yujiro and Gladin, Olivier and Ladev\`{e}ze, Nicolas and Fleury, C\'{e}dric and Bourdot, Patrick},
title = {Investigating Collaborative Exploration of Design Alternatives on a Wall-Sized Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376736},
doi = {10.1145/3313831.3376736},
abstract = {Industrial design review is an iterative process which mainly relies on two steps
involving many stakeholders: design discussion and CAD data adjustment. We investigate
how a wall-sized display could be used to merge these two steps by allowing multidisciplinary
collaborators to simultaneously generate and explore design alternatives. We designed
ShapeCompare based on the feedback from a usability study. It enables multiple users
to compute and distribute CAD data with touch interaction. To assess the benefit of
the wall-sized display in such context, we ran a controlled experiment which aims
to compare ShapeCompare with a visualization technique suitable for standard screens.
The results show that pairs of participants performed a constraint solving task faster
and used more deictic instructions with ShapeCompare. From these findings, we draw
generic recommendations for collaborative exploration of alternatives.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {wall-sized display, collaboration, computer-aided design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376737,
author = {Wang, Yanan and Amores, Judith and Maes, Pattie},
title = {On-Face Olfactory Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376737},
doi = {10.1145/3313831.3376737},
abstract = {On-face wearables are currently limited to piercings, tattoos, or interactive makeup
that aesthetically enhances the user, and have been minimally used for scent-delivery
methods. However, on-face scent interfaces could provide an advantage for personal
scent delivery in comparison with other modalities or body locations since they are
closer to the nose. In this paper, we present the mechanical and industrial design
details of a series of form factors for on-face olfactory wearables that are lightweight
and can be adhered to the skin or attached to glasses or piercings. We assessed the
usability of three prototypes by testing with 12 participants in a within-subject
study design while they were interacting in pairs at a close personal distance. We
compare two of these designs with an "off-face" olfactory necklace and evaluate their
social acceptance, comfort as well as perceived odor intensity for both the wearer
and observer.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {scent display, olfaction, wearable device, on-face wearables, jewelry, wearability, on-face interfaces, olfactory interfaces, fashion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376738,
author = {Agarwal, Mohit and Sivakumar, Raghupathy},
title = {Charge for a Whole Day: Extending Battery Life for BCI Wearables Using a Lightweight Wake-Up Command},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376738},
doi = {10.1145/3313831.3376738},
abstract = {Commercially available EEG-based Brain-Computer Interface (BCI) wearable headsets
are always-on and are thus power hungry, requiring users to charge the headsets multiple
times a day. In this paper, we tackle the problem of wake-up command design and detection
for BCI headsets, and explore how battery life can be made to last for approximately
a whole day. The key challenge that we address is enabling the headset to operate
in a near-sleep mode but still reliably detect and interpret an EEG-based wake-up
command from the user. Towards addressing the challenge, we present a solution that
is built upon eye-blinks. Our core contribution is Trance, a user-friendly and robust
wake-up command for BCI headsets that is computationally lightweight. We show using
experimental results coupled with multiple data sets collected through user-studies
that Trance can extend battery life by approximately 2.7x or to approximately 10 hours
for a typical wearable battery, while remaining user-friendly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {eye tracking, input techniques, interaction design, wearable systems, brain-computer interfaces (bcis)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376739,
author = {Louie, Ryan and Coenen, Andy and Huang, Cheng Zhi and Terry, Michael and Cai, Carrie J.},
title = {Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376739},
doi = {10.1145/3313831.3376739},
abstract = {While generative deep neural networks (DNNs) have demonstrated their capacity for
creating novel musical compositions, less attention has been paid to the challenges
and potential of co-creating with these musical AIs, especially for novices. In a
needfinding study with a widely used, interactive musical AI, we found that the AI
can overwhelm users with the amount of musical content it generates, and frustrate
them with its non-deterministic output. To better match co-creation needs, we developed
AI-steering tools, consisting of Voice Lanes that restrict content generation to particular
voices; Example-Based Sliders to control the similarity of generated content to an
existing example; Semantic Sliders to nudge music generation in high-level directions
(happy/sad, conventional/surprising); and Multiple Alternatives of generated content
to audition and choose from. In a summative study (N=21), we discovered the tools
not only increased users' trust, control, comprehension, and sense of collaboration
with the AI, but also contributed to a greater sense of self-efficacy and ownership
of the composition relative to the AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-creation, generative deep neural networks, human-ai interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376740,
author = {Wang, April Yi and Wu, Zihan and Brooks, Christopher and Oney, Steve},
title = {Callisto: Capturing the "Why" by Connecting Conversations with Computational Narratives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376740},
doi = {10.1145/3313831.3376740},
abstract = {When teams of data scientists collaborate on computational notebooks, their discussions
often contain valuable insight into their design decisions. These discussions not
only explain analysis in the current notebook but also alternative paths, which are
often poorly documented. However, these discussions are disconnected from the notebooks
for which they could provide valuable context. We propose Callisto, an extension to
computational notebooks that captures and stores contextual links between discussion
messages and notebook elements with minimal effort from users. Callisto allows notebook
readers to better understand the current notebook content and the overall problem-solving
process that led to it, by making it possible to browse the discussions and code history
relevant to any part of the notebook. This is particularly helpful for onboarding
new notebook collaborators to avoid misinterpretations and duplicated work, as we
found in a two-stage evaluation with 32 data science students.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {datascience, collaborative systems, computational notebooks, literate programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376741,
author = {Klefeker, Josephine and striegl, libi and Devendorf, Laura},
title = {What HCI Can Learn from ASMR: Becoming Enchanted with the Mundane},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376741},
doi = {10.1145/3313831.3376741},
abstract = {In this paper we explore how the qualities of Autonomous Sensory Meridian Response
(ASMR) media - its pairing of sonic and visual design, ability to subvert fast-paced
technology for slow experiences, production of somatic responses, and attention to
the everyday-might reveal new design possibilities for interactions with wearable
technology. We recount our year-long design inquiry into the subject which began with
an interview with a "live" ASMR creator and design probes, a series of first-person
design exercises, and resulted in the creation of two interactive garments for attending,
noticing, and becoming enchanted with our our everyday surroundings. We conclude by
suggesting that these ASMR inspired designs cultivate personal, intimate, embodied,
and felt practices of attention within our everyday, mundane, environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {smart textiles, wearable technology, sonic interaction, asmr media, enchantment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376742,
author = {Osmers, Niklas and Prilla, Michael},
title = {Getting out of Out of Sight: Evaluation of AR Mechanisms for Awareness and Orientation Support in Occluded Multi-Room Settings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376742},
doi = {10.1145/3313831.3376742},
abstract = {Augmented Reality can provide orientation and awareness in situations in which objects
or people are occluded by physical structures. This is relevant for many situations
in the workplace, where objects are scattered across rooms and people are out of sight.
While several AR mechanisms have been proposed to provide awareness and orientation
in these situations, little is known about their effect on people's performance when
searching objects and coordinating with each other. In this paper, we compare three
AR based mechanisms (map, x-ray, compass) according to their utility, usability, social
presence, task load and users' preferences. 48 participants had to work together in
groups of four to find people and objects located around different rooms. Results
show that map and x-ray performed best but provided least social presence among participants.
We discuss these and other observations as well as potential impacts on designing
AR awareness and orientation support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {ar, social presence, orientation support, occlusion, coordination, cooperation, awareness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376743,
author = {Kim, Taewan and Ruensuk, Mintra and Hong, Hwajung},
title = {In Helping a Vulnerable Bot, You Help Yourself: Designing a Social Bot as a Care-Receiver to Promote Mental Health and Reduce Stigma},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376743},
doi = {10.1145/3313831.3376743},
abstract = {Helping others can have a positive effect on both the giver and the receiver. However,
supporting someone with depression can be complicated and overwhelming. To address
this, we proposed a Facebook-based social bot displaying depressive symptoms and disclosing
vulnerable experiences that allows users to practice providing reactions online. We
investigated how 55 college students interacted with the social bot for three weeks
and how these support-giving experiences affected their mental health and stigma.
By responding to the bot, the participants reframed their own negative experiences,
reported reduced feelings of danger regarding an individual with depression and increased
willingness to help the person, and presented favorable attitudes toward seeking treatment
for depression. We discuss design opportunities for accessible social bots that could
help users to keep practicing peer support interventions without fear of negative
consequences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {stigma, health, social bot, depression, college student, mental health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376744,
author = {Smith, C. Estelle and Nevarez, Eduardo and Zhu, Haiyi},
title = {Disseminating Research News in HCI: Perceived Hazards, How-To's, and Opportunities for Innovation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376744},
doi = {10.1145/3313831.3376744},
abstract = {Mass media afford researchers critical opportunities to disseminate research findings
and trends to the general public. Yet researchers also perceive that their work can
be miscommunicated in mass media, thus generating unintended understandings of HCI
research by the general public. We conduct a Grounded Theory analysis of interviews
with 12 HCI researchers and find that miscommunication can occur at four origins along
the socio-technical infrastructure known as the Media Production Pipeline (MPP) for
science news. Results yield researchers' perceived hazards of disseminating their
work through mass media, as well as strategies for fostering effective communication
of research. We conclude with implications for augmenting or innovating new MPP technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {journalism, mass communication, mass media, media production pipeline, miscommunication, news production, science communications},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376745,
author = {Fiesler, Casey},
title = {Lawful Users: Copyright Circumvention and Legal Constraints on Technology Use},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376745},
doi = {10.1145/3313831.3376745},
abstract = {The study of human-computer interaction requires consideration of aspects of interactions
with technology that may be outside of the control of both user and designer. One
example of when a user's question of "can I do this?" may have an answer beyond technological
affordances is that of legal constraints. This paper considers an example of this
phenomenon: section 1201 of the Digital Millennium Copyright Act (DMCA) in the United
States, which criminalizes circumventing copyright protection such as digital rights
management (DRM). The DMCA also includes a triennial policymaking process that considers
exemptions to the law to protect "lawful users" from adverse effects. Through an analysis
of public comments of support for exemptions, this paper explores the ways in which
users see the law as a hindrance to desired uses of technology. This analysis sheds
light on users' expectations for rights of use, how these expectations clash with
policy, and what this might mean for technology designers. Drawing lessons from the
infrastructure problem in HCI, this paper concludes with laying out solutions that
can both work within policy constraints, and more importantly, work to change them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {drm, copyright, infrastructure, dmca, policy, accessibility, ownership, law},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376746,
author = {Bae, Suyun Sandra and Kwon, Oh-Hyun and Chandrasegaran, Senthil and Ma, Kwan-Liu},
title = {Spinneret: Aiding Creative Ideation through Non-Obvious Concept Associations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376746},
doi = {10.1145/3313831.3376746},
abstract = {Mind mapping is a popular way to explore a design space in creative thinking exercises,
allowing users to form associations between concepts. Yet, most existing digital tools
for mind mapping focus on authoring and organization, with little support for addressing
the challenges of mind mapping such as stagnation and design fixation. We present
Spinneret, a functional approach to aid mind mapping by providing suggestions based
on a knowledge graph. Spinneret uses biased random walks to explore the knowledge
graph in the neighborhood of an existing concept node in the mind map, and provides
"suggestions" for the user to add to the mind map. A comparative study with a baseline
mind-mapping tool reveals that participants created more diverse and distinct concepts
with Spinneret, and reported that the suggestions inspired them to think of ideas
they would otherwise not have explored.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {knowledge graph, creativity, suggestion, mind mapping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376747,
author = {Ghosh, Arup Kumar and Hughes, Charles E. and Wisniewski, Pamela J.},
title = {Circle of Trust: A New Approach to Mobile Online Safety for Families},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376747},
doi = {10.1145/3313831.3376747},
abstract = {Traditional parental control applications designed to protect children and teens from
online risks do so through parental restrictions and privacy-invasive monitoring.
We propose a new approach to adolescent online safety that aims to strike a balance
between a teen's privacy and their online safety through active communication and
fostering trust between parents and children. We designed and developed an Android
"app" called Circle of Trust and conducted a mixed methods user study of 17 parent-child
pairs to understand their perceptions about the app. Using a within-subjects experimental
design, we found that parents and children significantly preferred our new app design
over existing parental control apps in terms of perceived usefulness, ease of use,
and behavioral intent to use. By applying a lens of Value Sensitive Design to our
interview data, we uncovered that parents and children who valued privacy, trust,
freedom, and balance of power preferred our app over traditional apps. However, those
who valued transparency and control preferred the status quo. Overall, we found that
our app was better suited for teens than for younger children.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {adolescent online safety, parental mediation, mobile smart phones, technical monitoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376748,
author = {Kors, Martijn J.L. and van der Spek, Erik D. and Bopp, Julia A. and Millenaar, Karel and van Teutem, Rutger L. and Ferri, Gabriele and Schouten, Ben A.M.},
title = {The Curious Case of the Transdiegetic Cow, or a Mission to Foster Other-Oriented Empathy Through Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376748},
doi = {10.1145/3313831.3376748},
abstract = {Socially aware persuasive games that use immersive technologies often appeal to empathy,
prompting users to feel and understand the struggles of another. However, the often
sought-after standing in another's shoes' experience, in which users virtually inhabit
another in distress, may complicate other-oriented empathy. Following a Research through
Design approach, we designed for other-oriented empathy - focusing on a partaker-perspective
and diegetic reflection - which resulted in Permanent; a virtual reality game designed
to foster empathy towards evacuees from the 2011 Fukushima Daiichi nuclear disaster.
We deployed Permanent 'in the wild' and carried out a qualitative study with 78 participants
in the Netherlands and Japan to capture user experiences. Content Analysis of the
data showed a predominance of other-oriented empathy across countries, and in our
Thematic Analysis, we identified the themes of 'Spatial, Other, and Self -Awareness', 'Personal Accounts', 'Ambivalence', and 'Transdiegetic Items', resulting in design
insights for fostering other-oriented empathy through virtual reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, empathy, game, interactive narrative},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376749,
author = {Brul\'{e}, Emeline and Tomlinson, Brianna J. and Metatla, Oussama and Jouffrais, Christophe and Serrano, Marcos},
title = {Review of Quantitative Empirical Evaluations of Technology for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376749},
doi = {10.1145/3313831.3376749},
abstract = {Addressing the needs of visually impaired people is of continued interest in Human
Computer Interaction (HCI) research. Yet, one of the major challenges facing researchers
in this field continues to be how to design adequate quantitative empirical evaluation
for these users in HCI. In this paper, we analyse a corpus of 178 papers on technologies
designed for people with visual impairments, published since 1988, and including at
least one quantitative empirical evaluation (243 evaluations in total). To inform
future research in this area, we provide an overview, historic trends and a unified
terminology to design and report quantitative empirical evaluations. We identify open
issues and propose a set of guidelines to address them. Our analysis aims to facilitate
and stimulate future research on this topic.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {assistive technology, education, visual impairments, evaluation methods, literature review, experiments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376750,
author = {Hirsch, Tad},
title = {Practicing Without a License: Design Research as Psychotherapy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376750},
doi = {10.1145/3313831.3376750},
abstract = {This paper considers the potential for participants to experience psychotherapeutic
effects through their involvement in design research. Drawing on literature in human-computer
interaction, psychotherapy, and feminist sociology, I argue that vulnerable participants
may experience qualitative interviews therapeutically when they engage in reflexive
activity about sensitive topics with researchers who employ psychotherapeutic techniques
that encourage disclosure and reflection. I discuss ethical concerns and suggest the
need for trauma-informed research practices, updated consent procedures, and revised
pedagogy that better support researchers and participants engaged in emotionally charged
encounters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {trauma-informed research, design research, psychotherapy, semi-structured interviewing, emotion work, qualitative research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376751,
author = {Gerber, Michael A. and Schroeter, Ronald and Xiaomeng, Li and Elhenawy, Mohammed},
title = {Self-Interruptions of Non-Driving Related Tasks in Automated Vehicles: Mobile vs Head-Up Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376751},
doi = {10.1145/3313831.3376751},
abstract = {Automated driving raises new human factors challenges. There is a paradox that allows
drivers to perform non-driving related tasks (NDRTs), while benefiting from a driver
who regularly attends to the driving task. Systems that aim to better manage a driver's
attention, encouraging task switching and interleaving, may help address this paradox.
However, a better understanding of how drivers self-interrupt while engaging in NDRTs
is required to inform such systems. This paper presents a counterbalanced within-subject
simulator study with N=42 participants experiencing automated driving in a familiar
driving environment. Participants chose a TV show to watch on a HUD and mobile display
during two 15min drives on the same route. Eye and head tracking data revealed more
self-interruptions in the HUD condition, suggesting a higher likelihood of a higher
situation awareness. Our results may benefit the design of future attention management
systems by informing the visual and temporal integration of the driving and non-driving
related task.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {self-interruption, attention management, non-driving related task, human-automation interaction, task engagement, conditionally automated vehicles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376752,
author = {Kizilcec, Rene F. and Saltarelli, Andrew and Bonfert-Taylor, Petra and Goudzwaard, Michael and Hamonic, Ella and Sharrock, R\'{e}mi},
title = {Welcome to the Course: Early Social Cues Influence Women's Persistence in Computer Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376752},
doi = {10.1145/3313831.3376752},
abstract = {First impressions influence subsequent behavior, especially when deciding how much
effort to invest in an activity such as taking an online course. In computer programming
courses, a context where social group stereotypes are salient, social cues early in
the course can be used strategically to affirm members of historically underrepresented
groups in their sense of belonging. We tested this idea in two randomized field experiments
(N=53,922) by varying the social identity and status of the presenter of a welcome
video and assessing online learners' persistence and achievement. Counter to our hypotheses,
we found lower persistence among women in certain age groups if the welcome video
was presented by a female instructor or by lower-status peers. Men remained unaffected.
The results suggest that women are more responsive to social cues in online STEM courses,
an environment where their social identity has been negatively stereotyped. Presenting
a male and female instructor together was an effective strategy for retaining women
in the course.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gender, psychology, education, computer science, inclusion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376753,
author = {Hu, Donghan and Lee, Sang Won},
title = {ScreenTrack: Using a Visual History of a Computer Screen to Retrieve Documents and Web Pages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376753},
doi = {10.1145/3313831.3376753},
abstract = {Computers are used for various purposes and frequent context switch is inevitable.
In this setting, retrieving the documents, files, and web pages that have been used
for a task can be a challenge. While modern applications provide a history of recent
documents for users to resume work, this is not sufficient to retrieve all the digital
resources relevant to a given primary document. The histories currently available
- file names, web page titles, or URLs - does not take into account the complex dependencies
that exist among resources across applications. To address this problem, we tested
the idea of using a visual history of a computer screen to retrieve digital resources
within a few days through the development of ScreenTrack. ScreenTrack is software
that captures screenshots of a computer at regular intervals. It then generates a
time-lapse video from the captured screenshots and lets users retrieve a recently
opened document or web page from a screenshot that they recognize from its visuals.
Through a controlled user study, it was found that participants were able to retrieve
requested information more quickly with ScreenTrack than under the control condition.
A follow-up study showed that the participants used ScreenTrack to retrieve previously
used resources, in order to resume interrupted tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {task resumption, self-tracking, productivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376754,
author = {Votipka, Daniel and Abrokwa, Desiree and Mazurek, Michelle L.},
title = {Building and Validating a Scale for Secure Software Development Self-Efficacy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376754},
doi = {10.1145/3313831.3376754},
abstract = {Security is an essential component of the software development lifecycle. Researchers
and practitioners have developed educational interventions, guidelines, security analysis
tools, and new APIs aimed at improving security. However, measuring any resulting
improvement in secure development skill is challenging. As a proxy for skill, we propose
to measure self-efficacy, which has been shown to correlate with skill in other contexts.
Here, we present a validated scale measuring secure software-development self-efficacy
(SSD-SES). We first reviewed popular secure-development frameworks and surveyed 22
secure-development experts to identify 58 unique tasks. Next, we asked 311 developers
- over multiple rounds - to rate their skill at each task. We iteratively updated
our questions to ensure they were easily understandable, showed adequate variance
between participants, and demonstrated reliability. Our final 15-item scale contains
two sub-scales measuring belief in ability to perform vulnerability identification
and mitigation as well as security communications tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–20},
numpages = {20},
keywords = {secure development, scale development},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376755,
author = {Troiano, Giovanni Maria and Chen, Qinyu and Alba, \'{A}ngela Vargas and Robles, Gregorio and Smith, Gillian and Cassidy, Michael and Tucker-Raymond, Eli and Puttick, Gillian and Harteveld, Casper},
title = {Exploring How Game Genre in Student-Designed Games Influences Computational Thinking Development},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376755},
doi = {10.1145/3313831.3376755},
abstract = {Game design is increasingly used in modern education to foster Computational Thinking
(CT). Yet, it is unclear how and if the game genre of student-designed games impact
CT and programming. We explore how game genre impacts CT development and programming
routines in Scratch games designed by 8th-grade students using a metrics-based approach
(i.e., Dr. Scratch). Our findings show that designing particular games (e.g., action,
storytelling) impact CT and programming development. We observe, for instance, that
CT skills develop and consolidate fast, after which students can focus on aspects
more specific to game design. Based on the results, we suggest that researchers and
educators in constructionist learning consider the impact of game genre when designing
game-based curricula for the learning of programming and CT.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {Dr. Scratch, constructionist learning, game-based learning, computational thinking, video games, game design, scratch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376756,
author = {Ku, Pin-Sung and Gong, Jun and Wu, Te-Yen and Wei, Yixin and Tang, Yiwen and Ens, Barrett and Yang, Xing-Dong},
title = {Zippro: The Design and Implementation of An Interactive Zipper},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376756},
doi = {10.1145/3313831.3376756},
abstract = {Zippers are common in a wide variety of objects that we use daily. This work investigates
how we can take advantage of such common daily activities to support seamless interaction
with technology. We look beyond simple zipper-sliding interactions explored previously
to determine how to weave foreground and background interactions into a vocabulary
of natural usage patterns. We begin by conducting two user studies to understand how
people typically interact with zippers. The findings identify several opportunities
for zipper input and sensing, which inform the design of Zippro, a self-contained
prototype zipper slider, which we evaluate with a standard jacket zipper. We conclude
by demonstrating several applications that make use of the identified foreground and
background input methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {zipper, smart things, wearable},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376757,
author = {Miri, Pardis and Jusuf, Emily and Uusberg, Andero and Margarit, Horia and Flory, Robert and Isbister, Katherine and Marzullo, Keith and Gross, James J.},
title = {Evaluating a Personalizable, Inconspicuous Vibrotactile(PIV) Breathing Pacer for In-the-Moment Affect Regulation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376757},
doi = {10.1145/3313831.3376757},
abstract = {Given the prevalence and adverse impact of anxiety, there is considerable interest
in using technology to regulate anxiety. Evaluating the efficacy of such technology
in terms of both the average effect (the intervention efficacy) and the heterogeneous
effect (for whom and in what context the intervention was effective) is of paramount
importance. In this paper, we demonstrate the efficacy of PIV, a personalized breathing
pacer, in reducing anxiety in the presence of a cognitive stressor. We also quantify
the relation between our specific stressor and PIV-user engagement. To our knowledge,
this is the first mixed-design study of a vibrotactile affect regulation technology
which accounts for a specific stressor and for individual differences in relation
to the technology's efficacy. Guidelines in this paper can be applied for designing
and evaluating other affect regulation technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {affect, respiration, affect regulation, shapley values, anxiety, slow-paced breathing, haptic, linear mixed model, vibrotactile, wearable, machine learning, xgboost, pacer},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376758,
author = {Jain, Dhruv and Mack, Kelly and Amrous, Akli and Wright, Matt and Goodman, Steven and Findlater, Leah and Froehlich, Jon E.},
title = {HomeSound: An Iterative Field Deployment of an In-Home Sound Awareness System for Deaf or Hard of Hearing Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376758},
doi = {10.1145/3313831.3376758},
abstract = {We introduce HomeSound, an in-home sound awareness system for Deaf and hard of hearing
(DHH) users. Similar to the Echo Show or Nest Hub, HomeSound consists of a microphone
and display, and uses multiple devices installed in each home. We iteratively developed
two prototypes, both of which sense and visualize sound information in real-time.
Prototype 1 provided a floorplan view of sound occurrences with waveform histories
depicting loudness and pitch. A three-week deployment in four DHH homes showed an
increase in participants' home- and self-awareness but also uncovered challenges due
to lack of line of sight and sound classification. For Prototype 2, we added automatic
sound classification and smartwatch support for wearable alerts. A second field deployment
in four homes showed further increases in awareness but misclassifications and constant
watch vibrations were not well received. We discuss findings related to awareness,
privacy, and display placement and implications for future home sound awareness technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sound awareness, deaf and hard of hearing, smart home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376759,
author = {Tuncer, Sylvaine and Brown, Barry and Lindwall, Oskar},
title = {On Pause: How Online Instructional Videos Are Used to Achieve Practical Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376759},
doi = {10.1145/3313831.3376759},
abstract = {Instructional videos have become an important site of everyday learning. This paper
explores how these videos are used to complete practical tasks, analyzing video-recorded
interactions between pairs of users. Users need to repeatedly pause their videos to
be able to follow the instructions, and we document how pausing is used to coordinate
and interweave watching and doing. We describe four purposes and types of pausing:
finding task objects, turning to action, keeping up, and fixing problems. Building
on these results, we discuss how video players could better support following instructions,
and the role of basic user interface functions in complex tasks involving different
forms of engagement with the physical world and with screen-based activity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {video players, instructional videos, video interface, ethnomethodology, pause button},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376760,
author = {Trajkova, Milka and Martin-Hammond, Aqueasha},
title = {"Alexa is a Toy": Exploring Older Adults' Reasons for Using, Limiting, and Abandoning Echo},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376760},
doi = {10.1145/3313831.3376760},
abstract = {Intelligent voice assistants (IVAs) have the potential to support older adults' independent
living. However, despite a growing body of research focusing on IVA use, we know little
about why older adults become IVA non-users. This paper examines the reasons older
adults use, limit, and abandon IVAs (i.e., Amazon Echo) in their homes. We conducted
eight focus groups, with 38 older adults residing in a Life Plan Community. Thirty-six
participants owned an Echo for at least a year, and two were considering adoption.
Over time, most participants became non-users due to their difficulty finding valuable
uses, beliefs associated with ability and IVA use, or challenges with use in shared
spaces. However, we also found that participants saw the potential for future IVA
support. We contribute a better understanding of the reasons older adults do not engage
with IVAs and how IVAs might better support aging and independent living in the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {focus group, smart environments, older adults, life plan community, technology non-use, voice assistants},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376761,
author = {Khurana, Rushil and Hodges, Steve},
title = {Beyond the Prototype: Understanding the Challenge of Scaling Hardware Device Production},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376761},
doi = {10.1145/3313831.3376761},
abstract = {The hardware research and development communities have invested heavily in tools and
materials that facilitate the design and prototyping of electronic devices. Numerous
easy-to-access and easy-to-use tools have streamlined the prototyping of interactive
and embedded devices for experts and led to a remarkable growth in non-expert builders.
However, there has been little exploration of challenges associated with moving beyond
a prototype and creating hundreds or thousands of exact replicas - a process that
is still challenging for many. We interviewed 25 individuals with experience taking
prototype hardware devices into low volume production. We systematically investigated
the common issues faced and mitigation strategies adopted. We present our findings
in four main categories: (1) gaps in technical knowledge; (2) gaps in non-technical
knowledge; (3) minimum viable rigor in manufacturing preparation; and (4) building
relationships and a professional network. Our study unearthed several opportunities
for new tools and processes to support the transition beyond a working prototype to
cost effective low-volume manufacturing. These would complement the aforementioned
tools and materials that support design and prototyping.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {long tail hardware, productization, low volume electronics manufacturing, hardware device realization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376762,
author = {Gupta, Saumya and Tanenbaum, Theresa Jean and Muralikumar, Meena Devii and Marathe, Aparajita S.},
title = {Investigating Roleplaying and Identity Transformation in a Virtual Reality Narrative Experience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376762},
doi = {10.1145/3313831.3376762},
abstract = {In this paper we describe the design and evaluation of The Next Fairy Tale (TNFT)
VR, a theatrical interactive storytelling system created in virtual reality and informed
by performing arts theories. TNFT was designed to produce opportunities for interactors
to experience role-taking and character identification using design principles drawn
from actor training and theatrical performance. We report the results of a pilot qualitative
study of interactors using TNFT to explore the elements of the design that supported
or hindered roleplaying behavior. We identify four design patterns that supported
roleplaying in the system: (1) using explicit roles to set player expectations, (2)
embracing the "mask and the mirror" effect, (3) attending to visual and interactional
details, and (4) easing the player gently into the roleplaying experience. These patterns
speak to a broader need to support roleplay through explicit scaffolding of desired
player behaviors in digital narrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive performance, narrative, roleplaying, drama, virtual reality, interactive digital storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376763,
author = {Wendt, Nicola and Jensen, Rikke Bjerg and Coles-Kemp, Lizzie},
title = {Civic Empowerment through Digitalisation: The Case of Greenlandic Women},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376763},
doi = {10.1145/3313831.3376763},
abstract = {This paper explores the disruptive and transformative effects of digital technology
on gendered security asymmetries in Greenland. Through ethnographic fieldwork conducted
in Greenland and Denmark, research findings emerged through in-depth interviews, collaborative
mappings and field observations with 51 participants. Employing a critical feminist
lens, the paper identifies how Greenlandic women develop digital security practices
to respond to Greenland's ecologically, politically and socially induced transformation
processes. By connecting individual security concerns of Greenlandic women with the
broader regional context, the findings highlight how digital technology has created
transitory spaces in which collective security is cultivated, shaped and challenged.
The contribution to HCI scholarship is therefore threefold: (1) identification and
acknowledgement of gendered effects of increased usage of digital technology in remote
and hard-to-reach communities, (2) a broader conceptualisation of digital security
and (3) a recommendation for more contextualised, pluralistic digitalisation policies
and design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {digital security, indigenous identity, Greenland, women empowerment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376764,
author = {Subramanian, Krishna and Maas, Johannes and Borchers, Jan},
title = {TRACTUS: Understanding and Supporting Source Code Experimentation in Hypothesis-Driven Data Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376764},
doi = {10.1145/3313831.3376764},
abstract = {Data scientists experiment heavily with their code, compromising code quality to obtain
insights faster. We observed ten data scientists perform hypothesis-driven data science
tasks, and analyzed their coding, commenting, and analysis practice. We found that
they have difficulty keeping track of their code experiments. When revisiting exploratory
code to write production code later, they struggle to retrace their steps and capture
the decisions made and insights obtained, and have to rerun code frequently. To address
these issues, we designed TRACTUS, a system extending the popular RStudio IDE, that
detects, tracks, and visualizes code experiments in hypothesis-driven data science
tasks. TRACTUS helps recall decisions and insights by grouping code experiments into
hypotheses, and structuring information like code execution output and documentation.
Our user studies show how TRACTUS improves data scientists' workflows, and suggest
additional opportunities for improvement. TRACTUS is available as an open source RStudio
IDE addin at http://hci.rwth-aachen.de/tractus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {programming ide, data science, exploratory programming, information visualization, observational study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376765,
author = {Li, Jingyi and Brandt, Joel and Mech, Radom\'{\i}r and Agrawala, Maneesh and Jacobs, Jennifer},
title = {Supporting Visual Artists in Programming through Direct Inspection and Control of Program Execution},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376765},
doi = {10.1145/3313831.3376765},
abstract = {Programming offers new opportunities for visual art creation, but understanding and
manipulating the abstract representations that make programming powerful can pose
challenges for artists who are accustomed to manual tools and concrete visual interaction.
We hypothesize that we can reduce these barriers through programming environments
that link state to visual artwork output. We created Demystified Dynamic Brushes (DDB),
a tool that bidirectionally links code, numerical data, and artwork across the programming
interface and the execution environment - i.e., the artist's in-progress artwork.
DDB automatically records stylus input as artists draw, and stores a history of brush
state and output in relation to the input. This structure enables artists to inspect
current and past numerical input, state, and output and control program execution
through the direct selection of visual geometric elements in the drawing canvas. An
observational study suggests that artists engage in program inspection when they can
visually access geometric state information on the drawing canvas in the process of
manual drawing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {programming, creativity support tools, visual art},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376766,
author = {Kosch, Thomas and Schmidt, Albrecht and Thanheiser, Simon and Chuang, Lewis L.},
title = {One Does Not Simply RSVP: Mental Workload to Select Speed Reading Parameters Using Electroencephalography},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376766},
doi = {10.1145/3313831.3376766},
abstract = {Rapid Serial Visual Presentation (RSVP) has gained popularity as a method for presenting
text on wearable devices with limited screen space. Nonetheless, it remains unclear
how to calibrate RSVP display parameters, such as spatial alignments or presentation
rates, to suit the reader's information processing ability at high presentation speeds.
Existing methods rely on comprehension and subjective workload scores, which are influenced
by the user's knowledge base and subjective perception. Here, we use electroencephalography
(EEG) to directly determine how individual information processing varies with changes
in RSVP display parameters. Eighteen participants read text excerpts with RSVP in
a repeated-measures design that manipulated the Text Alignment and Presentation Speed
of text representation. We evaluated how predictive EEG metrics were of gains in reading
speed, subjective workload, and text comprehension. We found significant correlations
between EEG and increasing Presentation Speeds and propose how EEG can be used for
dynamic selection of RSVP parameters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {rsvp, working memory, cognitive load, electroencephalography, workload-aware interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376767,
author = {Reyes-Cruz, Gisela and Fischer, Joel E. and Reeves, Stuart},
title = {Reframing Disability as Competency: Unpacking Everyday Technology Practices of People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376767},
doi = {10.1145/3313831.3376767},
abstract = {More than a billion people in the world live with some form of visual impairment,
and a wide variety of technologies are now routinely used by them in the course of 'getting on' in everyday life. However, little is known about the ways in which assistive
and non-assistive technologies are brought to bear on material practices. We present
findings from a four-month ethnographic study facilitated by a local branch of a UK
charity that supports people with visual impairments. Our study explores mainstream
and assistive technology use within their everyday lives. We identify three main sites
for technology use: social relations and communication practices, textual reading
practices, and mobility practices. Via an ethnographic approach we contribute to understanding
how people accomplish such practices, and in doing so, uncover the practical competencies
that enable people with visual impairments to conduct their everyday activities. Thus
we investigate how disability can be thought of in terms of competencies, arguing
that understanding of competencies can enrich the design of technologies that fit
the needs of people with visual impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {disability, assistive technology, ethnomethodology, ethnography, visual impairments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376768,
author = {Tahaei, Mohammad and Vaniea, Kami and Saphra, Naomi},
title = {Understanding Privacy-Related Questions on Stack Overflow},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376768},
doi = {10.1145/3313831.3376768},
abstract = {We analyse Stack Overflow (SO) to understand challenges and confusions developers
face while dealing with privacy-related topics. We apply topic modelling techniques
to 1,733 privacy-related questions to identify topics and then qualitatively analyse
a random sample of 315 privacy-related questions. Identified topics include privacy
policies, privacy concerns, access control, and version changes. Results show that
developers do ask SO for support on privacy-related issues. We also find that platforms
such as Apple and Google are defining privacy requirements for developers by specifying
what "sensitive" information is and what types of information developers need to communicate
to users (e.g. privacy policies). We also examine the accepted answers in our sample
and find that 28% of them link to official documentation and more than half are answered
by SO users without references to any external resources.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {stack overflow, software developers, usable privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376769,
author = {Marky, Karola and Zimmermann, Verena and Funk, Markus and Daubert, J\"{o}rg and Bleck, Kira and M\"{u}hlh\"{a}user, Max},
title = {Improving the Usability and UX of the Swiss Internet Voting Interface},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376769},
doi = {10.1145/3313831.3376769},
abstract = {Up to 20% of residential votes and up to 70% of absentee votes in Switzerland are
cast online. The Swiss system aims to provide individual verifiability by different
verification codes. The voters have to carry out verification on their own, making
the usability and UX of the interface of great importance. To improve the usability,
we first performed an evaluation with 12 human-computer interaction experts to uncover
usability weaknesses of the Swiss Internet voting interface. Based on the experts'
findings, related work, and an exploratory user study with 36 participants, we propose
a redesign that we evaluated in a user study with 49 participants. Our study confirmed
that the redesign indeed improves the detection of incorrect votes by 33% and increases
the trust and understanding of the voters. Our studies furthermore contribute important
lessons for designing verifiable e-voting systems in general.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {individual verifiability, e-voting, usability evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376770,
author = {Salminen, Joni and Jung, Soon-Gyo and Chowdhury, Shammur and Seng\"{u}n, Sercan and Jansen, Bernard J.},
title = {Personas and Analytics: A Comparative User Study of Efficiency and Effectiveness for a User Identification Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376770},
doi = {10.1145/3313831.3376770},
abstract = {Personas are a well-known technique in human computer interaction. However, there
is a lack of rigorous empirical research evaluating personas relative to other methods.
In this 34-participant experiment, we compare a persona system and an analytics system,
both using identical user data, for efficiency and effectiveness for a user identification
task. Results show that personas afford faster task completion than the analytics
system, as well as outperforming analytics with significantly higher user identification
accuracy. Qualitative analysis of think-aloud transcripts shows that personas have
other benefits regarding learnability and consistency. However, the analytics system
affords insights and capabilities that personas cannot due to inherent design differences.
Findings support the use of personas to learn about users, empirically confirming
some of the stated benefits in the literature, while also highlighting the limitations
of personas that may necessitate the use of accompanying methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed methods, analytics systems, personas},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376771,
author = {Zhu, Suwen and Kim, Yoonsang and Zheng, Jingjie and Luo, Jennifer Yi and Qin, Ryan and Wang, Liuping and Fan, Xiangmin and Tian, Feng and Bi, Xiaojun},
title = {Using Bayes' Theorem for Command Input: Principle, Models, and Applications},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376771},
doi = {10.1145/3313831.3376771},
abstract = {Entering commands on touchscreens can be noisy, but existing interfaces commonly adopt
deterministic principles for deciding targets and often result in errors. Building
on prior research of using Bayes' theorem to handle uncertainty in input, this paper
formalized Bayes' theorem as a generic guiding principle for deciding targets in command
input (referred to as "BayesianCommand"), developed three models for estimating prior
and likelihood probabilities, and carried out experiments to demonstrate the effectiveness
of this formalization. More specifically, we applied BayesianCommand to improve the
input accuracy of (1) point-and-click and (2) word-gesture command input. Our evaluation
showed that applying BayesianCommand reduced errors compared to using deterministic
principles (by over 26.9% for point-and-click and by 39.9% for word-gesture command
input) or applying the principle partially (by over 28.0% and 24.5%).},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {word-gesture shortcuts, command input, point-and-click, bayes' theorem, touchscreen},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376772,
author = {Elkin, Lisa A. and Beau, Jean-Baptiste and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Manipulation, Learning, and Recall with Tangible Pen-Like Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376772},
doi = {10.1145/3313831.3376772},
abstract = {We examine two key human performance characteristics of a pen-like tangible input
device that executes a different command depending on which corner, edge, or side
contacts a surface. The manipulation time when transitioning between contacts is examined
using physical mock-ups of three representative device sizes and a baseline pen mock-up.
Results show the largest device is fastest overall and minimal differences with a
pen for equivalent transitions. Using a hardware prototype able to sense all 26 different
contacts, a second experiment evaluates learning and recall. Results show almost all
26 contacts can be learned in a two-hour session with an average of 94% recall after
24 hours. The results provide empirical evidence for the practicality, design, and
utility for this type of tangible pen-like input.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {command selection, learning, pen input, tangible interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376773,
author = {Eschler, Jordan and Burgess, Eleanor R. and Reddy, Madhu and Mohr, David C.},
title = {Emergent Self-Regulation Practices in Technology and Social Media Use of Individuals Living with Depression},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376773},
doi = {10.1145/3313831.3376773},
abstract = {Much human-computer interaction work related to depression focuses on the population
level (e.g., studying social media hashtags related to depression) or evaluates prototypes
for digital interventions to manage depression. However, little is known about how
people living with depression perceive and manage technology use, such as time spent
on social media per day. For this study, we interviewed 30 individuals living with
depression to explore their technology and social media use. We find that these individuals
demonstrated emergent practices related to self-regulation, such as learning to monitor
and adjust technology use to improve their emotional, cognitive, and behavioral health.
Our findings add a human-centered viewpoint to the relationship between living with
depression and technology and social media use. We present design implications of
these findings for better empowering individuals with depression to encourage their
natural inclinations to self-regulate technology and social media use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {qualitative, depression, self-regulation, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376774,
author = {Feltwell, Tom and Wood, Gavin and Brooker, Phillip and Rowland, Scarlett and Baumer, Eric P. S. and Long, Kiel and Vines, John and Barnett, Julie and Lawson, Shaun},
title = {Broadening Exposure to Socio-Political Opinions via a Pushy Smart Home Device},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376774},
doi = {10.1145/3313831.3376774},
abstract = {Motivated by the effects of the filter bubble and echo chamber phenomena on social
media, we developed a smart home device, Spkr, that unpredictably "pushes" socio-political
discussion topics into the home. The device utilised trending Twitter discussions,
categorised by their socio-political alignment, to present people with a purposefully
assorted range of viewpoints. We deployed Spkr in 10 homes for 28 days with a diverse
range of participants and interviewed them about their experiences. Our results show
that Spkr presents a novel means of combating selective exposure to socio-political
issues, providing participants with identifiably diverse viewpoints. Moreover, Spkr
acted as a conversational prompt for discussion within the home, initiating collective
processes and engaging those who would not often be involved in political discussions.
We demonstrate how smart home assistants can be used as a catalyst for provocation
by altering and pluralising political discussions within households.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {filter bubble, echo chamber, socio-political discussion, Nolan chart, pushy device, selective exposure, viewpoint diversity, smart home technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376775,
author = {Noguchi, Yohei and Tanaka, Fumihide},
title = {OMOY: A Handheld Robotic Gadget That Shifts Its Weight to Express Emotions and Intentions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376775},
doi = {10.1145/3313831.3376775},
abstract = {A robotic gadget that is equipped with a movable weight inside its body is developed.
By controlling the movement of the internal weight together with other robotic behaviors
such as hand gestures or speech dialogues, it is expected that emotional and/or intentional
messaging between users is enhanced. To gain knowledge for designing effective weight
shifts, an elicitation study was conducted to investigate how users holding this gadget
in their hand interpreted its 36 weight shift patterns generated by setting four basic
movement parameters (target position, trajectory, speed, and repetition). Results
present mappings between these parameters and the emotional perception of the users.
Furthermore, specific weight shift patterns that can express certain human emotions
and intentions are revealed. These findings will be useful for designing effective
weight shifts to enhance emotional and intentional messaging between users. This study
attempts to open a new dimension for the expression capability of robotic gadgets.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {expression, communication agent, elicitation study, weight shift, emotional/intentional messaging, social mediator robot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376776,
author = {Alaimi, Mehdi and Law, Edith and Pantasdo, Kevin Daniel and Oudeyer, Pierre-Yves and Sauzeon, H\'{e}l\`{e}ne},
title = {Pedagogical Agents for Fostering Question-Asking Skills in Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376776},
doi = {10.1145/3313831.3376776},
abstract = {Question asking is an important tool for constructing academic knowledge, and a self-reinforcing
driver of curiosity. However, research has found that question asking is infrequent
in the classroom and children's questions are often superficial, lacking deep reasoning.
In this work, we developed a pedagogical agent that encourages children to ask divergent-thinking
questions, a more complex form of questions that is associated with curiosity. We
conducted a study with 95 fifth grade students, who interacted with an agent that
encourages either convergent-thinking or divergent-thinking questions. Results showed
that both interventions increased the number of divergent-thinking questions and the
fluency of question asking, while they did not significantly alter children's perception
of curiosity despite their high intrinsic motivation scores. In addition, children's
curiosity trait has a mediating effect on question asking under the divergent-thinking
agent, suggesting that question-asking interventions must be personalized to each
student based on their tendency to be curious.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {question-asking, divergent vs convergent thinking, educational application, pedagogical agents, epistemic curiosity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376777,
author = {Hoffswell, Jane and Li, Wilmot and Liu, Zhicheng},
title = {Techniques for Flexible Responsive Visualization Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376777},
doi = {10.1145/3313831.3376777},
abstract = {Responsive visualizations adapt to effectively present information based on the device
context. Such adaptations are essential for news content that is increasingly consumed
on mobile devices. However, existing tools provide little support for responsive visualization
design. We analyze a corpus of 231 responsive news visualizations and discuss formative
interviews with five journalists about responsive visualization design. These interviews
motivate four central design guidelines: enable simultaneous cross-device edits, facilitate
device-specific customization, show cross-device previews, and support propagation
of edits. Based on these guidelines, we present a prototype system that allows users
to preview and edit multiple visualization versions simultaneously. We demonstrate
the utility of the system features by recreating four real-world responsive visualizations
from our corpus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {news, visualization, mobile devices, responsive design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376778,
author = {Lee, DoYoung and Lee, SooHwan and Oakley, Ian},
title = {Nailz: Sensing Hand Input with Touch Sensitive Nails},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376778},
doi = {10.1145/3313831.3376778},
abstract = {Touches between the fingers of an unencumbered hand represent a ready-to-use, eyes-free
and expressive input space suitable for interacting with wearable devices such as
smart glasses or watches. While prior work has focused on touches to the inner surface
of the hand, touches to the nails, a practical site for mounting sensing hardware,
have been comparatively overlooked. We extend prior implementations of single touch
sensing nails to a full set of five and explore their potential for wearable input.
We present design ideas and an input space of 144 touches (taps, flicks and swipes)
derived from an ideation workshop. We complement this with data from two studies characterizing
the subjective comfort and objective characteristics (task time, accuracy) of each
touch. We conclude by synthesizing this material into a set of 29 viable nail touches,
assessing their performance in a final study and illustrating how they could be used
by presenting, and qualitatively evaluating, two example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touch sensing fingernail, finger input, eyes-free, wearable},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376779,
author = {Ku, Pin-Sung and Shao, Qijia and Wu, Te-Yen and Gong, Jun and Zhu, Ziyan and Zhou, Xia and Yang, Xing-Dong},
title = {ThreadSense: Locating Touch on an Extremely Thin Interactive Thread},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376779},
doi = {10.1145/3313831.3376779},
abstract = {We propose a new sensing technique for one-dimensional touch input workable on an
interactive thread of less than 0.4 mm thick. Our technique locates up to two touches
using impedance sensing with a spacing resolution unachievable by the existing methods.
Our approach is also unique in that it locates a touch based on a mathematical model
describing the change in thread impedance in relation to the touch locations. This
allows the system to be easily calibrated by the user touching a known location(s)
on the thread. The system can thus quickly adapt to various environmental settings
and users. A system evaluation showed that our system could track the slide motion
of a finger with an average error distance of 6.13 mm and 4.16 mm using one and five
touches for calibration, respectively. The system could also distinguish between single
touch and two concurrent touches with an accuracy of 99% and could track two concurrent
touches with an average error distance of 8.55 mm. We demonstrate new interactions
enabled by our sensing approach in several unique applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {thread, touch input, impedance sensing, fabric},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376780,
author = {P\"{a}\"{a}kk\"{o}nen, Juho and Nelimarkka, Matti and Haapoja, Jesse and Lampinen, Airi},
title = {Bureaucracy as a Lens for Analyzing and Designing Algorithmic Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376780},
doi = {10.1145/3313831.3376780},
abstract = {Scholarship on algorithms has drawn on the analogy between algorithmic systems and
bureaucracies to diagnose shortcomings in algorithmic decision-making. We extend the
analogy further by drawing on Michel Crozier's theory of bureaucratic organizations
to analyze the relationship between algorithmic and human decision-making power. We
present algorithms as analogous to impartial bureaucratic rules for controlling action,
and argue that discretionary decision-making power in algorithmic systems accumulates
at locations where uncertainty about the operation of algorithms persists. This key
point of our essay connects with Alkhatib and Bernstein's theory of 'street-level
algorithms', and highlights that the role of human discretion in algorithmic systems
is to accommodate uncertain situations which inflexible algorithms cannot handle.
We conclude by discussing how the analysis and design of algorithmic systems could
seek to identify and cultivate important sources of uncertainty, to enable the human
discretionary work that enhances systemic resilience in the face of algorithmic errors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {algorithmic power, street-level bureaucracies, bureaucracy, algorithmic systems, uncertainty, automated decision-making, street-level algorithms},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376781,
author = {Winkler, Rainer and Hobert, Sebastian and Salovaara, Antti and S\"{o}llner, Matthias and Leimeister, Jan Marco},
title = {Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376781},
doi = {10.1145/3313831.3376781},
abstract = {Enrollment in online courses has sharply increased in higher education. Although online
education can be scaled to large audiences, the lack of interaction between educators
and learners is difficult to replace and remains a primary challenge in the field.
Conversational agents may alleviate this problem by engaging in natural interaction
and by scaffolding learners' understanding similarly to educators. However, whether
this approach can also be used to enrich online video lectures has largely remained
unknown. We developed Sara, a conversational agent that appears during an online video
lecture. She provides scaffolds by voice and text when needed and includes a voice-based
input mode. An evaluation with 182 learners in a 2 x 2 lab experiment demonstrated
that Sara, compared to more traditional conversational agents, significantly improved
learning in a programming task. This study highlights the importance of including
scaffolding and voice-based conversational agents in online videos to improve meaningful
learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {online education, scaffolding, experiment, online videos, conversational agent, voice interaction, interactivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376782,
author = {Srinivasan, Arjun and Lee, Bongshin and Henry Riche, Nathalie and Drucker, Steven M. and Hinckley, Ken},
title = {InChorus: Designing Consistent Multimodal Interactions for Data Visualization on Tablet Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376782},
doi = {10.1145/3313831.3376782},
abstract = {While tablet devices are a promising platform for data visualization, supporting consistent
interactions across different types of visualizations on tablets remains an open challenge.
In this paper, we present multimodal interactions that function consistently across
different visualizations, supporting common operations during visual data analysis.
By considering standard interface elements (e.g., axes, marks) and grounding our design
in a set of core concepts including operations, parameters, targets, and instruments,
we systematically develop interactions applicable to different visualization types.
To exemplify how the proposed interactions collectively facilitate data exploration,
we employ them in a tablet-based system, InChorus that supports pen, touch, and speech
input. Based on a study with 12 participants performing replication and factchecking
tasks with InChorus, we discuss how participants adapted to using multimodal input
and highlight considerations for future multimodal visualization systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tablet devices, data visualization, speech, pen, touch, multimodal interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376783,
author = {Smith, C. Estelle and Yu, Bowen and Srivastava, Anjali and Halfaker, Aaron and Terveen, Loren and Zhu, Haiyi},
title = {Keeping Community in the Loop: Understanding Wikipedia Stakeholder Values for Machine Learning-Based Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376783},
doi = {10.1145/3313831.3376783},
abstract = {On Wikipedia, sophisticated algorithmic tools are used to assess the quality of edits
and take corrective actions. However, algorithms can fail to solve the problems they
were designed for if they conflict with the values of communities who use them. In
this study, we take a Value-Sensitive Algorithm Design approach to understanding a
community-created and -maintained machine learning-based algorithm called the Objective
Revision Evaluation System (ORES)---a quality prediction system used in numerous Wikipedia
applications and contexts. Five major values converged across stakeholder groups that
ORES (and its dependent applications) should: (1) reduce the effort of community maintenance,
(2) maintain human judgement as the final authority, (3) support differing peoples'
differing workflows, (4) encourage positive engagement with diverse editor groups,
and (5) establish trustworthiness of people and algorithms within the community. We
reveal tensions between these values and discuss implications for future research
to improve algorithms like ORES.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {wikipedia, machine learning, peer production, ORES, community values, value sensitive algorithm design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376784,
author = {Geeng, Christine and Yee, Savanna and Roesner, Franziska},
title = {Fake News on Facebook and Twitter: Investigating How People (Don't) Investigate},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376784},
doi = {10.1145/3313831.3376784},
abstract = {With misinformation proliferating online and more people getting news from social
media, it is crucial to understand how people assess and interact with low-credibility
posts. This study explores how users react to fake news posts on their Facebook or
Twitter feeds, as if posted by someone they follow. We conducted semi-structured interviews
with 25 participants who use social media regularly for news, temporarily caused fake
news to appear in their feeds with a browser extension unbeknownst to them, and observed
as they walked us through their feeds. We found various reasons why people do not
investigate low-credibility posts, including taking trusted posters' content at face
value, as well as not wanting to spend the extra time. We also document people's investigative
methods for determining credibility using both platform affordances and their own
ad-hoc strategies. Based on our findings, we present design recommendations for supporting
users when investigating low-credibility posts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {misinformation, social media, disinformation, verification, fake news, Facebook, trust, twitter},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376785,
author = {Kim, Soomin and Eun, Jinsu and Oh, Changhoon and Suh, Bongwon and Lee, Joonhwan},
title = {Bot in the Bunch: Facilitating Group Chat Discussion by Improving Efficiency and Participation with a Chatbot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376785},
doi = {10.1145/3313831.3376785},
abstract = {Although group chat discussions are prevalent in daily life, they have a number of
limitations. When discussing in a group chat, reaching a consensus often takes time,
members contribute unevenly to the discussion, and messages are unorganized. Hence,
we aimed to explore the feasibility of a facilitator chatbot agent to improve group
chat discussions. We conducted a needfinding survey to identify key features for a
facilitator chatbot. We then implemented GroupfeedBot, a chatbot agent that could
facilitate group discussions by managing the discussion time, encouraging members
to participate evenly, and organizing members' opinions. To evaluate GroupfeedBot,
we performed preliminary user studies that varied for diverse tasks and different
group sizes. We found that the group with GroupfeedBot appeared to exhibit more diversity
in opinions even though there were no differences in output quality and message quantity.
On the other hand, GroupfeedBot promoted members' even participation and effective
communication for the medium-sized group.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational agent, group chat, consensus, discussion, chatbot, online communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376786,
author = {La Delfa, Joseph and Baytas, Mehmet Aydin and Patibanda, Rakesh and Ngari, Hazel and Khot, Rohit Ashok and Mueller, Florian 'Floyd'},
title = {Drone Chi: Somaesthetic Human-Drone Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376786},
doi = {10.1145/3313831.3376786},
abstract = {Somaesthetics - motivated by improving life quality via appreciation for bodily and
sensory experiences - is increasingly influencing HCI designs. Investigating the potential
of drones as a material for somaesthetic HCI, we designed Drone Chi: a Tai Chi-inspired
close-range human-drone interaction experience. The design process for Drone Chi has
been informed by the soma design approach and the Somaesthetic Appreciation concept
from HCI literature. The artifact expands somaesthetic HCI by exemplifying dynamic
and intimate somaesthetic interactions with a robotic design material, and body movements
in expansive 3D space. To characterize the Drone Chi experience, we conducted an empirical
study with 32 participants. Analysis of participant accounts revealed 4 themes that
articulate different aspects of the experience: Looping Mental States, Environment,
Agency vs. Control, and Physical Narratives. From these accounts and our craft knowledge,
we derive 5 design implications to guide the development of movement-based close-range
drone interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {drones, tai chi, human-drone interaction, soma design, movement, somaesthetic appreciation, somaesthetics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376787,
author = {Yeo, Dohyeon and Kim, Gwangbin and Kim, Seungjun},
title = {Toward Immersive Self-Driving Simulations: Reports from a User Study across Six Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376787},
doi = {10.1145/3313831.3376787},
abstract = {As self-driving car technology matures, autonomous vehicle research is moving toward
building more human-centric interfaces and accountable experiences. Driving simulators
avoid many ethical and regulatory concerns about self-driving cars and play a key
role in testing new interfaces or autonomous driving scenarios. However, apart from
validity studies for manual driving simulation, the capabilities of driving simulators
in replicating the experience of self-driving cars have not been widely investigated.
In this paper, we build six self-driving simulation platforms with varying levels
of visual and motion fidelities ranging from a screen-based in-lab simulator to the
mixed-reality on-road simulator we propose. We compare the sense of presence and simulator
sickness for each simulator composition, as well as its visual and motion fidelities
with a user study. Our novel mixed-reality automotive driving simulator, named MAXIM,
showed highest fidelity and presence. Our findings suggest how visual and motion configurations
affect experience in autonomous driving simulators.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user studies, mixed reality, driving simulator, on-road simulation, immersive technology, autonomous driving},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376788,
author = {Niforatos, Evangelos and Palma, Adam and Gluszny, Roman and Vourvopoulos, Athanasios and Liarokapis, Fotis},
title = {Would You Do It?: Enacting Moral Dilemmas in Virtual Reality for Understanding Ethical Decision-Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376788},
doi = {10.1145/3313831.3376788},
abstract = {A moral dilemma is a decision-making paradox without unambiguously acceptable or preferable
options. This paper investigates if and how the virtual enactment of two renowned
moral dilemmas---the Trolley and the Mad Bomber---influence decision-making when compared
with mentally visualizing such situations. We conducted two user studies with two
gender-balanced samples of 60 participants in total that compared between paper-based
and virtual-reality (VR) conditions, while simulating 5 distinct scenarios for the
Trolley dilemma, and 4 storyline scenarios for the Mad Bomber's dilemma. Our findings
suggest that the VR enactment of moral dilemmas further fosters utilitarian decision-making,
while it amplifies biases such as sparing juveniles and seeking retribution. Ultimately,
we theorize that the VR enactment of renowned moral dilemmas can yield ecologically-valid
data for training future Artificial Intelligence (AI) systems on ethical decision-making,
and we elicit early design principles for the training of such systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ethics, decision-making, moral dilemmas, ethical AI, VR},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376789,
author = {Cambre, Julia and Colnago, Jessica and Maddock, Jim and Tsai, Janice and Kaye, Jofish},
title = {Choice of Voices: A Large-Scale Evaluation of Text-to-Speech Voice Quality for Long-Form Content},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376789},
doi = {10.1145/3313831.3376789},
abstract = {The advancement of text-to-speech (TTS) voices and a rise of commercial TTS platforms
allow people to easily experience TTS voices across a variety of technologies, applications,
and form factors. As such, we evaluated TTS voices for long-form content: not individual
words or sentences, but voices that are pleasant to listen to for several minutes
at a time. We introduce a method using a crowdsourcing platform and an online survey
to evaluate voices based on listening experience, perception of clarity and quality,
and comprehension. We evaluated 18 TTS voices, three human voices, and a text-only
control condition. We found that TTS voices are close to rivaling human voices, yet
no single voice outperforms the others across all evaluation dimensions. We conclude
with considerations for selecting text-to-speech voices for long-form content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {voice interface, voice quality, long-form, text-to-speech, synthesized speech, tts, listening experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376790,
author = {Glenn, Terrell and Ipsita, Ananya and Carithers, Caleb and Peppler, Kylie and Ramani, Karthik},
title = {StoryMakAR: Bringing Stories to Life With An Augmented Reality &amp; Physical Prototyping Toolkit for Youth},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376790},
doi = {10.1145/3313831.3376790},
abstract = {Makerspaces can support educational experiences in prototyping for children. Storytelling
platforms enable high levels of creativity and expression, but have high barriers
of entry. We introduce StoryMakAR, which combines making and storytelling. StoryMakAR
is a new AR-IoT system for children that uses block programming, physical prototyping,
and event-based storytelling to bring stories to life. We reduce the barriers to entry
for youth (Age=14-18) by designing an accessible, plug-and-play system through merging
both electro-mechanical devices and virtual characters to create stories. We describe
our initial design process, the evolution and workflow of StoryMakAR, and results
from multiple single-session workshops with 33 high school students. Our preliminary
studies led us to understand what students want to make. We provide evidence of how
students both engage and have difficulties with maker-based storytelling. We also
discuss the potential for StoryMakAR to be used as a learning environment for classrooms
and younger students.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {augmented reality, children, maker culture, storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376791,
author = {Naiakshina, Alena and Danilova, Anastasia and Gerlitz, Eva and Smith, Matthew},
title = {On Conducting Security Developer Studies with CS Students: Examining a Password-Storage Study with CS Students, Freelancers, and Company Developers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376791},
doi = {10.1145/3313831.3376791},
abstract = {Ecological validity is a major concern in usable security studies with developers.
Many studies are conducted with computer science (CS) students out of convenience,
since recruiting professional software developers in sufficient numbers is very challenging.
In a password-storage study, Naiakshina et al. (CHI'19) showed that CS students behave
similarly to freelance developers recruited online. While this is a promising result
for conducting developer studies with students, an open question remains: Do professional
developers employed in companies behave similarly as well? To provide more insight
into the ecological validity of recruiting students for security developer studies,
we replicated the study of Naiakshina et al. with developers from diverse companies
in Germany. We found that developers employed in companies performed better than students
and freelancers in a direct comparison. However, treatment effects were found to be
significant in all groups; the treatment effects on CS students also held for company
developers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {developer password study, usable security and privacy, student developer, security developer study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376792,
author = {Lindley, Joseph and Akmal, Haider Ali and Pilling, Franziska and Coulton, Paul},
title = {Researching AI Legibility through Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376792},
doi = {10.1145/3313831.3376792},
abstract = {Everyday interactions with computers are increasingly likely to involve elements of
Artificial Intelligence (AI). Encompassing a broad spectrum of technologies and applications,
AI poses many challenges for HCI and design. One such challenge is the need to make
AI's role in a given system legible to the user in a meaningful way. In this paper
we employ a Research through Design (RtD) approach to explore how this might be achieved.
Building on contemporary concerns and a thorough exploration of related research,
our RtD process reflects on designing imagery intended to help increase AI legibility
for users. The paper makes three contributions. First, we thoroughly explore prior
research in order to critically unpack the AI legibility problem space. Second, we
respond with design proposals whose aim is to enhance the legibility, to users, of
systems using AI. Third, we explore the role of design-led enquiry as a tool for critically
exploring the intersection between HCI and AI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-data interaction, legibility, research through design, artificial intelligence, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376793,
author = {Das Swain, Vedant and Saha, Koustuv and Reddy, Manikanta D. and Rajvanshy, Hemang and Abowd, Gregory D. and De Choudhury, Munmun},
title = {Modeling Organizational Culture with Workplace Experiences Shared on Glassdoor},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376793},
doi = {10.1145/3313831.3376793},
abstract = {Organizational culture (OC) encompasses the underlying beliefs, values, and practices
that are unique to an organization. However, OC is inherently subjective and a coarse
construct, and therefore challenging to quantify. Alternatively, self-initiated workplace
reviews on online platforms like Glassdoor provide the opportunity to leverage the
richness of language to understand OC. In as much, first, we use multiple job descriptors
to operationalize OC as a word vector representation. We validate this construct with
language used in 650k different Glassdoor reviews. Next, we propose a methodology
to apply our construct on Glassdoor reviews to quantify the OC of employees by sector.
We validate our measure of OC on a dataset of 341 employees by providing empirical
evidence that it helps explain job performance. We discuss the implications of our
work in guiding tailored interventions and designing tools for improving employee
functioning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {organizational culture, social media, glassdoor, wordvector},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376794,
author = {Shin, Joon Gi and Kim, Doheon and So, Chaehan and Saakes, Daniel},
title = {Body Follows Eye: Unobtrusive Posture Manipulation Through a Dynamic Content Position in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376794},
doi = {10.1145/3313831.3376794},
abstract = {While virtual objects are likely to be a part of future interfaces, we lack knowledge
of how the dynamic position of virtual objects influences users' posture. In this
study, we investigated users' posture change following the unobtrusive and swift motions
of a content window in virtual reality (VR). In two perception studies, we estimated
the perception threshold on undetectable slow motions and displacement during an eye
blink. In a formative study, we compared users' performance, posture change as well
as subjective responses on unobtrusive, swift, and no motions. Based on the result,
we designed concept applications and explored potential design space of moving virtual
content for unobtrusive posture change. With our study, we discuss the interfaces
that control users and the initial design guidelines of unobtrusive posture manipulation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, unobtrusive interaction, posture change},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376795,
author = {Avellino, Ignacio and Bailly, Gilles and Arico, Mario and Morel, Guillaume and Canlorbe, Geoffroy},
title = {Multimodal and Mixed Control of Robotic Endoscopes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376795},
doi = {10.1145/3313831.3376795},
abstract = {Bedside robotic endoscopes render surgeons autonomous from assistants, potentially
improving surgical outcome and decreasing costs. Why then have they not been widely
adopted? We take a step back and first characterize classic (non-robotic) endoscope
use through observations, literature and a domain expert interview. We review the
literature on bedside robotic endoscopes and find that existing controls, individually,
do not have the power to support both intended and appropriated endoscope uses. We
thus explore combining controls to support this diversity of uses. Through an iterative
cycle, we design and implement a multimodal and mixed-initiative technique that combines
two user controls and one system control. Our evaluations confirm that individual
controls do not satisfy the diversity of endoscope uses, and also that our technique
indeed does so. Our work highlights the relevance of HCI research in the medical domain
through robotic systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {minimally invasive surgery, mixed-initiative interfaces, robotic endoscope manipulator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376796,
author = {M\"{a}kel\"{a}, Ville and Radiah, Rivu and Alsherif, Saleh and Khamis, Mohamed and Xiao, Chong and Borchert, Lisa and Schmidt, Albrecht and Alt, Florian},
title = {Virtual Field Studies: Conducting Studies on Public Displays in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376796},
doi = {10.1145/3313831.3376796},
abstract = {Field studies on public displays can be difficult, expensive, and time-consuming.
We investigate the feasibility of using virtual reality (VR) as a test-bed to evaluate
deployments of public displays. Specifically, we investigate whether results from
virtual field studies, conducted in a virtual public space, would match the results
from a corresponding real-world setting. We report on two empirical user studies where
we compared audience behavior around a virtual public display in the virtual world
to audience behavior around a real public display. We found that virtual field studies
can be a powerful research tool, as in both studies we observed largely similar behavior
between the settings. We discuss the opportunities, challenges, and limitations of
using virtual reality to conduct field studies, and provide lessons learned from our
work that can help researchers decide whether to employ VR in their research and what
factors to account for if doing so.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {research methods, public displays, field studies, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376797,
author = {Hastings, Emily M. and Alamri, Albatool and Kuznetsov, Andrew and Pisarczyk, Christine and Karahalios, Karrie and Marinov, Darko and Bailey, Brian P.},
title = {LIFT: Integrating Stakeholder Voices into Algorithmic Team Formation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376797},
doi = {10.1145/3313831.3376797},
abstract = {Team formation tools assume instructors should configure the criteria for creating
teams, precluding students from participating in a process affecting their learning
experience. We propose LIFT, a novel learner-centered workflow where students propose,
vote for, and weigh the criteria used as inputs to the team formation algorithm. We
conducted an experiment (N=289) comparing LIFT to the usual instructor-led process,
and interviewed participants to evaluate their perceptions of LIFT and its outcomes.
Learners proposed novel criteria not included in existing algorithmic tools, such
as organizational style. They avoided criteria like gender and GPA that instructors
frequently select, and preferred those promoting efficient collaboration. LIFT led
to team outcomes comparable to those achieved by the instructor-led approach, and
teams valued having control of the team formation process. We provide instructors
and designers with a workflow and evidence supporting giving learners control of the
algorithmic process used for grouping them into teams.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {learnersourcing, algorithms, team formation, team composition, crowdsourcing, learning, catme},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376798,
author = {Head, Andrew and Jiang, Jason and Smith, James and Hearst, Marti A. and Hartmann, Bj\"{o}rn},
title = {Composing Flexibly-Organized Step-by-Step Tutorials from Linked Source Code, Snippets, and Outputs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376798},
doi = {10.1145/3313831.3376798},
abstract = {Programming tutorials are a pervasive, versatile medium for teaching programming. In this paper, we report on the content and structure of programming tutorials, the pain points authors experience in writing them, and a design for a tool to help improve this process. An interview study with 12 experienced tutorial authors found that they construct documents by interleaving code snippets with text and illustrative outputs. It also revealed that authors must often keep related artifacts of source programs, snippets, and outputs consistent as a program evolves. A content analysis of 200 frequently-referenced tutorials on the web also found that most tutorials contain related artifacts—duplicate code and outputs generated from snippets—that an author would need to keep consistent with each other. To address these needs, we designed a tool called Torii with novel authoring capabilities. An in-lab study showed that tutorial authors can successfully use the tool for the unique affordances identified, and provides guidance for designing future tools for tutorial authoring.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {literate programming, code evolution, authoring, code editors, programming tutorials, consistency},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376799,
author = {Newman, Anelise and McNamara, Barry and Fosco, Camilo and Zhang, Yun Bin and Sukhum, Pat and Tancik, Matthew and Kim, Nam Wook and Bylinskii, Zoya},
title = {TurkEyes: A Web-Based Toolbox for Crowdsourcing Attention Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376799},
doi = {10.1145/3313831.3376799},
abstract = {Eye movements provide insight into what parts of an image a viewer finds most salient,
interesting, or relevant to the task at hand. Unfortunately, eye tracking data, a
commonly-used proxy for attention, is cumbersome to collect. Here we explore an alternative:
a comprehensive web-based toolbox for crowdsourcing visual attention. We draw from
four main classes of attention-capturing methodologies in the literature. ZoomMaps
is a novel zoom-based interface that captures viewing on a mobile phone. CodeCharts
is a self-reporting methodology that records points of interest at precise viewing
durations. ImportAnnots is an "annotation" tool for selecting important image regions,
and cursor-based BubbleView lets viewers click to deblur a small area. We compare
these methodologies using a common analysis framework in order to develop appropriate
use cases for each interface. This toolbox and our analyses provide a blueprint for
how to gather attention data at scale without an eye tracker.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {attention, crowdsourcing, eye tracking, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376800,
author = {Baig, Khadija and Mohamed, Reham and Theus, Anna-Lena and Chiasson, Sonia},
title = {"I'm Hoping They're an Ethical Company That Won't Do Anything That I'll Regret": Users Perceptions of At-Home DNA Testing Companies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376800},
doi = {10.1145/3313831.3376800},
abstract = {At-home DNA testing has become increasingly popular due to the ability to be able
to gain both ancestry and health information, as well as connect with others who share
your DNA. Do users have reasonable mental models of how these systems work? Do users
have privacy concerns and what do they understand as the benefits and risks involved?
We conducted 27 interviews with Canadian users of at-home DNA testing companies. Our
interviews covered perceived and desired data use, data management, data sharing practices,
control over data, and any regrets. Our qualitative analysis revealed that many users
have inconsistencies in their mental models and liken their DNA data to their data
stored with existing technologies, such as social media, rather than health data.
They are generally either dismissive of privacy concerns towards themselves or their
relatives or they had not considered privacy in their choice. We discuss our findings
and propose possible future work in this area.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy, interviews, at home DNA-testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376801,
author = {Bomfim, Marcela C. C. and Kirkpatrick, Sharon I. and Nacke, Lennart E. and Wallace, James R.},
title = {Food Literacy While Shopping: Motivating Informed Food Purchasing Behaviour with a Situated Gameful App},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376801},
doi = {10.1145/3313831.3376801},
abstract = {Establishing healthy eating patterns early in life is critical and has implications for lifelong health. Situated interventions are a promising approach to improve eating patterns. However, HCI research has emphasized calorie control and weight loss, potentially leading consumers to prioritize caloric intake over healthy eating patterns. To support healthy eating more holistically, we designed a gameful app called Pirate Bri's Grocery Adventure (PBGA) that seeks to improve food literacy—meaning the interconnected combination of food-related knowledge, skills, and behaviours that empower an individual to make informed food choices— through a situated approach to grocery shopping. Findings from our three-week field study revealed that PBGA was effective for improving players' nutrition knowledge and motivation for healthier food choices and reducing their impulse purchases. Our findings highlight that nutrition apps should promote planning and shopping based on balance, variety, and moderation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {grocery shopping, situated app, healthy eating, gameful design, food literacy, nutrition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376802,
author = {Monastero, Beatrice and McGookin, David and Takala, Tapio},
title = {"I Just Leaned on It!" Exploring Opportunistic Social Discovery of a Technologically Augmented Cushion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376802},
doi = {10.1145/3313831.3376802},
abstract = {While personal devices are often used to connect online with others far away, public
media rarely offers opportunities to connect with collocated individuals. We explore
novel interaction strategies to enhance opportunistic collocated sociality through
technologically augmented daily objects. ThinkCushion is an augmented cushion allowing
users to record and playback audio messages either explicitly or implicitly by leaning
on it. We deployed ThinkCushion in an open coworking space and gathered quantitative
and qualitative data over one month to unveil how individuals discovered it and interacted.
We individuate three modes of discovery (serendipitous, spectated and facilitated)
and their relations with situated socio-spatial aspects. We discuss the interplay
of active and passive interaction modalities for locally accessing and creating content,
and how verbal content can be used in either performative or informative ways. We
suggest future research on how to design public technologies supporting collocated
sociality already from the phase of technological discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {opportunistic interaction, sociality, embedded systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376803,
author = {Lange, Daniel and Stratmann, Tim Claudius and Gruenefeld, Uwe and Boll, Susanne},
title = {HiveFive: Immersion Preserving Attention Guidance in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376803},
doi = {10.1145/3313831.3376803},
abstract = {Recent advances in Virtual Reality (VR) technology, such as larger fields of view,
have made VR increasingly immersive. However, a larger field of view often results
in a user focusing on certain directions and missing relevant content presented elsewhere
on the screen. With HiveFive, we propose a technique that uses swarm motion to guide
user attention in VR. The goal is to seamlessly integrate directional cues into the
scene without losing immersiveness. We evaluate HiveFive in two studies. First, we
compare biological motion (from a prerecorded swarm) with non-biological motion (from
an algorithm), finding further evidence that humans can distinguish between these
motion types and that, contrary to our hypothesis, non-biological swarm motion results
in significantly faster response times. Second, we compare HiveFive to four other
techniques and show that it not only results in fast response times but also has the
smallest negative effect on immersion.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, particle swarms, user studies, attention guidance, eye-tracking, immersion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376804,
author = {Han, Han L. and Renom, Miguel A. and Mackay, Wendy E. and Beaudouin-Lafon, Michel},
title = {Textlets: Supporting Constraints and Consistency in Text Documents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376804},
doi = {10.1145/3313831.3376804},
abstract = {Writing technical documents frequently requires following constraints and consistently
using domain-specific terms. We interviewed 12 legal professionals and found that
they all use a standard word processor, but must rely on their memory to manage dependencies
and maintain consistent vocabulary within their documents. We introduce Textlets,
interactive objects that reify text selections into persistent items. We show how
Textlets help manage consistency and constraints within the document, including selective
search and replace, word count, and alternative wording. Eight participants tested
a search-and-replace Textlet as a technology probe. All successfully interacted directly
with the Textlet to perform advanced tasks; and most (6/8) spontaneously generated
a novel replace-all-then-correct strategy. Participants suggested additional ideas,
such as supporting collaborative editing over time by embedding a Textlet into the
document to flag forbidden words. We argue that Textlets serve as a generative concept
for creating powerful new tools for document editing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {text editing, document processing, reification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376805,
author = {Dahl, Yngve and Svan\ae{}s, Dag},
title = {Facilitating Democracy: Concerns from Participatory Design with Asymmetric Stakeholder Relations in Health Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376805},
doi = {10.1145/3313831.3376805},
abstract = {This paper addresses how facilitation can implicate what, whose and how perspectives
and values become embedded in the results from participatory design activities. Inspired
by Donald Sch\"{o}n's reflection-on-action theory, an analysis of our facilitator performances
in three design activities involving health care stakeholder groups with asymmetric
relations has been performed. The analysis highlights the often subtle and unforeseen
ways by which facilitator actions influence who "has a say". The results emphasize
how continuous introspective analyses and reflections may improve the facilitator's
attentiveness to actions that may inadvertently impede the disfavored party. In the
long-term, neglect may threaten the integrity of participatory design as a democratic
and empowering design approach. The shift towards a practice-perspective on facilitation
goes beyond the efforts of the individual practitioner. The cultivation of the reflective
facilitator, a concern of relevance for the Human?Computer Interaction and Participatory
Design community as a whole, is considered.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reflection, asymmetries, participation, facilitation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376806,
author = {Brooks, Jas and Nagels, Steven and Lopes, Pedro},
title = {Trigeminal-Based Temperature Illusions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376806},
doi = {10.1145/3313831.3376806},
abstract = {We explore a temperature illusion that uses low-powered electronics and enables the
miniaturization of simple warm and cool sensations. Our illusion relies on the properties
of certain scents, such as the coolness of mint or hotness of peppers. These odors
trigger not only the olfactory bulb, but also the nose's trigeminal nerve, which has
receptors that respond to both temperature and chemicals. To exploit this, we engineered
a wearable device based on micropumps and an atomizer that emits up to three custom-made
"thermal" scents directly to the user's nose. Breathing in these scents causes the
user to feel warmer or cooler. We demonstrate how our device renders warmth and cooling
sensations in virtual experiences. In our first study, we evaluated six candidate
"thermal" scents. We found two hot-cold pairs, with one pair being less identifiable
by odor. In our second study, pParticipants rated VR experiences with our device trigeminal
stimulants as significantly warmer or cooler than the baseline conditions. Lastly,
we believe this offers an alternative to existing thermal feedback devices, which
unfortunately rely on power-hungry heat-lamps or Peltier-elements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {vr, haptics, smell, trigeminal, illusion, thermal},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376807,
author = {Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang 'Anthony'},
title = {CheXplain: Enabling Physicians to Explore and Understand Data-Driven, AI-Enabled Medical Imaging Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376807},
doi = {10.1145/3313831.3376807},
abstract = {The recent development of data-driven AI promises to automate medical diagnosis; however, most AI functions as 'black boxes' to physicians with limited computational knowledge. Using medical imaging as a point of departure, we conducted three iterations of design activities to formulate CheXplain — a system that enables physicians to explore and understand AI-enabled chest X-ray analysis: (i) a paired survey between referring physicians and radiologists reveals whether, when, and what kinds of explanations are needed; (ii) a low-fidelity prototype co-designed with three physicians formulates eight key features; and (iii) a high-fidelity prototype evaluated by another six physicians provides detailed summative insights on how each feature enables the exploration and understanding of AI. We summarize by discussing recommendations for future work to design and implement explainable medical AI systems that encompass four recurring themes: motivation, constraint, explanation, and justification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {system design, physician-centered design, explainable artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376808,
author = {Zhang, Tianyi and El Ali, Abdallah and Wang, Chen and Hanjalic, Alan and Cesar, Pablo},
title = {RCEA: Real-Time, Continuous Emotion Annotation for Collecting Precise Mobile Video Ground Truth Labels},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376808},
doi = {10.1145/3313831.3376808},
abstract = {Collecting accurate and precise emotion ground truth labels for mobile video watching
is essential for ensuring meaningful predictions. However, video-based emotion annotation
techniques either rely on post-stimulus discrete self-reports, or allow real-time,
continuous emotion annotations (RCEA) only for desktop settings. Following a user-centric
approach, we designed an RCEA technique for mobile video watching, and validated its
usability and reliability in a controlled, indoor (N=12) and later outdoor (N=20)
study. Drawing on physiological measures, interaction logs, and subjective workload
reports, we show that (1) RCEA is perceived to be usable for annotating emotions while
mobile video watching, without increasing users' mental workload (2) the resulting
time-variant annotations are comparable with intended emotion attributes of the video
stimuli (classification error for valence: 8.3%; arousal: 25%). We contribute a validated
annotation technique and associated annotation fusion method, that is suitable for
collecting fine-grained emotion annotations while users watch mobile videos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {annotation, continuous, emotion, labels, mobile, real-time, video},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376809,
author = {Ayobi, Amid and Marshall, Paul and Cox, Anna L.},
title = {Trackly: A Customisable and Pictorial Self-Tracking App to Support Agency in Multiple Sclerosis Self-Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376809},
doi = {10.1145/3313831.3376809},
abstract = {Self-tracking is an important part of self-care. However, predefined self-tracking
approaches can impede people's agency in managing their health. We investigated a
customisable and pictorial self-tracking approach in multiple sclerosis self-management
by implementing and conducting a field study of Trackly: a prototype app that supports
people in defining and colouring pictorial trackers, such as body shapes. We found
that participants utilised the elements of Trackly designed to support agentive behaviour:
they defined personally meaningful tracking parameters in their own words, and particularly
valued being able to flexibly colour in and make sense of their pictorial trackers.
Having been able to support their individual self-care intentions with Trackly, participants
reported a spectrum of interrelated experiences of agency, including a sense of ownership,
identity, self-awareness, mindfulness, and control. Our findings demonstrate the importance
of supporting people's individual needs and creative capacities to foster mindful
and personally meaningful engagement with health and wellbeing data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {customization, self-reflection, mood tracking, mindfulness, agency, symptom monitoring, perceived control, customisation, self-tracking, bullet journaling, self-awareness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376810,
author = {Yan, Yukang and Yu, Chun and Zheng, Wengrui and Tang, Ruining and Xu, Xuhai and Shi, Yuanchun},
title = {FrownOnError: Interrupting Responses from Smart Speakers by Facial Expressions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376810},
doi = {10.1145/3313831.3376810},
abstract = {In the conversations with smart speakers, misunderstandings of users' requests lead
to erroneous responses. We propose FrownOnError, a novel interaction technique that
enables users to interrupt the responses by intentional but natural facial expressions.
This method leverages the human nature that the facial expression changes when we
receive unexpected responses. We conducted a first user study (N=12) to understand
users' intuitive reactions to the correct and incorrect responses. Our results reveal
the significant difference in the frequency of occurrence and intensity of users'
facial expressions between two conditions, and frowning and raising eyebrows are intuitive
to perform and easy to control. Our second user study (N=16) evaluated the user experience
and interruption efficiency of FrownOnError and the third user study (N=12) explored
suitable conversation recovery strategies after the interruptions. Our results show
that FrownOnError can be accurately detected (precision: 97.4%, recall: 97.6%), provides
the most timely interruption compared to the baseline methods of wake-up word and
button press, and is rated as most intuitive and easiest to be performed by users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {conversation interruption, voice user interface, facial expression},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376811,
author = {Oh, Changhoon and Choi, Jinhan and Lee, Sungwoo and Park, SoHyun and Kim, Daeryong and Song, Jungwoo and Kim, Dongwhan and Lee, Joonhwan and Suh, Bongwon},
title = {Understanding User Perception of Automated News Generation System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376811},
doi = {10.1145/3313831.3376811},
abstract = {Automated journalism refers to the generation of news articles using computer programs.
Although it is widely used in practice, its user experience and interface design remain
largely unexplored. To understand the user perception of an automated news system,
we designed NewsRobot, a research prototype that automatically generated news on major
events of the PyeongChang 2018 Winter Olympic Games in real-time. It produces six
types of news by combining two kinds of content (general/individualized) and three
styles (text, text+image, text+image+sound). A total of 30 users participated in using
NewsRobot, completing surveys and interviews on their experience. Our findings are
as follows: (1) Users preferred individualized news yet considered it less credible,
(2) more presentation elements were appreciated but only if their quality was assured,
and (3) NewsRobot was considered factual and accurate yet shallow in depth. Based
on our findings, we discuss implications for designing automated journalism user interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {automated journalism, robot journalism, multimedia modality, automated news generation system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376812,
author = {Tennent, Paul and Marshall, Joe and Tsaknaki, Vasiliki and Windlin, Charles and H\"{o}\"{o}k, Kristina and Alfaras, Miquel},
title = {Soma Design and Sensory Misalignment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376812},
doi = {10.1145/3313831.3376812},
abstract = {We report on a workshop bringing together researchers working in soma design and sensory
misalignment. Creating experiences that make use of sensory misalignment has become
increasingly common, often associated with virtual reality research. However, little
attention has been paid to how to design such experiences. We argue that the practice
of soma design is a relevant candidate method for designing misalignment experiences,
since soma design brings with it concepts such as estrangement and disrupting the
habitual as a path to design. We further argue that sensory misalignment may in turn
extend soma design methods, adding methods for explicitly disrupting sensory perception
using technology interventions. Finally, we draw on the findings of that workshop
to discuss the ideas of: pluralism in experience; orchestration of overall experience;
as well as the broader intersection of soma design and sensory misalignment approaches.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {soma design, bodily sensation, sensory misalignment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376813,
author = {Wang, Ruotong and Harper, F. Maxwell and Zhu, Haiyi},
title = {Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376813},
doi = {10.1145/3313831.3376813},
abstract = {Algorithmic decision-making systems are increasingly used throughout the public and
private sectors to make important decisions or assist humans in making these decisions
with real social consequences. While there has been substantial research in recent
years to build fair decision-making algorithms, there has been less research seeking
to understand the factors that affect people's perceptions of fairness in these systems,
which we argue is also important for their broader acceptance. In this research, we
conduct an online experiment to better understand perceptions of fairness, focusing
on three sets of factors: algorithm outcomes, algorithm development and deployment
procedures, and individual differences. We find that people rate the algorithm as
more fair when the algorithm predicts in their favor, even surpassing the negative
effects of describing algorithms that are very biased against particular demographic
groups. We find that this effect is moderated by several variables, including participants'
education level, gender, and several aspects of the development procedure. Our findings
suggest that systems that evaluate algorithmic fairness through users' feedback must
consider the possibility of "outcome favorability" bias.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {algorithmic decision-making, algorithm development, perceived fairness, algorithmoutcome},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376814,
author = {Kim, Lawrence H. and Drew, Daniel S. and Domova, Veronika and Follmer, Sean},
title = {User-Defined Swarm Robot Control},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376814},
doi = {10.1145/3313831.3376814},
abstract = {A swarm of robots can accomplish more than the sum of its parts, and swarm systems
will soon see increased use in applications ranging from tangible interfaces to search
and rescue teams. However, effective human control of robot swarms has been shown
to be demonstrably more difficult than controlling a single robot, and swarm-specific
interactions methodologies are relatively underexplored. As we envision even non-expert
users will have more daily in-person encounters with different numbers of robots in
the future, we present a user-defined set of control interactions for tabletop swarm
robots derived from an elicitation study. We investigated the effects of number of
robots and proximity on the user's interaction and found significant effects. For
instance, participants varied between using 1-2 fingers, one hand, and both hands
depending on the group size. We also provide general design guidelines such as preferred
interaction modality, common strategies, and a high-agreement interaction set.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {swarm robotics, elicitation study, swarm user interface, swarm robot control, multi-robot control},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376815,
author = {Putze, Felix and Ihrig, Tilman and Schultz, Tanja and Stuerzlinger, Wolfgang},
title = {Platform for Studying Self-Repairing Auto-Corrections in Mobile Text Entry Based on Brain Activity, Gaze, and Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376815},
doi = {10.1145/3313831.3376815},
abstract = {Auto-correction is a standard feature of mobile text entry. While the performance
of state-of-the-art auto-correct methods is usually relatively high, any errors that
occur are cumbersome to repair, interrupt the flow of text entry, and challenge the
user's agency over the process. In this paper, we describe a system that aims to automatically
identify and repair auto-correction errors. This system comprises a multi-modal classifier
for detecting auto-correction errors from brain activity, eye gaze, and context information,
as well as a strategy to repair such errors by replacing the erroneous correction
or suggesting alternatives. We integrated both parts in a generic Android component
and thus present a research platform for studying self-repairing end-to-end systems.
To demonstrate its feasibility, we performed a user study to evaluate the classification
performance and usability of our approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {EEG, auto-correction, eye gaze, text entry, self-repair},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376816,
author = {Funk, Markus and Tobisch, Vanessa and Emfield, Adam},
title = {Non-Verbal Auditory Input for Controlling Binary, Discrete, and Continuous Input in Automotive User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376816},
doi = {10.1145/3313831.3376816},
abstract = {Using auditory input while driving is becoming increasingly popular for making distraction-free
inputs while driving. However, we argue that auditory input is more than just using
speech. Thus, in this work, we explore using Non-Verbal Auditory Input (NVAI) for
interacting with smart assistants while driving. Through an online study with 100
participants, we initially investigated users' input preferences for binary, discrete,
and continuous data types. After identifying the top three modalities for NVAI, we
subsequently conducted an in-person study with 16 participants. In our study, the
participants tested these input modalities for three different input data types regarding
their accuracy, driver-distraction, and social acceptability, while operating a driving
simulator. The results reveal that, although clapping hands for making input was initially
preferred in our online survey, it is snapping fingers for binary input and discrete
input and humming for making continuous input that is the preferred NVAI modality
while driving.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {voice-user interface, automotive user interfaces, non-verbal auditory interaction, speech input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376817,
author = {Kaur, Harmanpreet and Williams, Alex C. and McDuff, Daniel and Czerwinski, Mary and Teevan, Jaime and Iqbal, Shamsi T.},
title = {Optimizing for Happiness and Productivity: Modeling Opportune Moments for Transitions and Breaks at Work},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376817},
doi = {10.1145/3313831.3376817},
abstract = {Information workers perform jobs that demand constant multitasking, leading to context
switches, productivity loss, stress, and unhappiness. Systems that can mediate task
transitions and breaks have the potential to keep people both productive and happy.
We explore a crucial initial step for this goal: finding opportune moments to recommend
transitions and breaks without disrupting people during focused states. Using affect,
workstation activity, and task data from a three-week field study (N=25), we build
models to predict whether a person should continue their task, transition to a new
task, or take a break.&nbsp;The R-squared values of our models are as high as 0.7, with
only 15% error cases. We ask users to evaluate the timing of recommendations provided
by a recommender that relies on these models. Our study shows that users find our
transition and break recommendations to be well-timed, rating them as 86% and 77%
accurate, respectively. We conclude with a discussion of the implications for intelligent
systems that seek to guide task transitions and manage interruptions at work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {recommendations, affect, workplace, productivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376818,
author = {Pine, Kathleen H. and Chen, Yunan},
title = {Right Information, Right Time, Right Place: Physical Alignment and Misalignment in Healthcare Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376818},
doi = {10.1145/3313831.3376818},
abstract = {Implementation of new health information systems such as Electronic Health Records
(EHR) is expected to reap many benefits. However, the transition from one information
system to another is often associated with inefficiency, ineffectiveness, and patient
safety hazards. These negative consequences are difficult to predict and avoid before
system transitions take place. The changed physical form of information remains an
unexamined facet of healthcare system transitions. Using ethnographic methods in two
clinical sites, we discovered a recurrent set of problems that emerged due to physical
disconnections between information and practice predicated on implementation of new
information systems. "Physical misalignments" are instances where workers cannot bring
information sources to hand in the precise time and place in which they are needed.
We identify three types of physical misalignments, then discuss how physical misalignments
can be proactively identified and corrected before, during, and after implementation
of new health information systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ethnography, implementation, electronic health records, health information systems, unintended consequences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376819,
author = {Do, Seungwon and Lee, Byungjoo},
title = {Improving Reliability of Virtual Collision Responses: A Cue Integration Technique},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376819},
doi = {10.1145/3313831.3376819},
abstract = {In virtual reality (VR), a user's virtual avatar can interact with a virtual object
by colliding with it. If collision responses do not occur in the direction that the
user expects, the user experiences degradation of accuracy and precision in applications
such as VR sports games. In determining the response of a virtual collision, existing
physics engines have not considered the direction in which the user perceived and
estimated the collision. Based on the cue integration theory, this study presents
a statistical model explaining how users estimate the direction of a virtual collision
from their body's orientation and velocity vectors. The accuracy and precision of
virtual collisions can be improved by 8.77% and 30.29%, respectively, by setting the
virtual collision response in the direction that users perceive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, cue integration theory, collision response},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376820,
author = {Devendorf, Laura and Arquilla, Katya and Wirtanen, Sandra and Anderson, Allison and Frost, Steven},
title = {Craftspeople as Technical Collaborators: Lessons Learned through an Experimental Weaving Residency},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376820},
doi = {10.1145/3313831.3376820},
abstract = {While craft has had increasing influence on HCI research, HCI researchers tend to
engage craft in limited capacities, often focusing on the juxtapositions of "traditional"
craft and "innovative" computing. In this paper, we describe the structure and results
of a six-week "experimental weaving residency" to show how HCI practitioners, engineers,
and craftspeople perform similar work and can productively collaborate to envision
new technological interfaces at early stages of development. We address both social
and technical challenges of residencies and critically reflect on biases about technical
and craft labor that we held prior to the residency. We share our experiences and
lessons learned in the hopes of supporting future collaborations with craftspeople
and broadening the techniques we use to address design challenges.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart textiles, electrodes, feminist HCI, collaboration models, artist residencies, weaving},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376821,
author = {Rietzler, Michael and Deubzer, Martin and Dreja, Thomas and Rukzio, Enrico},
title = {Telewalk: Towards Free and Endless Walking in Room-Scale Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376821},
doi = {10.1145/3313831.3376821},
abstract = {Natural navigation in VR is challenging due to spatial limitations. While Teleportation
enables navigation within very small physical spaces and without causing motion sickness
symptoms, it may reduce the feeling of presence and spacial awareness. Redirected
walking (RDW), in contrast, allows users to naturally walk while staying inside a
finite, but still very large, physical space. We present Telewalk, a novel locomotion
approach that combines curvature and translation gains known from RDW research in
a perceivable way. This combination enables Telewalk to be applied even within a physical
space of 3m x 3m. Utilizing the head rotation as input device enables directional
changes without any physical turns to keep the user always on an optimal circular
path inside the real world while freely walking inside the virtual one. In a user
study we found that even though motion sickness susceptible participants reported
respective symptoms, Telewalk did result in stronger feelings of presence and immersion
and was seen as more natural then Teleportation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {redirected walking, Telewalk, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376822,
author = {Khurana, Rushil and Goel, Mayank},
title = {Eyes on the Road: Detecting Phone Usage by Drivers Using On-Device Cameras},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376822},
doi = {10.1145/3313831.3376822},
abstract = {Using a phone while driving is distracting and dangerous. It increases the accident
chances by 400%. Several techniques have been proposed in the past to detect driver
distraction due to phone usage. However, such techniques usually require instrumenting
the user or the car with custom hardware. While detecting phone usage in the car can
be done by using the phone's GPS, it is harder to identify whether the phone is used
by the driver or one of the passengers. In this paper, we present a lightweight, software-only
solution that uses the phone's camera to observe the car's interior geometry to distinguish
phone position and orientation. We then use this information to distinguish between
driver and passenger phone use. We collected data in 16 different cars with 33 different
users and achieved an overall accuracy of 94% when the phone is held in hand and 92.2%
when the phone is docked (1 sec. delay). With just a software upgrade, this work can
enable smartphones to proactively adapt to the user's context in the car and and substantially
reduce distracted driving incidents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {situational impairments, in-car behavior, position sensing, driver detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376823,
author = {Kamikubo, Rie and Kato, Naoya and Higuchi, Keita and Yonetani, Ryo and Sato, Yoichi},
title = {Support Strategies for Remote Guides in Assisting People with Visual Impairments for Effective Indoor Navigation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376823},
doi = {10.1145/3313831.3376823},
abstract = {People with visual impairments often require mobility assistance of sighted guides
but they are not always available. Recent technological strides have opened up new
directions for sighted guidance services, assigning guides from a network of remote
workers to provide real-time assistance via audio/video communication. However, little
has been known regarding desirable support characteristics of remote guides or challenges
experienced in guide practices without the requisite expertise. To recommend support
strategies that contribute to facilitating a successful platform for remote sighted
guidance, this paper presents a comparative study of the performance of trained and
untrained sighted guides who are recruited for a remote scenario in assisting people
with visual impairments in indoor navigation. As an outcome of this research, we provide
a deeper understanding of design opportunities for HCI to scaffold requirements of
remote guides, such that their collaborative efforts and environmental knowledge influence
the user experience. Based on our empirical insights, we suggest to develop the expertise
of remote guides through: a) preliminary guidance cooperation awareness b) guidelines
for verbal description methods, and c) approaches to compensate for the lack of environmental
knowledge.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual impairment, remote assistance, collaboration, indoor navigation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376824,
author = {Gray, Stuart and Hahn, Rachel and Cater, Kirsten and Watson, Debbie and Williams, Keir and Metcalfe, Tom and Meineck, Chloe},
title = {Towards A Design For Life: Redesigning For Reminiscence With Looked After Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376824},
doi = {10.1145/3313831.3376824},
abstract = {For 'looked-after' and adopted children, physical objects are often the only remaining
link to their pasts; a portal to stories of former families, homes, and events. The
act of reminiscence, known as 'life story work', can help children to process their
pasts and overcome trauma. This paper describes the user-centred redesign of Trove,
a digital and physical memory box for storing and curating stories about precious
objects. We describe our redesign process, synthesising the insights from previous
Trove evaluations with looked-after and adopted children, and three re-design workshops
with 4 looked-after children at a therapeutic residential school. Our findings advocate
for prioritisation of Trove's digital and physical security, the sustainability of
its companionship, and the provision of multimedia storytelling to encourage the construction
of identity narratives. Inspired by this, we present and discuss the redeveloped Trove,
before analysing our participatory design approach with these complex and under-represented
groups.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {storytelling, children, life story work, memory boxes, participatory design, reminiscence, social care},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376825,
author = {Agrawal, Ankit and Abraham, Sophia J. and Burger, Benjamin and Christine, Chichi and Fraser, Luke and Hoeksema, John M. and Hwang, Sarah and Travnik, Elizabeth and Kumar, Shreya and Scheirer, Walter and Cleland-Huang, Jane and Vierhauser, Michael and Bauer, Ryan and Cox, Steve},
title = {The Next Generation of Human-Drone Partnerships: Co-Designing an Emergency Response System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376825},
doi = {10.1145/3313831.3376825},
abstract = {The use of semi-autonomous Unmanned Aerial Vehicles (UAV) to support emergency response
scenarios, such as fire surveillance and search and rescue, offers the potential for
huge societal benefits. However, designing an effective solution in this complex domain
represents a "wicked design" problem, requiring a careful balance between trade-offs
associated with drone autonomy versus human control, mission functionality versus
safety, and the diverse needs of different stakeholders. This paper focuses on designing
for situational awareness (SA) using a scenario-driven, participatory design process.
We developed SA cards describing six common design-problems, known as SA demons, and
three new demons of importance to our domain. We then used these SA cards to equip
domain experts with SA knowledge so that they could more fully engage in the design
process. We designed a potentially reusable solution for achieving SA in multi-stakeholder,
multi-UAV, emergency response applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emergency response, situational awareness, unmanned aerial vehicles, participatory design, human-CPS interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376826,
author = {Hansen, Derek L. and Hughes, Amanda Lee and Cram, Sophie and Harker, Austin Bond and Ashton, Brinnley and Hirschi, Karli and Dorton, Ben and Bothwell, Nate and Stevens, Ashley},
title = {The DELAY Framework: Designing for Extended LAtencY},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376826},
doi = {10.1145/3313831.3376826},
abstract = {This paper introduces the Designing for Extended Latency (DELAY) Framework meant to
inspire new systems that support social interaction in high-latency settings such
as interplanetary communication, intermittent internet access, and time-zone incompatibilities.
The framework includes six dimensions: Goal, Communication Genre, Sequencing, Cardinality,
Mutability, and Responsiveness. We describe the iterative design process used to create
the Framework, as well as three novel prototypes designed to increase social connectedness
and social presence in high-latency situations: 1) the InSync app that allows partners
to perform activities simultaneously even though they only see proof of their synchronicity
later; 2) the After the Beep system that lets users leave IoT messages that are triggered
by the recipients; and 3) the Surrogate platform where players play group battle games
against "surrogate" artificial intelligence avatars that mimic unavailable individuals.
Data from two design workshops validates the usefulness of the framework for generating
new solutions to high-latency scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interpersonal communication, delay framework, high-latency, social presence, social connectedness, interplanetary communication, delayed communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376827,
author = {Nguyen, Josef and Ruberg, Bonnie},
title = {Challenges of Designing Consent: Consent Mechanics in Video Games as Models for Interactive User Agency},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376827},
doi = {10.1145/3313831.3376827},
abstract = {This paper argues for a conceptual framework that treats user consent in interactive
technologies as a design challenge necessitating careful, culturally-informed consideration.
We draw on recent work in HCI as well as queer and feminist theory that understands
consent as rooted in negotiating agency in order to frame our exploration of unique
difficulties and potential solutions to meaningful opportunities for user consent
in the design of computational technologies. Through a critical analysis of three
video games that offer different models of consent-each of which communicates different
values through its design-we introduce the concept of consent mechanics. Consent mechanics
describe designed interactions that allow players to consent to or opt out of in-game
experiences, often those related to sexuality or intimacy. Here, we approach video
games as windows onto design considerations surrounding interactive technologies more
broadly, suggesting crucial questions and tactics for how to design user agency ethically
into computational systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design, ethics, consent, queerness, sexuality, video games, critical approaches},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376828,
author = {Gallo, Danilo and Shreepriya, Shreepriya and Willamowski, Jutta},
title = {RunAhead: Exploring Head Scanning Based Navigation for Runners},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376828},
doi = {10.1145/3313831.3376828},
abstract = {Navigation systems for runners commonly provide turn-by-turn directions via voice
and/or map-based visualizations. While voice directions require permanent attention,
map-based guidance requires regular consultation. Both disrupt the running activity.
To address this, we designed RunAhead, a navigation system using head scanning to
query for navigation feedback, and we explored its suitability for runners in an outdoor
experiment. In our design, we provide the runner with simple and intuitive navigation
feedback on the path s/he is looking at through three different feedback modes: haptic,
music and audio cues. In our experiment, we compare the resulting three versions of
RunAhead with a baseline voice-based navigation system. We find that demand and error
are equivalent across all four conditions. However, the head scanning based haptic
and music conditions are preferred over the baseline and these preferences are impacted
by runners' habits. With this study we contribute insights for designing navigation
support for runners.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {audio feedback, haptic feedback, head scanning, navigation for running},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376829,
author = {Syeda, Uzma Haque and Murali, Prasanth and Roe, Lisa and Berkey, Becca and Borkin, Michelle A.},
title = {Design Study "Lite" Methodology: Expediting Design Studies and Enabling the Synergy of Visualization Pedagogy and Social Good},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376829},
doi = {10.1145/3313831.3376829},
abstract = {Design studies are frequently used to conduct problem-driven visualization research
by working with real-world domain experts. In visualization pedagogy, design studies
are often introduced but rarely practiced due to their large time requirements. This
limits students to a classroom curriculum, often involving projects that may not have
implications beyond the classroom. Thus we present the Design Study "Lite" Methodology,
a novel framework for implementing design studies with novice students in 14 weeks.
We utilized the Design Study "Lite" Methodology in conjunction with Service-Learning
to teach five Data Visualization courses and demonstrate that it benefits not only
the students but also the community through service to non-profit partners. In this
paper, we provide a detailed breakdown of the methodology and how Service-Learning
can be incorporated with it. We also include an extensive reflection on the methodology
and provide recommendations for future applications of the framework for teaching
visualization courses and research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, pedagogy, design studies, theory and methods, service-learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376830,
author = {Kim, Yoojung and Bhattacharya, Arpita and Kientz, Julie A. and Lee, Jin Ha},
title = {"It Should Be a Game for Fun, Not Exercise": Tensions in Designing Health-Related Features for Pok\'{e}Mon GO},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376830},
doi = {10.1145/3313831.3376830},
abstract = {Leveraging existing popular games such as Pok\'{e}mon GO to promote health can engage
people in healthy activities without sacrificing gaming appeal. However, little is
known about what potential tensions arise from incorporating new health-related features
to already existing and popular games and how to resolve those tensions from players'
perspectives. In this paper, we identify design tensions surrounding the appeals of
Pok\'{e}mon GO, perspectives on different health needs, and mobile health technologies.
By conducting surveys and design workshops with 20 avid Pok\'{e}mon GO players, we demonstrate
four design tensions: (1) diverse goals and rewards vs. data accuracy, (2) strong
bonds between players and characters vs. gaming obsession, (3) collaborative play
vs. social anxiety, and (4) connection of in-real-life experiences with the game vs.
different individual contexts. We provide design implications to resolve these tensions
in Pok\'{e}mon GO and discuss how to extend our findings to the broader context of health
promotion in location-based games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {health promotion, location-based game, game design, design tension, health-related game feature, pokemon go, augmented reality game},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376831,
author = {Mirza-Babaei, Pejman and Stahlke, Samantha and Wallner, G\"{u}nter and Nova, Atiya},
title = {A Postmortem on Playtesting: Exploring the Impact of Playtesting on the Critical Reception of Video Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376831},
doi = {10.1145/3313831.3376831},
abstract = {Game studios aim to develop titles that deliver a fun and engaging experience for
players. Playtesting promises to help identify opportunities to improve player experience
and assist developers in achieving their design intent. However, a lack of research
on the added value of playtesting means that many studios are still uncertain about
its commercial viability and impact on product success. This gap in understanding
is further complicated by the vague definition of "success" afforded by sales figures
and review scores. In this paper, we assess reported feature quality of three commercial
titles by analyzing playtesting reports and game reviews. By comparing themes and
design issues expressed in game reviews to the results of pre-release playtesting
for each game, we aim to highlight the value of playtesting and propose a set of guidelines
for selecting playtest methods based on the needs of a given game evaluation. Through
the real-world case studies presented, this paper contributes to the growing domain
of games user research and highlights the value of playtesting in game development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {playtesting, games user research, game reviews},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376832,
author = {Monaco, John V.},
title = {Bug or Feature? Covert Impairments to Human Computer Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376832},
doi = {10.1145/3313831.3376832},
abstract = {Computer users commonly experience interaction anomalies, such as the text cursor
jumping to another location in a document, perturbed mouse pointer motion, or a disagreement
between tactile input and touch screen location. These anomalies impair interaction
and require the user to take corrective measures, such as resetting the text cursor
or correcting the trajectory of the pointer to reach a desired target. Impairments
can result from software bugs, physical hardware defects, and extraneous input. However,
some designs alter the course of interaction through covert impairments, anomalies
introduced intentionally and without the user's knowledge. There are various motivations
for doing so rooted in disparate fields including biometrics, electronic voting, and
entertainment. We examine this kind of deception by systematizing four different ways
computer interaction may become impaired and three different goals of the designer,
providing insight to the design of systems that implement covert impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {deception, influence, cybersecurity, behavior change, interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376833,
author = {Stowell, Elizabeth and O'Leary, Teresa K. and Kimani, Everlyne and Paasche-Orlow, Michael K. and Bickmore, Timothy and Parker, Andrea G.},
title = {Investigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376833},
doi = {10.1145/3313831.3376833},
abstract = {Churches play a major role in providing social support to address health inequities
within Black communities, in part by connecting members to key organizations and services.
While public health has a history of disseminating interventions in faith communities,
little work has explored the use of crowdsourcing to tailor interventions to the unique
culture of each church community. Following Community Based Participatory Research
principles, we partnered with two predominantly Black churches, and report on a series
of three participatory design sessions with nine participants. We developed a novel
storyboarding method to explore how crowdsourcing could promote health in these faith-based
communities. Our findings characterize existing supports within the church community,
and how church social structures impact member access to these supports. We further
identify motivations to engage with a church-situated health application, and how
these motivations translate to crowdsourcing tasks. Finally, we discuss considerations
for public health crowdsourcing tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mhealth, participatory design, african-american, crowdsourcing, faith-based communities, health promotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376834,
author = {Gr\o{}nb\ae{}k, Jens Emil and Rasmussen, Majken Kirkegaard and Halskov, Kim and Petersen, Marianne Graves},
title = {KirigamiTable: Designing for Proxemic Transitions with a Shape-Changing Tabletop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376834},
doi = {10.1145/3313831.3376834},
abstract = {A core challenge in tabletop research is to support transitions between individual
activities and team work. Shape-changing tabletops open up new opportunities for addressing
this challenge. However, interaction design for shape-changing furniture is in its
early stages - so far, research has mainly focused on triggering shape-changes, and
less on the actual interface transitions. We present KirigamiTable - a novel actuated
shape-changing tabletop for supporting transitions in collaborative work. Our work
builds on the concept of Proxemic Transitions, considering the dynamic interplay between
social interactions, interactive technologies and furniture. With KirigamiTable, we
demonstrate the potential of interactions for proxemic transitions that combine transformation
of shape and digital contents. We highlight challenges for shape-changing tabletops:
initiating shape and content transformations, cooperative control, and anticipating
shape-change. To address these challenges, we propose a set of novel interaction techniques,
including shape-first and content-first interaction, cooperative gestures, and physical
and digital preview of shape-changes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {shape-changing interfaces, transitions, interaction techniques, collaboration, interactive tabletops, proxemics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376835,
author = {Chen, Yan and Pandey, Maulishree and Song, Jean Y. and Lasecki, Walter S. and Oney, Steve},
title = {Improving Crowd-Supported GUI Testing with Structural Guidance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376835},
doi = {10.1145/3313831.3376835},
abstract = {Crowd testing is an emerging practice in Graphical User Interface (GUI) testing, where
developers recruit a large number of crowd testers to test GUI features. It is often
easier and faster than a dedicated quality assurance team, and its output is more
realistic than that of automated testing. However, crowds of testers working in parallel
tend to focus on a small set of commonly-used User Interface (UI) navigation paths,
which can lead to low test coverage and redundant effort. In this paper, we introduce
two techniques to increase crowd testers' coverage: interactive event-flow graphs
and GUI-level guidance. The interactive event-flow graphs track and aggregate every
tester's interactions into a single directed graph that visualizes the cases that
have already been explored. Crowd testers can interact with the graphs to find new
navigation paths and increase the coverage of the created tests. We also use the graphs
to augment the GUI (GUI-level guidance) to help testers avoid only exploring common
paths. Our evaluation with 30 crowd testers on 11 different test pages shows that
the techniques can help testers avoid redundant effort while also increasing untrained
testers' coverage by 55%. These techniques can help us develop more robust software
that works in more mission-critical settings not only by performing more thorough
testing with the same effort that has been put in before but also by integrating them
into different parts of the development pipeline to make more reliable software in
the early development stage.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {crowdsourcing, software testing, GUI testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376836,
author = {Xu, Xuhai and Shi, Haitian and Yi, Xin and Liu, WenJia and Yan, Yukang and Shi, Yuanchun and Mariakakis, Alex and Mankoff, Jennifer and Dey, Anind K.},
title = {EarBuddy: Enabling On-Face Interaction via Wireless Earbuds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376836},
doi = {10.1145/3313831.3376836},
abstract = {Past research regarding on-body interaction typically requires custom sensors, limiting
their scalability and generalizability. We propose EarBuddy, a real-time system that
leverages the microphone in commercial wireless earbuds to detect tapping and sliding
gestures near the face and ears. We develop a design space to generate 27 valid gestures
and conducted a user study (N=16) to select the eight gestures that were optimal for
both human preference and microphone detectability. We collected a dataset on those
eight gestures (N=20) and trained deep learning models for gesture detection and classification.
Our optimized classifier achieved an accuracy of 95.3%. Finally, we conducted a user
study (N=12) to evaluate EarBuddy's usability. Our results show that EarBuddy can
facilitate novel interaction and that users feel very positively about the system.
EarBuddy provides a new eyes-free, socially acceptable input method that is compatible
with commercial wireless earbuds and has the potential for scalability and generalizability},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {face and ear interaction, wireless earbuds, gesture recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376837,
author = {Cibrian, Franceli L. and Lakes, Kimberley D. and Tavakoulnia, Arya and Guzman, Kayla and Schuck, Sabrina and Hayes, Gillian R.},
title = {Supporting Self-Regulation of Children with ADHD Using Wearables: Tensions and Design Challenges},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376837},
doi = {10.1145/3313831.3376837},
abstract = {The design of wearable applications supporting children with Attention Deficit Hyperactivity
Disorders (ADHD) requires a deep understanding not only of what is possible from a
clinical standpoint but also how the children might understand and orient towards
wearable technologies, such as a smartwatch. Through a series of participatory design
workshops with children with ADHD and their caregivers, we identified tensions and
challenges in designing wearable applications supporting the self-regulation of children
with ADHD. In this paper, we describe the specific challenges of smartwatches for
this population, the balance between self-regulation and co-regulation, and tensions
when receiving notifications on a smartwatch in various contexts. These results indicate
key considerations-from both the child and caregiver viewpoints-for designing technological
interventions supporting children with ADHD.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design tensions, smartwatch, wearable, adhd, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376838,
author = {Han, Changyo and Takahashi, Ryo and Yahagi, Yuchi and Naemura, Takeshi},
title = {PneuModule: Using Inflatable Pin Arrays for Reconfigurable Physical Controls on Pressure-Sensitive Touch Surfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376838},
doi = {10.1145/3313831.3376838},
abstract = {We present PneuModule, a tangible interface platform that enables users to reconfigure
physical controls on pressure-sensitive touch surfaces using pneumatically-actuated
inflatable pin arrays. PneuModule consists of a main module and extension modules.
The main module is tracked on the touch surface and forwards continuous inputs from
attached multiple extension modules to the touch surface. Extension modules have distinct
mechanisms for user input, which pneumatically actuates the inflatable pins at the
bottom of the main module through internal air pipes. The main module accepts multi-dimensional
inputs since each pin is individually inflated by the corresponding air chamber. Also,
since the extension modules are swappable and identifiable owing to the marker design,
users can quickly customize the interface layout. We contribute to design details
of inflatable pins and diverse pneumatic input control design examples for PneuModule.
We also showcase the feasibility of PneuModule through a series of evaluations and
interactive prototypes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {pneumatic actuation, pressure-sensitive touch surfaces, tangible user interfaces, reconfigurable physical controls},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376839,
author = {Stemasov, Evgeny and Wagner, Tobias and Gugenheimer, Jan and Rukzio, Enrico},
title = {Mix&amp;Match: Towards Omitting Modelling Through In-Situ Remixing of Model Repository Artifacts in Mixed Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376839},
doi = {10.1145/3313831.3376839},
abstract = {The accessibility of tools to model artifacts is one of the core driving factors for
the adoption of Personal Fabrication. Subsequently, model repositories like Thingiverse
became important tools in (novice) makers' processes. They allow them to shorten or
even omit the design process, offloading a majority of the effort to other parties.
However, steps like measurement of surrounding constraints (e.g., clearance) which
exist only inside the users' environment, can not be similarly outsourced. We propose
Mix&amp;Match a mixed-reality-based system which allows users to browse model repositories,
preview the models in-situ, and adapt them to their environment in a simple and immediate
fashion. Mix&amp;Match aims to provide users with CSG operations which can be based on
both virtual and real geometry. We present interaction patterns and scenarios for
Mix&amp;Match, arguing for the combination of mixed reality and model repositories. This
enables almost modelling-free personal fabrication for both novices and expert makers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3D printing, in-situ modelling, in-situ previews, mixed reality, model repositories, personal fabrication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376840,
author = {Katsini, Christina and Abdrabou, Yasmeen and Raptis, George E. and Khamis, Mohamed and Alt, Florian},
title = {The Role of Eye Gaze in Security and Privacy Applications: Survey and Future HCI Research Directions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376840},
doi = {10.1145/3313831.3376840},
abstract = {For the past 20 years, researchers have investigated the use of eye tracking in security
applications. We present a holistic view on gaze-based security applications. In particular,
we canvassed the literature and classify the utility of gaze in security applications
into a) authentication, b) privacy protection, and c) gaze monitoring during security
critical tasks. This allows us to chart several research directions, most importantly
1) conducting field studies of implicit and explicit gaze-based authentication due
to recent advances in eye tracking, 2) research on gaze-based privacy protection and
gaze monitoring in security critical tasks which are under-investigated yet very promising
areas, and 3) understanding the privacy implications of pervasive eye tracking. We
discuss the most promising opportunities and most pressing challenges of eye tracking
for security that will shape research in gaze-based security applications for the
next decade.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–21},
numpages = {21},
keywords = {literature survey, usable security, survey, human-centered security, gaze interaction, eye tracking, security, privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376841,
author = {Honnet, Cedric and Perner-Wilson, Hannah and Teyssier, Marc and Fruchard, Bruno and Steimle, J\"{u}rgen and Baptista, Ana C. and Strohmeier, Paul},
title = {PolySense: Augmenting Textiles with Electrical Functionality Using In-Situ Polymerization},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376841},
doi = {10.1145/3313831.3376841},
abstract = {We present a method for enabling arbitrary textiles to sense pressure and deformation:
In-situ polymerization supports integration of piezoresistive properties at the material
level, preserving a textile's haptic and mechanical characteristics. We demonstrate
how to enhance a wide set of fabrics and yarns using only readily available tools.
To further support customisation by the designer, we present methods for patterning,
as needed to create circuits and sensors, and demonstrate how to combine areas of
different conductance in one material. Technical evaluation results demonstrate the
performance of sensors created using our method is comparable to off-the-shelf piezoresistive
textiles. As application examples, we demonstrate rapid manufacturing of on-body interfaces,
tie-dyed motion-capture clothing, and zippers that act as potentiometers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {in-situ polymerization, etextiles, electro-functionalization, wearables, piezoresistive sensors, personal fabrication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376842,
author = {Goffin, Pascal and Blascheck, Tanja and Isenberg, Petra and Willett, Wesley},
title = {Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376842},
doi = {10.1145/3313831.3376842},
abstract = {We describe a design space of view manipulation interactions for small data-driven
contextual visualizations (word-scale visualizations). These interaction techniques
support an active reading experience and engage readers through exploration of embedded
visualizations whose placement and content connect them to specific terms in a document.
A reader could, for example, use our proposed interaction techniques to explore word-scale
visualizations of stock market trends for companies listed in a market overview article.
When readers wish to engage more deeply with the data, they can collect, arrange,
compare, and navigate the document using the embedded word-scale visualizations, permitting
more visualization-centric analyses. We support our design space with a concrete implementation,
illustrate it with examples from three application domains, and report results from
two experiments. The experiments show how view manipulation interactions helped readers
examine embedded visualizations more quickly and with less scrolling and yielded qualitative
feedback on usability and future opportunities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {word-scale visualization, information visualization, text visualization, glyphs, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376843,
author = {Shi, Weiyan and Wang, Xuewei and Oh, Yoo Jung and Zhang, Jingwen and Sahay, Saurav and Yu, Zhou},
title = {Effects of Persuasive Dialogues: Testing Bot Identities and Inquiry Strategies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376843},
doi = {10.1145/3313831.3376843},
abstract = {Intelligent conversational agents, or chatbots, can take on various identities and
are increasingly engaging in more human-centered conversations with persuasive goals.
However, little is known about how identities and inquiry strategies influence the
conversation's effectiveness. We conducted an online study involving 790 participants
to be persuaded by a chatbot for charity donation. We designed a two by four factorial
experiment (two chatbot identities and four inquiry strategies) where participants
were randomly assigned to different conditions. Findings showed that the perceived
identity of the chatbot had significant effects on the persuasion outcome (i.e., donation)
and interpersonal perceptions (i.e., competence, confidence, warmth, and sincerity).
Further, we identified interaction effects among perceived identities and inquiry
strategies. We discuss the findings for theoretical and practical implications for
developing ethical and effective persuasive chatbots. Our published data, codes, and
analyses serve as the first step towards building competent ethical persuasive chatbots.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {crowdsourced, text/speech/language, behavior change, empirical study that tells us about people},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376844,
author = {Karyda, Maria and Ry\"{o}ppy, Merja and Buur, Jacob and Lucero, Andr\'{e}s},
title = {Imagining Data-Objects for Reflective Self-Tracking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376844},
doi = {10.1145/3313831.3376844},
abstract = {While self-tracking data is typically captured real-time in a lived experience, the
data is often stored in a manner detached from the context where it belongs. Research
has shown that there is a potential to enhance people's lived experiences with data-objects
(artifacts representing contextually relevant data), for individual and collective
reflections through a physical portrayal of data. This paper expands that research
by studying how to design contextually relevant data-objects based on people's needs.
We conducted a participatory research project with five households using object theater
as a core method to encourage participants to speculate upon combinations of meaningful
objects and personal data archives. In this paper, we detail three aspects that seem
relevant for designing data-objects: social sharing, contextual ambiguity and interaction
with the body. We show how an experience-centric view on data-objects can contribute
with the contextual, social and bodily interplay between people, data and objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {personal objects, data-objects, object theater, experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376845,
author = {Lee, Bridjet and Muldner, Kasia},
title = {Instructional Video Design: Investigating the Impact of Monologue- and Dialogue-Style Presentations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376845},
doi = {10.1145/3313831.3376845},
abstract = {Instructional videos are frequently used in online courses and websites. Such videos
may include an instructor delivering a monologue-style presentation, or alternatively,
engaging in a dialogue with a student who appears in the video alongside of the instructor.
We compared three instructional video designs (N = 77), including monologue and dialogue
style presentations. To obtain a comprehensive view of the impact of video design,
we used a variety of measures, including eye tracking data, learning gains, self-efficacy,
cognitive load, social presence, and interest. Despite eye tracking data showing that
participants in speaker-visible conditions spent significantly less time on the domain
content, learning and related variables were similar in all three conditions, a result
we confirmed with Bayesian statistics that provided substantial evidence for the null
model. Altogether, we provide evidence that learning and interest are not enhanced
by a dialogue-style presentation or visual presence of the instructor. However, further
work is needed to investigate the effect of other domains, speaker persona and saliency,
and configuration of the speakers in the instructional video.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interest, visual presence, monologue presentation, dialogue presentation, eye tracking, instructional video design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376846,
author = {Williams, Francis and Bock, Alexander and Doraiswamy, Harish and Donatelli, Cassandra and Hall, Kayla and Summers, Adam and Panozzo, Daniele and Silva, Cl\'{a}udio T.},
title = {Unwind: Interactive Fish Straightening},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376846},
doi = {10.1145/3313831.3376846},
abstract = {The ScanAllFish project is a large-scale effort to scan all the world's 33,100 known
species of fishes. It has already generated thousands of volumetric CT scans of fish
species which are available on open access platforms such as the Open Science Framework.
To achieve a scanning rate required for a project of this magnitude, many specimens
are grouped together into a single tube and scanned all at once. The resulting data
contain many fish which are often bent and twisted to fit into the scanner. Our system,
Unwind, is a novel interactive visualization and processing tool which extracts, unbends,
and untwists volumetric images of fish with minimal user interaction. Our approach
enables scientists to interactively unwarp these volumes to remove the undesired torque
and bending using a piecewise-linear skeleton extracted by averaging isosurfaces of
a harmonic function connecting the head and tail of each fish. The result is a volumetric
dataset of a individual, straight fish in a canonical pose defined by the marine biologist
expert user. We have developed Unwind in collaboration with a team of marine biologists:
Our system has been deployed in their labs, and is presently being used for dataset
construction, biomechanical analysis, and the generation of figures for scientific
publication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {volumetric deformation, interactive system, visualization, ct scan data, visual analytics, visualization toolkits},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376847,
author = {Peng, Yi-Hao and Yu, Carolyn and Liu, Shi-Hong and Wang, Chung-Wei and Taele, Paul and Yu, Neng-Hao and Chen, Mike Y.},
title = {WalkingVibe: Reducing Virtual Reality Sickness and Improving Realism While Walking in VR Using Unobtrusive Head-Mounted Vibrotactile Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376847},
doi = {10.1145/3313831.3376847},
abstract = {Virtual Reality (VR) sickness is common with symptoms such as headaches, nausea, and
disorientation, and is a major barrier to using VR. We propose WalkingVibe, which
applies unobtrusive vibrotactile feedback for VR walking experiences, and also reduces
VR sickness and discomfort while improving realism. Feedback is delivered through
two small vibration motors behind the ears at a frequency that strikes a balance in
inducing vestibular response while minimizing annoyance. We conducted a 240-person
study to explore how visual, audio, and various tactile feedback designs affect the
locomotion experience of users walking passively in VR while seated statically in
reality. Results showed timing and location for tactile feedback have significant
effects on VR sickness and realism. With WalkingVibe, 2-sided step-synchronized design
significantly reduces VR sickness and discomfort while significantly improving realism.
Furthermore, its unobtrusiveness and ease of integration make WalkingVibe a practical
approach for improving VR experiences with new and existing VR headsets.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {vibrotactile feedback, discomfort, vestibular system, virtual reality sickness, realism},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376848,
author = {Wacker, Philipp and Wagner, Adrian and Voelker, Simon and Borchers, Jan},
title = {Heatmaps, Shadows, Bubbles, Rays: Comparing Mid-Air Pen Position Visualizations in Handheld AR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376848},
doi = {10.1145/3313831.3376848},
abstract = {In Handheld Augmented Reality, users look at AR scenes through the smartphone held
in their hand. In this setting, having a mid-air pointing device like a pen in the
other hand greatly expands the interaction possibilities. For example, it lets users
create 3D sketches and models while on the go. However, perceptual issues in Handheld
AR make it difficult to judge the distance of a virtual object, making it hard to
align a pen to it. To address this, we designed and compared different visualizations
of the pen's position in its virtual environment, measuring pointing precision, task
time, activation patterns, and subjective ratings of helpfulness, confidence, and
comprehensibility of each visualization. While all visualizations resulted in only
minor differences in precision and task time, subjective ratings of perceived helpfulness
and confidence favor a 'heatmap' technique that colors the objects in the scene based
on their distance to the pen.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {mid-air, interaction, modeling, augmented reality, 3D pen, depth perception, depth cues, smartphone},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376849,
author = {Baughan, Amanda and August, Tal and Yamashita, Naomi and Reinecke, Katharina},
title = {Keep It Simple: How Visual Complexity and Preferences Impact Search Efficiency on Websites},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376849},
doi = {10.1145/3313831.3376849},
abstract = {We conducted an online study with 165 participants in which we tested their search
efficiency and information recall. We confirm that the visual complexity of a website
has a significant negative effect on search efficiency and information recall. However,
the search efficiency of those who preferred simple websites was more negatively affected
by highly complex websites than those who preferred high visual complexity. Our results
suggest that diverse visual preferences need to be accounted for when assessing search
response time and information recall in HCI experiments, testing software, or A/B
tests.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {design, visual complexity, usability, information recall, search efficiency, visual appeal, user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376850,
author = {Olgado, Benedict Salazar and Pei, Lucy and Crooks, Roderic},
title = {Determining the Extractive Casting Mold of Intimate Platforms through Document Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376850},
doi = {10.1145/3313831.3376850},
abstract = {This paper introduces document theory as a mechanism to analyze intimate platforms
as sociotechnical systems. The theory, developed in documentation studies and applied
to HCI, focuses on the casting mold or how agents, through particular means and modes,
produce documents that govern social relations. We studied the process of creating
a profile by identifying and mapping out the fields asked among the ten most popular
online dating apps in the US. By looking at dating profiles as documents and their
creation as a process of documentation, we argue that the current casting mold of
these intimate platforms is designed to extract profit via invisibilization of labor
in digital networks leading to the emergence of a constrained rational market agent.
Our study illustrates how document theory makes visible the assumptions of technological
systems, calling on us to imagine alternatives beyond incremental design changes given
broader structural realities of market and power.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {document theory, intimate platforms, political economy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376851,
author = {D\"{u}rr, Maximilian and Gr\"{o}schel, Carla and Pfeil, Ulrike and Reiterer, Harald},
title = {NurseCare: Design and 'In-The-Wild' Evaluation of a Mobile System to Promote the Ergonomic Transfer of Patients},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376851},
doi = {10.1145/3313831.3376851},
abstract = {Nurses are frequently required to transfer patients as part of their daily duties.
However, the manual transfer of patients is a major risk factor for injuries to the
back. Although the Kinaesthetics Care Conception can help to address this issue, existing
support for the integration of the concept into nursing-care practice is low. We present
NurseCare, a mobile system that aims to promote the practical application of ergonomic
patient transfers based on the Kinaesthetics Care Conception. NurseCare consists of
a wearable and a smartphone app. Key features of NurseCare include mobile accessible
instructions for ergonomic patient transfers, in-situ feedback for the risky bending
of the back, and long-term feedback. We evaluated NurseCare in a nine participant 'in-the-wild' evaluation. Results indicate that NurseCare can facilitate ergonomic
work while providing a high user experience adequate to the nurses' work domain, and
reveal how NurseCare can be incorporated in given practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile system, nursing care, `in-the-wild' evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376852,
author = {M\"{u}ller, Florian and Schmitz, Martin and Schmitt, Daniel and G\"{u}nther, Sebastian and Funk, Markus and M\"{u}hlh\"{a}user, Max},
title = {Walk The Line: Leveraging Lateral Shifts of the Walking Path as an Input Modality for Head-Mounted Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376852},
doi = {10.1145/3313831.3376852},
abstract = {Recent technological advances have made head-mounted displays (HMDs) smaller and untethered,
fostering the vision of ubiquitous interaction in a digitally augmented physical world.
Consequently, a major part of the interaction with such devices will happen on the
go, calling for interaction techniques that allow users to interact while walking.
In this paper, we explore lateral shifts of the walking path as a hands-free input
modality. The available input options are visualized as lanes on the ground parallel
to the user's walking path. Users can select options by shifting the walking path
sideways to the respective lane. We contribute the results of a controlled experiment
with 18 participants, confirming the viability of our approach for fast, accurate,
and joyful interactions. Further, based on the findings of the controlled experiment,
we present three example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {head-mounted display, augmented reality, input, walking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376853,
author = {Kulp, Leah and Sarcevic, Aleksandra and Zheng, Yinan and Cheng, Megan and Alberto, Emily and Burd, Randall},
title = {Checklist Design Reconsidered: Understanding Checklist Compliance and Timing of Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376853},
doi = {10.1145/3313831.3376853},
abstract = {We examine the association between user interactions with a checklist and task performance
in a time-critical medical setting. By comparing 98 logs from a digital checklist
for trauma resuscitation with activity logs generated by video review, we identified
three non-compliant checklist use behaviors: failure to check items for completed
tasks, falsely checking items when tasks were not performed, and inaccurately checking
items for incomplete tasks. Using video review, we found that user perceptions of
task completion were often misaligned with clinical practices that guided activity
coding, thereby contributing to non-compliant check-offs. Our analysis of associations
between different contexts and the timing of check-offs showed longer delays when
(1) checklist users were absent during patient arrival, (2) patients had penetrating
injuries, and (3) resuscitations were assigned to the highest acuity. We discuss opportunities
for reconsidering checklist designs to reduce non-compliant checklist use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {checklist design, mixed methods, trauma resuscitation, video review, medical checklist, dynamic checklist},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376854,
author = {Sundar, S. Shyam and Kim, Jinyoung and Rosson, Mary Beth and Molina, Maria D.},
title = {Online Privacy Heuristics That Predict Information Disclosure},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376854},
doi = {10.1145/3313831.3376854},
abstract = {Online users' attitudes toward privacy are context-dependent. Studies show that contextual
cues are quite influential in motivating users to disclose personal information. Increasingly,
these cues are embedded in the interface, but the mechanisms of their effects (e.g.,
unprofessional design contributing to more disclosure) are not fully understood. We
posit that each cue triggers a specific "cognitive heuristic" that provides a rationale
for decision-making. Using a national survey (N = 786) that elicited participants'
disclosure intentions in common online scenarios, we identify 12 distinct heuristics
relevant to privacy, and demonstrate that they are systematically associated with
information disclosure. Data show that those with a higher accessibility to a given
heuristic are more likely to disclose information. Design implications for protection
of online privacy and security are discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information disclosure, online decision-making, cognitive heuristics, information privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376855,
author = {Wang, Weichen and Mirjafari, Shayan and Harari, Gabriella and Ben-Zeev, Dror and Brian, Rachel and Choudhury, Tanzeem and Hauser, Marta and Kane, John and Masaba, Kizito and Nepal, Subigya and Sano, Akane and Scherer, Emily and Tseng, Vincent and Wang, Rui and Wen, Hongyi and Wu, Jialing and Campbell, Andrew},
title = {Social Sensing: Assessing Social Functioning of Patients Living with Schizophrenia Using Mobile Phone Sensing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376855},
doi = {10.1145/3313831.3376855},
abstract = {Impaired social functioning is a symptom of mental illness (e.g., depression, schizophrenia)
and a wide range of other conditions (e.g., cognitive decline in the elderly, dementia).
Today, assessing social functioning relies on subjective evaluations and self assessments.
We propose a different approach and collect detailed social functioning measures and
objective mobile sensing data from N=55 outpatients living with schizophrenia to study
new methods of passively accessing social functioning. We identify a number of behavioral
patterns from sensing data, and discuss important correlations between social function
sub-scales and mobile sensing features. We show we can accurately predict the social
functioning of outpatients in our study including the following sub-scales: prosocial
activities (MAE = 7.79, r = 0.53), which indicates engagement in common social activities;
interpersonal behavior (MAE = 3.39, r = 0.57), which represents the number of friends
and quality of communications; and employment/occupation (MAE = 2.17, r = 0.62), which
relates to engagement in productive employment or a structured program of daily activity.
Our work on automatically inferring social functioning opens the way to new forms
of assessment and intervention across a number of areas including mental health and
aging in place.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mobile sensing, health, social functioning, social sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376856,
author = {Tigwell, Garreth W. and Crabb, Michael},
title = {Household Surface Interactions: Understanding User Input Preferences and Perceived Home Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376856},
doi = {10.1145/3313831.3376856},
abstract = {Households contain a variety of surfaces that are used in a number of activity contexts.
As ambient technology becomes commonplace in our homes, it is only a matter of time
before these surfaces become linked to computer systems for Household Surface Interaction
(HSI). However, little is known about the user experience attached to HSI, and the
potential acceptance of HSI within modern homes. To address this problem, we ran a
mixed methods user study with 39 participants to examine HSI using nine household
surfaces and five common gestures (tap, press, swipe, drag, and pinch). We found that
under the right conditions, surfaces with some amount of texture can enhance HSI.
Furthermore, perceived good and poor user experience varied among participants for
surface type indicating individual preferences. We present findings and design considerations
based on surface characteristics and the challenges that users perceive they may have
with HSI within their homes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {user experience, materiality, surface texture},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376857,
author = {Price, Thomas W. and Williams, Joseph Jay and Solyst, Jaemarie and Marwan, Samiha},
title = {Engaging Students with Instructor Solutions in Online Programming Homework},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376857},
doi = {10.1145/3313831.3376857},
abstract = {Students working on programming homework do not receive the same level of support
as in the classroom, relying primarily on automated feedback from test cases. One
low-effort way to provide more support is by prompting students to compare their solution
to an instructor's solution, but it is unclear the best way to design such prompts
to support learning. We designed and deployed a randomized controlled trial during
online programming homework, where we provided students with an instructor's solution,
and randomized whether they were prompted to compare their solution to the instructor's,
to fill in the blanks for a written explanation of the instructor's solution, to do
both, or neither. Our results suggest that these prompts can effectively engage students
in reflecting on instructor solutions, although the results point to design trade-offs
between the amount of effort that different prompts require from students and instructors,
and their relative impact on learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {computing education, self-explanation, programming, comparison},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376858,
author = {Kleinberger, R\'{e}becca and Harrington, Anne H. K. and Yu, Lydia and van Troyer, Akito and Su, David and Baker, Janet M. and Miller, Gabriel},
title = {Interspecies Interactions Mediated by Technology: An Avian Case Study at the Zoo},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376858},
doi = {10.1145/3313831.3376858},
abstract = {Enrichment is a methodology for caregivers to offer zoo animals improved psychological
and physiological well-being. Although many species rely on auditory senses, sonic
enrichment is rarely implemented. Zoo soundscapes are dominated by human-generated
noises and do not respond meaningfully to animals' behavior. Designing interactive
sonic enrichment systems for animals presents unique ergonomic, ethical, and agency-related
challenges. We present a case study of such design. We deployed two novel interventions
at the San Diego Zoo to allow Sampson, a music-savvy hyacinth macaw, to gain control
over his sonic environment. Our results suggest that (1) the bird uses, understands,
and benefits from the system, and (2) visitors play a major role in Sampson's engagement
with this technology. With his new agency, the bird seemingly gains more control over
his interactions with the public, creating an interspecies experience mediated by
technology. The resulting animal-human-computer interaction may inform mediated interspecies
experiences in the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {animal agency, interspecies interactions, animal computer interaction, sonic enrichment, enrichment, animal music},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376859,
author = {Altarriba Bertran, Ferran and M\'{a}rquez Segura, Elena and Isbister, Katherine},
title = {Technology for Situated and Emergent Play: A Bridging Concept and Design Agenda},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376859},
doi = {10.1145/3313831.3376859},
abstract = {Despite the capacity of play to spontaneously emerge in our daily life, the scope
of application of play design in HCI is generally narrower, specifically targeting
areas of pure leisure, or wholly utilitarian and productive play. Here we focus on
the value of play design to respond to and support our natural gravitation towards
emergent play that helps to meet our social and emotional needs. We present a bridging
concept: Technology for Situated and Emergent Play, i.e. technology design that supports
playful engagement that emerges interwoven with our everyday activities outside leisure,
and that enriches these activities with socio-emotional value. Our intermediate-level
contribution has value as a synthesis piece: it weaves together theories of play and
play design and bridges them with concrete design examples. As a bridging concept,
it contributes: i) theoretical grounding; ii) inspiring design exemplars that illustrate
the theory and foreground its value; and iii) design articulations in the form of
valuable experiential qualities and design features. Our work can help to focus design
agendas for playful technology and inspire future designs in this space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {play, playfulness, hci, interaction design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376860,
author = {Jahanbakhsh, Farnaz and Cranshaw, Justin and Counts, Scott and Lasecki, Walter S. and Inkpen, Kori},
title = {An Experimental Study of Bias in Platform Worker Ratings: The Role of Performance Quality and Gender},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376860},
doi = {10.1145/3313831.3376860},
abstract = {We study how the ratings people receive on online labor platforms are influenced by
their performance, gender, their rater's gender, and displayed ratings from other
raters. We conducted a deception study in which participants collaborated on a task
with a pair of simulated workers, who varied in gender and performance level, and
then rated their performance. When the performance of paired workers was similar,
low-performing females were rated lower than their male counterparts. Where there
was a clear performance difference between paired workers, low-performing females
were preferred over a similarly-performing male peer. Furthermore, displaying an average
rating from other raters made ratings more extreme, resulting in high performing workers
receiving significantly higher ratings and low performers lower ratings compared to
when average ratings were absent. This work contributes an empirical understanding
of when biases in ratings manifest, and offers recommendations for how online work
platforms can counter these biases.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {bias in gig platforms, bias in ratings, social mimicry, digital ratings, gender discrimination},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376861,
author = {Foley, Margaret and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Comparing Smartphone Speech Recognition and Touchscreen Typing for Composition and Transcription},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376861},
doi = {10.1145/3313831.3376861},
abstract = {Ruan et al. found transcribing short phrases with speech recognition nearly 200% faster
than typing on a smartphone. We extend this comparison to a novel composition task,
using a protocol that enables a controlled comparison with transcription. Results
show that both composing and transcribing with speech is faster than typing. But,
the magnitude of this difference is lower with composition, and speech has a lower
error rate than keyboard during composition, but not during transcription. When transcribing,
speech outperformed typing in most NASA-TLX measures, but when composing, there were
no significant differences between typing and speech for any measure except physical
demand.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {speech recognition, mobile phones, text entry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376862,
author = {Zhang, Yixuan and Suhaimi, Nurul and Azghandi, Rana and Joseph, Mary Amulya and Kim, Miso and Griffin, Jacqueline and Parker, Andrea G.},
title = {Understanding the Use of Crisis Informatics Technology among Older Adults},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376862},
doi = {10.1145/3313831.3376862},
abstract = {Mass emergencies increasingly pose significant threats to human life, with a disproportionate
burden being incurred by older adults. Research has explored how mobile technology
can mitigate the effects of mass emergencies. However, less work has examined how
mobile technologies support older adults during emergencies, considering their unique
needs. To address this research gap, we interviewed 16 older adults who had recent
experience with an emergency evacuation to understand the perceived value of using
mobile technology during emergencies. We found that there was a lack of awareness
and engagement with existing crisis apps. Our findings characterize the ways in which
our participants did and did not feel crisis informatics tools address human values,
including basic needs and esteem needs. We contribute an understanding of how older
adults used mobile technology during emergencies and their perspectives on how well
such tools address human values.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {older adults, human values, emergencies, crisis informatics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376863,
author = {Jung, Jingun and Lee, Sangyoon and Hong, Jiwoo and Youn, Eunhye and Lee, Geehyuk},
title = {Voice+Tactile: Augmenting In-Vehicle Voice User Interface with Tactile Touchpad Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376863},
doi = {10.1145/3313831.3376863},
abstract = {Promisingly, driving is adapting to a Voice User Interface (VUI) that lets drivers
utilize diverse applications with little effort. However, the VUI has innate usability
issues, such as a turn-taking problem, a short-term memory workload, inefficient controls,
and difficulty correcting errors. To overcome these weaknesses, we explored supplementing
the VUI with tactile interaction. As an early result, we present the Voice+Tactile
interactions that augment the VUI via multi-touch inputs and high-resolution tactile
outputs. We designed various Voice+Tactile interactions to support different VUI interaction
stages and derived four Voice+Tactile interaction themes: Status Feedback, Input Adjustment,
Output Control, and Finger Feedforward. A user study showed that the Voice+Tactile
interactions improved the VUI efficiency and its user experiences without incurring
significant additional distraction overhead on driving. We hope these early results
open new research questions to improve in-vehicle VUI with a tactile channel.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice user interface, in-vehicle user interface, tactile feedback touchpad},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376864,
author = {Kuosmanen, Elina and Kan, Valerii and Visuri, Aku and Hosio, Simo and Ferreira, Denzil},
title = {Let's Draw: Detecting and Measuring Parkinson's Disease on Smartphones},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376864},
doi = {10.1145/3313831.3376864},
abstract = {Spiral drawing has been utilized for years as a clinical tool to observe tremors and
other abnormal movements in the assessment of different movement disorders. Specifically,
in Parkinson's Disease (PD), patients' motor functionalities are measured by various
tests, and spiral drawing is one of the proven techniques for assessing the severity
of PD motor symptoms. Traditionally, this test is performed on pen and paper, and
visually assessed by a clinician. There have been successful efforts for digitizing
this test on tablets. Here, we describe a smartphone-based digitized version of the
spiral drawing test. Moreover, we introduce a square-shaped drawing to solve an identified
challenge of a smaller screen estate: finger occlusion while drawing. Both approaches
are evaluated with 8 Parkinson's Disease patients and 6 age-matching control participants.
Based on earlier studies and our data, we select suitable motion parameters for quantifying
the task. Our results show an observable, statistically difference in performance
between users with Parkinson's Disease and the control group in drawing accuracy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {motor assessment, smartphone, spiral analysis, archimedean spiral, parkinson's disease},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376865,
author = {Wang, Chi and Huang, Da-Yuan and Hsu, Shuo-Wen and Lin, Cheng-Lung and Chiu, Yeu-Luen and Hou, Chu-En and Chen, Bing-Yu},
title = {Gaiters: Exploring Skin Stretch Feedback on Legs for Enhancing Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376865},
doi = {10.1145/3313831.3376865},
abstract = {We propose generating two-dimensional skin stretch feedback on the user's legs. Skin
stretch is useful cutaneous feedback to induce the perception of virtual textures
and illusory forces and to deliver directional cues. This feedback has been applied
to the head, body, and upper limbs to simulate rich physical properties in virtual
reality (VR). However, how to expand the benefit of skin stretch feedback and apply
it to the lower limbs, remains to be explored. Our first two psychophysical studies
examined the minimum changes in skin stretch distance and stretch angle that are perceivable
by participants. We then designed and implemented Gaiters, a pair of ungrounded, leg-worn
devices, each of which is able to generate multiple two-dimensional skin stretches
on the skin of the user's leg. With Gaiters, we conducted an exploratory study to
understand participants' experiences when coupling skin stretch patterns with various
lower limb actions. The results indicate that rich haptic experiences can be created
by our prototype. Finally, a user evaluation indicates that participants enjoyed the
experiences when using Gaiters and considered skin stretch as compelling haptic feedback
on the legs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sheartactors, haptics, skin stretch feedback, leg-worn device, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376866,
author = {Sun, Dong and Feng, Zezheng and Chen, Yuanzhe and Wang, Yong and Zeng, Jia and Yuan, Mingxuan and Pong, Ting-Chuen and Qu, Huamin},
title = {DFSeer: A Visual Analytics Approach to Facilitate Model Selection for Demand Forecasting},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376866},
doi = {10.1145/3313831.3376866},
abstract = {Selecting an appropriate model to forecast product demand is critical to the manufacturing
industry. However, due to the data complexity, market uncertainty and users' demanding
requirements for the model, it is challenging for demand analysts to select a proper
model. Although existing model selection methods can reduce the manual burden to some
extent, they often fail to present model performance details on individual products
and reveal the potential risk of the selected model. This paper presents DFSeer, an
interactive visualization system to conduct reliable model selection for demand forecasting
based on the products with similar historical demand. It supports model comparison
and selection with different levels of details. Besides, it shows the difference in
model performance on similar products to reveal the risk of model selection and increase
users' confidence in choosing a forecasting model. Two case studies and interviews
with domain experts demonstrate the effectiveness and usability of DFSeer.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive visualization, model selection, product demand forecasting, time series},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376867,
author = {Zhu, Haining and Moffa, Zachary J. and Carroll, John M.},
title = {Relational Aspects in Patient-Provider Interactions: A Facial Paralysis Case Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376867},
doi = {10.1145/3313831.3376867},
abstract = {Facial appearance is significant for everyday interactions, but hundreds of thousands
of people have interactions negatively affected by facial paralysis (FP) annually.
FP treatment utilizes multiple components and requires significant collaboration amongst
multidisciplinary specialists and patients. Complex interactions in these contexts
offer ample challenges for designers to technologically support healthcare providers
in their processes. We conduct a formative case study, employing 20 clinic observations
and 11 interviews, to investigate FP treatment workflow. We use cognitive authority
theory (CAT) to understand relational factors in patient-provider collaboration. We
then pinpoint structural and relational components of workflow challenges and discuss
the utility of these distinctions; notably, we identify that patient adherence lapses
caused by perceived plateaus may be primarily relational and caused by unmet expectations.
Our work adds to patient-provider interaction literature and sheds light upon technology
design for healthcare team contexts with significant patient obligations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cognitive authority theory, multidisciplinary team, facial paralysis, therapy, patient-provider interaction, workflow},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376868,
author = {Voelker, Simon and Hueber, Sebastian and Corsten, Christian and Remy, Christian},
title = {HeadReach: Using Head Tracking to Increase Reachability on Mobile Touch Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376868},
doi = {10.1145/3313831.3376868},
abstract = {People often operate their smartphones with only one hand, using just their thumb
for touch input. With today's larger smartphones, this leads to a reachability issue:
Users can no longer comfortably touch everywhere on the screen without changing their
grip. We investigate using the head tracking in modern smartphones to address this
reachability issue. We developed three interaction techniques, pure head (PH), head
+ touch (HT), and head area + touch (HA), to select targets beyond the reach of one's
thumb. In two user studies, we found that selecting targets using HT and HA had higher
success rates than the default direct touch (DT) while standing (by about 9%) and
walking (by about 12%), while being moderately slower. HT and HA were also faster
than one of the best techniques, BezelCursor (BC) (by about 20% while standing and
6% while walking), while having the same success rate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {walking, gaze selection, touch input, reachability, head tracking, user study, force input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376869,
author = {Bedri, Abdelkareem and Li, Diana and Khurana, Rushil and Bhuwalka, Kunal and Goel, Mayank},
title = {FitByte: Automatic Diet Monitoring in Unconstrained Situations Using Multimodal Sensing on Eyeglasses},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376869},
doi = {10.1145/3313831.3376869},
abstract = {In an attempt to help users reach their health goals and practitioners understand
the relationship between diet and disease, researchers have proposed many wearable
systems to automatically monitor food consumption. When a person consumes food, he/she
brings the food close to their mouth, take a sip or bite and chew, and then swallow.
Most diet monitoring approaches focus on one of these aspects of food intake, but
this narrow reliance requires high precision and often fails in noisy and unconstrained
situations common in a person's daily life. In this paper, we introduce FitByte, a
multi-modal sensing approach on a pair of eyeglasses that tracks all phases of food
intake. FitByte contains a set of inertial and optical sensors that allow it to reliably
detect food intake events in noisy environments. It also has an on-board camera that
opportunistically captures visuals of the food as the user consumes it. We evaluated
the system in two studies with decreasing environmental constraints with 23 participants.
On average, FitByte achieved 89% F1-score in detecting eating and drinking episodes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ubiquitous computing, eating detection, drinking detection, diet monitoring, wearable computing, activity recognition, health sensing, earables},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376870,
author = {Yuan, Arianna and Li, Yang},
title = {Modeling Human Visual Search Performance on Realistic Webpages Using Analytical and Deep Learning Methods},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376870},
doi = {10.1145/3313831.3376870},
abstract = {Modeling visual search not only offers an opportunity to predict the usability of
an interface before actually testing it on real users but also advances scientific
understanding about human behavior. In this work, we first conduct a set of analyses
on a large-scale dataset of visual search tasks on realistic webpages. We then present
a deep neural network that learns to predict the scannability of webpage content,
i.e., how easy it is for a user to find a specific target. Our model leverages both
heuristic-based features such as target size and unstructured features such as raw
image pixels. This approach allows us to model complex interactions that might be
involved in a realistic visual search task, which can not be achieved by traditional
analytical models. We analyze the model behavior to offer our insights into how the
salience map learned by the model aligns with human intuition.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {webpage, visual attention, scannability, deep learning, performance modeling, convolutional neural network},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376871,
author = {McNaney, Roisin and Tsekleves, Emmanuel and Synnott, Jonathan},
title = {Future Opportunities for IoT to Support People with Parkinson's},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376871},
doi = {10.1145/3313831.3376871},
abstract = {Recent years have seen an explosion of internet of things (IoT) technologies being
released to the market. There has also been an emerging interest in the potentials
of IoT devices to support people with chronic health conditions. In this paper, we
describe the results of engagements to scope the future potentials of IoT for supporting
people with Parkinson's (PwP). We ran a 2-day multi-disciplinary event with professionals
with expertise in Parkinson's and IoT, to explore the opportunities, challenges and
benefits. We then ran 4 workshops, engaging 13 PwP and caregivers, to scope out the
needs, values and desires that the community has for utilizing IoT to monitor their
symptoms. This work contributes considerations for future IoT solutions that might
support PwP in better understanding their condition, through the provision of objective
measurements that correspond to their, currently unmeasured, subjective experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {design, iot, parkinson's, quantified self, self-monitoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376872,
author = {Baceviciute, Sarune and Mottelson, Aske and Terkildsen, Thomas and Makransky, Guido},
title = {Investigating Representation of Text and Audio in Educational VR Using Learning Outcomes and EEG},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376872},
doi = {10.1145/3313831.3376872},
abstract = {This paper reports findings from a between-subjects experiment that investigates how
different learning content representations in virtual environments (VE) affect the
process and outcomes of learning. Seventy-eight participants were subjected to an
immersive virtual reality (VR) application, where they received identical instructional
information, rendered in three different formats: as text in an overlay interface,
as text embedded semantically in a virtual book, or as audio. Learning outcome measures,
self-reports, and an electroencephalogram (EEG) were used to compare conditions. Results
show that reading was superior to listening for the learning outcomes of retention,
self-efficacy, and extraneous attention. Reading text from a virtual book was reported
to be less cognitively demanding, compared to reading from an overlay interface. EEG
analyses show significantly lower theta and higher alpha activation in the audio condition.
The findings provide important considerations for the design of educational VR environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eeg, learning, cognitive load, educational technology, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376873,
author = {Lai, Vivian and Liu, Han and Tan, Chenhao},
title = {"Why is 'Chicago' Deceptive?" Towards Building Model-Driven Tutorials for Humans},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376873},
doi = {10.1145/3313831.3376873},
abstract = {To support human decision making with machine learning models, we often need to elucidate
patterns embedded in the models that are unsalient, unknown, or counterintuitive to
humans. While existing approaches focus on explaining machine predictions with real-time
assistance, we explore model-driven tutorials to help humans understand these patterns
in a train- ing phase. We consider both tutorials with guidelines from scientific
papers, analogous to current practices of science communication, and automatically
selected examples from training data with explanations. We use deceptive review detection
as a testbed and conduct large-scale, randomized human-subject experiments to examine
the effectiveness of such tutorials. We find that tutorials indeed improve human performance,
with and without real-time assistance. In particular, although deep learning provides
superior predictive performance than simple models, tutorials and explanations from
simple models are more useful to humans. Our work suggests future directions for human-centered
tutorials and explanations towards a synergy between humans and AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interpretable machine learning, tutorials, deception detection, explanations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376874,
author = {Leung, Weiwen and Zhang, Zheng and Jibuti, Daviti and Zhao, Jinhao and Klein, Maximilian and Pierce, Casey and Robert, Lionel and Zhu, Haiyi},
title = {Race, Gender and Beauty: The Effect of Information Provision on Online Hiring Biases},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376874},
doi = {10.1145/3313831.3376874},
abstract = {We conduct a study of hiring bias on a simulation platform where we ask Amazon MTurk
participants to make hiring decisions for a mathematically intensive task. Our findings
suggest hiring biases against Black workers and less attractive workers, and preferences
towards Asian workers, female workers and more attractive workers. We also show that
certain UI designs, including provision of candidates' information at the individual
level and reducing the number of choices, can significantly reduce discrimination.
However, provision of candidate's information at the subgroup level can increase discrimination.
The results have practical implications for designing better online freelance marketplaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {discrimination, hiring, gig economy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376875,
author = {Wu, Jason and Harrison, Chris and Bigham, Jeffrey P. and Laput, Gierad},
title = {Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376875},
doi = {10.1145/3313831.3376875},
abstract = {Acoustic activity recognition has emerged as a foundational element for imbuing devices
with context-driven capabilities, enabling richer, more assistive, and more accommodating
computational experiences. Traditional approaches rely either on custom models trained
in situ, or general models pre-trained on preexisting data, with each approach having
accuracy and user burden implications. We present Listen Learner, a technique for
activity recognition that gradually learns events specific to a deployed environment
while minimizing user burden. Specifically, we built an end-to-end system for self-supervised
learning of events labelled through one-shot interaction. We describe and quantify
system performance 1) on preexisting audio datasets, 2) on real-world datasets we
collected, and 3) through user studies which uncovered system behaviors suitable for
this new type of interaction. Our results show that our system can accurately and
automatically learn acoustic events across environments (e.g., 97% precision, 87%
recall), while adhering to users' preferences for non-intrusive interactive behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {acoustic activity recognition, automatic class discovery},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376876,
author = {Wolf, Dennis and Gugenheimer, Jan and Combosch, Marco and Rukzio, Enrico},
title = {Understanding the Heisenberg Effect of Spatial Interaction: A Selection Induced Error for Spatially Tracked Input Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376876},
doi = {10.1145/3313831.3376876},
abstract = {Virtual and augmented reality head-mounted displays (HMDs) are currently heavily relying
on spatially tracked input devices (STID) for interaction. These STIDs are all prone
to the phenomenon that a discrete input (e.g. button press) will disturb the position
of the tracker, resulting in a different selection point during ray-cast interaction
(Heisenberg Effect of Spatial Interaction). Besides the knowledge of its existence,
there is currently a lack of a deeper understanding of its severity, structure and
impact on throughput and angular error during a selection task. In this work, we present
a formal evaluation of the Heisenberg effect and the impact of body posture, arm position
and STID degrees of freedom on its severity. In a Fitt's Law inspired user study (N=16),
we found that the Heisenberg effect is responsible for 30.45% of the overall errors
occurring during a pointing task, but can be reduced by 25.4% using a correction function.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {pointing, vr, stid, offset, selection, correction, heisenberg effect},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376877,
author = {V\"{o}lkel, Sarah Theres and Haeuslschmid, Renate and Werner, Anna and Hussmann, Heinrich and Butz, Andreas},
title = {How to Trick AI: Users' Strategies for Protecting Themselves from Automatic Personality Assessment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376877},
doi = {10.1145/3313831.3376877},
abstract = {Psychological targeting tries to influence and manipulate users' behaviour. We investigated
whether users can protect themselves from being profiled by a chatbot, which automatically
assesses users' personality. Participants interacted twice with the chatbot: (1) They
chatted for 45 minutes in customer service scenarios and received their actual profile
(baseline). (2) They then were asked to repeat the interaction and to disguise their
personality by strategically tricking the chatbot into calculating a falsified profile.
In interviews, participants mentioned 41 different strategies but could only apply
a subset of them in the interaction. They were able to manipulate all Big Five personality
dimensions by nearly 10%. Participants regarded personality as very sensitive data.
As they found tricking the AI too exhaustive for everyday use, we reflect on opportunities
for privacy protective designs in the context of personality-aware systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {automatic personality assessment, chatbot, personality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376878,
author = {Liu, Wanyu and Gori, Julien and Rioul, Olivier and Beaudouin-Lafon, Michel and Guiard, Yves},
title = {How Relevant is Hick's Law for HCI?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376878},
doi = {10.1145/3313831.3376878},
abstract = {Hick's law is a key quantitative law in Psychology that relates reaction time to the
logarithm of the number of stimulus-response alternatives in a task. Its application
to HCI is controversial: Some believe that the law does not apply to HCI tasks, others
regard it as the cornerstone of interface design. The law, however, is often misunderstood.
We review the choice-reaction time literature and argue that: (1) Hick's law speaks
against, not for, the popular principle that 'less is better'; (2) logarithmic growth
of observed temporal data is not necessarily interpretable in terms of Hick's law;
(3) the stimulus-response paradigm is rarely relevant to HCI tasks, where choice-reaction
time can often be assumed to be constant; and (4) for user interface design, a detailed
examination of the effects on choice-reaction time of psychological processes such
as visual search and decision making is more fruitful than a mere reference to Hick's
law.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {the hick-hyman law, convexity, information, uncertainty, hick's law, stimulus-response, logarithm, choice reaction time},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376879,
author = {Rohani, Darius A. and Quemada Lopategui, Andrea and Tuxen, Nanna and Faurholt-Jepsen, Maria and Kessing, Lars V. and Bardram, Jakob E.},
title = {MUBS: A Personalized Recommender System for Behavioral Activation in Mental Health},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376879},
doi = {10.1145/3313831.3376879},
abstract = {Depression is a leading cause of disability worldwide, which has inspired the design
of mobile health (mHealth) applications for disease monitoring, prediction, and diagnosis.
Less mHealth research has, however, focused on the treatment of depressive disorders.
Clinical evidence shows that depressive symptoms can be reduced through a behavior
change method known as Behavioral Activation (BA). This paper presents MUBS; a smartphone-based
system for BA, which specifically contributes a personalized content-based activity
recommendation model using a unique list of validated activities. An 8-week feasibility
study with 17 depressive patients provided detailed insight into how MUBS provided
inspiration and motivation for planning and engaging in more pleasant activities,
thereby facilitating the core components of BA. Based on this study, the paper discusses
how recommender technology can be used in the design of mHealth technology for BA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {behavioral activation, mental health, recommendation, depression, activities, well-being, planning, smartphone},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376880,
author = {Lin, Halden and Moritz, Dominik and Heer, Jeffrey},
title = {Dziban: Balancing Agency &amp; Automation in Visualization Design via Anchored Recommendations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376880},
doi = {10.1145/3313831.3376880},
abstract = {Visualization recommender systems attempt to automate design decisions spanning choices
of selected data, transformations, and visual encodings. However, across invocations
such recommenders may lack the context of prior results, producing unstable outputs
that override earlier design choices. To better balance automated suggestions with
user intent, we contribute Dziban, a visualization API that supports both ambiguous
specification and a novel anchoring mechanism for conveying desired context. Dziban
uses the Draco knowledge base to automatically complete partial specifications and
suggest appropriate visualizations. In addition, it extends Draco with chart similarity
logic, enabling recommendations that also remain perceptually similar to a provided
"anchor" chart. Existing APIs for exploratory visualization, such as ggplot2 and Vega-Lite,
require fully specified chart definitions. In contrast, Dziban provides a more concise
and flexible authoring experience through automated design, while preserving predictability
and control through anchored recommendations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {anchoring, recommendation, visualization, language},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376881,
author = {Stobert, Elizabeth and Barrera, David and Homier, Val\'{e}rie and Kollek, Daniel},
title = {Understanding Cybersecurity Practices in Emergency Departments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376881},
doi = {10.1145/3313831.3376881},
abstract = {Emergency departments (EDs) have unique operational requirements within hospitals.
They have strong availability demands, are staffed by rotating personnel, and must
provide services as quickly as possible. Modern EDs are also heavily computerized,
and as such cybersecurity practices play a key role in meeting the expected operational
standards. To better understand the cybersecurity challenges in EDs, we conducted
a survey asking 347 ED personnel across Canada about their cybersecurity practices.
The survey collected information relating to authentication and password management,
use of personal devices for handling patient data, Internet connectivity on personal
and hospital systems, and institutional security policies. Our results show that across
multiple hospitals, deployed computer security systems fail to integrate with the
requirements of staff and patients, leading to interruptions and inefficiencies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {usability, hospitals, security, medicine},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376882,
author = {Yeckehzaare, Iman and Barghi, Tirdad and Resnick, Paul},
title = {QMaps: Engaging Students in Voluntary Question Generation and Linking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376882},
doi = {10.1145/3313831.3376882},
abstract = {Generating multiple-choice questions is known to improve students' critical thinking
and deep learning. Visualizing relationships between concepts enhances meaningful
learning, students' ability to relate new concepts to previously learned concepts.
We designed and deployed a collaborative learning process through which students generate
multiple-choice questions and represent the prerequisite knowledge structure between
questions as visual links in a shared map, using a variation of Concept Maps that
we call "QMap." We conducted a four-month study with 19 undergraduate students. Students
sustained voluntary contributions, creating 992 good questions, and drawing 1,255
meaningful links between the questions. Through analyzing self-reports, observations,
and usage data, we report on the technical and social design features that led students
to sustain their motivation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {learner-centered design, concept mapping, question generation, intrinsic motivation, collaborative learning, learnersourcing, cscl},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376883,
author = {Beneteau, Erin},
title = {Who Are You Asking?: Qualitative Methods for Involving AAC Users as Primary Research Participants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376883},
doi = {10.1145/3313831.3376883},
abstract = {When trying to understand people's perspectives, qualitative researchers in HCI often
use methods which assume participants can easily communicate verbally. There are few
dedicated resources in HCI which provide an overview of qualitative methods to effectively
gather the perspectives of people who cannot easily communicate verbally; specifically,
people who use Augmentative and Alternative Communication (AAC). As a result, AAC
users might be excluded from studies using methods such as interviews or focus groups,
even if they fit the researcher's target population. To address this problem, I review
literature from both HCI and therapeutic AAC research fields to discuss methods used
with AAC users. In addition, I present relevant case examples from my own qualitative
research and propose a framework to guide HCI researchers on choosing appropriate
methods when involving AAC users as central research participants. I also identify
design opportunities for HCI researchers to innovate on the tools and methods used
for qualitative research with AAC users. This paper provides an easily accessible
overview of qualitative methods HCI researchers can use with AAC users as participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {methods, disabilities, aac, augmentative and alternative communication, qualitative research, hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376884,
author = {Hou, Ming and Mahadevan, Karthik and Somanath, Sowmya and Sharlin, Ehud and Oehlberg, Lora},
title = {Autonomous Vehicle-Cyclist Interaction: Peril and Promise},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376884},
doi = {10.1145/3313831.3376884},
abstract = {Autonomous vehicles (AVs) will redefine interactions between road users. Presently,
cyclists and drivers communicate through implicit cues (vehicle motion) and explicit
but imprecise signals (hand gestures, horns). Future AVs could consistently communicate
awareness and intent and other feedback to cyclists based on their sensor data. We
present an exploration of AV-cyclist interaction, starting with preliminary design
studies which informed the implementation of an immersive VR AV-cyclist simulator,
and the design and evaluation of a number of AV-cyclist interfaces. Our findings suggest
that AV-cyclist interfaces can improve rider confidence in lane merging scenarios.
We contribute an AV-cyclist immersive simulator, insights on trade-offs of various
aspects of AV-cyclist interaction design including modalities, location, and complexity,
and positive results suggesting improved rider confidence due to AV-cyclist interaction.
While we are encouraged by the potential positive impact AV-cyclist interfaces can
have on cyclist culture, we also emphasize the risks over-reliance can pose to cyclists.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interfaces for communicating intent and awareness, autonomous vehicle cyclist interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376885,
author = {Bowen, Simon and Wright, Peter and Wilson, Alexander and Dow, Andy and Bartindale, Tom and Anderson, Robert},
title = {Metro Futures: Experience-Centred Co-Design at Scale},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376885},
doi = {10.1145/3313831.3376885},
abstract = {This paper discusses how characteristics of experience-centred and collaborative design
can be translated to larger scales. We describe Metro Futures, a region-wide public
consultation on the design of new light rail trains, where we followed an experience-centred
co-design approach supported by digital media and tools to develop findings with a
core group of 20 ?co-researchers' and ~4000 public participants. The paper discusses
how the characteristics of a focus on experience, and collaborative design exploration
were achieved with co-researchers and, at scale, through online and face-to-face interactions
using various digital media and tools. Whilst not at the depth of smaller scales,
there are opportunities to retain characteristics of experience-centred co-design
at scale to produce findings that can usefully inform ensuing design work, and avoid
the averaging of public contributions often evident in large scale public consultations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {large-scale design, co-design, experience-centred design, public transport},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376886,
author = {Tomlinson, Brianna J. and Walker, Bruce N. and Moore, Emily B.},
title = {Auditory Display in Interactive Science Simulations: Description and Sonification Support Interaction and Enhance Opportunities for Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376886},
doi = {10.1145/3313831.3376886},
abstract = {Science simulations are widely used in classrooms to support inquiry-based learning
of complex science concepts. These tools typically rely on interactive visual displays
to convey relationships. Auditory displays, including verbal description and sonification
(non-speech audio), combined with alternative input capabilities, may provide an enhanced
experience for learners, particularly learners with visual impairment. We completed
semi-structured interviews and usability testing with eight adult learners with visual
impairment for two audio-enhanced simulations. We analyzed trends and edge cases in
participants' interaction patterns, interpretations, and preferences. Findings include
common interaction patterns across simulation use, increased efficiency with second
use, and the complementary role that description and sonification play in supporting
learning opportunities. We discuss how these control and display layers work to encourage
exploration and engagement with science simulations. We conclude with general and
specific design takeaways to support the implementation of auditory displays for accessible
simulations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual impairment, learning, multimodal, interactive simulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376887,
author = {Heyer, Jeremy and Raveendranath, Nirmal Kumar and Reda, Khairi},
title = {Pushing the (Visual) Narrative: The Effects of Prior Knowledge Elicitation in Provocative Topics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376887},
doi = {10.1145/3313831.3376887},
abstract = {Narrative visualization is a popular style of data-driven storytelling. Authors use
this medium to engage viewers with complex and sometimes controversial issues. A challenge
for authors is to not only deliver new information, but to also overcome people's
biases and misconceptions. We study how people adjust their attitudes toward (or away
from) a message experienced through a narrative visualization. In a mixed-methods
analysis, we investigate whether eliciting participants' prior beliefs, and visualizing
those beliefs alongside actual data, can increase narrative persuasiveness. We find
that incorporating priors does not significantly affect attitudinal change. However,
participants who externalized their beliefs expressed greater surprise at the data.
Their comments also indicated a greater likelihood of acquiring new information, despite
the minimal change in attitude. Our results also extend prior findings, showing that
visualizations are more persuasive than equivalent textual data representations for
exposing contentious issues. We discuss the implications and outline future research
directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {persuasion, debiasing, narrative visualization, belief elicitation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376888,
author = {Wu, Qin and Yu, Chenmei and Chen, Yanjun and Yao, Jiayu and Wu, Xi and Peng, Xiaolan and Han, Teng},
title = {Squeeze the Ball: Designing an Interactive Playground towards Aiding Social Activities of Children with Low-Function Autism},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376888},
doi = {10.1145/3313831.3376888},
abstract = {Most intervention methods used for social skills training in children with autism
are dedicated to high-functioning autism (HFA). However, extensive neurological and
developmental disorders of low-functioning autism (LFA) have hampered their adoption.
In this study, we observed and interviewed children with LFA, and their teachers,
from a local educational institution, to better understand the children's social needs
and barriers. Then, with the aim of aiding the children with their social activities,
we illustrate the design process of SqueeBall, an interactive playground equipment.
We evaluated the design with 18 children (16 with LFA and 2 with HFA) between 2.5
and 7 years of age. Results showed that these children had a pleasant game experience
when the group bonded, and the equipment had a positive effect on aiding them in various
ways. Finally, we discuss the challenges and opportunities of multimedia interaction
techniques in aiding children with LFA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {disability, autism, social communication intervention, low-function autism, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376889,
author = {Sanches, Pedro and Tsaknaki, Vasiliki and Rostami, Asreen and Brown, Barry},
title = {Under Surveillance: Technology Practices of Those Monitored by the State},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376889},
doi = {10.1145/3313831.3376889},
abstract = {This paper documents the experiences of those living under state surveillance. We
interviewed our participants about how they lived under threat, and how it changed
their technology practices. Our participants spanned three groups - journalists who
reported from countries where their activities were illegal; activists who took part
in civil disobedience, and individuals who worked in illegal activities that would
have likely led to prosecution. In our analysis we cover four themes: first, 'the
imagined surveillant'. Second, the danger and dependencies of technology use, third,
their coping strategies, and lastly how belonging to a group can protect but also
expose. In our discussion we cover how we can design for dissidents, and how to deal
with the difficult questions this raises. We conclude by advocating for research that
takes into account a critical view of the state in HCI and more broadly for an anti-surveillance
stance in the design of technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {state, dissidents, surveillance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}


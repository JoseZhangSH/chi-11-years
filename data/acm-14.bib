@inproceedings{10.1145/3251017,
author = {Edge, Darren},
title = {Session Details: Exploring Exergames},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251017},
doi = {10.1145/3251017},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557385,
author = {Sheinin, Mike and Gutwin, Carl},
title = {Exertion in the Small: Improving Differentiation and Expressiveness in Sports Games with Physical Controls},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557385},
doi = {10.1145/2556288.2557385},
abstract = {Many sports video games contain elements such as running or throwing that are based
on real-world physical activities, but the translation of these activities to game
controllers means that the original physicality is lost. This results in games where
players have limited opportunity to improve their physical skills, where there is
little differentiation in people's physical abilities, and where skills do not change
over the course of a game. To explore ways of adding these elements back into sports
games, we developed two games with small-scale physical controls for running and throwing
-- one game was a simple running race, and one was a team-based handball-style game
called Jelly Polo. In two studies (three track-and-field tournaments for the running
game, and a four-week league for Jelly Polo), we observed the effects of physical
controls on gameplay. Our studies showed that the physical controls enabled substantial
individual differences in running and passing skill, allowed people to increase their
expertise over time, and led to fatigue-based changes in performance during a game.
Physical controls increased the games' challenge, complexity, and unpredictability,
and dramatically improved player interest, expressiveness, and enjoyment. Our work
shows that game designers should consider the idea of "exertion in the small" as a
way to improve play experience in games based on physical activities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1845–1854},
numpages = {10},
keywords = {exertion games, physical controls, sports video games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557246,
author = {Chen, Frank X. and King, Abby C. and Hekler, Eric B.},
title = {"healthifying" Exergames: Improving Health Outcomes through Intentional Priming},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557246},
doi = {10.1145/2556288.2557246},
abstract = {Exergames, video game systems that require exertion and interaction, have been rising
in popularity in the past years. However, research on popular exergames shows mixed
health benefits, potentially due to minimal energy expenditure and decreasing use
over time. This paper presents a 2x2 experimental study (N = 44), using a popular
exergame, where we vary the framing of intention (i.e., "Gameplay" or "Exercise")
and feedback (i.e., "Health" or "No health") to explore their single and interactive
impacts on perceived exertion, objectively measured energy expenditure, affect, and
duration of usage in a single session. Our study showed that participants primed with
exercise used the system significantly longer than those primed with game play (M
= 49.2 ±2.0 min versus M = 39.3 ±2.0 min). We discuss our results and possible design
implications based on our single-session experiment. We conclude with a discussion
on the potential impact of focusing on "healthifying" exergames -highlighting an exergames"
dual purpose as both a game and exercise - as opposed to gamifying health behaviors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1855–1864},
numpages = {10},
keywords = {persuasive technology, exergaming, fitness, priming},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557091,
author = {Park, Taiwoo and Lee, Uichin and MacKenzie, Scott and Moon, Miri and Hwang, Inseok and Song, Junehwa},
title = {Human Factors of Speed-Based Exergame Controllers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557091},
doi = {10.1145/2556288.2557091},
abstract = {Exergame controllers are intended to add fun to monotonous exercise. However, studies
on exergame controllers mostly focus on designing new controllers and exploring specific
application domains without analyzing human factors, such as performance, comfort,
and effort. In this paper, we examine the characteristics of a speed-based exergame
controller that bear on human factors related to body movement and exercise. Users
performed tasks such as changing and maintaining exercise speed for avatar control
while their performance was measured. The exergame controller follows Fitts' law,
but requires longer movement time than a gamepad and Wiimote. As well, resistance
force and target speed affect performance. User experience data confirm that the comfort
and mental effort are adequate as practical game controllers. The paper concludes
with discussion on applying our findings to practical exergame design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1865–1874},
numpages = {10},
keywords = {game controller, speed-based control, exergame},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557329,
author = {Zaczynski, Monica and Whitehead, Anthony D.},
title = {Establishing Design Guidelines in Interactive Exercise Gaming: Preliminary Data from Two Posing Studies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557329},
doi = {10.1145/2556288.2557329},
abstract = {Interactive gaming has demonstrated promise as a low-cost, at-home training and fitness
instruction alternative. Gaming systems offer convenience and the ability to provide
enhanced reporting and progress data if body measurement information is collected
effectively. However, commercially available systems today are designed primarily
for entertainment and as a result, the quality of instruction delivery and level of
involvement may not meet the needs of a user performing a disciplined activity.This
paper will look at adapting for occlusion and lack of visibility; learning and orientation;
and providing feedback in an effort to determine if there is an ideal visual demonstration
delivery that maximizes pose understanding and user self-efficacy, determine whether
supplementary modalities are important for instruction, and determine if there is
an ideal feedback delivery that promotes pose comprehension, confidence and motivation.
This information can provide a guideline for designing clear and supportive, interactive
training systems that can engage users, prevent injury and help maintain fitness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1875–1884},
numpages = {10},
keywords = {visual delivery, yoga, panning, usability, wii balance board, haptic feedback, design guidelines, low-paced exercise training, feedback},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251018,
author = {Kelliher, Aisling},
title = {Session Details: Narratives and Storytelling},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251018},
doi = {10.1145/3251018},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557034,
author = {Wood, Gavin and Vines, John and Balaam, Madeline and Taylor, Nick and Smith, Thomas and Crivellaro, Clara and Mensah, Juliana and Limon, Helen and Challis, John and Anderson, Linda and Clarke, Adam and Wright, Peter C.},
title = {The Department of Hidden Stories: Playful Digital Storytelling for Children in a Public Library},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557034},
doi = {10.1145/2556288.2557034},
abstract = {We detail the design of the Department of Hidden Stories (DoHS), a mobile-based game
to support playful digital storytelling among primary school children in public libraries.
Through a process of iterative design in collaboration with library staff and children's
writers we designed DoHS to support the potential for playful storytelling through
interactions with books. A deployment of DoHS with two classes of 8 to 10 years olds
as part of their regular library visits revealed insights related to how to balance
the expectations of a child-at-play and the requirement to further develop their creative
reading and writing skills. Based on our experiences we recommend that designers create
playful digitally based activities that encourage children to explore libraries and
experience new interactions with physical books.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1885–1894},
numpages = {10},
keywords = {children's library, storytelling, augmenting books, play},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557296,
author = {Andrews, Daniel and Baber, Chris},
title = {Visualizing Interactive Narratives: Employing a Branching Comic to Tell a Story and Show Its Readings},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557296},
doi = {10.1145/2556288.2557296},
abstract = {This paper describes the design and evaluation of a branching comic to compare how
readers recall a visual narrative when presented as an interactive, digital program,
or as a linear sequence on paper. The layout of the comic is used to visualize this
data as heat maps and explore patterns of users' recollections. We describe the theoretical
justification for this based upon previous work in narrative visualizations, interactive
stories and comics. Having tested the comic with school boys aged 11-12; we saw patterns
in the data that complement other research in both interactive stories and visualizations.
We argue that the heat maps helped identify these patterns, which have implications
for future designs and analyses of interactive visual and/or narrative media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1895–1904},
numpages = {10},
keywords = {interactive stories, narrative visualization, branching comics, story comprehension},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557339,
author = {Huang, Jin and Yu, Chun and Wang, Yuntao and Zhao, Yuhang and Liu, Siqi and Mo, Chou and Liu, Jie and Zhang, Lie and Shi, Yuanchun},
title = {FOCUS: Enhancing Children's Engagement in Reading by Using Contextual BCI Training Sessions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557339},
doi = {10.1145/2556288.2557339},
abstract = {Reading is an important aspect of a child's development. Reading outcome is heavily
dependent on the level of engagement while reading. In this paper, we present FOCUS,
an EEG-augmented reading system which monitors a child's engagement level in real
time, and provides contextual BCI training sessions to improve a child's reading engagement.
A laboratory experiment was conducted to assess the validity of the system. Results
showed that FOCUS could significantly improve engagement in terms of both EEG-based
measurement and teachers' subjective measure on the reading outcome.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1905–1908},
numpages = {4},
keywords = {reading engagement, brain-computer interface (BCI), contextual reading},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557154,
author = {Wang, Chen and Geelhoed, Erik N. and Stenton, Phil P. and Cesar, Pablo},
title = {Sensing a Live Audience},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557154},
doi = {10.1145/2556288.2557154},
abstract = {Psychophysiological measurement has the potential to play an important role in audience
research. Currently, such research is still in its infancy and it usually involves
collecting data in the laboratory, where during each experimental session one individual
watches a video recording of a performance. We extend the experimental paradigm by
simultaneously measuring Galvanic Skin Response (GSR) of a group of participants during
a live performance. GSR data were synchronized with video footage of performers and
audience. In conjunction with questionnaire data, this enabled us to identify a strongly
correlated main group of participants, describe the nature of their theatre experience
and map out a minute-by-minute unfolding of the performance in terms of psycho-physiological
engagement. The benefits of our approach are twofold. It provides a robust and accurate
mechanism for assessing a performance. Moreover, our infrastructure can enable, in
the future, real-time feedback from remote audiences for online performances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1909–1912},
numpages = {4},
keywords = {galvanic skin response., audience engagement},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251019,
author = {Hanson, Vicki},
title = {Session Details: Designing for Older Adults and Demographic Change},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251019},
doi = {10.1145/3251019},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557124,
author = {Haddad, Shathel and McGrenere, Joanna and Jacova, Claudia},
title = {Interface Design for Older Adults with Varying Cultural Attitudes toward Uncertainty},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557124},
doi = {10.1145/2556288.2557124},
abstract = {This work reports on the design and evaluation of culturally appropriate technology
for older adults. Our design context was Cognitive Testing on a Computer (C-TOC):
a self-administered computerized test under development, intended to screen older
adults for cognitive impairments. Using theory triangulation of cultural attitudes
toward uncertainty, we designed two interfaces (one minimal and one rich) for one
C-TOC subtest and hypothesized they would be culturally appropriate for older adult
Caucasians and East Asians respectively. We ran an experiment with 36 participants
to investigate cultural differences in performance, preference and anxiety. We found
that Caucasians preferred the interface with minimal elements (i.e. those essential
for the primary task) or had no preference. By contrast, East Asians preferred the
rich interface augmented with security and learning support and felt less anxious
with it than the minimal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1913–1922},
numpages = {10},
keywords = {older adults, experiment, cultural design, computerized cognitive assessment, uncertainty avoidance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557300,
author = {Meurer, Johanna and Stein, Martin and Randall, David and Rohde, Markus and Wulf, Volker},
title = {Social Dependency and Mobile Autonomy: Supporting Older Adults' Mobility with Ridesharing Ict},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557300},
doi = {10.1145/2556288.2557300},
abstract = {Alternative mobility modes for older adults are increasingly important for economic,
ecological and social reasons. A promising option is ridesharing, defined as use of
the same vehicle by two or more people traveling to a common destination. In particular,
mobile computer supported ridesharing provides a promising way to enlarge older adults'
mobility choices in addition to private driving and public transportation options.
In order to understand the opportunities and obstacles of ridesharing from the point
of view of elderly people, we conducted an interview study in order to examining ridesharing
experiences. It turns out that "mobile independence" and "decisional autonomy" are
key issues for mobile wellbeing. This partially conflicts with common ridesharing
concepts. Hence, we further analyze older adults' strategies dealing with these conflicts
and show that these strategies offer departure points for the design ridesharing solutions,
which are better suited to the demands of older adults.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1923–1932},
numpages = {10},
keywords = {design, dynamic ridesharing, social experiences, elderly, ethnography},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557084,
author = {Arreola, Ingrid and Morris, Zan and Francisco, Matthew and Connelly, Kay and Caine, Kelly and White, Ginger},
title = {From Checking on to Checking in: Designing for Low Socio-Economic Status Older Adults},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557084},
doi = {10.1145/2556288.2557084},
abstract = {In this paper we describe the design evolution of a novel technology that collects
and displays presence information to be used in the homes of older adults. The first
two iterations, the Ambient Plant and Presence Clock, were designed for higher socio-economic
status (SES) older adults, whereas the Check-In Tree was designed for low SES older
adults. We describe how feedback from older adult participants drove our design decisions,
and give an in-depth account of how the Check-In Tree evolved from concept to a final
design ready for in situ deployment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1933–1936},
numpages = {4},
keywords = {aging in place, caregivers, older adults, peer production},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557314,
author = {Vaisutis, Kate and Brereton, Margot and Robertson, Toni and Vetere, Frank and Durick, Jeannette and Nansen, Bjorn and Buys, Laurie},
title = {Invisible Connections: Investigating Older People's Emotions and Social Relations around Objects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557314},
doi = {10.1145/2556288.2557314},
abstract = {The advent of the Internet of Things creates an interest in how people might interrelate
through and with networks of internet enabled objects. With an emphasis on fostering
social connection and physical activity among older people, this preliminary study
investigated objects that people over the age of 65 years viewed as significant to
them. We conducted contextual interviews in people's homes about their significant
objects in order to understand the role of the objects in their lives, the extent
to which they fostered emotional and social connections and physical activity, and
how they might be augmented through internet connection.Discussion of significant
objects generated considerable emotion in the participants. We identified objects
of comfort and routine, objects that exhibited status, those that fostered independence
and connection, and those that symbolized relationships with loved ones. These findings
lead us to consider implications for the design of interconnected objects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1937–1940},
numpages = {4},
keywords = {objects, socio-material relations, internet of things, social relations, ageing, tangible interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251020,
author = {Parker, Andrea},
title = {Session Details: Critical Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251020},
doi = {10.1145/3251020},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557055,
author = {Feinberg, Melanie and Carter, Daniel and Bullard, Julia},
title = {Always Somewhere, Never There: Using Critical Design to Understand Database Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557055},
doi = {10.1145/2556288.2557055},
abstract = {Structured databases achieve effective searching and sorting by enacting sharply delineated
category boundaries around their contents. While this enables precise retrieval, it
also distorts identities that exist between category lines. A choice between Single
and Married, for example, blurs distinctions within the Single group: single, perhaps,
merely because same-sex marriage is not legal in one's locality. Sociologists Susan
Leigh Star and Geoffrey Bowker describe such residual states as inevitable byproducts
of information systems. To minimize residuality, traditional practice for descriptive
metadata seeks to demarcate clear and objective classes. In this study, we use critical
design to question this position by creating information collections that foreground
the residual, instead of diminishing it. We then interrogate our design experiments
with solicited critical responses from invited experts and student designers. Inspired
by the anthropologist Tim Ingold, we argue that our experiments illuminate a form
of interacting with databases characterized by notions of wayfaring, or inhabiting
a space, as opposed to notions of transport, or reaching a known destination. We suggest
that the form of coherence that shapes a wayfaring database is enacted through its
flow, or fluid integration between structure and content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1941–1950},
numpages = {10},
keywords = {criticism, classification, collections, metadata, design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557137,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Stolterman, Erik},
title = {Reading Critical Designs: Supporting Reasoned Interpretations of Critical Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557137},
doi = {10.1145/2556288.2557137},
abstract = {Critical Design has emerged as an important concept in HCI research and practice.
Yet researchers have noted that its uptake has been limited by certain lacks of intellectual
infrastructure theories, methodologies, canons and exemplars, and a community of practice.
We argue that one way to create this infrastructure is to cultivate a community adept
at reading that is, critically interpreting and making reasoned judgments about critical
designs. We propose an approach to developing close readings of critical designs,
which are both evidence-based and carefully reasoned. The approach highlights analytical
units of analysis, the relevance of design languages and social norms, and the analytical
contemplation of critical aspects of a design. It is intended to be relatively easy
to learn, to try out, and to teach, in the hopes of inviting more members of the HCI
community to engage in this practice. We exemplify the approach with readings of two
critical designs and reflect on different ways that a design might serve a critical
purpose or offer a critical argument about design, society, and the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1951–1960},
numpages = {10},
keywords = {art, criticism, critical design, design theory, interpretation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557178,
author = {Odom, William T. and Sellen, Abigail J. and Banks, Richard and Kirk, David S. and Regan, Tim and Selby, Mark and Forlizzi, Jodi L. and Zimmerman, John},
title = {Designing for Slowness, Anticipation and Re-Visitation: A Long Term Field Study of the Photobox},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557178},
doi = {10.1145/2556288.2557178},
abstract = {We describe the design, implementation and deployment of Photobox, a domestic technology
that prints four or five randomly selected photos from the owner's Flickr collection
at random intervals each month. We deployed Photobox in three homes for fourteen months,
to explore how the slow pace at which it operates could support experiences of anticipation
and re-visitation of the past. Findings reveal changes in attitude toward the device,
from frustration to eventual acceptance. Participants drew on the photos to reflect
on past life events and reactions indicated a renewed interest for their Flickr collection.
Photobox also provoked reflection on technology in and around the home. These findings
suggest several opportunities, such as designing for anticipation, better supporting
reflection on the past, and, more generally, expanding the slow technology research
program within the HCI community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1961–1970},
numpages = {10},
keywords = {interaction design, home, design, slow technology},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557357,
author = {Sas, Corina and Whittaker, Steve and Dow, Steven and Forlizzi, Jodi and Zimmerman, John},
title = {Generating Implications for Design through Design Research},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557357},
doi = {10.1145/2556288.2557357},
abstract = {A central tenet of HCI is that technology should be user-centric, with designs being
based around social science findings about users. Nevertheless a repeated but critical
challenge in design is translating empirical findings into actionable ideas that inform
design, or generating implications for design. Despite various design methods aiming
to bridge this gap, knowledge informing design is still seen as problematic. However
there has been little empirical exploration into what design researchers understand
by such design knowledge, the functions and principles behind their creation. We report
on interviews with twelve expert HCI design researchers probing the roles and types
of design implications, and the process of generating and evaluating them. We synthesize
different types of design implications into a framework to guide their generation.
Our findings identify a broader range than previously described, additional sources
and heuristics supporting their development as well some important evaluation criteria.
We discuss the value of these findings for interaction design research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1971–1980},
numpages = {10},
keywords = {design knowledge, implications for design, design research},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251021,
author = {Vogel, Daniel},
title = {Session Details: Understanding and Modeling Touch},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251021},
doi = {10.1145/3251021},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557312,
author = {Ng, Alexander and Brewster, Stephen A. and Williamson, John H.},
title = {Investigating the Effects of Encumbrance on One- and Two- Handed Interactions with Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557312},
doi = {10.1145/2556288.2557312},
abstract = {In this paper, we investigate the effects of encumbrance (carrying typical objects
such as shopping bags during interaction) and walking on target acquisition on a touchscreen
mobile phone. Users often hold objects and use mobile devices at the same time and
we examined the impact encumbrance has on one- and two- handed interactions. Three
common input postures were evaluated: two-handed index finger, one-handed preferred
thumb and two-handed both thumbs, to assess the effects on performance of carrying
a bag in each hand while walking. The results showed a significant decrease in targeting
performance when users were encumbered. For example, input accuracy dropped to 48.1%
for targeting with the index finger when encumbered, while targeting error using the
preferred thumb to input was 4.2mm, an increase of 40% compared to unencumbered input.
We also introduce a new method to evaluate the user's preferred walking speed when
interacting - PWS&amp;I, and suggest future studies should use this to get a more accurate
measure of the user's input performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1981–1990},
numpages = {10},
keywords = {target acquisition, encumbrance, one- and two- handed input, mobile interactions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557354,
author = {Bergstrom-Lehtovirta, Joanna and Oulasvirta, Antti},
title = {Modeling the Functional Area of the Thumb on Mobile Touchscreen Surfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557354},
doi = {10.1145/2556288.2557354},
abstract = {We present a predictive model for the functional area of the thumb on a touchscreen
surface: the area of the interface reachable by the thumb of the hand that is holding
the device. We derive a quadratic formula by analyzing the kinematics of the gripping
hand. Model fit is high for the thumb-motion trajectories of 20 participants. The
model predicts the functional area for a given 1) surface size, 2) hand size, and
3) position of the index finger on the back of the device. Designers can use this
model to ensure that a user interface is suitable for interaction with the thumb.
The model can also be used inversely - that is, to infer the grips assumed by a given
user interface layout.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1991–2000},
numpages = {10},
keywords = {thumb, predictive model, touchscreen, functional area},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557088,
author = {Tsandilas, Theophanis and Appert, Caroline and Bezerianos, Anastasia and Bonnet, David},
title = {Coordination of Tilt and Touch in One- and Two-Handed Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557088},
doi = {10.1145/2556288.2557088},
abstract = {Our goal is to enhance navigation in mobile interfaces with quick command gestures
that do not make use of explicit mode-switching actions. TilTouch gestures extend
the vocabulary of navigation interfaces by combining motion tilt with directional
touch. We consider sixteen directional TilTouch gestures that rely on tilt and touch
movements along the four main compass directions. An experiment explores their effectiveness
for both one-handed and two-handed use. Results identify the best combinations of
TilTouch gestures in terms of performance, motor coordination, and user preferences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2001–2004},
numpages = {4},
keywords = {mobile devices, tilt, touchscreen, gestures, touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557148,
author = {Mohd Noor, Mohammad Faizuddin and Ramsay, Andrew and Hughes, Stephen and Rogers, Simon and Williamson, John and Murray-Smith, Roderick},
title = {28 Frames Later: Predicting Screen Touches from Back-of-Device Grip Changes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557148},
doi = {10.1145/2556288.2557148},
abstract = {We demonstrate that front-of-screen targeting on mobile phones can be predicted from
back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors
placed around a standard phone, we outline a machine learning approach to modelling
the grip modulation and inferring front-of-screen touch targets. We experimentally
demonstrate that grip is a remarkably good predictor of touch, and we can predict
touch position 200ms before contact with an accuracy of 18mm.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2005–2008},
numpages = {4},
keywords = {machine learning, touch, capacitive, back-of-device},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557056,
author = {Schwarz, Julia and Xiao, Robert and Mankoff, Jennifer and Hudson, Scott E. and Harrison, Chris},
title = {Probabilistic Palm Rejection Using Spatiotemporal Touch Features and Iterative Classification},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557056},
doi = {10.1145/2556288.2557056},
abstract = {Tablet computers are often called upon to emulate classical pen-and-paper input. However,
touchscreens typically lack the means to distinguish between legitimate stylus and
finger touches and touches with the palm or other parts of the hand. This forces users
to rest their palms elsewhere or hover above the screen, resulting in ergonomic and
usability problems. We present a probabilistic touch filtering approach that uses
the temporal evolution of touch contacts to reject palms. Our system improves upon
previous approaches, reducing accidental palm inputs to 0.016 per pen stroke, while
correctly passing 98% of stylus inputs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2009–2012},
numpages = {4},
keywords = {touchscreen, pen and stylus input, palm rejection, touch interaction, tablet computing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557399,
author = {Nguyen, Quan and Kipp, Michael},
title = {Orientation Matters: Efficiency of Translation-Rotation Multitouch Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557399},
doi = {10.1145/2556288.2557399},
abstract = {The translation and rotation of objects with two fingers is a well explored multitouch
technique. However, there are some unsolved questions regarding the optimal conditions
under which this technique functions best. Does it matter in which direction the movement
is oriented? Does parallel or sequential performance of the two operations work best?
This study attempts to answer this question using a typical Fitts' Law setup but with
varying translation-rotation orientation combinations. The results show that right-oriented
movements were faster and easier than left-oriented ones. Movement combinations which
went in different directions (translation right, rotation left, and vice versa) were
found more tiresome and resulted in more strategy switches compared to equi-directional
combinations. Our findings can inform positioning decisions in interaction design
and contribute to theoretical adjustments to Fitts' Law.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2013–2016},
numpages = {4},
keywords = {multitouch interaction techniques, fitts law, 2d translation and rotation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251022,
author = {Stuerzlinger, Wolfgang},
title = {Session Details: 3D Interaction: Modeling and Prototyping},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251022},
doi = {10.1145/3251022},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557218,
author = {Gupta, Ankit and Agrawala, Maneesh and Curless, Brian and Cohen, Michael},
title = {MotionMontage: A System to Annotate and Combine Motion Takes for 3D Animations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557218},
doi = {10.1145/2556288.2557218},
abstract = {We present MotionMontage, a system for recording multiple motion takes of a rigid
virtual object and compositing them together into a montage. Our system incorporates
a Kinect-based performance capture setup that allows animators to create 3D animations
by tracking the motion of a rigid physical object and mapping it in realtime onto
a virtual object. The animator then temporally annotates the best parts of each take.
MotionMontage merges the annotated motions into a single composite montage using a
combination of dynamic time warping and optimization of a Semi-Markov Conditional
Random Field. Our system also supports the creation of layered animations in which
multiple objects are moving at the same time. To aid the animator in coordinating
the motions of the objects we provide spatial markers which indicate the positions
of previously recorded objects at user-specified points in time. We perform a user
study to evaluate the perceived quality of the montages created with our system and
find that viewers (including both the original animators and new viewers) generally
prefer the animation montage to any individual take.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2017–2026},
numpages = {10},
keywords = {montage, animation, active visual feedback, depth camera},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557009,
author = {Chen, Hsiang-Ting and Grossman, Tovi and Wei, Li-Yi and Schmidt, Ryan M. and Hartmann, Bj\"{o}rn and Fitzmaurice, George and Agrawala, Maneesh},
title = {History Assisted View Authoring for 3D Models},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557009},
doi = {10.1145/2556288.2557009},
abstract = {3D modelers often wish to showcase their models for sharing or review purposes. This
may consist of generating static viewpoints of the model or authoring animated fly-throughs.
Manually creating such views is often tedious and few automatic methods are designed
to interactively assist the modelers with the view authoring process. We present a
view authoring assistance system that supports the creation of informative view points,
view paths, and view surfaces, allowing modelers to author the interactive navigation
experience of a model. The key concept of our implementation is to analyze the model's
workflow history, to infer important regions of the model and representative viewpoints
of those areas. An evaluation indicated that the viewpoints generated by our algorithm
are comparable to those manually selected by the modeler. In addition, participants
of a user study found our system easy to use and effective for authoring viewpoint
summaries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2027–2036},
numpages = {10},
keywords = {3D model, viewpoint authoring, editing history},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557183,
author = {Broy, Nora and Schneegass, Stefan and Alt, Florian and Schmidt, Albrecht},
title = {FrameBox and MirrorBox: Tools and Guidelines to Support Designers in Prototyping Interfaces for 3D Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557183},
doi = {10.1145/2556288.2557183},
abstract = {In this paper, we identify design guidelines for stereoscopic 3D (S3D) user interfaces
(UIs) and present the MirrorBox and the FrameBox, two UI prototyping tools for S3D
displays. As auto-stereoscopy becomes available for the mass market we believe the
design of S3D UIs for devices, for example, mobile phones, public displays, or car
dashboards, will rapidly gain importance. A benefit of such UIs is that they can group
and structure information in a way that makes them easily perceivable for the user.
For example, important information can be shown in front of less important information.
This paper identifies core requirements for designing S3D UIs and derives concrete
guidelines. The requirements also serve as a basis for two depth layout tools we built
with the aim to overcome limitations of traditional prototyping when sketching S3D
UIs. We evaluated the tools with usability experts and compared them to traditional
paper prototyping.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2037–2046},
numpages = {10},
keywords = {user interfaces, prototyping, stereoscopic 3d},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557242,
author = {Ortega, Micha\"{e}l and Vincent, Thomas},
title = {Direct Drawing on 3D Shapes with Automated Camera Control},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557242},
doi = {10.1145/2556288.2557242},
abstract = {We present ACCD, an interaction technique that allows direct drawing of long curves
on 3D shapes with a tablet display over both multiple depth layers and multiple viewpoints.
ACCD reduces the number of explicit viewpoint manipulations by combining self-occlusion
management and automated camera control. As such it enables drawing on occluded faces
but also around a 3D shape while keeping a constant drawing precision. Our experimental
results indicates the efficacy of ACCD over conventional techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2047–2050},
numpages = {4},
keywords = {3d painting, 3d interaction technique, camera controls},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556966,
author = {Joshi, Neel S. and Morris, Dan and Cohen, Michael F.},
title = {Interactively Stylizing Camera Motion},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556966},
doi = {10.1145/2556288.2556966},
abstract = {Movie directors and cinematographers impart style onto video using techniques that
are learned through years of experience: camera movement, framing, color, lighting,
etc. Without this experience and expensive equipment, it is very difficult to control
stylistic aspects of a video. We introduce a novel approach for post-hoc editing of
one specific aspect of cinematography -- camera motion style -- via an equalizer-like
set of controls that manipulates the power spectra of a video's apparent motion path.
We explore free manipulation of apparent camera motion as well as the transfer of
motion styles from an example video to a new video to create a wide range of stylistic
variations. We report on a user study confirming the ability of non-expert users to
create motion styles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2051–2054},
numpages = {4},
keywords = {video stylization, camera motion editing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251023,
author = {Steimle, J\"{u}rgen},
title = {Session Details: The Eyes Have It},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251023},
doi = {10.1145/3251023},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557129,
author = {Crnovrsanin, Tarik and Wang, Yang and Ma, Kwan-Liu},
title = {Stimulating a Blink: Reduction of Eye Fatigue with Visual Stimulus},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557129},
doi = {10.1145/2556288.2557129},
abstract = {Computers make incredible amounts of information available at our fingertips. As computers
become integral parts of our lives, we spend more time staring at computer monitor
than ever before, sometimes with negative effects. One major concern is the increasing
number of people suffering from Computer Vision Syndrome (CVS). CVS is caused by extensive
use of computers, and its symptoms include eye fatigue, frequent headaches, dry eyes,
and blurred vision. It is possible to partially alleviate CVS if we can remind users
to blink more often. We present a prototype system that uses a camera to monitor a
user's blink rate, and when the user has not blinked in a while, the system triggers
a blink stimulus. We investigated four different types of eye-blink stimulus: screen
blurring, screen flashing, border flashing, and pop-up notifications. Users also rated
each stimulus type in terms of effectiveness, intrusiveness, and satisfaction. Results
from our user studies show that our stimuli are effective in increasing user blink
rate with screen blurring being the best.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2055–2064},
numpages = {10},
keywords = {cvs, user study, blink detection, blink stimulus},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557025,
author = {Walber, Tina Caroline and Scherp, Ansgar and Staab, Steffen},
title = {Smart Photo Selection: Interpret Gaze as Personal Interest},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557025},
doi = {10.1145/2556288.2557025},
abstract = {Manually selecting subsets of photos from large collections in order to present them
to friends or colleagues or to print them as photo books can be a tedious task. Today,
fully automatic approaches are at hand for supporting users. They make use of pixel
information extracted from the images, analyze contextual information such as capture
time and focal aperture, or use both to determine a proper subset of photos. However,
these approaches miss the most important factor in the photo selection process: the
user. The goal of our approach is to consider individual interests. By recording and
analyzing gaze information from the user's viewing photo collections, we obtain information
on user's interests and use this information in the creation of personal photo selections.
In a controlled experiment with 33 participants, we show that the selections can be
significantly improved over a baseline approach by up to 22% when taking individual
viewing behavior into account. We also obtained significantly better results for photos
taken at an event participants were involved in compared with photos from another
event.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2065–2074},
numpages = {10},
keywords = {photo selection, usage-based image selection, eye tracking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557086,
author = {Jiang, Xianta and Atkins, M. Stella and Tien, Geoffrey and Bednarik, Roman and Zheng, Bin},
title = {Pupil Responses during Discrete Goal-Directed Movements},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557086},
doi = {10.1145/2556288.2557086},
abstract = {Pupil size is known to correlate with the changes of cognitive task workloads, but
how the pupil responds to requirements of basic goal-directed motor tasks involved
in human-machine interactions is not yet clear. This work conducted a user study to
investigate the pupil dilations during aiming in a tele-operation setting, with the
purpose of better understanding how the changes in task requirements are reflected
by the changes of pupil size. The task requirements, managed by Fitts' index of difficulty
(ID), i.e. the size and distance apart of the targets, were varied between tasks,
and pupil responses to different task IDs were recorded. The results showed that pupil
diameter can be employed as an indicator of task requirements in goal-directed movements-higher
task difficulty evoked higher valley to peak pupil dilation, and the peak pupil dilation
occurred after a longer delay. These findings contribute to the foundation for developing
methods to objectively evaluate interactive task requirements using pupil parameters
during goal-directed movements in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2075–2084},
numpages = {10},
keywords = {fitts' law, movement-evoked pupillary response, pupil diameter, goal-directed movement},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557279,
author = {May, Jon and Gamble, Tim},
title = {Collocating Interface Objects: Zooming into Maps},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557279},
doi = {10.1145/2556288.2557279},
abstract = {May, Dean and Barnard (2003) used a theoretically based model to argue that objects
in a wide range of interfaces should be collocated following screen changes such as
a zoom-in to detail. Many existing online maps do not follow this principle, but move
a clicked point to the centre of the subsequent display, leaving the user looking
at an unrelated location. This paper presents three experiments showing that collocating
the point clicked on a map so that the detailed location appears in the place previously
occupied by the overview location makes the map easier to use, reducing eye movements
and interaction duration. We discuss the benefit of basing design principles on theoretical
models so that they can be applied to novel situations, and so designers can infer
when to use and not use them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2085–2094},
numpages = {10},
keywords = {eye-tracking, cognitive models, maps, zooming, collocation, cinematography},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251024,
author = {Tatar, Deborah},
title = {Session Details: Learning and Education},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251024},
doi = {10.1145/3251024},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557207,
author = {Kizilcec, Ren\'{e} F. and Papadopoulos, Kathryn and Sritanyaratana, Lalida},
title = {Showing Face in Video Instruction: Effects on Information Retention, Visual Attention, and Affect},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557207},
doi = {10.1145/2556288.2557207},
abstract = {The amount of online educational content is rapidly increasing, particularly in the
form of video lectures. The goal is to design video instruction to facilitate an experience
that maximizes learning and satisfaction. A widely used but understudied design element
in video instruction is the overlay of a small video of the instructor over lecture
slides. We conducted an experiment with eye-tracking and recall tests to investigate
how adding the instructor's face to video instruction affects information retention,
visual attention, and affect. Participants strongly preferred instruction with the
face and perceived it as more educational. They spent about 41% of time looking at
the face and switched between the face and slide every 3.7 seconds. Consistent with
prior work, no significant difference in short- and medium-term recall ability was
found. Including the face in video instruction is encouraged based on learners' positive
affective response. More fine-grained analytics combining eye-tracking with detailed
learning assessment could shed light on the mechanisms by which the face aids or hinders
learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2095–2102},
numpages = {8},
keywords = {multimedia learning, audiovisual instruction, eye-tracking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557162,
author = {Lui, Michelle and Kuhn, Alex C. and Acosta, Alisa and Quintana, Chris and Slotta, James D.},
title = {Supporting Learners in Collecting and Exploring Data from Immersive Simulations in Collective Inquiry},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557162},
doi = {10.1145/2556288.2557162},
abstract = {Digitally augmented physical spaces (e.g., smart classrooms) offer opportunities to
engage students in novel and potentially transformative learning experiences. This
paper presents an immersive rainforest simulation and collective inquiry activity
where students collect observational data from the environment and explore their peers'
data through large visualization displays and personal mobile devices. Two iterations
of the design were tested, which resulted in higher quality student explanations constructed.
Images were found to be an important source of evidence for the explanations, more
so than text-only evidence. We also found that patterns of collective ideas influenced
student performance, and that visualizations, as ambient or plenary displays, supported
both teacher and students in reviewing patterns of collected data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2103–2112},
numpages = {10},
keywords = {mobile computing, multi-device environments, smart classroom, large displays, digitally augmented physical spaces, science inquiry, visualizations},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557387,
author = {Mentis, Helena M. and Chellali, Amine and Schwaitzberg, Steven},
title = {Learning to See the Body: Supporting Instructional Practices in Laparoscopic Surgical Procedures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557387},
doi = {10.1145/2556288.2557387},
abstract = {Learning the practices and the performance of physically manipulating instruments
in minimally invasive surgeries is an impetus for the development of surgical training
simulators. However, an often-overlooked aspect of surgical training is learning how
to see the body through the various imaging mechanisms. With this study, we address
the ways in which surgeons demonstrate and instruct residents in seeing the body during
minimally invasive surgical procedures. Drawing on observations and analysis of video
recordings of minimally invasive surgical operations, we examine how particular anatomy
and movement within the body to see and conceptualize that anatomy are made visible
by the instructive practices of the surgeon. We use these findings to discuss further
directions for minimally invasive surgical training through mechanisms for making
the body visible during situated surgical training and surgical training simulation
systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2113–2122},
numpages = {10},
keywords = {gestures, training, movement, vision, surgery},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557294,
author = {Shelley, Tia and Lyons, Leilah and Moher, Tom and Dasgupta, Chandan and Lopez Silva, Brenda and Silva, Alexandra},
title = {Information-Building Applications: Designing for Data Exploration and Analysis by Elementary School Students},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557294},
doi = {10.1145/2556288.2557294},
abstract = {The propagation of Inquiry Based Learning has lead to many more elementary students
interacting with authentic scientific tools and practices. However, the more problematic
realities of scientific data collection, such as noise and large data sets, are often
deliberately hidden from students. Students will need to confront these realities
and be able to make skillful data scoping decisions in order to make sense of ever
more prevalent large datasets. We dub software designed to support these activities
Information-Building Applications (IBAs). This paper presents the design considerations
that went into building an exemplar IBA, PhotoMAT (Photo Management and Analysis Tool),
a brief user study to show how the solutions enacted by following these principles
are taken up by actual students, and a discussion of how the design considerations
identified by our work might be applied to another IBA.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2123–2132},
numpages = {10},
keywords = {k-12 science education, information-building applications, learner centered design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250953,
author = {Inkpen, Kori},
title = {Session Details: Telepresence and Connecting over Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250953},
doi = {10.1145/3250953},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557169,
author = {Nakanishi, Hideyuki and Tanaka, Kazuaki and Wada, Yuya},
title = {Remote Handshaking: Touch Enhances Video-Mediated Social Telepresence},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557169},
doi = {10.1145/2556288.2557169},
abstract = {Since past studies on haptic and visual communication have tended to be isolated from
each other, it has remained unclear whether a touch channel can still enrich mediated
communication where video and audio channels are already available. To clarify this,
we analyzed remote handshaking in which a robot hand that was attached just under
a videoconferencing terminal's display moved according to the opening and closing
motion of a conversation partner's hand. Combining touch and video channels raises
a question as to whether the partner's action of touching a haptic device should be
visible to the user. If it can be invisible, the action may be unnecessary, and a
unilaterally controlled device may be enough to establish an effective touch channel.
Our analysis revealed that the feeling of being close to the partner can be enhanced
by mutual touch in which the partner's action needs to occur but should be invisible.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2143–2152},
numpages = {10},
keywords = {video-mediated communication, social telepresence, videoconferencing, social touch, haptic devices, humanoid robots, social interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557047,
author = {Rae, Irene and Mutlu, Bilge and Takayama, Leila},
title = {Bodies in Motion: Mobility, Presence, and Task Awareness in Telepresence},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557047},
doi = {10.1145/2556288.2557047},
abstract = {Robotic telepresence systems - videoconferencing systems that allow a remote user
to drive around in another location - provide an alternative to video-mediated communications
as a way of interacting over distances. These systems, which are seeing increasing
use in business and medical settings, are unique in their ability to grant the remote
user the ability to maneuver in a distant location. While this mobility promises increased
feelings of "being there" for remote users and thus greater support for task collaboration,
whether these promises are borne out, providing benefits in task performance, is unknown.
To better understand the role that mobility plays in shaping the remote user's sense
of presence and its potential benefits, we conducted a two-by-two (system mobility:
stationary vs. mobile; task demands for mobility: low vs. high) controlled laboratory
experiment. We asked participants (N=40) to collaborate in a construction task with
a confederate via a robotic telepresence system. Our results showed that mobility
significantly increased the remote user's feelings of presence, particularly in tasks
with high mobility requirements, but decreased task performance. Our findings highlight
the positive effects of mobility on feelings of "being there," while illustrating
the need to design support for effective use of mobility in high-mobility tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2153–2162},
numpages = {10},
keywords = {presence, robot-mediated communication, mobility, robotic telepresence, task awareness, remote collaboration},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557198,
author = {Procyk, Jason and Neustaedter, Carman and Pang, Carolyn and Tang, Anthony and Judge, Tejinder K.},
title = {Exploring Video Streaming in Public Settings: Shared Geocaching over Distance Using Mobile Video Chat},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557198},
doi = {10.1145/2556288.2557198},
abstract = {Our research explores the use of mobile video chat in public spaces by people participating
in parallel experiences, where both a local and remote person are doing the same activity
together at the same time. We prototyped a wearable video chat experience and had
pairs of friends and family members participate in 'shared geocaching' over distance.
Our results show that video streaming works best for navigation tasks but is more
challenging to use for fine-grained searching tasks. Video streaming also creates
a very intimate experience with a remote partner, but this can lead to distraction
from the 'real world' and even safety concerns. Overall, privacy concerns with streaming
from a public space were not typically an issue; however, people tended to rely on
assumptions of what were acceptable. The implications are that designers should consider
appropriate feedback, user disembodiment, and asymmetry when designing for parallel
experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2163–2172},
numpages = {10},
keywords = {video communication, geocaching, shared experiences},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557320,
author = {Pan, Ye and Steed, Anthony},
title = {A Gaze-Preserving Situated Multiview Telepresence System},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557320},
doi = {10.1145/2556288.2557320},
abstract = {Gaze, attention, and eye contact are important aspects of face to face communication,
but some subtleties can be lost in videoconferencing because participants look at
a single planar image of the remote user. We propose a low-cost cylindrical videoconferencing
system that preserves gaze direction by providing perspective-correct images for multiple
viewpoints around a conference table. We accomplish this by using an array of cameras
to capture a remote person, and an array of projectors to present the camera images
onto a cylindrical screen. The cylindrical screen reflects each image to a narrow
viewing zone. The use of such a situated display allows participants to see the remote
person from multiple viewing directions. We compare our system to three alternative
display configurations. We demonstrate the effectiveness of our system by showing
it allows multiple participants to simultaneously tell where the remote person is
placing their gaze.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2173–2176},
numpages = {4},
keywords = {camera arrays, gaze, non-planar displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557117,
author = {Cohen, Maayan and Dillman, Kody R. and MacLeod, Haley and Hunter, Seth and Tang, Anthony},
title = {OneSpace: Shared Visual Scenes for Active Freeplay},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557117},
doi = {10.1145/2556288.2557117},
abstract = {Children engage in free play for emotional, physical and social development; researchers
have explored supporting free play between physically remote playmates using videoconferencing
tools. We show that the configuration of the video conferencing setup affects play.
Specifically, we show that a shared visual scene configuration promotes fundamentally
active forms of engaged, co-operative play.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2177–2180},
numpages = {4},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250954,
author = {Munson, Sean},
title = {Session Details: Exergame Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250954},
doi = {10.1145/3250954},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557257,
author = {Garner, Jayden and Wood, Gavin and Pijnappel, Sebastiaan and Murer, Martin and Mueller, Florian},
title = {I-Dentity: Innominate Movement Representation as Engaging Game Element},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557257},
doi = {10.1145/2556288.2557257},
abstract = {Movement-based digital games typically make it clear whose movement representation
belongs to which player. In contrast, we argue that selectively concealing whose movement
controls which representation can facilitate engaging play experiences. We call this
"innominate movement representation" and explore this opportunity through our game
"i-dentity", where players have to guess who makes everyone's controller light up
based on his/her movements. Our work reveals five dimensions for the design of innominate
movement representation: concealing the association between movement and representation;
number of represented movements; number of players with representations; location
of representation in relation to the body and technical attributes of representation.
We also present five strategies for how innominate representation can be embedded
into a play experience. With our work we hope to expand the range of digital movement
games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2181–2190},
numpages = {10},
keywords = {movement representation, ambiguity, game design, engagement, social play, digital play, entertainment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557163,
author = {Mueller, Florian and Isbister, Katherine},
title = {Movement-Based Game Guidelines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557163},
doi = {10.1145/2556288.2557163},
abstract = {Movement-based digital games are becoming increasingly popular, yet there is limited
comprehensive guidance on how to design these games. We present a set of guidelines
for movement-based game design that has emerged from our research-based game development
practice. These guidelines have been examined and refined by 14 movement-based game
design experts with experience in the academic, independent and commercial game development
domains. We contextualize the guidelines using current findings about movement-based
game and interaction design, taken from both published research papers and game design
venues. Our primary contribution is a body of generative intermediate-level knowledge
in the design research tradition that is readily accessible and actionable for the
design of future movement-based games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2191–2200},
numpages = {10},
keywords = {movement-based games, digital games, play, whole-body interaction, exertion},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556963,
author = {Gerling, Kathrin Maria and Miller, Matthew and Mandryk, Regan L. and Birk, Max Valentin and Smeddinck, Jan David},
title = {Effects of Balancing for Physical Abilities on Player Performance, Experience and Self-Esteem in Exergames},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556963},
doi = {10.1145/2556288.2556963},
abstract = {Game balancing can help players with different skill levels play multiplayer games
together; however, little is known about how the balancing approach affects performance,
experience, and self-esteem'especially when differences in player strength result
from given abilities, rather than learned skill. We explore three balancing approaches
in a dance game and show that the explicit approach commonly used in commercial games
reduces self-esteem and feelings of relatedness in dyads, whereas hidden balancing
improves self-esteem and reduces score differential without affecting game outcome.
We apply our results in a second study with dyads where one player had a mobility
disability and used a wheelchair. By making motion-based games accessible for people
with different physical abilities, and by enabling people with mobility disabilities
to compete on a par with able-bodied peers, we show how to provide empowering experiences
through enjoyable games that have the potential to increase physical activity and
self-esteem.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2201–2210},
numpages = {10},
keywords = {motion-based games, balancing, physical abilities, player experience, exergames},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557272,
author = {Mueller, Florian and Gibbs, Martin R. and Vetere, Frank and Edge, Darren},
title = {Supporting the Creative Game Design Process with Exertion Cards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557272},
doi = {10.1145/2556288.2557272},
abstract = {Advances in sensing technologies have led to research into exertion games that support
physically effortful experiences. Despite the existence of theoretical frameworks
that can be used to analyze such exertion experiences, there are few tools to support
the hands-on practice of exertion game design. To address this, we present a set of
design cards based on the "Exertion Framework", grounded in our experience of creating
exertion games for over a decade. We present results demonstrating the value and utility
of these Exertion Cards based on our studies of their use in three workshops held
over seven sessions with 134 design students and experts. We also articulate lessons
learned from transforming a theoretical framework into a design tool that aims to
support designers in their practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2211–2220},
numpages = {10},
keywords = {workshops, whole-body interaction, game design, exertion interface, design cards, exergame, creative process},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250955,
author = {Nebeling, Michael},
title = {Session Details: Designing and Modeling GUIs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250955},
doi = {10.1145/3250955},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557349,
author = {Meng, Xiaojun and Zhao, Shengdong and Huang, Yongfeng and Zhang, Zhongyuan and Eagan, James and Subramanian, Ramanathan},
title = {WADE: Simplified GUI Add-on Development for Third-Party Software},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557349},
doi = {10.1145/2556288.2557349},
abstract = {We present the WADE Integrated Development Environment (IDE), which simplifies interface
and functionality modification of existing third-party software without access to
source code. WADE clones the Graphical User Interface (GUI) of a host program through
dynamic-link library (DLL) injection, enabling modifications to (1) the GUI in a WYSIWYG
fashion and (2) software functionality. We compare WADE with an alternative state-of-the-art
runtime toolkit overloading approach in a user-study, whose results demonstrate that
WADE significantly simplifies the task of GUI-based add-on development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2221–2230},
numpages = {10},
keywords = {WADE, IDE, wysiwyg, add-on integration, GUI},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556979,
author = {Dixon, Morgan and Laput, Gierad and Fogarty, James},
title = {Pixel-Based Methods for Widget State and Style in a Runtime Implementation of Sliding Widgets},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556979},
doi = {10.1145/2556288.2556979},
abstract = {Pixel-based methods offer unique potential for modifying existing interfaces independent
of their underlying implementation. Prior work has demonstrated a variety of modifications
to existing interfaces, including accessibility enhancements, interface language translation,
testing frameworks, and interaction techniques. But pixel-based methods have also
been limited in their understanding of the interface and therefore the complexity
of modifications they can support. This work examines deeper pixel-level understanding
of widgets and the resulting capabilities of pixel-based runtime enhancements. Specifically,
we present three new sets of methods: methods for pixel-based modeling of widgets
in multiple states, methods for managing the combinatorial complexity that arises
in creating a multitude of runtime enhancements, and methods for styling runtime enhancements
to preserve consistency with the design of an existing interface. We validate our
methods through an implementation of Moscovich et al.'s Sliding Widgets, a novel runtime
enhancement that could not have been implemented with prior pixel-based methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2231–2240},
numpages = {10},
keywords = {pixel-based runtime modification, hybrid touch and mouse interaction, prefab, real-world interfaces, sliding widgets},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556976,
author = {Scarr, Joey and Cockburn, Andy and Gutwin, Carl and Bunt, Andrea and Cechanowicz, Jared E.},
title = {The Usability of CommandMaps in Realistic Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556976},
doi = {10.1145/2556288.2556976},
abstract = {CommandMaps are a promising interface technique that flattens command hierarchies
and exploits human spatial memory to provide rapid access to commands. CommandMaps
have performed favorably in constrained cued-selection studies, but have not yet been
tested in the context of real tasks. In this paper we present two real-world implementations
of CommandMaps: one for Microsoft Word and one for an image editing program called
Pinta. We use these as our experimental platforms in two experiments. In the first,
we show that CommandMaps demonstrate performance and subjective advantages in a realistic
task. In the second, we observe naturalistic use of CommandMaps over the course of
a week, and gather qualitative data from interviews, questionnaires, and conversations.
Our results provide substantial insight into users' reactions to CommandMaps, showing
that they are positively received by users and allowing us to provide concrete recommendations
to designers regarding when and how they should be implemented in real applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2241–2250},
numpages = {10},
keywords = {commandmaps, hierarchies, spatial memory, real tasks},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556972,
author = {Hong, Kyung Wha and St. Amant, Robert},
title = {Novice Use of a Predictive Human Performance Modeling Tool to Produce UI Recommendations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556972},
doi = {10.1145/2556288.2556972},
abstract = {This note describes two studies of the use of a performance modeling tool, CogTool,
for making recommendations to improve a user interface. The first study replicates
findings by Bonnie John [7]: the rates at which novice modelers made correct recommendations
(88.1%) and supported them (68.2%) are close to the values in John's study (91.7%
and 75.1%, respectively). A follow-on study of novice modelers on the same task without
CogTool produced sig-nificantly lower values. CogTool improves the UI design recommendations
made by novices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2251–2254},
numpages = {4},
keywords = {interface design, usability analysis, cogtool},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557288,
author = {Balata, Jan and Cmolik, Ladislav and Mikovec, Zdenek},
title = {On the Selection of 2D Objects Using External Labeling},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557288},
doi = {10.1145/2556288.2557288},
abstract = {We present an external labeling laid over small and/or overlapping 2D objects as an
efficient representation for their selection. The approximation of objects with points
allows us to transform the labeling problem to graph layout problem, which we solve
by means of force-based algorithm. The input parameters allow us to influence the
resulting layout of label boxes (e.g. to adapt their distance for imprecise input
devices). In a study with 15 participants two implementations of our algorithm were
compared against labeling method, where all label boxes share the same offset from
corresponding objects. The results of the study show that implementation using a special
functionality (temporary freezing of the label box position recalculation) was 14%
faster with a comparable accuracy. The subjective evaluation revealed that the implementation
with temporary freezing is perceived as most comfortable, fastest and most accurate.
The implementation without temporary freezing showed much higher error rate and cannot
be recommended.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2255–2258},
numpages = {4},
keywords = {visualization, user study, object selection, external labeling},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250956,
author = {Wolters, Maria},
title = {Session Details: Health and Everyday Life},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250956},
doi = {10.1145/3250956},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557210,
author = {Lee, Matthew L. and Dey, Anind K.},
title = {Real-Time Feedback for Improving Medication Taking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557210},
doi = {10.1145/2556288.2557210},
abstract = {Medication taking is a self-regulatory process that requires individuals to self-monitor
their medication taking behaviors, but this can be difficult because medication taking
is such a mundane, unremarkable behavior. Ubiquitous sensing systems have the potential
to sense everyday behaviors and provide the objective feedback necessary for self-regulation
of medication taking. We describe an unobtrusive sensing system consisting of a sensor-augmented
pillbox and an ambient display that provides near real-time visual feedback about
how well medications are being taken. In contrast to other systems that focus on reminding
before medication taking, our approach uses feedback after medication taking to allow
the individual to develop their own routines through self-regulation. We evaluated
this system in the homes of older adults in a 10-month deployment. Feedback helped
improve the consistency of medication-taking behaviors as well as increased ratings
of self-efficacy. However, the improved performance did not persist after the feedback
display was removed, because individuals had integrated the feedback display into
their routines to support their self-awareness, identify mistakes, guide the timing
of medication taking, and provide a sense of security that they are taking their medications
well. Finally, we reflect on design considerations for feedback systems to support
the process of self-regulation of everyday behaviors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2259–2268},
numpages = {10},
keywords = {behavior change, sensors, ambient display, self-regulation, feedback, self-efficacy, medication adherence},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557210_R50745,
author = {Olagunju, Amos O},
title = {Review ID:R50745 for DOI: 10.1145/2556288.2557210},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557210_R50745}
}

@inproceedings{10.1145/2556288.2557079,
author = {Stawarz, Katarzyna and Cox, Anna L. and Blandford, Ann},
title = {Don't Forget Your Pill! Designing Effective Medication Reminder Apps That Support Users' Daily Routines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557079},
doi = {10.1145/2556288.2557079},
abstract = {Despite the fact that a third of all cases of unintentional medication non-adherence
are caused by simple forgetfulness, the majority of interventions neglect this issue.
Even though patients have access to smartphone applications ("apps") designed to help
them remember medication, neither their quality nor effectiveness has been evaluated
yet. We report the findings of a functionality review of 229 medication reminder apps
and a thematic analysis of their 1,012 user reviews. Our research highlights the gap
between the theory and practice: while the literature shows that many medication regimens
are habitual in nature and the presence of daily routines supports remembering, existing
apps rely on timer-based reminders. To address this disparity, we present design requirements
for building medication reminders that support the routine aspect of medication-taking
and its individual nature, and demonstrate how they could be implemented to move from
passive alerts to a smarter memory and routine assistant.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2269–2278},
numpages = {10},
keywords = {smartphone apps, medication reminders, habits, routines, forgetfulness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557386,
author = {Suh, Hyewon and Porter, John R. and Hiniker, Alexis and Kientz, Julie A.},
title = {@BabySteps: Design and Evaluation of a System for Using Twitter for Tracking Children's Developmental Milestones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557386},
doi = {10.1145/2556288.2557386},
abstract = {The tracking of developmental milestones in young children is an important public
health goal for ensuring early detection and treatment for developmental delay. While
numerous paper-based and web-based solutions are available for tracking milestones,
many busy parents often forget to enter information on a regular basis. To help address
this need, we have developed an interactive system called @BabySteps for allowing
parents who use Twitter to track and respond to tweets about developmental milestones
using a special hashtag syntax. Parent responses are parsed automatically and written
into a central database that can be accessed via the web. We deployed @BabySteps with
14 parents over a 3-week period and found that parents were able to learn how to use
the system to track their children's progress, with some using it to communicate with
other parents. The study helped to identify a number of ways to improve the approach,
including simplifying the hashtag syntax, allowing for private responses via direct
messaging, and improving the social component. We provide a discussion of lessons
learned and suggestions for the design of interactive public health systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2279–2288},
numpages = {10},
keywords = {twitter, social media, microblogging, children, memories, data capture, parents, health, public health},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557334,
author = {Nguyen, Linh Chi and Do, Ellen Yi-Luen and Chia, Audrey and Wang, Yuan and Duh, Henry Been-Lirn},
title = {DoDo Game, a Color Vision Deficiency Screening Test for Young Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557334},
doi = {10.1145/2556288.2557334},
abstract = {This paper presents 'DoDo's Catching Adventure,' a new color vision deficient screening
test for young children. Early detection of color blindness among children is useful
for parents and teachers to better understand children's needs, to overcome difficulties
in learning, and for life and career planning. Unfortunately, current color screening
tests are not designed for young children; most require more advanced verbal or cognitive
skills. DoDo game has taken a new approach by embedding game elements into a color
vision screening test. A user study conducted at Singapore National Eye Centre on
twenty-eight children, identified fourteen as Red-Green deficient subjects as did
by Ishihara screening test, showed that DoDo was adequately effective in identifying
Red-Green color vision deficiency and comparable to two current gold standard colorblind
tests, Ishihara and D15.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2289–2292},
numpages = {4},
keywords = {digital game, children game, color deficiency test},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557065,
author = {Cairns, Paul and Pandab, Pratyush and Power, Christopher},
title = {The Influence of Emotion on Number Entry Errors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557065},
doi = {10.1145/2556288.2557065},
abstract = {Given the proliferation of devices like infusion pumps in hospitals, number entry
and in particular number entry error is an emerging important concern in HCI. There
are clearly design features that could greatly improve accuracy in entering numbers
but the context of the task could also play an important role. In particular, the
emotional state of a person is known to strongly influence their response to a difficult
situation and hence the errors that they make. In this paper, we consider the impact
of the emotional state of the user on the accuracy with which people enter numbers.
Our experiment shows that participants who are in a more positive emotional state
are more accurate. The effect is small but could be very important when considering
the potentially highly-charged emotional contexts where many healthcare devices are
used.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2293–2296},
numpages = {4},
keywords = {number entry, human error, affect, healthcare},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250957,
author = {Oulasvirta, Antti},
title = {Session Details: Text Entry and Evaluation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250957},
doi = {10.1145/3250957},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557414,
author = {Bi, Xiaojun and Ouyang, Tom and Zhai, Shumin},
title = {Both Complete and Correct? Multi-Objective Optimization of Touchscreen Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557414},
doi = {10.1145/2556288.2557414},
abstract = {Correcting erroneous input (i.e., correction) and completing a word based on partial
input (i.e., completion) are two important "smart" capabilities of a modern intelligent
touchscreen keyboard. However little is known whether these two capabilities are conflicting
or compatible with each other in the keyboard parameter tuning. Applying computational
optimization methods, this work explores the optimality issues related to them. The
work demonstrates that it is possible to simultaneously optimize a keyboard algorithm
for both correction and completion. The keyboard simultaneously optimized for both
introduces no compromise to correction and only a slight compromise to completion
when compared to the keyboards exclusively optimized for one objective. Our research
also demonstrates the effectiveness of the proposed optimization method in keyboard
algorithm design, which is based on the Pareto multi-objective optimization and the
Metropolis algorithm. For the development and test datasets used in our experiments,
computational optimization improved the correction accuracy rate by 8.3% and completion
power by 17.7%.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2297–2306},
numpages = {10},
keywords = {correction, optimization, completion, mobile, keyboard algorithm, intelligent user interfaces, text input, smart touch screen keyboard},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557412,
author = {Weir, Daryl and Pohl, Henning and Rogers, Simon and Vertanen, Keith and Kristensson, Per Ola},
title = {Uncertain Text Entry on Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557412},
doi = {10.1145/2556288.2557412},
abstract = {Users often struggle to enter text accurately on touchscreen keyboards. To address
this, we present a flexible decoder for touchscreen text entry that combines probabilistic
touch models with a language model. We investigate two different touch models. The
first touch model is based on a Gaussian Process regression approach and implicitly
models the inherent uncertainty of the touching process. The second touch model allows
users to explicitly control the uncertainty via touch pressure. Using the first model
we show that the character error rate can be reduced by up to 7% over a baseline method,
and by up to 1.3% over a leading commercial keyboard. Using the second model we demonstrate
that providing users with control over input certainty reduces the amount of text
users have to correct manually and increases the text entry rate.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2307–2316},
numpages = {10},
keywords = {keyboard error correction, mobile text entry},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250958,
author = {Kr\"{u}ger, Antonio},
title = {Session Details: Emotions and Mobiles},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250958},
doi = {10.1145/3250958},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557295,
author = {Meschtscherjakov, Alexander and Wilfinger, David and Tscheligi, Manfred},
title = {Mobile Attachment Causes and Consequences for Emotional Bonding with Mobile Phones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557295},
doi = {10.1145/2556288.2557295},
abstract = {This paper addresses the phenomenon of emotional attachments to mobile phones. We
introduce the term "mobile attachment" and define it as a bond between a person's
self and a mobile phone that varies in strength. Based on a critical reflection of
interdisciplinary literature, a conceptual mobile attachment model is developed. Within
this model causes, consequences and influencing factors of mobile attachment are exposed
and elaborated. We argue that mobile attachment emerges when the mobile phone becomes
part of the user's self concept. The link between the user and their mobile phone
may be fostered when it empowers, enriches, or gratifies the user's self. Attachment
causes lead to "design space determinants" that enable user experience designers to
design for mobile attachment. Attachment consequences may be operationalized for user
experience evaluation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2317–2326},
numpages = {10},
keywords = {emotional attachment, user experience, mobile phones},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557366,
author = {Lee, Uichin and Lee, Joonwon and Ko, Minsam and Lee, Changhun and Kim, Yuhwan and Yang, Subin and Yatani, Koji and Gweon, Gahgene and Chung, Kyong-Mee and Song, Junehwa},
title = {Hooked on Smartphones: An Exploratory Study on Smartphone Overuse among College Students},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557366},
doi = {10.1145/2556288.2557366},
abstract = {The negative aspects of smartphone overuse on young adults, such as sleep deprivation
and attention deficits, are being increasingly recognized recently. This emerging
issue motivated us to analyze the usage patterns related to smartphone overuse. We
investigate smartphone usage for 95 college students using surveys, logged data, and
interviews. We first divide the participants into risk and non-risk groups based on
self-reported rating scale for smartphone overuse. We then analyze the usage data
to identify between-group usage differences, which ranged from the overall usage patterns
to app-specific usage patterns. Compared with the non-risk group, our results show
that the risk group has longer usage time per day and different diurnal usage patterns.
Also, the risk group users are more susceptible to push notifications, and tend to
consume more online content. We characterize the overall relationship between usage
features and smartphone overuse using analytic modeling and provide detailed illustrations
of problematic usage behaviors based on interview data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2327–2336},
numpages = {10},
keywords = {smartphone overuse, measurement},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557067,
author = {Schaub, Florian and Seifert, Julian and Honold, Frank and M\"{u}ller, Michael and Rukzio, Enrico and Weber, Michael},
title = {Broken Display = Broken Interface': The Impact of Display Damage on Smartphone Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557067},
doi = {10.1145/2556288.2557067},
abstract = {This paper is the first to assess the impact of touchscreen damage on smartphone interaction.
We gathered a dataset consisting of 95 closeup images of damaged smartphones and extensive
information about a device's usage history, damage severity, and impact on use. 88%
of our participants continued to use their damaged smartphone for at least three months;
32% plan to use it for another year or more, mainly due to high repair and replacement
costs. From the dataset, we identified three categories of damaged smartphone displays.
Reading and text input were most affected. Further interviews (n=11) revealed that
users adapt to damage with diverse coping strategies, closely tailored to specific
interaction issues. In total, we identified 23 different strategies. Based on our
results, we proposed guidelines for interaction design in order to provide a positive
user experience when display damage occurs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2337–2346},
numpages = {10},
keywords = {smartphone, broken display, mobile interaction, user experience, display damage},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250959,
author = {Patil, Sameer},
title = {Session Details: Privacy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250959},
doi = {10.1145/3250959},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557421,
author = {Shklovski, Irina and Mainwaring, Scott D. and Sk\'{u}lad\'{o}ttir, Halla Hrund and Borgthorsson, H\"{o}skuldur},
title = {Leakiness and Creepiness in App Space: Perceptions of Privacy and Mobile App Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557421},
doi = {10.1145/2556288.2557421},
abstract = {Mobile devices are playing an increasingly intimate role in everyday life. However,
users can be surprised when informed of the data collection and distribution activities
of apps they install. We report on two studies of smartphone users in western European
countries, in which users were confronted with app behaviors and their reactions assessed.
Users felt their personal space had been violated in "creepy" ways. Using Altman's
notions of personal space and territoriality, and Nissenbaum's theory of contextual
integrity, we account for these emotional reactions and suggest that they point to
important underlying issues, even when users continue using apps they find creepy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2347–2356},
numpages = {10},
keywords = {mobile devices, bodily integrity, creepiness, data privacy, learned helplessness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557287,
author = {Davies, Nigel and Langheinrich, Marc and Clinch, Sarah and Elhart, Ivan and Friday, Adrian and Kubitza, Thomas and Surajbali, Bholanathsingh},
title = {Personalisation and Privacy in Future Pervasive Display Networks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557287},
doi = {10.1145/2556288.2557287},
abstract = {There is increasing interest in using digital signage to deliver highly personalised
content. However, display personalization presents a number of architectural design
challenges in particular, how best to provide personalisation without unduly compromising
viewers' privacy. While previous research has focused on understanding specific elements
of the overall vision, our work presents details of the first significant attempt
at a system that integrates future pervasive display networks and mobile devices to
support display personalisation. We describe a series of usage models and design goals
for display personalisation and then present Tacita, a system that supports these
models and goals. Our architecture includes mobile, display and cloud-based elements
and provides comprehensive personalisation features while preventing the creation
of user profiles within the display infrastructure, thus helping to preserve users'
privacy. An initial evaluation of our prototype implementation of the architecture
is also included and demonstrates the viability of the Tacita approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2357–2366},
numpages = {10},
keywords = {personalisation, digital signage, privacy, architecture},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557413,
author = {Wang, Yang and Leon, Pedro Giovanni and Acquisti, Alessandro and Cranor, Lorrie Faith and Forget, Alain and Sadeh, Norman},
title = {A Field Trial of Privacy Nudges for Facebook},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557413},
doi = {10.1145/2556288.2557413},
abstract = {Anecdotal evidence and scholarly research have shown that Internet users may regret
some of their online disclosures. To help individuals avoid such regrets, we designed
two modifications to the Facebook web interface that nudge users to consider the content
and audience of their online disclosures more carefully. We implemented and evaluated
these two nudges in a 6-week field trial with 28 Facebook users. We analyzed participants'
interactions with the nudges, the content of their posts, and opinions collected through
surveys. We found that reminders about the audience of posts can prevent unintended
disclosures without major burden; however, introducing a time delay before publishing
users' posts can be perceived as both beneficial and annoying. On balance, some participants
found the nudges helpful while others found them unnecessary or overly intrusive.
We discuss implications and challenges for designing and evaluating systems to assist
users with online disclosures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2367–2376},
numpages = {10},
keywords = {behavioral bias, regret, social media, online disclosure, soft-paternalism, privacy, facebook, nudge},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557352,
author = {Denning, Tamara and Dehlawi, Zakariya and Kohno, Tadayoshi},
title = {In Situ with Bystanders of Augmented Reality Glasses: Perspectives on Recording and Privacy-Mediating Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557352},
doi = {10.1145/2556288.2557352},
abstract = {Augmented reality (AR) devices are poised to enter the market. It is unclear how the
properties of these devices will affect individuals' privacy. In this study, we investigate
the privacy perspectives of individuals when they are bystanders around AR devices.
We conducted 12 field sessions in caf\'{e}s and interviewed 31 bystanders regarding their
reactions to a co-located AR device. Participants were predominantly split between
having indifferent and negative reactions to the device. Participants who expressed
that AR devices change the bystander experience attributed this difference to subtleness,
ease of recording, and the technology's lack of prevalence. Additionally, participants
surfaced a variety of factors that make recording more or less acceptable, including
what they are doing when the recording is being taken. Participants expressed interest
in being asked permission before being recorded and in recording-blocking devices.
We use the interview results to guide an exploration of design directions for privacy-mediating
technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2377–2386},
numpages = {10},
keywords = {augmented reality, privacy, surveillance, wearable camera},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250960,
author = {Comber, Rob},
title = {Session Details: Issues That Matter},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250960},
doi = {10.1145/3250960},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557022,
author = {Moran, Stuart and Pantidi, Nadia and Rodden, Tom and Chamberlain, Alan and Griffiths, Chloe and Zilli, Davide and Merrett, Geoff and Rogers, Alex},
title = {Listening to the Forest and Its Curators: Lessons Learnt from a Bioacoustic Smartphone Application Deployment},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557022},
doi = {10.1145/2556288.2557022},
abstract = {Our natural environment is complex and sensitive, and is home to a number of species
on the verge of extinction. Surveying is one approach to their preservation, and can
be supported by technology. This paper presents the deployment of a smartphone-based
citizen science biodiversity application. Our findings from interviews with members
of the biodiversity community revealed a tension between the technology and their
established working practices. From our experience, we present a series of general
guidelines for those designing citizen science apps.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2387–2396},
numpages = {10},
keywords = {participatory sensing, citizen science, mobile, tradition, tension, biodiversity, bioacoustics, community practices},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557359,
author = {DiSalvo, Carl and Lukens, Jonathan and Lodato, Thomas and Jenkins, Tom and Kim, Tanyoung},
title = {Making Public Things: How HCI Design Can Express Matters of Concern},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557359},
doi = {10.1145/2556288.2557359},
abstract = {Science studies scholar Bruno Latour suggests that contemporary democracy is shifting
from "matters of fact"to "matters of concern": contentious conditions entwined with
everyday life. What is the role of human-computer interaction (HCI) design in this
shift' In this paper we draw from five design projects to explore how design can express
matters of concern by communicating the factors and consequences of issues. In the
process, we consider the role of design in contributing to the formation of publics
and discuss an emerging orientation to publics in HCI design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2397–2406},
numpages = {10},
keywords = {matters of concern, design, public design, publics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557193,
author = {Pater, Jessica Annette and Nadji, Yacin and Mynatt, Elizabeth D. and Bruckman, Amy S.},
title = {Just Awful Enough: The Functional Dysfunction of the Something Awful Forums},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557193},
doi = {10.1145/2556288.2557193},
abstract = {The Something Awful Forums (SAF) is an online community comprised of a loosely connected
federation of forums, united in a distinctive brand of humor with a focus on the quality
of member contributions. In this case study we find that the site has sustained success
while deviating from common conventions and norms of online communities. Humor and
the quality of content contributed by SAF members foster practices that seem counterintuitive
to the development of a stable and thriving community. In this case study we show
how design decisions are contextual and inter-dependent and together these heuristics
create a different kind of online third place that challenges common practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2407–2410},
numpages = {4},
keywords = {third place, design, online community, case study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250961,
author = {Kelley, Patrick Gage},
title = {Session Details: Understanding and Using Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250961},
doi = {10.1145/3250961},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557273,
author = {Linder, Rhema and Snodgrass, Clair and Kerne, Andruid},
title = {Everyday Ideation: All of My Ideas Are on Pinterest},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557273},
doi = {10.1145/2556288.2557273},
abstract = {We develop new understanding of how people engage in digital curation. We interview
twenty users of Pinterest, a social curation platform. We find that through collecting,
organizing, and sharing image bookmarks, users engage in processes of everyday ideation.
That is, they use digital found objects as creative resources to develop ideas for
shaping their lives. Curators assemble information into new contexts, forming and
sharing ideas with practical and emotional value. We investigate cognitive and social
aspects of creativity that affect the digital curation practices of everyday ideation.
We derive implications for the design of curation environments that support information-based
ideation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2411–2420},
numpages = {10},
keywords = {pinterest, creativity, everyday design, information-based ideation, curation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557363,
author = {Wisniewski, Pamela and Xu, Heng and Chen, Yunan},
title = {Understanding User Adaptation Strategies for the Launching of Facebook Timeline},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557363},
doi = {10.1145/2556288.2557363},
abstract = {This paper applies coping theory to understand user adaptation strategies to major
interface changes on Social Networking Sites (SNSs). Specifically, we qualitatively
examine 1,149 user comments posted to the Facebook's official Timeline blog in order
to get a large and unobtrusive sample of real Facebook users' perceptions about the
launch of Timeline. Our data suggests a high level of stress associated with the transition
to the new interface introduced by Timeline. We also found evidence which suggests
that increasing users' perceptions of control over major interface changes may help
facilitate user adaptation to these changes. This study offers valuable insights to
SNSs for mitigating user stress and facilitating successful adaptation during major
interface changes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2421–2430},
numpages = {10},
keywords = {user adaptation, coping, privacy, facebook timeline, stress, change},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557291,
author = {Zhao, Xuan and Lindley, Si\^{a}n E.},
title = {Curation through Use: Understanding the Personal Value of Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557291},
doi = {10.1145/2556288.2557291},
abstract = {Content generation on social network sites has been considered mainly from the perspective
of individuals interacting with social network contacts. Yet research has also pointed
to the potential for social media to become a meaningful personal archive over time.
The aim of this paper is to consider how social media, over time and across sites,
forms part of the wider digital archiving space for individuals. Our findings, from
a qualitative study of 14 social media users, highlight how although some sites are
more associated with 'keepable' social media than others, even those are not seen
as archives in the usual sense of the word. We show how this perception is bound up
with five contradictions, which center on social media as curated, as a reliable repository
of meaningful content, as readily encountered and as having the potential to present
content as a compelling narrative. We conclude by highlighting opportunities for design
relating to curation through use and what this implies for personal digital archives,
which are known to present difficulties in terms of curation and re-finding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2431–2440},
numpages = {10},
keywords = {personal information management, exhibition, archive},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557070,
author = {Schirra, Steven and Sun, Huan and Bentley, Frank},
title = {Together Alone: Motivations for Live-Tweeting a Television Series},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557070},
doi = {10.1145/2556288.2557070},
abstract = {In this paper, we explore motivations for live-tweeting across a season of a television
show. Using the third season of Downton Abbey as a case study, we followed 2,234 live-tweeters
from the show's premiere episode to its finale, finding that nearly a third of users
returned each week to tweet. Semi-structured interviews with 11 diverse live-tweeters
revealed that the decision to live-tweet is dependent upon a variety of personal considerations
and social conventions forming around this emerging TV viewing practice. This includes
the desire to feel connected to a larger community that is interested in the show.
Participants actively sought to protect the user experience of others by following
good live-tweeting "etiquette", including limiting their number of posts and censoring
content that might spoil the show for others. Over time, live-tweeting helped users
build and maintain a network of fellow Downton Abbey viewers with shared interests.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2441–2450},
numpages = {10},
keywords = {second screen, live-tweeting, twitter, user research, annotation, social television},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250962,
author = {Furniss, Dominic},
title = {Session Details: Working Together},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250962},
doi = {10.1145/3250962},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557305,
author = {Christensen, Lars Rune and Bjorn, Pernille},
title = {Documentscape: Intertextuality, Sequentiality, &amp; Autonomy at Work},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557305},
doi = {10.1145/2556288.2557305},
abstract = {On the basis of an ethnographic field study, this article introduces the concept of
documentscape to the analysis of document-centric work practices. The concept of documentscape
refers to the entire ensemble of documents in their mutual intertextual interlocking.
Providing empirical data from a global software development case, we show how hierarchical
structures and sequentiality across the interlocked documents are critical to how
actors make sense of the work of others and what to do next in a geographically distributed
setting. Furthermore, we found that while each document is created as part of a quasi-sequential
order, this characteristic does not make the document, as a single entity, into a
stable object. Instead, we found that the documents were malleable and dynamic while
suspended in intertextual structures. Our concept of documentscape points to how the
hierarchical structure, sequentiality, and authorless nature of documents serve as
a constitutive platform for the development of iterative and emergent work practices,
making it possible for highly distributed actors to collaborate with limited communication,
as the documentscape serves as a vehicle of coordination.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2451–2460},
numpages = {10},
keywords = {global software development, documentscape, "documents, global interaction"},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557042,
author = {Massey, Charlotte and Lennig, Thomas and Whittaker, Steve},
title = {Cloudy Forecast: An Exploration of the Factors Underlying Shared Repository Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557042},
doi = {10.1145/2556288.2557042},
abstract = {Many teams are now adopting shared repositories for their work. Such adoption is paradoxical,
however, as past research has repeatedly shown major co-organizational barriers; teams
cannot agree a common organizational scheme, making it difficult to retrieve information
organized by others. Another barrier is email competition; email provides a reliable
alternative for distributing files that are then personally organized. To address
this paradox, we explored how 27 participants actively using shared repositories overcome
these barriers in a qualitative study. We found teams addressed co-organization using
4 strategies. First they create ContentMaps that provide explicit structure to organize
shared information. Participants also co-organize using implicit strategies based
on task structure, expertise, and tool affordances. Greater shared repository use
also leads to a changed role for email. Versioning problems mean email is not used
for distributing attachments, instead for task management. We present technical implications
suggesting how new tools might be better integrated with email facilitating these
continued email uses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2461–2470},
numpages = {10},
keywords = {email competition, co-organization, contentmaps, versioning, shared repositories},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557072,
author = {Forte, Andrea and Andalibi, Nazanin and Park, Thomas and Willever-Farr, Heather},
title = {Designing Information Savvy Societies: An Introduction to Assessability},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557072},
doi = {10.1145/2556288.2557072},
abstract = {This paper provides first steps toward an empirically grounded design vocabulary for
assessable design as an HCI response to the global need for better information literacy
skills. We present a framework for synthesizing literatures called the Interdisciplinary
Literacy Framework and use it to highlight gaps in our understanding of information
literacy that HCI as a field is particularly well suited to fill. We report on two
studies that lay a foundation for developing guidelines for assessable information
system design. The first is a study of Wikipedians', librarians', and laypersons'
information assessment practices from which we derive two important features of assessable
designs: information provenance and stewardship. The second is an experimental study
in which we operationalize these concepts in designs and test them using Amazon Mechanical
Turk (MTurk).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2471–2480},
numpages = {10},
keywords = {credibility, information literacy, wikipedia, assessability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250963,
author = {Chevalier, Fanny},
title = {Session Details: Programming and Development Tools},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250963},
doi = {10.1145/3250963},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557409,
author = {Lieber, Tom and Brandt, Joel R. and Miller, Rob C.},
title = {Addressing Misconceptions about Code with Always-on Programming Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557409},
doi = {10.1145/2556288.2557409},
abstract = {We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript
code editor. By displaying real-time information about how code actually behaves during
execution, Theseus proactively addresses misconceptions by drawing attention to similarities
and differences between the programmer's idea of what code does and what it actually
does. To understand how programmers would respond to this kind of an always-on visualization,
we ran a lab study with graduate students, and interviewed 9 professional programmers
who were asked to use Theseus in their day-to-day work. We found that users quickly
adopted strategies that are unique to always-on, real-time visualizations, and used
the additional information to guide their navigation through their code.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2481–2490},
numpages = {10},
keywords = {debugging, programming, code understanding},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556998,
author = {Fast, Ethan and Steffee, Daniel and Wang, Lucy and Brandt, Joel R. and Bernstein, Michael S.},
title = {Emergent, Crowd-Scale Programming Practice in the IDE},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556998},
doi = {10.1145/2556288.2556998},
abstract = {While emergent behaviors are uncodified across many domains such as programming and
writing, interfaces need explicit rules to support users. We hypothesize that by codifying
emergent programming behavior, software engineering interfaces can support a far broader
set of developer needs. To explore this idea, we built Codex, a knowledge base that
records common practice for the Ruby programming language by indexing over three million
lines of popular code. Codex enables new data-driven interfaces for programming systems:
statistical linting, identifying code that is unlikely to occur in practice and may
constitute a bug; pattern annotation, automatically discovering common programming
idioms and annotating them with metadata using expert crowdsourcing; and library generation,
constructing a utility package that encapsulates and reflects emergent software practice.
We evaluate these applications to find Codex captures a broad swatch of programming
practice, statistical linting detects problematic code snippets, and pattern annotation
discovers nontrivial idioms such as basic HTTP authentication and database migration
templates. Our work suggests that operationalizing practice-driven knowledge in structured
domains such as programming can enable a new class of user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2491–2500},
numpages = {10},
keywords = {programming tools, data mining},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557350,
author = {Atachiants, Roman and Gregg, David and Jarvis, Kim and Doherty, Gavin},
title = {Design Considerations for Parallel Performance Tools},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557350},
doi = {10.1145/2556288.2557350},
abstract = {In recent years there has been a shift in microprocessor manufacture from building
single-core processors towards providing multiple cores on the same chip. This shift
has meant that a much wider population of developers are faced with the task of developing
parallel software: a difficult, time consuming and expensive process. With the aim
of identifying issues, emerging practices and design opportunities for support, we
present in this paper a qualitative study in which we interviewed a range of software
developers, in both industry and academia. We then perform a systematic analysis of
the data and identify several cross-cutting themes. These analysis themes include
the practical relevance of the probe effect, the significance of orchestration models
in development and the mismatch between currently available tools and developers'
needs. We also identify an important characteristic of parallel programming, where
the process of optimisation goes hand in hand with the process of debugging, as opposed
to clearer distinctions which may be made in traditional programming. We conclude
with reflection on how the study can inform the design of software tools to support
developers in the endeavour of parallel programming.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2501–2510},
numpages = {10},
keywords = {parallel programing, many-core, qualitative study, multi-core, visualisation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557073,
author = {Henley, Austin Z. and Fleming, Scott D.},
title = {The Patchworks Code Editor: Toward Faster Navigation with Less Code Arranging and Fewer Navigation Mistakes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557073},
doi = {10.1145/2556288.2557073},
abstract = {Increasingly, people are faced with navigating large information spaces, and making
such navigation efficient is of paramount concern. In this paper, we focus on the
problems programmers face in navigating large code bases, and propose a novel code
editor, Patchworks, that addresses the problems. In particular, Patchworks leverages
two new interface idioms - the patch grid and the ribbon - to help programmers navigate
more quickly, make fewer navigation errors, and spend less time arranging their code.
To validate Patchworks, we conducted a user study that compared Patchworks to two
existing code editors: the traditional file-based editor, Eclipse, and the newer canvas-based
editor, Code Bubbles. Our results showed (1) that programmers using Patchworks were
able to navigate significantly faster than with Eclipse (and comparably with Code
Bubbles), (2) that programmers using Patchworks made significantly fewer navigation
errors than with Code Bubbles or Eclipse, and (3) that programmers using Patchworks
spent significantly less time arranging their code than with Code Bubbles (and comparably
with Eclipse).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2511–2520},
numpages = {10},
keywords = {user study, code editor, integrated development environment (ide), navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250964,
author = {Zhou, Xiaomu},
title = {Session Details: Interactive Technologies for Rehabilitation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250964},
doi = {10.1145/3250964},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557353,
author = {Ayoade, Mobolaji and Baillie, Lynne},
title = {A Novel Knee Rehabilitation System for the Home},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557353},
doi = {10.1145/2556288.2557353},
abstract = {In this paper, we describe the design and evaluation of an interactive home-based
rehabilitation visualisation system used by a wide variety of ages (users in our studies
were aged from 47-89) to undertake rehabilitation in the home following knee replacement
surgery. We present the rehabilitation visualization system and the results of a randomized
controlled study in which we investigated the usability and feasibility of the system
in the home. We found that our users were able to use the system successfully for
their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared
to the current rehabilitation care. Finally we highlight the lessons learned which
will benefit prospective designers of home rehabilitation technology in ensuring successful
home evaluations in clinical rehabilitation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2521–2530},
numpages = {10},
keywords = {home knee rehabilitation, usability, inertial sensors, visualizations, user design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557278,
author = {Mazilu, Sinziana and Blanke, Ulf and Hardegger, Michael and Tr\"{o}ster, Gerhard and Gazit, Eran and Hausdorff, Jeffrey M.},
title = {GaitAssist: A Daily-Life Support and Training System for Parkinson's Disease Patients with Freezing of Gait},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557278},
doi = {10.1145/2556288.2557278},
abstract = {Patients with Parkinson's disease often experience freezing of gait, which bears a
high risk of falling, a prevalent cause for morbidity and mortality. In this work
we present GaitAssist, a wearable system for freezing of gait support in daily life.
The system provides real-time auditory cueing after the onset of freezing episodes.
Furthermore, GaitAssist implements training exercises to learn how to handle freezing
situations. GaitAssist is the result of a design process where we considered the input
of engineers, clinicians and 18 Parkinson's disease patients, in order to find an
optimal trade-off between system wearability and performance. We tested the final
system in a user study with 5 additional patients. They reported a reduction in the
freezing of gait duration as a result of the auditory stimulation provided, and that
they feel the system enhanced their confidence during walking.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2531–2540},
numpages = {10},
keywords = {wearable support, freezing of gait, on-body sensors, gait impairment, user-centered},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557416,
author = {Huang, Kevin and Sparto, Patrick J. and Kiesler, Sara and Smailagic, Asim and Mankoff, Jennifer and Siewiorek, Dan},
title = {A Technology Probe of Wearable In-Home Computer-Assisted Physical Therapy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557416},
doi = {10.1145/2556288.2557416},
abstract = {Physical therapists could make better treatment decisions if they had accurate patient
home exercise data but today this information is only available from patient self-report.
A more accurate source of data could be gained from wearable computing designed for
physical therapy exercise support. Existing systems have been tested in the lab but
we have little information about issues they may face in home settings. We designed
a technology probe, SenseCap, and deployed it for seven days in ten physical therapy
patients' homes. SenseCap is a wearable physical therapy support system that gathers
patient exercise compliance and performance data and summarizes the data in charts
on an iPad Dashboard for physical therapists to view when patients return to the clinic.
In this paper, we present the results of our deployment, show in-home patient exercise
data gathered by the probe, and make design recommendations based on patient and physical
therapist responses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2541–2550},
numpages = {10},
keywords = {mobile, exercise, ipod, ubiquitous computing, wearable, technology probe, quantifying, physical therapy, rehabilitation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557092,
author = {McNaney, Roisin and Vines, John and Roggen, Daniel and Balaam, Madeline and Zhang, Pengfei and Poliakov, Ivan and Olivier, Patrick},
title = {Exploring the Acceptability of Google Glass as an Everyday Assistive Device for People with Parkinson's},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557092},
doi = {10.1145/2556288.2557092},
abstract = {We describe a qualitative study investigating the acceptability of the Google Glass
eyewear computer to people with Parkinson's disease (PD). We held a workshop with
5 PD patients and 2 carers exploring perceptions of Glass. This was followed by 5-day
field trials of Glass with 4 PD patients, where participants wore the device during
everyday activities at home and in public. We report generally positive responses
to Glass as a device to instil confidence and safety for this potentially vulnerable
group. We also raise concerns related to the potential for Glass to reaffirm dependency
on others and stigmatise wearers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2551–2554},
numpages = {4},
keywords = {parkinson's disease, field trial, qualitative, google glass},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556981,
author = {Zhang, Qiao and Gollakota, Shyamnath and Taskar, Ben and Rao, Raj P.N.},
title = {Non-Intrusive Tongue Machine Interface},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556981},
doi = {10.1145/2556288.2556981},
abstract = {There has been recent interest in designing systems that use the tongue as an input
interface. Prior work however either require surgical procedures or in-mouth sensor
placements. In this paper, we introduce TongueSee, a non-intrusive tongue machine
interface that can recognize a rich set of tongue gestures using electromyography
(EMG) signals from the surface of the skin. We demonstrate the feasibility and robustness
of TongueSee with experimental studies to classify six tongue gestures across eight
participants. TongueSee achieves a classification accuracy of 94.17% and a false positive
probability of 0.000358 per second using three-protrusion preamble design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2555–2558},
numpages = {4},
keywords = {electromyography (emg), tongue gesture interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250965,
author = {Karnik, Abhijit},
title = {Session Details: Shape-Changing Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250965},
doi = {10.1145/3250965},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557360,
author = {Gr\"{o}nvall, Erik and Kinch, Sofie and Petersen, Marianne Graves and Rasmussen, Majken K.},
title = {Causing Commotion with a Shape-Changing Bench: Experiencing Shape-Changing Interfaces in Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557360},
doi = {10.1145/2556288.2557360},
abstract = {In this paper we describe results from testing coMotion, a shape-changing bench, in
three different contexts: a concert hall foyer, an airport departure hall and a shopping
mall. We have gathered insights from more than 120 people, with regard to how users
experience and make sense of the bench's shape changing capability. The paper applies
McCarthy and Wright's six different sense making processes (anticipating, connecting,
interpreting, reflecting, appropriating and recounting) as an instrument to analyse
people's experience with shape-changing furniture in the wild. The paper also introduces
exploring as a seventh sense making process. Based on this analysis, the paper points
to three relevant aspects when designing shape-changing artefacts for the wild, namely:
1) Affordance of shape-changing interfaces, 2) Transitions between background and
foreground and 3) Interpreting physically dynamic objects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2559–2568},
numpages = {10},
keywords = {interactive furniture, user experience, shape-changing interface, design, sense-making, in situ},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557340,
author = {Ramakers, Raf and Sch\"{o}ning, Johannes and Luyten, Kris},
title = {Paddle: Highly Deformable Mobile Devices with Physical Controls},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557340},
doi = {10.1145/2556288.2557340},
abstract = {We present the concept of highly deformable mobile devices that can be transformed
into various special-purpose controls in order to bring physical controls to mobile
devices. Physical controls have the advantage of exploiting people's innate abilities
for manipulating physical objects in the real world. We designed and implemented a
prototype, called Paddle, to demonstrate our concept. Additionally, we explore the
interaction techniques enabled by this concept and conduct an in-depth study to evaluate
our transformable physical controls. Our findings show that these physical controls
provide several benefits over traditional touch interaction techniques commonly used
on mobile devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2569–2578},
numpages = {10},
keywords = {tangible interfaces, mobile devices, deformable interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557018,
author = {Pedersen, Esben W. and Subramanian, Sriram and Hornb\ae{}k, Kasper},
title = {Is My Phone Alive? A Large-Scale Study of Shape Change in Handheld Devices Using Videos},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557018},
doi = {10.1145/2556288.2557018},
abstract = {Shape-changing handheld devices are emerging as research prototypes, but it is unclear
how users perceive them and which experiences they engender. The little data we have
on user experience is from single prototypes, only covering a small part of the possibilities
in shape change. We produce 51 videos of a shape-changing handheld device by systematically
varying seven parameters of shape change. In a crowd-sourced study, 187 participants
watched the videos and described their experiences using rating scales and free text.
We find significant and large differences among parameters of shape change. Shapes
that have previously been used for notifications were rated the least urgent; the
degree of shape change was found to impact experience more than type of shape change.
The experience of shape change was surprisingly complex: hedonic quality were inversely
related to urgency, and some shapes were perceived as ugly, yet useful. We discuss
how to advance models of shape change and improve research on the experience of shape
change.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2579–2588},
numpages = {10},
keywords = {actuated interfaces, shape-changing interfaces, organic user interfaces, shape displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557164,
author = {Dimitriadis, Panteleimon and Alexander, Jason},
title = {Evaluating the Effectiveness of Physical Shape-Change for in-Pocket Mobile Device Notifications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557164},
doi = {10.1145/2556288.2557164},
abstract = {Audio and vibrotactile output are the standard mechanisms mobile devices use to attract
their owner's attention. Yet in busy and noisy environments, or when the user is physically
active, these channels sometimes fail. Recent work has explored the use of physical
shape-change as an additional method for conveying notifications when the device is
in-hand or viewable. However, we do not yet understand the effectiveness of physical
shape-change as a method for communicating in-pocket notifications. This paper presents
three robustly implemented, mobile-device sized shape-changing devices, and two user
studies to evaluate their effectiveness at conveying notifications. The studies reveal
that (1) different types and configurations of shape-change convey different levels
of urgency and; (2) fast pulsing shape-changing notifications are missed less often
and recognised more quickly than the standard slower vibration pulse rates of a mobile
device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2589–2592},
numpages = {4},
keywords = {notifications, mobile devices, shape-change},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557006,
author = {Roudaut, Anne and Reed, Rebecca and Hao, Tianbo and Subramanian, Sriram},
title = {Changibles: Analyzing and Designing Shape Changing Constructive Assembly},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557006},
doi = {10.1145/2556288.2557006},
abstract = {Advances in shape changing assemblies have been made in reconfiguration algorithms,
hardware designs and interaction techniques. However no tools exist for guiding designers
in building those modular devices and especially for choosing the shape of the units.
The task becomes even more complex when the units themselves can change their shapes
to animate the entire assembly. In this paper, we contribute with the first analysis
tool which helps the designer to both choose the right subset of forms for the units
and to create an assembly with maximum accuracy from the set of given objects. We
introduce the concept of Changibles that are interactive wireless units that can reshape
themselves and be attached together to create an animated assembly. We present a use
case to demonstrate the use of our tool, with an instantiation of six Changibles that
are used to construct a pulsing heart assembly.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2593–2596},
numpages = {4},
keywords = {actuated display, constructive assembly, shape changing object, modular robot.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250966,
author = {Wigdor, Daniel},
title = {Session Details: Touch Input},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250966},
doi = {10.1145/3250966},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557234,
author = {Heo, Seongkook and Gu, Jiseong and Lee, Geehyuk},
title = {Expanding Touch Input Vocabulary by Using Consecutive Distant Taps},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557234},
doi = {10.1145/2556288.2557234},
abstract = {In recent years, touch screens have emerged and matured as the main input interface
for mobile and tablet computers calling for extended touch input possibilities. In
this paper, we explore the use of consecutive distant taps to expand the touch screen
input vocabulary. We analyzed time intervals and distances between consecutive taps
during common applications on a tablet and verified that consecutive distant taps
can be used conflict-free with existing touch gestures. We designed the two interaction
techniques Ta-tap and Ta-Ta-tap that utilize consecutive distant taps. Ta-tap uses
two consecutive distant taps to invoke alternative touch operations for multi-touch
emulation, whereas Ta-Ta-tap uses a series of consecutive distant taps to define a
spatial gesture. We verified the feasibility of both interaction techniques through
a series of experiments and a user study. The high recognition rate of Ta-tap and
Ta-Ta-tap gestures, the few conflicts with existing gestures, and the positive feedback
from the participants assert the potential of consecutive distant taps as a new design
space to enrich touch screen interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2597–2606},
numpages = {10},
keywords = {ta-tap, command shortcut, consecutive distant taps, touch screen, ta-ta-tap},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557096,
author = {Au, Oscar Kin-Chung and Su, Xiaojun and Lau, Rynson W.H.},
title = {LinearDragger: A Linear Selector for One-Finger Target Acquisition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557096},
doi = {10.1145/2556288.2557096},
abstract = {Touch input is increasingly popular nowadays, especially for mobile devices such as
smartphones and tablet computers. However, the human finger has considerably large
fingertip size and finger input is imprecise. As such, acquiring small targets on
a touch screen is still a challenging task. In this paper, we present the LinearDragger,
a new and integrated one-finger target acquisition technique for small and clustered
targets. The proposed method has three advantages. First, it allows users to select
targets in dense clustered groups easily with a single touch-drag-release operation.
Second, it maps the 2D selection problem into a more precise 1D selection problem,
which is independent of the target distribution. Third, it avoids finger occlusion
and does not create visual distraction. As a result, it is particularly suitable for
applications with dense targets and rich visual elements. Results of our controlled
experiments show that when selecting small targets, LinearDragger takes about 70%
and 30% less selection time than target acquisition without using any techniques and
with the state-of-the-art target acquisition technique that involves a single touch
operation, respectively, while maintaining a reasonable error rate.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2607–2616},
numpages = {10},
keywords = {dense target selection, target acquisition, touch input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557136,
author = {Gutwin, Carl and Cockburn, Andy and Scarr, Joey and Malacria, Sylvain and Olson, Scott C.},
title = {Faster Command Selection on Tablets with FastTap},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557136},
doi = {10.1145/2556288.2557136},
abstract = {Touch-based tablet UIs provide few shortcut mechanisms for rapid command selection;
as a result, command selection on tablets often requires slow traversal of menus.
We developed a new selection technique for multi-touch tablets, called FastTap, that
uses thumb-and-finger touches to show and choose from a spatially-stable grid-based
overlay interface. FastTap allows novices to view and inspect the full interface,
but once item locations are known, FastTap allows people to select commands with a
single quick thumb-and-finger tap. The interface helps users develop expertise, since
the motor actions carried out as a novice rehearse the expert behavior. A controlled
study showed that FastTap was significantly faster (by 33% per selection overall)
than marking menus, both for novices and experts, and without reduction in accuracy
or subjective preference. Our work introduces a new and efficient selection mechanism
that supports rapid command execution on touch tablets, for both novices and experts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2617–2626},
numpages = {10},
keywords = {tablet uis, expertise, command selection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557397,
author = {Luo, Yuexing and Vogel, Daniel},
title = {Crossing-Based Selection with Direct Touch Input},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557397},
doi = {10.1145/2556288.2557397},
abstract = {Fundamental performance results for crossing-based selec-tion tasks with direct touch
input are presented. A close adaptation of Accot and Zhai's indirect stylus crossing
ex-periment reveals similar trends for direct touch input: touch crossing task time
is faster or equivalent to touch pointing; continuous selection of large orthogonal
crossing targets is most effective; and continuous selection of small collinear targets
is least effective. Unlike indirect stylus and mouse crossing, not every kind of direct
touch pointing perfor-mance is modeled accurately with standard Fitts' law. Instead,
Fitts' law, used previously for touch pointing with small targets, is used to more
accurately model discrete touch crossing with a directionally constrained target.
In addition, visual touch feedback is shown to have a strong effect on absolute accuracy.
Our work empirically validates touch crossing as a practical and efficient selection
technique, and motivates the exploration of novel forms of expressive multi-touch
crossing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2627–2636},
numpages = {10},
keywords = {crossing, touch input, target selection, goal crossing, pen input, multi-touch, ffitts, pointing, fitts, stylus input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250967,
author = {De Luca, Alexander},
title = {Session Details: Risks and Security},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250967},
doi = {10.1145/3250967},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557322,
author = {Bursztein, Elie and Moscicki, Angelique and Fabry, Celine and Bethard, Steven and Mitchell, John C. and Jurafsky, Dan},
title = {Easy Does It: More Usable CAPTCHAs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557322},
doi = {10.1145/2556288.2557322},
abstract = {Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer
algorithms masquerading as people. While CAPTCHAs are generally effective at stopping
abuse, they might impair website usability if they are not properly designed. In this
paper we describe how we designed two new CAPTCHA schemes for Google that focus on
maximizing usability. We began by running an evaluation on Amazon Mechanical Turk
with over 27,000 respondents to test the usability of different feature combinations.
Then we studied user preferences using Google's consumer survey infrastructure. Finally,
drawing on the insights gleaned during those studies, we tested our new captcha schemes
first on Mechanical Turk and then on a fraction of production traffic. The resulting
scheme is now an integral part of our production system and is served to millions
of users. Our scheme achieved a 95.3% human accuracy, a 6.7.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2637–2646},
numpages = {10},
keywords = {CAPTCHA, quantitative usability testing and evaluation, empirical methods, user studies, security, world wide web},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556978,
author = {Harbach, Marian and Hettig, Markus and Weber, Susanne and Smith, Matthew},
title = {Using Personal Examples to Improve Risk Communication for Security &amp; Privacy Decisions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556978},
doi = {10.1145/2556288.2556978},
abstract = {IT security systems often attempt to support users in taking a decision by communicating
associated risks. However, a lack of efficacy as well as problems with habituation
in such systems are well known issues. In this paper, we propose to leverage the rich
set of personal data available on smartphones to communicate risks using personalized
examples. Examples of private information that may be at risk can draw the users'
attention to relevant information for a decision and also improve their response.
We present two experiments that validate this approach in the context of Android app
permissions. Private information that becomes accessible given certain permissions
is displayed when a user wants to install an app, demonstrating the consequences this
installation might have. We find that participants made more privacy-conscious choices
when deciding which apps to install. Additionally, our results show that our approach
causes a negative affect in participants, which makes them pay more attention.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2647–2656},
numpages = {10},
keywords = {consequences, privacy, examples, usable security, risks, android, personalization, permissions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557330,
author = {Shay, Richard and Ion, Iulia and Reeder, Robert W. and Consolvo, Sunny},
title = {"My Religious Aunt Asked Why i Was Trying to Sell Her Viagra": Experiences with Account Hijacking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557330},
doi = {10.1145/2556288.2557330},
abstract = {With so much of our lives digital, online, and not entirely under our control, we
risk losing access to our communications, reputation, and data. Recent years have
brought a rash of high-profile account compromises, but account hijacking is not limited
to high-profile accounts. In this paper, we report results of a survey about people's
experiences with and attitudes toward account hijacking. The problem is widespread;
30% of our 294 participants had an email or social networking account accessed by
an unauthorized party. Five themes emerged from our results: (1) compromised accounts
are often valuable to victims, (2) attackers are mostly unknown, but sometimes known,
to victims, (3) users acknowledge some responsibility for keeping their accounts secure,
(4) users' understanding of important security measures is incomplete, and (5) harm
from account hijacking is concrete and emotional. We discuss implications for designing
security mechanisms to improve chances for user adoption.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2657–2666},
numpages = {10},
keywords = {security, online accounts, google consumer survey, mechanical turk, attackers, microsurvey, account compromise, authentication, account hijacking, survey},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557292,
author = {Felt, Adrienne Porter and Reeder, Robert W. and Almuhimedi, Hazim and Consolvo, Sunny},
title = {Experimenting at Scale with Google Chrome's SSL Warning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557292},
doi = {10.1145/2556288.2557292},
abstract = {Web browsers show HTTPS authentication warnings (i.e., SSL warnings) when the integrity
and confidentiality of users' interactions with websites are at risk. Our goal in
this work is to decrease the number of users who click through the Google Chrome SSL
warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower
click-through rate (CTR) than Chrome. We investigate several factors that could be
responsible: the use of imagery, extra steps before the user can proceed, and style
choices. To test these factors, we ran six experimental SSL warnings in Google Chrome
29 and measured 130,754 impressions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2667–2670},
numpages = {4},
keywords = {SSL warnings, interstitials, interruptive warnings, active warnings, browser security warnings},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557275,
author = {Vaniea, Kami E. and Rader, Emilee and Wash, Rick},
title = {Betrayed by Updates: How Negative Experiences Affect Future Security},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557275},
doi = {10.1145/2556288.2557275},
abstract = {Installing security-relevant software updates is one of the best computer protection
mechanisms. However, users do not always choose to install updates. Through interviewing
non-expert Windows users, we found that users frequently decide not to install future
updates, regardless of whether they are important for security, after negative experiences
with past updates. This means that even non-security updates (such as user interface
changes) can impact the security of a computer. We discuss three themes impacting
users' willingness to install updates: unexpected new features in an update, the difficulty
of assessing whether an update is ``worth it', and confusion about why an update is
necessary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2671–2674},
numpages = {4},
keywords = {human factors, software updates, security},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250968,
author = {Sambasivan, Nithya},
title = {Session Details: CHI for Social Development},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250968},
doi = {10.1145/3250968},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557323,
author = {Balestrini, Mara and Bird, Jon and Marshall, Paul and Zaro, Alberto and Rogers, Yvonne},
title = {Understanding Sustained Community Engagement: A Case Study in Heritage Preservation in Rural Argentina},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557323},
doi = {10.1145/2556288.2557323},
abstract = {HCI projects are increasingly evaluating technologies in the wild, which typically
involves working with communities over extended periods, often with the goal of effecting
sustainable change. However, there are few descriptions of projects that have been
successful in the long-term. In this paper we investigate what factors are important
for developing long lasting community ICT interventions. We do this by analysing a
successful action research project and provide five recommendations for facilitating
sustained community engagement. CrowdMemo aimed to preserve local heritage in a town
in rural Argentina and the project was set up so that it could be continued by the
community once researchers had left. Participants created videos about personal memories
of the town and over 600 people attended the premiere where they were first screened.
The impact has not just been short-term and there has been sustained engagement with
the project by stakeholders in the town and wider region: the local school integrated
digital storytelling into its curriculum; the approach has been adopted by two nearby
towns; and the project has influenced regional government educational policy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2675–2684},
numpages = {10},
keywords = {research in the wild, community engagement, hci4d, digital storytelling, action research},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557196,
author = {Durrant, Abigail C. and Kirk, David S. and Reeves, Stuart},
title = {Human Values in Curating a Human Rights Media Archive},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557196},
doi = {10.1145/2556288.2557196},
abstract = {Cultural institutions, such as museums, often curate politically and ethically sensitive
materials. Increasingly, Internet-enabled, digital technology intersects with these
curatorial practices offering new opportunities for public and scholarly engagement.
We report on a case study of human rights media archiving at a genocide memorial centre
in Rwanda, motivated by our interests in ICT support to memorialisation practices.
Through an analysis of our discussions with staff about their work, we report on how
accounts of the Rwandan Genocide are being captured and curated to support the centre's
humanitarian agenda and associated values. We identify transferable curatorial concerns
for human rights media communication amongst scholarly networks and public audiences
worldwide, elucidating interaction design challenges for supportive ICT and contributing
to HCI discourses on Value Sensitive Design and cultural engagement with sensitive
materials.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2685–2694},
numpages = {10},
keywords = {human rights media, rwanda, genocide, curation, memorial, value sensitive design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557376,
author = {Ahmed, Syed Ishtiaque and Jackson, Steven J. and Ahmed, Nova and Ferdous, Hasan Shahid and Rifat, Md. Rashidujjaman and Rizvi, A.S.M and Ahmed, Shamir and Mansur, Rifat Sabbir},
title = {<i>Protibadi</i>: A Platform for Fighting Sexual Harassment in Urban Bangladesh},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557376},
doi = {10.1145/2556288.2557376},
abstract = {Public sexual harassment has emerged as a large and growing concern in urban Bangladesh,
with deep and damaging implications for gender security, justice, and rights of public
participation. In this paper we describe an integrated program of ethnographic and
design work meant to understand and address such problems. For one year we conducted
surveys, interviews, and focus groups around sexual harassment with women at three
different universities in Dhaka. Based on this input, we developed "Protibadi", a
web and mobile phone based application designed to report, map, and share women's
stories around sexual harassment in public places. In August 2013 the system launched,
user studies were conducted, and public responses were monitored to gauge reactions,
strengths, and limits of the system. This paper describes the findings of our ethnographic
and design-based work, and suggests lessons relevant to other HCI efforts to understand
and design around difficult and culturally sensitive problems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2695–2704},
numpages = {10},
keywords = {design, postcolonial computing, hci4d, sexual harassment, bangladesh, ethnography, ictd},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557277,
author = {Oduor, Erick and Neustaedter, Carman and Judge, Tejinder K. and Hennessy, Kate and Pang, Carolyn and Hillman, Serena},
title = {How Technology Supports Family Communication in Rural, Suburban, and Urban Kenya},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557277},
doi = {10.1145/2556288.2557277},
abstract = {Much ICTD research for sub-Saharan Africa has focused on how technology related interventions
have aimed to incorporate marginalized communities towards global economic growth.
Our work builds on this. We present results from an exploratory qualitative study
on the family communication practices of family members who communicate both within
and between rural, suburban, and urban settings in Kenya. Our findings reveal that
family communication focuses on economic support, well-being, life advice, and everyday
coordination of activities. We also outline social factors that affect family communication,
including being an eldest child, having a widowed sibling, and having reduced access
to technology because of gender, literacy, or one's financial situation. Lastly, we
discuss new opportunities for technology design and articulate the challenges that
designers will face if creating or deploying family communication technologies in
Kenya.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2705–2714},
numpages = {10},
keywords = {ict4d, family communication, awareness, mobile devices},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250993,
author = {Nichols, Jeffrey},
title = {Session Details: Question and Answer Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250993},
doi = {10.1145/3250993},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557202,
author = {Piccardi, Tiziano and Convertino, Gregorio and Zancanaro, Massimo and Wang, Ji and Archambeau, Cedric},
title = {Towards Crowd-Based Customer Service: A Mixed-Initiative Tool for Managing Q&amp;A Sites},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557202},
doi = {10.1145/2556288.2557202},
abstract = {In this paper, we propose a mixed-initiative approach to integrate a Q&amp;A site based
on a crowd of volunteers with a standard operator-based help desk, ensuring quality
of customer service. Q&amp;A sites have emerged as an efficient way to address questions
in various domains by leveraging crowd knowledge. However, they lack sufficient reliability
to be the sole basis of customer service applications. We built a proof-of-concept
mixed-initiative tool that helps a crowd-manager to decide if a question will get
a satisfactory and timely answer by the crowd or if it should be redirected to a dedicated
operator. A user experiment found that our tool reduced the participants' cognitive
load and improved their performance, in terms of their precision and recall. In particular,
those with higher performance benefited more than those with lower performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2725–2734},
numpages = {10},
keywords = {customer care, mixed initiative, crowdsourcing, q&amp;a},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557181,
author = {Rzeszotarski, Jeffrey M. and Morris, Meredith Ringel},
title = {Estimating the Social Costs of Friendsourcing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557181},
doi = {10.1145/2556288.2557181},
abstract = {Every day users of social networking services ask their followers and friends millions
of questions. These friendsourced questions not only provide informational benefits,
but also may reinforce social bonds. However, there is a limit to how much a person
may want to friendsource. They may be uncomfortable asking questions that are too
private, might not want to expend others' time or effort, or may feel as though they
have already accrued too many social debts. These perceived social costs limit the
potential benefits of friendsourcing. In this paper we explore the perceived social
costs of friendsourcing on Twitter via a monetary choice. We develop a model of how
users value the attention and effort of their social network while friendsourcing,
compare and contrast it with paid question answering in a crowdsourced labor market,
and provide future design considerations for better supporting friendsourcing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2735–2744},
numpages = {10},
keywords = {crowdsourcing, twitter, sns q&amp;a, friendsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557240,
author = {Liao, Q. Vera and Fu, Wai-Tat},
title = {Expert Voices in Echo Chambers: Effects of Source Expertise Indicators on Exposure to Diverse Opinions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557240},
doi = {10.1145/2556288.2557240},
abstract = {We studied how a source expertise indicator impacted users' information seeking behavior
when using a system aggregating diverse opinions, and how it interacted with a source
position indicator to shape users' selectivity of information. We found that, for
both attitude consistent and inconsistent information, the expertise indicator increased
the selection of sources indicated to have high expertise and decreased that of low
expertise. Moreover, when both source expertise and position indicators were present,
users' selective exposure tendency, i.e., preferential selection of attitude consistent
sources over inconsistent ones, decreased among expert sources. Moreover, we found
that the expertise indicator could benefit encouraging common ground seeking with
different others by increasing the agreement with, and perceived expertise of inconsistent
sources indicated to be experts. Design implications for moderating selective exposure
by highlighting the utility of dissonant information were discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2745–2754},
numpages = {10},
keywords = {source expertise, diversity seeking, selective exposure},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557175,
author = {Rzeszotarski, Jeffrey M. and Spiro, Emma S. and Matias, Jorge Nathan and Monroy-Hern\'{a}ndez, Andr\'{e}s and Morris, Meredith Ringel},
title = {Is Anyone out There? Unpacking Q&amp;A Hashtags on Twitter},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557175},
doi = {10.1145/2556288.2557175},
abstract = {In addition to posting news and status updates, many Twitter users post questions
that seek various types of subjective and objective information. These questions are
often labeled with 'Q&amp;A' hashtags, such as #lazyweb or #twoogle. We surveyed Twitter
users and found they employ these Q&amp;A hashtags both as a topical signifier (this tweet
needs an answer!) and to reach out to those beyond their immediate followers (a community
of helpful tweeters who monitor the hashtag). However, our log analysis of thousands
of hashtagged Q&amp;A exchanges reveals that nearly all replies to hashtagged questions
come from a user's immediate follower network, contradicting users' beliefs that they
are tapping into a larger community by tagging their question tweets. This finding
has implications for designing next-generation social search systems that reach and
engage a wide audience of answerers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2755–2758},
numpages = {4},
keywords = {social search, twitter, hashtags, q&amp;a, information seeking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557081,
author = {Gilbert, Eric},
title = {What If We Ask a Different Question? Social Inferences Create Product Ratings Faster},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557081},
doi = {10.1145/2556288.2557081},
abstract = {Consumer product reviews are the backbone of commerce online. Most commonly, sites
ask users for their personal opinions on a product or service. I conjecture, however,
that this traditional method of eliciting reviews often invites idiosyncratic viewpoints.
In this paper, I present a statistical study examining the differences between traditionally
elicited product ratings (i.e., "How do you rate this product'") and social inference
ratings (i.e., "How do you think other people will rate this product'"). In 5 of 6
trials, I find that social inference ratings produce the same aggregate product rating
as the one produced via traditionally elicited ratings. In all cases, however, social
inferences yield less variance. This is significant because using social inference
ratings 1) therefore converges on the true aggregate product rating faster, and 2)
is a cheap design intervention on the part of existing sites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2759–2762},
numpages = {4},
keywords = {product reviews, ecommerce, social psychology, ratings},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250994,
author = {Patern', Fabio},
title = {Session Details: Cross-Device Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250994},
doi = {10.1145/3250994},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556956,
author = {Chapuis, Olivier and Bezerianos, Anastasia and Frantzeskakis, Stelios},
title = {Smarties: An Input System for Wall Display Development},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556956},
doi = {10.1145/2556288.2556956},
abstract = {Wall-sized displays can support data visualization and collaboration, but making them
interactive is challenging. Smarties allows wall application developers to easily
add interactive support to their collaborative applications. It consists of an interface
running on touch mobile devices for input, a communication protocol between devices
and the wall, and a library that implements the protocol and handles synchronization,
locking and input conflicts. The library presents the input as an event loop with
callback functions. Each touch mobile has multiple cursor controllers, each associated
with keyboards, widgets and clipboards. These controllers can be assigned to specific
tasks, are persistent in nature, and can be shared by multiple collaborating users
for sharing work. They can control simple cursors on the wall application, or specific
content (objects or groups of them). The types of associated widgets are decided by
the wall application, making the mobile interface customizable by the wall application
it connects to.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2763–2772},
numpages = {10},
keywords = {input toolkit, hand-held touch devices, wall display, multi-cursors, cscw},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557170,
author = {Hamilton, Peter and Wigdor, Daniel J.},
title = {Conductor: Enabling and Understanding Cross-Device Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557170},
doi = {10.1145/2556288.2557170},
abstract = {The proliferation of inexpensive connected devices has created a situation where a
person, at any given moment, is surrounded by interactive computers. Despite this
fact, there are very few means by which a user may take advantage of this large number
of screens. We present Conductor, a prototype framework which serves as an exemplar
for the construction of cross-device applications. We present a series of interaction
methods by which users can easily share information, chain tasks across devices, and
manage sessions across devices. We also present a cross-device usage scenario which
utilizes several cross-device applications built within our prototype framework. We
also describe a user study, which helped us to understand how users will take advantage
of a large number of devices in support of performance of a sense making task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2773–2782},
numpages = {10},
keywords = {distributed user interfaces, cross-device applications, user interface design, multi-device environments, optimization, information sharing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557199,
author = {Yang, Jishuo and Wigdor, Daniel},
title = {Panelrama: Enabling Easy Specification of Cross-Device Web Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557199},
doi = {10.1145/2556288.2557199},
abstract = {We present Panelrama, a web-based framework for the construction of applications using
distributed user interfaces (DUIs). Our implementation provides developers with low
migration costs through built-in mechanisms for the synchronization of a UI state,
requiring minimal changes to existing languages. Additionally, we describe a solution
to categorize device characteristics and dynamically change UI allocation to best-fit
devices. We illustrate the use of Panelrama through three sample applications which
demonstrate its support for known interaction methods, we also present the results
of a developer study, which validates our belief that cross-device application experiences
can be easily implemented using our framework.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2783–2792},
numpages = {10},
keywords = {distributed user interfaces, multi-device environments},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556980,
author = {Nebeling, Michael and Mintsi, Theano and Husmann, Maria and Norrie, Moira},
title = {Interactive Development of Cross-Device User Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556980},
doi = {10.1145/2556288.2556980},
abstract = {Current GUI builders provide a design environment for user interfaces that target
either a single type or fixed set of devices, and provide little support for scenarios
in which the user interface, or parts of it, are distributed over multiple devices.
Distributed user interfaces have received increasing attention over the past years.
There are different, often model-based, approaches that focus on technical issues.
This paper presents XDStudio--a new GUI builder designed to support interactive development
of cross-device web interfaces. XDStudio implements two complementary authoring modes
with a focus on the design process of distributed user interfaces. First, simulated
authoring allows designing for a multi-device environment on a single device by simulating
other target devices. Second, on-device authoring allows the design process itself
to be distributed over multiple devices, as design and development take place on the
target devices themselves. To support interactive development for multi-device environments,
where not all devices may be present at design and run-time, XDStudio supports switching
between the two authoring modes, as well as between design and use modes, as required.
This paper focuses on the design of XDStudio, and evaluates its support for two distribution
scenarios.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2793–2802},
numpages = {10},
keywords = {distributed user interfaces, distributed authoring, simulated authoring, multi-device},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250995,
author = {Morris, Dan},
title = {Session Details: Exergaming for Health and Fitness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250995},
doi = {10.1145/3250995},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557268,
author = {Singh, Aneesha and Klapper, Annina and Jia, Jinni and Fidalgo, Antonio and Tajadura-Jim\'{e}nez, Ana and Kanakam, Natalie and Bianchi-Berthouze, Nadia and Williams, Amanda},
title = {Motivating People with Chronic Pain to Do Physical Activity: Opportunities for Technology Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557268},
doi = {10.1145/2556288.2557268},
abstract = {Physical activity is important for improving quality of life in people with chronic
pain. However, actual or anticipated pain exacerbation, and lack of confidence when
doing physical activity, make it difficult to maintain and build towards long-term
activity goals. Research guiding the design of interactive technology to motivate
and support physical activity in people with chronic pain is lacking. We conducted
studies with: (1) people with chronic pain, to understand how they maintained and
increased physical activity in daily life and what factors deterred them; and (2)
pain-specialist physiotherapists, to understand how they supported people with chronic
pain. Building on this understanding, we investigated the use of auditory feedback
to address some of the psychological barriers and needs identified and to increase
self-efficacy, motivation and confidence in physical activity. We conclude by discussing
further design opportunities based on the overall findings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2803–2812},
numpages = {10},
keywords = {chronic pain, auditory feedback, physical activity, interactive systems design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557160,
author = {Uzor, Stephen and Baillie, Lynne},
title = {Investigating the Long-Term Use of Exergames in the Home with Elderly Fallers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557160},
doi = {10.1145/2556288.2557160},
abstract = {Rehabilitation has been shown to significantly reduce the risk of falling in older
adults. However, low adherence to rehabilitation exercises in the home means that
seniors often do not get the therapy that they require. We propose that the use of
tailored exergames could encourage adherence to falls rehabilitation in the home,
as exergames have proved successful in clinical settings. We describe the results
from the first known study to investigate the long-term (12 weeks) use of exergames,
designed in close collaboration with elderly users, for falls rehabilitation in the
home. Our findings suggest that there is an untapped potential of exergames for home
rehabilitation use, as our findings show that there was better adherence to exercise
in participants who used the exergames, versus those who used standard care. Finally,
we make recommendations for designers, on the design of exergames for the rehabilitation
of seniors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2813–2822},
numpages = {10},
keywords = {rehabilitation., home, user studies, exergames, elderly, falls, games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557190,
author = {Miller, Andrew D. and Mynatt, Elizabeth D.},
title = {StepStream: A School-Based Pervasive Social Fitness System for Everyday Adolescent Health},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557190},
doi = {10.1145/2556288.2557190},
abstract = {Computer-supported fitness interventions for adolescents have the potential to improve
adolescents' attitudes and perceptions about physical activity through peer influence
and interpersonal accountability. Past research has explored the potential of interventions
based on competition and social-comparison mechanisms. We present a new approach:
school-based, pervasive social fitness systems. We describe one such system: StepStream,
a pedometer-based microblog we designed and deployed for four weeks with 42 US middle
school students. StepStream users improved their attitudes about fitness and increased
their sense of social support for fitness. The least-active students also increased
their daily activity. We show that our school-based social fitness approach performed
comparably in attitude and behavior change to more competitive or direct-comparison
systems. These results expand the strategies available computer-supported fitness
interventions. Our school-based social fitness approach to everyday adolescent health
shows the potential for social computing systems to positively influence offline health
behaviors in real-world settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2823–2832},
numpages = {10},
keywords = {deployments, fitness intervention, pervasive health, adolescents, social computing, youth},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557299,
author = {Mauriello, Matthew and Gubbels, Michael and Froehlich, Jon E.},
title = {Social Fabric Fitness: The Design and Evaluation of Wearable E-Textile Displays to Support Group Running},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557299},
doi = {10.1145/2556288.2557299},
abstract = {Group exercise has multiple benefits including greater adherence to fitness regimens,
increased enjoyment among participants, and enhanced workout intensity. While a large
number of technology tools have emerged to support real-time feedback of individual
performance, tools to support group fitness are limited. In this paper, we present
a set of wearable e-textile displays for running groups called Social Fabric Fitness
(SFF). SFF provides a glanceable, shared screen on the back of the wearer's shirt
to increase awareness and motivation of group fitness performance. We discuss parallel
prototyping of three designs-one flexible e-ink and two flexible LED-based displays;
the selection and refinement of one design; and two evaluations'a field study of 10
running groups and two case studies of running races. Our qualitative findings indicate
that SFF improves awareness of individual and group performance, helps groups stay
together, and improves in-situ motivation. We close with reflections for future athletic
e-textile displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2833–2842},
numpages = {10},
keywords = {glanceable displays, quantified self, fitness, wearables, personal informatics, visualization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250996,
author = {Hoonhout, Jettie},
title = {Session Details: Sensory Experiences: Smell and Taste},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250996},
doi = {10.1145/3250996},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557008,
author = {Obrist, Marianna and Tuch, Alexandre N. and Hornbaek, Kasper},
title = {Opportunities for Odor: Experiences with Smell and Implications for Technology},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557008},
doi = {10.1145/2556288.2557008},
abstract = {Technologies for capturing and generating smell are emerging, and our ability to engineer
such technologies and use them in HCI is rapidly developing. Our understanding of
how these technologies match the experiences with smell that people have or want to
have is surprisingly limited. We therefore investigated the experience of smell and
the emotions that accompany it. We collected stories from 439 participants who described
personally memorable smell experiences in an online questionnaire. Based on the stories
we developed 10 categories of smell experience. We explored the implications of the
categories for smell-enhanced technology design by (a) probing participants to envision
technologies that match their smell story and (b) having HCI researchers brainstorm
technologies using the categories as design stimuli. We discuss how our findings can
benefit research on personal memories, momentary and first time experiences, and wellbeing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2843–2852},
numpages = {10},
keywords = {smell, olfaction, odor, design brainstorming, smell experiences, crowdsourcing, smell stories, narratives, designing for smell., user experience, smell-enhanced technology},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557007,
author = {Obrist, Marianna and Comber, Rob and Subramanian, Sriram and Piqueras-Fiszman, Betina and Velasco, Carlos and Spence, Charles},
title = {Temporal, Affective, and Embodied Characteristics of Taste Experiences: A Framework for Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557007},
doi = {10.1145/2556288.2557007},
abstract = {We present rich descriptions of taste experience through an analysis of the diachronic
and synchronic experiences of each of the five basic taste qualities: sweet, sour,
salt, bitter, and umami. Our findings, based on a combination of user experience evaluation
techniques highlight three main themes: temporality, affective reactions, and embodiment.
We present the taste characteristics as a framework for design and discuss each taste
in order to elucidate the design qualities of individual taste experiences. These
findings add a semantic understanding of taste experiences, their temporality enhanced
through descriptions of the affective reactions and embodiment that the five basic
tastes elicit. These findings are discussed on the basis of established psychological
and behavioral phenomena, highlighting the potential for taste-enhanced design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2853–2862},
numpages = {10},
keywords = {sensory research, explicitation interview technique, user experience, taste experiences, taste, sensual evaluation tool},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557087,
author = {Seah, Sue Ann and Martinez Plasencia, Diego and Bennett, Peter D. and Karnik, Abhijit and Otrocol, Vlad Stefan and Knibbe, Jarrod and Cockburn, Andy and Subramanian, Sriram},
title = {SensaBubble: A Chrono-Sensory Mid-Air Display of Sight and Smell},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557087},
doi = {10.1145/2556288.2557087},
abstract = {We present SensaBubble, a chrono-sensory mid-air display system that generates scented
bubbles to deliver information to the user via a number of sensory modalities. The
system reliably produces single bubbles of specific sizes along a directed path. Each
bubble produced by SensaBubble is filled with fog containing a scent relevant to the
notification. The chrono-sensory aspect of SensaBubble means that information is presented
both temporally and multimodally. Temporal information is enabled through two forms
of persistence: firstly, a visual display projected onto the bubble which only endures
until it bursts; secondly, a scent released upon the bursting of the bubble slowly
disperses and leaves a longer-lasting perceptible trace of the event. We report details
of SensaBubble's design and implementation, as well as results of technical and user
evaluations. We then discuss and demonstrate how SensaBubble can be adapted for use
in a wide range of application contexts -- from an ambient peripheral display for
persistent alerts, to an engaging display for gaming or education.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2863–2872},
numpages = {10},
keywords = {multimodality., ambient displays, interactive displays, ephemeral interfaces, bubbles},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557026,
author = {Wei, Jun and Ma, Xiaojuan and Zhao, Shengdong},
title = {Food Messaging: Using Edible Medium for Social Messaging},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557026},
doi = {10.1145/2556288.2557026},
abstract = {Food is more than just a means of survival; it is also a form of communication. In
this paper, we investigate the potential of food as a social message carrier (a.k.a.,
food messaging). To investigate how people accept, use, and perceive food messaging,
we conducted exploratory interviews, a field study, and follow-up interviews over
four weeks in a large information technology (IT) company. We collected 904 messages
sent by 343 users. Our results suggest strong acceptance of food messaging as an alternative
message channel. Further analysis implies that food messaging embodies characteristics
of both text messaging and gifting. It is preferred in close relationships for its
evocation of positive emotions. As the first field study on edible social messaging,
our empirical findings provide valuable insights into the uniqueness of food as a
message carrier and its capabilities to promote greater social bonding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2873–2882},
numpages = {10},
keywords = {edible social messaging, affective communication, food hci, food printer, food messaging, field study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250997,
author = {Boring, Sebastian},
title = {Session Details: Multitouch Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250997},
doi = {10.1145/3250997},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556958,
author = {Wagner, Julie and Lecolinet, Eric and Selker, Ted},
title = {Multi-Finger Chords for Hand-Held Tablets: Recognizable and Memorable},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556958},
doi = {10.1145/2556288.2556958},
abstract = {Despite the demonstrated benefits of multi-finger input, todays gesture vocabularies
offer a limited number of postures and gestures. Previous research designed several
posture sets, but does not address the limited human capacity of retaining them. We
present a multi-finger chord vocabulary, introduce a novel hand-centric approach to
detect the identity of fingers on off-the-shelf hand-held tablets, and report on the
detection accuracy. A between-subjects experiment comparing "random" to a "categorized"
chord-command mapping found that users retained categorized mappings more accurately
over one week than random ones. In response to the logical posture-language structure,
people adapted to logical memorization strategies, such as 'exclusion', 'order', and 'category', to minimize the amount of information to retain. We conclude that structured
chord-command mappings support learning, short-, and long-term retention of chord-
command mappings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2883–2892},
numpages = {10},
keywords = {hand-held tablet, finger identification, multi-finger chord, chord-command mapping},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557029,
author = {Olafsdottir, Halla B. and Tsandilas, Theophanis and Appert, Caroline},
title = {Prospective Motor Control on Tabletops: Planning Grasp for Multitouch Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557029},
doi = {10.1145/2556288.2557029},
abstract = {Substantial amount of research in Psychology has studied how people manipulate objects
in the physical world. This work has unveiled that people show strong signs of prospective
motor planning, i.e., they choose initial grasps that avoid uncomfortable end postures
and facilitate object manipulation. Interactive tabletops allow their users great
flexibility in the manipulation of virtual objects but to our knowledge previous work
has never examined whether prospective motor control takes place in this context.
To test this, we ran three experiments. We systematically studied how users adapt
their grasp when asked to translate and rotate virtual objects on a multitouch tabletop.
Our results demonstrate that target position and orientation significantly affect
the orientation of finger placement on the object. We analyze our results in the light
of the most recent model of planning for manipulating physical objects and identify
their implications for the design of tabletop interfaces. },
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2893–2902},
numpages = {10},
keywords = {movement planning, multitouch, tabletops, acquisition and manipulation, end-state comfort effect, range of motion},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557282,
author = {Alzayat, Ayman and Hancock, Mark and Nacenta, Miguel},
title = {Quantitative Measurement of Virtual vs. Physical Object Embodiment through Kinesthetic Figural after Effects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557282},
doi = {10.1145/2556288.2557282},
abstract = {Over the past decade, multi-touch surfaces have become commonplace, with many researchers
and practitioners describing the benefits of their natural, physical-like interactions.
We present a pair of studies that empirically investigates the psychophysical effects
of direct interaction with both physical and virtual artefacts. We use the phenomenon
of Kinesthetic Figural After Effects-a change in understanding of the physical size
of an object after a period of exposure to an object of different size. Our studies
show that, while this effect is robustly reproducible when using physical artefacts,
this same effect does not manifest when manipulating virtual artefacts on a direct,
multi-touch tabletop display. We contribute quantitative evidence suggesting a psychophysical
difference in our response to physical vs. virtual objects, and discuss future research
directions to explore measurable phenomena to evaluate the presence of physical-like
changes from virtual on-screen objects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2903–2912},
numpages = {10},
keywords = {embodied interaction, tabletop displays, tangible user interfaces, physical interaction, multi-touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557012,
author = {Harrison, Chris and Xiao, Robert and Schwarz, Julia and Hudson, Scott E.},
title = {TouchTools: Leveraging Familiarity and Skill with Physical Tools to Augment Touch Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557012},
doi = {10.1145/2556288.2557012},
abstract = {The average person can skillfully manipulate a plethora of tools, from hammers to
tweezers. However, despite this remarkable dexterity, gestures on today's touch devices
are simplistic, relying primarily on the chording of fingers: one-finger pan, two-finger
pinch, four-finger swipe and similar. We propose that touch gesture design be inspired
by the manipulation of physical tools from the real world. In this way, we can leverage
user familiarity and fluency with such tools to build a rich set of gestures for touch
interaction. With only a few minutes of training on a proof-of-concept system, users
were able to summon a variety of virtual tools by replicating their corresponding
real-world grasps.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2913–2916},
numpages = {4},
keywords = {tangible computing, multitouch, touchscreen, capacitive sensing, surface computing, gesture design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250998,
author = {Egelman, Serge},
title = {Session Details: Authentication and Passwords},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250998},
doi = {10.1145/3250998},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557153,
author = {Chowdhury, Soumyadeb and Poet, Ron and Mackenzie, Lewis},
title = {Passhint: Memorable and Secure Authentication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557153},
doi = {10.1145/2556288.2557153},
abstract = {People find it difficult to remember multiple alphanumeric as well as graphical passwords.
We propose a Passhint authentication system (PHAS), where the users have to choose
four images and create hints for each one of them in order to register a new password.
During authentication, they have to recognize only the target images, which are displayed
with their corresponding hints, among collections of 15 decoy images, in a four step
process. A usability study was conducted with 40 subjects. They created 1 Mikon, 1
doodle, 1 art and 1 object password and then recalled each password after a period
of two weeks (without any practice sessions). The results demonstrated that the memorability
of multiple passwords in PHAS is better than in existing Graphical authentication
systems (GASs). Although the registration time is high, authentication time for successful
attempts is either equivalent to or less than the time reported for previous GASs.
A guessability study conducted with the same subjects revealed that art passwords
are the least guessable, followed by Mikon, doodle and objects in that order. The
results strongly suggest the use of art passwords in PHAS, which would offer usable
as well as secure authentication. The preliminary results indicate that PHAS has solved
the memorability problem with multiple passwords. We propose two new features that
could enhance the security offered by PHAS, but the usability of these features would
need to be tested before they could be adopted in practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2917–2926},
numpages = {10},
keywords = {usability, graphical authentication, guessability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557377,
author = {Shay, Richard and Komanduri, Saranga and Durity, Adam L. and Huh, Phillip (Seyoung) and Mazurek, Michelle L. and Segreti, Sean M. and Ur, Blase and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith},
title = {Can Long Passwords Be Secure and Usable?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557377},
doi = {10.1145/2556288.2557377},
abstract = {To encourage strong passwords, system administrators employ password-composition policies,
such as a traditional policy requiring that passwords have at least 8 characters from
4 character classes and pass a dictionary check. Recent research has suggested, however,
that policies requiring longer passwords with fewer additional requirements can be
more usable and in some cases more secure than this traditional policy. To explore
long passwords in more detail, we conducted an online experiment with 8,143 participants.
Using a cracking algorithm modified for longer passwords, we evaluate eight policies
across a variety of metrics for strength and usability. Among the longer policies,
we discover new evidence for a security/usability tradeoff, with none being strictly
better than another on both dimensions. However, several policies are both more usable
and more secure that the traditional policy we tested. Our analyses additionally reveal
common patterns and strings found in cracked passwords. We discuss how system administrators
can use these results to improve password-composition policies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2927–2936},
numpages = {10},
keywords = {passwords, authentication, usable security, security policy, password-composition policies},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557097,
author = {De Luca, Alexander and Harbach, Marian and von Zezschwitz, Emanuel and Maurer, Max-Emanuel and Slawik, Bernhard Ewald and Hussmann, Heinrich and Smith, Matthew},
title = {Now You See Me, Now You Don't: Protecting Smartphone Authentication from Shoulder Surfers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557097},
doi = {10.1145/2556288.2557097},
abstract = {In this paper, we present XSide, an authentication mechanism that uses the front and
the back of smartphones to enter stroke-based passwords. Users can switch sides during
input to minimize the risk of shoulder surfing. We performed a user study (n = 32)
to explore how switching sides during authentication affects usability and security
of the system. The results indicate that switching the sides increases security while
authentication speed stays relatively fast (≤ 4 seconds). The paper furthermore provides
insights on accuracy of eyes-free input (as used in XSide) and shows how 3D printed
prototype cases can improve the back-of-device interaction experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2937–2946},
numpages = {10},
keywords = {authentication, security, back-of-device interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557212,
author = {Thorpe, Julie and Al-Badawi, Muath and MacRae, Brent and Salehi-Abari, Amirali},
title = {The Presentation Effect on Graphical Passwords},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557212},
doi = {10.1145/2556288.2557212},
abstract = {We provide a simple yet powerful demonstration of how an unobtrusive change to a graphical
password interface can modify the distribution of user chosen passwords, and thus
possibly the security it provides. The only change to the interface is how the background
image is presented to the user in the password creation phase--we call the effect
of this change the "presentation effect". We demonstrate the presentation effect by
performing a comparative user study of two groups using the same background image,
where the image is presented in two different ways prior to password creation. Our
results show a statistically different distribution of user's graphical passwords,
with no observed usability consequences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2947–2950},
numpages = {4},
keywords = {user authentication, graphical passwords, passwords},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557346,
author = {Burgbacher, Ulrich and Hinrichs, Klaus},
title = {An Implicit Author Verification System for Text Messages Based on Gesture Typing Biometrics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557346},
doi = {10.1145/2556288.2557346},
abstract = {Gesture typing is a popular text input method used on smartphones. Gesture keyboards
are based on word gestures that subsequently trace all letters of a word on a virtual
keyboard. Instead of tapping a word key by key, the user enters a word gesture with
a single continuous stroke. In this paper, we introduce an implicit user verification
approach for short text messages that are entered with a gesture keyboard. We utilize
the way people interact with gesture keyboards to extract behavioral biometric features.
We propose a proof-of-concept classification framework that learns the gesture typing
behavior of a person and is able to decide whether a gestured message was written
by the legitimate user or an imposter. Data collected from gesture keyboard users
in a user study is used to assess the performance of the classification framework,
demonstrating that the technique has considerable promise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2951–2954},
numpages = {4},
keywords = {mobile phone security, gesture keyboards, implicit authentication, behavioral biometrics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250999,
author = {Wulf, Volker},
title = {Session Details: Policies and Practice: Doing the Right Thing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250999},
doi = {10.1145/3250999},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557367,
author = {Harvey, John and Golightly, David and Smith, Andrew},
title = {HCI as a Means to Prosociality in the Economy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557367},
doi = {10.1145/2556288.2557367},
abstract = {HCI research often involves intervening in the economic lives of people, but researchers
only rarely give explicit consideration to what actually constitutes prosociality
in the economy. Much has been said previously regarding sustainability but this has
largely focused on environmental rather than interpersonal relations. This paper provides
an analysis of how prosocial HCI has been discussed and continues to be defined as
a research field. Based on a corpus of published works, we describe a variety of genres
of work relating to prosocial HCI. Key intellectual differences are explored, including
the epistemological and ethical positions involved in designing for prosocial outcomes
as well as how HCI researchers posit economic decision-making. Finally, emerging issues
and opportunities for further debate and collaboration are discussed in turn.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2955–2964},
numpages = {10},
keywords = {hci, economic anthropology, prosocial},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557364,
author = {Grimpe, Barbara and Hartswood, Mark and Jirotka, Marina},
title = {Towards a Closer Dialogue between Policy and Practice: Responsible Design in HCI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557364},
doi = {10.1145/2556288.2557364},
abstract = {Given the potent and pervasive nature of modern technologies, this paper lays out
the complexities involved in achieving responsible design. In order to do this we
will first compare an emerging policy-oriented programme of research known as RRI
(Responsible Research and Innovation) with initiatives in HCI. A focus on the similarities
and differences may highlight to what extent responsibility is already and successfully
embedded within the concerns and practices of design and use, and what may yet need
to be incorporated for responsible design. The paper then discusses the challenges
of 'naturalising' the very ambitious programme of RRI within specific design activities
and concerns, through the lens of four analytic concepts: reflexivity; responsiveness;
inclusion; and anticipation. Finally, we make a case for a pragmatic, 'unromantic',
but engaged reinterpretation of RRI for HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2965–2974},
numpages = {10},
keywords = {responsible design, critical design, value-sensitive design, participatory design, risk society, governance, user-centered design, innovation, ethics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557061,
author = {Bellotti, Victoria M.E. and Cambridge, Sara and Hoy, Karen and Shih, Patrick C. and Handalian, Lisa Renery and Han, Kyungsik and Carroll, John M.},
title = {Towards Community-Centered Support for Peer-to-Peer Service Exchange: Rethinking the Timebanking Metaphor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557061},
doi = {10.1145/2556288.2557061},
abstract = {Commercial peer-to-peer service exchange businesses, such as AirBnB, Lyft and TaskRabbit,
are expanding rapidly, but their non-profit counterparts are lagging behind. We conducted
a field study of the most prominent of these, timebanking; a system in which 'time
dollars' are earned and spent by people providing services for and receiving them
from each other. Our study exposed problems with the very metaphor of banking itself,
which deter participation. In this paper we discuss how these problems can be tackled
with user experience design for systems supporting timebanking. Our design ideas emphasize
the personal and social benefits of participation, and avoid such unappealing concepts
as debt and neediness that the timebanking metaphor falls afoul of.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2975–2984},
numpages = {10},
keywords = {user experience design, timebanking, field study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251000,
author = {Cheshire, Coye},
title = {Session Details: Journalism and Social News},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251000},
doi = {10.1145/3251000},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557262,
author = {Eveleigh, Alexandra and Jennett, Charlene and Blandford, Ann and Brohan, Philip and Cox, Anna L.},
title = {Designing for Dabblers and Deterring Drop-Outs in Citizen Science},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557262},
doi = {10.1145/2556288.2557262},
abstract = {In most online citizen science projects, a large proportion of participants contribute
in small quantities. To investigate how low contributors differ from committed volunteers,
we distributed a survey to members of the Old Weather project, followed by interviews
with respondents selected according to a range of contribution levels. The studies
reveal a complex relationship between motivations and contribution. Whilst high contributors
were deeply engaged by social or competitive features, low contributors described
a solitary experience of 'dabbling' in projects for short periods. Since the majority
of participants exhibit this small-scale contribution pattern, there is great potential
value in designing interfaces to tempt lone workers to complete 'just another page',
or to lure early drop-outs back into participation. This includes breaking the work
into components which can be tackled without a major commitment of time and effort,
and providing feedback on the quality and value of these contributions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2985–2994},
numpages = {10},
keywords = {citizen science, motivation, engagement, dabblers},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557054,
author = {Taylor, Nick and Frohlich, David M. and Egglestone, Paul and Marshall, Justin and Rogers, Jon and Blum-Ross, Alicia and Mills, John and Shorter, Mike and Olivier, Patrick},
title = {Utilising Insight Journalism for Community Technology Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557054},
doi = {10.1145/2556288.2557054},
abstract = {We describe the process of insight journalism, in which local amateur journalists
were used to generate unique insights into the digital needs of a community. We position
this as a means for communities to represent themselves to designers, both as a method
of designing community technologies and as a first step towards supporting innovation
at a local level. To demonstrate insight journalism, we present two case studies of
community technologies that were directly inspired, informed and evaluated by journalistic
content. Based on this experience, we evaluate the role that insight journalism can
play in designing for communities, the particular characteristics that it lends to
the design process and how it might be employed to support sustainable community innovation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2995–3004},
numpages = {10},
keywords = {local innovation, community, co-design, ethnography, design, citizen journalism, participatory design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557228,
author = {Gao, Tong and Hullman, Jessica R. and Adar, Eytan and Hecht, Brent and Diakopoulos, Nicholas},
title = {NewsViews: An Automated Pipeline for Creating Custom Geovisualizations for News},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557228},
doi = {10.1145/2556288.2557228},
abstract = {Interactive visualizations add rich, data-based context to online news articles. Geographic
maps are currently the most prevalent form of these visualizations. Unfortunately,
designers capable of producing high-quality, customized geovisualizations are scarce.
We present NewsViews, a novel automated news visualization system that generates interactive,
annotated maps without requiring professional designers. NewsViews' maps support trend
identification and data comparisons relevant to a given news article. The NewsViews
system leverages text mining to identify key concepts and locations discussed in articles
(as well as potential annotations), an extensive repository of 'found' databases,
and techniques adapted from cartography to identify and create visually 'interesting'
thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated,
map generation and experimentally validate the key features for successful representations
(e.g., relevance to context, variable selection, 'interestingness' of representation
and annotation quality).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3005–3014},
numpages = {10},
keywords = {online news, narrative information visualization, text summarization, geovisualization, interactive maps},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557114,
author = {Garbett, Andrew Thomas and Comber, Rob and Egglestone, Paul and Glancy, Maxine and Olivier, Patrick},
title = {Finding "Real People": Trust and Diversity in the Interface between Professional and Citizen Journalists},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557114},
doi = {10.1145/2556288.2557114},
abstract = {The increase of social media and web blogs has enabled a new generation of citizen
journalism to provide new perspectives into local communities. However traditional
news organisations are currently struggling to incorporate this new form of journalism
into their existing organisational workflow. We present an analysis from 10 interviews
with professional journalists and explore the current issues faced by professional
journalists when searching for reliable and reputable local news sources as well as
the perceived role of citizen journalists within a large news organisation. From this
analysis we present a set of design implications for building systems that support
interaction between citizen and professional journalists in order to encourage participatory
news production and diversify national news perspectives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3015–3024},
numpages = {10},
keywords = {reputation, journalism, diversity, trust, citizen journalism},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251001,
author = {Alexander, Jason},
title = {Session Details: Interruptions and Distractions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251001},
doi = {10.1145/3251001},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557204,
author = {Mark, Gloria and Iqbal, Shamsi T. and Czerwinski, Mary and Johns, Paul},
title = {Bored Mondays and Focused Afternoons: The Rhythm of Attention and Online Activity in the Workplace},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557204},
doi = {10.1145/2556288.2557204},
abstract = {While distractions using digital media have received attention in HCI, understanding
engagement in workplace activities has been little explored. We logged digital activity
and continually probed perspectives of 32 information workers for five days in situ
to understand how attentional states change with context. We present a framework of
how engagement and challenge in work relate to focus, boredom, and rote work. Overall,
we find more focused attention than boredom in the workplace. Focus peaks mid-afternoon
while boredom is highest in early afternoon. People are happiest doing rote work and
most stressed doing focused work. On Mondays people are most bored but also most focused.
Online activities are associated with different attentional states, showing different
patterns at beginning and end of day, and before and after a mid-day break. Our study
shows how rhythms of attentional states are associated with context and time, even
in a dynamic workplace environment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3025–3034},
numpages = {10},
keywords = {attention, focus, computer logging, multi-tasking, engagement, empirical study, experience sampling, workplace},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557109,
author = {Shrot, Tammar and Rosenfeld, Avi and Golbeck, Jennifer and Kraus, Sarit},
title = {CRISP: An Interruption Management Algorithm Based on Collaborative Filtering},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557109},
doi = {10.1145/2556288.2557109},
abstract = {Interruptions can have a significant impact on users working to complete a task. When
people are collaborating, either with other users or with systems, coordinating interruptions
is an important factor in maintaining efficiency and preventing information overload.
Computer systems can observe user behavior, model it, and use this to optimize the
interruptions to minimize disruption. However, current techniques often require long
training periods that make them unsuitable for online collaborative environments where
new users frequently participate.In this paper, we present a novel synthesis between
Collaborative Filtering methods and machine learning classification algorithms to
create a fast learning algorithm, CRISP. CRISP exploits the similarities between users
in order to apply data from known users to new users, therefore requiring less information
on each person. Results from user studies indicate the algorithm significantly improves
users' performances in completing the task and their perception of how long it took
to complete each task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3035–3044},
numpages = {10},
keywords = {collaborative filtering, classification algorithm, interruption management (cost estimation)},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557066,
author = {B\"{o}hmer, Matthias and Lander, Christian and Gehring, Sven and Brumby, Duncan P. and Kr\"{u}ger, Antonio},
title = {Interrupted by a Phone Call: Exploring Designs for Lowering the Impact of Call Notifications for Smartphone Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557066},
doi = {10.1145/2556288.2557066},
abstract = {Mobile phones have evolved significantly in recent years from single-purpose communication
devices to multi-purpose computing devices. Despite this evolution, the interaction
model for how incoming calls are handled has barely changed. Current-generation smartphones
still use abrupt full-screen notifications to alert users to incoming calls, demanding
a decision to either accept or decline the call. These full-screen notifications forcibly
interrupt whatever activity the user was already engaged in. This might be undesirable
when the user's primary task was more important than the incoming call. This paper
explores the design space for how smartphones can alert users to incoming calls. We
consider designs that allow users to postpone calls and also to multiplex by way of
a smaller partial-screen notification. These design alternatives were evaluated in
both a small-scale controlled lab study as well as a large-scale naturalistic in-the-wild
study. Results show that a multiplex design solution works best because it allows
people to continue working on their primary task while being made aware that there
is a caller on the line. The contribution of this work is an enhanced interaction
design for handling phone calls, and an understanding of how people use it for handling
incoming calls.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3045–3054},
numpages = {10},
keywords = {interruptions, smartphones, app usage, phone calls},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557189,
author = {Sahami Shirazi, Alireza and Henze, Niels and Dingler, Tilman and Pielot, Martin and Weber, Dominik and Schmidt, Albrecht},
title = {Large-Scale Assessment of Mobile Notifications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557189},
doi = {10.1145/2556288.2557189},
abstract = {Notifications are a core feature of mobile phones. They inform users about a variety
of events. Users may take immediate action or ignore them depending on the importance
of a notification as well as their current context. The nature of notifications is
manifold, applications use them both sparsely and frequently. In this paper we present
the first large-scale analysis of mobile notifications with a focus on users' subjective
perceptions. We derive a holistic picture of notifications on mobile phones by collecting
close to 200 million notifications from more than 40,000 users. Using a data-driven
approach, we break down what users like and dislike about notifications. Our results
reveal differences in importance of notifications and how users value notifications
from messaging apps as well as notifications that include information about people
and events. Based on these results we derive a number of findings about the nature
of notifications and guidelines to effectively use them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3055–3064},
numpages = {10},
keywords = {in the wild, large-scale, mobile hci, mobile phone, notification, apps},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251002,
author = {Froehlich, Jon},
title = {Session Details: Decisions, Recommendations, and Machine Learning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251002},
doi = {10.1145/3251002},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557211,
author = {Solomon, Jacob},
title = {Customization Bias in Decision Support Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557211},
doi = {10.1145/2556288.2557211},
abstract = {Many Decision Support Systems (DSS) afford customization of inputs or algorithms before
generating recommendations to a decision maker. This paper describes an experiment
in which users make decisions assisted by recommendations of a DSS in a fantasy baseball
game. This experiment shows that the act of customizing a DSS can lead to biased decision
making. I show that users who believe they have customized a DSS's recommendation
algorithm are more likely to follow the recommendations regardless of their accuracy.
I also show that this customization bias is the result of using a DSS to seek confirmatory
information in a recommendation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3065–3074},
numpages = {10},
keywords = {fantasy sports, decision support systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557238,
author = {Kulesza, Todd and Amershi, Saleema and Caruana, Rich and Fisher, Danyel and Charles, Denis},
title = {Structured Labeling for Facilitating Concept Evolution in Machine Learning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557238},
doi = {10.1145/2556288.2557238},
abstract = {Labeling data is a seemingly simple task required for training many machine learning
systems, but is actually fraught with problems. This paper introduces the notion of
concept evolution, the changing nature of a person's underlying concept (the abstract
notion of the target class a person is labeling for, e.g., spam email, travel related
web pages) which can result in inconsistent labels and thus be detrimental to machine
learning. We introduce two structured labeling solutions, a novel technique we propose
for helping people define and refine their concept in a consistent manner as they
label. Through a series of five experiments, including a controlled lab study, we
illustrate the impact and dynamics of concept evolution in practice and show that
structured labeling helps people label more consistently in the presence of concept
evolution than traditional labeling.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3075–3084},
numpages = {10},
keywords = {interactive machine learning, concept evolution},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557069,
author = {Loepp, Benedikt and Hussein, Tim and Ziegler, J\"{u}ergen},
title = {Choice-Based Preference Elicitation for Collaborative Filtering Recommender Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557069},
doi = {10.1145/2556288.2557069},
abstract = {We present an approach to interactive recommending that combines the advantages of
algorithmic techniques with the benefits of user-controlled, interactive exploration
in a novel manner. The method extracts latent factors from a matrix of user rating
data as commonly used in Collaborative Filtering, and generates dialogs in which the
user iteratively chooses between two sets of sample items. Samples are chosen by the
system for low and high values of each latent factor considered. The method positions
the user in the latent factor space with few interaction steps, and finally selects
items near the user position as recommendations.In a user study, we compare the system
with three alternative approaches including manual search and automatic recommending.
The results show significant advantages of our approach over the three competing alternatives
in 15 out of 24 possible parameter comparisons, in particular with respect to item
fit, interaction effort and user control. The findings corroborate our assumption
that the proposed method achieves a good trade-off between automated and interactive
functions in recommender systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3085–3094},
numpages = {10},
keywords = {user interfaces, recommender systems, matrix factorization, interactive recommending},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557176,
author = {Lasecki, Walter S. and Weingard, Leon and Ferguson, George and Bigham, Jeffrey P.},
title = {Finding Dependencies between Actions Using the Crowd},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557176},
doi = {10.1145/2556288.2557176},
abstract = {Activity recognition can provide computers with the context underlying user inputs,
enabling more relevant responses and more fluid interaction. However, training these
systems is difficult because it requires observing every possible sequence of actions
that comprise a given activity. Prior work has enabled the crowd to provide labels
in real-time to train automated systems on-the-fly, but numerous examples are still
needed before the system can recognize an activity on its own. To reduce the need
to collect this data by observing users, we introduce ARchitect, a system that uses
the crowd to capture the dependency structure of the actions that make up activities.
Our tests show that over seven times as many examples can be collected using our approach
versus relying on direct observation alone, demonstrating that by leveraging the understanding
of the crowd, it is possible to more easily train automated systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3095–3098},
numpages = {4},
keywords = {constraint finding, crowdsourcing, activity recognition},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557011,
author = {Deng, Jia and Russakovsky, Olga and Krause, Jonathan and Bernstein, Michael S. and Berg, Alex and Fei-Fei, Li},
title = {Scalable Multi-Label Annotation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557011},
doi = {10.1145/2556288.2557011},
abstract = {We study strategies for scalable multi-label annotation, or for efficiently acquiring
multiple labels from humans for a collection of items. We propose an algorithm that
exploits correlation, hierarchy, and sparsity of the label distribution. A case study
of labeling 200 objects using 20,000 images demonstrates the effectiveness of our
approach. The algorithm results in up to 6x reduction in human computation time compared
to the naive method of querying a human annotator for the presence of every object
in every image.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3099–3102},
numpages = {4},
keywords = {human computation, crowdsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251003,
author = {Takagi, Hironobu},
title = {Session Details: Accessibility},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251003},
doi = {10.1145/3251003},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557237,
author = {Carrington, Patrick and Hurst, Amy and Kane, Shaun K.},
title = {Wearables and Chairables: Inclusive Design of Mobile Input and Output Techniques for Power Wheelchair Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557237},
doi = {10.1145/2556288.2557237},
abstract = {Power wheelchair users often use and carry multiple mobile computing devices. Many
power wheelchair users have some upper body motor impairment that can make using these
devices difficult. We believe that mobile device accessibility could be improved through
designs that take into account users' functional abilities and take advantage of available
space around the wheelchair itself. In this paper we present findings from multiple
design sessions and interviews with 13 power wheelchair users and 30 clinicians, exploring
the placement and form factor possibilities for input and output on a power wheelchair.
We found that many power wheelchair users could benefit from chairable technology
that is designed to work within the workspace of the wheelchair, whether worn on the
body or mounted on he wheelchair frame. We present participants' preferences for chairable
input and output devices, and identify possible design configurations for wearable
and chairable devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3103–3112},
numpages = {10},
keywords = {participatory design, wearable computers, mobile computing, natural user interface, output, accessibility, input, power wheelchair},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557328,
author = {Manduchi, Roberto and Coughlan, James M.},
title = {The Last Meter: Blind Visual Guidance to a Target},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557328},
doi = {10.1145/2556288.2557328},
abstract = {Smartphone apps can use object recognition software to provide information to blind
or low vision users about objects in the visual environment. A crucial challenge for
these users is aiming the camera properly to take a well-framed picture of the desired
target object. We investigate the effects of two fundamental constraints of object
recognition -- frame rate and camera field of view -- on a blind person's ability
to use an object recognition smartphone app. The app was used by 18 blind participants
to find visual targets beyond arm's reach and approach them to within 30 cm. While
we expected that a faster frame rate or wider camera field of view should always improve
search performance, our experimental results show that in many cases increasing the
field of view does not help, and may even hurt, performance. These results have important
implications for the design of object recognition systems for blind users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3113–3122},
numpages = {10},
keywords = {blindness, assistive technology, wayfinding, camera-based access to information},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557085,
author = {Ye, Hanlu and Malu, Meethu and Oh, Uran and Findlater, Leah},
title = {Current and Future Mobile and Wearable Device Use by People with Visual Impairments},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557085},
doi = {10.1145/2556288.2557085},
abstract = {With the increasing popularity of mainstream wearable devices, it is critical to assess
the accessibility implications of such technologies. For people with visual impairments,
who do not always need the visual display of a mobile phone, alternative means of
eyes-free wearable interaction are particularly appealing. To explore the potential
impacts of such technology, we conducted two studies. The first was an online survey
that included 114 participants with visual impairments and 101 sighted participants;
we compare the two groups in terms of current device use. The second was an interview
and design probe study with 10 participants with visual impairments. Our findings
expand on past work to characterize a range of trends in smartphone use and accessibility
issues therein. Participants with visual impairments also responded positively to
two eyes-free wearable device scenarios: a wristband or ring and a glasses-based device.
Discussions on projected use of these devices suggest that small, easily accessible,
and discreet wearable input could positively impact the ability of people with visual
impairments to access information on the go and to participate in certain social interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3123–3132},
numpages = {10},
keywords = {accessibility, visual impairments, wearable computing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557415,
author = {Wu, Shaomei and Adamic, Lada A.},
title = {Visually Impaired Users on an Online Social Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557415},
doi = {10.1145/2556288.2557415},
abstract = {In this paper we present the first large-scale empirical study of how visually impaired
people use online social networks, specifically Facebook. We identify a sample of
50K visually impaired users, and study the activities they perform, the content they
produce, and the friendship networks they build on Facebook. We find that visually
impaired users participate on Facebook (e.g. status updates, comments, likes) as much
as the general population, and receive more feedback (i.e., comments and likes) on
average on their content. By analyzing the content produced by visually impaired users,
we find that they share their experience and issues related to vision impairment.
We also identify distinctive patterns in their language and technology use. We also
show that, compared to other users, visually impaired users have smaller social networks,
but such differences have decreased over time. Our findings have implications for
improving the utility and usability of online social networks for visually impaired
users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3133–3142},
numpages = {10},
keywords = {facebook, vision disability, social media, visually impaired users, social networking sites},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251004,
author = {Solovey, Erin},
title = {Session Details: Tangible Interactions and Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251004},
doi = {10.1145/3251004},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557016,
author = {Schmidt, Dominik and Ramakers, Raf and Pedersen, Esben W. and Jasper, Johannes and K\"{o}hler, Sven and Pohl, Aileen and Rantzsch, Hannes and Rau, Andreas and Schmidt, Patrick and Sterz, Christoph and Yurchenko, Yanina and Baudisch, Patrick},
title = {Kickables: Tangibles for Feet},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557016},
doi = {10.1145/2556288.2557016},
abstract = {We introduce the concept of tangibles that users can manipulate with their feet. We
call them kickables. Unlike traditional tangibles, kickables allow for very large
interaction surfaces as kickables reside on the ground. The main benefit of kickables
over other foot-based modalities, such as foot touch, is their strong affordance,
which we validate in two user studies. This affordance makes kickables well-suited
for walk-up installations, such as tradeshows or museum exhibits.We present a custom
design as well as five families of standard kickables to help application designers
create kickable applications faster. Each family supports multiple standard controls,
such as push buttons, switches, dials, and sliders. Each type explores a different
design principle, in particular different mechanical constraints. We demonstrate an
implementation on our pressure-sensing floor.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3143–3152},
numpages = {10},
keywords = {interactive floor, tangibles, affordance., foot-based interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557105,
author = {Liang, Rong-Hao and Chan, Liwei and Tseng, Hung-Yu and Kuo, Han-Chih and Huang, Da-Yuan and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBricks: Magnetic Building Blocks for Constructive Tangible Interactions on Portable Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557105},
doi = {10.1145/2556288.2557105},
abstract = {This work describes a novel building block system for tangible interaction design,
GaussBricks, which enables real-time constructive tangible interactions on portable
displays. Given its simplicity, the mechanical design of the magnetic building blocks
facilitates the construction of configurable forms. The form constructed by the magnetic
building blocks, which are connected by the magnetic joints, allows users to stably
manipulate with various elastic force feedback mechanisms. With an analog Hall-sensor
grid mounted to its back, a portable display determines the geometrical configuration
and detects various user interactions in real time. This work also introduce several
methods to enable shape changing, multi-touch input, and display capabilities in the
construction. The proposed building block system enriches how individuals interact
with the portable displays physically.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3153–3162},
numpages = {10},
keywords = {constructive assembly, tangible interactions, portable displays, magnetism},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556991,
author = {Pillias, Cl\'{e}ment and Robert-Bouchard, Rapha\"{e}l and Levieux, Guillaume},
title = {Designing Tangible Video Games: Lessons Learned from the Sifteo Cubes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556991},
doi = {10.1145/2556288.2556991},
abstract = {In this paper, we present a collaborative game designed for Sifteo Cubes, a new tangible
interface for multiplayer games. We discuss how this game exploits the platform's
interface to transfer some of the game mechanics into the non-digital world, and how
this approach affects both the player's experience and the design process. We present
the technical limitations encountered during game development and analyze video recordings
of play sessions with regard to the play strategies developed by the players. Then,
we identify two properties that this game shares with many other games on tangible
platforms and discuss how these properties influence both the game design process
and the player experience. We advocate that these properties provide players with
more freedom and relatedness, while helping to create an easy-to-learn and customizable
gameplay, despite their own design limitations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3163–3166},
numpages = {4},
keywords = {mixed-reality games, tangible user interface, sifteo cubes, video game design, player strategies, tangible video game},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557331,
author = {Le Goc, Mathieu and Taylor, Stuart and Izadi, Shahram and Keskin, Cem},
title = {A Low-Cost Transparent Electric Field Sensor for 3d Interaction on Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557331},
doi = {10.1145/2556288.2557331},
abstract = {We contribute a thin, transparent, and low-cost design for electric field sensing,
allowing for 3D finger and hand tracking and gestures on mobile devices. Our approach
requires no direct instrumentation of the hand or body, and is non-optical, allowing
for a compact form-factor that is resilient to ambient illumination. Our simple driver
electronics are based on an off-the-shelf chip that removes the need for building
custom analog electronics. We describe the design of our transparent electrode array,
and present a machine learning algorithm for mapping from signal measurements at the
receivers to 3D positions. We demonstrate non-contact motion gestures, and precise
3D hand and finger localization. We conclude by discussing limitations and future
work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3167–3170},
numpages = {4},
keywords = {mobile, non-optical, nui, 3d sensing, electric-field sensing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251005,
author = {Bailey, Brian},
title = {Session Details: Head-Worn Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251005},
doi = {10.1145/3251005},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557058,
author = {Ens, Barrett M. and Finnegan, Rory and Irani, Pourang P.},
title = {The Personal Cockpit: A Spatial Interface for Effective Task Switching on Head-Worn Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557058},
doi = {10.1145/2556288.2557058},
abstract = {As wearable computing goes mainstream, we must improve the state of interface design
to keep users productive with natural-feeling interactions. We present the Personal
Cockpit, a solution for mobile multitasking on head-worn displays. We appropriate
empty space around the user to situate virtual windows for use with direct input.
Through a design-space exploration, we run a series of user studies to fine-tune our
layout of the Personal Cockpit. In our final evaluation, we compare our design against
two baseline interfaces for switching between everyday mobile applications. This comparison
highlights the deficiencies of current view-fixed displays, as the Personal Cockpit
provides a 40% improvement in application switching time. We demonstrate of several
useful implementations and a discussion of important problems for future implementation
of our design on current and near-future wearable devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3171–3180},
numpages = {10},
keywords = {head-mounted display, spatial user interface, virtual window management, spatial input, task switching, multi-display environment, head-worn display},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556984,
author = {Serrano, Marcos and Ens, Barrett M. and Irani, Pourang P.},
title = {Exploring the Use of Hand-to-Face Input for Interacting with Head-Worn Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556984},
doi = {10.1145/2556288.2556984},
abstract = {We propose the use of Hand-to-Face input, a method to interact with head-worn displays
(HWDs) that involves contact with the face. We explore Hand-to-Face interaction to
find suitable techniques for common mobile tasks. We evaluate this form of interaction
with document navigation tasks and examine its social acceptability. In a first study,
users identify the cheek and forehead as predominant areas for interaction and agree
on gestures for tasks involving continuous input, such as document navigation. These
results guide the design of several Hand-to-Face navigation techniques and reveal
that gestures performed on the cheek are more efficient and less tiring than interactions
directly on the HWD. Initial results on the social acceptability of Hand-to-Face input
allow us to further refine our design choices, and reveal unforeseen results: some
gestures are considered culturally inappropriate and gender plays a role in selection
of specific Hand-to-Face interactions. From our overall results, we provide a set
of guidelines for developing effective Hand-to-Face interaction techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3181–3190},
numpages = {10},
keywords = {hmd, body interaction, hwd, head-worn display, input techniques, mobile interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557405,
author = {Lissermann, Roman and Huber, Jochen and Schmitz, Martin and Steimle, J\"{u}rgen and M\"{u}hlh\"{a}user, Max},
title = {Permulin: Mixed-Focus Collaboration on Multi-View Tabletops},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557405},
doi = {10.1145/2556288.2557405},
abstract = {We contribute Permulin, an integrated set of interaction and visualization techniques
for multi-view tabletops to support co-located collaboration across a wide variety
of collaborative coupling styles. These techniques (1) provide support both for group
work and for individual work, as well as for the transitions in-between, (2) contribute
sharing and peeking techniques to support mutual awareness and group coordination
during phases of individual work, (3) reduce interference during group work on a group
view, and (4) directly integrate with conventional multi-touch input. We illustrate
our techniques in a proof-of-concept implementation with the two example applications
of map navigation and photo collages. Results from two user studies demonstrate that
Permulin supports fluent transitions between individual and group work and exhibits
unique awareness properties that allow participants to be highly aware of each other
during tightly coupled collaboration, while being able to unobtrusively perform individual
work during loosely coupled collaboration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3191–3200},
numpages = {10},
keywords = {multi-view, personal input, collaborative coupling styles, mixed-focus collaboration, tabletop, multi touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557063,
author = {Lauber, Felix and Butz, Andreas},
title = {In-Your-Face, yet Unseen? Improving Head-Stabilized Warnings to Reduce Reaction Time},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557063},
doi = {10.1145/2556288.2557063},
abstract = {One unique property of head-mounted displays (HMDs) is that content can easily be
displayed at a fixed position within the user's field of view (head-stabilized). This
ensures that critical information (e.g. warnings) is continuously visible and can,
in principle, be perceived as quickly as possible. We examined this strategy with
a physically and visually distracted driver. We ran two consecutive studies in a driving
simulator, comparing different warning visualizations in a head-up display (HUD) and
a HMD. In an initial study, we found no significant effects of warning type or display
technology on the reaction times. In a second study, after modifying our visualization
to include a visual reference marker, we found that with only this minor change, reaction
times were significantly lower in the HMD when compared to the HUD. Our insights can
help others design better head-stabilized notifications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3201–3204},
numpages = {4},
keywords = {driver safety, head-mounted displays, head-up displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251006,
author = {Fussell, Susan},
title = {Session Details: Applications of Body Sensing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251006},
doi = {10.1145/3251006},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557060,
author = {Wang, Hao-Chuan and Lai, Chien-Tung},
title = {Kinect-Taped Communication: Using Motion Sensing to Study Gesture Use and Similarity in Face-to-Face and Computer-Mediated Brainstorming},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557060},
doi = {10.1145/2556288.2557060},
abstract = {One key difference between face-to-face (F2F) communication and computer-mediated
communication (CMC) is the availability of visual cues. It is often assumed that the
reduction of visibility in audio and video conferencing may negatively impact the
use of gesture to communicate, and thus negatively influence other outcomes. In this
paper we "Kinect-taped" F2F and CMC communication in brainstorming groups by using
motion sensors to record and analyze group members' hand movements during communication.
We investigate how different media influence gesture use and gestural similarity,
and how the use of gesture associates with level of understanding and brainstorming
performance. Implications to future research and design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3205–3214},
numpages = {10},
keywords = {computer-mediated communication, communication accommodation, kinect, non-verbal communication, gesture, motion sensing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557027,
author = {Bachynskyi, Myroslav and Oulasvirta, Antti and Palmas, Gregorio and Weinkauf, Tino},
title = {Is Motion Capture-Based Biomechanical Simulation Valid for HCI Studies? Study and Implications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557027},
doi = {10.1145/2556288.2557027},
abstract = {Motion-capture-based biomechanical simulation is a non-invasive analysis method that
yields a rich description of posture, joint, and muscle activity in human movement.
The method is presently gaining ground in sports, medicine, and industrial ergonomics,
but it also bears great potential for studies in HCI where the physical ergonomics
of a design is important. To make the method more broadly accessible, we study its
predictive validity for movements and users typical to studies in HCI. We discuss
the sources of error in biomechanical simulation and present results from two validation
studies conducted with a state-of-the-art system. Study I tested aimed movements ranging
from multitouch gestures to dancing, finding out that the critical limiting factor
is the size of movement. Study II compared muscle activation predictions to surface-EMG
recordings in a 3D pointing task. The data shows medium-to-high validity that is,
however, constrained by some characteristics of the movement and the user. We draw
concrete recommendations to practitioners and discuss challenges to developing the
method further.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3215–3224},
numpages = {10},
keywords = {physical ergonomics, biomechanical simulation, optical motion capture., validity, empirical methods},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557116,
author = {Morris, Dan and Saponas, T. Scott and Guillory, Andrew and Kelner, Ilya},
title = {RecoFit: Using a Wearable Sensor to Find, Recognize, and Count Repetitive Exercises},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557116},
doi = {10.1145/2556288.2557116},
abstract = {Although numerous devices exist to track and share exercise routines based on running
and walking, these devices offer limited functionality for strength-training exercises.
We introduce RecoFit, a system for automatically tracking repetitive exercises - such
as weight training and calisthenics - via an arm-worn inertial sensor. Our goal is
to provide real-time and post-workout feedback, with no user-specific training and
no intervention during a workout. Toward this end, we address three challenges: (1)
segmenting exercise from intermittent non-exercise periods, (2) recognizing which
exercise is being performed, and (3) counting repetitions. We present cross-validation
results on our training data and results from a study assessing the final system,
totaling 114 participants over 146 sessions. We achieve precision and recall greater
than 95% in identifying exercise periods, recognition of 99%, 98%, and 96% on circuits
of 4, 7, and 13 exercises respectively, and counting that is accurate to ±1 repetition
93% of the time. These results suggest that our approach enables a new category of
fitness tracking devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3225–3234},
numpages = {10},
keywords = {machine learning, fitness, inertial sensors},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556957,
author = {Vosoughi, Soroush},
title = {Improving Automatic Speech Recognition through Head Pose Driven Visual Grounding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556957},
doi = {10.1145/2556288.2556957},
abstract = {In this paper, we present a multimodal speech recognition system for real world scene
description tasks. Given a visual scene, the system dynamically biases its language
model based on the content of the visual scene and visual attention of the speaker.
Visual attention is used to focus on likely objects within the scene. Given a spoken
description the system then uses the visually biased language model to process the
speech. The system uses head pose as a proxy for the visual attention of the speaker.
Readily available standard computer vision algorithms are used to recognize the objects
in the scene and automatic real time head pose estimation is done using depth data
captured via a Microsoft Kinect. The system was evaluated on multiple participants.
Overall, incorporating visual information into the speech recognizer greatly improved
speech recognition accuracy. The rapidly decreasing cost of 3D sensing technologies
such as the Kinect allows systems with similar underlying principles to be used for
many speech recognition tasks where there is visual information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3235–3238},
numpages = {4},
keywords = {automatic speech recognition, visual attention, visual grounding, language models, head pose estimation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251007,
author = {Shami, N. Sadat},
title = {Session Details: Urban Communities and Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251007},
doi = {10.1145/3251007},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557319,
author = {Masden, Christina A. and Grevet, Catherine and Grinter, Rebecca E. and Gilbert, Eric and Edwards, W. Keith},
title = {Tensions in Scaling-up Community Social Media: A Multi-Neighborhood Study of Nextdoor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557319},
doi = {10.1145/2556288.2557319},
abstract = {This paper presents a study of Nextdoor, a social media system designed to support
local neighborhoods. While not the first system designed to support community engagement,
Nextdoor has a number of attributes that make it distinct. Our study, across three
communities in a major U.S. city, illustrates that Nextdoor inhabits an already-rich
ecosystem of community-oriented social media, but is being appropriated by its users
for use in different ways than these existing media. Nextdoor also raises tensions
in how it defines the boundaries of neighborhoods, and in the privacy issues it raises
among its users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3239–3248},
numpages = {10},
keywords = {civic engagement, social media, local social media, nextdoor},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557401,
author = {Cranshaw, Justin B. and Luther, Kurt and Kelley, Patrick Gage and Sadeh, Norman},
title = {Curated City: Capturing Individual City Guides through Social Curation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557401},
doi = {10.1145/2556288.2557401},
abstract = {We report on our design of Curated City, a website that lets people build their own
personal guide to the city's neighborhoods by chronicling their favorite experiences.
Although users make their own personal guides, they are immersed in a social curatorial
experience where they are influenced directly and indirectly by the guides of others.
We use a 2-week field trial involving 20 residents of Pittsburgh as a technological
probe to explore the initial design decisions, and we further refine the design landscape
through subject interviews. Based on this study, we identify a set of design recommendations
for building scalable social platforms for curating the experiences of the city.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3249–3258},
numpages = {10},
keywords = {mental maps, social curation, local search, neighborhoods, urban computing, location-based services, social computing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557053,
author = {Laureyssens, Thomas and Coenen, Tanguy and Claeys, Laurence and Mechant, Peter and Criel, Johan and Vande Moere, Andrew},
title = {ZWERM: A Modular Component Network Approach for an Urban Participation Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557053},
doi = {10.1145/2556288.2557053},
abstract = {As information technology is increasingly embedded in our cities, opportunities arise
to design novel applications that benefit urban communities. We describe the design
and evaluation of ZWERM (Dutch for the term 'swarm'), a public game that was specifically
designed for augmenting community participation in urban neighborhoods. A network
of ten components has been designed, some of which had different interfaces and design
approaches: from totem-like Trees for gathering around with RFID cards to playful
Sparrows that react on whistle sounds. After implementing the urban game in two city
neighborhoods, we investigated the impact of each of these components on their communities.
Our insights are useful for the public interaction design of future urban, interactive
networks that aim to positively influence community participation and social cohesion.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3259–3268},
numpages = {10},
keywords = {gamification, social engagement, urban game, social cohesion, social informatics, network, urban intervention},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557266,
author = {McGookin, David K. and Brewster, Stephen A. and Christov, Georgi},
title = {Studying Digital Graffiti as a Location-Based Social Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557266},
doi = {10.1145/2556288.2557266},
abstract = {Increasing amounts of geo-tagged social media have led to interest in how that media
can be re-integrated into the physical environment. Yet, although location information
is often automatically appended to media, little is know about how users consider
location in its creation and viewing. Using Graffiti as a design meme, we developed
a novel social media service to investigate these issues. A two week field study showed
how users incorporated both utilitarian and playful aspects of location into their
social media creation, as well as revealing a disconnect between the location-media
relationship intended by creators and perceived by viewers. We outline implications
of our work for services that seek to repurpose existing geo-tagged social media in
the design of novel services.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3269–3278},
numpages = {10},
keywords = {pico projection, graffiti, digigraff, geo-social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250969,
author = {Geerts, David},
title = {Session Details: Social Media Usage},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250969},
doi = {10.1145/3250969},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556977,
author = {Chan, Rosanna Yuen-Yan and Li, Silu and Hui, Diane},
title = {Social Epistemic Cognition in Online Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556977},
doi = {10.1145/2556288.2556977},
abstract = {Social media and online social networks dramatically change the way in which knowledge
is acquired and disseminated. How do we re-understand about human knowledge and knowing?
This work aims at extending the current understanding of human epistemic cognition
in online social environments, where epistemic cognition refers to cognitions and
cognitive processes related to epistemic matters such as knowledge and beliefs justification.
We approach our inquiry with mixed methods: (1) quantitative study to test whether
epistemic cognition might differ in individual and social contexts, and whether online
interactions might mediate the later; and (2) social cognitive task analysis with
interviews to manifest the intricate interplay of dynamics between social epistemic
cognition and online interactions. We introduce the new construct of social epistemic
cognition and contribute to the field of HCI with an evolved theory which states that
epistemic cognition can be promoted in online social environments as mediated by online
interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3289–3298},
numpages = {10},
keywords = {epistemic cognition, cognitive task analysis, online interactions, learning sciences., social epistemology, cscl},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557143,
author = {Yue, Yanzhen and Ma, Xiaojuan and Jiang, Zhenhui},
title = {Share Your View: Impact of Co-Navigation Support and Status Composition in Collaborative Online Shopping},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557143},
doi = {10.1145/2556288.2557143},
abstract = {Collaborative online shopping, an emerging paradigm in e-commerce, allows remote shoppers
to extend purchase-oriented social interactions into the digital environment. Online
vendors have been experimenting ways to facilitate this activity. However, more research
needs to be done on identifying what feature can create a pleasing shopping experience
and ultimately encourage spending. In this paper, we present an exploration of the
impact of co-navigation supports, including location cue, split screen, and shared
view, on the experiences and performance of 60 co-shopper dyads. We also studied if
status composition of shopping companions played a role in this process. By analyzing
about 1800 minutes of eye-tracking data, video footages, and web logs, we found that
split screen encouraged more diverse product search, shared view enabled better coordination,
and location cue was the least distracting. Co-buyers achieved better factual and
inference understanding, though buyer-advisor dyads were more likely to stay together.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3299–3308},
numpages = {10},
keywords = {split screen, location cue, buyer-advisor, collaborative online shopping, co-buyers, status composition, shared view, eye-tracking, co-navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557384,
author = {Reitberger, Wolfgang H. and Spreicer, Wolfgang and Fitzpatrick, Geraldine},
title = {Nutriflect: Reflecting Collective Shopping Behavior and Nutrition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557384},
doi = {10.1145/2556288.2557384},
abstract = {A poor nutritional state, as is the case for many people today, can increase risks
for cancer, cardiovascular disease and obesity. Technology supported approaches could
potentially be used to positively influence food consumption. We present the Nutriflect
system, which utilizes users' shopping data to inform them about their long term shopping
behavior. In an initial study we conducted structured interviews in grocery stores.
Based on the results we implemented a system that visualized a household's collective
shopping information via situated displays. The aim was to raise awareness about shopping
habits and to enable reflection about nutrition without burdening the users with the
manual entry of their eating habits. We evaluated the system in a 4 week field study
in 8 households with 21 users. The results indicate that contextually situated displays,
showing shopping patterns against personal nutrition goals, can foster a reflective
and respectful approach towards better shopping and nutrition.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3309–3318},
numpages = {10},
keywords = {field study, reflection, behavior change, nutrition, situated displays, shopping, awareness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556973,
author = {Pielot, Martin and de Oliveira, Rodrigo and Kwak, Haewoon and Oliver, Nuria},
title = {Didn't You See My Message? Predicting Attentiveness to Mobile Instant Messages},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556973},
doi = {10.1145/2556288.2556973},
abstract = {Mobile instant messaging (e.g., via SMS or WhatsApp) often goes along with an expectation
of high attentiveness, i.e., that the receiver will notice and read the message within
a few minutes. Hence, existing instant messaging services for mobile phones share
indicators of availability, such as the last time the user has been online. However,
in this paper we not only provide evidence that these cues create social pressure,
but that they are also weak predictors of attentiveness. As remedy, we propose to
share a machine-computed prediction of whether the user will view a message within
the next few minutes or not. For two weeks, we collected behavioral data from 24 users
of mobile instant messaging services. By the means of machine-learning techniques,
we identified that simple features extracted from the phone, such as the user's interaction
with the notification center, the screen activity, the proximity sensor, and the ringer
mode, are strong predictors of how quickly the user will attend to the messages. With
seven automatically selected features our model predicts whether a phone user will
view a message within a few minutes with 70.6% accuracy and a precision for fast attendance
of 81.2%},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3319–3328},
numpages = {10},
keywords = {attentiveness, prediction, mobile devices, availability, asynchronous communication, messaging},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250970,
author = {Forlizzi, Jodi},
title = {Session Details: Games and Education},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250970},
doi = {10.1145/3250970},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557393,
author = {Harpstead, Erik and MacLellan, Christopher J. and Aleven, Vincent and Myers, Brad A.},
title = {Using Extracted Features to Inform Alignment-Driven Design Ideas in an Educational Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557393},
doi = {10.1145/2556288.2557393},
abstract = {As educational games have become a larger field of study, there has been a growing
need for analytic methods that can be used to assess game design and inform iteration.
While much previous work has focused on the measurement of student engagement or learning
at a gross level, we argue that new methods are necessary for measuring the alignment
of a game to its target learning goals at an appropriate level of detail to inform
design decisions. We present a novel technique that we have employed to examine alignment
in an open-ended educational game. The approach is based on examining how the game
reacts to representative student solutions that do and do not obey target principles.
We demonstrate this method using real student data and discuss how redesign might
be informed by these techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3329–3338},
numpages = {10},
keywords = {game user research, educational games, analytics, alignment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557157,
author = {O'Rourke, Eleanor and Haimovitz, Kyla and Ballweber, Christy and Dweck, Carol and Popovi\'{c}, Zoran},
title = {Brain Points: A Growth Mindset Incentive Structure Boosts Persistence in an Educational Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557157},
doi = {10.1145/2556288.2557157},
abstract = {There is great interest in leveraging video games to improve student engagement and
motivation. However, educational games are not uniformly effective, and little is
known about how in-game rewards affect children's learning-related behavior. In this
work, we argue that educational games can be improved by fundamentally changing their
incentive structures to promote the growth mindset, or the belief that intelligence
is malleable. We present "brain points," a system that encourages the development
of growth mindset behaviors by directly incentivizing effort, use of strategy, and
incremental progress. Through a study of 15,000 children, we show that the "brain
points" system encourages more low-performing students to persist in the educational
game Refraction when compared to a control, and increases overall time played, strategy
use, and perseverance after challenge. We believe that this growth mindset incentive
structure has great potential in many educational environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3339–3348},
numpages = {10},
keywords = {incentive structures, growth mindset, educational games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557392,
author = {Liu, Yun-En and Mandel, Travis and Brunskill, Emma and Popovi\'{c}, Zoran},
title = {Towards Automatic Experimentation of Educational Knowledge},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557392},
doi = {10.1145/2556288.2557392},
abstract = {We present a general automatic experimentation and hypothesis generation framework
that utilizes a large set of users to explore the effects of different parts of an
intervention parameter space on any objective function. We also incorporate importance
sampling, allowing us to run these automatic experiments even if we cannot give out
the exact intervention distributions that we want. To show the utility of this framework,
we present an implementation in the domain of fractions and numberlines, using an
online educational game as the source of players. Our system is able to automatically
explore the parameter space and generate hypotheses about what types of numberlines
lead to maximal short-term transfer; testing on a separate dataset shows the most
promising hypotheses are valid. We briefly discuss our results in the context of the
wider educational literature, showing that one of our results is not explained by
current research on multiple fraction representations, thus proving our ability to
generate potentially interesting hypotheses to test.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3349–3358},
numpages = {10},
keywords = {education, datamining, games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557074,
author = {Wohn, Donghee Yvette},
title = {Spending Real Money: Purchasing Patterns of Virtual Goods in an Online Social Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557074},
doi = {10.1145/2556288.2557074},
abstract = {Researchers have found that 'social' factors contribute to purchasing intentions of
virtual goods in an online social game, but little is known about actual purchasing
behavior. Study 1 examined the relationship between social factors and virtual goods
purchasing patterns using large scale data obtained by server logs of an online social
game. Exchange of virtual goods and number of friends increased the likelihood of
spending real money compared to no spending. Among those who did spend real money,
giving virtual goods to others was the strongest factor associated with the amount
of spending. Study 2 examined purchasing patterns of players who spent real money:
high real-money spenders were buying items for visual customization while low spenders
were buying consumable items necessary to sustain playing the game.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3359–3368},
numpages = {10},
keywords = {big data, consumer behavior, e-commerce, social exchange, social game, virtual goods, customization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250971,
author = {Ogan, Amy},
title = {Session Details: Learning and Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250971},
doi = {10.1145/3250971},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556954,
author = {Li, Wei and Grossman, Tovi and Fitzmaurice, George},
title = {CADament: A Gamified Multiplayer Software Tutorial System},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556954},
doi = {10.1145/2556288.2556954},
abstract = {We present CADament, a gamified multiplayer tutorial system for learning AutoCAD.
Compared with existing gamified software tutorial systems, CADament generates engaging
learning experience through competitions. We investigate two variations of our game,
where over-the-shoulder learning was simulated by providing viewports into other player's
screens. We introduce an empirical lab study methodology where participants compete
with one another, and we study knowledge transfer effects by tracking the migration
of strategies between players during the study session. Our study shows that CADament
has an advantage over pre-authored tutorials for improving learners' performance,
increasing motivation, and stimulating knowledge transfer.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3369–3378},
numpages = {10},
keywords = {tutorial, game, multiplayer, learning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557217,
author = {Dontcheva, Mira and Morris, Robert R. and Brandt, Joel R. and Gerber, Elizabeth M.},
title = {Combining Crowdsourcing and Learning to Improve Engagement and Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557217},
doi = {10.1145/2556288.2557217},
abstract = {Crowdsourcing complex creative tasks remains difficult, in part because these tasks
require skilled workers. Most crowdsourcing platforms do not help workers acquire
the skills necessary to accomplish complex creative tasks. In this paper, we describe
a platform that combines learning and crowdsourcing to benefit both the workers and
the requesters. Workers gain new skills through interactive step-by-step tutorials
and test their knowledge by improving real-world images submitted by requesters. In
a series of three deployments spanning two years, we varied the design of our platform
to enhance the learning experience and improve the quality of the crowd work. We tested
our approach in the context of LevelUp for Photoshop, which teaches people how to
do basic photograph improvement tasks using Adobe Photoshop. We found that by using
our system workers gained new skills and produced high-quality edits for requested
images, even if they had little prior experience editing images.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3379–3388},
numpages = {10},
keywords = {training, games, crowdsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557281,
author = {Dunwell, Ian and de Freitas, Sara and Petridis, Panagiotis and Hendrix, Maurice and Arnab, Sylvester and Lameras, Petros and Stewart, Craig},
title = {A Game-Based Learning Approach to Road Safety: The Code of Everand},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557281},
doi = {10.1145/2556288.2557281},
abstract = {Game and gamification elements are increasingly seeing use as part of interface designs
for applications seeking to engage and retain users whilst transferring information.
This paper presents an evaluation of a game-based approach seeking to improve the
road safety behaviour amongst children aged 9-15 within the UK, made available outside
of a classroom context as an online, browser-based, free-to-play game. The paper reports
on data for 99,683 players over 315,882 discrete logins, supplemented by results from
a nationally-representative survey of children at UK schools (n=1,108), an incentivized
survey of the player-base (n=1,028), and qualitative data obtained through a series
of one-to-one interviews aged 9-14 (n=28). Analysis demonstrates the reach of the
game to its target demographic, with 88.13% of players within the UK. A 3.94 male/female
ratio was observed amongst players surveyed, with an age distribution across the target
range of 9-15. Noting mean and median playtimes of 93 and 31 minutes (n=99,683), it
is suggested such an approach to user engagement and retention can surpass typical
contact times obtained through other forms of web-based content. The size of the player-base
attracted to the game and players' qualitative feedback demonstrates the potential
for serious games deployed on a national scale.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3389–3398},
numpages = {10},
keywords = {road safety, game-based interfaces, e-learning, serious games, gamification, attitudinal change},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557368,
author = {Monserrat, Toni-Jan Keith Palma and Li, Yawen and Zhao, Shengdong and Cao, Xiang},
title = {L.IVE: An Integrated Interactive Video-Based Learning Environment},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557368},
doi = {10.1145/2556288.2557368},
abstract = {In this paper, we introduce L.IVE: an online interactive video-based learning environment
with an alternative design and architecture that integrates three major interface
components: video, comment threads, and assessments. This is in contrast with the
approach of existing interfaces which visually separate these components. Our study,
which compares L.IVE with existing popular video-based learning environments, suggests
advantages in this integrated approach as compared to the separated approach in learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3399–3402},
numpages = {4},
keywords = {l.ive, video-based online learning, interactive video},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250972,
author = {Cherry, Erin},
title = {Session Details: Persuasive Technologies and Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250972},
doi = {10.1145/3250972},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557099,
author = {Hsu, Anne and Yang, Jing and Yilmaz, Yigit Han and Haque, Md Sanaul and Can, Cengiz and Blandford, Ann E.},
title = {Persuasive Technology for Overcoming Food Cravings and Improving Snack Choices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557099},
doi = {10.1145/2556288.2557099},
abstract = {A central challenge in weight management is the difficulty of overcoming desires for
excessive and unhealthy food. Yet, studies show that when people are able to resist
their desires for unhealthy choices, they experience pride and satisfaction. In order
to alleviate the former and support the latter, we designed, implemented and tested
a mobile application for improving snacking behavior. Our application delivers a food
craving reduction intervention at the moment of need and allows users to track how
often they successfully resisted cravings. Our craving reduction intervention is based
on recent research that shows that food cravings can be reduced through imagery techniques.
We conducted a week-long evaluation of our application, comparing the effectiveness
of our application to a basic tracking application. We found that our imagery application
significantly reduced both overall snacking and unhealthy snacking compared to a simple
snack-tracking application.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3403–3412},
numpages = {10},
keywords = {behavior change, wellness, weight management, persuasive technologies, mobile, user-centered design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556962,
author = {Gerling, Kathrin Maria and Mandryk, Regan L. and Birk, Max Valentin and Miller, Matthew and Orji, Rita},
title = {The Effects of Embodied Persuasive Games on Player Attitudes toward People Using Wheelchairs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556962},
doi = {10.1145/2556288.2556962},
abstract = {People using wheelchairs face barriers in their daily lives, many of which are created
by people who surround them. Promoting positive attitudes towards persons with disabilities
is an integral step in removing these barriers and improving their quality of life.
In this context, persuasive games offer an opportunity of encouraging attitude change.
We created a wheelchair-controlled persuasive game to study how embodied interaction
can be applied to influence player attitudes over time. Our results show that the
game intervention successfully raised awareness for challenges that people using wheelchairs
face, and that embodied interaction is a more effective approach than traditional
input in terms of retaining attitude change over time. Based on these findings, we
provide design strategies for embodied interaction in persuasive games, and outline
how our findings can be leveraged to help designers create effective persuasive experiences
beyond games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3413–3422},
numpages = {10},
keywords = {attitude change, persuasive games, embodied interaction, disability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557390,
author = {Ruggiero, Dana N.},
title = {Spent: Changing Students' Affective Learning toward Homelessness through Persuasive Video Game Play},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557390},
doi = {10.1145/2556288.2557390},
abstract = {To investigate whether a persuasive game may serve as a way to increase affective
learning about homelessness, this study examined the effects of procedural rhetoric
and ethos in a video game designed to put the player in the shoes of an almost-homeless
person. Data were collected from 5139 students across four states. Examination revealed
that playing the game or doing the reading significantly increased the affective learning
score after treatment with the game group scoring 1.57 points higher and the reading
group scoring .66 points higher out of a score of 6. Findings indicate that students
who played Spent sustained significantly higher scores after three weeks. Overall,
findings suggest that when students play a video game that is designed using persuasive
mechanics an affective change can be measured empirically.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3423–3432},
numpages = {10},
keywords = {affective learning, video games, persuasive mechanics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557418,
author = {Fiore, Andrew T. and Cheshire, Coye and Shaw Taylor, Lindsay and Mendelsohn, G.A.},
title = {Incentives to Participate in Online Research: An Experimental Examination of "Surprise" Incentives},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557418},
doi = {10.1145/2556288.2557418},
abstract = {The recruitment of participants for online survey research presents many challenges.
In this work, we present four experiments examining how two different kinds of "surprise"
financial incentives affect the rate of participation in a longitudinal study when
participants are initially solicited with either an appeal to intrinsic motivation
to participate in research or one that also offers extrinsic financial incentives.
We find that unexpected financial incentives ("existence surprises") presented to
people who click a recruitment advertisement focused on intrinsic incentives lead
to a lower recruitment rate than do the same incentives offered to those who clicked
an advertisement that led them to expect it. However, when potential participants
expect a financial incentive, surprising them with a higher amount ("amount surprises")
yields a higher recruitment rate. We interpret these results in the context of crowding
theory. Neither type of surprise affected ongoing participation, measured as the number
of questions and questionnaires completed over the course of the study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3433–3442},
numpages = {10},
keywords = {motivation, incentives, online research recruitment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250973,
author = {Hilliges, Otmar},
title = {Session Details: Whole Body Sensing and Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250973},
doi = {10.1145/3250973},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556989,
author = {Schwarz, Julia and Marais, Charles Claudius and Leyvand, Tommer and Hudson, Scott E. and Mankoff, Jennifer},
title = {Combining Body Pose, Gaze, and Gesture to Determine Intention to Interact in Vision-Based Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556989},
doi = {10.1145/2556288.2556989},
abstract = {Vision-based interfaces, such as those made popular by the Microsoft Kinect, suffer
from the Midas Touch problem: every user motion can be interpreted as an interaction.
In response, we developed an algorithm that combines facial features, body pose and
motion to approximate a user's intention to interact with the system. We show how
this can be used to determine when to pay attention to a user's actions and when to
ignore them. To demonstrate the value of our approach, we present results from a 30-person
lab study conducted to compare four engagement algorithms in single and multi-user
scenarios. We found that combining intention to interact with a 'raise an open hand
in front of you' gesture yielded the best results. The latter approach offers a 12%
improvement in accuracy and a 20% reduction in time to engage over a baseline 'wave
to engage' gesture currently used on the Xbox 360.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3443–3452},
numpages = {10},
keywords = {vision-based input, user engagement, input segmentation, learned models, free-space interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557043,
author = {Hayashi, Eiji and Maas, Manuel and Hong, Jason I.},
title = {Wave to Me: User Identification Using Body Lengths and Natural Gestures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557043},
doi = {10.1145/2556288.2557043},
abstract = {We introduce a body-based identification system that leverages individual differences
in body segment lengths and hand waving gesture patterns. The system identifies users
based on a two-second hand waving gesture captured by a Microsoft Kinect. To evaluate
our system, we collected 8640 gesture measurements from 75 participants through two
lab studies and a field study. In the first lab study, we evaluated the feasibility
of our concept and basic properties of features to narrow down the design space. In
the second lab study, our system achieved a 1% equal error rate in user identification
among seven registered users after two weeks following initial registration. We also
found that our system was robust even when lower body segments could not be measured
because of occlusions. In the field study, our system achieved 0.5 to 1.6% equal error
rates, demonstrating that the system also works well in ecologically valid situations.
Lastly, throughout the studies, our participants were positive about the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3453–3462},
numpages = {10},
keywords = {gesture, natural user interface, user identification},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557101,
author = {Cheng, Lung-Pan and L\"{u}hne, Patrick and Lopes, Pedro and Sterz, Christoph and Baudisch, Patrick},
title = {Haptic Turk: A Motion Platform Based on People},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557101},
doi = {10.1145/2556288.2557101},
abstract = {Motion platforms are used to increase the realism of virtual interaction. Unfortunately,
their size and weight is proportional to the size of what they actuate. We present
haptic turk, a different approach to motion platforms that is light and mobile. The
key idea is to replace motors and mechanical components with humans. All haptic turk
setups consist of a player who is supported by one or more turkers. The player enjoys
an interactive experience, such as a flight simulation. The motion in the player's
experience is generated by the turkers who manually lift, tilt, and push the player's
limbs or torso. To get the timing and force right, timed motion instructions in a
format familiar from rhythm games are displayed on turkers' mobile devices, which
they attach to the player's body. We demonstrate a range of installations based on
mobile phones, projectors, and head-mounted displays. In our user study, participants
rated not only the experience as player as enjoyable (6.1/7), but also the experience
as a turker (4.4/7). The approach of leveraging humans allows us to deploy our approach
anytime anywhere, as we demonstrate by experimentally deploying at an art festival
in the Nevada desert.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3463–3472},
numpages = {10},
keywords = {immersion, haptics, motion platform, force-feedback},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556965,
author = {Downs, John and Vetere, Frank and Howard, Steve and Loughnan, Steve and Smith, Wally},
title = {Audience Experience in Social Videogaming: Effects of Turn Expectation and Game Physicality},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556965},
doi = {10.1145/2556288.2556965},
abstract = {Videogames are often played socially with both co-players and audiences. Audience
members' experiences are not well understood, nor are the factors of videogaming sessions
that influence their experience. We conducted a study to examine the effects of game
physicality and turn anticipation on audience members' experiences in social videogaming
sessions. Pairs of participants played games under three conditions of physicality
(controller-based, Wii, and Kinect) and their expectation of turn-taking was manipulated.
Their enjoyment, game engagement, social engagement and sense of participation were
measured. We found that the introduction of turn-taking into the session had positive
effects for audience members -- both anticipated and residual play effects -- and
that Kinect gameplay resulted in a more enjoyable experience for audience members.
We argue that audience members' experience changes as they become more active within
a session, and suggest there are design opportunities between purely active 'players'
and passive 'audience members'.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3473–3482},
numpages = {10},
keywords = {audience experience, social gaming, physical videogames, turn-taking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250974,
author = {Forlines, Clifton},
title = {Session Details: Novel Mobile Displays and Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250974},
doi = {10.1145/3250974},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557208,
author = {Sahami Shirazi, Alireza and Abdelrahman, Yomna and Henze, Niels and Schneegass, Stefan and Khalilbeigi, Mohammadreza and Schmidt, Albrecht},
title = {Exploiting Thermal Reflection for Interactive Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557208},
doi = {10.1145/2556288.2557208},
abstract = {Thermal cameras have recently drawn the attention of HCI researchers as a new sensory
system enabling novel interactive systems. They are robust to illumination changes
and make it easy to separate human bodies from the image background. Far-infrared
radiation, however, has another characteristic that distinguishes thermal cameras
from their RGB or depth counterparts, namely thermal reflection. Common surfaces reflect
thermal radiation differently than visual light and can be perfect thermal mirrors.
In this paper, we show that through thermal reflection, thermal cameras can sense
the space beyond their direct field-of-view. A thermal camera can sense areas besides
and even behind its field-of-view through thermal reflection. We investigate how thermal
reflection can increase the interaction space of projected surfaces using camera-projection
systems. We moreover discuss the reflection characteristics of common surfaces in
our vicinity in both the visual and thermal radiation bands. Using a proof-of-concept
prototype, we demonstrate the increased interaction space for hand-held camera-projection
system. Furthermore, we depict a number of promising application examples that can
benefit from the thermal reflection characteristics of surfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3483–3492},
numpages = {10},
keywords = {camera-projector system, roughness, heat, thermal imaging, reflection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557325,
author = {Martinez Plasencia, Diego and Joyce, Edward and Subramanian, Sriram},
title = {MisTable: Reach-through Personal Screens for Tabletops},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557325},
doi = {10.1145/2556288.2557325},
abstract = {We present MisTable, a tabletop system that combines a conventional horizontal interactive
surface with personal screens between the user and the tabletop surface. These personal
screens, built using fog, are both see-through and reach-through. Being see-through
provides direct line of sight of the personal screen and the elements behind it on
the tabletop. Being reach-through allows the user to switch from interacting with
the personal screen to reaching through it to interact with the tabletop or the space
above it. The personal screen allows a range of customisations and novel interactions
such as presenting 2D personal contents on the screen, 3D contents above the tabletop
or augmenting and relighting tangible objects differently for each user. Besides,
having a personal screen for each user allows us to customize the view of each of
them according to their identity or preferences. Finally, the personal screens preserve
all well-established tabletop interaction techniques like touch and tangible interactions.
We explore the challenges in building such a reach-through system through a proof-of-concept
implementation and discuss the possibilities afforded by the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3493–3502},
numpages = {10},
keywords = {fog screens., see-through displays, reach-through displays, tabletops systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557306,
author = {Ahmaniemi, Teemu T. and Kildal, Johan and Haveri, Merja},
title = {What is a Device Bend Gesture Really Good For?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557306},
doi = {10.1145/2556288.2557306},
abstract = {Device deformation allows new types of gestures to be used in interaction. We identify
that the gesture/use-case pairings proposed by interaction designers are often driven
by factors relating improved tangibility, spatial directionality and strong metaphorical
bonds. With this starting point, we argue that some of the designs may not make use
of the full potential of deformation gestures as continuous, bipolar input techniques.
In two user studies, we revisited the basics of deformation input by taking a new
systematic look at the question of matching gestures with use cases. We observed comparable
levels of UX when using bend input in different continuous bipolar interactions, irrespective
of the choice of tangibility, directionality and metaphor. We concluded that device
bend gestures use their full potential when used to control continuous bipolar parameters,
and when quick reactions are needed. From our studies, we also identify relative strengths
of absolute and relative mappings, and report a Fitts' law study for device bending
input.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3503–3512},
numpages = {10},
keywords = {absolute mapping, fitts' law, organic ui, relative mapping, bend input, device deformation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557075,
author = {Winkler, Christian and L\"{o}chtefeld, Markus and Dobbelstein, David and Kr\"{u}ger, Antonio and Rukzio, Enrico},
title = {SurfacePhone: A Mobile Projection Device for Single- and Multiuser Everywhere Tabletop Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557075},
doi = {10.1145/2556288.2557075},
abstract = {To maintain a mobile form factor, the screen real estate of a mobile device canIn
this paper we present SurfacePhone; a novel configuration of a projector phone which
aligns the projector to project onto a physical surface to allow tabletop-like interaction
in a mobile setup. The projection is created behind the upright standing phone and
is touch and gesture-enabled. Multiple projections can be merged to create shared
spaces for multi-user collaboration. We investigate this new setup, starting with
the concept that we evaluated with a concept prototype. Furthermore we present our
technical prototype, a mobile phone case with integrated projector that allows for
the aforementioned interaction. We discuss its technical requirements and evaluate
the accuracy of interaction in a second user study. We conclude with lessons learned
and design guidelines.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3513–3522},
numpages = {10},
keywords = {projector phone, mobile multi display environment, interactive surfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250975,
author = {Bardzell, Jeffrey},
title = {Session Details: HCI Paradigms: Past, Present and Future},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250975},
doi = {10.1145/3250975},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557004,
author = {Hornb\ae{}k, Kasper and Sander, S\o{}ren S. and Bargas-Avila, Javier Andr\'{e}s and Grue Simonsen, Jakob},
title = {Is Once Enough? On the Extent and Content of Replications in Human-Computer Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557004},
doi = {10.1145/2556288.2557004},
abstract = {A replication is an attempt to confirm an earlier study's findings. It is often claimed
that research in Human-Computer Interaction (HCI) contains too few replications. To
investigate this claim we examined four publication outlets (891 papers) and found
3% attempting replication of an earlier result. The replications typically confirmed
earlier findings, but treated replication as a confirm/not-confirm decision, rarely
analyzing effect sizes or comparing in depth to the replicated paper. When asked,
most authors agreed that their studies were replications, but rarely planned them
as such. Many non-replication studies could have corroborated earlier work if they
had analyzed data differently or used minimal effort to collect extra data. We discuss
what these results mean to HCI, including how reporting of studies could be improved
and how conferences/journals may change author instructions to get more replications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3523–3532},
numpages = {10},
keywords = {replications},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557185,
author = {Sun, Huatong and Hart-Davidson, William F.},
title = {Binding the Material and the Discursive with a Relational Approach of Affordances},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557185},
doi = {10.1145/2556288.2557185},
abstract = {As Norman's vision of affordances developed twenty-six years ago is unable to address
complex challenges faced by today's designers, we outline a view of affordances as
discursive relations in HCI design. This argument is framed in the discussion of a
larger trend of work beyond the HCI field, the scholarship on relational affordances
from the fields of communication and organization studies. Through comparison and
interrogation, we maintain a relational approach of affordances that bind the material
and the discursive will help us to address design issues such as discursive power,
cultural values, performed identities, mediated agency, and articulated voices in
this increasingly globalized world and design culturally sensitive technology for
transformation and emancipation. With a few cases, this paper deciphers the hidden
power relationship of interaction design and suggests ways of we should design for
social affordances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3533–3542},
numpages = {10},
keywords = {cross-cultural design, ideology, affordance, culture, hci, discursive, hci4d, materiality, critical design, identity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557111,
author = {Kuutti, Kari and Bannon, Liam J.},
title = {The Turn to Practice in HCI: Towards a Research Agenda},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557111},
doi = {10.1145/2556288.2557111},
abstract = {This paper argues that a new paradigm for HCI research, which we label the 'practice'
perspective, has been emerging in recent years. This stands in contrast to the prevailing
mainstream HCI paradigm, which we term the 'interaction' perspective. The 'practice
turn', as it has been dubbed in the social sciences, provides a conceptual frame to
organize a variety of issues emerging in more recent HCI research. While this approach
has been present in certain strands of HCI research for some time, it has not been
articulated fully to date. In this paper, we provide a short account of the main tenets
of this perspective, and then show how it can illuminate some of the recent debates
within HCI. Our argument is one which does not seek to replace extant HCI theories,
but rather to provide an alternative, complementary theoretical lens which may illuminate
the present confusion among both researchers and practitioners as to the direction
of HCI. The paper articulates a set of issues which can help direct HCI research programs,
as well as highlighting the potential contribution of the HCI field to this practice
approach itself, in terms of a more nuanced understanding of emerging practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3543–3552},
numpages = {10},
keywords = {theory, methodology, practice, research},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556969,
author = {Liu, Yong and Goncalves, Jorge and Ferreira, Denzil and Xiao, Bei and Hosio, Simo and Kostakos, Vassilis},
title = {CHI 1994-2013: Mapping Two Decades of Intellectual Progress through Co-Word Analysis},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556969},
doi = {10.1145/2556288.2556969},
abstract = {This study employs hierarchical cluster analysis, strategic diagrams and network analysis
to map and visualize the intellectual landscape of the CHI conference on Human Computer
Interaction through the use of co-word analysis. The study quantifies and describes
the thematic evolution of the field based on a total of 3152 CHI articles and their
associated 16035 keywords published between 1994 and 2013. The analysis is conducted
for two time periods (1994-2003, 2004-2013) and a comparison between them highlights
the underlying trends in our community. More significantly, this study identifies
the evolution of major themes in the discipline, and highlights individual topics
as popular, core, or backbone research topics within HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3553–3562},
numpages = {10},
keywords = {co-word analysis, bibliometric study, coherence, conceptual evolution, hci, cohesion},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250976,
author = {Gergle, Darren},
title = {Session Details: PolitiCHI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250976},
doi = {10.1145/3250976},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557197,
author = {De Choudhury, Munmun and Monroy-Hern\'{a}ndez, Andr\'{e}s and Mark, Gloria},
title = {"Narco" Emotions: Affect and Desensitization in Social Media during the Mexican Drug War},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557197},
doi = {10.1145/2556288.2557197},
abstract = {Social media platforms have emerged as prominent information sharing ecosystems in
the context of a variety of recent crises, ranging from mass emergencies, to wars
and political conflicts. We study affective responses in social media and how they
might indicate desensitization to violence experienced in communities embroiled in
an armed conflict. Specifically, we examine three established affect measures: negative
affect, activation, and dominance as observed on Twitter in relation to a number of
statistics on protracted violence in four major cities afflicted by the Mexican Drug
War. During a two year period (Aug 2010 - Dec 2012), while violence was on the rise
in these regions, our findings show a decline in negative emotional expression as
well as a rise in emotional arousal and dominance in Twitter posts: aspects known
to be psychological markers of desensitization. We discuss the implications of our
work for behavioral health, facilitating rehabilitation efforts in communities enmeshed
in an acute and persistent urban warfare, and the impact on civic engagement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3563–3572},
numpages = {10},
keywords = {crisis informatics, affect, social media, desensitization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557100,
author = {Crivellaro, Clara and Comber, Rob and Bowers, John and Wright, Peter C. and Olivier, Patrick},
title = {A Pool of Dreams: Facebook, Politics and the Emergence of a Social Movement},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557100},
doi = {10.1145/2556288.2557100},
abstract = {In this paper we present insights from an empirical analysis of data from an emergent
social movement primarily located on a Facebook page to contribute understanding of
the conduct of everyday politics in social media and through this open up research
agendas for HCI. The analysis focuses on how interactions and contributions facilitated
the emergence of a collective with political will. We lay out an exploration of the
intrinsic relationship between cultural memories, cultural expression and everyday
politics and show how diverging voices co-constructed dynamic collectives capable
of political action. We look at how interactions through the Facebook page challenge
traditional ways for conceiving politics and the political. We outline possible research
agendas in the field of everyday politics, which are sensitive to the everyday acts
of resistance enclosed in the ordinary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3573–3582},
numpages = {10},
keywords = {social media, discourse, politics, activism, collectives},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556971,
author = {Voida, Amy and Dombrowski, Lynn and Hayes, Gillian R. and Mazmanian, Melissa},
title = {Shared Values/Conflicting Logics: Working around e-Government Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556971},
doi = {10.1145/2556288.2556971},
abstract = {In this paper, we describe results from fieldwork conducted at a social services site
where the workers evaluate citizens' applications for food and medical assistance
submitted via an e-government system. These results suggest value tensions that result
- not from different stakeholders with different values - but from differences among
how stakeholders enact the same shared value in practice. In the remainder of this
paper, we unpack the distinct and conflicting interpretations or logics of three shared
values - efficiency, access, and education. In particular, we analyze what happens
when social services workers have ideas about what it means to expand access, increase
efficiency, and educate the public that conflict with the logics embedded in the e-government
system. By distinguishing between overarching values and specific logics, we provide
an analytic framework for exploring value tensions as values are enacted in practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3583–3592},
numpages = {10},
keywords = {values, social services, e-government},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557311,
author = {Knowles, Bran and Blair, Lynne and Coulton, Paul and Lochrie, Mark},
title = {Rethinking Plan A for Sustainable HCI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557311},
doi = {10.1145/2556288.2557311},
abstract = {This paper challenges the sustainable HCI community to move away from a focus on demand
and instead address climate change as a supply problem. We identify a new route to
impact, namely addressing the psychological barriers that interfere with political
mobilization toward limiting the use of fossil fuels. Five barriers are explored as
a means of re-focusing research objectives for the community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3593–3596},
numpages = {4},
keywords = {sustainability, psychological barriers, activism, supply, climate change},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250977,
author = {Perry, Mark},
title = {Session Details: Location-Based Services and Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250977},
doi = {10.1145/3250977},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557404,
author = {Prasad, Manoj and Taele, Paul and Goldberg, Daniel and Hammond, Tracy A.},
title = {HaptiMoto: Turn-by-Turn Haptic Route Guidance Interface for Motorcyclists},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557404},
doi = {10.1145/2556288.2557404},
abstract = {A national study by the Australian Transport Safety Bureau revealed that motorcyclist
deaths were nearly thirty times more prevalent than that of drivers of other vehicles.
These fatalities represent approximately 5% of all highway deaths each year, yet motorcycles
account for only 2% of all registered vehicles in the USA. Motorcyclists are highly
exposed on the road, so maintaining situational awareness at all times is crucial.
Route guidance systems enable users to efficiently navigate between locations using
dynamic visual maps and audio directions, and have been well tested with motorists,
but remain unsafe for use by motorcyclists. Audio/visual routing systems decrease
motorcyclists' situational awareness and vehicle control, and thus elevate chances
of an accident. To enable motorcyclists to take advantage of route guidance while
maintaining situational awareness, we created HaptiMoto, a wearable haptic route guidance
system. HaptiMoto uses tactile signals to encode the distance and direction of approaching
turns, thus avoiding interference with audio/visual awareness. Our evaluations demonstrate
that HaptiMoto is both intuitive and a safer alternative for motorcyclists compared
to existing solutions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3597–3606},
numpages = {10},
keywords = {vibro-tactile, advanced traveler information system, route guidance, tactile interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557003,
author = {M\"{o}ller, Andreas and Kranz, Matthias and Diewald, Stefan and Roalter, Luis and Huitl, Robert and Stockinger, Tobias and Koelle, Marion and Lindemann, Patrick A.},
title = {Experimental Evaluation of User Interfaces for Visual Indoor Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557003},
doi = {10.1145/2556288.2557003},
abstract = {Mobile location recognition by capturing images of the environment (visual localization)
is a promising technique for indoor navigation in arbitrary surroundings. However,
it has barely been investigated so far how the user interface (UI) can cope with the
challenges of the vision-based localization technique, such as varying quality of
the query images. We implemented a novel UI for visual localization, consisting of
Virtual Reality (VR) and Augmented Reality (AR) views that actively communicate and
ensure localization accuracy. If necessary, the system encourages the user to point
the smartphone at distinctive regions to improve localization quality. We evaluated
the UI in a experimental navigation task with a prototype, informed by initial evaluation
results using design mockups. We found that VR can contribute to efficient and effective
indoor navigation even at unreliable location and orientation accuracy. We discuss
identified challenges and share lessons learned as recommendations for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3607–3616},
numpages = {10},
keywords = {mobile interaction, virtual reality, augmented reality, visual localization, indoor navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557156,
author = {Pritchard, Gary and Vines, John and Briggs, Pam and Thomas, Lisa and Olivier, Patrick},
title = {Digitally Driven: How Location Based Services Impact the Work Practices of London Bus Drivers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557156},
doi = {10.1145/2556288.2557156},
abstract = {This paper examines how an occupational group has adapted to the demands of working
with a Location Based Service (LBS). Instead of following a rigid timetable, London's
bus drivers are now required to maintain an equal distance between the bus in front
and the one behind. Our qualitative study employs ethnographic fieldwork and in-depth
semi-structured interviews to elicit drivers' perspectives of the new system and show
how it has modified their driving and general work conditions. We explore how passengers
influence the movement of the bus and how the technology frames bus drivers' relationships
to their managers and commuters. This work contributes to our understanding of the
impact of LBS in the workplace and shows how technological imperatives can be established
that cause unanticipated consequences and gradually undermine human relationships.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3617–3626},
numpages = {10},
keywords = {location based devices, auto ethnography, lbd, location based services, public transport, lbs, ethnography},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557289,
author = {Dancu, Alexandru and Franjcic, Zlatko and Fjeld, Morten},
title = {Smart Flashlight: Map Navigation Using a Bike-Mounted Projector},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557289},
doi = {10.1145/2556288.2557289},
abstract = {While mobile phones affect our behavior and tend to separate us from our physical
environment, this very environment could instead become a responsive part of the information
domain. For navigation using a map while cycling in an urban environment, we studied
two alternative solutions: smartphone display and projection on the road. This paper
firstly demonstrates by proof-of-concept a GPS-based map navigation using a bike-mounted
projector. Secondly, it implements a prototype using both a projector and a smartphone
mounted on a bike, comparing them for use in a navigation system for nighttime cycling.
Thirdly, it examines how visuo-spatial factors influence navigation. We believe that
our findings will be useful for designing navigation systems for bikes and even for
cars, helping cyclists and drivers be more attentive to their environment while navigating,
and to provide useful information while moving.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3627–3630},
numpages = {4},
keywords = {gps, smartphone, field of view, navigation, visuo-spatial, bike, pico-projector},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557370,
author = {Lee, Key Jung and Joo, Yeon Kyoung and Nass, Clifford},
title = {Partially Intelligent Automobiles and Driving Experience at the Moment of System Transition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557370},
doi = {10.1145/2556288.2557370},
abstract = {The current study (N = 49) took a user-centered approach to explore how level of automation
(pedal automated, wheel automated or fully automated driving) and the interface modality
(switching automation on or off via touch or voice control) in automated vehicles
influence drivers' perceived experience and performance. The results found that full
or wheel automation in vehicles was perceived significantly more intelligent than
pedal automation. Furthermore, drivers in the pedal automation condition reported
greater nervousness when using the touch interface than the voice interface. This
tendency was not found among drivers in the full and wheel automation conditions.
Drivers who used the voice interface to control automated driving had fewer driving
mistakes than those who operated the touch interface. Our findings have important
psychological and practical implications for designing a user interface for automated
vehicles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3631–3634},
numpages = {4},
keywords = {in-car interfaces, situational awareness, automated car, partial automation, safe driving},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250978,
author = {Dow, Steven},
title = {Session Details: Crowdsourcing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250978},
doi = {10.1145/3250978},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557044,
author = {Truong, Khai N. and Shihipar, Thariq and Wigdor, Daniel J.},
title = {Slide to X: Unlocking the Potential of Smartphone Unlocking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557044},
doi = {10.1145/2556288.2557044},
abstract = {Unlock gestures are performed by billions of users across the world multiple times
a day. Beyond preventing accidental input on mobile devices, they currently serve
little to no other purpose. In this paper, we explore how replacing the regular unlock
screen with one that asks the user to perform a simple, optional task, can benefit
a wealth of application domains, including data collection, personal-health metrics
collection, and human intelligence tasks. We evaluate this concept, which we refer
to as Slide to X. Further, we show that people are willing to perform microtasks presented
through this interface and continue to do so throughout the day while they visit different
locations as part of their daily routines. We then discuss how to implement this concept
and demonstrate three applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3635–3644},
numpages = {10},
keywords = {phone unlock, microtasks, dual-purpose interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556996,
author = {Vaish, Rajan and Wyngarden, Keith and Chen, Jingshu and Cheung, Brandon and Bernstein, Michael S.},
title = {Twitch Crowdsourcing: Crowd Contributions in Short Bursts of Time},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556996},
doi = {10.1145/2556288.2556996},
abstract = {To lower the threshold to participation in crowdsourcing, we present twitch crowdsourcing:
crowdsourcing via quick contributions that can be completed in one or two seconds.
We introduce Twitch, a mobile phone application that asks users to make a micro-contribution
each time they unlock their phone. Twitch takes advantage of the common habit of turning
to the mobile phone in spare moments. Twitch crowdsourcing activities span goals such
as authoring a census of local human activity, rating stock photos, and extracting
structured data from Wikipedia pages. We report a field deployment of Twitch where
82 users made 11,240 crowdsourcing contributions as they used their phone in the course
of everyday life. The median Twitch activity took just 1.6 seconds, incurring no statistically
distinguishable costs to unlock speed or cognitive load compared to a standard slide-to-unlock
interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3645–3654},
numpages = {10},
keywords = {microtasking, crowdsourcing, mobile crowdsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556967,
author = {Forlines, Clifton and Miller, Sarah and Guelcher, Leslie and Bruzzi, Robert},
title = {Crowdsourcing the Future: Predictions Made with a Social Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556967},
doi = {10.1145/2556288.2556967},
abstract = {Researchers have long known that aggregate estimations built from the collected opinions
of a large group of people often outperform the estimations of individual experts.
This phenomenon is generally described as the "Wisdom of Crowds". This approach has
shown promise with respect to the task of accurately forecasting future events. Previous
research has demonstrated the value of utilizing meta-forecasts (forecasts about what
others in the group will predict) when aggregating group predictions. In this paper,
we describe an extension to meta-forecasting and demonstrate the value of modeling
the familiarity among a population's members (its social network) and applying this
model to forecast aggregation. A pair of studies demonstrates the value of taking
this model into account, and the described technique produces aggregate forecasts
for future events that are significantly better than the standard Wisdom of Crowds
approach as well as previous meta-forecasting techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3655–3664},
numpages = {10},
keywords = {forecasting, social network, crowd-sourcing, bayesian truth serum, meta-forecast, aggregation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557155,
author = {Alagarai Sampath, Harini and Rajeshuni, Rajeev and Indurkhya, Bipin},
title = {Cognitively Inspired Task Design to Improve User Performance on Crowdsourcing Platforms},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557155},
doi = {10.1145/2556288.2557155},
abstract = {Recent research in human computation has focused on improving the quality of work
done by crowd workers on crowdsourcing platforms. Multiple approaches have been adopted
like filtering crowd workers through qualification tasks, and aggregating responses
from multiple crowd workers to obtain consensus. We investigate here how improving
the presentation of the task itself by using cognitively inspired features affects
the performance of crowd workers. We illustrate this with a case-study for the task
of extracting text from scanned images. We generated six task-presentation designs
by modifying two parameters - visual saliency of the target fields and working memory
requirements - and conducted experiments on Amazon Mechanical Turk (AMT) and with
an eye-tracker in the lab setting. Our results identify which task-design parameters
(e.g. highlighting target fields) result in improved performance, and which ones do
not (e.g. reducing the number of distractors). In conclusion, we claim that the use
of cognitively inspired features for task design is a powerful technique for maximizing
the performance of crowd workers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3665–3674},
numpages = {10},
keywords = {visual saliency, working memory, eye tracking, crowdsourcing, cognitive psychology, task design, mechanical turk},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250979,
author = {Zhou, Michelle},
title = {Session Details: Desktop Search and History},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250979},
doi = {10.1145/3250979},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557356,
author = {Marshall, Catherine C. and Lindley, Si\^{a}n E.},
title = {Searching for Myself: Motivations and Strategies for Self-Search},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557356},
doi = {10.1145/2556288.2557356},
abstract = {We present findings from a qualitative study of self-search, also known as ego or
vanity search. In the context of a broader study about personal online content, participants
were asked to search for themselves using their own computers and the browsers and
queries they would normally adopt. Our analysis highlights five motivations for self-search:
as a form of identity management; to discover reactions to and reuse of user-generated
media; to re-find personal content; as a form of entertainment; and to reveal lost
or forgotten content. Strategies vary according to motivation, and may differ markedly
from typical information-seeking, with users looking deep into the results and using
image search to identify content about themselves. We argue that two dimensions underpin
ways of improving self-search: controllability and expectedness, and discuss what
these dimensions imply for design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3675–3684},
numpages = {10},
keywords = {autosurveillance, identity, archive, vanity search, doppelganger, ego search, aggregation, self-search},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557014,
author = {Fitchett, Stephen and Cockburn, Andy and Gutwin, Carl},
title = {Finder Highlights: Field Evaluation and Design of an Augmented File Browser},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557014},
doi = {10.1145/2556288.2557014},
abstract = {Navigating to files through a hierarchy is often a slow, laborious, and repetitive
task. Recent lab studies showed that file browser interface augmentations, such as
Icon Highlights and Search Directed Navigation, have the potential to reduce file
retrieval times. However, for this potential to be realised in actual systems, further
study is necessary to address two important issues. First, there are important design
and implementation challenges in advancing the research prototypes previously evaluated
into complete interactive systems that can be used for real work. Second, it is unknown
how real users would employ these systems while engaged in actual work; would the
potential performance improvements suggested by the earlier lab studies be realised?
We therefore describe the design, implementation, and longitudinal field study evaluation
of Finder Highlights, a file browser plugin for the OS X 'Finder' that adds support
for Icon Highlights and Search Directed Navigation. Study results confirm that the
augmentations are effective in reducing real-world file retrieval times, with retrieval
times 13% faster when using Finder Highlights compared to the standard tool (10.6
s versus 12.2 s), while also emphasising important differences between lab and field
studies. In summary, the paper strongly suggests that large-scale deployment of interface
augmentations to file browsers, particularly Icon Highlights, will have a marked effect
in improving users' real-world file retrieval.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3685–3694},
numpages = {10},
keywords = {prediction, revisitation, file navigation, file retrieval},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557023,
author = {Massey, Charlotte and TenBrook, Sean and Tatum, Chaconne and Whittaker, Steve},
title = {PIM and Personality: What Do Our Personal File Systems Say about Us?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557023},
doi = {10.1145/2556288.2557023},
abstract = {Individual differences are prevalent in personal information management (PIM). There
is large variation between individuals in how they structure and retrieve information
from personal archives. These differences make it hard to develop general PIM tools.
However we know little about the origins of these differences. We present two studies
evaluating whether differences arise from personality traits, by exploring whether
different personalities structure personal archives differently. The first exploratory
study asks participants to identify PIM cues that signal personality traits. While
the aim was to identify cues, these cues also proved surprisingly accurate indicators
of personality. In a second study, to evaluate these cues, we directly measure relations
between structure and traits. We demonstrate that Conscientiousness predicts file
organization, particularly PC users' desktops. Neurotic people may also keep more
desktop files. One implication is that systems might be customized for different personalities.
We also advance personality theory, showing that personal digital artifacts signal
personality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3695–3704},
numpages = {10},
keywords = {file systems, personality, personal information management, individual differences},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557032,
author = {Geymayer, Thomas and Steinberger, Markus and Lex, Alexander and Streit, Marc and Schmalstieg, Dieter},
title = {Show Me the Invisible: Visualizing Hidden Content},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557032},
doi = {10.1145/2556288.2557032},
abstract = {Content on computer screens is often inaccessible to users because it is hidden, e.g.,
occluded by other windows, outside the viewport, or overlooked. In search tasks, the
efficient retrieval of sought content is important. Current software, however, only
provides limited support to visualize hidden occurrences and rarely supports search
synchronization crossing application boundaries. To remedy this situation, we introduce
two novel visualization methods to guide users to hidden content. Our first method
generates awareness for occluded or out-of-viewport content using see-through visualization.
For content that is either outside the screen's viewport or for data sources not opened
at all, our second method shows off-screen indicators and an on-demand smart preview.
To reduce the chances of overlooking content, we use visual links, i.e., visible edges,
to connect the visible content or the visible representations of the hidden content.
We show the validity of our methods in a user study, which demonstrates that our technique
enables a faster localization of hidden content compared to traditional search functionality
and thereby assists users in information retrieval tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3705–3714},
numpages = {10},
keywords = {off-screen content, occluded content, visual linking, hidden content},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}


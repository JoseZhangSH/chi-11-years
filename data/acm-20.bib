@inproceedings{10.1145/3248970,
author = {Pratt, Wanda},
title = {Session Details: Health 1: Technology Challenges},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248970},
doi = {10.1145/3248970},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978944,
author = {Cramer, Meg and Hirano, Sen H. and Tentori, Monica and Yeganyan, Michael T. and Hayes, Gillian R.},
title = {Classroom-Based Assistive Technology: Collective Use of Interactive Visual Schedules by Students with Autism},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978944},
doi = {10.1145/1978942.1978944},
abstract = {vSked is an interactive and collaborative assistive technology for students with autism,
combining visual schedules, choice boards, and a token-based reward system into an
integrated classroom system. In this paper, we present the results of a study of three
deployments of vSked over the course of a year in two autism classrooms. The results
of our study demonstrate that vSked can promote student independence, reduce the quantity
of educator-initiated prompts, encourage consistency and predictability, reduce the
time required to transition from one activity to another. The findings from this study
reveal practices surrounding the use of assistive technologies in classrooms and highlight
important considerations for both the design and the evaluation of assistive technologies
in the future, especially those destined for classroom use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {assistive technology, autism, visual schedules},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978945,
author = {Raij, Andrew and Ghosh, Animikh and Kumar, Santosh and Srivastava, Mani},
title = {Privacy Risks Emerging from the Adoption of Innocuous Wearable Sensors in the Mobile Environment},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978945},
doi = {10.1145/1978942.1978945},
abstract = {Wearable sensors are revolutionizing healthcare and science by enabling capture of
physiological, psychological, and behavioral measurements in natural environments.
However, these seemingly innocuous measurements can be used to infer potentially private
behaviors such as stress, conversation, smoking, drinking, illicit drug usage, and
others. We conducted a study to assess how concerned people are about disclosure of
a variety of behaviors and contexts that are embedded in wearable sensor data. Our
results show participants are most concerned about disclosures of conversation episodes
and stress - inferences that are not yet widely publicized. These concerns are mediated
by temporal and physical context associated with the data and the participant's personal
stake in the data. Our results provide key guidance on the extent to which people
understand the potential for harm and data characteristics researchers should focus
on to reduce the perceived harm from such datasets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {privacy, information disclosure, mobile health, wearable sensors, user study},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978946,
author = {Das, Anita and Faxvaag, Arild and Svan\ae{}s, Dag},
title = {Interaction Design for Cancer Patients: Do We Need to Take into Account the Effects of Illness and Medication?},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978946},
doi = {10.1145/1978942.1978946},
abstract = {In this paper we explore how having cancer and receiving therapy influences upon patients'
ability to use an online healthcare system. The motivation is that no empirically
based design guidelines are available concerning this user group. Ignoring possible
effects of illness and therapy can result in systems with poor usability and user
acceptance. A case-control usability test with 14 cancer patients and 14 matched controls
revealed that the cancer patients experienced significantly more difficulties compared
with the healthy controls using a web-based online healthcare system. We conclude
that designers of online healthcare systems need to take into consideration the unique
challenges of being ill and/or using medication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–24},
numpages = {4},
keywords = {medical informatics, usability, patient-centred information systems, user interfaces, cancer patients},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978947,
author = {Quek, Melissa and Boland, Daniel and Williamson, John and Murray-Smith, Roderick and Tavella, Michele and Perdikis, Serafeim and Schreuder, Martijn and Tangermann, Michael},
title = {Simulating the Feel of Brain-Computer Interfaces for Design, Development and Social Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978947},
doi = {10.1145/1978942.1978947},
abstract = {We describe an approach to improving the design and development of Brain-Computer
Interface (BCI) applications by simulating the error-prone characteristics and subjective
feel of electroencephalogram (EEG), motor-imagery based BCIs. BCIs have the potential
to enhance the quality of life of people who are severely disabled, but it is often
time-consuming to test and develop the systems. Simulation of BCI characteristics
allows developers to rapidly test design options, and gain both subjective and quantitative
insight into expected behaviour without using an EEG cap. A further motivation for
the use of simulation is that 'impairing' a person without motor disabilities in a
game with a disabled BCI user can create a level playing field and help carers empathise
with BCI users. We demonstrate a use of the simulator in controlling a game of Brain
Pong.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {25–28},
numpages = {4},
keywords = {british columbiai, brain-computer interaction, disability, hci, human computer interaction, usability, motor imagery, simulation, smr, social interaction},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978948,
author = {Wilcox, Lauren and Morris, Dan and Tan, Desney and Gatewood, Justin and Horvitz, Eric},
title = {Characterizing Patient-Friendly "Micro-Explanations"of Medical Events},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978948},
doi = {10.1145/1978942.1978948},
abstract = {Patients' basic understanding of clinical events has been shown to dramatically improve
patient care. We propose that the automatic generation of very short micro-explanations,
suitable for real-time delivery in clinical settings, can transform patient care by
giving patients greater awareness of key events in their electronic medical record.
We present results of a survey study indicating that it may be possible to automatically
generate such explanations by extracting individual sentences from consumer-facing
Web pages. We further inform future work by characterizing physician and non-physician
responses to a variety of Web-extracted explanations of medical lab tests.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {29–32},
numpages = {4},
keywords = {personal health records, electronic medical records},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248971,
author = {Neustaedter, Carman},
title = {Session Details: Telepresence},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248971},
doi = {10.1145/3248971},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978950,
author = {Lee, Min Kyung and Takayama, Leila},
title = {"Now, i Have a Body": Uses and Social Norms for Mobile Remote Presence in the Workplace},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978950},
doi = {10.1145/1978942.1978950},
abstract = {As geographically distributed teams become increasingly common, there are more pressing
demands for communication work practices and technologies that support distributed
collaboration. One set of technologies that are emerging on the commercial market
is mobile remote presence (MRP) systems, physically embodied videoconferencing systems
that remote workers use to drive through a workplace, communicating with locals there.
Our interviews, observations, and survey results from people, who had 2-18 months
of MRP use, showed how remotely-controlled mobility enabled remote workers to live
and work with local coworkers almost as if they were physically there. The MRP supported
informal communications and connections between distributed coworkers. We also found
that the mobile embodiment of the remote worker evoked orientations toward the MRP
both as a person and as a machine, leading to formation of new usage norms among remote
and local coworkers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {33–42},
numpages = {10},
keywords = {human-robot interaction, computer supported collaborative work, mobile remote presence},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978951,
author = {Luff, Paul and Yamashita, Naomi and Kuzuoka, Hideaki and Heath, Christian},
title = {Hands on Hitchcock: Embodied Reference to a Moving Scene},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978951},
doi = {10.1145/1978942.1978951},
abstract = {In this paper we report on some experiments with a high fidelity media space, t-Room,
an immersive system that presents full scale, real-time images of co-participants
who are in similar spaces many miles apart. Although being designed to provide a coherent
environment for interaction the system introduces a number of incongruities, both
in time and space. Drawing on some quasi-naturalistic experiments, where the participants
were required to analyse complex data, we consider how the participants manage these
incongruities. We conclude by briefly discussing the resources people utilize to produce
and recognize conduct in embodied spaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {43–52},
numpages = {10},
keywords = {interaction analysis, embodied interaction, media spaces, cscw},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978952,
author = {Zhu, Dingyun and Gedeon, Tom and Taylor, Ken},
title = {Exploring Camera Viewpoint Control Models for a Multi-Tasking Setting in Teleoperation},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978952},
doi = {10.1145/1978942.1978952},
abstract = {Control of camera viewpoint plays a vital role in many teleoperation activities, as
watching live video streams is still the fundamental way for operators to obtain situational
awareness from remote environments. Motivated by a real-world industrial setting in
mining teleoperation, we explore several possible solutions to resolve a common multi-tasking
situation where an operator is required to control a robot and simultaneously perform
remote camera operation. Conventional control interfaces are predominantly used in
such teleoperation settings, but could overload an operator's hand-operation capability,
and require frequent attention switches and thus could decrease productivity. We report
on an empirical user study in a model multi-tasking teleoperation setting where the
user has a main task which requires their attention. We compare three different camera
viewpoint control models: (1) dual manual control, (2) natural interaction (combining
eye gaze and head motion) and (3) autonomous tracking. The results indicate the advantages
of using the natural interaction model, while the manual control model performed the
worst.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {53–62},
numpages = {10},
keywords = {remote camera control, multi-tasking setting, autonomous tracking, natural interaction, dual manual control},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978953,
author = {Nakanishi, Hideyuki and Kato, Kei and Ishiguro, Hiroshi},
title = {Zoom Cameras and Movable Displays Enhance Social Telepresence},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978953},
doi = {10.1145/1978942.1978953},
abstract = {This paper shows that the augmentation of a remote person's positional movement enhances
social telepresence. There are three possible ways of representing a remote person's
movement toward the user in visual communication: a) the remote person's movement
toward the remote camera, b) the remote camera's zooming in to enlarge the remote
person's picture, and c) a forward movement of the display that is displaying the
remote person. We conducted an experiment to see the relationship among these three
ways and the effects of a remote camera's zooming and a display's movement on social
telepresence. In the experiment, we observed that the remote person's movement lowered
the reality of conversations, and the remote camera's zooming lowered the visual quality.
However, social telepresence was enhanced when both the person's movement and the
camera's zooming occurred simultaneously. We also observed that a 6-centimeter movement
of the display enhanced social telepresence, whether the remote person moved or not.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {63–72},
numpages = {10},
keywords = {videoconferencing, telepresence, telerobotics},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248972,
author = {Jacob, Rob},
title = {Session Details: Olfaction, Breath &amp; Biofeedback},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248972},
doi = {10.1145/3248972},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978955,
author = {Marshall, Joe and Rowland, Duncan and Rennick Egglestone, Stefan and Benford, Steve and Walker, Brendan and McAuley, Derek},
title = {Breath Control of Amusement Rides},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978955},
doi = {10.1145/1978942.1978955},
abstract = {Emerging robotic technologies are enabling the control of individual seats on rollercoasters
and other thrill rides. We explore the potential of breathing as an effective and
engaging way of driving this. Observations and interviews from trials of an enhanced
bucking bronco ride show that breath-control is fun, challenging and intelligible,
and reveal riders-x tactics as they battled the machine. We conclude that breath control
is feasible and appropriate for controlling rides, unpack its important characteristics,
and consider how it might be built into future ride systems. We argue that the combination
of voluntary and involuntary factors in breathing is especially appealing for controlling
rides as it balances game-like elements of skill and learning against the thrill of
surrendering control to the machine.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {73–82},
numpages = {10},
keywords = {biosensing, breath control, breathing, amusement ride, themepark, affective computing, thrill, bucking bronco},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978956,
author = {Noguchi, Daisuke and Sugimoto, Sayumi and Bannai, Yuichi and Okada, Ken-ichi},
title = {Time Characteristics of Olfaction in a Single Breath},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978956},
doi = {10.1145/1978942.1978956},
abstract = {The transmission of olfactory information together with audiovisual information is
now attracting much attention. However, the information is difficult to synchronize
because of problems of scent lingering in the air and olfactory adaptation. We aimed
at minimizing the amount of odorant presented to users in order to mitigate these
problems, and developed an olfactory display that is able to present scents precisely.
The display uses pulse ejection, whereby scents are emitted for only short periods
of time. In this study, we aimed to mitigate the above-mentioned problems and to measure
the time characteristics of olfaction in a single breath, which are difficult to measure
by conventional methods. As a result, the most effective conditions for using a small
amount of odorant in a single breath were revealed. These results are expected to
ease the synchronization of olfactory and audiovisual information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {83–92},
numpages = {10},
keywords = {olfactory display, olfactory information, pulse ejection},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978957,
author = {Narumi, Takuji and Nishizaka, Shinya and Kajinami, Takashi and Tanikawa, Tomohiro and Hirose, Michitaka},
title = {Augmented Reality Flavors: Gustatory Display Based on Edible Marker and Cross-Modal Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978957},
doi = {10.1145/1978942.1978957},
abstract = {The main contribution of this paper is to realize computer generated augmented flavors
and establish a method to integrate gustatory information into computer human interactions.
There are several reasons for the scarcity of research on gustatory information. One
reason is that taste sensations are affected by a number of factors, such as vision,
olfaction and memories. This produces a complex cognition mechanism for a user's gustatory
sensation, and makes it difficult to build up a gustatory display which produces a
specific taste on demand.Our hypothesis is that the complexity of gustatory sensation
can be applied to the realization of a "Pseudo-gustatory" display that presents the
desired flavors by means of a cross-modal effect elicited by visual and olfactory
augmented reality. We propose the Edible Marker system, which can detect the state
[number/shape/6-degree-of-freedom (DOF) coordinate] of each piece of bitten or divided
food in real time, and the "Pseudo-gustation" method to change the perceived taste
of food by changing its appearance and scent. We construct "MetaCookie+" as an implementation
and discuss its validity through an exploratory study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {93–102},
numpages = {10},
keywords = {gustatory display, edible marker, pseudo-gustation, cross-modal interaction, augmented reality},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978958,
author = {Nacke, Lennart Erik and Kalyn, Michael and Lough, Calvin and Mandryk, Regan Lee},
title = {Biofeedback Game Design: Using Direct and Indirect Physiological Control to Enhance Game Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978958},
doi = {10.1145/1978942.1978958},
abstract = {Prior work on physiological game interaction has focused on dynamically adapting games
using physiological sensors. In this paper, we propose a classification of direct
and indirect physiological sensor input to augment traditional game control. To find
out which sensors work best for which game mechanics, we conducted a mixed-methods
study using different sensor mappings. Our results show participants have a preference
for direct physiological control in games. This has two major design implications
for physiologically controlled games: (1) Direct physiological sensors should be mapped
intuitively to reflect an action in the virtual world; (2) Indirect physiological
input is best used as a dramatic device in games to influence features altering the
game world.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {103–112},
numpages = {10},
keywords = {affective computing, physiological input, entertainment, affective gaming, psychophysiology, biofeedback, games},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248973,
author = {Lai, Jennifer},
title = {Session Details: Research Methods},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248973},
doi = {10.1145/3248973},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978960,
author = {Furniss, Dominic and Blandford, Ann and Curzon, Paul},
title = {Confessions from a Grounded Theory PhD: Experiences and Lessons Learnt},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978960},
doi = {10.1145/1978942.1978960},
abstract = {Grounded Theory (GT) is used within HCI research, but nuances and more modern interpretations
of the method are rarely discussed. This paper has two intentions: to offer guidance
on practical issues when applying GT, and to clarify the space of methodological possibilities.
We describe an extended GT study on understanding why practitioners choose particular
usability evaluation methods. We describe five stages in this study to highlight our
experiences and choices made. We draw out seven practical and methodological considerations
in applying GT in a CHI context. This challenges the more traditional inductive and
objective positions on GT use; it sensitizes novices of GT to these issues; and through
the extended case study it provides substance for debate on issues that affect those
that use qualitative methods more broadly.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {113–122},
numpages = {10},
keywords = {grounded theory, resilience engineering, qualitative, distributed cognition, constructivist, method},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978961,
author = {Rode, Jennifer A.},
title = {Reflexivity in Digital Anthropology},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978961},
doi = {10.1145/1978942.1978961},
abstract = {There are a variety of forms of ethnography inside and outside HCI each with valid
complementary contributions. This paper looks at the practices of digital anthropology
and how it contributes to reflexive design in HCI. The paper overviews key aspects
its use in HCI, as well as in the anthropological approach. In doing so it relates
these practices to participatory design and the socio-technical gap, and the ways
ethnography can address them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {123–132},
numpages = {10},
keywords = {iterative, participant-observation, rapport, ethnography},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978962,
author = {Baumer, Eric P.S. and Tomlinson, Bill},
title = {Comparing Activity Theory with Distributed Cognition for Video Analysis: Beyond "Kicking the Tires"},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978962},
doi = {10.1145/1978942.1978962},
abstract = {The field of HCI is growing, not only in the variety of application areas or the volume
of research conducted, but also in the number of analytical approaches for use in
the evaluation and design of interactive systems. However, despite the abundance of
theoretical frameworks available, relatively little work has directly compared the
application of these frameworks. This paper compares video analysis methods based
on two analytic frameworks - activity theory (AT) and distributed cognition (DCog)
- by performing an analysis of the same system from each of the two different theoretical
perspectives. The results presented here provide a better understanding of how such
theoretically informed methods in practice both resemble and differ from one another.
Furthermore, this comparison enables specific insights about each of the theories
themselves, as well as more general discussion about the role of theory in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {133–142},
numpages = {10},
keywords = {video analysis, distributed cognition, activity theory, methodology evaluation, evaluation methodology},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978963,
author = {Wobbrock, Jacob O. and Findlater, Leah and Gergle, Darren and Higgins, James J.},
title = {The Aligned Rank Transform for Nonparametric Factorial Analyses Using Only Anova Procedures},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978963},
doi = {10.1145/1978942.1978963},
abstract = {Nonparametric data from multi-factor experiments arise often in human-computer interaction
(HCI). Examples may include error counts, Likert responses, and preference tallies.
But because multiple factors are involved, common nonparametric tests (e.g., Friedman)
are inadequate, as they are unable to examine interaction effects. While some statistical
techniques exist to handle such data, these techniques are not widely available and
are complex. To address these concerns, we present the Aligned Rank Transform (ART)
for nonparametric factorial data analysis in HCI. The ART relies on a preprocessing
step that "aligns" data before applying averaged ranks, after which point common ANOVA
procedures can be used, making the ART accessible to anyone familiar with the F-test.
Unlike most articles on the ART, which only address two factors, we generalize the
ART to N factors. We also provide ARTool and ARTweb, desktop and Web-based programs
for aligning and ranking data. Our re-examination of some published HCI results exhibits
advantages of the ART.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {143–146},
numpages = {4},
keywords = {anova, factorial analysis, statistics, analysis of variance, f-test, nonparametric data},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248974,
author = {Gajos, Krzysztof},
title = {Session Details: Machine Learning},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248974},
doi = {10.1145/3248974},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978965,
author = {Fiebrink, Rebecca and Cook, Perry R. and Trueman, Dan},
title = {Human Model Evaluation in Interactive Supervised Learning},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978965},
doi = {10.1145/1978942.1978965},
abstract = {Model evaluation plays a special role in interactive machine learning (IML) systems
in which users rely on their assessment of a model's performance in order to determine
how to improve it. A better understanding of what model criteria are important to
users can therefore inform the design of user interfaces for model evaluation as well
as the choice and design of learning algorithms. We present work studying the evaluation
practices of end users interactively building supervised learning systems for real-world
gesture analysis problems. We examine users' model evaluation criteria, which span
conventionally relevant criteria such as accuracy and cost, as well as novel criteria
such as unexpectedness. We observed that users employed evaluation techniques---including
cross-validation and direct, real-time evaluation---not only to make relevant judgments
of algorithms' performance and interactively improve the trained models, but also
to learn to provide more effective training data. Furthermore, we observed that evaluation
taught users about what types of models were easy or possible to build, and users
sometimes used this information to modify the learning problem definition or their
plans for using the trained models in practice. We discuss the implications of these
findings with regard to the role of generalization accuracy in IML, the design of
new algorithms and interfaces, and the scope of potential benefits of incorporating
human interaction in the design of supervised learning systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {147–156},
numpages = {10},
keywords = {music, interactive machine learning, evaluation, gesture},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978966,
author = {Amershi, Saleema and Lee, Bongshin and Kapoor, Ashish and Mahajan, Ratul and Christian, Blaine},
title = {CueT: Human-Guided Fast and Accurate Network Alarm Triage},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978966},
doi = {10.1145/1978942.1978966},
abstract = {Network alarm triage refers to grouping and prioritizing a stream of low-level device
health information to help operators find and fix problems. Today, this process tends
to be largely manual because existing tools cannot easily evolve with the network.
We present CueT, a system that uses interactive machine learning to learn from the
triaging decisions of operators. It then uses that learning in novel visualizations
to help them quickly and accurately triage alarms. Unlike prior interactive machine
learning systems, CueT handles a highly dynamic environment where the groups of interest
are not known a-priori and evolve constantly. A user study with real operators and
data from a large network shows that CueT significantly improves the speed and accuracy
of alarm triage compared to the network's current practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {157–166},
numpages = {10},
keywords = {visualization, interactive machine learning, triage},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978967,
author = {Chau, Duen Horng and Kittur, Aniket and Hong, Jason I. and Faloutsos, Christos},
title = {Apolo: Making Sense of Large Network Data by Combining Rich User Interaction and Machine Learning},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978967},
doi = {10.1145/1978942.1978967},
abstract = {Extracting useful knowledge from large network datasets has become a fundamental challenge
in many domains, from scientific literature to social networks and the web. We introduce
Apolo, a system that uses a mixed-initiative approach - combining visualization, rich
user interaction and machine learning - to guide the user to incrementally and interactively
explore large network data and make sense of it. Apolo engages the user in bottom-up
sensemaking to gradually build up an understanding over time by starting small, rather
than starting big and drilling down. Apolo also helps users find relevant information
by specifying exemplars, and then using a machine learning method called Belief Propagation
to infer which other nodes may be of interest. We evaluated Apolo with twelve participants
in a between-subjects study, with the task being to find relevant new papers to update
an existing survey paper. Using expert judges, participants using Apolo found significantly
more relevant papers. Subjective feedback of Apolo was also very positive.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {167–176},
numpages = {10},
keywords = {belief propagation, large network, sensemaking},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248975,
author = {Rohs, Michael},
title = {Session Details: Mid-Air Pointing &amp; Gestures},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248975},
doi = {10.1145/3248975},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978969,
author = {Nancel, Mathieu and Wagner, Julie and Pietriga, Emmanuel and Chapuis, Olivier and Mackay, Wendy},
title = {Mid-Air Pan-and-Zoom on Wall-Sized Displays},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978969},
doi = {10.1145/1978942.1978969},
abstract = {Very-high-resolution wall-sized displays offer new opportunities for interacting with
large data sets. While pointing on this type of display has been studied extensively,
higher-level, more complex tasks such as pan-zoom navigation have received little
attention. It thus remains unclear which techniques are best suited to perform multiscale
navigation in these environments. Building upon empirical data gathered from studies
of pan-and-zoom on desktop computers and studies of remote pointing, we identified
three key factors for the design of mid-air pan-and-zoom techniques: uni- vs. bimanual
interaction, linear vs. circular movements, and level of guidance to accomplish the
gestures in mid-air. After an extensive phase of iterative design and pilot testing,
we ran a controlled experiment aimed at better understanding the influence of these
factors on task performance. Significant effects were obtained for all three factors:
bimanual interaction, linear gestures and a high level of guidance resulted in significantly
improved performance. Moreover, the interaction effects among some of the dimensions
suggest possible combinations for more complex, real-world tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {177–186},
numpages = {10},
keywords = {mid-air interaction techniques, navigation, multi-scale interfaces, pan &amp; zoom, wall-sized displays},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978970,
author = {Bragdon, Andrew and Ko, Hsu-Sheng},
title = {Gesture Select: Acquiring Remote Targets on Large Displays without Pointing},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978970},
doi = {10.1145/1978942.1978970},
abstract = {When working at a large wall display, even if partially utilized, many targets are
likely to be distant from the user, requiring walking, which is slow, and interrupts
workflow. We propose a novel technique for selecting remote targets called Gesture
Select, in which users draw an initial mark, in a target's direction; rectilinear
gestures represented as icons are dynamically overlaid on targets within a region
of interest; the user then continues by drawing the continuation mark corresponding
to the target, to select it. Extensions to this technique to support working with
remote content for an extended period, and learning gesture shortcuts are presented.
A formal experiment indicates Gesture Select significantly outperformed direct selection
for mid/far targets. Further analysis suggests Gesture Select performance is principally
affected by the extent to which users can read the gestures, influenced by distance
and perspective warping, and the gesture complexity in the ROI. The results of a second
2-D experiment with labeled targets indicate Gesture Select significantly outperformed
direct selection and an existing technique.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {187–196},
numpages = {10},
keywords = {remote targets, large display, gestures, selection},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978971,
author = {Ruiz, Jaime and Li, Yang and Lank, Edward},
title = {User-Defined Motion Gestures for Mobile Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978971},
doi = {10.1145/1978942.1978971},
abstract = {Modern smartphones contain sophisticated sensors to monitor three-dimensional movement
of the device. These sensors permit devices to recognize motion gestures - deliberate
movements of the device by end-users to invoke commands. However, little is known
about best-practices in motion gesture design for the mobile computing paradigm. To
address this issue, we present the results of a guessability study that elicits end-user
motion gestures to invoke commands on a smartphone device. We demonstrate that consensus
exists among our participants on parameters of movement and on mappings of motion
gestures onto commands. We use this consensus to develop a taxonomy for motion gestures
and to specify an end-user inspired motion gesture set. We highlight the implications
of this work to the design of smartphone applications and hardware. Finally, we argue
that our results influence best practices in design for all gestural interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {197–206},
numpages = {10},
keywords = {mobile interaction, motion gestures, sensors},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978972,
author = {L\"{u}, Hao and Li, Yang},
title = {Gesture Avatar: A Technique for Operating Mobile User Interfaces Using Gestures},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978972},
doi = {10.1145/1978942.1978972},
abstract = {Finger-based touch input has become a major interaction modality for mobile user interfaces.
However, due to the low precision of finger input, small user interface components
are often difficult to acquire and operate on a mobile device. It is even harder when
the user is on the go and unable to pay close attention to the interface. In this
paper, we present Gesture Avatar, a novel interaction technique that allows users
to operate existing arbitrary user interfaces using gestures. It leverages the visibility
of graphical user interfaces and the casual interaction of gestures. Gesture Avatar
can be used to enhance a range of mobile interactions. A user study we conducted showed
that compared to Shift (an alternative technique for target acquisition tasks), Gesture
Avatar performed at a much lower error rate on various target sizes and significantly
faster on small targets (1mm). It also showed that using Gesture Avatar while walking
did not significantly impact its performance, which makes it suitable for mobile uses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {207–216},
numpages = {10},
keywords = {mobile devices, target acquisition, finger-based touch input, touchscreens, gestures},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248976,
author = {Paul, Sharoda},
title = {Session Details: Twitter Systems},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248976},
doi = {10.1145/3248976},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978974,
author = {Chen, Jilin and Nairn, Rowan and Chi, Ed},
title = {Speak Little and Well: Recommending Conversations in Online Social Streams},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978974},
doi = {10.1145/1978942.1978974},
abstract = {Conversation is a key element in online social streams such as Twitter and Facebook.
However, finding interesting conversations to read is often a challenge, due to information
overload and differing user preferences. In this work we explored five algorithms
that recommend conversations to Twitter users, utilizing thread length, topic and
tie-strength as factors. We compared the algorithms through an online user study and
gathered feedback from real Twitter users. In particular, we investigated how users'
purposes of using Twitter affect user preferences for different types of conversations
and the performance of different algorithms. Compared to a random baseline, all algorithms
recommended more interesting conversations. Further, tie-strength based algorithms
performed significantly better for people who use Twitter for social purposes than
for people who use Twitter for informational purpose only.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–226},
numpages = {10},
keywords = {user preference, social stream, recommender system, conversation},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978975,
author = {Marcus, Adam and Bernstein, Michael S. and Badar, Osama and Karger, David R. and Madden, Samuel and Miller, Robert C.},
title = {Twitinfo: Aggregating and Visualizing Microblogs for Event Exploration},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978975},
doi = {10.1145/1978942.1978975},
abstract = {Microblogs are a tremendous repository of user-generated content about world events.
However, for people trying to understand events by querying services like Twitter,
a chronological log of posts makes it very difficult to get a detailed understanding
of an event. In this paper, we present TwitInfo, a system for visualizing and summarizing
events on Twitter. TwitInfo allows users to browse a large collection of tweets using
a timeline-based display that highlights peaks of high tweet activity. A novel streaming
algorithm automatically discovers these peaks and labels them meaningfully using text
from the tweets. Users can drill down to subevents, and explore further via geolocation,
sentiment, and popular URLs. We contribute a recall-normalized aggregate sentiment
visualization to produce more honest sentiment overviews. An evaluation of the system
revealed that users were able to reconstruct meaningful summaries of events in a small
amount of time. An interview with a Pulitzer Prize-winning journalist suggested that
the system would be especially useful for understanding a long-running event and for
identifying eyewitnesses. Quantitatively, our system can identify 80-100% of manually
labeled peaks, facilitating a relatively complete view of each event studied.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {227–236},
numpages = {10},
keywords = {twitter visualization streaming aggregate sentiment},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978976,
author = {Hecht, Brent and Hong, Lichan and Suh, Bongwon and Chi, Ed H.},
title = {Tweets from Justin Bieber's Heart: The Dynamics of the Location Field in User Profiles},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978976},
doi = {10.1145/1978942.1978976},
abstract = {Little research exists on one of the most common, oldest, and most utilized forms
of online social geographic information: the 'location' field found in most virtual
community user profiles. We performed the first in-depth study of user behavior with
regard to the location field in Twitter user profiles. We found that 34% of users
did not provide real location information, frequently incorporating fake locations
or sarcastic comments that can fool traditional geographic information tools. When
users did input their location, they almost never specified it at a scale any more
detailed than their city. In order to determine whether or not natural user behaviors
have a real effect on the 'locatability' of users, we performed a simple machine learning
experiment to determine whether we can identify a user's location by only looking
at what that user tweets. We found that a user's country and state can in fact be
determined easily with decent accuracy, indicating that users implicitly reveal location
information, with or without realizing it. Implications for location-based services
and privacy are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {237–246},
numpages = {10},
keywords = {twitter, privacy, location-based services, social networks, geography, location, location prediction},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978977,
author = {Geyer, Werner and Dugan, Casey and Brownholtz, Beth and Masli, Mikhil and Daly, Elizabeth and Millen, David R.},
title = {An Open, Social Microcalender for the Enterprise: Timely?},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978977},
doi = {10.1145/1978942.1978977},
abstract = {We present the system design and rational for a novel social microcalendar called
Timely. Our system has been inspired by previous research on calendaring and popular
social network applications, in particular microblogging. Timely provides an open,
social space for enterprise users to share their events, socialize, and discover what
else is going on in their network and beyond. A detailed analysis of the events shared
by users during the site's first 47 days reveals that users willingly share their
time commitments despite an existing culture of restricted calendars.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {247–256},
numpages = {10},
keywords = {social software, electronic calendars, gcs, microcalendar},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248977,
author = {Wulf, Volker},
title = {Session Details: Sex &amp; Bodies},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248977},
doi = {10.1145/3248977},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978979,
author = {Bardzell, Jeffrey and Bardzell, Shaowen},
title = {Pleasure is Your Birthright: Digitally Enabled Designer Sex Toys as a Case of Third-Wave HCI},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978979},
doi = {10.1145/1978942.1978979},
abstract = {In the past decade, HCI has become increasingly preoccupied with the deeply subjective
qualities of interaction: experience, embodiment, pleasure, intimacy, and so on, an
agenda sometimes grouped under the heading of "third-wave HCI"."Analytically understanding
and designing for such qualities has been an ongoing challenge to the field, in part
because its established theories and methodologies are comparatively weak at understanding
and being responsive to human subjectivity. In this paper, we present a case study
of a group of designers who have, in the past few years, revolutionized their domain
- sex toys - by combining embodied pleasure, intimate experience, health and wellness,
emerging technologies, high-quality design processes, and social activism. We consider
the implications this case could have for researchers innovating on especially third-wave
HCI design theories, methodologies, and processes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {257–266},
numpages = {10},
keywords = {human sexuality, HCI, activism, criticism},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978980,
author = {Sambasivan, Nithya and Weber, Julie and Cutrell, Edward},
title = {Designing a Phone Broadcasting System for Urban Sex Workers in India},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978980},
doi = {10.1145/1978942.1978980},
abstract = {In this paper, we present the design, implementation, and deployment of a phone-based
broadcasting system designed for reaching out to at-risk populations in urban India.
We worked in collaboration with Pragati, a non-governmental organization dedicated
to assisting Urban Sex Workers (USWs) in Bangalore, India, with the goal of improving
Pragati's outreach to the women they serve. We conducted ethnographic action research
to understand and address the needs of Pragati and the lifestyles of USWs. Responding
to the unique design constraints of the USW community such as specific privacy and
timing constraints, a desire to remain invisible, and the unusually high rate of mobile
phone use, we designed a phone-based broadcasting system for Pragati. We then deployed
the system on four different occasions and application areas. We present the results
and key findings from our study, and conclude with a discussion on how designing for
particularly difficult cases such as USWs can shed new light on the design of mobile
applications for the developing world in general, such as challenging ubiquity and
phone numbers as identity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {267–276},
numpages = {10},
keywords = {India, urban sex workers, ICT4D, HCI4D, M4D},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978981,
author = {Ferreira, Pedro and H\"{o}\"{o}k, Kristina},
title = {Bodily Orientations around Mobiles: Lessons Learnt in Vanuatu},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978981},
doi = {10.1145/1978942.1978981},
abstract = {Since we started carrying mobiles phones, they have altered the ways in which we orient
our bodies in the world. Many of those changes are invisible to us - they have become
habits, deeply engrained in our society. To make us more aware of our bodily ways
of living with mobiles and open the design space for novel ways of designing mobiles
and their interactions, we decided to study one of the last groups of users on earth
who had not been exposed to mobiles: the people of Vanuatu. As they had so recently
started using mobiles, their use was still in flux: the fragility of the mobile was
unusual to them as was the need to move in order to find coverage. They were still
getting used to carrying their mobiles and keeping them safe. Their encounters with
mobile use exposed the need to consider somaesthetics practices when designing mobiles
as they profoundly affect our bodily ways of being in the world.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {277–286},
numpages = {10},
keywords = {embodiment, experience, ethnography, movement},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248978,
author = {Chi, Ed},
title = {Session Details: Watching Together},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248978},
doi = {10.1145/3248978},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978983,
author = {Vihavainen, Sami and Mate, Sujeet and Sepp\"{a}l\"{a}, Lassi and Cricri, Francesco and Curcio, Igor D.D.},
title = {We Want More: Human-Computer Collaboration in Mobile Social Video Remixing of Music Concerts},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978983},
doi = {10.1145/1978942.1978983},
abstract = {Recording and publishing mobile video clips from music concerts is popular. There
is a high potential to increase the concert's perceived value when producing video
remixes from individual video clips and using them socially. A digital production
of a video remix is an interactive process between human and computer. However, it
is not clear what the collaboration implications between human and computer are.We
present a case study where we compare the processes and products of manual and automatic
mobile video remixing. We provide results from the first systematic real world study
of the subject. We draw our observations from a user trial where fans recorded mobile
video clips during a rock concert.The results reveal issues on heterogeneous interests
of the stakeholders, unexpected uses of the raw material, the burden of editing, diverse
quality requirements, motivations for remixing, the effect of understanding the logic
of automation, and the collaborative use of manual and automatic remixing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {287–296},
numpages = {10},
keywords = {automation, human factors, social, video, mobile, music},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978984,
author = {Yew, Jude and Shamma, David A. and Churchill, Elizabeth F.},
title = {Knowing Funny: Genre Perception and Categorization in Social Video Sharing},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978984},
doi = {10.1145/1978942.1978984},
abstract = {Categorization of online videos is often treated as a tag suggestion task; tags can
be generated by individuals or by machine classification. In this paper, we suggest
categorization can be determined socially, based on people's interactions around media
content without recourse to metadata that are intrinsic to the media object itself.
This work bridges the gap between the human perception of genre and automatic categorization
of genre in classifying online videos. We present findings from two internet surveys
and from follow-up interviews where we address how people determine genre classification
for videos and how social framing of video content can alter the perception and categorization
of that content. From these findings, we train a Naive Bayes classifier to predict
genre categories. The trained classifier achieved 82% accuracy using only social action
data, without the use of content or media-specific metadata. We conclude with implications
on how we categorize and organize media online as well as what our findings mean for
designing and building future tools and interaction experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {297–306},
numpages = {10},
keywords = {video, social, categorization, classification, survey, interview, youtube, naive bayes, genre},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978985,
author = {Sahami Shirazi, Alireza and Rohs, Michael and Schleicher, Robert and Kratz, Sven and M\"{u}ller, Alexander and Schmidt, Albrecht},
title = {Real-Time Nonverbal Opinion Sharing through Mobile Phones during Sports Events},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978985},
doi = {10.1145/1978942.1978985},
abstract = {Even with the rise of the World Wide Web, TV has remained the most pervasive entertainment
medium and is nowadays often used together with other media, which allow for active
participation. The idea of connecting non-collocated TV viewers via telecommunication
technologies, referred to as Social TV, has recently received considerable attention.
Such systems typically include set-top boxes for supporting collaboration. In this
research we investigate if real-time opinion sharing about TV shows through a nonverbal
(non-textual) iconic UI on mobile phones is reasonable. For this purpose we developed
a mobile app, made it available to a large number of users through the Android Market,
and conducted an uncontrolled user study in the wild during the soccer world cup 2010.
The results of the study indicate that TV viewers who used the app had more fun and
felt more connected to other viewers. We also show that by monitoring this channel
it is possible to collect sentiments relevant to the broadcasted content in real-time.
The collected data exemplify that the aggregated sentiments correspond to important
moments, and hence can be used to generate a summary of the event.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {307–310},
numpages = {4},
keywords = {social tv, sports, mobile phone, sentiment support},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978986,
author = {Geerts, David and Vaishnavi, Ishan and Mekuria, Rufael and van Deventer, Oskar and Cesar, Pablo},
title = {Are We in Sync? Synchronization Requirements for Watching Online Video Together.},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978986},
doi = {10.1145/1978942.1978986},
abstract = {Synchronization between locations is an important factor for enabling remote shared
experiences. Still, experimental data on what is the acceptable synchronization level
is scarce. This paper discusses the synchronization requirements for watching online
videos together - a popular set of services that recreate the shared experience of
watching TV together by offering tools to communicate while watching. It studies the
noticeability and annoyance of synchronization differences of the video being watched,
as well as the impact on users' feelings of togetherness, both for voice chat and
text chat. Results of an experiment with 36 participants show that when using voice
chat, users notice synchronization differences sooner, are more annoyed and feel more
together than when using text chat. However, users with high text chat activity notice
synchronization differences similar to participants using voice chat.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {311–314},
numpages = {4},
keywords = {online video, social tv, entertainment, synchronization},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248979,
author = {Gerber, Elizabeth},
title = {Session Details: Health 2: Persuasive Systems},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248979},
doi = {10.1145/3248979},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978988,
author = {Maitland, Julie and Chalmers, Matthew},
title = {Designing for Peer Involvement in Weight Management},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978988},
doi = {10.1145/1978942.1978988},
abstract = {The problems of obesity and overweight are commonly cited as the motivation behind
recent efforts to develop technology that promotes physical activity. Prompted by
the social nature of many of the emerging applications, this paper presents our investigation
of the sociality of weight management as experienced by a broad demographic of individuals.
Our findings highlight the broad scope of peer involvement, and provide insight into
the context and mechanics of related interaction that may prove valuable in informing
the next generation of peer-based weight management technology for use in everyday
life.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {315–324},
numpages = {10},
keywords = {social support, social networks, physical activity, diet, weight, obesity, behavioral change, social influence, health},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978989,
author = {Lee, Min Kyung and Kiesler, Sara and Forlizzi, Jodi},
title = {Mining Behavioral Economics to Design Persuasive Technology for Healthy Choices},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978989},
doi = {10.1145/1978942.1978989},
abstract = {Influence through information and feedback has been one of the main approaches of
persuasive technology. We propose another approach based on behavioral economics research
on decision-making. This approach involves designing the presentation and timing of
choices to encourage people to make self-beneficial decisions. We applied three behavioral
economics persuasion techniques - the default option strategy, the planning strategy,
and the asymmetric choice strategy - to promote healthy snacking in the workplace.
We tested the strategies in three experimental case studies using a human snack deliverer,
a robot, and a snack ordering website. The default and the planning strategies were
effective, but they worked differently depending on whether the participants had healthy
dietary lifestyles or not. We discuss designs for persuasive technologies that apply
behavioral economics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {325–334},
numpages = {10},
keywords = {asymmetric dominance, snacking, default bias, persuasive technology, present-biased preferences, choice, behavioral economics, health technology, healthy eating},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978990,
author = {Kaptein, Maurits and Duplinsky, Steven and Markopoulos, Panos},
title = {Means Based Adaptive Persuasive Systems},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978990},
doi = {10.1145/1978942.1978990},
abstract = {Large differences in individual responses to persuasive strategies suggest the need
for systems that rely on persuasion profiles: estimates of an individual user's susceptibility
to different persuasive strategies. Establishing an empirical ground supporting decisions
regarding user involvement can provide valuable guidelines for the design of such
systems. We describe two studies examining the effects of choice, disclosure, and
multiple strategy usage on user compliance to persuasive attempts. We show that involving
users in the selection of a specific influence strategy can increase compliance, while
disclosing the persuasive intent can reduce compliance. Furthermore, we demonstrate
that it is not only feasible, but optimal to choose the single correct influence strategy
for a given context; even more so than implementing multiple relevant and congruent
influence attempts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {335–344},
numpages = {10},
keywords = {recommender systems, influence strategies, adaptive systems, persuasive technology, online commerce},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978991,
author = {Schwanda, Victoria and Ibara, Steven and Reynolds, Lindsay and Cosley, Dan},
title = {Side Effects and "Gateway" Tools: Advocating a Broader Look at Evaluating Persuasive Systems},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978991},
doi = {10.1145/1978942.1978991},
abstract = {This paper argues for evaluating the impact of persuasive systems on users beyond
metrics that focus on system usage, based on an interview study of 16 Wii Fit users.
While exploring their experiences and reasons for abandoning the system, two main
themes emerged: the tension between Wii Fit as a fitness tool and a game, and ways
participants reacted to the system's feedback about their weight and performance.
Some participants used Wii Fit as a "gateway fitness" tool, moving beyond it to other
fitness routines. Additionally, some users had significant emotional reactions to
the Wii Fitts feedback. We argue that these 'side effects' are crucial considerations
for the design and long-term evaluation of persuasive technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {345–348},
numpages = {4},
keywords = {persuasive technologies, wii fit, e-health interventions},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978992,
author = {Schwind, Christina and Buder, J\"{u}rgen and Hesse, Friedrich W.},
title = {I Will Do It, but i Don't like It: User Reactions to Preference-Inconsistent Recommendations},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978992},
doi = {10.1145/1978942.1978992},
abstract = {Recommender systems have their origin in e-commerce. In this domain the users are
meant to like the recommended information. This preference-consistency is not adequate
or even desirable for all domains where recommender systems are implemented. One key
issue for opinion formation and informed decision making is to be aware of more than
one's own perspective. However, information search is often biased, because confirming
information is favored over opposing information. Therefore it would be useful to
recommend information that is inconsistent to users' prior perspective to help overcome
this bias. The present paper deals with an online experiment aimed at investigating
the effects of preference-consistent compared to preference-inconsistent recommendations
on information selection and evaluation. Results showed a significant reduction of
confirmation bias in the condition with preference-inconsistent recommendations. However,
participants prefer preference-consistent recommendations in terms of global, cognitive
and affective evaluations. We discuss the impact of these findings for application.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {349–352},
numpages = {4},
keywords = {confirmation bias, recommendations, experimental study},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248980,
author = {Mandryk, Regan},
title = {Session Details: Brain &amp; Bio-Sensor Interactions},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248980},
doi = {10.1145/3248980},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978994,
author = {O'Hara, Kenton and Sellen, Abigail and Harper, Richard},
title = {Embodiment in Brain-Computer Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978994},
doi = {10.1145/1978942.1978994},
abstract = {With emerging opportunities for using Brain-Computer Interaction (BCI) in gaming applications,
there is a need to understand the opportunities and constraints of this interaction
paradigm. To complement existing laboratory-based studies, there is also a call for
the study of BCI in real world contexts. In this paper we present such a real world
study of a simple BCI game called MindFlex®, played as a social activity in the home.
In particular, drawing on the philosophical traditions of embodied interaction, we
highlight the importance of considering the body in BCI and not simply what is going
on in the head. The study shows how people use bodily actions to facilitate control
of brain activity but also to make their actions and intentions visible to, and interpretable
by, others playing and watching the game. It is the public availability of these bodily
actions during BCI that allows action to be socially organised, understood and coordinated
with others and through which social relationships can be played out. We discuss the
implications of this perspective and findings for BCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {353–362},
numpages = {10},
keywords = {embodied interaction, brain-computer interaction, play, gaming},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978995,
author = {Pan, Matthew K.X.J. and Chang, Jih-Shiang and Himmetoglu, Gokhan H. and Moon, AJung and Hazelton, Thomas W. and MacLean, Karon E. and Croft, Elizabeth A.},
title = {Now Where Was I? Physiologically-Triggered Bookmarking},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978995},
doi = {10.1145/1978942.1978995},
abstract = {This work explores a novel interaction paradigm driven by implicit, low-attention
user control, accomplished by monitoring a user's physiological state. We have designed
and prototyped this interaction for a first use case of bookmarking an audio stream,
to holistically explore the implicit interaction concept. Here, a user's galvanic
skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions;
our prototype automatically bookmarks the media such that the user can attend to the
interruption, then resume listening from the point he/she is interrupted. To test
this approach's viability, we addressed questions such as: does GSR exhibit a detectable
response to interruptions, and how should the interaction utilize this information?
In evaluating this system in a controlled environment, we found an OR detection accuracy
of 84%; users provided subjective feedback on its accuracy and utility.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {363–372},
numpages = {10},
keywords = {orienting response, physiological signals, interruption, human-computer interaction, galvanic skin response},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978996,
author = {Hirshfield, Leanne M. and Gulotta, Rebecca and Hirshfield, Stuart and Hincks, Sam and Russell, Matthew and Ward, Rachel and Williams, Tom and Jacob, Robert},
title = {This is Your Brain on Interfaces: Enhancing Usability Testing with Functional near-Infrared Spectroscopy},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978996},
doi = {10.1145/1978942.1978996},
abstract = {This project represents a first step towards bridging the gap between HCI and cognition
research. Using functional near-infrared spectroscopy (fNIRS), we introduce tech-niques
to non-invasively measure a range of cognitive workload states that have implications
to HCI research, most directly usability testing. We present a set of usability experiments
that illustrates how fNIRS brain measurement provides information about the cognitive
demands placed on computer users by different interface designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {373–382},
numpages = {10},
keywords = {workload, usability testing, brain, fNIRS, functional near infrared spectroscopy},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978997,
author = {Solovey, Erin Treacy and Lalooses, Francine and Chauncey, Krysta and Weaver, Douglas and Parasi, Margarita and Scheutz, Matthias and Sassaroli, Angelo and Fantini, Sergio and Schermerhorn, Paul and Girouard, Audrey and Jacob, Robert J.K.},
title = {Sensing Cognitive Multitasking for a Brain-Based Adaptive User Interface},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978997},
doi = {10.1145/1978942.1978997},
abstract = {Multitasking has become an integral part of work environments, even though people
are not well-equipped cognitively to handle numerous concurrent tasks effectively.
Systems that support such multitasking may produce better performance and less frustration.
However, without understanding the user's internal processes, it is difficult to determine
optimal strategies for adapting interfaces, since all multitasking activity is not
identical. We describe two experiments leading toward a system that detects cognitive
multitasking processes and uses this information as input to an adaptive interface.
Using functional near-infrared spectroscopy sensors, we differentiate four cognitive
multitasking processes. These states cannot readily be distinguished using behavioral
measures such as response time, accuracy, keystrokes or screen contents. We then present
our human-robot system as a proof-of-concept that uses real-time cognitive state information
as input and adapts in response. This prototype system serves as a platform to study
interfaces that enable better task switching, interruption management, and multitasking.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {383–392},
numpages = {10},
keywords = {near-infrared spectroscopy, human-robot interaction, brain computer interface, fnirs, multitasking, interruption},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248981,
author = {Feiner, Steven},
title = {Session Details: Gestures},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248981},
doi = {10.1145/3248981},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978999,
author = {Choi, Sangwon and Han, Jaehyun and Lee, Geehyuk and Lee, Narae and Lee, Woohun},
title = {RemoteTouch: Touch-Screen-like Interaction in the Tv Viewing Environment},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978999},
doi = {10.1145/1978942.1978999},
abstract = {We explored the possibility of touch-screen-like interaction with a remote control
in the TV-viewing environment. A shadow representing the user's thumb touches the
screen, presses a button, flicks a cover-flow list, and draws a simple stroke, while
the thumb stays and moves on and above the touchpad. In order to implement the concept
we developed an optical touchpad for tracking the thumb hovering over its surface,
and designed a TV application to demonstrate possible new interaction styles. Throughout
two iterations of prototyping, we corrected some of our false expectations, and also
verified its potential as a viable option for a TV remote control. This paper presents
technical issues and requirements for the hover-tracking touchpad and a complete report
of our user studies to explore touch-screen-like interaction for the TV.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {393–402},
numpages = {10},
keywords = {tv user interface, hover-tracking touchpad, remotetouch interaction, tv remote control},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979000,
author = {Bragdon, Andrew and Nelson, Eugene and Li, Yang and Hinckley, Ken},
title = {Experimental Analysis of Touch-Screen Gesture Designs in Mobile Environments},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979000},
doi = {10.1145/1978942.1979000},
abstract = {Direct-touch interaction on mobile phones revolves around screens that compete for
visual attention with users' real-world tasks and activities. This paper investigates
the impact of these situational impairments on touch-screen interaction. We probe
several design factors for touch-screen gestures, under various levels of environmental
demands on attention, in comparison to the status-quo approach of soft buttons. We
find that in the presence of environmental distractions, gestures can offer significant
performance gains and reduced attentional load, while performing as well as soft buttons
when the user's attention is focused on the phone. In fact, the speed and accuracy
of bezel gestures did not appear to be significantly affected by environment, and
some gestures could be articulated eyes-free, with one hand. Bezel-initiated gestures
offered the fastest performance, and mark-based gestures were the most accurate. Bezel-initiated
marks therefore may offer a promising approach for mobile touch-screen interaction
that is less demanding of the user's attention.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {403–412},
numpages = {10},
keywords = {mobile phones, evaluation, touch, gestures, performance},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979001,
author = {Kane, Shaun K. and Wobbrock, Jacob O. and Ladner, Richard E.},
title = {Usable Gestures for Blind People: Understanding Preference and Performance},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979001},
doi = {10.1145/1978942.1979001},
abstract = {Despite growing awareness of the accessibility issues surrounding touch screen use
by blind people, designers still face challenges when creating accessible touch screen
interfaces. One major stumbling block is a lack of understanding about how blind people
actually use touch screens. We conducted two user studies that compared how blind
people and sighted people use touch screen gestures. First, we conducted a gesture
elicitation study in which 10 blind and 10 sighted people invented gestures to perform
common computing tasks on a tablet PC. We found that blind people have different gesture
preferences than sighted people, including preferences for edge-based gestures and
gestures that involve tapping virtual keys on a keyboard. Second, we conducted a performance
study in which the same participants performed a set of reference gestures. We found
significant differences in the speed, size, and shape of gestures performed by blind
people versus those performed by sighted people. Our results suggest new design guidelines
for accessible touch screen interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {413–422},
numpages = {10},
keywords = {touch screens, gestures, blind, gesture recognition, accessibility},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248982,
author = {Kaye, Jofish},
title = {Session Details: Designing for Values, Democracy &amp; Peace},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248982},
doi = {10.1145/3248982},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979003,
author = {Purpura, Stephen and Schwanda, Victoria and Williams, Kaiton and Stubler, William and Sengers, Phoebe},
title = {Fit4life: The Design of a Persuasive Technology Promoting Healthy Behavior and Ideal Weight},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979003},
doi = {10.1145/1978942.1979003},
abstract = {This is a critical design paper offering a possible scenario of use intended to provoke
reflection about values and politics of design in persuasive computing. We describe
the design of a system - Fit4Life - that encourages individuals to address the larger
goal of reducing obesity in society by promoting individual healthy behaviors. Using
the Persuasive Systems Design Model [26], this paper outlines the Fit4Life persuasion
context, the technology, its use of persuasive messages, and an experimental design
to test the system's efficacy. We also contribute a novel discussion of the ethical
and sociocultural considerations involved in our design, an issue that has remained
largely unaddressed in the existing persuasive technologies literature [29].},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {423–432},
numpages = {10},
keywords = {weight loss, persuasive technology, social implications, critical design},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979004,
author = {Assogba, Yannick and Ros, Irene and DiMicco, Joan and McKeon, Matt},
title = {Many Bills: Engaging Citizens through Visualizations of Congressional Legislation},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979004},
doi = {10.1145/1978942.1979004},
abstract = {US federal legislation is a common subject of discussion and advocacy on the web,
inspired by the open government movement. While the contents of these bills are freely
available for download, understanding them is a significant challenge to experts and
average citizens alike due to their length, complex language, and obscure topics.
To make these important documents more accessible to the general public, we present
Many Bills (http://manybills.us): a web-based set of visualization tools that reveals
the underlying semantics of a bill. Using machine learning techniques, we classify
each bill's sections based on existing document-level categories. We then visualize
the resulting topic substructure of these bills. These visualizations provide an overview-and-detail
view of bills, enabling users to read individual sections of a bill and compare topic
patterns across multiple bills. Through an overview of the site's user activity and
interviews with active users, this paper highlights how Many Bills makes the tasks
of reading bills, identifying outlier sections in bills, and understanding congressperson's
legislative activity more manageable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {433–442},
numpages = {10},
keywords = {government, text classification, legislation, information visualization, government transparency},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979005,
author = {Hourcade, Juan Pablo and Bullock-Rest, Natasha E.},
title = {HCI for Peace: A Call for Constructive Action},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979005},
doi = {10.1145/1978942.1979005},
abstract = {Peace is an important value for the human-computer interaction research community,
yet it has not resulted in the development of a research sub-community or even a research
agenda. In this paper we seek to address this void by first motivating the need for
computing research on promoting peace and preventing war. We then review evidence
on the factors that affect the likelihood that armed conflict will occur, as well
as the aspects involved when individuals make moral decisions on whether or not to
support a war. Based on this review, we propose a research agenda, citing research
examples from the human-computer interaction literature and discussing new ideas.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {443–452},
numpages = {10},
keywords = {empathy, peace, research agenda, software, compassion, causes of conflict, technology, war},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979006,
author = {Jayatilaka, Lahiru G. and Bertuccelli, Luca F. and Staszewski, James and Gajos, Krzysztof Z.},
title = {Evaluating a Pattern-Based Visual Support Approach for Humanitarian Landmine Clearance},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979006},
doi = {10.1145/1978942.1979006},
abstract = {Unexploded landmines have severe post-conflict humanitarian repercussions: landmines
cost lives, limbs and land. For deminers engaged in humanitarian landmine clearance,
metal detectors remain the primary detection tool as more sophisticated technologies
fail to get adopted due to restrictive cost, low reliability, and limited robustness.
Metal detectors are, however, of limited effectiveness, as modern landmines contain
only minimal amounts of metal, making them difficult to distinguish from the ubiquitous
but harmless metallic clutter littering post-combat areas. We seek to improve the
safety and efficiency of the demining process by developing support tools that will
enable deminers to make better decisions using feedback from existing metal detectors.
To this end, in this paper we propose and evaluate a novel, pattern-based visual support
approach inspired by the documented strategies employed by expert deminers. In our
laboratory study, participants provided with a prototype of our support tool were
80% less likely to mistake a mine for harmless clutter. A follow-up study demonstrates
the potential of our pattern-based approach to enable peer decision-making support
during landmine clearance. Lastly, we identify several design opportunities for further
improving deminers' decision making capabilities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {453–462},
numpages = {10},
keywords = {humanitarian landmine clearance, visual support, decision support, demining},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248983,
author = {Salvucci, Dario},
title = {Session Details: Driving},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248983},
doi = {10.1145/3248983},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979008,
author = {Iqbal, Shamsi T. and Horvitz, Eric and Ju, Yun-Cheng and Mathews, Ella},
title = {Hang on a Sec! Effects of Proactive Mediation of Phone Conversations While Driving},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979008},
doi = {10.1145/1978942.1979008},
abstract = {Conversing on cell phones while driving is a risky, yet commonplace activity. State
legislatures in the U.S. have enacted rules that limit hand-held phone conversations
while driving but that allow for hands-free conversations. However, studies have demonstrated
that the cognitive load of conversation is a significant source of distraction that
increases the likelihood of accidents. We explore in a controlled study with a driving
simulator the effectiveness of proactive alerting and mediation of communications
during phone conversations while driving. We study the use of auditory messages indicating
upcoming critical road conditions and placing calls on hold. We found that such actions
reduce driving errors and that alerts sharing details about situations were more effective
than general alerts. Drivers found such a system valuable in most situations for maintaining
driving safety. These results provide evidence that context-sensitive mediation systems
could play a valuable role in focusing drivers' attention on the road during phone
conversations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {463–472},
numpages = {10},
keywords = {attention, driving, context-sensitive systems, cell phones},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979009,
author = {Brumby, Duncan P. and Davies, Samantha C.E. and Janssen, Christian P. and Grace, Justin J.},
title = {Fast or Safe? How Performance Objectives Determine Modality Output Choices While Interacting on the Move},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979009},
doi = {10.1145/1978942.1979009},
abstract = {In-car devices that use audio output have been shown to be less distracting than traditional
graphical user interfaces, but can be cumbersome and slow to use. In this paper, we
report an experiment that demonstrates how these performance characteristics impact
whether people will elect to use an audio interface in a multitasking situation. While
steering a simulated vehicle, participants had to locate a source of information in
a short passage of text. The text was presented either on a visual interface, or using
a text-to-speech audio interface. The relative importance of each task was varied.
A no-choice/choice paradigm was used in which participants first gained experience
with each of the two interfaces, before being given a choice on which interface to
use on later trials. The characteristics of the interaction with the interfaces, as
measured in the no-choice phase, and the relative importance of each task, had an
impact on which output modality was chosen in the choice phase. Participants that
prioritized the secondary task tended to select the (faster yet more distracting)
visual interface over the audio interface, and as a result had poorer lane keeping
performance. This work demonstrates how a user's task objective will influence modality
choices with multimodal devices in multitask environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–482},
numpages = {10},
keywords = {multitasking, driving, visual interface, audio interface, strategy selection, performance trade-offs.},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979010,
author = {D\"{o}ring, Tanja and Kern, Dagmar and Marshall, Paul and Pfeiffer, Max and Sch\"{o}ning, Johannes and Gruhn, Volker and Schmidt, Albrecht},
title = {Gestural Interaction on the Steering Wheel: Reducing the Visual Demand},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979010},
doi = {10.1145/1978942.1979010},
abstract = {Cars offer an increasing number of infotainment systems as well as comfort functions
that can be controlled by the driver. In our research, we investigate new interaction
techniques that aim to make it easier to interact with these systems while driving.
We suggest utilizing the steering wheel as an additional interaction surface. In this
paper, we present two user studies conducted with a working prototype of a multi-touch
steering wheel. In the first, we developed a user-defined steering wheel gesture set,
and in the second, we applied the identified gestures and compared their application
to conventional user interaction with infotainment systems in terms of driver distraction.
The main outcome was that driver's visual demand is reduced significantly by using
gestural interaction on the multi-touch steering wheel.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {483–492},
numpages = {10},
keywords = {user-defined gestures, driver distraction, visual demand, automotive user interfaces, multi-touch, gestural input},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979011,
author = {Kim, SeungJun and Dey, Anind K. and Lee, Joonhwan and Forlizzi, Jodi},
title = {Usability of Car Dashboard Displays for Elder Drivers},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979011},
doi = {10.1145/1978942.1979011},
abstract = {The elder population is rising worldwide; in the US, no longer being able to drive
is a significant marker of loss of independence. One of the approaches to helping
elders drive more safely is to investigate the use of automotive user interface technology,
and specifically, to explore the instrument panel (IP) display design to help attract
and manage attention and make information easier to interpret.In this paper, we explore
the premise that dashboard displays can be better designed to support elder drivers,
their information needs, and their cognitive capabilities. We conducted a study to
understand which display design features are critically linked to issues of divided
attention and driving performance. We found that contrast of size and reduced clutter
are instrumental in enhancing driving performance, particularly for the elder population.
Surprisingly, our results showed that color elements have a negative effect on driving
performance for elders, while color elements and fills slightly improve performance.
We conclude with design implications generated from this work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {493–502},
numpages = {10},
keywords = {eye tracking, interface design, senior drivers, dashboard, dashboard display, divided attention, automotive ui},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248984,
author = {Ju, Wendy},
title = {Session Details: Meetings &amp; Interaction Spaces},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248984},
doi = {10.1145/3248984},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979013,
author = {Erickson, Thomas and Shami, N. Sadat and Kellogg, Wendy A. and Levine, David W.},
title = {Synchronous Interaction among Hundreds: An Evaluation of a Conference in an Avatar-Based Virtual Environment},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979013},
doi = {10.1145/1978942.1979013},
abstract = {This paper presents the first in-depth evaluation of a large multi-format virtual
conference. The conference took place in an avatar-based 3D virtual world with spatialized
audio, and had keynote, poster and social sessions. We studied it by drawing on logs,
a survey and interviews with 30 participants. We develop a model - Coalescence, Focused
Interaction, Remixing (CoFIRe) -- of large synchronous interactions, and use it to
discuss how the technology supported, or failed to support, the interactions that
are the raison d'etre of conferences. We conclude by discussing the prospects for
such large virtual gatherings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–512},
numpages = {10},
keywords = {virtual conference, synchronous interaction, spatialized audio, second life, collaborative virtual environment, CVE, CMC, virtual world},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979014,
author = {Junuzovic, Sasa and Inkpen, Kori and Hegde, Rajesh and Zhang, Zhengyou and Tang, John and Brooks, Christopher},
title = {What Did i Miss? In-Meeting Review Using Multimodal Accelerated Instant Replay (Air) Conferencing},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979014},
doi = {10.1145/1978942.1979014},
abstract = {People sometimes miss small parts of meetings and need to quickly catch up without
disrupting the rest of the meeting. We developed an Accelerated Instant Replay (AIR)
Conferencing system for videoconferencing that enables users to catch up on missed
content while the meeting is ongoing. AIR can replay parts of the conference using
four different modalities: audio, video, conversation transcript, and shared workspace.
We performed two studies to evaluate the system. The first study explored the benefit
of AIR catch-up during a live meeting. The results showed that when the full videoconference
was reviewed (i.e., all four modalities) at an accelerated rate, users were able to
correctly recall a similar amount of information as when listening live. To better
understand the benefit of full review, a follow-up study more closely examined the
benefits of each of the individual modalities. The results show that users (a) preferred
using audio along with any other modality to using audio alone, (b) were most confident
and performed best when audio was reviewed with all other modalities, (c) compared
to audio-only, had better recall of facts and explanations when reviewing audio together
with the shared workspace and transcript modalities, respectively, and (d) performed
similarly with audio-only and audio with video review.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {513–522},
numpages = {10},
keywords = {review, telepresence, audio, video, dvr, meetings, shared workspace, transcript, cscw, videoconferencing},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248985,
author = {Voida, Amy},
title = {Session Details: Art, Music &amp; Movement},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248985},
doi = {10.1145/3248985},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979016,
author = {Zhou, Yinsheng and Percival, Graham and Wang, Xinxi and Wang, Ye and Zhao, Shengdong},
title = {MOGCLASS: Evaluation of a Collaborative System of Mobile Devices for Classroom Music Education of Young Children},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979016},
doi = {10.1145/1978942.1979016},
abstract = {Composition, listening, and performance are essential activities in classroom music
education, yet conventional music classes impose unnecessary limitations on students'
ability to develop these skills. Based on in-depth fieldwork and a user-centered design
approach, we created MOGCLASS, a multimodal collaborative music environment that enhances
students' musical experience and improves teachers' management of the classroom.We
conducted a two-round system evaluation to improve the prototype and evaluate the
system: Improvements were made based on the results from an iterative design evaluation,
in which a trial system was implemented. The system then underwent a second round
of evaluation through a three-week between-subject controlled experiment in a local
primary school. Results showed that MOGCLASS is effective in motivating students to
learn music, improving the way they collaborate with other students as well as helping
teachers manage the classroom.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {523–532},
numpages = {10},
keywords = {user-centered design, mobile devices, music, children, musical instruments, education},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979017,
author = {van der Linden, Janet and Johnson, Rose and Bird, Jon and Rogers, Yvonne and Schoonderwaldt, Erwin},
title = {Buzzing to Play: Lessons Learned from an in the Wild Study of Real-Time Vibrotactile Feedback},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979017},
doi = {10.1145/1978942.1979017},
abstract = {Vibrotactile feedback offers much potential for facilitating and accelerating how
people learn sensory-motor skills that typically take hundreds of hours to learn,
such as learning to play a musical instrument, skiing or swimming. However, there
is little evidence of this benefit materializing outside of research lab settings.
We describe the findings of an in-the-wild study that explored how to integrate vibrotactile
feedback into a real-world teaching setting. The focus of the study was on exploring
how children of different ages, learning to play the violin, can use real-time vibrotactile
feedback. Many of the findings were unexpected, showing how students and their teachers
appropriated the technology in creative ways. We present some 'lessons learned' that
are also applicable to other training settings, emphasizing the need to understand
how vibrotactile feedback can switch between being foregrounded and backgrounded depending
on the demands of the task, the teacher's role in making it work and when feedback
is most relevant and useful. Finally, we discuss how vibrotactile feedback can provide
a new language for talking about the skill being learned that may also play an instrumental
role in enhancing learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {533–542},
numpages = {10},
keywords = {vibrotactile feedback, violin teaching, children, in the wild study, motion capture, sensory-motor learning},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979018,
author = {Tamaki, Emi and Miyaki, Takashi and Rekimoto, Jun},
title = {PossessedHand: Techniques for Controlling Human Hands Using Electrical Muscles Stimuli},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979018},
doi = {10.1145/1978942.1979018},
abstract = {If a device can control human hands, the device can be useful for HCI and tangible
application's output. To aid the controlling of finger movement, we present PossessedHand,
a device with a forearm belt that can inform when and which fingers should be moved.
PossessedHand controls the user's fingers by applying electrical stimulus to the muscles
around the forearm. Each muscle is stimulated via 28 electrode pads. Muscles at different
depths in the forearm can be selected for simulation by varying the stimulation level.
PossessedHand can automatically calibrate the system for individuals. The automatic
calibration system estimates relations between each electrode pad, stimulation level
and muscle movement. Experiments show that PossessedHand can control the motion of
16 joints in the hand. Further, we also discuss an application based on this device
to aid in playing a musical instrument.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {543–552},
numpages = {10},
keywords = {fes, ems, hand gesture, musical performance, electric stimulation},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979019,
author = {McLoughlin, Marc and Ciolfi, Luigina},
title = {Design Interventions for Open-Air Museums: Applying and Extending the Principles of 'Assembly'},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979019},
doi = {10.1145/1978942.1979019},
abstract = {This paper presents an empirical approach to designing and deploying technologies
to support visitor activities in exhibition spaces. Specifically, we focus on the
concept of "assembly" and how it was extended and applied to develop an interactive
installation for an open-air museum. We argue that this approach to designing for
a meaningful visitor experience is particularly suited to open-air visit scenarios;
we describe how we have extended the approach and applied it, detailing the resulting
multi-device installation that was deployed on site, and presenting some reflections
on the usefulness of the assembly concept.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {553–556},
numpages = {4},
keywords = {design approaches, museums, assemblies, ubiquitous computing},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979020,
author = {Halpern, Megan K. and Tholander, Jakob and Evjen, Max and Davis, Stuart and Ehrlich, Andrew and Schustak, Kyle and Baumer, Eric P.S. and Gay, Geri},
title = {MoBoogie: Creative Expression through Whole Body Musical Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979020},
doi = {10.1145/1978942.1979020},
abstract = {In this paper we describe MoBoogie, an application that allows users to manipulate
and arrange music through movement. MoBoogie is designed to foster experiences in
creative expression for children and potentially adults. The application responds
to users' movements by changing variables in a continuous stream of music loops. Results
from this study suggest that the creative expressions arose in the joint space of
movement and music, and did not primarily have to be in one form or the other. This
allowed users with limited experience in dance and music making to be creative in
such forms of expression.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {557–560},
numpages = {4},
keywords = {mobile interaction, creative expression, whole-body interaction, music},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248986,
author = {Busse, Daniela},
title = {Session Details: Facebook},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248986},
doi = {10.1145/3248986},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979022,
author = {Ozenc, Fatih Kursat and Farnham, Shelly D.},
title = {Life "Modes" in Social Media},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979022},
doi = {10.1145/1978942.1979022},
abstract = {Current social media products such as Facebook and Twitter have not sufficiently addressed
how to help users organize people and content streams across different areas of their
lives. We conducted a qualitative design research study to explore how we might best
leverage natural models of social organization to improve experiences of social media.
We found that participants organize their social worlds based on life 'modes', i.e.,
family, work and social. They strategically use communication technologies to manage
intimacy levels within these modes, and levels of permeability through the boundaries
between these modes. Mobile communication in particular enabled participants to aggregate
and share content dynamically across life modes. While exploring problems with managing
their social media streams, people showed a strong need for focused sharing - the
ability to share content only with appropriate audiences within certain areas of life.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {561–570},
numpages = {10},
keywords = {modes, privacy, boundaries, facebook, email, faceted identity, roles, identity, social networks, transitions, social media},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979023,
author = {Burke, Moira and Kraut, Robert and Marlow, Cameron},
title = {Social Capital on Facebook: Differentiating Uses and Users},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979023},
doi = {10.1145/1978942.1979023},
abstract = {Though social network site use is often treated as a monolithic activity, in which
all time is equally social and its impact the same for all users, we examine how Facebook
affects social capital depending upon: (1) types of site activities, contrasting one-on-one
communication, broadcasts to wider audiences, and passive consumption of social news,
and (2) individual differences among users, including social communication skill and
self-esteem. Longitudinal surveys matched to server logs from 415 Facebook users reveal
that receiving messages from friends is associated with increases in bridging social
capital, but that other uses are not. However, using the site to passively consume
news assists those with lower social fluency draw value from their connections. The
results inform site designers seeking to increase social connectedness and the value
of those connections.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {571–580},
numpages = {10},
keywords = {computer-mediated communication, social skills, social network sites, social capital, self-esteem},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979024,
author = {Jianqiang, Don Sim and Ma, Xiaojuan and Zhao, Shengdong and Khoo, Jing Ting and Bay, Swee Ling and Jiang, Zhenhui},
title = {Farmer's Tale: A Facebook Game to Promote Volunteerism},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979024},
doi = {10.1145/1978942.1979024},
abstract = {Volunteering is an important activity that brings great benefits to societies. However,
encouraging volunteerism is difficult due to the altruistic nature of volunteer activities
and the high resource demand in carrying them out. We have created a Facebook game
called "Farmer's Tale" to attract and make it easier for people to volunteer. We evaluated
people's acceptance to this novel idea and the results revealed great potential in
such type of games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {581–584},
numpages = {4},
keywords = {volunteerism, social networking, persuasive games},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979025,
author = {Yoder, Christian and Stutzman, Fred},
title = {Identifying Social Capital in the Facebook Interface},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979025},
doi = {10.1145/1978942.1979025},
abstract = {A number of studies have identified a robust relationship between the use of social
network sites, particularly Facebook, and positive outcomes such as social capital.
Social network site use is often measured as a function of use frequency, network
size, and a range of subjective opinions about the value of the site. This research
extends this understanding by exploring the relationship between the use of particular
elements of the site and social capital. Our goal in this research is to identify
where, in the interface, perceived social capital is most effectively produced and
transmitted. We find that, as hypothesized, public, person-to-person communication
is positively associated with perceived social capital. Through the use of a structural
equation model, we are able to provide in-depth exploration of the relationship between
the interface elements and the outcome, perceived social capital.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {585–588},
numpages = {4},
keywords = {behavioral modeling, social network sites, social capital, privacy, facebook, social networking},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248987,
author = {Kientz, Julie},
title = {Session Details: Health 3: Online Communities &amp; Social Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248987},
doi = {10.1145/3248987},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979027,
author = {Mankoff, Jennifer and Kuksenok, Kateryna and Kiesler, Sara and Rode, Jennifer A. and Waldman, Kelly},
title = {Competing Online Viewpoints and Models of Chronic Illness},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979027},
doi = {10.1145/1978942.1979027},
abstract = {People with chronic health problems use online resources to understand and manage
their condition, but many such resources can present competing and confusing viewpoints.
We surveyed and interviewed with people experiencing prolonged symptoms after a Lyme
disease diagnosis. We explore how competing viewpoints in online content affect participants'
understanding of their disease. Our results illustrate how chronically ill people
search for information and support, and work to help others over time. Participant
identity and beliefs about their illness evolved, and this led many to take on new
roles, creating content and advising others who were sick. What we learned about online
content creation suggests a need for designs that support this journey and engage
with complex issues surrounding online health resources.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {589–598},
numpages = {10},
keywords = {health, search, community, social media, interviews},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979028,
author = {Kim, Hyang-Sook and Sundar, S. Shyam},
title = {Using Interface Cues in Online Health Community Boards to Change Impressions and Encourage User Contribution},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979028},
doi = {10.1145/1978942.1979028},
abstract = {Online health message boards have become popular, as users not only gain information
from other users but also share their own experiences. However, as with most venues
of user-generated content, there is need to constantly make quality evaluations as
one sifts through enormous amounts of content. Can interface cues, conveying (1) pedigree
of users posting content and (2) popularity of the posted content, help new users
efficiently make credibility assessments? Furthermore, can the assignment of these
same cues to their own posts serve to motivate content generation on their part? These
questions were investigated in a 2-session between-subjects experiment (N = 99) with
a prototype of a message-board that experimentally varied interface cues, and found
that popularity indicators are more influential than pedigree indicators for both
evaluation of existing content and contribution of new content. Findings also suggest
theoretical mechanisms - involving such concepts as perceived authority, bandwagon
effects, sense of agency and sense of community - by which cues affect user experience,
providing rich implications for designing and deploying interface cues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {599–608},
numpages = {10},
keywords = {sense of agency, heuristics, authority cues, user contribution, health community boards, sense of community, bandwagon cues},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979029,
author = {Hailpern, Joshua and Danilevsky, Marina and Harris, Andrew and Karahalios, Karrie and Dell, Gary and Hengst, Julie},
title = {ACES: Promoting Empathy towards Aphasia through Language Distortion Emulation Software},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979029},
doi = {10.1145/1978942.1979029},
abstract = {Individuals with aphasia, an acquired communication disorder, constantly struggle
against a world that does not understand them. This lack of empathy and understanding
negatively impacts their quality of life. While aphasic individuals may appear to
have lost cognitive functioning, their impairment relates to receptive and expressive
language, not to thinking processes. We introduce a novel system and model, Aphasia
Characteristics Emulation Software (ACES), enabling users (e.g., caregivers, speech
therapists and family) to experience, firsthand, the communication-distorting effects
of aphasia. By allowing neurologically typical individuals to "walk in another's shoes,"
we aim to increase patience, awareness and understanding. ACES was grounded in the
communication science and psychological literature, and informed by an initial pilot
study. Results from an evaluation of 64 participants indicate that ACES provides a
rich experience that increases understanding and empathy for aphasia.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {609–618},
numpages = {10},
keywords = {language, disabilities, emulation software, speech, empathy, assistive technology, aphasia},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979030,
author = {McNaney, Roisin and Lindsay, Stephen and Ladha, Karim and Ladha, Cassim and Schofield, Guy and Ploetz, Thomas and Hammerla, Nils and Jackson, Daniel and Walker, Richard and Miller, Nick and Olivier, Patrick},
title = {Cueing for Drooling in Parkinson's Disease},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979030},
doi = {10.1145/1978942.1979030},
abstract = {We present the development of a socially acceptable cueing device for drooling in
Parkinson's disease (PD). Sialorrhea, or drooling, is a significant problem associated
with PD and has a strong negative emotional impact on those who experience it. Previous
studies have shown the potential for managing drooling by using a cueing device. However,
the devices used in these studies were deemed unacceptable by their users due to factors
such as hearing impairment and social embarrassment. We conducted exploratory scoping
work and high fidelity iterative prototyping with people with PD to get their input
on the design of a cueing aid and this has given us an insight into challenges that
confront users with PD and limit device usability and acceptability. The key finding
from working with people with PD was the need for the device to be socially acceptable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {619–622},
numpages = {4},
keywords = {drooling, Parkinson's disease, participatory design, swallowing},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979031,
author = {Wacharamanotham, Chat and Hurtmanns, Jan and Mertens, Alexander and Kronenbuerger, Martin and Schlick, Christopher and Borchers, Jan},
title = {Evaluating Swabbing: A Touchscreen Input Method for Elderly Users with Tremor},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979031},
doi = {10.1145/1978942.1979031},
abstract = {Elderly users suffering from hand tremor have difficulties interacting with touchscreens
because of finger oscillation. It has been previously observed that sliding one's
finger across the screen may help reduce this oscillation. In this work, we empirically
confirm this advantage by (1) measuring finger oscillation during different actions
and (2) comparing error rate and user satisfaction between traditional tapping and
swabbing in which the user slides his finger towards a target on a screen edge to
select it. We found that oscillation is generally reduced during sliding. Also, compared
to tapping, swabbing resulted in improved error rates and user satisfaction. We believe
that swabbing will make touchscreens more accessible to senior users with tremor.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {623–626},
numpages = {4},
keywords = {accuracy, touchscreen, tapping, older adults, input methods, evaluation, swabbing, tremor},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248988,
author = {Vera, Alonso},
title = {Session Details: Human-Robot Interaction},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248988},
doi = {10.1145/3248988},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979033,
author = {Kwon, Bum chul and Javed, Waqas and Elmqvist, Niklas and Yi, Ji Soo},
title = {Direct Manipulation through Surrogate Objects},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979033},
doi = {10.1145/1978942.1979033},
abstract = {Direct manipulation has had major influence on interface design since it was proposed
by Shneiderman in 1982. Although directness generally benefits users, direct manipulation
also has weaknesses. In some cases, such as when a user needs to manipulate small,
attribute-rich objects or multiple objects simultaneously, indirect manipulation may
be more efficient at the cost of directness or intuitiveness of the interaction. Several
techniques have been developed over the years to address these issues, but these are
all isolated and limited efforts with no coherent underlying principle. We propose
the notion of Surrogate Interaction that ties together a large subset of these techniques
through the use of a surrogate object that allow users to interact with the surrogate
instead of the domain object. We believe that formalizing this family of interaction
techniques will provide an additional and powerful interface design alternative for
interaction designers, as well as uncover opportunities for future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {627–636},
numpages = {10},
keywords = {design, direct manipulation, instrumental interaction},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979034,
author = {Yoshizaki, Wataru and Sugiura, Yuta and Chiou, Albert C. and Hashimoto, Sunao and Inami, Masahiko and Igarashi, Takeo and Akazawa, Yoshiaki and Kawachi, Katsuaki and Kagami, Satoshi and Mochimaru, Masaaki},
title = {An Actuated Physical Puppet as an Input Device for Controlling a Digital Manikin},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979034},
doi = {10.1145/1978942.1979034},
abstract = {We present an actuated handheld puppet system for controlling the posture of a virtual
character. Physical puppet devices have been used in the past to intuitively control
character posture. In our research, an actuator is added to each joint of such an
input device to provide physical feedback to the user. This enhancement offers many
benefits. First, the user can upload pre-defined postures to the device to save time.
Second, the system is capable of dynamically adjusting joint stiffness to counteract
gravity, while allowing control to be maintained with relatively little force. Third,
the system supports natural human body behaviors, such as whole-body reaching and
joint coupling. This paper describes the user interface and implementation of the
proposed technique and reports the results of expert evaluation. We also conducted
two user studies to evaluate the effectiveness of our method.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {637–646},
numpages = {10},
keywords = {force feedback, robot, posture, input device},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979035,
author = {Liu, Kexi and Sakamoto, Daisuke and Inami, Masahiko and Igarashi, Takeo},
title = {Roboshop: Multi-Layered Sketching Interface for Robot Housework Assignment and Management},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979035},
doi = {10.1145/1978942.1979035},
abstract = {As various home robots come into homes, the need for efficient robot task management
tools is arising. Current tools are designed for controlling individual robots independently,
so they are not ideally suitable for assigning coordinated action among multiple robots.
To address this problem, we developed a management tool for home robots with a graphical
editing interface. The user assigns instructions by selecting a tool from a toolbox
and sketching on a bird's-eye view of the environment. Layering supports the management
of multiple tasks in the same room. Layered graphical representation gives a quick
overview of and access to rich information tied to the physical environment. This
paper describes the prototype system and reports on our evaluation of the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {647–656},
numpages = {10},
keywords = {graphical user interface, home robots, housework management, human-robot interaction, sketching interface},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3248989,
author = {Thom-Santelli, Jennifer},
title = {Session Details: Tagging},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3248989},
doi = {10.1145/3248989},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979037,
author = {Mamykina, Lena and Miller, Andrew D. and Grevet, Catherine and Medynskiy, Yevgeniy and Terry, Michael A. and Mynatt, Elizabeth D. and Davidson, Patricia R.},
title = {Examining the Impact of Collaborative Tagging on Sensemaking in Nutrition Management},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979037},
doi = {10.1145/1978942.1979037},
abstract = {Collaborative tagging mechanisms are integral to social computing applications in
a variety of domains. Their expected benefits include simplified retrieval of digital
content, as well as enhanced ability of a community to makes sense of the shared content.
We examine the impact of collaborative tagging in context of nutrition management.
In a controlled experiment we asked individuals to assess the nutritional value of
meals based on photographic images and observed the impact of different types of tags
and tagging mechanisms on individuals nutritional sensemaking. The results of the
study show that tags enhance individuals' ability to remember the viewed meals. However,
we found that some types of tags can be detrimental to sensemaking, rather than supporting
it. These findings stress the importance of tagging vocabularies and suggest a need
for expert moderation of community sensemaking.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {657–666},
numpages = {10},
keywords = {nutrition, collaborative tagging, collective sensemaking, wellness},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979038,
author = {Kuhn, Alex and Cahill, Clara and Quintana, Chris and Schmoll, Shannon},
title = {Using Tags to Encourage Reflection and Annotation on Data during Nomadic Inquiry},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979038},
doi = {10.1145/1978942.1979038},
abstract = {Nomadic inquiry may benefit from tagging when used for educational purposes to support
reflection and annotation during data collection. To that end we created Zydeco, a
mobile system to scaffold learners through the science inquiry process in and out
of the classroom, and tested it in a museum with 42 middle school students. Students
report that tags encouraged reflection and annotation during data collection, suggesting
that tagging can be used to support nomadic inquiry. From this work we present some
emerging design recommendations for constructing similar systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {667–670},
numpages = {4},
keywords = {nomadic inquiry, learner-centered design, mobile computing, scaffolding, tagging, mobile learning},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979039,
author = {Kim, Yong-Mi and Rieh, Soo Young},
title = {User Perceptions of the Role and Value of Tags},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979039},
doi = {10.1145/1978942.1979039},
abstract = {This study investigates user ideas about the role and value of tags in social media.
An analysis of 45 interviews with heavy Web users reveals that user perceptions of
tags differ from common assumptions held by researchers and designers of social tagging
systems. Among beliefs held by participants were that tags were query suggestions
or links to other pages, sites, or advertisements - although most identified tags
as categories or keywords - and that tags were generated automatically by the computer
system. Several participants believed that tags were intended for not only other users
but also systems such as search engines. Our findings indicate that Web users, including
those who are taggers themselves, experience a high level of uncertainty and confusion
about the nature, purpose and value of tags.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {671–674},
numpages = {4},
keywords = {user perceptions, tags, value of tags, social tagging},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}


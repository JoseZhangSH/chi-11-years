@inbook{10.1145/3411764.3445235,
author = {Murali, Prasanth and Hernandez, Javier and McDuff, Daniel and Rowan, Kael and Suh, Jina and Czerwinski, Mary},
title = {AffectiveSpotlight: Facilitating the Communication of Affective Responses from Audience Members during Online Presentations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445235},
abstract = { The ability to monitor audience reactions is critical when delivering presentations.
However, current videoconferencing platforms offer limited solutions to support this.
This work leverages recent advances in affect sensing to capture and facilitate communication
of relevant audience signals. Using an exploratory survey&nbsp;(N=175), we assessed the
most relevant audience responses such as confusion, engagement, and head-nods. We
then implemented AffectiveSpotlight, a Microsoft Teams bot that analyzes facial responses
and head gestures of audience members and dynamically spotlights the most expressive
ones. In a within-subjects study with 14&nbsp;groups&nbsp;(N=117), we observed that the system
made presenters significantly more aware of their audience, speak for a longer period
of time, and self-assess the quality of their talk more similarly to the audience
members, compared to two control conditions&nbsp;(randomly-selected spotlight and default
platform UI). We provide design recommendations for future affective interfaces for
online presentations based on feedback from the study.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {247},
numpages = {13}
}

@inbook{10.1145/3411764.3445504,
author = {M\"{a}kel\"{a}, Ville and Kleine, Johannes and Hood, Maxine and Alt, Florian and Schmidt, Albrecht},
title = {Hidden Interaction Techniques: Concealed Information Acquisition and Texting on Smartphones and Wearables},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445504},
abstract = { There are many situations where using personal devices is not socially acceptable,
or where nearby people present a privacy risk. For these situations, we explore the
concept of hidden interaction techniques through two prototype applications. HiddenHaptics
allows users to receive information through vibrotactile cues on a smartphone, and
HideWrite allows users to write text messages by drawing on a dimmed smartwatch screen.
We conducted three user studies to investigate whether, and how, these techniques
can be used without being exposed. Our primary findings are (1) users can effectively
hide their interactions while attending to a social situation, (2) users seek to interact
when another person is speaking, and they also tend to hide the interaction using
their body or furniture, and (3) users can sufficiently focus on the social situation
despite their interaction, whereas non-users feel that observing the user hinders
their ability to focus on the social activity.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {248},
numpages = {14}
}

@inbook{10.1145/3411764.3445640,
author = {Axtell, Benett and Munteanu, Cosmin},
title = {Tea, Earl Grey, Hot: Designing Speech Interactions from the Imagined Ideal of Star Trek},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445640},
abstract = {Speech is now common in daily interactions with our devices, thanks to voice user
interfaces (VUIs) like Alexa. Despite their seeming ubiquity, designs often do not
match users’ expectations. Science fiction, which is known to influence design of
new technologies, has included VUIs for decades. Star Trek: The Next Generation is
a prime example of how people envisioned ideal VUIs. Understanding how current VUIs
live up to Star Trek’s utopian technologies reveals mismatches between current designs
and user expectations, as informed by popular fiction. Combining conversational analysis
and VUI user analysis, we study voice interactions with the Enterprise’s computer
and compare them to current interactions. Independent of futuristic computing power,
we find key design-based differences: Star Trek interactions are brief and functional,
not conversational, they are highly multimodal and context-driven, and there is often
no spoken computer response. From this, we suggest paths to better align VUIs with
user expectations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {249},
numpages = {14}
}

@inbook{10.1145/3411764.3445409,
author = {Cambre, Julia and Williams, Alex C and Razi, Afsaneh and Bicking, Ian and Wallin, Abraham and Tsai, Janice and Kulkarni, Chinmay and Kaye, Jofish},
title = {Firefox Voice: An Open and Extensible Voice Assistant Built Upon the Web},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445409},
abstract = { Voice assistants are fundamentally changing the way we access information. However,
voice assistants still leverage little about the web beyond simple search results.
We introduce Firefox Voice, a novel voice assistant built on the open web ecosystem
with an aim to expand access to information available via voice. Firefox Voice is
a browser extension that enables users to use their voice to perform actions such
as setting timers, navigating the web, and reading a webpage’s content aloud. Through
an iterative development process and use by over 12,000 active users, we find that
users see voice as a way to accomplish certain browsing tasks efficiently, but struggle
with discovering functionality and frequently discontinue use. We conclude by describing
how Firefox Voice enables the development of novel, open web-powered voice-driven
experiences.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {250},
numpages = {18}
}

@inbook{10.1145/3411764.3445430,
author = {Pandey, Laxmi and Hasan, Khalad and Arif, Ahmed Sabbir},
title = {Acceptability of Speech and Silent Speech Input Methods in Private and Public},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445430},
abstract = {Silent speech input converts non-acoustic features like tongue and lip movements into
text. It has been demonstrated as a promising input method on mobile devices and has
been explored for a variety of audiences and contexts where the acoustic signal is
unavailable (e.g., people with speech disorders) or unreliable (e.g., noisy environment).
Though the method shows promise, very little is known about peoples’ perceptions regarding
using it. In this work, first, we conduct two user studies to explore users’ attitudes
towards the method with a particular focus on social acceptance and error tolerance.
Results show that people perceive silent speech as more socially acceptable than speech
input and are willing to tolerate more errors with it to uphold privacy and security.
We then conduct a third study to identify a suitable method for providing real-time
feedback on silent speech input. Results show users find an abstract feedback method
effective and significantly more private and secure than a commonly used video feedback
method. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {251},
numpages = {13}
}

@inbook{10.1145/3411764.3445615,
author = {Samrose, Samiha and McDuff, Daniel and Sim, Robert and Suh, Jina and Rowan, Kael and Hernandez, Javier and Rintel, Sean and Moynihan, Kevin and Czerwinski, Mary},
title = {MeetingCoach: An Intelligent Dashboard for Supporting Effective &amp; Inclusive Meetings},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445615},
abstract = {Video-conferencing is essential for many companies, but its limitations in conveying
social cues can lead to ineffective meetings. We present MeetingCoach, an intelligent
post-meeting feedback dashboard that summarizes contextual and behavioral meeting
information. Through an exploratory survey&nbsp;(N=120), we identified important signals&nbsp;(e.g.,
turn taking, sentiment) and used these insights to create a wireframe dashboard. The
design was evaluated with in situ participants&nbsp;(N=16) who helped identify the components
they would prefer in a post-meeting dashboard. After recording video-conferencing
meetings of eight teams over four weeks, we developed an AI system to quantify the
meeting features and created personalized dashboards for each participant. Through
interviews and surveys&nbsp;(N=23), we found that reviewing the dashboard helped improve
attendees’ awareness of meeting dynamics, with implications for improved effectiveness
and inclusivity. Based on our findings, we provide suggestions for future feedback
system designs of video-conferencing meetings.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {252},
numpages = {13}
}

@inbook{10.1145/3411764.3445729,
author = {Williamson, Julie and Li, Jie and Vinayagamoorthy, Vinoba and Shamma, David A. and Cesar, Pablo},
title = {Proxemics and Social Interactions in an Instrumented Virtual Reality Workshop},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445729},
abstract = { Virtual environments (VEs) can create collaborative and social spaces, which are
increasingly important in the face of remote work and travel reduction. Recent advances,
such as more open and widely available platforms, create new possibilities to observe
and analyse interaction in VEs. Using a custom instrumented build of Mozilla Hubs
to measure position and orientation, we conducted an academic workshop to facilitate
a range of typical workshop activities. We analysed social interactions during a keynote,
small group breakouts, and informal networking/hallway conversations. Our mixed-methods
approach combined environment logging, observations, and semi-structured interviews.
The results demonstrate how small and large spaces influenced group formation, shared
attention, and personal space, where smaller rooms facilitated more cohesive groups
while larger rooms made small group formation challenging but personal space more
flexible. Beyond our findings, we show how the combination of data and insights can
fuel collaborative spaces’ design and deliver more effective virtual workshops.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {253},
numpages = {13}
}

@inbook{10.1145/3411764.3445536,
author = {V\"{o}lkel, Sarah Theres and Buschek, Daniel and Eiband, Malin and Cowan, Benjamin R. and Hussmann, Heinrich},
title = {Eliciting and Analysing Users’ Envisioned Dialogues with Perfect Voice Assistants},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445536},
abstract = {We present a dialogue elicitation study to assess how users envision conversations
with a perfect voice assistant (VA). In an online survey, N=205 participants were
prompted with everyday scenarios, and wrote the lines of both user and VA in dialogues
that they imagined as perfect. We analysed the dialogues with text analytics and qualitative
analysis, including number of words and turns, social aspects of conversation, implied
VA capabilities, and the influence of user personality. The majority envisioned dialogues
with a VA that is interactive and not purely functional; it is smart, proactive, and
has knowledge about the user. Attitudes diverged regarding the assistant’s role as
well as it expressing humour and opinions. An exploratory analysis suggested a relationship
with personality for these aspects, but correlations were low overall. We discuss
implications for research and design of future VAs, underlining the vision of enabling
conversational UIs, rather than single command “Q&amp;As”. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {254},
numpages = {15}
}

@inbook{10.1145/3411764.3445401,
author = {Dickinson, Patrick and Jones, Arthur and Christian, Wayne and Westerside, Andrew and Mulloy, Francis and Gerling, Kathrin and Hicks, Kieran and Wilson, Liam and Parke, Adrian},
title = {Experiencing Simulated Confrontations in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445401},
abstract = { The use of virtual reality (VR) to simulate confrontational human behaviour has significant
potential for use in training, where the recreation of uncomfortable feelings may
help users to prepare for challenging real-life situations. In this paper we present
a user study (n=68) in which participants experienced simulated confrontational behaviour
performed by a virtual character either in immersive VR, or on a 2D display. Participants
reported a higher elevation in anxiety in VR, which correlated positively with a perceived
sense of physical space. Character believability was influenced negatively by visual
elements of the simulation, and positively by behavioural elements, which complements
findings from previous work. We recommend the use of VR for simulations of confrontational
behaviour, where a realistic emotional response is part of the intended experience.
We also discuss incorporation of domain knowledge of human behaviours, and carefully
crafted motion-captured sequences, to increase users’ sense of believability. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {255},
numpages = {10}
}

@inbook{10.1145/3411764.3445445,
author = {Yang, Xi and Aurisicchio, Marco},
title = {Designing Conversational Agents: A Self-Determination Theory Approach},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445445},
abstract = {Bringing positive experiences to users is one of the key goals when designing conversational
agents (CAs). Yet we still lack an understanding of users’ underlying needs to achieve
positive experiences and how to support them in design. This research first applies
Self-Determination Theory in an interview study to explore how users’ needs of competence,
autonomy and relatedness could be supported or undermined in CA experiences. Ten guidelines
are then derived from the interview findings. The key findings demonstrate that: competence
is affected by users’ knowledge of the CA capabilities and effectiveness of the conversation;
autonomy is influenced by flexibility of the conversation, personalisation of the
experiences, and control over user data; regarding relatedness, users still have concerns
over integrating social features into CAs. The guidelines recommend how to inform
users about the system capabilities, design effective and socially appropriate conversations,
and support increased system intelligence, customisation, and data transparency.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {16}
}

@inbook{10.1145/3411764.3445318,
author = {Bae Brandtz\ae{}g, Petter Bae and Skjuve, Marita and Kristoffer Dysthe, Kim Kristoffer and F\o{}lstad, Asbj\o{}rn},
title = {When the Social Becomes Non-Human: Young People's Perception of Social Support in Chatbots},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445318},
abstract = {Although social support is important for health and well-being, many young people
are hesitant to reach out for support. The emerging uptake of chatbots for social
and emotional purposes entails opportunities and concerns regarding non-human agents
as sources of social support. To explore this, we invited 16 participants (16–21 years)
to use and reflect on chatbots as sources of social support. Our participants first
interacted with a chatbot for mental health (Woebot) for two weeks. Next, they participated
in individual in-depth interviews. As part of the interview session, they were presented
with a chatbot prototype providing information to young people. Two months later,
the participants reported on their continued use of Woebot. Our findings provide in-depth
knowledge about how young people may experience various types of social support—appraisal,
informational, emotional, and instrumental support—from chatbots. We summarize implications
for theory, practice, and future research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {257},
numpages = {13}
}

@inbook{10.1145/3411764.3445656,
author = {Homewood, Sarah and Hedemyr, Marika and Fagerberg Ranten, Maja and Kozel, Susan},
title = {Tracing Conceptions of the Body in HCI: From User to More-Than-Human},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445656},
abstract = {This paper traces different conceptions of the body in HCI and identifies a narrative
from user to body, body to bodies, and bodies to more-than-human bodies. Firstly,
this paper aims to present a broader, updated, survey of work around the body in HCI.
The overview shows how bodies are conceptualized as performative, sensing, datafied,
intersectional and more-than-human. This paper then diverges from similar surveys
of research addressing the body in HCI in that it is more disruptive and offers a
critique of these approaches and pointers for where HCI might go next. We end our
paper with recommendations drawn from across the different approaches to the body
in HCI. In particular, that researchers working with the body have much to gain from
the 4th wave HCI approach when designing with and for the body, where our relationships
with technologies are understood as entangled and the body is always more-than-human.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {258},
numpages = {12}
}

@inbook{10.1145/3411764.3445773,
author = {van Koningsbruggen, Rosa and Hengeveld, Bart and Alexander, Jason},
title = {Understanding the Design Space of Embodied Passwords Based on Muscle Memory},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445773},
abstract = { Passwords have become a ubiquitous part of our everyday lives, needed for every web-service
and system. However, it is challenging to create safe and diverse alphanumeric passwords,
and to recall them, imposing a cognitive burden on the user. Through consecutive experiments,
we explored the movement space, affordances and interaction, and memorability of a
tangible, handheld, embodied password. In this context, we found that: (1) a movement
space of 200 mm \texttimes{} 200 mm is preferred; (2) each context has a perceived level of safety,
which—together with the affordances and link to familiarity—influences how the password
is performed. Furthermore, the artefact’s dimensions should be balanced within the
design itself, with the user, and the context, but there is a trade-off between the
perceived safety and ergonomics; and (3) the designed embodied passwords can be recalled
for at least a week, with participants creating unique passwords which were reproduced
consistently.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {259},
numpages = {13}
}

@inbook{10.1145/3411764.3445471,
author = {S\o{}ndergaard, Marie Louise Juul and Ciolfi Felice, Marianela and Balaam, Madeline},
title = {Designing Menstrual Technologies with Adolescents},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445471},
abstract = { Starting to menstruate can restrict adolescents’ movements due to physiological changes
and societal stigma. We present a participatory soma design project advocating for
young adolescents to listen to and care for their newly-menstruating bodies, specifically
focusing on participation in sport. We designed Menarche Bits, an open-ended prototyping
toolkit consisting of shape-changing actuators and heat pads, and used it in two design
workshops with seven participants aged 16-18, as part of collaboration and menstrual
advocacy in their sports clubs and high school. The participants designed menstrual
technologies that respond to menstrual cramps and depressive, anxious feelings before
menstruating. We contribute findings on designing menstrual technologies with adolescents
using participatory soma design. We found that a toolkit approach to the design of
menstrual technologies can allow for pluralist experiences of menstrual cycles. In
addition, we found that participatory design with adolescents benefits from drawing
on qualities of embodiment and participants’ own body literacy. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {260},
numpages = {14}
}

@inbook{10.1145/3411764.3445052,
author = {Hendriks, Sjoerd and Mare, Simon and Gamboa, Mafalda and Bayta\th{}, Mehmet Ayd\'{y}n},
title = {Azalea: Co-Experience in Remote Dialog through Diminished Reality and Somaesthetic Interaction Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445052},
abstract = {We introduce Azalea: a design to enrich remote dialog by diminishing externalities,
created through a process informed by somaesthetics. Azalea is a tactile cushion that
envelops a smartphone running a bespoke app. A pair of Azaleas mediate an embodied
co-experience between remote interlocutors via a motion-driven soundscape and audio-driven
visuals. While most designs for enriching remote communication increase dimensionality
and fidelity of modalities, Azalea diminishes distractions and serves an abstract
medium for co-experiencing embodied information. We present the theoretical foundations
and design tactics of Azalea, and characterize the experience through a qualitative
empirical study. Our findings culminated in 12 qualities, supporting 5 themes with
design implications that contribute to (1) a design ethos of diminished reality and
(2) an expansion of somaesthetic HCI towards expression and communication. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {261},
numpages = {11}
}

@inbook{10.1145/3411764.3445804,
author = {Zhou, Qiushi and Chua, Cheng Cheng and Knibbe, Jarrod and Goncalves, Jorge and Velloso, Eduardo},
title = {Dance and Choreography in HCI: A Two-Decade Retrospective},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445804},
abstract = { Designing computational support for dance is an emerging area of HCI research, incorporating
the cultural, experiential, and embodied characteristics of the third-wave shift.
The challenges of recognising the abstract qualities of body movement, and of mediating
between the diverse parties involved in the idiosyncratic creative process, present
important questions to HCI researchers: how can we effectively integrate computing
with dance, to understand and cultivate the felt dimension of creativity, and to aid
the dance-making process? In this work, we systematically review the past twenty years
of dance literature in HCI. We discuss our findings, propose directions for future
HCI works in dance, and distil lessons for related disciplines.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {262},
numpages = {14}
}

@inbook{10.1145/3411764.3445533,
author = {Jung, Annkatrin and Alfaras, Miquel and Karpashevich, Pavel and Primett, William and H\"{o}\"{o}k, Kristina},
title = {Exploring Awareness of Breathing through Deep Touch Pressure},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445533},
abstract = { Deep Pressure Therapy relies on exerting firm touch to help individuals with sensory
sensitivity. We performed first-person explorations of deep pressure enabled by shape-changing
actuation driven by breathing sensing. This revealed a novel design space with rich,
evocative, aesthetically interesting interactions that can help increase breathing
awareness and appreciation through: (1) applying symmetrical as well as asymmetrical
pressure on the torso; (2) using pressure to direct attention to muscles or bone structure
involved in different breathing patterns; (3) apply synchronous as well as asynchronous
feedback following or opposing the user’s breathing rhythm through applying rhythmic
pressure. Taken together these explorations led us to design (4) breathing correspondence
interactions – a balance point right between leading and following users’ breathing
patterns by first applying deep pressure – almost to the point of being unpleasant
– and then releasing in rhythmic flow.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {263},
numpages = {15}
}

@inbook{10.1145/3411764.3445379,
author = {Dewez, Diane and Hoyet, Ludovic and L\'{e}cuyer, Anatole and Argelaguet Sanz, Ferran},
title = {Towards “Avatar-Friendly” 3D Manipulation Techniques: Bridging the Gap Between Sense of Embodiment and Interaction in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445379},
abstract = { Avatars, the users’ virtual representations, are becoming ubiquitous in virtual reality
applications. In this context, the avatar becomes the medium which enables users to
manipulate objects in the virtual environment. It also becomes the users’ main spatial
reference, which can not only alter their interaction with the virtual environment,
but also the perception of themselves. In this paper, we review and analyse the current
state-of-the-art for 3D object manipulation and the sense of embodiment. Our analysis
is twofold. First, we discuss the impact that the avatar can have on object manipulation.
Second, we discuss how the different components of a manipulation technique (i.e.
input, control and feedback) can influence the user’s sense of embodiment. Throughout
the analysis, we crystallise our discussion with practical guidelines for VR application
designers and we propose several research topics towards “avatar-friendly’’ manipulation
techniques. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {264},
numpages = {14}
}

@inbook{10.1145/3411764.3445137,
author = {Daud\'{e}n Roquet, Claudia and Sas, Corina},
title = {Interoceptive Interaction: An Embodied Metaphor Inspired Approach to Designing for Meditation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445137},
abstract = {Meditation is a mind-body practice with considerable wellbeing benefits that can take
different forms. Novices usually start with focused attention meditation that supports
regulation of attention towards an inward focus or internal bodily sensations and
away from external stimuli or distractors. Most meditation technologies employ metaphorical
mappings of meditative states to visual or soundscape representations to support awareness
of mind wandering and attention regulation, although the rationale for such mappings
is seldom articulated. Moreover, such external modalities also take the focus attention
away from the body. We advance the concept of interoceptive interaction and employed
the embodied metaphor theory to explore the design of mappings to the interoceptive
sense of thermoception. We illustrate this concept with WarmMind, an on-body interface
integrating heat actuators for mapping meditation states. We report on an exploratory
study with 10 participants comparing our novel thermal metaphors for mapping meditation
states with comparable ones, albeit in aural modality, as provided by Muse meditation
app. Findings indicate a tension between the highly discoverable soundscape's metaphors
which however hinder attention regulation, and the ambiguous thermal metaphors experienced
as coming from the body and supported attention regulation. We discuss the qualities
of embodied metaphors underpinning this tension and propose an initial framework to
inform the design of metaphorical mappings for meditation technologies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {265},
numpages = {17}
}

@inbook{10.1145/3411764.3445628,
author = {Tsaknaki, Vasiliki and Cotton, Kelsey and Karpashevich, Pavel and Sanches, Pedro},
title = {“Feeling the Sensor Feeling You”: A Soma Design Exploration on Sensing Non-Habitual Breathing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445628},
abstract = { Though seemingly straightforward and habitual, breathing is a complex bodily function.
Problematising the space of designing for breathing as a non-habitual act pertaining
to different bodies or situations, we conducted a soma design exploration together
with a classical singer. Reflecting on how sensors could capture the impact and somatic
experience of being sensed led us to develop a new sensing mechanism using shape-change
technologies integrated in the Breathing Shell: a wearable that evokes a reciprocal
experience of “feeling the sensor feeling you” when breathing. We contribute with
two design implications: 1) Enabling reflections of the somatic impact of being sensed
in tandem with the type of data captured, 2) creating a tactile impact of the sensor
data on the body. Both implications aim to deepen one’s understanding of how the whole
soma relates to or with biosensors and ultimately leading to designing for symbiotic
experiences between biosensors and bodies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {266},
numpages = {16}
}

@inbook{10.1145/3411764.3445700,
author = {Turmo Vidal, Laia and Zhu, Hui and Waern, Annika and M\'{a}rquez Segura, Elena},
title = {The Design Space of Wearables for Sports and Fitness Practices},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445700},
abstract = {The growing interest in wearables for sports and fitness calls for design knowledge
and conceptualizations that can help shape future designs. Towards that end, we present
and discuss a design space of wearables for these practices, based on a survey of
previous work. Through a thematic analysis of 47 research publications in the domain,
we surface core design decisions concerning wearability, technology design, and wearable
use in practice. Building on these, we show how the design space takes into account
the goals of introducing technology, that design decisions can be either directly
designed, or left open for appropriation by end-users; and the social organization
of the practice. We characterize prior work based on the design space elements, which
yields trends and opportunities for design. Our contributions can help designers think
about key design decisions, exploit trends and explore new areas in the domain of
wearables for sports and fitness practices.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {267},
numpages = {14}
}

@inbook{10.1145/3411764.3445482,
author = {Tennent, Paul and H\"{o}\"{o}k, Kristina and Benford, Steve and Tsaknaki, Vasiliki and St\r{a}hl, Anna and Dauden Roquet, Claudia and Windlin, Charles and Sanches, Pedro and Marshall, Joe and Li, Christine and Martinez Avila, Juan Pablo and Alfaras, Miquel and Umair, Muhammad and Zhou, Feng},
title = {Articulating Soma Experiences Using Trajectories},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445482},
abstract = {In this paper, we reflect on the applicability of the concept of trajectories to soma
design. Soma design is a first-person design method which considers users’ subjective
somatic or bodily experiences of a design. Due to bodily changes over time, soma experiences
are inherently temporal. Current instruments for articulating soma experiences lack
the power to express the effects of experiences on the body over time. To address
this, we turn to trajectories, a well-known concept in the HCI community, as a way
of mapping this aspect of soma experience. By showing trajectories through a range
of dimensions, we can articulate individual experiences and differences in those experiences.
Through analysis of a set of soma experience designs and a set of temporal dimensions
within the experiences, this paper demonstrates how trajectories can provide a practical
conceptual framing for articulating the temporal complexity of soma designs. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {268},
numpages = {16}
}

@inbook{10.1145/3411764.3445548,
author = {Funk, Julie M. and Lakier, Matthew and O'Gorman, Marcel and Vogel, Daniel},
title = {Exploring Smartphone Relationships through Roland Barthes Using an Instrumented Pillow Technology Probe},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445548},
abstract = {We examine a vocabulary of affective language, borrowed from Roland Barthes’ “A Lover’s
Discourse: Fragments,” and its applicability to discourse describing smartphone attachment.
This vocabulary, adopted from four of Barthes’ terms, waiting, dependency, anxiety,
and absence, is used as a discursive lens to illustrate some of the many ways people
understand and engage with their relationships to their smartphones. Based on this,
a survey is conducted, and a speculative technology probe is created in the form of
an instrumented pillow for people to lock away their smartphones during the night.
The pillow is deployed in a diary study in which five people sleep with their phone
locked away for multiple nights. The self-reported and observed behaviours are presented
in a selection of vignettes. The results support the proposed discursive lens and
suggest future interdisciplinary strategies to investigate how people relate to interactive
technology, using a combined approach of literary theory and a technology probe supported
by survey and study data. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {269},
numpages = {13}
}

@inbook{10.1145/3411764.3445242,
author = {Schaadhardt, Anastasia and Hiniker, Alexis and Wobbrock, Jacob O.},
title = {Understanding Blind Screen-Reader Users’ Experiences of Digital Artboards},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445242},
abstract = { Two-dimensional canvases are the core components of many digital productivity and
creativity tools, with “artboards” containing objects rather than pixels. Unfortunately,
the contents of artboards remain largely inaccessible to blind users relying on screen-readers,
but the precise problems are not well understood. This study sought to understand
how blind screen-reader users interact with artboards. Specifically, we conducted
contextual interviews, observations, and task-based usability studies with 15 blind
participants to understand their experiences of artboards found in Microsoft PowerPoint,
Apple Keynote, and Google Slides. Participants expressed that the inaccessibility
of these artboards contributes to significant educational and professional barriers.
We found that the key problems faced were: (1) high cognitive loads from a lack of
feedback about artboard contents and object state; (2) difficulty determining relationships
among artboard objects; and (3) constant uncertainty about whether object manipulations
were successful. We offer design remedies that improve feedback for object state,
relationships, and manipulations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {19}
}

@inbook{10.1145/3411764.3445416,
author = {Bragg, Danielle and Caselli, Naomi and Gallagher, John W. and Goldberg, Miriam and Oka, Courtney J. and Thies, William},
title = {ASL Sea Battle: Gamifying Sign Language Data Collection},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445416},
abstract = {The development of accurate machine learning models for sign languages like American
Sign Language (ASL) has the potential to break down communication barriers for deaf
signers. However, to date, no such models have been robust enough for real-world use.
The primary barrier to enabling real-world applications is the lack of appropriate
training data. Existing training sets suffer from several shortcomings: small size,
limited signer diversity, lack of real-world settings, and missing or inaccurate labels.
In this work, we present ASL Sea Battle, a sign language game designed to collect
datasets that overcome these barriers, while also providing fun and education to users.
We conduct a user study to explore the data quality that the game collects, and the
user experience of playing the game. Our results suggest that ASL Sea Battle can reliably
collect and label real-world sign language videos, and provides fun and education
at the expense of data throughput.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {13}
}

@inbook{10.1145/3411764.3445233,
author = {Liu, Xingyu and Carrington, Patrick and Chen, Xiang 'Anthony' and Pavel, Amy},
title = {What Makes Videos Accessible to Blind and Visually Impaired People?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445233},
abstract = { User-generated videos are an increasingly important source of information online,
yet most online videos are inaccessible to blind and visually impaired (BVI) people.
To find videos that are accessible, or understandable without additional description
of the visual content, BVI people in our formative studies reported that they used
a time-consuming trial-and-error approach: clicking on a video, watching a portion,
leaving the video, and repeating the process. BVI people also reported video accessibility
heuristics that characterize accessible and inaccessible videos. We instantiate 7
of the identified heuristics (2 audio-related, 2 video-related, and 3 audio-visual)
as automated metrics to assess video accessibility. We collected a dataset of accessibility
ratings of videos by BVI people and found that our automatic video accessibility metrics
correlated with the accessibility ratings (Adjusted R2 = 0.642). We augmented a video
search interface with our video accessibility metrics and predictions. BVI people
using our augmented video search interface selected an accessible video more efficiently
than when using the original search interface. By integrating video accessibility
metrics, video hosting platforms could help people surface accessible videos and encourage
content creators to author more accessible products, improving video accessibility
for all.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {272},
numpages = {14}
}

@inbook{10.1145/3411764.3445510,
author = {South, Laura and Saffo, David and Borkin, Michelle A.},
title = {Detecting and Defending Against Seizure-Inducing GIFs in Social Media},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445510},
abstract = {Despite recent improvements in online accessibility, the Internet remains an inhospitable
place for users with photosensitive epilepsy, a chronic condition in which certain
light stimuli can trigger seizures and even lead to death in extreme cases. In this
paper, we explore how current risk detection systems have allowed attackers to take
advantage of design oversights and target vulnerable users with photosensitivity on
popular social media platforms. Through interviews with photosensitive individuals
and a critical review of existing systems, we constructed design requirements for
consumer-driven protective systems and developed a prototype browser extension for
actively detecting and disarming potentially seizure-inducing GIFs and videos. We
validate our system with a comprehensive dataset of simulated GIFs and GIFs collected
from social media. Finally, we conduct a novel quantitative analysis of the prevalence
of seizure-inducing GIFs across popular social media platforms and contribute recommendations
for improving online accessibility for individuals with photosensitivity. All study
materials are available at https://osf.io/5a3dy/.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {273},
numpages = {17}
}

@inbook{10.1145/3411764.3445455,
author = {Salehnamadi, Navid and Alshayban, Abdulaziz and Lin, Jun-Wei and Ahmed, Iftekhar and Branham, Stacy and Malek, Sam},
title = {Latte: Use-Case and Assistive-Service Driven Automated Accessibility Testing Framework for Android},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445455},
abstract = { For 15% of the world population with disabilities, accessibility is arguably the
most critical software quality attribute. The ever-growing reliance of users with
disability on mobile apps further underscores the need for accessible software in
this domain. Existing automated accessibility assessment techniques primarily aim
to detect violations of predefined guidelines, thereby produce a massive amount of
accessibility warnings that often overlook the way software is actually used by users
with disability. This paper presents a novel, high-fidelity form of accessibility
testing for Android apps, called Latte, that automatically reuses tests written to
evaluate an app’s functional correctness to assess its accessibility as well. Latte
first extracts the use case corresponding to each test, and then executes each use
case in the way disabled users would, i.e., using assistive services. Our empirical
evaluation on real-world Android apps demonstrates Latte’s effectiveness in detecting
substantially more useful defects than prior techniques.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {274},
numpages = {11}
}

@inbook{10.1145/3411764.3445186,
author = {Zhang, Xiaoyi and de Greef, Lilian and Swearngin, Amanda and White, Samuel and Murray, Kyle and Yu, Lisa and Shan, Qi and Nichols, Jeffrey and Wu, Jason and Fleizach, Chris and Everitt, Aaron and Bigham, Jeffrey P},
title = {Screen Recognition: Creating Accessibility Metadata for Mobile Applications from Pixels},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445186},
abstract = { Many accessibility features available on mobile platforms require applications (apps)
to provide complete and accurate metadata describing user interface (UI) components.
Unfortunately, many apps do not provide sufficient metadata for accessibility features
to work as expected. In this paper, we explore inferring accessibility metadata for
mobile apps from their pixels, as the visual interfaces often best reflect an app’s
full functionality. We trained a robust, fast, memory-efficient, on-device model to
detect UI elements using a dataset of 77,637 screens (from 4,068 iPhone apps) that
we collected and annotated. To further improve UI detections and add semantic information,
we introduced heuristics (e.g., UI grouping and ordering) and additional models (e.g.,
recognize UI content, state, interactivity). We built Screen Recognition to generate
accessibility metadata to augment iOS VoiceOver. In a study with 9 screen reader users,
we validated that our approach improves the accessibility of existing mobile apps,
enabling even previously inaccessible apps to be used. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {15}
}

@inbook{10.1145/3411764.3445572,
author = {Peng, Yi-Hao and Jang, JiWoong and Bigham, Jeffrey P and Pavel, Amy},
title = {Say It All: Feedback for Improving Non-Visual Presentation Accessibility},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445572},
abstract = {Presenters commonly use slides as visual aids for informative talks. When presenters
fail to verbally describe the content on their slides, blind and visually impaired
audience members lose access to necessary content, making the presentation difficult
to follow. Our analysis of 90 presentation videos revealed that 72% of 610 visual
elements (e.g., images, text) were insufficiently described. To help presenters create
accessible presentations, we introduce Presentation A11y, a system that provides real-time
and post-presentation accessibility feedback. Our system analyzes visual elements
on the slide and the transcript of the verbal presentation to provide element-level
feedback on what visual content needs to be further described or even removed. Presenters
using our system with their own slide-based presentations described more of the content
on their slides, and identified &nbsp;3.26 times more accessibility problems to fix after
the talk than when using a traditional slide-based presentation interface. Integrating
accessibility feedback into content creation tools will improve the accessibility
of informational content for all. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {12}
}

@inbook{10.1145/3411764.3445347,
author = {Wang, Yujia and Liang, Wei and Huang, Haikun and Zhang, Yongqi and Li, Dingzeyu and Yu, Lap-Fai},
title = {Toward Automatic Audio Description Generation for Accessible Videos},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445347},
abstract = { Video accessibility is essential for people with visual impairments. Audio descriptions
describe what is happening on-screen, e.g., physical actions, facial expressions,
and scene changes. Generating high-quality audio descriptions requires a lot of manual
description generation&nbsp;[50]. To address this accessibility obstacle, we built a system
that analyzes the audiovisual contents of a video and generates the audio descriptions.
The system consisted of three modules: AD insertion time prediction, AD generation,
and AD optimization. We evaluated the quality of our system on five types of videos
by conducting qualitative studies with 20 sighted users and 12 users who were blind
or visually impaired. Our findings revealed how audio description preferences varied
with user types and video types. Based on our study’s analysis, we provided recommendations
for the development of future audio description generation technologies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {277},
numpages = {12}
}

@inbook{10.1145/3411764.3445207,
author = {Butler, Matthew and Holloway, Leona M and Reinders, Samuel and Goncu, Cagatay and Marriott, Kim},
title = {Technology Developments in Touch-Based Accessible Graphics: A Systematic Review of Research 2010-2020},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445207},
abstract = { This paper presents a systematic literature review of 292 publications from 97 unique
venues on touch-based graphics for people who are blind or have low vision, from 2010
to mid-2020. It is the first review of its kind on touch-based accessible graphics.
It is timely because it allows us to assess the impact of new technologies such as
commodity 3D printing and low-cost electronics on the production and presentation
of accessible graphics. As expected our review shows an increase in publications from
2014 that we can attribute to these developments. It also reveals the need to: broaden
application areas, especially to the workplace; broaden end-user participation throughout
the full design process; and conduct more in situ evaluation. This work is linked
to an online living resource to be shared with the wider community.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {278},
numpages = {15}
}

@inbook{10.1145/3411764.3445038,
author = {Alonzo, Oliver and Trussell, Jessica and Dingman, Becca and Huenerfauth, Matt},
title = {Comparison of Methods for Evaluating Complexity of Simplified Texts among Deaf and Hard-of-Hearing Adults at Different Literacy Levels},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445038},
abstract = { Research has explored using Automatic Text Simplification for reading assistance,
with prior work identifying benefits and interests from Deaf and Hard-of-Hearing (DHH)
adults. While the evaluation of these technologies remains a crucial aspect of research
in the area, researchers lack guidance in terms of how to evaluate text complexity
with DHH readers. Thus, in this work we conduct methodological research to evaluate
metrics identified from prior work (including reading speed, comprehension questions,
and subjective judgements of understandability and readability) in terms of their
effectiveness for evaluating texts modified to be at various complexity levels with
DHH adults at different literacy levels. Subjective metrics and low-linguistic-complexity
comprehension questions distinguished certain text complexity levels with participants
with lower literacy. Among participants with higher literacy, only subjective judgements
of text readability distinguished certain text complexity levels. For all metrics,
participants with higher literacy scored higher or provided more positive subjective
judgements overall.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {279},
numpages = {12}
}

@inbook{10.1145/3411764.3445647,
author = {Ellis, Kirsten and Dao, Emily and Smith, Osian and Lindsay, Stephen and Olivier, Patrick},
title = {TapeBlocks: A Making Toolkit for People Living with Intellectual Disabilities},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445647},
abstract = { The accessibility and affordability of tangible electronic toolkits are significant
barriers to their uptake by people with disabilities. We present the design and evaluation
of TapeBlocks, a low-cost, low-fidelity toolkit intended to be accessible for people
with intellectual disabilities while promoting creativity and engagement. We evaluated
TapeBlocks by interviewing makers, special educational needs teachers and support
coaches. Analysis of these interviews informed the design of a series of maker workshops
using TapeBlocks with young adults living with intellectual disabilities, led by support
coaches with support from the research team. Participants were able to engage with
TapeBlocks and making, eventually building their own TapeBlocks to make personal creations.
Our evaluation reveals how TapeBlocks supports accessible making and playful discovery
of electronics for people living with disabilities, and addresses a gap in existing
toolkits by being tinkerable, affordable and having a low threshold for engagement.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {280},
numpages = {12}
}

@inbook{10.1145/3411764.3445115,
author = {Moon, Hee-Seung and Seo, Jiwon},
title = {Optimal Action-Based or User Prediction-Based Haptic Guidance: Can You Do Even Better?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445115},
abstract = { The recently advanced robotics technology enables robots to assist users in their
daily lives. Haptic guidance (HG) improves users’ task performance through physical
interaction between robots and users. It can be classified into optimal action-based
HG (OAHG), which assists users with an optimal action, and user prediction-based HG
(UPHG), which assists users with their next predicted action. This study aims to understand
the difference between OAHG and UPHG and propose a combined HG (CombHG) that achieves
optimal performance by complementing each HG type, which has important implications
for HG design. We propose implementation methods for each HG type using deep learning-based
approaches. A user study (n=20) in a haptic task environment indicated that UPHG induces
better subjective evaluations, such as naturalness and comfort, than OAHG. In addition,
the CombHG that we proposed further decreases the disagreement between the user intention
and HG, without reducing the objective and subjective scores.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {281},
numpages = {12}
}

@inbook{10.1145/3411764.3445626,
author = {Huang, Michael Xuelin and Li, Yang and Nazneen, Nazneen and Chao, Alexander and Zhai, Shumin},
title = {TapNet: The Design, Training, Implementation, and Applications of a Multi-Task Learning CNN for Off-Screen Mobile Input},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445626},
abstract = {To make off-screen interaction without specialized hardware practical, we investigate
using deep learning methods to process the common built-in IMU sensor (accelerometers
and gyroscopes) on mobile phones into a useful set of one-handed interaction events.
We present the design, training, implementation and applications of TapNet, a multi-task
network that detects tapping on the smartphone. With phone form factor as auxiliary
information, TapNet can jointly learn from data across devices and simultaneously
recognize multiple tap properties, including tap direction and tap location. We developed
two datasets consisting of over 135K training samples, 38K testing samples, and 32
participants in total. Experimental evaluation demonstrated the effectiveness of the
TapNet design and its significant improvement over the state of the art. Along with
the datasets, codebase1, and extensive experiments, TapNet establishes a new technical
foundation for off-screen mobile input. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {282},
numpages = {11}
}

@inbook{10.1145/3411764.3445106,
author = {Lee, DoYoung and Kim, Jiwan and Oakley, Ian},
title = {FingerText: Exploring and Optimizing Performance for Wearable, Mobile and One-Handed Typing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445106},
abstract = {Typing on wearables while situationally impaired, such as while walking, is challenging.
However, while HCI research on wearable typing is diverse, existing work focuses on
stationary scenarios and fine-grained input that will likely perform poorly when users
are on-the-go. To address this issue we explore single-handed wearable typing using
intra-hand touches between the thumb and fingers, a modality we argue will be robust
to the physical disturbances inherent to input while mobile. We first examine the
impact of walking on performance of these touches, noting no significant differences
in accuracy or speed, then feed our study data into a multi-objective optimization
process in order to design keyboard layouts (for both five and ten keys) capable of
supporting rapid, accurate, comfortable, and unambiguous typing. A final study tests
these layouts against QWERTY baselines and reports performance improvements of up
to 10.45% WPM and 39.44% WER when users type while walking. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {283},
numpages = {15}
}

@inbook{10.1145/3411764.3445631,
author = {Ogata, Masa and Koyama, Yuki},
title = {A Computational Approach to Magnetic Force Feedback Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445631},
abstract = { We present a computational approach to haptic design embedded in everyday tangible
interaction with digital fabrication. To generate haptic feedback, the use of permanent
magnets as the mechanism potentially contributes to simpleness and robustness; however,
it is difficult to manually design how magnets should be embedded in the objects.
Our approach enables the inverse design of magnetic force feedback; that is, we computationally
solve an inverse problem to obtain an optimal arrangement of permanent magnets that
renders the user-specified haptic sensation. To solve the inverse problem in a practical
manner, we also present techniques on magnetic simulation and optimization. We demonstrate
applications to explore the design possibility of augmenting digital fabrication for
everyday use.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {284},
numpages = {12}
}

@inbook{10.1145/3411764.3445184,
author = {Velloso, Eduardo and Morimoto, Carlos H},
title = {A Probabilistic Interpretation of Motion Correlation Selection Techniques},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445184},
abstract = { Motion correlation interfaces are those that present targets moving in different
patterns, which the user can select by matching their motion. In this paper, we re-formulate
the task of target selection as a probabilistic inference problem. We demonstrate
that previous interaction techniques can be modelled using a Bayesian approach and
that how modelling the selection task as transmission of information can help us make
explicit the assumptions behind similarity measures. We propose ways of incorporating
uncertainty into the decision-making process and demonstrate how the concept of entropy
can illuminate the measurement of the quality of a design. We apply these techniques
in a case study and suggest guidelines for future work.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {285},
numpages = {13}
}

@inbook{10.1145/3411764.3445514,
author = {Do, Seungwon and Chang, Minsuk and Lee, Byungjoo},
title = {A Simulation Model of Intermittently Controlled Point-and-Click Behaviour},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445514},
abstract = { We present a novel simulation model of point-and-click behaviour that is applicable
both when a target is stationary or moving. To enable more realistic simulation than
existing models, the model proposed in this study takes into account key features
of the user and the external environment, such as intermittent motor control, click
decision-making, visual perception, upper limb kinematics and the effect of input
device. The simulated user’s point-and-click behaviour is formulated as a Markov decision
process (MDP), and the user’s policy of action is optimised through deep reinforcement
learning. As a result, our model successfully and accurately reproduced the trial
completion time, distribution of click endpoints, and cursor trajectories of real
users. Through an ablation study, we showed how the simulation results change when
the model’s sub-modules are individually removed. The implemented model and dataset
are publicly available.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {286},
numpages = {17}
}

@inbook{10.1145/3411764.3445671,
author = {Foy, Conor R. and Dudley, John J. and Gupta, Aakar and Benko, Hrvoje and Kristensson, Per Ola},
title = {Understanding, Detecting and Mitigating the Effects of Coactivations in Ten-Finger Mid-Air Typing in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445671},
abstract = {Typing with ten fingers on a virtual keyboard in virtual or augmented reality exposes
a challenging input interpretation problem. There are many sources of noise in this
interaction context and these exacerbate the challenge of accurately translating human
actions into text. A particularly challenging input noise source arises from the physiology
of the hand. Intentional finger movements can produce unintentional coactivations
in other fingers. On a physical keyboard, the resistance of the keys alleviates this
issue. On a virtual keyboard, coactivations are likely to introduce spurious input
events under a na\"{\i}ve solution to input detection. In this paper we examine the features
that discriminate intentional activations from coactivations. Based on this analysis,
we demonstrate three alternative coactivation detection strategies with high discrimination
power. Finally, we integrate coactivation detection into a probabilistic decoder and
demonstrate its ability to further reduce uncorrected character error rates by approximately
10% relative and 0.9% absolute. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {287},
numpages = {11}
}

@inbook{10.1145/3411764.3445177,
author = {Chen, Xiuli and Acharya, Aditya and Oulasvirta, Antti and Howes, Andrew},
title = {An Adaptive Model of Gaze-Based Selection},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445177},
abstract = { Gaze-based selection has received significant academic attention over a number of
years. While advances have been made, it is possible that further progress could be
made if there were a deeper understanding of the adaptive nature of the mechanisms
that guide eye movement and vision. Control of eye movement typically results in a
sequence of movements (saccades) and fixations followed by a ‘dwell’ at a target and
a selection. To shed light on how these sequences are planned, this paper presents
a computational model of the control of eye movements in gaze-based selection. We
formulate the model as an optimal sequential planning problem bounded by the limits
of the human visual and motor systems and use reinforcement learning to approximate
optimal solutions. The model accurately replicates earlier results on the effects
of target size and distance and captures a number of other aspects of performance.
The model can be used to predict number of fixations and duration required to make
a gaze-based selection. The future development of the model is discussed.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {11}
}

@inbook{10.1145/3411764.3445621,
author = {Streli, Paul and Holz, Christian},
title = {CapContact: Super-Resolution Contact Areas from Capacitive Touchscreens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445621},
abstract = { Touch input is dominantly detected using mutual-capacitance sensing, which measures
the proximity of close-by objects that change the electric field between the sensor
lines. The exponential drop-off in intensities with growing distance enables software
to detect touch events, but does not reveal true contact areas. In this paper, we
introduce CapContact, a novel method to precisely infer the contact area between the
user’s finger and the surface from a single capacitive image. At 8 \texttimes{} super-resolution,
our convolutional neural network generates refined touch masks from 16-bit capacitive
images as input, which can even discriminate adjacent touches that are not distinguishable
with existing methods. We trained and evaluated our method using supervised learning
on data from 10 participants who performed touch gestures. Our capture apparatus integrates
optical touch sensing to obtain ground-truth contact through high-resolution frustrated
total internal reflection. We compare our method with a baseline using bicubic upsampling
as well as the ground truth from FTIR images. We separately evaluate our method’s
performance in discriminating adjacent touches. CapContact successfully separated
closely adjacent touch contacts in 494 of 570 cases (87%) compared to the baseline’s
43 of 570 cases (8%). Importantly, we demonstrate that our method accurately performs
even at half of the sensing resolution at twice the grid-line pitch across the same
surface area, challenging the current industry-wide standard of a ∼ 4&nbsp;mm sensing pitch.
We conclude this paper with implications for capacitive touch sensing in general and
for touch-input accuracy in particular.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {289},
numpages = {14}
}

@inbook{10.1145/3411764.3445349,
author = {Evangelista Belo, Jo\~{a}o Marcelo and Feit, Anna Maria and Feuchtner, Tiare and Gr\o{}nb\ae{}k, Kaj},
title = {XRgonomics: Facilitating the Creation of Ergonomic 3D Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445349},
abstract = {Arm discomfort is a common issue in Cross Reality applications involving prolonged
mid-air interaction. Solving this problem is difficult because of the lack of tools
and guidelines for 3D user interface design. Therefore, we propose a method to make
existing ergonomic metrics available to creators during design by estimating the interaction
cost at each reachable position in the user’s environment. We present XRgonomics,
a toolkit to visualize the interaction cost and make it available at runtime, allowing
creators to identify UI positions that optimize users’ comfort. Two scenarios show
how the toolkit can support 3D UI design and dynamic adaptation of UIs based on spatial
constraints. We present results from a walkthrough demonstration, which highlight
the potential of XRgonomics to make ergonomics metrics accessible during the design
and development of 3D UIs. Finally, we discuss how the toolkit may address design
goals beyond ergonomics.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {290},
numpages = {11}
}

@inbook{10.1145/3411764.3445766,
author = {Mo, George B. and Dudley, John J and Kristensson, Per Ola},
title = {Gesture Knitter: A Hand Gesture Design Tool for Head-Mounted Mixed Reality Applications},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445766},
abstract = { Hand gestures are a natural and expressive input method enabled by modern mixed reality
headsets. However, it remains challenging for developers to create custom gestures
for their applications. Conventional strategies to bespoke gesture recognition involve
either hand-crafting or data-intensive deep-learning. Neither approach is well suited
for rapid prototyping of new interactions. This paper introduces a flexible and efficient
alternative approach for constructing hand gestures. We present Gesture Knitter: a
design tool for creating custom gesture recognizers with minimal training data. Gesture
Knitter allows the specification of gesture primitives that can then be combined to
create more complex gestures using a visual declarative script. Designers can build
custom recognizers by declaring them from scratch or by providing a demonstration
that is automatically decoded into its primitive components. Our developer study shows
that Gesture Knitter achieves high recognition accuracy despite minimal training data
and delivers an expressive and creative design experience.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {291},
numpages = {13}
}

@inbook{10.1145/3411764.3445138,
author = {Ahuja, Karan and Jiang, Yue and Goel, Mayank and Harrison, Chris},
title = {Vid2Doppler: Synthesizing Doppler Radar Data from Videos for Training Privacy-Preserving Activity Recognition},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445138},
abstract = { Millimeter wave (mmWave) Doppler radar is a new and promising sensing approach for
human activity recognition, offering signal richness approaching that of microphones
and cameras, but without many of the privacy-invading downsides. However, unlike audio
and computer vision approaches that can draw from huge libraries of videos for training
deep learning models, Doppler radar has no existing large datasets, holding back this
otherwise promising sensing modality. In response, we set out to create a software
pipeline that converts videos of human activities into realistic, synthetic Doppler
radar data. We show how this cross-domain translation can be successful through a
series of experimental results. Overall, we believe our approach is an important stepping
stone towards significantly reducing the burden of training such as human sensing
systems, and could help bootstrap uses in human-computer interaction.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {292},
numpages = {10}
}

@inbook{10.1145/3411764.3445167,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Light, Ann},
title = {Wanting To Live Here: Design After Anthropocentric Functionalism},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445167},
abstract = {Design research has recently turned to theoretical perspectives, including care ethics
and posthumanism, to counter the industrial processes that have led to climate crisis.
As design theorists and ethnographers of interaction, we researched experimental eco-farming
in a community that shared many of these theoretical and ideological commitments.
Our goal was not to offer an account of use and provide design implications in support
of it. Instead, we chose to identify concrete practices and artifacts that embody
the sorts of industrial transformations that we are seeking—even if they are manifest
in an imperfect or partial form. We encountered practices focused on community building,
local resilience to climate disruptions, experiments in eco-farming, economic survival,
and attracting the next generation. One interlocutor translated these concerns into
a simple binary, asking, “do we want to live here?” This paper contributes to a design
research agenda that might (eventually) provide an affirmative answer.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {293},
numpages = {24}
}

@inbook{10.1145/3411764.3445175,
author = {Yu, Minjing and Zhang, Meng and Yu, Chun and Ma, Xiaoguang and Yang, Xing-Dong and Zhang, Jiawan},
title = {We Can Do More to Save Guqin: Design and Evaluate Interactive Systems to Make Guqin More Accessible to the General Public},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445175},
abstract = { Guqin is a plucked seven-string traditional Chinese musical instrument that exists
for over 3,000 years. However, as an Intangible World Cultural Heritage, the inheritance
of Guqin and its culture in modern society is in deep danger. According to our study
with 1,006 Chinese worldwide, Guqin as an instrument is not well-known and barely
accessible. To better promote Guqin, we developed two interactive systems: VirGuqin
and MRGuqin. VirGuqin was developed using a low-cost motion tracking device and was
tested in a museum. 89% of 308 participants expressed an increase in interest in learning
Guqin after using our system. MRGuqin was developed as a mixed reality learning environment
to reduce the entry barrier to Guqin, and was tested by 16 participants, allowing
them to learn Guqin significantly faster and perform better than the current practice.
Our study demonstrates how technology can be used to help the inheritance of this
dying art.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {294},
numpages = {12}
}

@inbook{10.1145/3411764.3445375,
author = {Chivukula, Shruthi Sai and Hasib, Aiza and Li, Ziqing and Chen, Jingle and Gray, Colin M.},
title = {Identity Claims That Underlie Ethical Awareness and Action},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445375},
abstract = {HCI and STS researchers have previously described the ethical complexity of practice,
drawing together aspects of organizational complexity, design knowledge, and ethical
frameworks. Building on this work, we investigate the identity claims and beliefs
that impact practitioners’ ability to recognize and act upon ethical concerns in a
range of technology-focused disciplines. In this paper, we report results from an
interview study with 12 practitioners, identifying and describing their identity claims
related to ethical awareness and action. We conducted a critically-focused thematic
analysis to identify eight distinct claims representing roles relating to learning,
educating, following policies, feeling a sense of responsibility, being a member of
a profession, a translator, an activist, and deliberative. Based on our findings,
we demonstrate how the claims foreground building competence in relation to ethical
practice. We highlight the dynamic interplay among these claims and point towards
implications for identity work in socio-technical contexts. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {295},
numpages = {13}
}

@inbook{10.1145/3411764.3445253,
author = {Mhaidli, Abraham Hani and Schaub, Florian},
title = {Identifying Manipulative Advertising Techniques in XR Through Scenario Construction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445253},
abstract = {As Extended Reality (XR) devices and applications become more mainstream, so too will
XR advertising&nbsp;—&nbsp;advertising that takes place in XR mediums. Due to the defining features
of XR devices, such as the immersivity of the medium and the ability of XR devices
to simulate reality, there are fears that these features could be exploited to create
manipulative XR ads that trick consumers into buying products they do not need or
might harm them. Using scenario construction, we investigate potential future incarnations
of manipulative XR advertising and their harms. We identify five key mechanisms of
manipulative XR advertising: misleading experience marketing; inducing artificial
emotions in consumers; sensing and targeting people when they are vulnerable; emotional
manipulation through hyperpersonalization; and distortion of reality. We discuss research
challenges and questions in order to address and mitigate manipulative XR advertising
risks. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {18}
}

@inbook{10.1145/3411764.3445314,
author = {Whitney, Cedric Deslandes and Naval, Teresa and Quepons, Elizabeth and Singh, Simrandeep and Rick, Steven R and Irani, Lilly},
title = {HCI Tactics for Politics from Below: Meeting the Challenges of Smart Cities},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445314},
abstract = { As crucial public functions are transferred to computer systems, emerging technologies
have public implications that are often shaped beyond public influence and oversight.
“Smart city” and “modernization” projects are just some examples of such transformations.
This paper focuses on struggles over the acquisition, control, and maintenance of
these public, digital infrastructures. We focus on the forms of HCI knowledge and
practice that proved useful to a coalition of community organizations claiming rights
of input into and political oversight over surveillance technology. Their claims were
a response to their exclusion from decision-making about smart city implementation
in San Diego. We offer tactics “from below” as a way to attune HCI to the needs and
practices of those excluded from power over widespread technology infrastructures.
Ultimately, we argue that HCI cultivates a variety of capacities beyond design and
redesign that can strengthen struggles to shape real-world technologies from below.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {297},
numpages = {15}
}

@inbook{10.1145/3411764.3445244,
author = {Lee, Minha and Noortman, Renee and Zaga, Cristina and Starke, Alain and Huisman, Gijs and Andersen, Kristina},
title = {Conversational Futures: Emancipating Conversational Interactions for Futures Worth Wanting},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445244},
abstract = { We present a vision for conversational user interfaces (CUIs) as probes for speculating
with, rather than as objects to speculate about. Popular CUIs, e.g., Alexa, are changing
the way we converse, narrate, and imagine the world(s) to come. Yet, current conversational
interactions normatively may promote non-desirable ends, delivering a restricted range
of request-response interactions with sexist and digital colonialist tendencies. Our
critical design approach envisions alternatives by considering how future voices can
reside in CUIs as enabling probes. We present novel explorations that illustrate the
potential of CUIs as critical design material, by critiquing present norms and conversing
with imaginary species. As micro-level interventions, we show that conversations with
diverse futures through CUIs can persuade us to critically shape our discourse on
macro-scale concerns of the present, e.g., sustainability. We reflect on how conversational
interactions with pluralistic, imagined futures can contribute to how being human
stands to change. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {298},
numpages = {13}
}

@inbook{10.1145/3411764.3445268,
author = {Landwehr, Marvin and Engelbutzeder, Philip and Wulf, Volker},
title = {Community Supported Agriculture: The Concept of Solidarity in Mitigating Between Harvests and Needs},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445268},
abstract = { There is a developing recognition of the social and economic costs entailed in global
supply chains. In this paper, we report on efforts to provide alternative, more sustainable
and resilient models of production. Community Supported Agricultures (CSAs) address
this problem but require new means of exchange which, we suggest, offer a design opportunity
for sustainable HCI research. This paper presents a two months participatory observation
in a food movement, a German CSA which developed a distribution system involving their
own currency. Based on our ethnographic observations, we focus our discussion on (1)
the solidaristic principles upon which the movement is based and (2) techniques of
mediating between consumers’ wishes and the constraints of local agricultural production.
By relating to the continued development of CSAs, we identify three interrelated innovation
gaps and discuss new software architectures aimed at resolving the problems which
arise as the movement grows.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {299},
numpages = {13}
}

@inbook{10.1145/3411764.3445069,
author = {Hansson, Lon \r{A}ke Erni Johannes and Cerratto Pargman, Teresa and Pargman, Daniel Sapiens},
title = {A Decade of Sustainable HCI: Connecting SHCI to the Sustainable Development Goals},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445069},
abstract = { Sustainable HCI (SHCI) constitutes a relatively new research field within HCI. We
have identified four literature reviews of the field conducted between 2009-2014.
In this paper, we present and discuss the results of a systematic literature review
of peer-reviewed conference and journal articles that have been published in the field
during the last ten years (2010-2019). To this end, we apply the United Nations’ Sustainable
Development Goals (SDGs) as a framework to classify and discern high-level goals SHCI
researchers have worked towards during this period. This paper contributes to HCI
by 1) identifying Sustainable Development Goals that SHCI researchers have worked
towards, 2) discerning main research trends in the field during the last decade, 3)
using the SDG framework generatively to enumerate and reflect on areas that this far
have not been covered by SHCI research and 4) presenting takeaways and opportunities
for further research by the larger HCI community.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {300},
numpages = {19}
}

@inbook{10.1145/3411764.3445059,
author = {Berns, Katie and Rossitto, Chiara and Tholander, Jakob},
title = {Queuing for Waste: Sociotechnical Interactions within a Food Sharing Community},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445059},
abstract = { This paper investigates the practices of organising face-to-face events of a volunteer-run
food-sharing community in Denmark. The ethnographic fieldwork draws attention to the
core values underlying the ways sharing events are organised, and how - through the
work of volunteers - surplus food is transformed from a commodity to a gift. The findings
illustrate the community’s activist agenda of food waste reduction, along with the
volunteers’ concerns and practical labour of running events and organising the flow
of attendees through various queuing mechanisms. The paper contributes to the area
of Food and HCI by: i) outlining the role of queuing in organising activism and ii)
reflecting on the role that values, such as collective care and commons, can play
in structuring queuing at face-to-face events.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {301},
numpages = {15}
}

@inbook{10.1145/3411764.3445389,
author = {Kr\"{u}ger, Max and Weibert, Anne and Leal, Debora de Castro and Randall, Dave and Wulf, Volker},
title = {It Takes More Than One Hand to Clap: On the Role of ‘Care’ in Maintaining Design Results.},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445389},
abstract = { Within Participatory- and Co-Design projects, the issue of sustainability and maintenance
of the co-designed artefacts is a crucial yet largely unresolved issue. In this paper,
we look back on four years of work on co-designing tools that assist refugees and
migrants in their efforts to settle in Germany, the last of which the project has
been independently maintained by our community collaborators. We reflect on the role
of pre-existing care practices amongst our community collaborators, and a continued
openness throughout the project, that allowed a complex constellation of actors to
be involved in its ongoing maintenance and our own, often mundane activities which
have contributed to the sustainability of the results. Situating our account within
an HCI for Social Justice agenda, we thereby contribute to an ongoing discussion about
the sustainability of such activities.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {302},
numpages = {14}
}

@inbook{10.1145/3411764.3445263,
author = {Leal, Debora de Castro and Strohmayer, Angelika and Kr\"{u}ger, Max},
title = {On Activism and Academia: Reflecting Together and Sharing Experiences Among Critical Friends},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445263},
abstract = { In recent years HCI and CSCW work has increasingly begun to address complex social
problems and issues of social justice worldwide. Such activist-leaning work is not
without problems. Through the experiences and reflections of an activist becoming
academic and an academic becoming an activist, we outline these difficulties such
as (1) the risk of perpetuating violence, oppression and exploitation when working
with marginalised communities, (2) the reception of activist-academic work within
our academic communities, and (3) problems of social justice that exist within our
academic communities. Building on our own experiences, practices and existing literature
from a variety of disciplines we advocate for the possibility of an activist-academic
practice, outline possible ways forward and formulate questions we need to answer
for HCI to contribute to a more just world.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {18}
}

@inbook{10.1145/3411764.3445661,
author = {Raju, Dani Kalarikalayil and Seunarine, Krishna and Reitmaier, Thomas and Thomas, Gethin and Meena, Yogesh Kumar and Zhang, Chi and Pockett, Adam and Pearson, Jennifer and Robinson, Simon and Carnie, Matt and Sahoo, Deepak Ranjan and Jones, Matt},
title = {PV-Pix: Slum Community Co-Design of Self-Powered Deformable Smart Messaging Materials},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445661},
abstract = { Working with emergent users in two of Mumbai’s slums, we explored the value and uses
of photovoltaic (PV) self-powering digital materials. Through a series of co-design
workshops, a diary study and responses by artists and craftspeople, we developed the
PV-Pix concept for inter-home connections. Each PV-Pix element consists of a deformable
energy harvesting material that, when actuated by a person in one home, changes its
physical state both there and in a connected home. To explore the concept we considered
two forms of PV-Pix: one uses rigid materials and the other flexible ones. We deployed
two low-fidelity prototypes, each constructed of a grid of one PV-Pix type, in four
slum homes over a four week period to further understand the usability and uses of
the materials, eliciting interesting inter-family communication practices. Encouraged
by these results we report on a first-step towards working prototypes and demonstrate
the technical viability of the approach.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {14}
}

@inbook{10.1145/3411764.3445655,
author = {Heitlinger, Sara and Houston, Lara and Taylor, Alex and Catlow, Ruth},
title = {Algorithmic Food Justice: Co-Designing More-than-Human Blockchain Futures for the Food Commons},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445655},
abstract = {The relationships that constitute the global industrial food system tend towards two
dominant values that are creating unsustainable social and environmental inequalities.
The first is a human-centered perspective on food that privileges humans over all
other species. The second is a view of food as a commodity to be traded for maximum
economic value, rewarding a small number of shareholders. We present work that explores
the unique algorithmic affordances of blockchain to create new types of value exchange
and governance in the food system. We describe a project that used roleplay with urban
agricultural communities to co-design blockchain-based food futures and explore the
conditions for creating a thriving multispecies food commons. We discuss how the project
helped rethink algorithmic food justice by reconfiguring more-than-human values and
reconfiguring food as more-than-human commons. We also discuss some of the challenges
and tensions arising from these explorations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {305},
numpages = {17}
}

@inbook{10.1145/3411764.3445165,
author = {Chang, Chia-Ming and Lee, Chia-Hsien and Igarashi, Takeo},
title = {Spatial Labeling: Leveraging Spatial Layout for Improving Label Quality in Non-Expert Image Annotation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445165},
abstract = {Non-expert annotators (who lack sufficient domain knowledge) are often recruited for
manual image labeling tasks owing to the lack of expert annotators. In such a case,
label quality may be relatively low. We propose leveraging the spatial layout for
improving label quality in non-expert image annotation. In the proposed system, an
annotator first spatially lays out the incoming images and labels them on an open
space, placing related items together. This serves as a working space (spatial organization)
for tentative labeling. During the process, the annotator observes and organizes the
similarities and differences between the items. Finally, the annotator provides definitive
labels to the images based on the results of the spatial layout. We ran a user study
comparing the proposed method and a traditional non-spatial layout in an image labeling
task. The results demonstrated that annotators can complete the labeling tasks more
accurately using the spatial layout interface than the non-spatial layout interface.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {12}
}

@inbook{10.1145/3411764.3445527,
author = {Weinman, Nathaniel and Drucker, Steven M. and Barik, Titus and DeLine, Robert},
title = {Fork It: Supporting Stateful Alternatives in Computational Notebooks},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445527},
abstract = { Computational notebooks, which seamlessly interleave code with results, have become
a popular tool for data scientists due to the iterative nature of exploratory tasks.
However, notebooks provide a single execution state for users to manipulate through
creating and manipulating variables. When exploring alternatives, data scientists
must carefully create many-step manipulations in visually distant cells. We conducted
formative interviews with 6 professional data scientists, motivating design principles
behind exposing multiple states. We introduce forking — creating a new interpreter
session — and backtracking — navigating through previous states. We implement these
interactions as an extension to notebooks that help data scientists more directly
express and navigate through decision points a single notebook. In a qualitative evaluation,
11 professional data scientists found the tool would be useful for exploring alternatives
and debugging code to create a predictive model. Their insights highlight further
challenges to scaling this functionality.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {307},
numpages = {12}
}

@inbook{10.1145/3411764.3445048,
author = {Li, Xingjun and Wang, Yuanxin and Wang, Hong and Wang, Yang and Zhao, Jian},
title = {NBSearch: Semantic Search and Visual Exploration of Computational Notebooks},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445048},
abstract = { Code search is an important and frequent activity for developers using computational
notebooks (e.g., Jupyter). The flexibility of notebooks brings challenges for effective
code search, where classic search interfaces for traditional software code may be
limited. In this paper, we propose, NBSearch, a novel system that supports semantic
code search in notebook collections and interactive visual exploration of search results.
NBSearch leverages advanced machine learning models to enable natural language search
queries and intuitive visualizations to present complicated intra- and inter-notebook
relationships in the returned results. We developed NBSearch through an iterative
participatory design process with two experts from a large software company. We evaluated
the models with a series of experiments and the whole system with a controlled user
study. The results indicate the feasibility of our analytical pipeline and the effectiveness
of NBSearch to support code search in large notebook collections. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {308},
numpages = {14}
}

@inbook{10.1145/3411764.3445267,
author = {DeLine, Robert A},
title = {Glinda: Supporting Data Science with Live Programming, GUIs and a Domain-Specific Language},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445267},
abstract = { Researchers have explored several avenues to mitigate data scientists’ frustrations
with computational notebooks, including: (1) live programming, to keep notebook results
consistent and up to date; (2) supplementing scripting with graphical user interfaces
(GUIs), to improve ease of use; and (3) providing domain-specific languages (DSLs),
to raise a script’s level of abstraction. This paper introduces Glinda, which combines
these three approaches by providing a live programming experience, with interactive
results, for a domain-specific language for data science. The language’s compiler
uses an open-ended set of “recipes” to execute steps in the user’s data science workflow.
Each recipe is intended to combine the expressiveness of a written notation with the
ease-of-use of a GUI. Live programming provides immediate feedback to a user’s input,
whether in the form of program edits or GUI gestures. In a qualitative evaluation
with 12 professional data scientists, participants highly rated the live programming
and interactive results. They found the language productive and sufficiently expressive
and suggested opportunities to extend it.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {309},
numpages = {11}
}

@inbook{10.1145/3411764.3445538,
author = {Schoop, Eldon and Huang, Forrest and Hartmann, Bjoern},
title = {UMLAUT: Debugging Deep Learning Programs Using Program Structure and Model Behavior},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445538},
abstract = {Training deep neural networks can generate non-descriptive error messages or produce
unusual output without any explicit errors at all. While experts rely on tacit knowledge
to apply debugging strategies, non-experts lack the experience required to interpret
model output and correct Deep Learning (DL) programs. In this work, we identify DL
debugging heuristics and strategies used by experts, andIn this work, we categorize
the types of errors novices run into when writing ML code, and map them onto opportunities
where tools could help. We use them to guide the design of Umlaut. Umlaut&nbsp;checks DL
program structure and model behavior against these heuristics; provides human-readable
error messages to users; and annotates erroneous model output to facilitate error
correction. Umlaut&nbsp;links code, model output, and tutorial-driven error messages in
a single interface. We evaluated Umlaut&nbsp;in a study with 15 participants to determine
its effectiveness in helping developers find and fix errors in their DL programs.
Participants using Umlaut&nbsp;found and fixed significantly more bugs and were able to
implement fixes for more bugs compared to a baseline condition. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {310},
numpages = {16}
}

@inbook{10.1145/3411764.3445265,
author = {Lau, Sam and Srinivasa Ragavan, Sruti Srinivasa and Milne, Ken and Barik, Titus and Sarkar, Advait},
title = {TweakIt: Supporting End-User Programmers Who Transmogrify Code},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445265},
abstract = { End-user programmers opportunistically copy-and-paste code snippets from colleagues
or the web to accomplish their tasks. Unfortunately, these snippets often don’t work
verbatim, so these people—who are non-specialists in the programming language—make
guesses and tweak the code to understand and apply it successfully. To support their
desired workflow and facilitate tweaking and understanding, we built a prototype tool,
TweakIt, that provides users with a familiar live interaction to help them understand,
introspect, and reify how different code snippets would transform their data. Through
a usability study with 14 data analysts, participants found the tool to be useful
to understand the function of otherwise unfamiliar code, to increase their confidence
about what the code does, to identify relevant parts of code specific to their task,
and to proactively explore and evaluate code. Overall, our participants were enthusiastic
about incorporating TweakIt in their own day-to-day work.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {311},
numpages = {12}
}

@inbook{10.1145/3411764.3445567,
author = {Zhao, Valerie and Zhang, Lefan and Wang, Bo and Littman, Michael L. and Lu, Shan and Ur, Blase},
title = {Understanding Trigger-Action Programs Through Novel Visualizations of Program Differences},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445567},
abstract = {Trigger-action programming (if-this-then-that rules) empowers non-technical users
to automate services and smart devices. As a user’s set of trigger-action programs
evolves, the user must reason about behavior differences between similar programs,
such as between an original program and several modification candidates, to select
programs that meet their goals. To facilitate this process, we co-designed user interfaces
and underlying algorithms to highlight differences between trigger-action programs.
Our novel approaches leverage formal methods to efficiently identify and visualize
differences in program outcomes or abstract properties. We also implemented a traditional
interface that shows only syntax differences in the rules themselves. In a between-subjects
online experiment with 107 participants, the novel interfaces better enabled participants
to select trigger-action programs matching intended goals in complex, yet realistic,
situations that proved very difficult when using traditional interfaces showing syntax
differences. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {312},
numpages = {17}
}

@inbook{10.1145/3411764.3445654,
author = {Yan, Litao and Glassman, Elena L. and Zhang, Tianyi},
title = {Visualizing Examples of Deep Neural Networks at Scale},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445654},
abstract = { Many programmers want to use deep learning due to its superior accuracy in many challenging
domains. Yet our formative study with ten programmers indicated that, when constructing
their own deep neural networks (DNNs), they often had a difficult time choosing appropriate
model structures and hyperparameter values. This paper presents ExampleNet—a novel
interactive visualization system for exploring common and uncommon design choices
in a large collection of open-source DNN projects. ExampleNet provides a holistic
view of the distribution over model structures and hyperparameter settings in the
corpus of DNNs, so users can easily filter the corpus down to projects tackling similar
tasks and compare design choices made by others. We evaluated ExampleNet in a within-subjects
study with sixteen participants. Compared with the control condition (i.e., online
search), participants using ExampleNet were able to inspect more online examples,
make more data-driven design decisions, and make fewer design mistakes.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {313},
numpages = {14}
}

@inbook{10.1145/3411764.3445682,
author = {Li, Jingyi and Hashim, Sonia and Jacobs, Jennifer},
title = {What We Can Learn From Visual Artists About Software Development},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445682},
abstract = {This paper explores software’s role in visual art production by examining how artists
use and develop software. We conducted interviews with professional artists who were
collaborating with software developers, learning software development, and building
and maintaining software. We found artists were motivated to learn software development
for intellectual growth and access to technical communities. Artists valued efficient
workflows through skilled manual execution and personal software development, but
avoided high-level forms of software automation. Artists identified conflicts between
their priorities and those of professional developers and computational art communities,
which influenced how they used computational aesthetics in their work. These findings
contribute to efforts in systems engineering research to integrate end-user programming
and creativity support across software and physical media, suggesting opportunities
for artists as collaborators. Artists’ experiences writing software can guide technical
implementations of domain-specific representations, and their experiences in interdisciplinary
production can aid inclusive community building around computational tools. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {14}
}

@inbook{10.1145/3411764.3445326,
author = {Zhong, Mingyuan and Li, Gang and Li, Yang},
title = {Spacewalker: Rapid UI Design Exploration Using Lightweight Markup Enhancement and Crowd Genetic Programming},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445326},
abstract = { User interface design is a complex task that involves designers examining a wide
range of options. We present Spacewalker, a tool that allows designers to rapidly
search a large design space for an optimal web UI with integrated support. Designers
first annotate each attribute they want to explore in a typical HTML page, using a
simple markup extension we designed. Spacewalker then parses the annotated HTML specification,
and intelligently generates and distributes various configurations of the web UI to
crowd workers for evaluation. We enhanced a genetic algorithm to accommodate crowd
worker responses from pairwise comparison of UI designs, which is crucial for obtaining
reliable feedback. Based on our experiments, Spacewalker allows designers to effectively
search a large design space of a UI, using the language they are familiar with, and
improve their design rapidly at a minimal cost.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {315},
numpages = {11}
}

@inbook{10.1145/3411764.3445043,
author = {Jiang, Yue and Stuerzlinger, Wolfgang and Lutteroth, Christof},
title = {ReverseORC: Reverse Engineering of Resizable User Interface Layouts with OR-Constraints},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445043},
abstract = { Reverse engineering (RE) of user interfaces (UIs) plays an important role in software
evolution. However, the large diversity of UI technologies and the need for UIs to
be resizable make this challenging. We propose ReverseORC, a novel RE approach able
to discover diverse layout types and their dynamic resizing behaviours independently
of their implementation, and to specify them by using OR constraints. Unlike previous
RE approaches, ReverseORC infers flexible layout constraint specifications by sampling
UIs at different sizes and analyzing the differences between them. It can create specifications
that replicate even some non-standard layout managers with complex dynamic layout
behaviours. We demonstrate that ReverseORC works across different platforms with very
different layout approaches, e.g., for GUIs as well as for the Web. Furthermore, it
can be used to detect and fix problems in legacy UIs, extend UIs with enhanced layout
behaviours, and support the creation of flexible UI layouts. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {316},
numpages = {18}
}

@inbook{10.1145/3411764.3445765,
author = {Dang, Hai and Buschek, Daniel},
title = {GestureMap: Supporting Visual Analytics and Quantitative Analysis of Motion Elicitation Data by Learning 2D Embeddings},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445765},
abstract = {This paper presents GestureMap, a visual analytics tool for gesture elicitation which
directly visualises the space of gestures. Concretely, a Variational Autoencoder embeds
gestures recorded as 3D skeletons on an interactive 2D map. GestureMap further integrates
three computational capabilities to connect exploration to quantitative measures:
Leveraging DTW Barycenter Averaging (DBA), we compute average gestures to 1) represent
gesture groups at a glance; 2) compute a new consensus measure (variance around average
gesture); and 3) cluster gestures with k-means. We evaluate GestureMap and its concepts
with eight experts and an in-depth analysis of published data. Our findings show how
GestureMap facilitates exploring large datasets and helps researchers to gain a visual
understanding of elicited gesture spaces. It further opens new directions, such as
comparing elicitations across studies. We discuss implications for elicitation studies
and research, and opportunities to extend our approach to additional tasks in gesture
elicitation. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {12}
}

@inbook{10.1145/3411764.3445457,
author = {Kang, Woojin and Jung, In-Taek and Lee, DaeHo and Hong, Jin-Hyuk},
title = {Styling Words: A Simple and Natural Way to Increase Variability in Training Data Collection for Gesture Recognition},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445457},
abstract = {Due to advances in deep learning, gestures have become a more common tool for human-computer
interaction. When implementing a large amount of training data, deep learning models
show remarkable performance in gesture recognition. Since it is expensive and time
consuming to collect gesture data from people, we are often confronted with a practicality
issue when managing the quantity and quality of training data. It is a well-known
fact that increasing training data variability can help to improve the generalization
performance of machine learning models. Thus, we directly intervene in the collection
of gesture data to increase human gesture variability by adding some words (called
styling words) into the data collection instructions, e.g., giving the instruction
"perform gesture #1 faster" as opposed to "perform gesture #1." Through an in-depth
analysis of gesture features and video-based gesture recognition, we have confirmed
the advantageous use of styling words in gesture training data collection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {318},
numpages = {12}
}

@inbook{10.1145/3411764.3445784,
author = {Sermuga Pandian, Vinoth Pandian and Suleri, Sarah and Jarke, Prof. Dr. Matthias},
title = {UISketch: A Large-Scale Dataset of UI Element Sketches},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445784},
abstract = { This paper contributes the first large-scale dataset of 17,979 hand-drawn sketches
of 21 UI element categories collected from 967 participants, including UI/UX designers,
front-end developers, HCI, and CS grad students, from 10 different countries. We performed
a perceptual study with this dataset and found out that UI/UX designers can recognize
the UI element sketches with ~96% accuracy. To compare human performance against computational
recognition methods, we trained the state-of-the-art DNN-based image classification
models to recognize the UI elements sketches. This study revealed that the ResNet-152
model outperforms other classification networks and detects unknown UI element sketches
with 91.77% accuracy (chance is 4.76%). We have open-sourced the entire dataset of
UI element sketches to the community intending to pave the way for further research
in utilizing AI to assist the conversion of lo-fi UI sketches to higher fidelities.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {319},
numpages = {14}
}

@inbook{10.1145/3411764.3445358,
author = {Yun, Gyeore and Lee, Hyoseung and Han, Sangyoon and Choi, Seungmoon},
title = {Improving Viewing Experiences of First-Person Shooter Gameplays with Automatically-Generated Motion Effects},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445358},
abstract = {In recent times, millions of people enjoy watching video gameplays at an eSports stadium
or home. We seek a method that improves gameplay spectator or viewer experiences by
presenting multisensory stimuli. Using a motion chair, we provide the motion effects
automatically generated from the audiovisual stream to the viewers watching a first-person
shooter (FPS) gameplay. The motion effects express the game character’s movement and
gunfire action. We describe algorithms for the computation of such motion effects
developed using computer vision techniques and deep learning. By a user study, we
demonstrate that our method of providing motion effects significantly improves the
viewing experiences of FPS gameplay. The contributions of this paper are with the
motion synthesis algorithms integrated for FPS games and the empirical evidence for
the benefits of experiencing multisensory gameplays. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {320},
numpages = {14}
}

@inbook{10.1145/3411764.3445143,
author = {Wu, Minerva and Lee, Je Seok and Steinkuehler, Constance},
title = {Understanding Tilt in Esports: A Study on Young League of Legends Players},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445143},
abstract = {Tilt as a gaming term is associated with frustration, rage, and deterioration of gameplay
ability. In this exploratory study, we surveyed 95 esports players in a high school
esports league on their definitions of tilt, triggers for tilting, responses to tilt,
and perception of its malleability. We found that players are tilted most commonly
by their own teammates rather than opponents, with their most negative tilt responses
reserved for themselves. The majority surveyed believe that they can change how easily
they are tilted and believing so was found to lead players to choose more positive
responses to tilt. In contrast, perceiving tilt as malleable was found to increase
the probability that participants respond with positive strategies. Implications for
efforts to improve esports culture and community are discussed.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {321},
numpages = {9}
}

@inbook{10.1145/3411764.3445073,
author = {Turkay, Selen and Formosa, Jessica and Cuthbert, Robert and Adinolf, Sonam and Brown, Ross Andrew},
title = {Virtual Reality Esports - Understanding Competitive Players’ Perceptions of Location Based VR Esports},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445073},
abstract = {Competitive VR gaming has emerged as a new trend in recent years, due to the availability
of consumer grade VR technologies and the rise of esports as a billion dollar industry.
Despite the considerable attention to competitive VR gaming, there is a lack of research
on attitudes and experiences that players have with these games. In this qualitative
study with a pre-post interview design, we recruited eight competitive Counter-Strike:
Global Offensive players from a university esports club. We aimed to understand their
attitudes towards VR esports and their experiences playing a representative location
based VR esports game. Findings showed that players had visceral and positive affective
experiences in the game, such as how players map physical movements to the game. These
findings can help design future competitive VR esports, while also further contributing
to HCI as the first exploration on player experiences with VR esports, laying groundwork
for future studies. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {322},
numpages = {15}
}

@inbook{10.1145/3411764.3445248,
author = {Madden, Daniel and Liu, Yuxuan and Yu, Haowei and Sonbudak, Mustafa Feyyaz and Troiano, Giovanni M and Harteveld, Casper},
title = {“Why Are You Playing Games? You Are a Girl!”: Exploring Gender Biases in Esports},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445248},
abstract = {Esports are rapidly growing within academia. In HCI, earlier work explored how problematic
behaviors emerging from gender biases (e.g., toxicity) negatively impact female participation
in esports. Here, we further explore gender biases in esports by interviewing 19 self-identified
female and male professional gamers and event organizers. We inquire our interviewees
about personal experiences with gender biases in esports and their perspective on
how these biases impact participation, inclusivity, and career prospects. Our interviewees
see gender biases in esports as a consequence of stereotypical gender roles in gaming
tout-court (e.g., girls do not like violence, boys are competitive by nature). The
rationale for separating male and female in esports, however, seems rooted in the
need for female gamers to create role-models and grow in self-confidence. We scrutinize
the considerations emerging from our interviews under a Feminist HCI lens and discuss
how HCI research can help design equitable environments in esports. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {323},
numpages = {15}
}

@inbook{10.1145/3411764.3445733,
author = {Madden, Daniel and Harteveld, Casper},
title = {“Constant Pressure of Having to Perform”: Exploring Player Health Concerns in Esports},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445733},
abstract = {Esports is a rapidly growing industry, generating interest from research disciplines
including marketing, social sciences, and human-computer interaction. Despite its
continued growth, there is a lack of studies surrounding the health of esports players.
Previous work on the subject is limited, as research has only recently begun to explore
the potential factors affecting physical and psychological wellness. Using an exploratory
mixed-methods approach, a series of semi-structured interviews (n = 10) and an online
survey (n = 68) were used to identify the biggest health concerns among esports players.
The results demonstrate a better understanding of issues regarding physical and psychological
wellness according to the players. Moving forward, we suggest the HCI community adapts
mindfulness, ergonomics, and social-emotional learning as methods for supporting player’s
health concerns. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {324},
numpages = {14}
}

@inbook{10.1145/3411764.3445363,
author = {A. Sparrow, Lucy and Gibbs, Martin and Arnold, Michael},
title = {The Ethics of Multiplayer Game Design and Community Management: Industry Perspectives and Challenges},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445363},
abstract = {Game industry professionals are frequently implementing new methods of addressing
ethical issues related to in-game toxicity and disruptive player behaviours associated
with online multiplayer games. However, academic work on these behaviours tends to
focus on the perspectives of players rather than the industry. To fully understand
the ethics of multiplayer games and promote ethical design, we must examine the challenges
facing those designing multiplayer games through an ethical lens. To this end, this
paper presents a reflexive thematic analysis of 21 in-depth interviews with games
industry professionals on their ethical views and experiences in game design and community
management. We identify a number of tensions involved in making ethics-related design
decisions for divided player communities alongside current game design practices that
are concerned with functionality, revenue and entertainment. We then put forward a
set of design considerations for integrating ethics into multiplayer game design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {325},
numpages = {13}
}

@inbook{10.1145/3411764.3445245,
author = {Liu, Shengmei and Claypool, Mark and Kuwahara, Atsuo and Sherman, Jamie and Scovell, James J},
title = {Lower is Better? The Effects of Local Latencies on Competitive First-Person Shooter Game Players},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445245},
abstract = { Video game play is among the most popular forms of entertainment in the world and
eSports is a multi-billion dollar industry. Esports gamers, and competitive gamers
more broadly, want fast game systems to maximize their chances of winning. In general,
the faster the game system, the lower the latency between a player’s action and the
intended outcome. But how much small reductions in local latencies benefit competitive
players is not known. This paper presents results from a 43-person user study that
evaluates the impact of system latencies for high-end gaming systems (below 125 ms)
on experienced Counter-strike: Global Offensive (CS:GO) players. Analysis of the results
show pronounced benefits to CS:GO player performance (accuracy and score) for even
small reductions in latency, with subjective opinions on Quality of Experience following
suit.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {326},
numpages = {12}
}

@inbook{10.1145/3411764.3445072,
author = {Kleinman, Erica and Chojnacki, Sara and Seif El-Nasr, Magy},
title = {The Gang’s All Here: How People Used Games to Cope with COVID19 Quarantine},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445072},
abstract = { In 2020, the rapid spread of COVID-19 forced many people to self-isolate, resulting
in struggles with mental health [60], and an increase in gaming [3]. In this paper,
we seek to examine how individuals used digital games during the quarantine. We conducted
a two-tier qualitative study where we used a thematic analysis of tweets to derive
questions for an online survey that we distributed. Results of thematic analysis of
survey responses identified 15 themes. Some themes confirm previous works’ findings,
particularly how games are used to increase social connection or distract oneself
from unpleasant situations. We also found new themes unique to the quarantine, such
as interactions with non-player characters used as a surrogate for real-world interaction
and using in-game routines as a substitute to real-world routines lost due to the
pandemic. This work discusses the use of games during the pandemic and can be seeds
for future studies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {327},
numpages = {12}
}

@inbook{10.1145/3411764.3445287,
author = {Denoo, Maarten and Bibert, Niels and Zaman, Bieke},
title = {Disentangling the Motivational Pathways of Recreational Esports Gamblers: A Laddering Study},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445287},
abstract = {Whereas past CHI-related work has paid attention to various elements of the esports
industry, there exists a scarcity of such research on the increasing convergence between
esports and gambling. This study, therefore, aimed to shed light on the emerging phenomenon
of esports betting in two ways. First, we theorized about its characteristics according
to the 5W1H framework. Second, using semi-structured laddering interviews and Means-End
Chain Theory, we assessed the esports betting motivations of young, male and recreational
gamblers who interact with monetary and skin betting websites. Our results show that
gamblers follow various motivational pathways when using an esports betting platform
and construct their motives in relation to platform-specific properties and personal
values. As such, we demonstrate that a holistic understanding of esports betting is
of utmost importance if we want to explain and investigate its appeal to a worldwide
audience.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {328},
numpages = {15}
}

@inbook{10.1145/3411764.3445511,
author = {Striner, Alina and Webb, Andrew M. and Hammer, Jessica and Cook, Amy},
title = {Mapping Design Spaces for Audience&nbsp;Participation&nbsp;In&nbsp;Game&nbsp;Live&nbsp;Streaming},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445511},
abstract = {Live streaming sites such as Twitch offer new ways for remote audiences to engage
with and affect gameplay. While research has considered how audiences interact with
games, HCI lacks clear demarcations of the potential design spaces for audience participation.
This paper introduces and validates a theme map of audience participation in game
live streaming for student designers. This map is a lens that reveals relationships
among themes and sub-themes of Agency, Pacing, and Community—to explore, reflect upon,
describe, and make sense of emerging, complex design spaces. We are the first to articulate
such a lens, and to provide a reflective tool to support future research and education.
To create the map, we perform a thematic analysis of design process documents of a
course on audience participation for Twitch, using this analysis to visually coordinate
relationships between important themes. To help student designers analyze and reflect
on existing experiences, we supplement the theme map with a set of mapping procedures.
We validate the applicability of our map with a second set of student designers, who
found the map useful as a comparative and reflective tool. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {329},
numpages = {15}
}

@inbook{10.1145/3411764.3445174,
author = {Wallner, G\"{u}nter and van Wijland, Marnix and Bernhaupt, Regina and Kriglstein, Simone},
title = {What Players Want: Information Needs of Players on Post-Game Visualizations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445174},
abstract = { With the rise of competitive online gaming and esports, players’ ability to review,
reflect upon, and improve their in-game performance has become important. Post-play
visualizations are key for such improvements. Despite the increased interest in visualizations
of gameplay, research specifically informing the design of player-centric visualizations
is currently limited. As with all visualizations, their design should, however, be
guided by a thorough understanding of the goals to be achieved and which information
is important and why. This paper reports on a mixed-methods study exploring the information
demands posed by players on post-play visualizations and the goals they pursue with
such visualizations. We focused on three genres that enjoy great popularity within
the competitive gaming scene. Our results provide useful guideposts on which data
to focus on by offering an overview of the relevance of different in-game metrics
across genres. Lastly, we outline high-level implications for the design of post-play
visualizations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {330},
numpages = {13}
}

@inbook{10.1145/3411764.3445217,
author = {Park, Eunji and Lee, Sangyoon and Ham, Auejin and Choi, Minyeop and Kim, Sunjun and Lee, Byungjoo},
title = {Secrets of Gosu: Understanding Physical Combat Skills of Professional Players in First-Person Shooters},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445217},
abstract = { In first-person shooters (FPS), professional players (a.k.a., Gosu) outperform amateur
players. The secrets behind the performance of professional FPS players have been
debated in online communities with many conjectures; however, attempts of scientific
verification have been limited. We addressed this conundrum through a data-collection
study of the gameplay of eight professional and eight amateur players in the commercial
FPS Counter-Strike: Global Offensive. The collected data cover behavioral data from
six sensors (motion capture, eye tracker, mouse, keyboard, electromyography armband,
and pulse sensor) and in-game data (player data and event logs). We examined conjectures
in four categories: aiming, character movement, physicality, and device and settings.
Only 6 out of 13 conjectures were supported with statistically sufficient evidence.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {331},
numpages = {14}
}

@inbook{10.1145/3411764.3445114,
author = {McKay, Dana and Miller, Charlynn},
title = {Standing in the Way of Control: A Call to Action to Prevent Abuse through Better Design of Smart Technologies},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445114},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {332},
numpages = {14}
}

@inbook{10.1145/3411764.3445121,
author = {Ku\v{c}era, Jan and Scott, James and Lindley, Si\^{a}n and Olivier, Patrick},
title = {Bedtime Window: A Field Study Connecting Bedrooms of Long-Distance Couples Using a Slow Photo-Stream and Shared Real-Time Inking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445121},
abstract = {We present a system for connecting partners in long-distance relationships in bedrooms
and at bedtime, a space and time that most couples share. Unlike communications explicitly
initiated by users, our system is always-on, staying in the background and enabling
remote presence without constant use. We present findings from a field study in which
the system was deployed into participants’ bedrooms. The system includes an automated
photo-stream (rather than video), which was found to provide a balance between the
feeling of presence and privacy, and to remove the pressure to communicate. The system
also includes a real-time shared inking canvas with disappearing ink, which was found
to provide a rich versatile medium allowing for new patterns of communication, live
interventions, and collaborative drawing. Learnings from how our system balances privacy
and remote connectedness may also have relevance for other domains such as remote
healthcare and education.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {333},
numpages = {12}
}

@inbook{10.1145/3411764.3445200,
author = {Liu, Fannie and Park, Chunjong and Tham, Yu Jiang and Tsai, Tsung-Yu and Dabbish, Laura and Kaufman, Geoff and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {Significant Otter: Understanding the Role of Biosignals in Communication},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445200},
abstract = { With the growing ubiquity of wearable devices, sensed physiological responses provide
new means to connect with others. While recent research demonstrates the expressive
potential for biosignals, the value of sharing these personal data remains unclear.
To understand their role in communication, we created Significant Otter, an Apple
Watch/iPhone app that enables romantic partners to share and respond to each other’s
biosignals in the form of animated otter avatars. In a one-month study with 20 couples,
participants used Significant Otter with biosignals sensing OFF and ON. We found that
while sensing OFF enabled couples to keep in touch, sensing ON enabled easier and
more authentic communication that fostered social connection. However, the addition
of biosignals introduced concerns about autonomy and agency over the messages they
sent. We discuss design implications and future directions for communication systems
that recommend messages based on biosignals.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {334},
numpages = {15}
}

@inbook{10.1145/3411764.3445405,
author = {Saha, Koustuv and Seybolt, Jordyn and Mattingly, Stephen M and Aledavood, Talayeh and Konjeti, Chaitanya and Martinez, Gonzalo J. and Grover, Ted and Mark, Gloria and De Choudhury, Munmun},
title = {What Life Events Are Disclosed on Social Media, How, When, and By Whom?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445405},
abstract = {Social media platforms continue to evolve as archival platforms, where important milestones
in an individual’s life are socially disclosed for support, solidarity, maintaining
and gaining social capital, or to meet therapeutic needs. However, a limited understanding
of how and what life events are disclosed (or not) prevents designing platforms to
be sensitive to life events. We ask what life events individuals disclose on a 256
participants’ year-long Facebook dataset of 14K posts against their self-reported
life events. We contribute a codebook to identify life event disclosures and build
regression models on factors explaining life events’ disclosures. Positive and anticipated
events are more likely, whereas significant, recent, and intimate events are less
likely to be disclosed on social media. While all life events may not be disclosed,
online disclosures can reflect complementary information to self-reports. Our work
bears practical and platform design implications in providing support and sensitivity
to life events. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {335},
numpages = {22}
}

@inbook{10.1145/3411764.3445353,
author = {Park, So Yeon and Santero, Nicole K. and Kaneshiro, Blair and Lee, Jin Ha},
title = {Armed in ARMY: A Case Study of How BTS Fans Successfully Collaborated to #MatchAMillion for Black Lives Matter},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445353},
abstract = { Music fans strategically support their artists. Their collective efforts can extend
to social causes as well: In 2020 for example, ARMY—the fandom of the music group
BTS—successfully organized the #MatchAMillion campaign to raise over one million USD
to support Black Lives Matter. To better understand factors of fandoms’ collaborative
success for arguably unrelated social goals, we conducted a survey focusing on ARMYs’
perceptions of their fandom and their social effort. Most ARMYs viewed the fandom
as a community, loosely structured with pillar accounts. They reported trust in each
other as well as high team composition, which mediated the relationship between their
neutral psychological safety and high efficacy. Respondents attributed their success
in #MatchAMillion to shared values, good teamwork, and established infrastructure.
Our findings elucidate contextual factors that contribute to ARMY’s collaborative
success and highlight themes that may be applied to studying other fandoms and their
collaborative efforts. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {336},
numpages = {14}
}

@inbook{10.1145/3411764.3445320,
author = {Mallari, Keri and Williams, Spencer and Hsieh, Gary},
title = {Understanding Analytics Needs of Video Game Streamers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445320},
abstract = { Live streaming is a rapidly growing industry, with millions of content creators using
platforms like Twitch to share games, art, and other activities. However, with this
rise in popularity, most streamers often fail to attract viewers and grow their platforms.
Analytic tools—which have shown success in other business and learning contexts—may
be one potential solution, but their use in streaming settings remains unexplored.
In this study, we focused on game streaming and interviewed 18 game streamers on Twitch
and Mixer about their information needs and current use of tools, supplemented by
explorations into their Discord communities. We find that streamers have a range of
content, marketing, and community information needs, many of which are not being met
by available tools. We conclude with design implications for developing more streamer-centered
analytics for video game streamers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {12}
}

@inbook{10.1145/3411764.3445397,
author = {Niu, Shuo and Bartolome, Ava and Mai, Cat and Ha, Nguyen Binh},
title = {#StayHome #WithMe: How Do YouTubers Help with COVID-19 Loneliness?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445397},
abstract = { Loneliness threatens public mental wellbeing during COVID-19. In response, YouTube
creators participated in the #StayHome #WithMe movement (SHWM) and made myriad videos
for people experiencing loneliness or boredom at home. User-shared videos generate
parasocial attachment and virtual connectedness. However, there is limited knowledge
of how creators contributed videos during disasters to provide social provisions as
disaster-relief. Grounded on Weiss’s loneliness theory, this work analyzed 1488 SHWM
videos to examine video sharing as a pathway to social provisions. Findings suggested
that skill and knowledge sharing, entertaining arts, homelife activities, live chatting,
and gameplay were the most popular video styles. YouTubers utilized parasocial relationships
to form a space for staying away from the disaster. SHWM YouTubers provided friend-like,
mentor-like, and family-like provisions through videos in different styles. Family-like
provisions led to the highest overall viewer engagement. Based on the findings, design
implications for supporting viewers’ mental wellbeing in disasters are discussed.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {338},
numpages = {15}
}

@inbook{10.1145/3411764.3445664,
author = {K. Miller, Matthew and Johannes Dechant, Martin and L. Mandryk, Regan},
title = {Meeting You, Seeing Me: The Role of Social Anxiety, Visual Feedback, and Interface Layout in a Get-to-Know-You Task via Video Chat.},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445664},
abstract = {The growing number of video chat users includes socially anxious people, but it is
not known how video chat interfaces affect their interpersonal interactions. In our
first study, we use a get-to-know-you task to show that when video feedback of oneself
is disabled, higher social anxiety is associated with more public self-awareness,
use of 2nd person pronouns, and experienced anxiety. Higher social anxiety was linked
to discussing more topics, but discussing more topics only elicited higher self-disclosure
and trust when social anxiety was low. In our second study, we assess these same effects
using a presentation layout video chat interface and observe no effects of social
anxiety on public self-awareness, 2nd person pronoun use, or number of topics discussed;
no effect of feedback on experienced anxiety; and no link between number of topics
and self-disclosure. Video chat adopters and designers should consider how feedback
and interface layout affect conversations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {339},
numpages = {14}
}

@inbook{10.1145/3411764.3445776,
author = {Song, Jaeyoon and Riedl, Christoph and Malone, Thomas W.},
title = {Online Mingling: Supporting Ad Hoc, Private Conversations at Virtual Conferences},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445776},
abstract = { Even though today’s videoconferencing systems are often very useful, these systems
do not provide support for one of the most important aspects of in-person meetings:
the ad hoc, private conversations that happen before, after, and during the breaks
of scheduled events–the proverbial hallway conversations. Here we describe our design
of a simple system, called Minglr, which supports this kind of interaction by facilitating
the matching of conversational partners. We describe two studies of this system’s
use at two virtual conferences with over 450 total participants. Our results provide
evidence for the usefulness of this capability, showing that, for example, 81% of
people who used the system successfully thought that future virtual conferences should
include a tool with similar functionality. We believe that similar functionality is
likely to be widely implemented in many videoconferencing systems and to increase
the feasibility and desirability of many kinds of remote work and socializing.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {340},
numpages = {10}
}

@inbook{10.1145/3411764.3445092,
author = {Steiger, Miriah and Bharucha, Timir J and Venkatagiri, Sukrit and Riedl, Martin J. and Lease, Matthew},
title = {The Psychological Well-Being of Content Moderators: The Emotional Labor of Commercial Moderation and Avenues for Improving Support},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445092},
abstract = { An estimated 100,000 people work today as commercial content moderators. These moderators
are often exposed to disturbing content, which can lead to lasting psychological and
emotional distress. This literature review investigates moderators’ psychological
symptomatology, drawing on other occupations involving trauma exposure to further
guide understanding of both symptoms and support mechanisms. We then introduce wellness
interventions and review both programmatic and technological approaches to improving
wellness. Additionally, we review methods for evaluating intervention efficacy. Finally,
we recommend best practices and important directions for future research. Content
Warning: we discuss the intense labor and psychological effects of CCM, including
graphic descriptions of mental distress and illness.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {341},
numpages = {14}
}

@inbook{10.1145/3411764.3445757,
author = {Griggio, Carla F. and Sato, Arissa J. and Mackay, Wendy E. and Yatani, Koji},
title = {Mediating Intimacy with DearBoard: A Co-Customizable Keyboard for Everyday Messaging},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445757},
abstract = { Co-customizations are collaborative customizations in messaging apps that all conversation
members can view and change, e.g. the color of chat bubbles on Facebook Messenger.
Co-customizations grant new opportunities for expressing intimacy; however, most apps
offer private customizations only. To investigate how people in close relationships
integrate co-customizations into their established communication app ecosystems, we
built DearBoard: an Android keyboard that allows two people to co-customize its color
theme and a toolbar of expression shortcuts (emojis and GIFs). In a 5-week field study
with 18 pairs of couples, friends, and relatives, participants expressed their shared
interests, history, and knowledge of each other through co-customizations that served
as meaningful decorations, interface optimizations, conversation themes, and non-verbal
channels for playful, affectionate interactions. The co-ownership of the co-customizations
invited participants to negotiate who customizes what and for whom they customize.
We discuss how co-customizations mediate intimacy through place-making efforts and
suggest design opportunities.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {342},
numpages = {16}
}

@inbook{10.1145/3411764.3445118,
author = {Warner, Mark and Lascau, Laura and Cox, Anna L and Brumby, Duncan P and Blandford, Ann},
title = {“Oops...”: Mobile Message Deletion in Conversation Error and Regret Remediation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445118},
abstract = { Message deletion in mobile messaging apps allows people to “unsay” things they have
said. This paper explores how and why people use (or do not use) this feature within
remediation strategies after a communication error is identified. We present findings
from a multi-stage survey designed to explore people’s general experiences of the
message deletion feature (N = 401), peoples’ experiences of using this feature during
the remediation of an error (N = 70), and receivers’ perceptions around recent message
deletions (N = 68). While people are typically aware of the deletion feature, it is
infrequently used. When used, it is primarily done so to improve conversations by
reducing confusion between conversation partners. We found people being aware of message
deletions creating information-gaps which can provoke curiosity in recipients, causing
them to develop narratives to help address the uncertainty. We found concerns amongst
senders that these narratives would be of a negative nature, having an undesirable
impact on how others perceive them. We use our findings to suggest ways in which mobile
messaging apps could improve conversational experiences around erroneous and regrettable
messages. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {343},
numpages = {13}
}

@inbook{10.1145/3411764.3445534,
author = {Clarke, Loraine and Hornecker, Eva and Ruthven, Ian},
title = {Fighting Fires and Powering Steam Locomotives: Distribution of Control and Its Role in Social Interaction at Tangible Interactive Museum Exhibits},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445534},
abstract = { We present a video-analysis study of museum visitors’ interactions at two tangible
interactive exhibits in a transport museum. Our focus is on groups’ social and shared
interactions, in particular how exhibit setup and structure influence collaboration
patterns. Behaviors at the exhibits included individuals focusing beyond their personal
activity towards companions’ interaction, adults participating via physical interaction,
and visitors taking opportunities to interact when companions moved between sections
of the exhibit or stepped back from interaction. We demonstrate how exhibits’ physical
configuration and interactive control engendered behavioral patterns. Systematic analysis
reveals how different configurations (concerning physical-spatial hardware and interactive
software) distribute control differently amongst visitors. We present four mechanisms
for how control can be distributed at an interactive installation: functional, temporal,
physical and indirect verbal. In summary, our work explores how mechanisms that distribute
control influence patterns of shared interaction with the exhibits and social interaction
between museum visitor companions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {344},
numpages = {17}
}

@inbook{10.1145/3411764.3445715,
author = {Lee, Kung Jin and Roldan, Wendy and Zhu, Tian Qi and Kaur Saluja, Harkiran and Na, Sungmin and Chin, Britnie and Zeng, Yilin and Lee, Jin Ha and Yip, Jason},
title = {The Show Must Go On: A Conceptual Model of Conducting Synchronous Participatory Design With Children Online},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445715},
abstract = {Co-designing with children in an online environment is increasingly important due
to external factors, such as the COVID-19 pandemic, and the diversification and inclusion
of youth participants. Many prior studies about co-design with youth focus on co-located
or asynchronous online sessions. However, conducting synchronous online co-design
sessions adds layers of complexity and uncertainty to collaboration. This paper introduces
a model explicating factors to consider when co-designing with children synchronously
in an online space. We examined ten consecutive intergenerational participatory design
sessions online where children (ages 7-11) and adults designed new technologies. Along
with highlighting unexpected moments and interactions, we use theories of improvisation
to guide our understanding of dynamic situations that are out of the control of researchers.
This work contributes to improving theoretical understanding of improvisation as a
method of inquiry for co-designing with youth, and offers practical suggestions for
suitable online co-design techniques and implementation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {345},
numpages = {16}
}

@inbook{10.1145/3411764.3445436,
author = {Gong, Jiangtao and Yao, Zheng and Lu, Zhicong and Ding, Qicheng and zhang, yu and Zhang, Liuxin and Wang, Qianying},
title = {All in One Group: Current Practices, Lessons and Challenges of Chinese Home-School Communication in IM Group Chat},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445436},
abstract = { When schools and families form a good partnership, children benefit. With the recent
flourishing of communication apps, families and schools in China have shifted their
primary communication channels to chat groups hosted on popular instant-messenger(IM)
tools such as WeChat and QQ. With an interview study consisting of 18 parents and
9 teachers, followed by a survey study with 210 teachers, we found that IM group chat
has become the most popular way that the majority of parents and teachers communicate,
from among the many different channels available. While there are definite advantages
to this kind of group chat, we also found a number of problematic issues, including
a lack of privacy and repeated negative feedback shared by both parents and teachers.
We discuss our results on how IM-based group chat could affect Chinese teachers’ authoritative
figures, affect Chinese teacher’s work-life balance and potentially compromise Chinese
students’ privacy.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {346},
numpages = {12}
}

@inbook{10.1145/3411764.3445044,
author = {Cumbo, Bronwyn J. and Bartindale, Tom and Richardson, Dan},
title = {Exploring the Opportunities for Online Learning Platforms to Support the Emergency Home School Context},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445044},
abstract = {The COVID-19 pandemic and subsequent closure of schools forced families across the
globe to transition to school at home. This unprecedented context is likely to have
a lasting impact on the practice of schooling and the role of online, digital platforms
within school contexts. In this paper we present a contextual inquiry of an ‘emergency
home school context’, detailing how nine young families in Melbourne, Australia adapted
to the unexpected introduction of school to the home following the government-directed
closure of schools. Through an online interview and photo-journal study, we develop
an emplaced understanding of the context detailing how the relations between people
and places around the home evolved over time. We present five design considerations
for digital platforms to support the emergency home school context, placing focus
on the fluid roles, relationships and evolving sense of place. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {347},
numpages = {11}
}

@inbook{10.1145/3411764.3445428,
author = {Chen, Zhilong and Cao, Hancheng and Deng, Yuting and Gao, Xuan and Piao, Jinghua and Xu, Fengli and Zhang, Yu and Li, Yong},
title = {Learning from Home: A Mixed-Methods Analysis of Live Streaming Based Remote Education Experience in Chinese Colleges during the COVID-19 Pandemic},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445428},
abstract = { The COVID-19 global pandemic and resulted lockdown policies have forced education
in nearly every country to switch from a traditional co-located paradigm to a pure
online “distance learning from home” paradigm. Lying in the center of this learning
paradigm shift is the emergence and wide adoption of distance communication tools
and live streaming platforms for education. Here, we present a mixed-methods study
on live streaming based education experience during the COVID-19 pandemic. We focus
our analysis on Chinese higher education, carried out semi-structured interviews on
30 students, and 7 instructors from diverse colleges and disciplines, meanwhile launched
a large-scale survey covering 6291 students and 1160 instructors in one leading Chinese
university. Our study not only reveals important design guidelines and insights to
better support current remote learning experience during the pandemic, but also provides
valuable implications towards constructing future collaborative education supporting
systems and experience after pandemic.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {348},
numpages = {16}
}

@inbook{10.1145/3411764.3445429,
author = {Kalinowski, Robert D and Xu, Ying and Salen, Katie},
title = {The Ecological Context of Preschool-Aged Children’s Selection of Media Content},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445429},
abstract = { Today, preschool-aged children have an abundance of digital content to choose from,
with some more desirable than others from a developmental perspective. We aim to describe
and better understand the interplay of factors that influence children’s selection
of media content using a year-long, multi-case ethnography of 13 diverse families
in Southern California. We found that young children’s media content selection may
be best understood as an ecologically situated process involving the interplay between
the content, the child, their family, community, and societal spheres. Children do
not make media selections on their own. Rather, these choices are supported or constrained
by a range of resource, culture, and policy factors specific to family and community
background. We argue that policy makers and technology designers are better served
by an ecological perspective if they wish to understand how digital content is selected
and used by children in sociocultural context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {349},
numpages = {14}
}

@inbook{10.1145/3411764.3445450,
author = {Benabdallah, Gabrielle and Bourgault, Sam and Peek, Nadya and Jacobs, Jennifer},
title = {Remote Learners, Home Makers: How Digital Fabrication Was Taught Online During a Pandemic},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445450},
abstract = {Digital fabrication courses that relied on physical makerspaces were severely disrupted
by COVID-19. As universities shut down in Spring 2020, instructors developed new models
for digital fabrication at a distance. Through interviews with faculty and students
and examination of course materials, we recount the experiences of eight remote digital
fabrication courses. We found that learning with hobbyist equipment and online social
networks could emulate using industrial equipment in shared workshops. Furthermore,
at-home digital fabrication offered unique learning opportunities including more iteration,
machine tuning, and maintenance. These opportunities depended on new forms of labor
and varied based on student living situations. Our findings have implications for
remote and in-person digital fabrication instruction. They indicate how access to
tools was important, but not as critical as providing opportunities for iteration;
they show how remote fabrication exacerbated student inequities; and they suggest
strategies for evaluating trade-offs in remote fabrication models with respect to
learning objectives. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {350},
numpages = {14}
}

@inbook{10.1145/3411764.3445240,
author = {Yarmand, Matin and Solyst, Jaemarie and Klemmer, Scott and Weibel, Nadir},
title = {“It Feels Like I Am Talking into a Void”: Understanding Interaction Gaps in Synchronous Online Classrooms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445240},
abstract = { This paper investigates in-class interactions in synchronous online classrooms when
the choice of modality is discretionary, such that students choose when and if they
turn on their cameras and microphones. Instructor interviews (N = 7) revealed that
most students preferred not to share videos and verbally participate. This hindered
instructors’ ability to read their classrooms and make deeper connections with students.
Survey results (N = 102) suggested that students felt a lacking sense of community
in online vs. in-person lectures. Some students felt uncomfortable broadcasting their
appearances to everyone in the class, and some were unaware of the benefits for instructors.
Most students favored using the text chat to participate. Considering the needs of
both instructors and students, we propose recommendations to mitigate the loss of
classroom interactions by collecting and presenting less invasive social cues in an
aggregated format, and incorporating opportunities for informal exchanges and individual
control to spark peer bonding.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {351},
numpages = {9}
}

@inbook{10.1145/3411764.3445541,
author = {Pitt, Caroline and Hock, Ari and Zelnick, Leila and Davis, Katie},
title = {The Kids Are / Not / Sort of All Right*},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445541},
abstract = {We investigated changes in and factors affecting American adolescents’ subjective
wellbeing during the early months (April – August 2020) of the coronavirus pandemic
in the United States. Twenty-one teens (14-19 years) participated in interviews at
the start and end of the study and completed ecological momentary assessments three
times per week between the interviews. There was an aggregate trend toward increased
wellbeing, with considerable variation within and across participants. Teens reported
greater reliance on networked technologies as their unstructured time increased during
lockdown. Using multilevel growth modeling, we found that how much total time teens
spent with technology had less bearing on daily fluctuations in wellbeing than the
satisfaction and meaning they derived from their technology use. Ultimately, teens
felt online communication could not replace face-to-face interactions. We conducted
two follow-up participatory design sessions with nine teens to explore these insights
in greater depth and reflect on general implications for design to support teens’
meaningful technology experiences and wellbeing during disruptive life events.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {352},
numpages = {14}
}

@inbook{10.1145/3411764.3445275,
author = {K. Chua, Phoebe and Mazmanian, Melissa},
title = {What Are You Doing With Your Phone? How Social Class Frames Parent-Teen Tensions around Teens’ Smartphone Use},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445275},
abstract = {Social class contexts shape parents’ guiding principles around teens’ smartphone use.
These contexts can affect how parents coach and censor their teens’ smartphone use
and can create tensions in the home. Through 174 interviews (87 parent-teen dyads),
we find that upper-middle-class families generally adopt an orientation toward scaffolded
achievements and working-class families tend to embrace an orientation toward empowered
self-sufficiency. We further find that these class-based orientations contribute to
parent-teen tensions. For upper-middle-class families, tensions arise when parents
insist that teens should use smartphones to get help with academic and enrichment
activities and teens disagree about whether their phone-related activities align with
this goal. In contrast, we find that conflict can occur in working-class families
when teens use their smartphones to get assistance and parents interpret such activity
as teens being lazy or not self-sufficient. These findings highlight the role of social
class contexts in shaping families’ orientations toward teens’ smartphone use and
phone-related tensions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {353},
numpages = {12}
}

@inbook{10.1145/3411764.3445635,
author = {Pitt, Caroline and Bell, Adam and S. Boyd, Brandyn and Demmel, Nikki and Davis, Katie},
title = {Connected Learning, Collapsed Contexts: Examining Teens’ Sociotechnical Ecosystems Through the Lens of Digital Badges},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445635},
abstract = {Researchers and designers have incorporated social media affordances into learning
technologies to engage young people and support personally relevant learning, but
youth may reject these attempts because they do not meet user expectations. Through
in-depth case studies, we explore the sociotechnical ecosystems of six teens (ages
15-18) working at a science center that had recently introduced a digital badge system
to track and recognize their learning. By analyzing interviews, observations, ecological
momentary assessments, and system data, we examined tensions in how badges as connected
learning technologies operate in teens' sociotechnical ecosystems. We found that,
due to issues of unwanted context collapse and incongruent identity representations,
youth only used certain affordances of the system and did so sporadically. Additionally,
we noted that some features seemed to prioritize values of adult stakeholders over
youth. Using badges as a lens, we reveal critical tensions and offer design recommendations
for networked learning technologies.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {354},
numpages = {14}
}

@inbook{10.1145/3411764.3445222,
author = {Lee, Yoonjoo and Chung, John Joon Young and Song, Jean Y. and Chang, Minsuk and Kim, Juho},
title = {Personalizing Ambience and Illusionary Presence: How People Use “Study with Me” Videos to Create Effective Studying Environments},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445222},
abstract = {“Study with me” videos contain footage of people studying for hours, in which social
components like conversations or informational content like instructions are absent.
Recently, they became increasingly popular on video-sharing platforms. This paper
provides the first broad look into what “study with me” videos are and how people
use them. We analyzed 30 “study with me” videos and conducted 12 interviews with their
viewers to understand their motivation and viewing practices. We identified a three-factor
model that explains the mechanism for shaping a satisfactory studying experience in
general. One of the factors, a well-suited ambience, was difficult to achieve because
of two common challenges: external conditions that prevent studying in study-friendly
places and extra cost needed to create a personally desired ambience. We found that
the viewers used “study with me” videos to create a personalized ambience at a lower
cost, to find controllable peer pressure, and to get emotional support. These findings
suggest that the viewers self-regulate their learning through watching “study with
me” videos to improve efficiency even when studying alone at home. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {355},
numpages = {13}
}

@inbook{10.1145/3411764.3445239,
author = {Potapov, Kyrill and Vasalou, Asimina and Lee, Victor and Marshall, Paul},
title = {What Do Teens Make of Personal Informatics? Young People's Responses to Self-Tracking Practices for Self-Determined Motives},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445239},
abstract = {Personal informatics (PI) technologies allow users to collect data about aspects of
their lifestyle like mood or step count. Though teens increasingly encounter and use
such technologies, little is known about how they ascribe meaning to their own PI
activities. We report a qualitative study of the PI experiences of eighteen teens
(aged 14 – 17). Following a learning phase focused on interpreting PI data, participants
chose a personal goal that interested them and a PI tool to track it for 4-8 weeks
in everyday contexts. Participants proved to be competent, flexible users of PI tools,
tracking a range of meaningful life factors, from ‘worries’ to ‘exercise’; they valued
learning about ‘natural patterns’ in their lives and were motivated to manage their
emotions and evaluate whether they were doing the right thing. Our findings contribute
to understanding how young people can engage in appropriation and interpretation of
PI data – suggesting opportunities for educational interventions and design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {356},
numpages = {10}
}

@inbook{10.1145/3411764.3445282,
author = {Iivari, Netta and Vent\"{a}-Olkkonen, Leena and Sharma, Sumita and Molin-Juustila, Tonja and Kinnunen, Essi},
title = {CHI Against Bullying: Taking Stock of the Past and Envisioning the Future},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445282},
abstract = {Bullying is a challenge concerning us all, and particularly our children. This has
already been acknowledged by CHI, among others. Despite the interest, there is a lack
of comprehensive understanding of the state of the art – a critical review is needed,
addressing bullying in the lives of children, in the context of and/or by the means
of design and technology, covering CHI as well as related computing fields, being
inspired by the strong body of knowledge within human sciences. We report on a comprehensive
literature review on the topic, with the aim to understand what and how has been done
so far to handle this troublesome and widespread phenomenon as well as to indicate
how to move the field forward. We report how the topic has been examined and with
what kind of means tackled, revealing interesting underlying assumptions about design,
technology and human agency.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {357},
numpages = {17}
}

@inbook{10.1145/3411764.3445680,
author = {Fan, Mingming and Zhao, Qiwen and Tibdewal, Vinita},
title = {Older Adults’ Think-Aloud Verbalizations and Speech Features for Identifying User Experience Problems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445680},
abstract = {Subtle patterns in users’ think-aloud (TA) verbalizations and speech features are
shown to be telltale signs of User Experience (UX) problems. However, such patterns
were uncovered among young adults. Whether such patterns apply for older adults remains
unknown. We conducted TA usability testing with older adults using physical and digital
products. We analyzed their verbalizations, extracted speech features, identified
UX problems, and uncovered the patterns that indicate UX problems. Our results show
that when older adults encounter problems, their verbalizations tend to include observations
(remarks), negations, question words and words with negative sentiments; and their
voices tend to include high loudness, high pitch and high speech rate. We compare
these subtle patterns with those of young adults uncovered in recent studies and discuss
the implications of these patterns for the design of Human-AI collaborative UX analysis
tools to better pinpoint UX problems. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {358},
numpages = {13}
}

@inbook{10.1145/3411764.3445758,
author = {Ali, Abdullah and Ringel Morris, Meredith and O. Wobbrock, Jacob},
title = {“I Am Iron Man”: Priming Improves the Learnability and Memorability of User-Elicited Gestures},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445758},
abstract = {Priming is used as a way of increasing the diversity of proposals in end-user elicitation
studies, but priming has not been investigated thoroughly in this context. We conduct
a distributed end-user elicitation study with 167 participants, which had three priming
groups: a no-priming control group, sci-fi priming, and a creative mindset group.
We evaluated the gestures proposed by these groups in a distributed learnability and
memorability study with 18 participants. We found that the user-elicited gestures
from the sci-fi group were significantly faster to learn, requiring an average of
1.22 viewings to learn compared to 1.60 viewings required to learn the control gestures,
and 1.56 viewings to learn the gestures elicited from the creative mindset group.
In addition, both primed gesture groups had higher memorability with 80% of the sci-fi-primed
gestures and 73% of the creative mindset group gestures were recalled correctly after
one week without practice compared to 43% of the control group gestures.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {359},
numpages = {14}
}

@inbook{10.1145/3411764.3445610,
author = {Mathur, Arunesh and Kshirsagar, Mihir and Mayer, Jonathan},
title = {What Makes a Dark Pattern... Dark? Design Attributes, Normative Considerations, and Measurement Methods},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445610},
abstract = {There is a rapidly growing literature on dark patterns, user interface designs—typically
related to shopping or privacy—that researchers deem problematic. Recent work has
been predominantly descriptive, documenting and categorizing objectionable user interfaces.
These contributions have been invaluable in highlighting specific designs for researchers
and policymakers. But the current literature lacks a conceptual foundation: What makes
a user interface a dark pattern? Why are certain designs problematic for users or
society? We review recent work on dark patterns and demonstrate that the literature
does not reflect a singular concern or consistent definition, but rather, a set of
thematically related considerations. Drawing from scholarship in psychology, economics,
ethics, philosophy, and law, we articulate a set of normative perspectives for analyzing
dark patterns and their effects on individuals and society. We then show how future
research on dark patterns can go beyond subjective criticism of user interface designs
and apply empirical methods grounded in normative perspectives. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {360},
numpages = {18}
}

@inbook{10.1145/3411764.3445459,
author = {Zeng, Eric and Kohno, Tadayoshi and Roesner, Franziska},
title = {What Makes a “Bad” Ad? User Perceptions of Problematic Online Advertising},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445459},
abstract = { Online display advertising on websites is widely disliked by users, with many turning
to ad blockers to avoid “bad” ads. Recent evidence suggests that today’s ads contain
potentially problematic content, in addition to well-studied concerns about the privacy
and intrusiveness of ads. However, we lack knowledge of which types of ad content
users consider problematic and detrimental to their browsing experience. Our work
bridges this gap: first, we create a taxonomy of 15 positive and negative user reactions
to online advertising from a survey of 60 participants. Second, we characterize classes
of online ad content that users dislike or find problematic, using a dataset of 500
ads crawled from popular websites, labeled by 1000 participants using our taxonomy.
Among our findings, we report that users consider a substantial amount of ads on the
web today to be clickbait, untrustworthy, or distasteful, including ads for software
downloads, listicles, and health &amp; supplements. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {361},
numpages = {24}
}

@inbook{10.1145/3411764.3445519,
author = {Baughan, Amanda and Oliveira, Nigini and August, Tal and Yamashita, Naomi and Reinecke, Katharina},
title = {Do Cross-Cultural Differences in Visual Attention Patterns Affect Search Efficiency on Websites?},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445519},
abstract = {Prior work in cross-cultural psychology and neuroscience has shown robust variations
in visual attention patterns. People from East Asian societies, in which a holistic
thinking style predominates, have been found to attend to contextual information in
scenes more than Westerners, whose tendency to think analytically expresses itself
in greater attention to foreground objects. This paper applies these findings to website
design, using an online study to evaluate whether Japanese (N=65) remember more and
are faster at finding contextual website information than US Americans (N=84). Our
results do not support this hypothesis. Instead, Japanese overall took significantly
longer to find information than US participants—a difference that was exacerbated
by an increase in website complexity—suggesting that Japanese may holistically take
in a website before engaging with detailed information. We discuss implications of
these findings for website design and cross-cultural research. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {362},
numpages = {12}
}

@inbook{10.1145/3411764.3445560,
author = {M\"{u}ller, Leon and Pfeuffer, Ken and Gugenheimer, Jan and Pfleging, Bastian and Prange, Sarah and Alt, Florian},
title = {SpatialProto: Exploring Real-World Motion Captures for Rapid Prototyping of Interactive Mixed Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445560},
abstract = { Spatial computing devices that blend virtual and real worlds have the potential to
soon become ubiquitous. Yet, creating experiences for spatial computing is non-trivial
and needs skills in programming and 3D content creation, rendering them inaccessible
to a wider group of users. We present SpatialProto, an in-situ spatial prototyping
system for lowering the barrier to engage in spatial prototyping. With a depth-sensing
capable mixed reality headset, SpatialProto lets users record animated objects of
the real-world environment (e.g. paper, clay, people, or any other prop), extract
only the relevant parts, and directly place and transform these recordings in their
physical environment. We describe the design and implementation of SpatialProto, a
user study evaluating the system’s prototype with non-expert users (n = 9), and demonstrate
applications where multiple captures are fused for compelling augmented reality experiences.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {363},
numpages = {13}
}

@inbook{10.1145/3411764.3445096,
author = {Mishra, Swati and Rzeszotarski, Jeffrey M},
title = {Designing Interactive Transfer Learning Tools for ML Non-Experts},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445096},
abstract = {Interactive machine learning (iML) tools help to make ML accessible to users with
limited ML expertise. However, gathering necessary training data and expertise for
model-building remains challenging. Transfer learning, a process where learned representations
from a model trained on potentially terabytes of data can be transferred to a new,
related task, offers the possibility of providing ”building blocks” for non-expert
users to quickly and effectively apply ML in their work. However, transfer learning
largely remains an expert tool due to its high complexity. In this paper, we design
a prototype to understand non-expert user behavior in an interactive environment that
supports transfer learning. Our findings reveal a series of data- and perception-driven
decision-making strategies non-expert users employ, to (in)effectively transfer elements
using their domain expertise. Finally, we synthesize design implications which might
inform future interactive transfer learning environments. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {364},
numpages = {15}
}

@inbook{10.1145/3411764.3445639,
author = {Gulay, Emrecan and Kotnik, Toni and Lucero, Andr\'{e}s},
title = {Exploring a Feedback-Oriented Design Process Through Curved Folding},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445639},
abstract = { The advancement of computational design and fabrication technologies has allowed
combining physical and digital processes in architecture. Existing methods for physical-digital
integration offer limited support for explorations with folded non-linear surfaces.
This paper introduces a feedback-oriented design approach linking physical models
with digital tools to enhance ideation processes in architecture. We employ paper
as a medium for translating simple mock-up ideas to more elaborate digital design
models. We explain the physical exploration, 3D scanning, digital simulation, and
fabrication processes. Then, we discuss the results, observations, and limitations
of this design approach.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {365},
numpages = {8}
}

@inbook{10.1145/3411764.3445673,
author = {Bentvelzen, Marit and Niess, Jasmin and Wo\'{z}niak, Miko\l{}aj P. and Wo\'{z}niak, Pawe\l{} W.},
title = {The Development and Validation of the Technology-Supported Reflection Inventory},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445673},
abstract = { Reflection is an often addressed design goal in Human-Computer Interaction (HCI)
research. An increasing number of artefacts for reflection have been developed in
recent years. However, evaluating if and how an interactive technology helps a user
reflect is still complex. This makes it difficult to compare artefacts (or prototypes)
for reflection, impeding future design efforts. To address this issue, we developed
the Technology-Supported Reflection Inventory (TSRI), which is a scale that evaluates
how effectively a system supports reflection. We first created a list of possible
scale items based on past work in defining reflection. The items were then reviewed
by experts. Next, we performed exploratory factor analysis to reduce the scale to
its final length of nine items. Subsequently, we confirmed test-retest validity of
our instrument, as well as its construct validity. The TSRI enables researchers and
practitioners to compare prototypes designed to support reflection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {366},
numpages = {8}
}

@inbook{10.1145/3411764.3445112,
author = {Karyda, Maria and Mekler, Elisa D and Lucero, Andr\'{e}s},
title = {Data Agents: Promoting Reflection through Meaningful Representations of Personal Data in Everyday Life},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445112},
abstract = { Visual and physical representations of historical personal data have been discussed
as artifacts that can lead to self-reflection through meaning-making. However, it
is yet unclear how those two concepts relate to each other. We focus on meaningfulness,
a part of meaning-making that relates to feelings. In this paper, we present three
projects where mundane objects, our data agents, are combined in meaningful ways with
personal data with the aim to trigger reflection by placing a person’s individual
experience of data in relation to others’. To identify relationships between self-reflection
and meaningfulness we use Fleck and Fitzpatrick’s framework to describe the levels
of reflection that we found in our projects and Mekler and Hornb\ae{}k’s meaning framework
to define the depth of reflection. We conclude with a discussion on four themes in
which we outline how data agents informed the intersections between our central concepts.
This paper, constitutes a first step towards unpacking those relationships and invites
for further explorations by the HCI community.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {367},
numpages = {11}
}

@inbook{10.1145/3411764.3445467,
author = {Lukoff, Kai and Lyngs, Ulrik and Zade, Himanshu and Liao, J. Vera and Choi, James and Fan, Kaiyue and Munson, Sean A. and Hiniker, Alexis},
title = {How the Design of YouTube Influences User Sense of Agency},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445467},
abstract = { In the attention economy, video apps employ design mechanisms like autoplay that
exploit psychological vulnerabilities to maximize watch time. Consequently, many people
feel a lack of agency over their app use, which is linked to negative life effects
such as loss of sleep. Prior design research has innovated external mechanisms that
police multiple apps, such as lockout timers. In this work, we shift the focus to
how the internal mechanisms of an app can support user agency, taking the popular
YouTube mobile app as a test case. From a survey of 120 U.S. users, we find that autoplay
and recommendations primarily undermine sense of agency, while playlists and search
support it. From 13 co-design sessions, we find that when users have a specific intention
for how they want to use YouTube they prefer interfaces that support greater agency.
We discuss implications for how designers can help users reclaim a sense of agency
over their media use.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {368},
numpages = {17}
}

@inbook{10.1145/3411764.3445202,
author = {Inie, Nanna and Lungu, Mircea F},
title = {Aiki - Turning Online Procrastination into Microlearning},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445202},
abstract = { This paper presents and evaluates Aiki, a simple browser extension designed to redirect
a user to a learning platform for a fixed amount of time before accessing websites
defined as ’procrastination’ or ’time-wasting’ websites. The goal of the extension
is to enable the user to exchange time spent on pages they believe contribute less
to their own productivity for microlearning activities, defined as small or short-term
learning activities. The paper describes the design and development of Aiki and evaluates
the extension with a group of n = 10 participants studying the Danish language. Based
on a two-week study, we conclude that this type of extension, even in its preliminary
version, has the potential to improve language skills in a lightweight manner and
that redirection is an important alternative to blocking for procrastination management.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {369},
numpages = {13}
}

@inbook{10.1145/3411764.3445159,
author = {Hoggenm\"{u}ller, Marius and Tomitsch, Martin and Hespanhol, Luke and Tran, Tram Thi Minh and Worrall, Stewart and Nebot, Eduardo},
title = {Context-Based Interface Prototyping: Understanding the Effect of Prototype Representation on User Feedback},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445159},
abstract = { The rise of autonomous systems in cities, such as automated vehicles (AVs), requires
new approaches for prototyping and evaluating how people interact with those systems
through context-based user interfaces, such as external human-machine interfaces (eHMIs).
In this paper, we present a comparative study of three prototype representations (real-world
VR, computer-generated VR, real-world video) of an eHMI in a mixed-methods study with
42 participants. Quantitative results show that while the real-world VR representation
results in higher sense of presence, no significant differences in user experience
and trust towards the AV itself were found. However, interview data shows that participants
focused on different experiential and perceptual aspects in each of the prototype
representations. These differences are linked to spatial awareness and perceived realism
of the AV behaviour and its context, affecting in turn how participants assess trust
and the eHMI. The paper offers guidelines for prototyping and evaluating context-based
interfaces through simulations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {370},
numpages = {14}
}

@inbook{10.1145/3411764.3445412,
author = {Mack, Kelly and McDonnell, Emma and Jain, Dhruv and Lu Wang, Lucy and E. Froehlich, Jon and Findlater, Leah},
title = {What Do We Mean by “Accessibility Research”? A Literature Survey of Accessibility Papers in CHI and ASSETS from 1994 to 2019},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445412},
abstract = {Accessibility research has grown substantially in the past few decades, yet there
has been no literature review of the field. To understand current and historical trends,
we created and analyzed a dataset of accessibility papers appearing at CHI and ASSETS
since ASSETS’ founding in 1994. We qualitatively coded areas of focus and methodological
decisions for the past 10 years (2010-2019, N=506 papers), and analyzed paper counts
and keywords over the full 26 years (N=836 papers). Our findings highlight areas that
have received disproportionate attention and those that are underserved—for example,
over 43% of papers in the past 10 years are on accessibility for blind and low vision
people. We also capture common study characteristics, such as the roles of disabled
and nondisabled participants as well as sample sizes (e.g., a median of 13 for participant
groups with disabilities and older adults). We close by critically reflecting on gaps
in the literature and offering guidance for future work in the field.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {371},
numpages = {18}
}

@inbook{10.1145/3411764.3445321,
author = {Li, Franklin Mingzhe and Chen, Di Laura and Fan, Mingming and Truong, Khai N.},
title = {“I Choose Assistive Devices That Save My Face”: A Study on Perceptions of Accessibility and Assistive Technology Use Conducted in China},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445321},
abstract = { Despite the potential benefits of assistive technologies (ATs) for people with various
disabilities, only around 7% of Chinese with disabilities have had an opportunity
to use ATs. Even for those who have used ATs, the abandonment rate was high. Although
China has the world’s largest population with disabilities, prior research exploring
how ATs are used and perceived, and why ATs are abandoned have been conducted primarily
in North America and Europe. In this paper, we present an interview study conducted
in China with 26 people with various disabilities to understand their practices, challenges,
perceptions, and misperceptions of using ATs. From the study, we learned about factors
that influence AT adoption practices (e.g., misuse of accessible infrastructure, issues
with replicating existing commercial ATs), challenges using ATs in social interactions
(e.g., Chinese stigma), and misperceptions about ATs (e.g., ATs should overcome inaccessible
social infrastructures). Informed by the findings, we derive a set of design considerations
to bridge the existing gaps in AT design (e.g., manual vs. electronic ATs) and to
improve ATs’ social acceptability in China.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {372},
numpages = {14}
}

@inbook{10.1145/3411764.3445150,
author = {Venkatasubramanian, Krishna and Skorinko, Jeanine L. M. and Kobeissi, Mariam and Lewis, Brittany and Jutras, Nicole and Bosma, Pauline and Mullaly, John and Kelly, Brian and Lloyd, Deborah and Freark, Mariah and Alterio, Nancy A.},
title = {Exploring A Reporting Tool to Empower Individuals with Intellectual and Developmental Disabilities to Self-Report Abuse},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445150},
abstract = { In the US, abuse of individuals with intellectual and developmental disabilities
(I/DD) is at epidemic proportions. Further, abuse incidents of individuals with I/DD
are woefully under-reported. We surveyed practitioners who help individuals with I/DD
post-abuse to get a broader context on the problem. We found that abuse of individuals
with I/DD was often reported by someone other than the survivor, as survivors faced
impediments in reporting. Consequently, we argue for developing a mobile-computing-based
reporting tool for empowering individuals with I/DD to self-report abuse. Next, we
conducted focus groups of individuals with I/DD to evaluate the tool’s viability,
with respect to their ability to recognize/report abuse and use mobile-computing devices.
We found individuals with I/DD could recognize/report abuse well when they received
appropriate training. We also found individuals with I/DD could independently use
their devices, though they shared access to them with family. Based on these findings,
we call for several lines of accessibility research in designing an abuse self-reporting
tool for individuals with I/DD.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {373},
numpages = {13}
}

@inbook{10.1145/3411764.3445756,
author = {Dai, Jiamin and Moffatt, Karyn},
title = {Surfacing the Voices of People with Dementia: Strategies for Effective Inclusion of Proxy Stakeholders in Qualitative Research},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445756},
abstract = {Best practices for conducting HCI research on dementia care increasingly involve multiple
stakeholders and incorporate diverse viewpoints. When done effectively, involving
proxy stakeholders such as family members and professionals can help bring forward
the voices of people with dementia. However, concrete practical guidance for navigating
the challenges of integrating different perspectives is lacking. We critically reflect
on our own recent qualitative fieldwork involving participants with dementia, family
caregivers, and facilitators at a local social program for people with dementia, re-examining
our interview transcripts and observation notes through content analysis. We illustrate
practical approaches to prioritizing participants’ voices through concrete excerpts
that demonstrate strategies for better managing dynamics, intervening effectively,
and engaging all stakeholders in the research process. Our reflections and proposed
guidelines can benefit HCI researchers and practitioners working with vulnerable populations.
We hope this work will spur further discussion and critique to strengthen and improve
research practices in this domain. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {374},
numpages = {13}
}

@inbook{10.1145/3411764.3445498,
author = {Bennett, Cynthia L. and Gleason, Cole and Scheuerman, Morgan Klaus and Bigham, Jeffrey P. and Guo, Anhong and To, Alexandra},
title = {“It’s Complicated”: Negotiating Accessibility and (Mis)Representation in Image Descriptions of Race, Gender, and Disability},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445498},
abstract = { Content creators are instructed to write textual descriptions of visual content to
make it accessible; yet existing guidelines lack specifics on how to write about people’s
appearance, particularly while remaining mindful of consequences of (mis)representation.
In this paper, we report on interviews with screen reader users who were also Black,
Indigenous, People of Color, Non-binary, and/or Transgender on their current image
description practices and preferences, and experiences negotiating theirs and others’
appearances non-visually. We discuss these perspectives, and the ethics of humans
and AI describing appearance characteristics that may convey the race, gender, and
disabilities of those photographed. In turn, we share considerations for more carefully
describing appearance, and contexts in which such information is perceived salient.
Finally, we offer tensions and questions for accessibility research to equitably consider
politics and ecosystems in which technologies will embed, such as potential risks
of human and AI biases amplifying through image descriptions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {375},
numpages = {19}
}

@inbook{10.1145/3411764.3445277,
author = {Shinohara, Kristen and McQuaid, Mick and Jacobo, Nayeri},
title = {The Burden of Survival: How Doctoral Students in Computing Bridge the Chasm of Inaccessibility},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445277},
abstract = { Despite efforts to support students with disabilities in higher education, few continue
to pursue doctoral degrees in computing. We conducted an interview study with 12 blind
and low vision, and 7 deaf and hard of hearing current and former doctoral students
in computing to understand how graduate students adjust to inaccessibility and ineffective
accommodations. We asked participants how they worked around inaccessibility, managed
ineffective accommodations, and advocated for tools and services. Employing a lens
of ableism in our analysis, we found that participants’ extra effort to address accessibility
gaps gave rise to a burden of survival, which they sustained to meet expectations
of graduate-level productivity. We recommend equitable solutions that acknowledge
taken-for-granted workarounds and that actively address inaccessibility in the graduate
school context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {376},
numpages = {13}
}

@inbook{10.1145/3411764.3445168,
author = {Kirabo, Lynn and Carter, Elizabeth Jeanne and Barry, Devon and Steinfeld, Aaron},
title = {Priorities, Technology, &amp; Power: Co-Designing an Inclusive Transit Agenda in Kampala, Uganda},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445168},
abstract = { There is considerable effort within the HCI community to explore, document, and advocate
for the lived experiences of persons with disabilities (PWDs). However, PWDs from
the Global South, particularly Africa, are underrepresented in this scholarship. We
contribute to closing this gap by investigating the unmet transit needs and characterization
of technology within the disability community in Kampala, Uganda. We investigated
transportation due to the increase in ride-share solutions created by widespread mobile
computing and the resulting disruption of transportation worldwide. We hosted co-design
sessions with disability advocates and adapted the stakeholder tokens method from
the value-sensitive design framework to map the stakeholder ecosystem. Our key insight
is the identification of a new group of non-traditional core stakeholders who highlight
the values of inclusion, mobility, and safety within the ecosystem. Finally, we discuss
how our findings engage with concepts of disability justice and perceptions of power.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {377},
numpages = {11}
}

@inbook{10.1145/3411764.3445620,
author = {Tigwell, Garreth W.},
title = {Nuanced Perspectives Toward Disability Simulations from Digital Designers, Blind, Low Vision, and Color Blind People},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445620},
abstract = { Designers of digital content have access to various resources that they use to help
them meet disabled people’s accessibility needs. Disability simulations are one resource,
but often criticized for failing to guide digital designers appropriately, and it
is unclear if digital designers are aware of the issues surrounding disability simulations.
I surveyed 92 digital designers to understand their perspectives toward disability
simulations (both perceived advantages and disadvantages). I then shared work process
challenges faced by digital designers and their reasons for using disability simulations
with 17 people with vision impairments to facilitate a discussion on this topic. The
interviewees discussed ideas that suggest many paths can be explored to connect digital
designers and disabled people, in general, to reduce reliance on simulations, and
a change is needed within workplace processes, culture, and staffing to further support
positive change. There are research opportunities to investigate establishing avenues
for connecting digital designers and disabled people in a way that is beneficial to
both groups.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {15}
}

@inbook{10.1145/3411764.3445070,
author = {Lewis, Brittany and Venkatasubramanian, Krishna},
title = {“I...Got My Nose-Print. But It Wasn’t Accurate”: How People with Upper Extremity Impairment Authenticate on Their Personal Computing Devices},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445070},
abstract = { Authentication has become increasingly ubiquitous for controlling access to personal
computing devices (e.g., laptops, tablets, and smartphones). In this paper, we aim
to understand the authentication process used by people with upper extremity impairment
(UEI). A person with UEI lacks range of motion, strength, endurance, speed, and/or
accuracy associated with arms, hands, or fingers. To this end, we conducted semi-structured
interviews with eight (8) adults with UEI about their use of authentication for their
personal computing devices. We found that our participants primarily use passwords
and PINs as a verification credential during authentication. We found the process
of authentication to have several accessibility issues for our participants. Consequently,
our participants implemented a variety of workarounds that prioritized usability over
security throughout the authentication process. Based on these findings, we present
six broad subareas of research that should be explored in order to create more accessible
authentication for people with UEI.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {379},
numpages = {14}
}

@inbook{10.1145/3411764.3445180,
author = {Sin, Jaisie and L. Franz, Rachel and Munteanu, Cosmin and Barbosa Neves, Barbara},
title = {Digital Design Marginalization: New Perspectives on Designing Inclusive Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445180},
abstract = {We conceptualize Digital Design Marginalization (DDM) as the process in which a digital
interface design excludes certain users and contributes to marginalization in other
areas of their lives. Due to non-inclusive designs, many underrepresented users face
barriers in accessing essential services that are moving increasingly, sometimes exclusively,
online – services such as personal finance, healthcare, social connectivity, and shopping.
This can further perpetuate the “digital divide,” a technology-based form of social
inequality that has offline consequences. We introduce the term Marginalizing Design
to describe designs that contribute to DDM. In this paper, we focus on the impact
of Marginalizing Design on older adults through examples from our research and discussions
of services that may have marginalizing designs for older adults. Our aim is to provide
a conceptual lens for designers, service providers, and policy makers through which
they can use to purposely lessen or avoid digitally marginalizing groups of users.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {380},
numpages = {11}
}

@inbook{10.1145/3411764.3445291,
author = {Uzor, Stephen and Jacques, Jason T. and Dudley, John J and Kristensson, Per Ola},
title = {Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445291},
abstract = { Crowdwork can enable invaluable opportunities for people with disabilities, not least
the work flexibility and the ability to work from home, especially during the current
Covid-19 pandemic. This paper investigates how engagement in crowdwork tasks is affected
by individual disabilities and the resulting implications for HCI. We first surveyed
1,000 Amazon Mechanical Turk (AMT) workers to identify demographics of crowdworkers
who identify as having various disabilities within the AMT ecosystem—including vision,
hearing, cognition/mental, mobility, reading and motor impairments. Through a second
focused survey and follow-up interviews, we provide insights into how respondents
cope with crowdwork tasks. We found that standard task factors, such as task completion
time and presentation, often do not account for the needs of users with disabilities,
resulting in anxiety and a feeling of depression on occasion. We discuss how to alleviate
barriers to enable effective interaction for crowdworkers with disabilities.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {381},
numpages = {14}
}

@inbook{10.1145/3411764.3445046,
author = {Prange, Alexander and Barz, Michael and Heimann-Steinert, Anika and Sonntag, Daniel},
title = {Explainable Automatic Evaluation of the Trail Making Test for Dementia Screening},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445046},
abstract = { The Trail Making Test (TMT) is a frequently used neuropsychological test for assessing
cognitive performance. The subject connects a sequence of numbered nodes by using
a pen on normal paper. We present an automatic cognitive assessment tool that analyzes
samples of the TMT which we record using a digital pen. This enables us to analyze
digital pen features that are difficult or impossible to evaluate manually. Our system
automatically measures several pen features, including the completion time which is
the main performance indicator used by clinicians to score the TMT in practice. In
addition, our system provides a structured report of the analysis of the test, for
example indicating missed or erroneously connected nodes, thereby offering more objective,
transparent and explainable results to the clinician. We evaluate our system with
40 elderly subjects from a geriatrics daycare clinic of a large hospital.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {382},
numpages = {9}
}

@inbook{10.1145/3411764.3445129,
author = {Guo, Jingya and Guo, Jiajing and Yang, Changyuan and Wu, Yanjing and Sun, Lingyun},
title = {Shing: A Conversational Agent to Alert Customers of Suspected Online-Payment Fraud with Empathetical Communication Skills},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445129},
abstract = {Alerting customers on suspected online-payment fraud and persuade them to terminate
transactions is increasingly requested with the rapid growth of digital finance worldwide.
We explored the feasibility of using a conversational agent (CA) to fulfill this request.
Shing, a voice-based CA, proactively initializes and repairs the conversation with
empathetical communication skills in order to alert customers when a suspected online-payment
fraud is detected, collects important information for fraud scrutiny and persuades
customers to terminate the transaction once the fraud is confirmed. We evaluated our
system by comparing it with a rule-based CA with regards to customer response and
perceptions in a real-world context where our systems took 144,795 phone calls in
total in which 83,019 (57.3%) natural breakdowns happened. Results showed that more
customers stopped risky transactions after conversing with Shing. They seemed more
willing to converse with Shing for more dialogue turns and provide transaction details.
Our work presents practical implications for the design of proactive CA.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {383},
numpages = {11}
}

@inbook{10.1145/3411764.3445645,
author = {Wang, Qiaosi and Saha, Koustuv and Gregori, Eric and Joyner, David and Goel, Ashok},
title = {Towards Mutual Theory of Mind in Human-AI Interaction: How Language Reflects What Students Perceive About a Virtual Teaching Assistant},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445645},
abstract = {Building conversational agents that can conduct natural and prolonged conversations
has been a major technical and design challenge, especially for community-facing conversational
agents. We posit Mutual Theory of Mind as a theoretical framework to design for natural
long-term human-AI interactions. From this perspective, we explore a community’s perception
of a question-answering conversational agent through self-reported surveys and computational
linguistic approach in the context of online education. We first examine long-term
temporal changes in students’ perception of Jill Watson (JW), a virtual teaching assistant
deployed in an online class discussion forum. We then explore the feasibility of inferring
students’ perceptions of JW through linguistic features extracted from student-JW
dialogues. We find that students’ perception of JW’s anthropomorphism and intelligence
changed significantly over time. Regression analyses reveal that linguistic verbosity,
readability, sentiment, diversity, and adaptability reflect student perception of
JW. We discuss implications for building adaptive community-facing conversational
agents as long-term companions and designing towards Mutual Theory of Mind in human-AI
interaction. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {384},
numpages = {14}
}

@inbook{10.1145/3411764.3445171,
author = {Zaheer, Nimra and Ahmad, Obaid Ullah and Ahmed, Ammar and Khan, Muhammad Shehryar and Shabbir, Mudassir},
title = {SEMOUR: A Scripted Emotional Speech Repository for Urdu},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445171},
abstract = {Designing reliable Speech Emotion Recognition systems is a complex task that inevitably
requires sufficient data for training purposes. Such extensive datasets are currently
available in only a few languages, including English, German, and Italian. In this
paper, we present SEMOUR, the first scripted database of emotion-tagged speech in
the Urdu language, to design an Urdu Speech Recognition System. Our gender-balanced
dataset contains 15,040 unique instances recorded by eight professional actors eliciting
a syntactically complex script. The dataset is phonetically balanced, and reliably
exhibits a varied set of emotions as marked by the high agreement scores among human
raters in experiments. We also provide various baseline speech emotion prediction
scores on the database, which could be used for various applications like personalized
robot assistants, diagnosis of psychological disorders, and getting feedback from
a low-tech-enabled population, etc. On a random test sample, our model correctly predicts
an emotion with a state-of-the-art 92% accuracy. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {385},
numpages = {12}
}

@inbook{10.1145/3411764.3445735,
author = {Hong, Matthew K. and Fourney, Adam and DeBellis, Derek and Amershi, Saleema},
title = {Planning for Natural Language Failures with the AI Playbook},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445735},
abstract = { Prototyping AI user experiences is challenging due in part to probabilistic AI models
making it difficult to anticipate, test, and mitigate AI failures before deployment.
In this work, we set out to support practitioners with early AI prototyping, with
a focus on natural language (NL)-based technologies. Our interviews with 12 NL practitioners
from a large technology company revealed that, in addition to challenges prototyping
AI, prototyping was often not happening at all or focused only on idealized scenarios
due to a lack of tools and tight timelines. These findings informed our design of
the AI Playbook, an interactive and low-cost tool we developed to encourage proactive
and systematic consideration of AI errors before deployment. Our evaluation of the
AI Playbook demonstrates its potential to 1) encourage product teams to prioritize
both ideal and failure scenarios, 2) standardize the articulation of AI failures from
a user experience perspective, and 3) act as a boundary object between user experience
designers, data scientists, and engineers. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {386},
numpages = {11}
}

@inbook{10.1145/3411764.3445281,
author = {AlOmar, Eman Abdullah and Aljedaani, Wajdi and Tamjeed, Murtaza and Mkaouer, Mohamed Wiem and El-Glaly, Yasmine N.},
title = {Finding the Needle in a Haystack: On the Automatic Identification of Accessibility User Reviews},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445281},
abstract = { In recent years, mobile accessibility has become an important trend with the goal
of allowing all users the possibility of using any app without many limitations. User
reviews include insights that are useful for app evolution. However, with the increase
in the amount of received reviews, manually analyzing them is tedious and time-consuming,
especially when searching for accessibility reviews. The goal of this paper is to
support the automated identification of accessibility in user reviews, to help technology
professionals in prioritizing their handling, and thus, creating more inclusive apps.
Particularly, we design a model that takes as input accessibility user reviews, learns
their keyword-based features, in order to make a binary decision, for a given review,
on whether it is about accessibility or not. The model is evaluated using a total
of 5,326 mobile app reviews. The findings show that (1) our model can accurately identify
accessibility reviews, outperforming two baselines, namely keyword-based detector
and a random classifier; (2) our model achieves an accuracy of 85% with relatively
small training dataset; however, the accuracy improves as we increase the size of
the training dataset.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {387},
numpages = {15}
}

@inbook{10.1145/3411764.3445423,
author = {Gordon, Mitchell L. and Zhou, Kaitlyn and Patel, Kayur and Hashimoto, Tatsunori and Bernstein, Michael S.},
title = {The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445423},
abstract = { Machine learning classifiers for human-facing tasks such as comment toxicity and
misinformation often score highly on metrics such as ROC AUC but are received poorly
in practice. Why this gap? Today, metrics such as ROC AUC, precision, and recall are
used to measure technical performance; however, human-computer interaction observes
that evaluation of human-facing systems should account for people’s reactions to the
system. In this paper, we introduce a transformation that more closely aligns machine
learning classification metrics with the values and methods of user-facing performance
measures. The disagreement deconvolution takes in any multi-annotator (e.g., crowdsourced)
dataset, disentangles stable opinions from noise by estimating intra-annotator consistency,
and compares each test set prediction to the individual stable opinions from each
annotator. Applying the disagreement deconvolution to existing social computing datasets,
we find that current metrics dramatically overstate the performance of many human-facing
machine learning tasks: for example, performance on a comment toxicity task is corrected
from .95 to .73 ROC AUC. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {14}
}

@inbook{10.1145/3411764.3445569,
author = {Han, Xu and Zhou, Michelle and Turner, Matthew J. and Yeh, Tom},
title = {Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445569},
abstract = {Recent studies show the effectiveness of interview chatbots for information elicitation.
However, designing an effective interview chatbot is non-trivial. Few tools exist
to help designers design, evaluate, and improve an interview chatbot iteratively.
Based on a formative study and literature reviews, we propose a computational framework
for quantifying the performance of interview chatbots. Incorporating the framework,
we have developed iChatProfile, an assistive chatbot design tool that can automatically
generate a profile of an interview chatbot with quantified performance metrics and
offer design suggestions for improving the chatbot based on such metrics. To validate
the effectiveness of iChatProfile, we designed and conducted a between-subject study
that compared the performance of 10 interview chatbots designed with or without using
iChatProfile. Based on the live chats between the 10 chatbots and 1349 users, our
results show that iChatProfile helped the designers build significantly more effective
interview chatbots, improving both interview quality and user experience.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {389},
numpages = {15}
}

@inbook{10.1145/3411764.3445308,
author = {Cheng, Hao-Fei and Stapleton, Logan and Wang, Ruiqi and Bullock, Paige and Chouldechova, Alexandra and Wu, Zhiwei Steven Steven and Zhu, Haiyi},
title = {Soliciting Stakeholders’ Fairness Notions in Child Maltreatment Predictive Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445308},
abstract = { Recent work in fair machine learning has proposed dozens of technical definitions
of algorithmic fairness and methods for enforcing these definitions. However, we still
lack an understanding of how to develop machine learning systems with fairness criteria
that reflect relevant stakeholders’ nuanced viewpoints in real-world contexts. To
address this gap, we propose a framework for eliciting stakeholders’ subjective fairness
notions. Combining a user interface that allows stakeholders to examine the data and
the algorithm’s predictions with an interview protocol to probe stakeholders’ thoughts
while they are interacting with the interface, we can identify stakeholders’ fairness
beliefs and principles. We conduct a user study to evaluate our framework in the setting
of a child maltreatment predictive system. Our evaluations show that the framework
allows stakeholders to comprehensively convey their fairness viewpoints. We also discuss
how our results can inform the design of predictive systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {390},
numpages = {17}
}

@inbook{10.1145/3411764.3445181,
author = {Lemmer, Stephan J. and Song, Jean Y. and Corso, Jason J.},
title = {Crowdsourcing More Effective Initializations for Single-Target Trackers Through Automatic Re-Querying},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445181},
abstract = { In single-target video object tracking, an initial bounding box is drawn around a
target object and propagated through a video. When this bounding box is provided by
a careful human expert, it is expected to yield strong overall tracking performance
that can be mimicked at scale by novice crowd workers with the help of advanced quality
control methods. However, we show through an investigation of 900 crowdsourced initializations
that such quality control strategies are inadequate for this task in two major ways:
first, the high level of redundancy in these methods (e.g., averaging multiple responses
to reduce error) is unnecessary, as 23% of crowdsourced initializations perform just
as well as the gold-standard initialization. Second, even nearly perfect initializations
can lead to degraded long-term performance due to the complexity of object tracking.
Considering these findings, we evaluate novel approaches for automatically selecting
bounding boxes to re-query, and introduce Smart Replacement, an efficient method that
decides whether to use the crowdsourced replacement initialization.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {391},
numpages = {13}
}

@inbook{10.1145/3411764.3445472,
author = {Lee, Min Hun and Siewiorek, Daniel P. P. and Smailagic, Asim and Bernardino, Alexandre and Berm\'{u}dez i Badia, Sergi Berm\'{u}dez},
title = {A Human-AI Collaborative Approach for Clinical Decision Making on Rehabilitation Assessment},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445472},
abstract = { Advances in artificial intelligence (AI) have made it increasingly applicable to
supplement expert’s decision-making in the form of a decision support system on various
tasks. For instance, an AI-based system can provide therapists quantitative analysis
on patient’s status to improve practices of rehabilitation assessment. However, there
is limited knowledge on the potential of these systems. In this paper, we present
the development and evaluation of an interactive AI-based system that supports collaborative
decision making with therapists for rehabilitation assessment. This system automatically
identifies salient features of assessment to generate patient-specific analysis for
therapists, and tunes with their feedback. In two evaluations with therapists, we
found that our system supports therapists significantly higher agreement on assessment
(0.71 average F1-score) than a traditional system without analysis (0.66 average F1-score,
p &lt; 0.05). After tuning with therapist’s feedback, our system significantly improves
its performance from 0.8377 to 0.9116 average F1-scores (p &lt; 0.01). This work discusses
the potential of a human-AI collaborative system to support more accurate decision
making while learning from each other’s strengths.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {392},
numpages = {14}
}

@inbook{10.1145/3411764.3445782,
author = {Rhys Cox, Samuel and Wang, Yunlong and Abdul, Ashraf and von der Weth, Christian and Y. Lim, Brian},
title = {Directed Diversity: Leveraging Language Embedding Distances for Collective Creativity in Crowd Ideation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445782},
abstract = {Crowdsourcing can collect many diverse ideas by prompting ideators individually, but
this can generate redundant ideas. Prior methods reduce redundancy by presenting peers’
ideas or peer-proposed prompts, but these require much human coordination. We introduce
Directed Diversity, an automatic prompt selection approach that leverages language
model embedding distances to maximize diversity. Ideators can be directed towards
diverse prompts and away from prior ideas, thus improving their collective creativity.
Since there are diverse metrics of diversity, we present a Diversity Prompting Evaluation
Framework consolidating metrics from several research disciplines to analyze along
the ideation chain — prompt selection, prompt creativity, prompt-ideation mediation,
and ideation creativity. Using this framework, we evaluated Directed Diversity in
a series of a simulation study and four user studies for the use case of crowdsourcing
motivational messages to encourage physical activity. We show that automated diverse
prompting can variously improve collective creativity across many nuanced metrics
of diversity.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {393},
numpages = {35}
}

@inbook{10.1145/3411764.3445591,
author = {Rietz, Tim and Maedche, Alexander},
title = {Cody: An AI-Based System to Semi-Automate Coding for Qualitative Research},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445591},
abstract = { Qualitative research can produce a rich understanding of a phenomenon but requires
an essential and strenuous data annotation process known as coding. Coding can be
repetitive and time-consuming, particularly for large datasets. Existing AI-based
approaches for partially automating coding, like supervised machine learning (ML)
or explicit knowledge represented in code rules, require high technical literacy and
lack transparency. Further, little is known about the interaction of researchers with
AI-based coding assistance. We introduce Cody, an AI-based system that semi-automates
coding through code rules and supervised ML. Cody supports researchers with interactively
(re)defining code rules and uses ML to extend coding to unseen data. In two studies
with qualitative researchers, we found that (1) code rules provide structure and transparency,
(2) explanations are commonly desired but rarely used, (3) suggestions benefit coding
quality rather than coding speed, increasing the intercoder reliability, calculated
with Krippendorff’s Alpha, from 0.085 (MAXQDA) to 0.33 (Cody).},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {394},
numpages = {14}
}

@inbook{10.1145/3411764.3445449,
author = {Jain, Vidit and Leekha, Maitree and Shah, Rajiv Ratn and Shukla, Jainendra},
title = {Exploring Semi-Supervised Learning for Predicting Listener Backchannels},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445449},
abstract = { Developing human-like conversational agents is a prime area in HCI research and subsumes
many tasks. Predicting listener backchannels is one such actively-researched task.
While many studies have used different approaches for backchannel prediction, they
all have depended on manual annotations for a large dataset. This is a bottleneck
impacting the scalability of development. To this end, we propose using semi-supervised
techniques to automate the process of identifying backchannels, thereby easing the
annotation process. To analyze our identification module’s feasibility, we compared
the backchannel prediction models trained on (a) manually-annotated and (b) semi-supervised
labels. Quantitative analysis revealed that the proposed semi-supervised approach
could attain 95% of the former’s performance. Our user-study findings revealed that
almost 60% of the participants found the backchannel responses predicted by the proposed
model more natural. Finally, we also analyzed the impact of personality on the type
of backchannel signals and validated our findings in the user-study.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {395},
numpages = {12}
}

@inbook{10.1145/3411764.3445290,
author = {Morrison, Cecily and Cutrell, Edward and Grayson, Martin and Thieme, Anja and Taylor, Alex and Roumen, Geert and Longden, Camilla and Tschiatschek, Sebastian and Faia Marques, Rita and Sellen, Abigail},
title = {Social Sensemaking with AI: Designing an Open-Ended AI Experience with a Blind Child},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445290},
abstract = {AI technologies are often used to aid people in performing discrete tasks with well-defined
goals (e.g., recognising faces in images). Emerging technologies that provide continuous,
real-time information enable more open-ended AI experiences. In partnership with a
blind child, we explore the challenges and opportunities of designing human-AI interaction
for a system intended to support social sensemaking. Adopting a research-through-design
perspective, we reflect upon working with the uncertain capabilities of AI systems
in the design of this experience. We contribute: (i) a concrete example of an open-ended
AI system that enabled a blind child to extend his own capabilities; (ii) an illustration
of the delta between imagined and actual use, highlighting how capabilities derive
from the human-AI interaction and not the AI system alone; and (iii) a discussion
of design choices to craft an ongoing human-AI interaction that addresses the challenge
of uncertain outputs of AI systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {396},
numpages = {14}
}

@inbook{10.1145/3411764.3445723,
author = {Harrington, Christina and Dillahunt, Tawanna R},
title = {Eliciting Tech Futures Among Black Young Adults: A Case Study of Remote Speculative Co-Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445723},
abstract = { The question of who gets to contribute to design futures and technology innovation
has become a topic of conversation across HCI, CSCW, and other computing communities.
This conversation has grave implications for communities that often find themselves
an afterthought in technology design, and who coincidentally could benefit most from
technological interventions in response to societal oppression. To explore this topic,
we examined “futuring” through co-designed speculative design fictions as methods
to envision utopian and dystopian futures. In a case study, we examined technology’s
role in the imagined futures of youth participants of a Chicago summer design program.
We highlight emerging themes and contribute an analysis of remote co-design through
an Afrofuturism lens. Our analysis shows that concepts of utopian futures and technologies
to support those futures are still heavily laden with dystopian realities of racism
and poverty. We discuss ways that speculative design fictions and futuring can serve
to address inclusivity in concept generation for new technologies, and we provide
recommendations for conducting design techniques remotely with historically excluded
populations. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {397},
numpages = {15}
}

@inbook{10.1145/3411764.3445590,
author = {To, Alexandra and Carey, Hillary and Kaufman, Geoff and Hammer, Jessica},
title = {Reducing Uncertainty and Offering Comfort: Designing Technology for Coping with Interpersonal Racism},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445590},
abstract = { Ranging from subtle to overt, unintentional to systemic, navigating racism is additional
everyday work for many people. Yet the needs of people who experience racism have
been overlooked as a fertile ground for better technology. Through a series of workshops
we call Foundational Fiction, we engaged BIPOC (Black, Indigenous, People of Color)
in participatory design to identify qualities of technology that can support people
coping before, during, and after a racist interaction. Participants developed storyboards
for digital tools that offer advice, predict consequences, identify racist remarks
and intervene, educate both targets and perpetrators about interpersonal and systemic
racism, and more. In the paper we present our workshop method utilizing interactive
fiction, participants’ design concepts, prevalent themes (reducing uncertainty and
offering comfort), and we provide critical analysis of the complexity of technology
in these contexts. This work identifies specific opportunities for exploring anti-racist
social tools.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {398},
numpages = {17}
}

@inbook{10.1145/3411764.3445383,
author = {Offenwanger, Anna and Milligan, Alan John and Chang, Minsuk and Bullard, Julia and Yoon, Dongwook},
title = {Diagnosing Bias in the Gender Representation of HCI Research Participants: How It Happens and Where We Are},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445383},
abstract = { In human-computer interaction (HCI) studies, bias in the gender representation of
participants can jeopardize the generalizability of findings, perpetuate bias in data
driven practices, and make new technologies dangerous for underrepresented groups.
Key to progress towards inclusive and equitable gender practices is diagnosing the
current status of bias and identifying where it comes from. In this mixed-methods
study, we interviewed 13 HCI researchers to identify the potential bias factors, defined
a systematic data collection procedure for meta-analysis of participant gender data,
and created a participant gender dataset from 1,147 CHI papers. Our analysis provided
empirical evidence for the underrepresentation of women, the invisibility of non-binary
participants, deteriorating representation of women in MTurk studies, and characteristics
of research topics prone to bias. Based on these findings, we make concrete suggestions
for promoting inclusive community culture and equitable research practices in HCI.
},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {18}
}

@inbook{10.1145/3411764.3445742,
author = {Scheuerman, Morgan Klaus and Jiang, Aaron and Spiel, Katta and Brubaker, Jed R.},
title = {Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non-)Binary People},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445742},
abstract = { Gender input forms act as gates to accessing information, websites, and services
online. Non-binary people regularly have to interact with them, though many do not
offer non-binary gender options. This results in non-binary individuals having to
either choose an incorrect gender category or refrain from using a site or service—which
is occasionally infeasible (e.g., when accessing health services). We tested five
different forms through a survey with binary and non-binary participants (n = 350)
in three contexts—a digital health form, a social media website, and a dating app.
Our results indicate that the majority of participants found binary “male or female”
forms exclusive and uncomfortable to fill out across all contexts. We conclude with
design considerations for improving gender input forms and consequently their underlying
gender model in databases. Our work aims to sensitize designers of (online) gender
web forms to the needs and desires of non-binary people.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {400},
numpages = {18}
}

@inbook{10.1145/3411764.3445701,
author = {MacArthur, Cayley and Grinberg, Arielle and Harley, Daniel and Hancock, Mark},
title = {You’Re Making Me Sick: A Systematic Review of How Virtual Reality Research Considers Gender &amp; Cybersickness},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445701},
abstract = {While multiple studies suggest that female-identified participants are more likely
to experience cybersickness in virtual reality (VR), our systematic review of 71 eligible
VR publications (59 studies and 12 surveys) pertaining to gender and cybersickness
reveals a number of confounding factors in study design (e.g., a variety of technical
specifications, tasks, content), a lack of demographic data, and a bias in participant
recruitment. Our review shows an ongoing need within VR research to more consistently
include and report on women’s experiences in VR to better understand the gendered
possibility of cybersickness. Based on the gaps identified in our systematic review,
we contribute study design recommendations for future work, arguing that gender considerations
are necessary at every stage of VR study design, even when the study is not ‘about’
gender. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {401},
numpages = {15}
}

@inbook{10.1145/3411764.3445126,
author = {Okerlund, Johanna and Wilson, David and Latulipe, Celine},
title = {A Feminist Utopian Perspective on the Practice and Promise of Making},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445126},
abstract = { While makerspaces are often discussed in terms of a utopian vision of democratization
and empowerment, many have shown how these narratives are problematic. There remains
optimism for the future of makerspaces, but there is a gap in knowledge of how to
articulate their promise and how to pursue it. We present a reflexive and critical
reflection of our efforts as leaders of a university makerspace to articulate a vision,
as well as our experience running a maker fashion show that aimed to address some
specific critiques. We analyze interviews of participants from the fashion show using
feminist utopianism as a lens to help us understand an alternate utopian narrative
for making. Our contributions include insights about how a particular making context
embodies feminist utopianism, insights about the applicability of feminist utopianism
to makerspace research and visioning efforts, and a discussion about how our results
can guide makerspace leaders and HCI researchers.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {402},
numpages = {16}
}

@inbook{10.1145/3411764.3445778,
author = {Im, Jane and Dimond, Jill and Berton, Melody and Lee, Una and Mustelier, Katherine and Ackerman, Mark S. and Gilbert, Eric},
title = {Yes: Affirmative Consent as a Theoretical Framework for Understanding and Imagining Social Platforms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445778},
abstract = { Affirmative consent is the idea that someone must ask for, and earn, enthusiastic
approval before interacting with someone else. For decades, feminist activists and
scholars have used affirmative consent to theorize and prevent sexual assault. In
this paper, we ask: Can affirmative consent help to theorize online interaction? Drawing
from feminist, legal, and HCI literature, we introduce the feminist theory of affirmative
consent and use it to analyze social computing systems. We present affirmative consent’s
five core concepts: it is voluntary, informed, revertible, specific, and unburdensome.
Using these principles, this paper argues that affirmative consent is both an explanatory
and generative theoretical framework. First, affirmative consent is a theoretical
abstraction for explaining various problematic phenomena in social platforms—including
mass online harassment, revenge porn, and problems with content feeds. Finally, we
argue that affirmative consent is a generative theoretical foundation from which to
imagine new design ideas for consentful socio-technical systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {403},
numpages = {18}
}

@inbook{10.1145/3411764.3445500,
author = {Spors, Velvet and Wagner, Hanne Gesine and Flintham, Martin and Brundell, Pat and Murphy, David},
title = {Selling Glossy, Easy Futures: A Feminist Exploration of Commercial Mental-Health-Focused Self-Care Apps’ Descriptions in the Google Play Store},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445500},
abstract = { Self-care apps offer a wide variety of different therapy paradigms, pedagogies and
concepts for people to maintain and make sense of their mental health. However, as
human-made artefacts, these apps are being imbued with their designers’ interests,
opinions, biases and assumptions about self-care. This paper is interested in making
these (often) implicit notions visible. After selecting 69 apps from the Google Play
Store, we use Feminist Content Analysis to investigate the store descriptions of these
apps: Inductively through thematic analysis and deductively through charting concepts
found within the descriptions. Our findings indicate that commercial self-care apps
portray themselves as “future creating” tools for individual self-discovery, but they
also create narratives that propagate an overly simplistic, individualistic and potentially
harmful view of mental distress. We conclude this paper by sketching out alternative
design considerations for how self-care apps can portray themselves and communicate
in a more transparent, plurality-embracing fashion.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {404},
numpages = {17}
}

@inbook{10.1145/3411764.3445107,
author = {Strengers, Yolande and Sadowski, Jathan and Li, Zhuying and Shimshak, Anna and 'Floyd' Mueller, Florian},
title = {What Can HCI Learn from Sexual Consent? A Feminist Process of Embodied Consent for Interactions with Emerging Technologies},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445107},
abstract = {Sexual consent has undergone a transformation toward an “enthusiastic” feminist model
that emphasizes consent as an ongoing and voluntary process of negotiation and affirmation.
This paper considers how such a model can advance understandings of consent in HCI
research and design in relation to embodied interactions with emerging technologies
that also occur outside of sexual interactions. We apply the popular “FRIES” model
of sexual consent (Freely given, Reversible, Informed, Enthusiastic and Specific)
to three areas of embodied interaction: 1) bodily-play interactions, 2) persuasive
interactions with smart technologies, and 3) intimate interactions with anthropomorphized
devices. Based on erotic play practices, we contribute a “TEASE” process guideline
(Traffic lights, Establish ongoing dialogue, Aftercare, Safewords, and Explicate soft/hard
limits) to advance consensual practice in HCI and develop implementation scenarios.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {405},
numpages = {13}
}

@inbook{10.1145/3411764.3445103,
author = {Pierre, Jennifer and Crooks, Roderic and Currie, Morgan and Paris, Britt and Pasquetto, Irene},
title = {Getting Ourselves Together: Data-Centered Participatory Design Research &amp; Epistemic Burden},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445103},
abstract = { Data-centered participatory design research projects—wherein researchers collaborate
with community members for the purpose of gathering, generating, or communicating
data about the community or their causes—can place epistemic burdens on minoritized
or racialized groups, even in projects focused on social justice outcomes. Analysis
of epistemic burden encourages researchers to rethink the purpose and value of data
in community organizing and activism more generally. This paper describes three varieties
of epistemic burden drawn from two case studies based on the authors’ previous work
with anti-police brutality community organizations. The authors conclude with a discussion
of ways to alleviate and avoid these issues through a series of questions about participatory
research design. Ultimately, we call for a reorientation of knowledge production away
from putative design solutions to community problems and toward a more robust interrogation
of the power dynamics of research itself.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {406},
numpages = {11}
}

@inbook{10.1145/3411764.3445058,
author = {Ehrenberg, Nils and Keinonen, Turkka},
title = {The Technology Is Enemy for Me at the Moment: How Smart Home Technologies Assert Control Beyond Intent},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445058},
abstract = { Smart technology turns the home into an active agent, which shifts the power structure
within the household. This paper examines how initiators of smart technology insert
their vision of the good life into households, and how these technologies exert power
over the residents. Through a thematic analysis of interviews with five households,
we consider Foucault’s theory on disciplinary power to examine how smart home technologies
shape the experience of the home by shifting the flow of information and thereby reify
power structures. Results indicate that the implementation of smart technology can
affect access to shared spaces, constrain interactions, and predefine practices thereby
establishing hierarchies within the household. We turn the discussion towards ethical
challenges concerning control, whose problems the smart home is concerned with, and
how the smart home embeds itself in the household. We conclude with design considerations
and future work.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {407},
numpages = {11}
}

@inbook{10.1145/3411764.3445153,
author = {Ciolfi Felice, Marianela and S\o{}ndergaard, Marie Louise Juul and Balaam, Madeline},
title = {Resisting the Medicalisation of Menopause: Reclaiming the Body through Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445153},
abstract = { The menopause transition involves bodily-rooted, socially-shaped changes, often in
a context of medicalisation that marginalises people based on their age and gender.
With the goal of addressing this social justice matter with a participatory design
approach, we started to cultivate partnerships with people going through menopause.
This paper reports on interviews with 12 women and a design workshop with three. Our
data analysis highlights their experiences from a holistic perspective that reclaims
the primacy of the body and acknowledges the entanglement of the physical and the
psychosocial. Participants’ design concepts show how design can come close the body
to make space for menopause experiences, recognising and transforming them. We discuss
how HCI can actively engage with the body to promote appreciation for it during menopause,
and call for design that accompanies people in resisting the medicalisation of menopause
as an enactment of social justice in everyday life.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {408},
numpages = {16}
}

@inbook{10.1145/3411764.3445132,
author = {Mehrnezhad, Maryam and Almeida, Teresa},
title = {Caring for Intimate Data in Fertility Technologies},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445132},
abstract = { Fertility tracking applications are technologies that collect sensitive information
about their users i.e. reproductive potential. For many, these apps are an affordable
solution when trying to conceive or managing their pregnancy. However, intimate data
are not only collected but also shared beyond users knowledge or consent. In this
paper, we explore the privacy risks that can originate from the mismanagement, misuse,
and misappropriation of intimate data, which are entwined in individual life events
and in public health issues such as abortion and (in)fertility. We look at differential
vulnerabilities to enquire data’s vulnerability and that of ‘data subjects’. We introduce
the General Data Protection Regulation (GDPR) and how it addresses fertility data.
We evaluate the privacy of 30 top ‘fertility apps’ through their privacy notices and
tracking practices. Lastly, we discuss the regulations and fertility data as critical
to the future design of tracking technologies and privacy rights.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {409},
numpages = {11}
}

@inbook{10.1145/3411764.3445054,
author = {Zhang, Yang and Mayer, Sven and Gonzalez, Jesse T. and Harrison, Chris},
title = {Vibrosight++: City-Scale Sensing Using Existing Retroreflective Signs and Markers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445054},
abstract = { Today’s smart cities use thousands of physical sensors distributed across the urban
landscape to support decision making in areas such as infrastructure monitoring, public
health, and resource management. These weather-hardened devices require power and
connectivity, and often cost thousands just to install, let alone maintain. In this
paper, we show how long-range laser vibrometry can be used for low-cost, city-scale
sensing. Although typically limited to just a few meters of sensing range, the use
of retroreflective markers can boost this to 1km or more. Fortuitously, cities already
make extensive use of retroreflective materials for street signs, construction barriers,
road studs, license plates, and many other markings. We describe how our prototype
system can co-opt these existing markers at very long ranges and use them as unpowered
accelerometers for use in a wide variety of sensing applications.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {410},
numpages = {14}
}

@inbook{10.1145/3411764.3445552,
author = {Wang, Zeyu and Nguyen, Cuong and Asente, Paul and Dorsey, Julie},
title = {DistanciAR: Authoring Site-Specific Augmented Reality Experiences for Remote Environments},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445552},
abstract = {Most augmented reality (AR) authoring tools only support the author’s current environment,
but designers often need to create site-specific experiences for a different environment.
We propose DistanciAR, a novel tablet-based workflow for remote AR authoring. Our
baseline solution involves three steps. A remote environment is captured by a camera
with LiDAR; then, the author creates an AR experience from a different location using
AR interactions; finally, a remote viewer consumes the AR content on site. A formative
study revealed understanding and navigating the remote space as key challenges with
this solution. We improved the authoring interface by adding two novel modes: Dollhouse,
which renders a bird’s-eye view, and Peek, which creates photorealistic composite
images using captured images. A second study compared this improved system with the
baseline, and participants reported that the new modes made it easier to understand
and navigate the remote scene.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {411},
numpages = {12}
}

@inbook{10.1145/3411764.3445302,
author = {Jiang, Ying and Zhang, Congyi and Fu, Hongbo and Cannav\`{o}, Alberto and Lamberti, Fabrizio and Lau, Henry Y K and Wang, Wenping},
title = {HandPainter - 3D Sketching in VR with Hand-Based Physical Proxy},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445302},
abstract = {3D sketching in virtual reality (VR) enables users to create 3D virtual objects intuitively
and immersively. However, previous studies showed that mid-air drawing may lead to
inaccurate sketches. To address this issue, we propose to use one hand as a canvas
proxy and the index finger of the other hand as a 3D pen. To this end, we first perform
a formative study to compare two-handed interaction with tablet-pen interaction for
VR sketching. Based on the findings of this study, we design HandPainter, a VR sketching
system which focuses on the direct use of two hands for 3D sketching without requesting
any tablet, pen, or VR controller. Our implementation is based on a pair of VR gloves,
which provide hand tracking and gesture capture. We devise a set of intuitive gestures
to control various functionalities required during 3D sketching, such as canvas panning
and drawing positioning. We show the effectiveness of HandPainter by presenting a
number of sketching results and discussing the outcomes of a user study-based comparison
with mid-air drawing and tablet-based sketching tools.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {412},
numpages = {13}
}

@inbook{10.1145/3411764.3445648,
author = {Head, Andrew and Lo, Kyle and Kang, Dongyeop and Fok, Raymond and Skjonsberg, Sam and Weld, Daniel S. and Hearst, Marti A.},
title = {Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445648},
abstract = {Despite the central importance of research papers to scientific progress, they can
be difficult to read. Comprehension is often stymied when the information needed to
understand a passage resides somewhere else—in another section, or in another paper.
In this work, we envision how interfaces can bring definitions of technical terms
and symbols to readers when and where they need them most. We introduce ScholarPhi,
an augmented reading interface with four novel features: (1) tooltips that surface
position-sensitive definitions from elsewhere in a paper, (2) a filter over the paper
that “declutters” it to reveal how the term or symbol is used across the paper, (3)
automatic equation diagrams that expose multiple definitions in parallel, and (4)
an automatically generated glossary of important terms and symbols. A usability study
showed that the tool helps researchers of all experience levels read papers. Furthermore,
researchers were eager to have ScholarPhi’s definitions available to support their
everyday reading. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {18}
}

@inbook{10.1145/3411764.3446864,
author = {Porfirio, David J. and Stegner, Laura and Cakmak, Maya and Saupp\'{e}, Allison and Albarghouthi, Aws and Mutlu, Bilge},
title = {Figaro: A Tabletop Authoring Environment for Human-Robot Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3446864},
abstract = { Human-robot interaction designers and developers navigate a complex design space,
which creates a need for tools that support intuitive design processes and harness
the programming capacity of state-of-the-art authoring environments. We introduce
Figaro, an expressive tabletop authoring environment for mobile robots, inspired by
shadow puppetry, that provides designers with a natural, situated representation of
human-robot interactions while exploiting the intuitiveness of tabletop and tangible
programming interfaces. On the tabletop, Figaro projects a representation of an environment.
Users demonstrate sequences of behaviors, or scenes, of an interaction by manipulating
instrumented figurines that represent the robot and the human. During a scene, Figaro
records the movement of figurines on the tabletop and narrations uttered by users.
Subsequently, Figaro employs real-time program synthesis to assemble a complete robot
program from all scenes provided. Through a user study, we demonstrate the ability
of Figaro to support design exploration and development for human-robot interaction.
},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {414},
numpages = {15}
}

@inbook{10.1145/3411764.3445732,
author = {Garza, Jorge and Merrill, Devon J. and Swanson, Steven},
title = {Appliancizer: Transforming Web Pages into Electronic Devices},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445732},
abstract = {Prototyping electronic devices that meet today’s consumer standards is a time-consuming
task that requires multi-domain expertise. Consumers expect electronic devices to
have visually appealing interfaces with both tactile and screen-based interfaces.
Appliancizer, our interactive computational design tool, exploits the similarities
between graphical and tangible interfaces, allowing web pages to be rapidly transformed
into physical electronic devices. Using a novel technique we call essential interface
mapping, our tool converts graphical user interface elements (e.g., an HTML button)
into tangible interface components (e.g., a physical button) without changing the
application source code. Appliancizer automatically generates the PCB and low-level
code from web-based prototypes and HTML mock-ups. This makes the prototyping of mixed
graphical-tangible interactions as easy as modifying a web page and allows designers
to leverage the well-developed ecosystem of web technologies. We demonstrate how our
technique simplifies and accelerates prototyping by developing two devices with Appliancizer.
},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {415},
numpages = {13}
}

@inbook{10.1145/3411764.3445573,
author = {Chen, Yan and Lee, Sang Won and Oney, Steve},
title = {CoCapture: Effectively Communicating UI Behaviors on Existing Websites by Demonstrating and Remixing},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445573},
abstract = {User Interface (UI) mockups are commonly used as shared context during interface development
collaboration. In practice, UI designers often use screenshots and sketches to create
mockups of desired UI behaviors for communication. However, in the later stages of
UI development, interfaces can be arbitrarily complex, making it labor-intensive to
sketch, and static screenshots are limited in the types of interactive and dynamic
behaviors they can express. We introduce CoCapture, a system that allows designers
to easily create UI behavior mockups on existing web interfaces by demonstrating and
remixing, and to accurately describe their requests to helpers by referencing the
resulting mockups using hypertext. We showed that participants could more accurately
describe UI behaviors with CoCapture than with existing sketch and communication tools
and that the resulting descriptions were clear and easy to follow. Our approach can
help teams develop UIs efficiently by bridging communication gaps with more accurate
visual context. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {416},
numpages = {14}
}

@inbook{10.1145/3411764.3445283,
author = {Huang, Gaoping and Qian, Xun and Wang, Tianyi and Patel, Fagun and Sreeram, Maitreya and Cao, Yuanzhi and Ramani, Karthik and Quinn, Alexander J.},
title = {AdapTutAR: An Adaptive Tutoring System for Machine Tasks in Augmented Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445283},
abstract = { Modern manufacturing processes are in a state of flux, as they adapt to increasing
demand for flexible and self-configuring production. This poses challenges for training
workers to rapidly master new machine operations and processes, i.e. machine tasks.
Conventional in-person training is effective but requires time and effort of experts
for each worker trained and not scalable. Recorded tutorials, such as video-based
or augmented reality (AR), permit more efficient scaling. However, unlike in-person
tutoring, existing recorded tutorials lack the ability to adapt to workers’ diverse
experiences and learning behaviors. We present AdapTutAR, an adaptive task tutoring
system that enables experts to record machine task tutorials via embodied demonstration
and train learners with different AR tutoring contents adapting to each user’s characteristics.
The adaptation is achieved by continually monitoring learners’ tutorial-following
status and adjusting the tutoring content on-the-fly and in-situ. The results of our
user study evaluation have demonstrated that our adaptive system is more effective
and preferable than the non-adaptive one. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {417},
numpages = {15}
}

@inbook{10.1145/3411764.3445254,
author = {Lin, Yu-Hsin and Wang, Yu-Wei and Ku, Pin-Sung and Cheng, Yun-Ting and Hsu, Yuan-Chih and Tsai, Ching-Yi and Chen, Mike Y.},
title = {HapticSeer: A Multi-Channel, Black-Box, Platform-Agnostic Approach to Detecting Video Game Events for Real-Time Haptic Feedback},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445254},
abstract = { Haptic feedback significantly enhances virtual experiences. However, supporting haptics
currently requires modifying the codebase, making it impractical to add haptics to
popular, high-quality experiences such as best selling games, which are typically
closed-source. We present HapticSeer, a multi-channel, black-box, platform-agnostic
approach to detecting game events for real-time haptic feedback. The approach is based
on two key insights: 1) all games have 3 types of data streams: video, audio, and
controller I/O, that can be analyzed in real-time to detect game events, and 2) a
small number of user interface design patterns are reused across most games, so that
event detectors can be reused effectively. We developed an open-source HapticSeer
framework and implemented several real-time event detectors for commercial PC and
VR games. We validated system correctness and real-time performance, and discuss feedback
from several haptics developers that used the HapticSeer framework to integrate research
and commercial haptic devices.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {418},
numpages = {14}
}

@inbook{10.1145/3411764.3445502,
author = {Schmitz, Martin and M\"{u}ller, Florian and M\"{u}hlh\"{a}user, Max and Riemann, Jan and Le, Huy Viet Viet},
title = {Itsy-Bits: Fabrication and Recognition of 3D-Printed Tangibles with Small Footprints on Capacitive Touchscreens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445502},
abstract = { Tangibles on capacitive touchscreens are a promising approach to overcome the limited
expressiveness of touch input. While research has suggested many approaches to detect
tangibles, the corresponding tangibles are either costly or have a considerable minimal
size. This makes them bulky and unattractive for many applications. At the same time,
they obscure valuable display space for interaction. To address these shortcomings,
we contribute Itsy-Bits: a fabrication pipeline for 3D printing and recognition of
tangibles on capacitive touchscreens with a footprint as small as a fingertip. Each
Itsy-Bit consists of an enclosing 3D object and a unique conductive 2D shape on its
bottom. Using only raw data of commodity capacitive touchscreens, Itsy-Bits reliably
identifies and locates a variety of shapes in different sizes and estimates their
orientation. Through example applications and a technical evaluation, we demonstrate
the feasibility and applicability of Itsy-Bits for tangibles with small footprints.
},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {419},
numpages = {12}
}

@inbook{10.1145/3411764.3445641,
author = {Schmitz, Martin and Riemann, Jan and M\"{u}ller, Florian and Kreis, Steffen and M\"{u}hlh\"{a}user, Max},
title = {Oh, Snap! A Fabrication Pipeline to Magnetically Connect Conventional and 3D-Printed Electronics},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445641},
abstract = { 3D printing has revolutionized rapid prototyping by speeding up the creation of custom-shaped
objects. With the rise of multi-material 3D printers, these custom-shaped objects
can now be made interactive in a single pass through passive conductive structures.
However, connecting conventional electronics to these conductive structures often
still requires time-consuming manual assembly involving many wires, soldering or gluing.
To alleviate these shortcomings, we propose : a fabrication pipeline and interfacing
concept to magnetically connect a 3D-printed object equipped with passive sensing
structures to conventional sensing electronics. To this end, utilizes ferromagnetic
and conductive 3D-printed structures, printable in a single pass on standard printers.
We further present a proof-of-concept capacitive sensing board that enables easy and
robust magnetic assembly to quickly create interactive 3D-printed objects. We evaluate
by assessing the robustness and quality of the connection and demonstrate its broad
applicability by a series of example applications.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {420},
numpages = {11}
}

@inbook{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
abstract = { Tangibles can enrich interaction with digital surfaces. Among others, they support
eyes-free control or increase awareness of other users’ actions. Tangibles have been
studied in combination with horizontal surfaces such as tabletops, but not with vertical
screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be
placed on such surfaces without falling. We present WallTokens, easy-to-fabricate
tangibles to interact with a vertical surface. A WallToken is a passive token whose
footprint is recognized on a tactile surface. It is equipped with a push-handle that
controls a suction cup. This makes it easy for users to switch between sliding the
token or attaching it to the wall. We describe how to build such tokens and how to
recognize them on a tactile surface. We report on a study showing the benefits of
WallTokens for manipulating virtual objects over multi-touch gestures. This project
is a step towards enabling tangible interaction in a wall display context. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13}
}

@inbook{10.1145/3411764.3445342,
author = {Fender, Andreas Rene and Martinez Plasencia, Diego and Subramanian, Sriram},
title = {ArticuLev: An Integrated Self-Assembly Pipeline for Articulated Multi-Bead Levitation Primitives},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445342},
abstract = { Acoustic levitation is gaining popularity as an approach to create physicalized mid-air
content by levitating different types of levitation primitives. Such primitives can
be independent particles or particles that are physically connected via threads or
pieces of cloth to form shapes in mid-air. However, initialization (i.e., placement
of such primitives in their mid-air target locations) currently relies on either manual
placement or specialized ad-hoc implementations, which limits their practical usage.
We present ArticuLev, an integrated pipeline that deals with the identification, assembly
and mid-air placement of levitated shape primitives. We designed ArticuLev with the
physical properties of commonly used levitation primitives in mind. It enables experiences
that seamlessly combine different primitives into meaningful structures (including
fully articulated animated shapes) and supports various levitation display approaches
(e.g., particles moving at high speed). In this paper, we describe our pipeline and
demonstrate it with heterogeneous combinations of levitation primitives.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {422},
numpages = {12}
}

@inbook{10.1145/3411764.3445762,
author = {Bunian, Sara and Li, Kai and Jemmali, Chaima and Harteveld, Casper and Fu, Yun and Seif El-Nasr, Magy Seif},
title = {VINS: Visual Search for Mobile User Interface Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445762},
abstract = {Searching for relative mobile user interface (UI) design examples can aid interface
designers in gaining inspiration and comparing design alternatives. However, finding
such design examples is challenging, especially as current search systems rely on
only text-based queries and do not consider the UI structure and content into account.
This paper introduces VINS, a visual search framework, that takes as input a UI image
(wireframe, high-fidelity) and retrieves visually similar design examples. We first
survey interface designers to better understand their example finding process. We
then develop a large-scale UI dataset that provides an accurate specification of the
interface’s view hierarchy (i.e., all the UI components and their specific location).
By utilizing this dataset, we propose an object-detection based image retrieval framework
that models the UI context and hierarchical structure. The framework achieves a mean
Average Precision of 76.39% for the UI detection and high performance in querying
similar UI designs. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {423},
numpages = {14}
}

@inbook{10.1145/3411764.3445551,
author = {Ettehadi, Omid and Anderson, Fraser and Tindale, Adam and Somanath, Sowmya},
title = {Documented: Embedding Information onto and Retrieving Information from 3D Printed Objects},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445551},
abstract = { Documentation for DIY tasks serve as codified project knowledge and help makers reach
new understandings and appreciations for the artifact. Engaging in reflective processes
using the documentation can be challenging when it comes to physical objects as the
documentation and the artifact exist separately. We hypothesize that spatially associating
the documentation information with the artifact can provide richer contextualization
to reflect upon the artifact and design process. We implemented and evaluated Documented,
a web application that helps makers associate documentation to 3D printed objects.
Information can be embedded using printed tags spatially placed on the model and accessed
using mobile AR. Our study highlights the different strategies participants had for
organizing, embedding, and retrieving information. Informed by our results, we discuss
how the coupling of the documentation and the artifact can support reflection and
identify potential barriers that need further investigation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {424},
numpages = {11}
}

@inbook{10.1145/3411764.3445346,
author = {Miyatake, Mako and Narumi, Koya and Sekiya, Yuji and Kawahara, Yoshihiro},
title = {Flower Jelly Printer: Slit Injection Printing for Parametrically Designed Flower Jelly},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445346},
abstract = { Flower jellies, a delicate dessert in which a flower-shaped jelly floats inside another
clear jelly, fascinate people with both their beauty and elaborate construction. In
efforts to simplify the challenging fabrication and enrich the design space of this
dessert, we present Flower Jelly Printer: a printing device and design software for
digitally fabricating flower jellies. Our design software lets users play with parameters
and preview the resulting forms until achieving their desired shapes. We also developed
slit injection printing that directly injects colored jelly into a base jelly, and
shared several design examples to show the breadth of design possibilities. Finally,
the user study with novice and experienced users demonstrates that our system benefits
creators of all experience levels by iterative design and precise fabrication. We
hope to enable more people to design and create their own flower jellies while expanding
access and the design space for digitally fabricated foods.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {425},
numpages = {10}
}

@inbook{10.1145/3411764.3445395,
author = {Lakshmi, Udaya and Hofmann, Megan and Mack, Kelly and Hudson, Scott E. and Mankoff, Jennifer and Arriaga, Rosa I.},
title = {Medical Maker Response to COVID-19: Distributed Manufacturing Infrastructure for Stopgap Protective Equipment},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445395},
abstract = { Unprecedented maker efforts arose in response to COVID-19 medical supply gaps worldwide.
Makers in the U.S., participated in peer-production activities to manufacture personal
protective equipment (PPE). Whereas, medical makers, who innovate exclusively for
points of care, pivoted towards safer, reliable PPE. What were their efforts to pivot
medical maker infrastructure towards reliable production of safe equipment at higher
volumes? We interviewed 13 medical makers as links between institutions, maker communities,
and wider regional industry networks. These medical makers organized stopgap manufacturing
in institutional spaces to resolve acute shortages (March–May) and chronic shortages
(May–July). They act as intermediaries in efforts to prototype and produce devices
under regulatory, material, and human constraints of a pandemic. We re-frame their
making efforts as repair work to offer an alternate critical view of optimism around
making for crisis. We contribute an understanding of these efforts to inform infrastructure
design for making with purpose and safety leading to opportunities for community production
of safe devices at scale.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {426},
numpages = {13}
}

@inbook{10.1145/3411764.3445325,
author = {Kang, Youwen and Sun, Zhida and Wang, Sitong and Huang, Zeyu and Wu, Ziming and Ma, Xiaojuan},
title = {MetaMap: Supporting Visual Metaphor Ideation through Multi-Dimensional Example-Based Exploration},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445325},
abstract = { Visual metaphors, which are widely used in graphic design, can deliver messages in
creative ways by fusing different objects. The keys to creating visual metaphors are
diverse exploration and creative combinations, which is challenging with conventional
methods like image searching. To streamline this ideation process, we propose to use
a mind-map-like structure to recommend and assist users to explore materials. We present
MetaMap, a supporting tool which inspires visual metaphor ideation through multi-dimensional
example-based exploration. To facilitate the divergence and convergence of the ideation
process, MetaMap provides 1) sample images based on keyword association and color
filtering; 2) example-based exploration in semantics, color, and shape dimensions;
and 3) thinking path tracking and idea recording. We conduct a within-subject study
with 24 design enthusiasts by taking a Pinterest-like interface as the baseline. Our
evaluation results suggest that MetaMap provides an engaging ideation process and
helps participants create diverse and creative ideas.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {427},
numpages = {15}
}

@inbook{10.1145/3411764.3445460,
author = {Saquib, Nazmus and Kazi, Rubaiat Habib and Wei, Li-yi and Mark, Gloria and Roy, Deb},
title = {Constructing Embodied Algebra by Sketching},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445460},
abstract = {Mathematical models and expressions traditionally evolved as symbolic representations,
with cognitively arbitrary rules of symbol manipulation. The embodied mathematics
philosophy posits that abstract math concepts are layers of metaphors grounded in
our intuitive arithmetic capabilities, such as categorizing objects and part-whole
analysis. We introduce a design framework that facilitates the construction and exploration
of embodied representations for algebraic expressions, using interactions inspired
by innate arithmetic capabilities. We instantiated our design in a sketch interface
that enables construction of visually interpretable compositions that are directly
mappable to algebraic expressions and explorable through a ladder of abstraction [47].
The emphasis is on bottom-up construction, with the user sketching pictures while
the system generates corresponding algebra. We present diverse examples created by
our prototype system. A coverage of the US Common Core curriculum and playtesting
studies with children point to the future direction and potential for a sketch-based
design paradigm for mathematics. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {428},
numpages = {16}
}

@inbook{10.1145/3411764.3445529,
author = {Song, Katherine W and Paulos, Eric},
title = {Unmaking: Enabling and Celebrating the Creative Material of Failure, Destruction, Decay, and Deformation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445529},
abstract = {The access and growing ubiquity of digital fabrication has ushered in a celebration
of creativity and “making.” However, the focus is often on the resulting static artifact
or the creative process and tools to design it. We envision a post-making process
that extends past these final static objects — not just in their making but in their
“unmaking.” By drawing from artistic movements such as Auto-Destructive Art, intentionally
inverting well-established engineering principles of structurally sound designs, and
safely misusing unstable materials, we demonstrate an important extension to making
— unmaking. In this paper, we provide designers with a new vocabulary of unmaking
operations within standard 3D modeling tools. We demonstrate how such designs can
be realized using a novel multi-material 3D printing process. Finally, we detail how
unmaking allows designs to change over time, is an ally to sustainability and re-usability,
and captures themes of “aura,” emotionality, and personalization. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {429},
numpages = {12}
}

@inbook{10.1145/3411764.3445360,
author = {Salminen, Joni and Jung, Soon-Gyo and M. Santos, Jo\~{a}o and Mohamed Sayed Kamel, Ahmed and J. Jansen, Bernard},
title = {Picturing It!: The Effect of Image Styles on User Perceptions of Personas},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445360},
abstract = {Though photographs of real people are typically used to portray personas, there is
little research into the potential advantages or disadvantages of using such images,
relative to other image styles. We conducted an experiment with 149 participants,
testing the effects of six different image styles on user perceptions and personality
traits that are attributed to personas by the participants. Results show that perceptions
of clarity, completeness, consistency, credibility, and empathy for a persona increase
with picture realism. Personas with more realistic pictures are also perceived as
more agreeable, open, and emotionally stable, with higher confidence in these assessments.
We also find evidence of the uncanny valley effect, with realistic cartoon personas
experiencing a decrease in the user perception scores.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {430},
numpages = {16}
}

@inbook{10.1145/3411764.3445062,
author = {Frich, Jonas and Nouwens, Midas and Halskov, Kim and Dalsgaard, Peter},
title = {How Digital Tools Impact Convergent and Divergent Thinking in Design Ideation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445062},
abstract = { Digital tools that support creative activities are ubiquitous in the design industry,
yet practitioners appear to prefer pen and paper for design ideation. To better understand
this exception, we conducted a comparative study between analog and digital tools
and their impact on the divergent and convergent thinking patterns of groups of designers.
We analysed how 24 participants solved comparable design ideation tasks in two conditions
using linkographic protocol analysis – a notation method that focuses on identifying
and linking small steps in the design process called moves. Our findings suggest that
digital ideation tools yield more convergent thinking compared to analog tools, with
no discernible impact on general productivity or divergent thinking.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {431},
numpages = {11}
}

@inbook{10.1145/3411764.3445311,
author = {Sun, Lingyun and Li, Jiaji and Chen, Yu and Yang, Yue and Yu, Zhi and Luo, Danli and Gu, Jianzhe and Yao, Lining and Tao, Ye and Wang, Guanyun},
title = {FlexTruss: A Computational Threading Method for Multi-Material, Multi-Form and Multi-Use Prototyping},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445311},
abstract = {3D printing, as a rapid prototyping technique, usually fabricates objects that are
difficult to modify physically. This paper presents FlexTruss, a design and construction
pipeline based on the assembly of modularized truss-shaped objects fabricated with
conventional 3D printers and assembled by threading. To create an end-to-end system,
a parametric design tool with an optimal Euler path calculation method is developed,
which can support both inverse and forward design workflow and multi-material construction
of modular parts. In addition, the assembly of truss modules by threading is evaluated
with a series of application cases to demonstrate the affordance of FlexTruss. We
believe that FlexTruss extends the design space of 3D printing beyond typically hard
and fixed forms, and it will provide new capabilities for designers and researchers
to explore the use of such flexible truss structures in human-object interaction.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {432},
numpages = {12}
}

@inbook{10.1145/3411764.3445220,
author = {Sun, Lingyun and Yang, Yue and Chen, Yu and Li, Jiaji and Luo, Danli and Liu, Haolin and Yao, Lining and Tao, Ye and Wang, Guanyun},
title = {ShrinCage: 4D Printing Accessories That Self-Adapt},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445220},
abstract = {3D printing technology makes Do-It-Yourself and reforming everyday objects a reality.
However, designing and fabricating attachments that can seamlessly adapt existing
objects to extended functionality is a laborious process, which requires accurate
measuring, modeling, manufacturing, and assembly. This paper presents ShrinCage, a
4D printing system that allows novices to easily create shrinkable adaptations to
fit and fasten existing objects. Specifically, the design tool presented in this work
aid in the design of attachment that adapts to irregular morphologies, which accommodates
the variations in measurements and fabrication, subsequently simplifying the modeling
and assembly processes. We further conduct mechanical tests and user studies to evaluate
the availability and feasibility of this method. Numerous application examples created
by ShrinCage prove that it can be adopted by aesthetic modification, assistive technology,
repair, upcycling, and augmented 3D printing.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {433},
numpages = {12}
}

@inbook{10.1145/3411764.3445236,
author = {Goveia da Rocha, Bruna and van der Kolk, Johannes M. L. and Andersen, Kristina},
title = {Exquisite Fabrication: Exploring Turn-Taking between Designers and Digital Fabrication Machines},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445236},
abstract = { Digital fabrication and craftsmanship is entering into a new phase with increasing
levels of complexity and a renewed desire for composites and cross-material experimentation.
However, allowing work to travel from machine to machine, remains a challenge in terms
of workflow, communication, orientation and material. Based on an exploration to combine
embroidery and 3D printing in the pursuit of inflatable solutions, we propose the
metaphor of the drawing game Exquisite Corpse to outline the three emerging concerns:
turn taking, orientation and trade-offs. We propose a set of guidelines that suggest
ways in which, we may allow different digital fabrication machines to be used in sequence,
as a method for adding complexity to the things we make and the ways our machines
may talk to one another.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {434},
numpages = {9}
}

@inbook{10.1145/3411764.3445744,
author = {'Floyd' Mueller, Florian and Patibanda, Rakesh and Byrne, Richard and Li, Zhuying and Wang, Yan and Andres, Josh and Li, Xiang and Marquez, Jonathan and Greuter, Stefan and Duckworth, Jonathan and Marshall, Joe},
title = {Limited Control Over the Body as Intriguing Play Design Resource},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445744},
abstract = {Interest in combining interactive play and the human body, using “bodily play” systems,
is increasing. While these systems primarily prioritize a player's control over their
bodily actions, we see intriguing possibilities in the pursuit of “limited control
over the body” as an intriguing design resource for bodily play systems. In this paper,
we use three of our bodily play systems to illustrate how designers can engage with
limited control over the body by varying the player's degree of indirect control (for
instance, via other bodily activity and external triggers). We also propose four strategies
for employing limited control over the body: Exploration, Reflection, Learning and
Embracement. We hope our own work and the strategies developed from it will assist
designers to employ limited control over the body, ultimately helping people benefit
from engaging their bodies through play.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {435},
numpages = {16}
}

@inbook{10.1145/3411764.3445512,
author = {Yuan, Ye and Cao, Jan and Wang, Ruotong and Yarosh, Svetlana},
title = {Tabletop Games in the Age of Remote Collaboration: Design Opportunities for a Socially Connected Game Experience},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445512},
abstract = {Prior research has highlighted opportunities for technology to better support the
tabletop game experience in offline and online settings, but little work has focused
on the social aspect of tabletop gaming. We investigated the social and collaborative
aspects of tabletop gaming in the unique context of “social distancing” during the
2020 COVID-19 pandemic to shed light on the experience of remote tabletop gaming.
With a multi-method qualitative approach (including digital ethnography and in-depth
interviews), we empirically studied how people appropriate existing technologies and
adapt their offline practices to play tabletop games remotely. We identify three themes
that describe people's game and social experience during remote play: creating a shared
tabletop environment (shared space), enabling a collective understanding (shared information
and awareness), and facilitating a communal temporal experience (shared time). We
reflect on challenges and design opportunities for a better experience in the age
of remote collaboration.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {14}
}

@inbook{10.1145/3411764.3445279,
author = {Kou, Yubo and Gui, Xinning},
title = {Flag and Flaggability in Automated Moderation: The Case of Reporting Toxic Behavior in an Online Game Community},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445279},
abstract = {Online platforms rely upon users or automated tools to flag toxic behaviors, the very
first step in online moderation. While much recent research has examined online moderation,
the role of flag remains poorly understood. This question becomes even more urgent
in automated moderation, where flagging becomes a primary source of human judgment.
We conducted a qualitative study of flagging practices in League of Legends (LoL),
a popular eSports game. We found stark differences between how flag is designed to
identify toxicity, and flaggability, or how players use and appropriate flag. Players
distrust flag, but also appropriate flag for instrumental purposes. Thus, flaggability
diverges decidedly from the conception of toxicity, and must be understood within
the highly competitive gaming context of LoL. These findings help shed light on the
situated nature of flaggability, the role of flag in online moderation, as well as
implications for designing flag and moderation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {437},
numpages = {12}
}

@inbook{10.1145/3411764.3445157,
author = {Beres, Nicole A and Frommel, Julian and Reid, Elizabeth and Mandryk, Regan L and Klarkowski, Madison},
title = {Don’t You Know That You’Re Toxic: Normalization of Toxicity in Online Gaming},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445157},
abstract = { Video game toxicity, endemic to online play, represents a pervasive and complex problem.
Antisocial behaviours in online play directly harm player wellbeing, enjoyment, and
retention—but research has also revealed that some players normalize toxicity as an
inextricable and acceptable element of the competitive video game experience. In this
work, we explore perceptions of toxicity and how they are predicted by player traits,
demonstrating that participants reporting a higher tendency towards Conduct Reconstrual,
Distorting Consequences, Dehumanization, and Toxic Online Disinhibition perceive online
game interactions as less toxic. Through a thematic analysis on willingness to report,
we also demonstrate that players abstain from reporting toxic content because they
view it as acceptable, typical of games, as banter, or as not their concern. We propose
that these traits and themes represent contributing factors to the cyclical normalization
of toxicity. These findings further highlight the multifaceted nature of toxicity
in online video games.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {438},
numpages = {15}
}

@inbook{10.1145/3411764.3445801,
author = {Xu, Wenge and Liang, Hai-Ning and Yu, Kangyou and Baghaei, Nilufar},
title = {Effect of Gameplay Uncertainty, Display Type, and Age on Virtual Reality Exergames},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445801},
abstract = { Uncertainty is widely acknowledged as an engaging gameplay element but rarely used
in exergames. In this research, we explore the role of uncertainty in exergames and
introduce three uncertain elements (false-attacks, misses, and critical hits) to an
exergame. We conducted a study under two conditions (uncertain and certain), with
two display types (virtual reality and large display) and across young and middle-aged
adults to measure their effect on game performance, experience, and exertion. Results
show that (1) our designed uncertain elements are instrumental in increasing exertion
levels; (2) when playing a motion-based first-person perspective exergame, virtual
reality can improve performance, while maintaining the same motion sickness level
as a large display; and (3) exergames for middle-aged adults should be designed with
age-related declines in mind, similar to designing for elderly adults. We also framed
two design guidelines for exergames that have similar features to the game used in
this research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {439},
numpages = {14}
}

@inbook{10.1145/3411764.3445163,
author = {M\'{a}rquez Segura, Elena and Turmo Vidal, Laia and Waern, Annika and Duval, Jared and Parrilla Bel, Luis and Altarriba Bertran, Ferran},
title = {Physical Warm-up Games: Exploring the Potential of Play and Technology Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445163},
abstract = {Warm-up games are widespread practices in multiple activities across domains, yet
little scholarly work can be found about their role in physical training. Here, we
study potential goals and benefits of warm-up games, and explore opportunities for
technology inclusion through investigating a collection of warm-up games gathered:
online, from a survey of online warm-up games curated, described, and used by Physical
Education teachers; and in person, from an ongoing design research work as part of
a technology-supported circus training course. Further, in the context of the latter,
we conducted explorative design interventions, augmenting a range of the warm-up games
with wearable technology. Our work surfaces major goals and benefits of warm-up games,
which can be broadly classified as preparing participants physically, socially, and
mentally. We also show how the inclusion of open-ended technology can support these
goals and discuss broader opportunities for technology inclusion in warm-up games.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {440},
numpages = {14}
}

@inbook{10.1145/3411764.3445622,
author = {Petersen Matjeka, Louise and Hobye, Mads and Larsen, Henrik Svarrer},
title = {Restraints as a Mechanic for Bodily Play},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445622},
abstract = {This paper presents restraints - directly imposed restrictions on players' bodily
movements, as a mechanic for bodily play in HCI. While this is a familiar mechanic
in non-digital movement-based games, its potential in designing bodily play experiences
in HCI has been scarcely explored. Three types of restraints observed in non-digital
movement-based games, are explored here: fixating body parts,&nbsp;excluding body parts
and&nbsp;depriving/manipulating bodily senses. Then, we investigate the experiential dynamics
of restraints as a bodily play mechanic bridging a phenomenological perspective on
bodily movement with theories on play. These investigations form the theoretical framework
for the subsequent analysis of five digital body game examples. Building on this analysis
and theoretical framework, we formulate five design strategies for implementing restraints
as a mechanic for bodily play in HCI. We propose restraints as a generative resource
for researchers and designers interested in understanding and designing bodily play
experiences in HCI.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {441},
numpages = {14}
}

@inbook{10.1145/3411764.3445592,
author = {M\'{a}rquez Segura, Elena and Rogers, Katja and Martin-Niedecken, Anna Lisa and Niedecken, Stephan and Vidal, Laia Turmo},
title = {Exploring the Design Space of Immersive Social Fitness Games: The ImSoFit Games Model},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445592},
abstract = {The design space of social exergames remains narrow despite the many benefits of playing
and exercising together. Towards opening this design space, we followed a Research
through Design (RtD) approach focused on exergames that can be fun and immersive social
training experiences. Through embodied sketching activities with designers and 10
pairs of players, we explored future games for the ExerCube, an immersive exergame
platform. Our work contributes with forms of intermediate-level knowledge: a design
space model (the Immersive Social Fitness—ImSoFit—Games model); and a novel design
vocabulary including new bodily orientations in co-located physical interaction. We
illustrate their use and value scrutinizing three of our games and applying three
analytical lenses to 1) understand how design choices impact how players move together;
2) evaluate design expectations and analyze players’ behavior in relation to design
choices; and 3) potentially extend the design space of immersive co-located social
fitness games. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {14}
}

@inbook{10.1145/3411764.3445492,
author = {Karaosmanoglu, Sukran and Rogers, Katja and Wolf, Dennis and Rukzio, Enrico and Steinicke, Frank and Nacke, Lennart E.},
title = {Feels like Team Spirit: Biometric and Strategic Interdependence in Asymmetric Multiplayer VR Games},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445492},
abstract = {Virtual reality (VR) multiplayer games increasingly use asymmetry (e.g., differences
in a person’s capability or the user interface) and resulting interdependence between
players to create engagement even when one player has no access to a head-mounted
display (HMD). Previous work shows this enhances player experience (PX). Until now,
it remains unclear whether and how an asymmetric game design with interdependences
creates comparably enjoyable PX for both an HMD and a non-HMD player. In this work,
we designed and implemented an asymmetric VR game (different in its user interface)
with two types of interdependence: strategic (difference in game information/player
capability) and biometric (difference in player’s biometric influence). Our mixed-methods
user study (N=30) shows that asymmetries positively impact PX for both player roles,
that interdependence strongly affects players’ perception of agency, and that biometric
feedback—while subjective—is a valuable game mechanic. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {443},
numpages = {15}
}

@inbook{10.1145/3411764.3445785,
author = {Buruk, O\u{g}uz 'Oz' and Salminen, Mikko and Xi, Nannan and Nummenmaa, Timo and Hamari, Juho},
title = {Towards the Next Generation of Gaming Wearables},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445785},
abstract = { Recent studies on gaming wearables show that wearables can contribute to the gaming
experience by bolstering performativity, facilitating social interaction, and accommodating
distinct interaction modalities. Still, these studies focused on contexts such as
role-playing, casual, or festival games. Stakeholder-oriented research that explores
the integration of wearables for mainstream gaming platforms such as game consoles
is scarce. To fill this gap, we have conducted an exploratory study through 6 participatory
design workshops focusing on different aspects of wearables with 33 participants from
different stakeholders. As a result, we have created fifteen design themes and three
gaming wearable concepts that led to seven actionable design implications which can
be adopted by designers and researchers for designing gaming wearables.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {444},
numpages = {15}
}

@inbook{10.1145/3411764.3445515,
author = {Emmerich, Katharina and Krekhov, Andrey and Cmentowski, Sebastian and Krueger, Jens},
title = {Streaming VR Games to the Broad Audience: A Comparison of the First-Person and Third-Person Perspectives},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445515},
abstract = { The spectatorship experience for virtual reality (VR) games differs strongly from
its non-VR precursor. When watching non-VR games on platforms such as Twitch, spectators
just see what the player sees, as the physical interaction is mostly unimportant for
the overall impression. In VR, the immersive full-body interaction is a crucial part
of the player experience. Hence, content creators, such as streamers, often rely on
green screens or similar solutions to offer a mixed-reality third-person view to disclose
their full-body actions. Our work compares the most popular realizations of the first-person
and the third-person perspective in an online survey (N&nbsp;=&nbsp;217) with three different
VR games. Contrary to the current trend to stream in third-person, our key result
is that most viewers prefer the first-person version, which they attribute mostly
to the better focus on in-game actions and higher involvement. Based on the study
insights, we provide design recommendations for both perspectives. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {445},
numpages = {14}
}

@inbook{10.1145/3411764.3445161,
author = {Jarrell, Marie and Ghaiumy Anaraky, Reza and Knijnenburg, Bart and Ash, Erin},
title = {Using Intersectional Representation &amp; Embodied Identification in Standard Video Game Play to Reduce Societal Biases},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445161},
abstract = { While virtual character embodiment has been studied as a mitigator of singular societal
biases in fully immersive VR and empathy games, there have been no major studies on
representation featuring standard game play or intersectional identities. In our study,
participants played a short 2D video game with racial and gender character manipulations.
They then rated a LinkedIn profile application to examine interactions of racial and
gender biases. White male participants showed bias against black and female applicants,
with the black female applicant experiencing both racial and gender bias. However,
participants who embodied certain underrepresented characters in the game displayed
reduced biases. Participants’ perceived identification with the characters moderated
this effect. The study highlights a lack of homogeneity in the prevalence and potential
reduction of different societal biases and incorporates intersectionality to illustrate
how multiple parts of a player character’s identity can be used to combat biases.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {446},
numpages = {18}
}

@inbook{10.1145/3411764.3445266,
author = {Wang, Yixue and Diakopoulos, Nicholas},
title = {Journalistic Source Discovery: Supporting The Identification of News Sources in User Generated Content},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445266},
abstract = { Many journalists and newsrooms now incorporate audience contributions in their sourcing
practices by leveraging user-generated content (UGC). However, their sourcing needs
and practices as they seek information from UGCs are still not deeply understood by
researchers or well-supported in tools. This paper first reports the results of a
qualitative interview study with nine professional journalists about their UGC sourcing
practices, detailing what journalists typically look for in UGCs and elaborating on
two UGC sourcing approaches: deep reporting and wide reporting. These findings then
inform a human-centered design approach to prototype a UGC sourcing tool for journalists,
which enables journalists to interactively filter and rank UGCs based on users’ example
content. We evaluate the prototype with nine professional journalists who source UGCs
in their daily routines to understand how UGC sourcing practices are enabled and transformed,
while also uncovering opportunities for future research and design to support journalistic
sourcing practices and sensemaking processes. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {447},
numpages = {18}
}

@inbook{10.1145/3411764.3445243,
author = {Cao, Hancheng and Lee, Chia-Jung and Iqbal, Shamsi and Czerwinski, Mary and Wong, Priscilla N Y and Rintel, Sean and Hecht, Brent and Teevan, Jaime and Yang, Longqi},
title = {Large Scale Analysis of Multitasking Behavior During Remote Meetings},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445243},
abstract = {Virtual meetings are critical for remote work because of the need for synchronous
collaboration in the absence of in-person interactions. In-meeting multitasking is
closely linked to people’s productivity and wellbeing. However, we currently have
limited understanding of multitasking in remote meetings and its potential impact.
In this paper, we present what we believe is the most comprehensive study of remote
meeting multitasking behavior through an analysis of a large-scale telemetry dataset
collected from February to May 2020 of U.S. Microsoft employees and a 715-person diary
study. Our results demonstrate that intrinsic meeting characteristics such as size,
length, time, and type, significantly correlate with the extent to which people multitask,
and multitasking can lead to both positive and negative outcomes. Our findings suggest
important best-practice guidelines for remote meetings (e.g., avoid important meetings
in the morning) and design implications for productivity tools (e.g., support positive
remote multitasking). },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {448},
numpages = {13}
}

@inbook{10.1145/3411764.3445399,
author = {Rubya, Sabirat and Numainville, Joseph and Yarosh, Svetlana},
title = {Comparing Generic and Community-Situated Crowdsourcing for Data Validation in the Context of Recovery from Substance Use Disorders},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445399},
abstract = { Targeting the right group of workers for crowdsourcing often achieves better quality
results. One unique example of targeted crowdsourcing is seeking community-situated
workers whose familiarity with the background and the norms of a particular group
can help produce better outcome or accuracy. These community-situated crowd workers
can be recruited in different ways from generic online crowdsourcing platforms or
from online recovery communities. We evaluate three different approaches to recruit
generic and community-situated crowd in terms of the time and the cost of recruitment,
and the accuracy of task completion. We consider the context of Alcoholics Anonymous
(AA), the largest peer support group for recovering alcoholics, and the task of identifying
and validating AA meeting information. We discuss the benefits and trade-offs of recruiting
paid vs. unpaid community-situated workers and provide implications for future research
in the recovery context and relevant domains of HCI, and for the design of crowdsourcing
ICT systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {449},
numpages = {17}
}

@inbook{10.1145/3411764.3445041,
author = {Sabet, Mehrnaz and Orand, Mania and W. McDonald, David},
title = {Designing Telepresence Drones to Support Synchronous, Mid-Air Remote Collaboration: An Exploratory Study},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445041},
abstract = {Drones are increasingly used to support humanitarian crises and events that involve
dangerous or costly tasks. While drones have great potential for remote collaborative
work and aerial telepresence, existing drone technology is limited in its support
for synchronous collaboration among multiple remote users. Through three design iterations
and evaluations, we prototyped Squadrone, a novel aerial telepresence platform that
supports synchronous mid-air collaboration among multiple remote users. We present
our design and report results from evaluating our iterations with 13 participants
in 3 different collaboration configurations. Our first design iteration validates
the basic functionality of the platform. Then, we establish the effectiveness of collaboration
using a 360-degree shared aerial display. Finally, we simulate a type of search task
in an open environment to see if collaborative telepresence impacts members’ participation.
The results validate some initial goals for Squadrone and are used to reflect back
on a recent telepresence design framework.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {17}
}

@inbook{10.1145/3411764.3445698,
author = {Gr\o{}nb\ae{}k, Jens Emil and Saat\c{c}i, Banu and Griggio, Carla F. and Klokmose, Clemens Nylandsted},
title = {MirrorBlender: Supporting Hybrid Meetings with a Malleable Video-Conferencing System},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445698},
abstract = { In hybrid meetings, multiple co-located participants communicate with remote participants
through video. But video communication inhibits non-verbal cues, and this often causes
remote participants to feel excluded. To address this issue, we built MirrorBlender:
a What-You-See-Is-What-I-See video-conferencing system for blending, repositioning,
and resizing mirrors. Mirrors here denote shared video feeds of people and screens.
In a qualitative study of MirrorBlender with three hybrid meeting sessions, we found
that the shared control of mirrors supported users in negotiating a blended interpersonal
space. Moreover, it enabled diverse acts of inclusion of remote participants. In particular,
remote participants brought attention to themselves by manipulating the position,
scale, and translucency of their camera and screen feeds. Participants also embodied
and leveraged their mirror images for deictic gestures and playful interactions. Based
on these findings, we discuss new opportunities for supporting video-mediated collaboration.
},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {451},
numpages = {13}
}

@inbook{10.1145/3411764.3445774,
author = {Lu, Alex Jiahong and Dillahunt, Tawanna R.},
title = {Uncovering the Promises and Challenges of Social Media Use in the Low-Wage Labor Market: Insights from Employers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445774},
abstract = { Social media has become an effective recruitment tool for higher-waged and white-collar
professionals. Yet, past studies have questioned its effectiveness for the recruitment
of lower-waged workers. It is also unclear whether or how employers leverage social
media in their recruitment of low-wage job seekers, and how social media could better
support the needs of both stakeholders. Therefore, we conducted 15 semi-structured
interviews with employers of low-wage workers in the U.S. We found that employers:
use social media, primarily Facebook, to access large pools of active low-wage job
seekers; and recognize indirect signals about low-wage job seekers’ commitment and
job readiness. Our work suggests that there remains a visible, yet unaddressed power
imbalance between low-wage workers and employers in the use of social media, which
risks further destabilizing the precarious labor market.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {452},
numpages = {13}
}

@inbook{10.1145/3411764.3445686,
author = {Kim, Tae Soo and Kim, Seungsu and Choi, Yoonseo and Kim, Juho},
title = {Winder: Linking Speech and Visual Objects to Support Communication in Asynchronous Collaboration},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445686},
abstract = {Team members commonly collaborate on visual documents remotely and asynchronously.
Particularly, students are frequently restricted to this setting as they often do
not share work schedules or physical workspaces. As communication in this setting
has delays and limits the main modality to text, members exert more effort to reference
document objects and understand others’ intentions. We propose Winder, a Figma plugin
that addresses these challenges through linked tapes—multimodal comments of clicks
and voice. Bidirectional links between the clicked-on objects and voice recordings
facilitate understanding tapes: selecting objects retrieves relevant recordings, and
playing recordings highlights related objects. By periodically prompting users to
produce tapes, Winder preemptively obtains information to satisfy potential communication
needs. Through a five-day study with eight teams of three, we evaluated the system’s
impact on teams asynchronously designing graphical user interfaces. Our findings revealed
that producing linked tapes could be as lightweight as face-to-face (F2F) interactions
while transmitting intentions more precisely than text. Furthermore, with preempted
tapes, teammates coordinated tasks and invited members to build on each others’ work.
},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {453},
numpages = {17}
}

@inbook{10.1145/3411764.3445335,
author = {Krau\ss{}, Veronika and Boden, Alexander and Oppermann, Leif and Reiners, Ren\'{e}},
title = {Current Practices, Challenges, and Design Implications for Collaborative AR/VR Application Development},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445335},
abstract = { Augmented/Virtual Reality (AR/VR) is still a fragmented space to design for due to
the rapidly evolving hardware, the interdisciplinarity of teams, and a lack of standards
and best practices. We interviewed 26 professional AR/VR designers and developers
to shed light on their tasks, approaches, tools, and challenges. Based on their work
and the artifacts they generated, we found that AR/VR application creators fulfill
four roles: concept developers, interaction designers, content authors, and technical
developers. One person often incorporates multiple roles and faces a variety of challenges
during the design process from the initial contextual analysis to the deployment.
From analysis of their tool sets, methods, and artifacts, we describe critical key
challenges. Finally, we discuss the importance of prototyping for the communication
in AR/VR development teams and highlight design implications for future tools to create
a more usable AR/VR tool chain.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {454},
numpages = {15}
}

@inbook{10.1145/3411764.3445305,
author = {Carlos Alvarez de la Vega, Juan and E. Cecchinato, Marta and Rooksby, John},
title = {“Why Lose Control?” A Study of Freelancers’ Experiences with Gig Economy Platforms},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445305},
abstract = {Freelancing platforms, such as Upwork, represent an expansion of the gig economy to
encompass knowledge-based work. Prior research in HCI has primarily focused on forms
of gig work such as ride-sharing and microwork but has not addressed how freelancing
platforms are disrupting high-skilled knowledge work. To understand freelancers’ perspectives
on how these platforms are disrupting their work we have collected and thematically
analysed 528 posts with 7499 comments from four relevant subforums on Reddit. The
qualitative findings reveal tensions between wanting autonomy and control and the
necessity of opportunities and convenience. Freelancing platforms are perceived as
systems that present advantages to find clients, gain experience and mitigate precarity.
However, these platforms constrain the control over their work that freelancers value.
The paper contributes an improved understanding of freelance work, the role and potential
for freelancing platforms in the knowledge-based gig economy, and directions for worker-centred
design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {14}
}

@inbook{10.1145/3411764.3445681,
author = {Manzano, Joshua C. and Soliven, Adrienne Francesca O. and Llamas, Antonio Miguel B. and Tinsay, Shenn Margareth V. and Samson, Briane Paul V. and Cabredo, Rafael A.},
title = {Using Boolean Satisfiability Solvers to Help Reduce Cognitive Load and Improve Decision Making When Creating Common Academic Schedules},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445681},
abstract = { Manual schedule creation often involves satisfying numerous unique and conflicting
constraints, which becomes more cognitively demanding when creating a common academic
schedule with other individuals. Poor decision making caused by cognitive overload
can result in unsuitable schedules. This study proposes the use of Boolean satisfiability
(SAT) solvers in an academic scheduling system to help students balance scheduling
preferences and satisfy necessary constraints. Based on the availability of courses
and the scheduling preferences of users, the system automatically resolves conflicts
and presents possible schedules. In a controlled experiment with 42 undergraduate
students, cognitive demand was reduced by eliminating menial decisions, which significantly
optimized the creation of a common schedule among peers. We found that human errors
and emotional stress were diminished, and schedules created using the system were
more satisfactory to participants. Finally, we present recommendations and design
implications for future academic scheduling systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {456},
numpages = {13}
}

@inbook{10.1145/3411764.3445633,
author = {Osmers, Niklas and Prilla, Michael and Blunk, Oliver and George Brown, Gordon and Jan\ss{}en, Marc and Kahrl, Nicolas},
title = {The Role of Social Presence for Cooperation in Augmented Reality on Head Mounted Devices: A Literature Review},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445633},
abstract = {With growing interest regarding cooperation support using Augmented Reality (AR),
social presence has become a popular measure of its quality. While this concept is
established throughout cooperation research, its role in AR is still unclear: Some
work uses social presence as an indicator for support quality, while others found
no impact at all. To clarify this role, we conducted a literature review of recent
publications that empirically investigated social presence in cooperative AR. After
a thorough selection procedure, we analyzed 19&nbsp;publications according to factors influencing
social presence and the impact of social presence on cooperation support. We found
that certain interventions support social presence better than others, that social
presence has an influence on user's preferences and that the relation between social
presence and cooperation quality may depend on the symmetry of the cooperation task.
This contributes to existing research by clarifying the role of social presence for
cooperative AR and deriving corresponding design recommendations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {457},
numpages = {17}
}

@inbook{10.1145/3411764.3445310,
author = {Branch, Boyd and Efstratiou, Christos and Mirowski, Piotr and Mathewson, Kory W. and Allain, Paul},
title = {Tele-Immersive Improv: Effects of Immersive Visualisations on Rehearsing and Performing Theatre Online},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445310},
abstract = {Performers acutely need but lack tools to remotely rehearse and create live theatre,
particularly due to global restrictions on social interactions during the Covid-19
pandemic. No studies, however, have heretofore examined how remote video-collaboration
affects performance. This paper presents the findings of a field study with 16 domain
experts over six weeks investigating how tele-immersion affects the rehearsal and
performance of improvisational theatre. To conduct the study, an original media server
was developed for co-locating remote performers into shared virtual 3D environments
which were accessed through popular video conferencing software. The results of this
qualitative study indicate that tele-immersive environments uniquely provide performers
with a strong sense of co- presence, feelings of physical connection, and an increased
ability to enter the social-flow states required for improvisational theatre. Based
on our observations, we put forward design recommendations for video collaboration
tools tailored to the unique demands of live performance. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {458},
numpages = {13}
}

@inbook{10.1145/3411764.3446866,
author = {Ens, Barrett and Bach, Benjamin and Cordeil, Maxime and Engelke, Ulrich and Serrano, Marcos and Willett, Wesley and Prouzeau, Arnaud and Anthes, Christoph and B\"{u}schel, Wolfgang and Dunne, Cody and Dwyer, Tim and Grubert, Jens and Haga, Jason H. and Kirshenbaum, Nurit and Kobayashi, Dylan and Lin, Tica and Olaosebikan, Monsurat and Pointecker, Fabian and Saffo, David and Saquib, Nazmus and Schmalstieg, Dieter and Szafir, Danielle Albers and Whitlock, Matt and Yang, Yalong},
title = {Grand Challenges in Immersive Analytics},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3446866},
abstract = { Immersive Analytics is a quickly evolving field that unites several areas such as
visualisation, immersive environments, and human-computer interaction to support human
data analysis with emerging technologies. This research has thrived over the past
years with multiple workshops, seminars, and a growing body of publications, spanning
several conferences. Given the rapid advancement of interaction technologies and novel
application domains, this paper aims toward a broader research agenda to enable widespread
adoption. We present 17 key research challenges developed over multiple sessions by
a diverse group of 24 international experts, initiated from a virtual scientific workshop
at ACM CHI 2020. These challenges aim to coordinate future work by providing a systematic
roadmap of current directions and impending hurdles to facilitate productive and effective
applications for Immersive Analytics.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {17}
}

@inbook{10.1145/3411764.3445152,
author = {Satriadi, Kadek Ananta and Ens, Barrett and Czauderna, Tobias and Cordeil, Maxime and Jenny, Bernhard},
title = {Quantitative Data Visualisation on Virtual Globes},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445152},
abstract = { Geographic data visualisation on virtual globes is intuitive and widespread, but
has not been thoroughly investigated. We explore two main design factors for quantitative
data visualisation on virtual globes: i)&nbsp;commonly used primitives (2D bar, 3D bar,
circle) and ii)&nbsp;the orientation of these primitives (tangential, normal, billboarded).
We evaluate five distinctive visualisation idioms in a user study with 50 participants.
The results show that aligning primitives tangentially on the globe’s surface decreases
the accuracy of area-proportional circle visualisations, while the orientation does
not have a significant effect on the accuracy of length-proportional bar visualisations.
We also find that tangential primitives induce higher perceived mental load than other
orientations. Guided by these results we design a novel globe visualisation idiom,
Geoburst, that combines a virtual globe and a radial bar chart. A preliminary evaluation
reports potential benefits and drawbacks of the Geoburst visualisation. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {460},
numpages = {14}
}

@inbook{10.1145/3411764.3445649,
author = {Lin, Tica and Singh, Rishi and Yang, Yalong and Nobre, Carolina and Beyer, Johanna and Smith, Maurice A. and Pfister, Hanspeter},
title = {Towards an Understanding of Situated AR Visualization for Basketball Free-Throw Training},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445649},
abstract = {We present an observational study to compare co-located and situated real-time visualizations
in basketball free-throw training. Our goal is to understand the advantages and concerns
of applying immersive visualization to real-world skill-based sports training and
to provide insights for designing AR sports training systems. We design both a situated
3D visualization on a head-mounted display and a 2D visualization on a co-located
display to provide immediate visual feedback on a player’s shot performance. Using
a within-subject study design with experienced basketball shooters, we characterize
user goals, report on qualitative training experiences, and compare the quantitative
training results. Our results show that real-time visual feedback helps athletes refine
subsequent shots. Shooters in our study achieve greater angle consistency with our
visual feedback. Furthermore, AR visualization promotes an increased focus on body
form in athletes. Finally, we present suggestions for the design of future sports
AR studies. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {461},
numpages = {13}
}

@inbook{10.1145/3411764.3445421,
author = {Kim, Young-Ho and Lee, Bongshin and Srinivasan, Arjun and Choe, Eun Kyoung},
title = {Data@Hand: Fostering Visual Exploration of Personal Data On&nbsp;Smartphones Leveraging Speech and Touch Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445421},
abstract = {Most mobile health apps employ data visualization to help people view their health
and activity data, but these apps provide limited support for visual data exploration.
Furthermore, despite its huge potential benefits, mobile visualization research in
the personal data context is sparse. This work aims to empower people to easily navigate
and compare their personal health data on smartphones by enabling flexible time manipulation
with speech. We designed and developed Data@Hand, a mobile app that leverages the
synergy of two complementary modalities: speech and touch. Through an exploratory
study with 13 long-term Fitbit users, we examined how multimodal interaction helps
participants explore their own health data. Participants successfully adopted multimodal
interaction (i.e., speech and touch) for convenient and fluid data exploration. Based
on the quantitative and qualitative findings, we discuss design implications and opportunities
with multimodal interaction for better supporting visual data exploration on mobile
devices. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {462},
numpages = {17}
}

@inbook{10.1145/3411764.3445704,
author = {Drogemuller, Adam and Cunningham, Andrew and Walsh, James A and Baumeister, James and Smith, Ross T. and Thomas, Bruce H},
title = {Haptic and Visual Comprehension of a 2D Graph Layout Through Physicalisation},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445704},
abstract = { Data physicalisations afford people the ability to directly interact with data using
their hands, potentially achieving a more comprehensive understanding of a dataset.
Due to their complex nature, the representation of graphs and networks could benefit
from physicalisation, bringing the dataset from the digital world into the physical
one. However, no empirical work exists investigating the effects physicalisations
have upon comprehension as they relate to graph representations. In this work, we
present initial design considerations for graph physicalisations, as well as an empirical
study investigating differences in comprehension between virtual and physical representations.
We found that participants perceived themselves as being more accurate via touch and
sight (visual-haptic) than the graphical-only modality, and perceived a triangle count
task as less difficult in visual-haptic than in the graphical-only modality. Additionally,
we found that participants significantly preferred interacting with visual-haptic
over other conditions, despite no significant effect on task time or error. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {463},
numpages = {16}
}

@inbook{10.1145/3411764.3445400,
author = {Srinivasan, Arjun and Nyapathy, Nikhila and Lee, Bongshin and Drucker, Steven M. and Stasko, John},
title = {Collecting and Characterizing Natural Language Utterances for Specifying Data Visualizations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445400},
abstract = { Natural language interfaces (NLIs) for data visualization are becoming increasingly
popular both in academic research and in commercial software. Yet, there is a lack
of empirical understanding of how people specify visualizations through natural language.
We conducted an online study (N = 102), showing participants a series of visualizations
and asking them to provide utterances they would pose to generate the displayed charts.
From the responses, we curated a dataset of 893 utterances and characterized the utterances
according to (1) their phrasing (e.g., commands, queries, questions) and (2) the information
they contained (e.g., chart types, data aggregations). To help guide future research
and development, we contribute this utterance dataset and discuss its applications
toward the creation and benchmarking of NLIs for visualization.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {464},
numpages = {10}
}

@inbook{10.1145/3411764.3445439,
author = {Chen, Kun-Ting and Dwyer, Tim and Bach, Benjamin and Marriott, Kim},
title = {It’s a Wrap: Toroidal Wrapping of Network Visualisations Supports Cluster Understanding Tasks},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445439},
abstract = { We explore network visualisation on a two-dimensional torus topology that continuously
wraps when the viewport is panned. That is, links may be “wrapped” across the boundary,
allowing additional spreading of node positions to reduce visual clutter. Recent work
has investigated such pannable wrapped visualisations, finding them not worse than
unwrapped drawings for small networks for path-following tasks. However, they did
not evaluate larger networks nor did they consider whether torus-based layout might
also better display high-level network structure like clusters. We offer two algorithms
for improving toroidal layout that is completely autonomous and automatic panning
of the viewport to minimiswe wrapping links. The resulting layouts afford fewer crossings,
less stress, and greater cluster separation. In a study of 32 participants comparing
performance in cluster understanding tasks, we find that toroidal visualisation offers
significant benefits over standard unwrapped visualisation in terms of improvement
in error by 62.7% and time by 32.3%. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {465},
numpages = {12}
}

@inbook{10.1145/3411764.3445508,
author = {Zheng, Rebecca and Fern\'{a}ndez Camporro, Marina and Romat, Hugo and Henry Riche, Nathalie and Bach, Benjamin and Chevalier, Fanny and Hinckley, Ken and Marquardt, Nicolai},
title = {Sketchnote Components, Design Space Dimensions, and Strategies for Effective Visual Note Taking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445508},
abstract = { Sketchnoting is a form of visual note taking where people listen to, synthesize,
and visualize ideas from a talk or other event using a combination of pictures, diagrams,
and text. Little is known about the design space of this kind of visual note taking.
With an eye towards informing the implementation of digital equivalents of sketchnoting,
inking, and note taking, we introduce a classification of sketchnote styles and techniques,
with a qualitative analysis of 103 sketchnotes, and situated in context with six semi-structured
follow up interviews. Our findings distill core sketchnote components (content, layout,
structuring elements, and visual styling) and dimensions of the sketchnote design
space, classifying levels of conciseness, illustration, structure, personification,
cohesion, and craftsmanship. We unpack strategies to address particular note taking
challenges, for example dealing with constraints of live drawings, and discuss relevance
for future digital inking tools, such as recomposition, styling, and design suggestions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {466},
numpages = {15}
}

@inbook{10.1145/3411764.3445063,
author = {Pu, Xiaoying and Kross, Sean and Hofman, Jake M. and Goldstein, Daniel G.},
title = {Datamations: Animated Explanations of Data Analysis Pipelines},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445063},
abstract = { Plots and tables are commonplace in today’s data-driven world, and much research
has been done on how to make these figures easy to read and understand. Often times,
however, the information they contain conveys only the end result of a complex and
subtle data analysis pipeline. This can leave the reader struggling to understand
what steps were taken to arrive at a figure, and what implications this has for the
underlying results. In this paper, we introduce datamations, which are animations
designed to explain the steps that led to a given plot or table. We present the motivation
and concept behind datamations, discuss how to programmatically generate them, and
provide the results of two large-scale randomized experiments investigating how datamations
affect people’s abilities to understand potentially puzzling results compared to seeing
only final plots and tables containing those results. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {14}
}

@inbook{10.1145/3411764.3445593,
author = {Langner, Ricardo and Satkowski, Marc and B\"{u}schel, Wolfgang and Dachselt, Raimund},
title = {MARVIS: Combining Mobile Devices and Augmented Reality for Visual Data Analysis},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445593},
abstract = { We present Marvis, a conceptual framework that combines mobile devices and head-mounted
Augmented Reality (AR) for visual data analysis. We propose novel concepts and techniques
addressing visualization-specific challenges. By showing additional 2D and 3D information
around and above displays, we extend their limited screen space. AR views between
displays as well as linking and brushing are also supported, making relationships
between separated visualizations plausible. We introduce the design process and rationale
for our techniques. To validate Marvis’ concepts and show their versatility and widespread
applicability, we describe six implemented example use cases. Finally, we discuss
insights from expert hands-on reviews. As a result, we contribute to a better understanding
of how the combination of one or more mobile devices with AR can benefit visual data
analysis. By exploring this new type of visualization environment, we hope to provide
a foundation and inspiration for future mobile data visualizations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {468},
numpages = {17}
}

@inbook{10.1145/3411764.3445298,
author = {Hubenschmid, Sebastian and Zagermann, Johannes and Butscher, Simon and Reiterer, Harald},
title = {STREAM: Exploring the Combination of Spatially-Aware Tablets with Augmented Reality Head-Mounted Displays for Immersive Analytics},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445298},
abstract = { Recent research in the area of immersive analytics demonstrated the utility of head-mounted
augmented reality devices for visual data analysis. However, it can be challenging
to use the by default supported mid-air gestures to interact with visualizations in
augmented reality (e.g. due to limited precision). Touch-based interaction (e.g. via
mobile devices) can compensate for these drawbacks, but is limited to two-dimensional
input. In this work we present STREAM: Spatially-aware Tablets combined with Augmented
Reality Head-Mounted Displays for the multimodal interaction with 3D visualizations.
We developed a novel eyes-free interaction concept for the seamless transition between
the tablet and the augmented reality environment. A user study reveals that participants
appreciated the novel interaction concept, indicating the potential for spatially-aware
tablets in augmented reality. Based on our findings, we provide design insights to
foster the application of spatially-aware touch devices in augmented reality and research
implications indicating areas that need further investigation.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {14}
}

@inbook{10.1145/3411764.3445651,
author = {B\"{u}schel, Wolfgang and Lehmann, Anke and Dachselt, Raimund},
title = {MIRIA: A Mixed Reality Toolkit for the In-Situ Visualization and Analysis of Spatio-Temporal Interaction Data},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445651},
abstract = { In this paper, we present MIRIA, a Mixed Reality Interaction Analysis toolkit designed
to support the in-situ visual analysis of user interaction in mixed reality and multi-display
environments. So far, there are few options to effectively explore and analyze interaction
patterns in such novel computing systems. With MIRIA, we address this gap by supporting
the analysis of user movement, spatial interaction, and event data by multiple, co-located
users directly in the original environment. Based on our own experiences and an analysis
of the typical data, tasks, and visualizations used in existing approaches, we identify
requirements for our system. We report on the design and prototypical implementation
of MIRIA, which is informed by these requirements and offers various visualizations
such as 3D movement trajectories, position heatmaps, and scatterplots. To demonstrate
the value of MIRIA for real-world analysis tasks, we conducted expert feedback sessions
using several use cases with authentic study data.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {15}
}

@inbook{10.1145/3411764.3445746,
author = {Sauv\'{e}, Kim and Verweij, David and Alexander, Jason and Houben, Steven},
title = {Reconfiguration Strategies with Composite Data Physicalizations},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445746},
abstract = { Composite data physicalizations allow for the physical reconfiguration of data points,
creating new opportunities for interaction and engagement. However, there is a lack
of understanding of people’s strategies and behaviors when directly manipulating physical
data objects. In this paper, we systematically characterize different reconfiguration
strategies using six exemplar physicalizations. We asked 20 participants to reorganize
these exemplars with two levels of restriction: changing a single data object versus
changing multiple data objects. Our findings show that there were two main reconfiguration
strategies used: changes in proximity and changes in atomic orientation. We further
characterize these using concrete examples of participant actions in relation to the
structure of the physicalizations. We contribute an overview of reconfiguration strategies,
which informs the design of future manually reconfigurable and dynamic composite physicalizations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {471},
numpages = {18}
}

@inbook{10.1145/3411764.3445532,
author = {Liang, Wei and Yu, Xinzhe and Alghofaili, Rawan and Lang, Yining and Yu, Lap-Fai},
title = {Scene-Aware Behavior Synthesis for Virtual Pets in Mixed Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445532},
abstract = { Virtual pets are an alternative to real pets, providing a substitute for people with
allergies or preparing people for adopting a real pet. Recent advancements in mixed
reality pave the way for virtual pets to provide a more natural and seamless experience
for users. However, one key challenge is embedding environmental awareness into the
virtual pet (e.g., identifying the food bowl’s location) so that they can behave naturally
in the real world. We propose a novel approach to synthesize virtual pet behaviors
by considering scene semantics, enabling a virtual pet to behave naturally in mixed
reality. Given a scene captured from the real world, our approach synthesizes a sequence
of pet behaviors (e.g., resting after eating). Then, we assign each behavior in the
sequence to a location in the real scene. We conducted user studies to evaluate our
approach, which showed the efficacy of our approach in synthesizing natural virtual
pet behaviors.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {472},
numpages = {12}
}

@inbook{10.1145/3411764.3445751,
author = {Liu, Tingting and Li, Xiaotong and Bao, Chen and Correll, Michael and Tu, Changehe and Deussen, Oliver and Wang, Yunhai},
title = {Data-Driven Mark Orientation for Trend Estimation in Scatterplots},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445751},
abstract = {A common task for scatterplots is communicating trends in bivariate data. However,
the ability of people to visually estimate these trends is under-explored, especially
when the data violate assumptions required for common statistical models, or visual
trend estimates are in conflict with statistical ones. In such cases, designers may
need to intervene and de-bias these estimations, or otherwise inform viewers about
differences between statistical and visual trend estimations. We propose data-driven
mark orientation as a solution in such cases, where the directionality of marks in
the scatterplot guide participants when visual estimation is otherwise unclear or
ambiguous. Through a set of laboratory studies, we investigate trend estimation across
a variety of data distributions and mark directionalities, and find that data-driven
mark orientation can help resolve ambiguities in visual trend estimates. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {473},
numpages = {16}
}

@inbook{10.1145/3411764.3445142,
author = {Kawas, Saba and Kuhn, Nicole S. and Sorstokke, Kyle and Bascom, Emily and Hiniker, Alexis and Davis, Katie},
title = {When Screen Time Isn't Screen Time: Tensions and Needs Between Tweens and Their Parents During Nature-Based Exploration},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445142},
abstract = {We investigated the experiences of 15 parents and their tween children (ages 8-12,
n=23) during nature explorations using the NatureCollections app, a mobile application
that connects children with nature. Drawing on parent interviews and in-app audio
recordings from a 2-week deployment study, we found that tweens’ experiences with
the NatureCollections app were influenced by tensions surrounding how parents and
tweens negotiate technology use more broadly. Despite these tensions, the app succeeded
in engaging tweens in outdoor nature explorations, and parents valued the shared family
experiences around nature. Parents desired the app to support family bonding and inform
them about how their tween used the app. This work shows how applications intended
to support enriching youth experiences are experienced in the context of screen time
tensions between parents and tween during a transitional period of child development.
We offer recommendations for designing digital experiences to support family needs
and reduce screen time tensions.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {14}
}

@inbook{10.1145/3411764.3445427,
author = {Yu, Junnan and DeVore, Andrea and Roque, Ricarose},
title = {Parental Mediation for Young Children’s Use of Educational Media: A Case Study with Computational Toys and Kits},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445427},
abstract = { Parental mediation literature is mostly situated in the contexts of television, Internet
use, video games, and mobile devices, while there is less understanding of how parents
mediate their children’s engagement with educational-focused media. We examine parental
involvement in young children’s use of a creation-oriented educational media, i.e.,
coding kits, from a mediation perspective through an interview study. We frame parents’
mediation practices along three dimensions: (1) creative mediation, where parents
mediate to support children’s creating and learning with media; (2) preparative mediation,
where parents explore and prepare media for children’s engagement; and (3) administrative
mediation, where parents administer and regulate their children’s media use. Compared
to the restrictive, active, and co-using mediation theory, our proposed framework
highlights various supportive practices parents take to help their children learn
and create with media. We further connect our findings to Joint Media Engagement and
reflect on implications for parent involvement in children’s creation-oriented media
design.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {475},
numpages = {12}
}

@inbook{10.1145/3411764.3445713,
author = {Baishya, Uddipana and N. Antle, Alissa and Neustaedter, Carman},
title = {Exploring Opportunities to Aid Generation of Input Action Ideas for Tangible User Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445713},
abstract = {Novice tangible interaction design students often find it challenging to generate
input action ideas for tangible interfaces. To identify opportunities to aid input
action idea generation, we built and evaluated a tool consisting of interactive physical
artifacts coupled with digital examples of tangible systems and technical implementation
guidance. Through video recorded design sessions and interviews with twelve students,
we investigated how they used the tool to generate input action ideas, how it supported
them, and what challenges they faced. We found that the tool helped in generating
input action ideas by enabling to experience input actions, supporting hands-on explorations,
and introducing possibilities. However, introducing examples at times caused design
fixation. The tool fell short in supporting the planning of technical implementation
of the generated ideas. This research is useful for tangible interaction design students,
instructors, and researchers to apply in education, design similar tools, or conduct
further research.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {476},
numpages = {21}
}

@inbook{10.1145/3411764.3445726,
author = {Villanueva, Ana M and Liu, Ziyi and Zhu, Zhengzhe and Du, Xin and Huang, Joey and Peppler, Kylie A and Ramani, Karthik},
title = {RobotAR: An Augmented Reality Compatible Teleconsulting Robotics Toolkit for Augmented Makerspace Experiences},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445726},
abstract = { Distance learning is facing a critical moment finding a balance between high quality
education for remote students and engaging them in hands-on learning. This is particularly
relevant for project-based classrooms and makerspaces, which typically require extensive
trouble-shooting and example demonstrations from instructors. We present RobotAR,
a teleconsulting robotics toolkit for creating Augmented Reality (AR) makerspaces.
We present the hardware and software for an AR-compatible robot, which behaves as
a student’s voice assistant and can be embodied by the instructor for teleconsultation.
As a desktop-based teleconsulting agent, the instructor has control of the robot’s
joints and position to better focus on areas of interest inside the workspace. Similarly,
the instructor has access to the student’s virtual environment and the capability
to create AR content to aid the student with problem-solving. We also performed a
user study which compares current techniques for distance hands-on learning and an
implementation of our toolkit.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {477},
numpages = {13}
}

@inbook{10.1145/3411764.3445191,
author = {Fuchsberger, Verena and Beuthel, Janne Mascha and Bentegeac, Philippe and Tscheligi, Manfred},
title = {Grandparents and Grandchildren Meeting Online: The Role of Material Things in Remote Settings},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445191},
abstract = { Grandparents and grandchildren, who cannot meet face-to-face (e.g., due to dislocation
or physical distancing induced by a pandemic), often use audio-visual communication
tools in order to maintain their relationship online. In a qualitative online survey
(n = 85), we inquired into the various ways that grandparents and grandchildren came
up with when being physically distant; many of them are tangible in nature as they
include “things” or incorporate “spaces”. In this paper, we illustrate related temporal
and spatial trajectories and unpack how online meetings are characterized by constant
negotiations of agency. We discuss how online meetings could complement face-to-face
meetings, instead of mimicking or replacing them. We finally articulate a collection
of design sensitivities with the aim to both inspire and question designing for intergenerational
online meetings.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {478},
numpages = {14}
}

@inbook{10.1145/3411764.3445688,
author = {Kang, Bumsoo and Kang, Seungwoo and Hwang, Inseok},
title = {MomentMeld: AI-Augmented Mobile Photographic Memento towards Mutually Stimulatory Inter-Generational Interaction},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445688},
abstract = { Aging often comes with declining social interaction, a known adversarial factor impacting
the life satisfaction of senior population. Such decline appears even in family–a
permanent social circle, as their adult children eventually go independent. We present
MomentMeld, an AI-powered, cloud-backed mobile application that blends with everyday
routine and naturally encourages rich and frequent inter-generational interactions
in a family, especially those between the senior generation and their adult children.
Firstly, we design a photographic interaction aid called mutually stimulatory memento,
which is a cross-generational juxtaposition of semantically related photos to bring
natural arousal of context-specific inter-generational empathy and reminiscence. Secondly,
we build comprehensive ensemble AI models consisting of various deep neural networks
and a runtime system that automates the creation of mutually stimulatory memento on
top of the user’s usual photo-taking routines. We deploy MomentMeld in-the-wild with
six families for an eight-week period, and discuss the key findings and further implications.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {479},
numpages = {16}
}

@inbook{10.1145/3411764.3445376,
author = {Oyg\"{u}r, I\th{}il and Su, Zhaoyuan and A. Epstein, Daniel and Chen, Yunan},
title = {The Lived Experience of Child-Owned Wearables: Comparing Children's and Parents’ Perspectives on Activity Tracking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445376},
abstract = {Children are increasingly using wearables with physical activity tracking features.
Although research has designed and evaluated novel features for supporting parent-child
collaboration with these wearables, less is known about how families naturally adopt
and use these technologies in their everyday life. We conducted interviews with 17
families who have naturally adopted child-owned wearables to understand how they use
wearables individually and collaboratively. Parents are primarily motivated to use
child-owned wearables for children's long-term health and wellbeing, whereas children
mostly seek out entertainment and feeling accomplished through reaching goals. Children
are often unable to interpret or contextualize the measures that wearables record,
while parents do not regularly track these measures and focus on deviations from their
children's routines. We discuss opportunities for making naturally-occurring family
moments educational to positively contribute to children's conceptual understanding
of health, such as developing age-appropriate trackable metrics for shared goal-setting
and data reflection.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {480},
numpages = {12}
}

@inbook{10.1145/3411764.3445139,
author = {Norouzi, Behnaz and Kinnula, Marianne and Iivari, Netta},
title = {Making Sense of 3D Modelling and 3D Printing Activities of Young People: A Nexus Analytic Inquiry},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445139},
abstract = {Physical space and materials we work with, as well as people we interact with affect
the design and making processes. These aspects in relation to 3D designing in alignment
with 3D printing need considerable exploration within Child-Computer interaction (CCI)
research community. We conducted our case study by collecting 9-full-day-observation
and interview data and examining 3D modeling and 3D printing activities, as work duties
of 15-17-years-old summer trainees organized at the university. We identified, inspired
by nexus analysis, different discourses circulating around these activities of novice
young people and how the discourses are intermingled with the space, the materials,
and the task at hand in complex ways, constructing and shaping the experience of the
young participants. In our research and design implications, by signifying the impact
of the people, challenges, tasks, spaces and tools, we provide recommendations for
maintaining children's engagement in digital fabrication, significantly 3D designing
and 3D printing, activities.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {481},
numpages = {16}
}

@inbook{10.1145/3411764.3445760,
author = {Petersen, Gustav B\o{}g and Mottelson, Aske and Makransky, Guido},
title = {Pedagogical Agents in Educational VR: An in the Wild Study},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445760},
abstract = {Pedagogical agents are theorized to increase humans’ effort to understand computerized
instructions. Despite the pedagogical promises of VR, the usefulness of pedagogical
agents in VR remains uncertain. Based on this gap, and inspired by global efforts
to advance remote learning during the COVID-19 pandemic, we conducted an educational
VR study in-the-wild (N = 161). With a 2 \texttimes{} 2 + 1 between subjects design, we manipulated
the appearance and behavior of a virtual museum guide in an exhibition about viruses.
Factual and conceptual learning outcomes as well as subjective learning experience
measures were collected. In general, participants reported high enjoyment and had
significant knowledge acquisition. We found that the agent’s appearance and behavior
impacted factual knowledge gain. We also report an interaction effect between behavioral
and visual realism for conceptual knowledge gain. Our findings nuance classical multimedia
learning theories and provide directions for employing agents in immersive learning
environments. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {482},
numpages = {12}
}

@inbook{10.1145/3411764.3445596,
author = {Gao, Hong and Bozkir, Efe and Hasenbein, Lisa and Hahn, Jens-Uwe and G\"{o}llner, Richard and Kasneci, Enkelejda},
title = {Digital Transformations of Classrooms in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445596},
abstract = { With rapid developments in consumer-level head-mounted displays and computer graphics,
immersive VR has the potential to take online and remote learning closer to real-world
settings. However, the effects of such digital transformations on learners, particularly
for VR, have not been evaluated in depth. This work investigates the interaction-related
effects of sitting positions of learners, visualization styles of peer-learners and
teachers, and hand-raising behaviors of virtual peer-learners on learners in an immersive
VR classroom, using eye tracking data. Our results indicate that learners sitting
in the back of the virtual classroom may have difficulties extracting information.
Additionally, we find indications that learners engage with lectures more efficiently
if virtual avatars are visualized with realistic styles. Lastly, we find different
eye movement behaviors towards different performance levels of virtual peer-learners,
which should be investigated further. Our findings present an important baseline for
design decisions for VR classrooms.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {483},
numpages = {10}
}

@inbook{10.1145/3411764.3445711,
author = {Ahuja, Karan and Shah, Deval and Pareddy, Sujeath and Xhakaj, Franceska and Ogan, Amy and Agarwal, Yuvraj and Harrison, Chris},
title = {Classroom Digital Twins with Instrumentation-Free Gaze Tracking},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445711},
abstract = { Classroom sensing is an important and active area of research with great potential
to improve instruction. Complementing professional observers – the current best practice
– automated pedagogical professional development systems can attend every class and
capture fine-grained details of all occupants. One particularly valuable facet to
capture is class gaze behavior. For students, certain gaze patterns have been shown
to correlate with interest in the material, while for instructors, student-centered
gaze patterns have been shown to increase approachability and immediacy. Unfortunately,
prior classroom gaze-sensing systems have limited accuracy and often require specialized
external or worn sensors. In this work, we developed a new computer-vision-driven
system that powers a 3D “digital twin” of the classroom and enables whole-class, 6DOF
head gaze vector estimation without instrumenting any of the occupants. We describe
our open source implementation, and results from both controlled studies and real-world
classroom deployments.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {484},
numpages = {9}
}

@inbook{10.1145/3411764.3445764,
author = {Mu\~{n}oz, Diego and Favilla, Stu and Pedell, Sonja and Murphy, Andrew and Beh, Jeanie and Petrovich, Tanya},
title = {Evaluating an App to Promote a Better Visit Through Shared Activities for People Living with Dementia and Their Families},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445764},
abstract = {This project aims to foster shared positive experiences between people living with
moderate to advanced dementia and their visitors as they may struggle to find topics
to talk about and engaging things to do together. To promote a better visit, we trialed
a previously developed app that includes eight games with twenty-one residents and
their partners or carers across four care centers for three months each. Through interviews
and data logging, we found that residents preferred games that were closer to their
interests and skills, and that gameplay and cooperation fostered meaningful and shared
interactions between residents and their visitors. The contribution of this work is
twofold: (1) insights and opportunities into dyadic interactions when using an app
and into promoting positive social experiences through technology design, and (2)
reflections on the challenges of evaluating the benefits of technology for people
living with dementia.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {485},
numpages = {13}
}

@inbook{10.1145/3411764.3445057,
author = {Bircanin, Filip and Brereton, Margot and Sitbon, Laurianne and Ploderer, Bernd and Azaabanye Bayor, Andrew and Koplick, Stewart},
title = {Including Adults with Severe Intellectual Disabilities in Co-Design through Active Support},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445057},
abstract = {In recent work, design researchers have sought to ensure that people with disabilities
are engaged as competent and valued contributors to co-design. Yet, little is known
about how to achieve this with adults with severe intellectual disabilities. Navigating
design in the context of complex care practices is challenging, charged with uncertainty,
and requires sustained effort of methodological and affective adjustments. To establish
a respectful co-design relationship and enrich participation, we turn to Active Support
(AS), an evidence-based strategy for engaging adults with severe intellectual disabilities.
We present a reflective account of long-term field work that utilized the four aspects
of AS, a) every moment has potential; b) graded assistance; c) little and often; d)
maximizing choice and control. We discuss how these principles contribute to deepening
HCI methods by ensuring interactional turns for adults with severe disabilities, revealing
their unique competences, thereby shaping design direction and providing design insight.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {486},
numpages = {12}
}

@inbook{10.1145/3411764.3445090,
author = {Storer, Kevin M and Sampath, Harini and Merrick, M. Alice Alice},
title = {”It’s Just Everything Outside of the IDE That’s the Problem”: Information Seeking by Software Developers with Visual Impairments},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445090},
abstract = { Many efforts to increase accessibility in coding for developers with visual impairments
(DWVI) focus on supporting interactions with development tools. But, to understand
how to appropriately modify and write source code, developers must seek information
from a variety of disparate and highly technical sources. DWVI might benefit from
technological support in this process. But, it is unclear what accessibility issues
arise in technical information sources, whether accessibility impacts strategies for
seeking technical information, or how best to support DWVI in information seeking.
We conducted observations and interviews with twelve DWVI, to explore their information
behaviors. We found that DWVI seek information in many of the same sources as their
sighted peers, and accessibility issues in technical information sources were similar
to those in nontechnical sources. But, despite these similarities, examining development
as an information seeking process highlighted the role of contextual and social factors
in determining accessibility for DWVI.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {487},
numpages = {12}
}

@inbook{10.1145/3411764.3445521,
author = {Gotfrid, Taylor and Mack, Kelly and Lum, Kathryn J and Yang, Evelyn and Hodgins, Jessica and Hudson, Scott E and Mankoff, Jennifer},
title = {Stitching Together the Experiences of Disabled Knitters},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445521},
abstract = { Knitting is a popular craft that can be used to create customized fabric objects
such as household items, clothing and toys. Additionally, many knitters find knitting
to be a relaxing and calming exercise. Little is known about how disabled knitters
use and benefit from knitting, and what accessibility solutions and challenges they
create and encounter. We conducted interviews with 16 experienced, disabled knitters
and analyzed 20 threads from six forums that discussed accessible knitting to identify
how and why disabled knitters knit, and what accessibility concerns remain. We additionally
conducted an iterative design case study developing knitting tools for a knitter who
found existing solutions insufficient. Our innovations improved the range of stitches
she could produce. We conclude by arguing for the importance of improving tools for
both pattern generation and modification as well as adaptations or modifications to
existing tools such as looms to make it easier to track progress},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {488},
numpages = {14}
}

@inbook{10.1145/3411764.3445544,
author = {Sampath, Harini and Merrick, Alice and Macvean, Andrew},
title = {Accessibility of Command Line Interfaces},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445544},
abstract = { Command-line interfaces (CLIs) remain a popular tool among developers and system
administrators. Since CLIs are text-based interfaces, they are sometimes considered
accessible alternatives to predominantly visual developer tools like IDEs. However,
there is no systematic evaluation of the accessibility of CLIs in the literature.
In this paper, we describe two studies with 12 developers on their experience of using
CLIs with screen readers. Our findings show that CLIs have their own set of accessibility
issues - the most important being CLIs are unstructured text interfaces. Based on
our results, we provide a set of recommendations for improving the accessibility of
command-line interfaces.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {489},
numpages = {10}
}

@inbook{10.1145/3411764.3445702,
author = {Pang, Carolyn and Collin Wang, Zhiqin and McGrenere, Joanna and Leung, Rock and Dai, Jiamin and Moffatt, Karyn},
title = {Technology Adoption and Learning Preferences for Older Adults: Evolving Perceptions, Ongoing Challenges, and Emerging Design Opportunities},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445702},
abstract = {Technology adoption among older adults has increased significantly in recent years.
Yet, as new technologies proliferate and the demographics of aging shift, continued
attention to older adults’ adoption priorities and learning preferences is required.
Through semi-structured interviews, we examine the factors adults 65+ prioritize in
choosing new technologies, the challenges they encounter in learning to use them,
and the human and material resources they employ to support these efforts. Using a
video prototype as a design probe, we present scenarios to explore older adults’ perceptions
of adoption and learning new technologies within the lens of health management support,
a relevant and beneficial context for older adults. Our results reveal that participants
appreciated self-paced learning, remote support, and flexible learning methods, and
were less reliant on instruction manuals than in the past. This work provides insight
into older adults’ evolving challenges, learning needs, and design opportunities for
next generation learning support.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {490},
numpages = {13}
}

@inbook{10.1145/3411764.3445752,
author = {Baker, Steven and Waycott, Jenny and Carrasco, Romina and Kelly, Ryan M. and Jones, Anthony John and Lilley, Jack and Dow, Briony and Batchelor, Frances and Hoang, Thuong and Vetere, Frank},
title = {Avatar-Mediated Communication in Social VR: An In-Depth Exploration of Older Adult Interaction in an Emerging Communication Platform},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445752},
abstract = {While HCI researchers have begun designing personalised VR experiences for older adults,
there has been limited research examining the use of social VR - where users interact
via avatars in a virtual environment. Avatar-mediated communication (AMC) is a crucial
component of the social VR experience, but older users’ experience with AMC is poorly
understood. We conducted a five-month study with 16 older adults evaluating a co-designed
social VR prototype. Results show that AMC in social VR was seen as medium that supported
introverted users to express themselves and was viewed as offering advantages when
discussing sensitive topics. Our study provides new insights into how older adults
view AMC in social VR as a communication medium and we contribute six design reflections,
based on our results, that highlight the steps that can be taken to ensure that AMC
in social VR can meet the communication needs of older users. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {13}
}

@inbook{10.1145/3411764.3445303,
author = {Duval, Jared and Altarriba Bertran, Ferran and Chen, Siying and Chu, Melissa and Subramonian, Divya and Wang, Austin and Xiang, Geoffrey and Kurniawan, Sri and Isbister, Katherine},
title = {Chasing Play on TikTok from Populations with Disabilities to Inspire Playful and Inclusive Technology Design},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445303},
abstract = { There is an open call for technology to be more playful [5, 79] and for tech design
to be more inclusive of people with disabilities [80]. In the era of COVID19, it is
often unsafe for the public in general and people with disabilities, in particular,
to engage in in-person design exercises using traditional methods. This presents a
missed opportunity as these populations are already sharing playful content rich with
tacit design knowledge that can be used to inspire the design of playful everyday
technology. We present our process of scraping play potentials [4] from TikTok from
content creators with disabilities to generate design concepts that may inspire future
technology design. We share 7 emerging themes from the scraped content, a catalog
of design concepts that may inspire designers, and discuss the relevance of the emerging
themes and possible implications for the design concepts.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {492},
numpages = {15}
}

@inbook{10.1145/3411764.3445520,
author = {Li, Junchen and W. Tigwell, Garreth and Shinohara, Kristen},
title = {Accessibility of High-Fidelity Prototyping Tools},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445520},
abstract = {High-fidelity prototyping tools are used by software designers and developers to iron
out interface details without full implementation. However, the lack of visual accessibility
in these tools creates a barrier for designers who may use screen readers, such as
those who are vision impaired. We assessed conformance of four prototyping tools (Sketch,
Adobe XD, Balsamiq, UXPin) with accessibility guidelines, using two screen readers
(Narrator and VoiceOver), focusing our analysis on GUI element accessibility and critical
workflows used to create prototypes. We found few tools were fully accessible, with
45.9% of GUI elements meeting accessibility criteria (34.2% partially supported accessibility,
19.9% not supporting accessibility). Accessibility issues stymied efforts to create
prototypes using screen readers. Though no screen reader-tool pairs were completely
accessible, the most accessible pairs were VoiceOver-Sketch, VoiceOver-Balsamiq, and
Narrator-Balsamiq. We recommend prioritizing improved accessibility for input and
control instruction, alternative text, focus order, canvas element properties, and
keyboard operations.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {493},
numpages = {17}
}

@inbook{10.1145/3411764.3445547,
author = {Wang, Ruolin and Chen, Zixuan and Zhang, Mingrui Ray and Li, Zhaoheng and Liu, Zhixiu and Dang, Zihan and Yu, Chun and Chen, Xiang 'Anthony'},
title = {Revamp: Enhancing Accessible Information Seeking Experience of Online Shopping for Blind or Low Vision Users},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445547},
abstract = {Online shopping has become a valuable modern convenience, but blind or low vision
(BLV) users still face significant challenges using it, because of: 1) inadequate
image descriptions and 2) the inability to filter large amounts of information using
screen readers. To address those challenges, we propose Revamp, a system that leverages
customer reviews for interactive information retrieval. Revamp is a browser integration
that supports review-based question-answering interactions on a reconstructed product
page. From our interview, we identified four main aspects (color, logo, shape, and
size) that are vital for BLV users to understand the visual appearance of a product.
Based on the findings, we formulated syntactic rules to extract review snippets, which
were used to generate image descriptions and responses to users’ queries. Evaluations
with eight BLV users showed that Revamp 1) provided useful descriptive information
for understanding product appearance and 2) helped the participants locate key information
efficiently. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {494},
numpages = {14}
}

@inbook{10.1145/3411764.3445638,
author = {Abdolrahmani, Ali and Howes Gupta, Maya and Vader, Mei-Lian and Kuber, Ravi and Branham, Stacy},
title = {Towards More Transactional Voice Assistants: Investigating the Potential for a Multimodal Voice-Activated Indoor Navigation Assistant for Blind and Sighted Travelers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445638},
abstract = {Voice assistants (VAs) – like Amazon Alexa or Siri – offer hands-/eyes-free interactions
that are beneficial to a range of users, including individuals who are blind, to fulfill
tasks that are otherwise difficult or inaccessible. While these interfaces model conversational
interactions to achieve simple tasks, there have been recent calls for VAs that model
more transactional interactions for a wider range of complex activities. In this study,
we explored the extension of VAs’ capabilities in the context of indoor navigation
through mixed-ability focus groups with blind and sighted airport travelers. We found
high overlap in the difficulties encountered by blind and sighted travelers, as well
as shared interest in a voice-activated travel assistant to improve travel experiences.
Leveraging user-elicited recommendations, we present interaction design examples that
showcase customization of different and multiple modalities, which collectively demonstrate
how VAs can more broadly achieve transactional interactions in complex task scenarios.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {495},
numpages = {16}
}

@inbook{10.1145/3411764.3445280,
author = {Obiorah, Mmachi God'sglory and Piper, Anne Marie Marie and Horn, Michael},
title = {Designing AACs for People with Aphasia Dining in Restaurants},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445280},
abstract = { There is a growing need to design augmentative and alternative communication (AAC)
devices that focus on supporting quality of life goals, such as increased social participation
in leisurely activities. Yet, designing AAC applications that support leisurely activities
is difficult, as the activity might require novel and specific language in a timely
manner. Through observations and contextual interviews with people with aphasia, their
social partners, and speech-language therapists, we characterize the important but
challenging nature of supporting one specific leisure activity: meal ordering in restaurants.
Based on our observational and interview data, we design and explore three prototype
AAC systems to support people with aphasia in ordering meals in restaurants. Each
prototype integrates a different AI technology, contributing insights into how AI
may enhance AAC usage and design. The study opens up questions of designing accessible
restaurant experiences for neurodivergent people and the role of AI in AAC devices
more broadly. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {496},
numpages = {14}
}

